(self.webpackChunkjohnnyreilly_com=self.webpackChunkjohnnyreilly_com||[]).push([[39699,64518,85308,42974,17181,60080,11661,68394,50218,52741,82147,93925,88468,15642,48441,71709,39732,13198,7224,51187,62304,32585,13264,24894,59812,17010,83599,98022,1412,95572,6064,81705,77448,27113,43575,95962,17192,66159,87940,68870,23057,50307,1376,78132,60948,45942,90174,72143,80822,20800,5424,54629,84748,11160,22375,93313,95340,38946,89161,98310,325,65865,39503,40072,17843,95966,79343,57874,81557,14068,41402,41106,63351,63275,451,49420,63104,69507,13462,85672,90413,92688,36683,66467,96763,7504,1714,74595,2378,33083,89163,98511,66190,60722,40922,77455,35983,20202,29586,80222,44638,1698,88997,26739,99463,2474,83925,99998,57411,91044,31315,27649,41514,26605,18574,89538,90937,47652,1630,98751,74614,29551,27526,41999,96984,19230,2368,35087,86612,5860,20538,69438,52715,89779,95738,56863,58113,7491,47911,11733,93171,22658,95852,60573,61595,45395,14510,80784,25896,68989,6806,73792,67356,47519,81431,36345,4805,55144,5606,25906,26444,42414,87903,63546,53910,48560,2402,9138,93090,49246,88949,85462,40284,21006,8279,78522,94597,32976,97054,75911,17068,28070,76689,68339,54869,45168,83606,58050,44637,53758,91924,81204,14576,33333,91515,82278,36891,25816,39530,57698,73156,58225,58891,21650,64613,38288,17014,52243,78806,35253,8224,17301,34643,34667,82832,78358,78842,66148,90180,35006,74351,26578,17891,32461,92952,79746,35153,90749,72014,35873,16023,30315,39037,66156,83779,72687,7915,74375,90702,86990,78254,32408,30687,30113,43142,70954,47060,47187,79225,94109,37486,13052,46133,2930,60967,11845,28511,98228,86989,21597,1902,1326,60017,17178,99581,79806,69443,10287,60921,31777,22624,60936,18936,74400,89398,9993,29028,59146,44947,64585,86896,21887,53501,52947,83359,3951,54034,87350,1476,13957,42487,71456,52905,40482],{84681:(e,t,n)=>{var a={"./2012-01-07-standing-on-shoulders-of-giants/index.md":98624,"./2012-01-14-jqgrid-its-just-far-better-grid/index.md":27378,"./2012-01-24-what-on-earth-is-jquery-and-why-should/index.md":19785,"./2012-01-30-javascript-getting-to-know-beast/index.md":34607,"./2012-02-05-potted-history-of-using-ajax-on/index.md":32630,"./2012-02-15-wcf-transport-windows-authentication/index.md":86702,"./2012-02-23-joy-of-json/index.md":81295,"./2012-03-03-jquery-unobtrusive-remote-validation/index.md":45372,"./2012-03-12-striving-for-javascript-convention/index.md":21706,"./2012-03-17-using-pubsub-observer-pattern-to/index.md":17667,"./2012-03-22-wcf-moving-from-config-to-code-simple/index.md":38008,"./2012-04-05-making-pdfs-from-html-in-c-using/index.md":4631,"./2012-04-16-simple-technique-for-initialising/index.md":97428,"./2012-04-23-jshint-customising-your-hurt-feelings/index.md":16558,"./2012-04-28-beg-steal-or-borrow-decent-javascript/index.md":85826,"./2012-05-07-globalizejs-number-and-date/index.md":9219,"./2012-05-30-dad-didnt-buy-any-games/index.md":48840,"./2012-06-04-reasons-to-be-cheerful-why-now-is-good/index.md":28985,"./2012-07-01-how-im-structuring-my-javascript-in-web/index.md":61945,"./2012-07-16-rendering-partial-view-to-string/index.md":71522,"./2012-08-06-jquery-unobtrusive-validation/index.md":91094,"./2012-08-16-closedxml-real-sdk-for-excel/index.md":96120,"./2012-08-24-how-to-attribute-encode-partialview-in/index.md":14293,"./2012-09-06-globalize-and-jquery-validate/index.md":24955,"./2012-09-24-giving-odata-to-crm-40/index.md":17196,"./2012-10-03-unit-testing-and-entity-framework-filth/index.md":41235,"./2012-10-05-using-web-optimization-with-mvc-3/index.md":72070,"./2012-10-22-mvc-3-meet-dictionary/index.md":39839,"./2012-11-02-xsdxml-schema-generator-xsdexe-taking/index.md":44765,"./2012-11-13-a-nicer-net-api-for-bloombergs-open-api/index.md":85410,"./2013-01-03-html-to-pdf-using-wcf-service/index.md":10528,"./2013-01-09-twitterbootstrapmvc4-meet-bootstrap/index.md":23579,"./2013-01-14-twitterbootstrapmvc4-meet-bootstrap_14/index.md":25770,"./2013-02-13-using-expressions-with-constructors/index.md":7550,"./2013-02-18-unit-testing-mvc-controllers-mocking/index.md":9120,"./2013-03-03-unit-testing-modelstate/index.md":65876,"./2013-03-11-decimalmodelbinder-for-nullable-decimals/index.md":55675,"./2013-04-01-death-to-compatibility-mode/index.md":63460,"./2013-04-09-making-ie-10s-clear-field-x-button-and/index.md":85785,"./2013-04-17-ie-10-install-torches-javascript/index.md":40704,"./2013-04-26-a-navigation-animation-for-your-users/index.md":42600,"./2013-05-04-how-im-using-cassette/index.md":49201,"./2013-06-06-how-im-using-cassette-part-2/index.md":68888,"./2013-06-26-jquery-validate-native-unobtrusive-validation/index.md":145,"./2013-07-06-how-im-using-cassette-part-3-typescript/index.md":9573,"./2013-08-08-announcing-jquery-validation/index.md":73297,"./2013-08-17-using-bootstrap-tooltips-to-display/index.md":36185,"./2013-10-04-migrating-from-jquery.validate.unobtrusive.js-to-jQuery.Validation.Unobtrusive.Native/index.md":67223,"./2013-10-30-getting-typescript-compile-on-save-and-continous-integration-to-play-nice/index.md":80977,"./2013-11-04-typescript-dont-forget-build-action-for-implicit-referencing/index.md":23138,"./2013-11-26-rolling-your-own-confirm-mechanism/index.md":61419,"./2013-12-04-simple-fading-in-and-out-using-css-transitions/index.md":75678,"./2013-12-13-nuget-and-webmatrix-how-to-install/index.md":47222,"./2014-01-09-upgrading-to-typescript-095-personal/index.md":7503,"./2014-01-24-integration-testing-with-entity/index.md":76689,"./2014-02-12-wpf-and-mystic-meg-or-playing/index.md":44278,"./2014-02-27-typescript-and-requirejs-keep-it-simple/index.md":31743,"./2014-03-05-caching-and-cache-busting-with-requirejs/index.md":73485,"./2014-03-11-knockout-globalize-valuenumber-binding/index.md":25578,"./2014-03-17-the-surprisingly-happy-tale-of-visual/index.md":26235,"./2014-04-01-typescript-instance-methods/index.md":83943,"./2014-05-05-typescript-jsdoc-and-intellisense/index.md":26289,"./2014-05-15-team-foundation-server-continuous-integration-and-javascript-unit-tests-in-unit-test-project/index.md":88723,"./2014-06-01-migrating-from-angularjs-to-angularts/index.md":26466,"./2014-06-20-dates-DataAnnotations-and-data-impedance-mismatch/index.md":90805,"./2014-07-03-hottowel-angular-meet-typescript/index.md":68552,"./2014-08-01-angularjs-meet-aspnet-server-validation/index.md":84848,"./2014-08-08-getting-more-RESTful-with-Web-API/index.md":61608,"./2014-08-12-my-unrequited-love-for-isolate-scope/index.md":11644,"./2014-09-06-running-javascript-unit-tests-in-appveyor/index.md":86247,"./2014-09-10-unit-testing-angular-controller-with/index.md":31301,"./2014-09-13-migrating-jasmine-tests-to-typescript/index.md":94437,"./2014-10-03-he-tasks-me-he-heaps-me-i-will-wreak/index.md":15430,"./2014-10-06-caching-and-cache-busting-in-angularjs-with-http-interceptors/index.md":63623,"./2014-11-04-using-gulp-in-visual-studio-instead-of-web-optimization/index.md":10212,"./2014-11-26-Coded-UI-IE-11-and-the-runas-problem/index.md":58276,"./2014-12-05-whats-in-a-name/index.md":73536,"./2014-12-12-gulp-npm-long-paths-and-visual-studio-fight/index.md":46648,"./2014-12-29-deploying-aspnet-mvc-to-github-pages-with-appveyor-part-1/index.md":23085,"./2015-01-07-deploying-aspnet-mvc-to-github-pages-with-appveyor-part-2/index.md":93670,"./2015-01-20-typescript-using-functions-with-union-types/index.md":23132,"./2015-02-11-the-convent-with-continuous-delivery/index.md":35243,"./2015-02-17-using-gulp-in-asp-net-instead-of-web-optimization/index.md":38305,"./2015-02-27-hey-tsconfigjson-where-have-you-been/index.md":67917,"./2015-03-20-partialview-tostring/index.md":44262,"./2015-04-17-how-to-activate-your-emoji-keyboard-on-android/index.md":21673,"./2015-04-24-tonight-ill-start-open-source-project/index.md":89101,"./2015-05-05-a-tale-of-angular-html5mode-aspnet-mvc/index.md":93282,"./2015-05-11-ngvalidationfor-baby-steps/index.md":11743,"./2015-05-23-angular-ui-bootstrap-datepicker-weirdness/index.md":97079,"./2015-06-19-Back-to-the-Future-with-Code-First-Migrations/index.md":22832,"./2015-06-29-npm-please-stop-hurting-visual-studio/index.md":64715,"./2015-07-30-upgrading-to-globalize-1x-for-dummies/index.md":68428,"./2015-08-13-top-one-nice-one-get-sorted/index.md":24570,"./2015-09-10-things-done-changed/index.md":50045,"./2015-09-23-authoring-npm-modules-with-typescript/index.md":30259,"./2015-10-05-jquery-validation-globalize-hits-10/index.md":19551,"./2015-10-23-the-names-have-been-changed/index.md":25419,"./2015-11-30-iqueryable-ienumerable-hmmm/index.md":54334,"./2015-12-16-es6-typescript-babel-react-flux-karma/index.md":46098,"./2015-12-20-live-reload-considered-harmful/index.md":64180,"./2016-01-01-usestaticfiles-for-aspnet-vold/index.md":86946,"./2016-01-14-coded-ui-and-curse-of-docking-station/index.md":78590,"./2016-02-01-tfs-2012-net-45-and-c-6/index.md":67782,"./2016-02-19-visual-studio-tsconfigjson-and-external/index.md":55122,"./2016-02-29-creating-angular-ui-routes-in-controller/index.md":66874,"./2016-03-04-tfs-2012-meet-powershell-karma-and-buildnumber/index.md":21443,"./2016-03-17-atom-recovering-from-corrupted-packages/index.md":51351,"./2016-03-22-concatting-ienumerables-in-csharp/index.md":82941,"./2016-04-25-instant-stubs-with-jsonnet/index.md":8489,"./2016-05-13-inlining-angular-templates-with-webpack/index.md":37665,"./2016-05-24-the-mysterious-case-of-webpack-angular-and-jquery/index.md":81386,"./2016-06-02-create-es2015-map-from-array-in-typescript/index.md":81043,"./2016-07-23-using-webpacks-defineplugin-with-typescript/index.md":82058,"./2016-08-19-the-ternary-operator-meets-destructuring/index.md":16313,"./2016-09-12-integration-tests-with-sql-server/index.md":6454,"./2016-09-22-typescript-20-es2016-and-babel/index.md":11387,"./2016-10-05-react-component-curry/index.md":69958,"./2016-11-01-but-you-cant-die-i-love-you-ts-loader/index.md":84855,"./2016-11-12-my-subconscious-is-better-developer/index.md":24107,"./2016-12-11-webpack-syncing-enhanced-resolve/index.md":20284,"./2016-12-19-using-ts-loader-with-webpack-2/index.md":88210,"./2017-01-01-webpack-configuring-loader-with-query/index.md":50313,"./2017-01-06-webpack-resolveloader-alias-with-query/index.md":40722,"./2017-02-01-hands-free-https/index.md":77317,"./2017-02-14-typescript-types-and-repeatable-builds/index.md":82510,"./2017-02-23-under-duck-afternoon-in-open-source/index.md":38243,"./2017-03-28-debugging-aspnet-core-in-vs-or-code/index.md":31785,"./2017-03-30-im-looking-for-work/index.md":59134,"./2017-04-25-setting-build-version-using-appveyor/index.md":54029,"./2017-05-20-typescript-spare-rod-spoil-code/index.md":2860,"./2017-06-11-windows-defender-step-away-from-npm/index.md":9136,"./2017-07-02-dynamic-import-ive-been-await-ing-you/index.md":31949,"./2017-07-29-a-haiku-on-problem-with-semver-us/index.md":85962,"./2017-08-27-karma-from-phantomjs-to-headless-chrome/index.md":32512,"./2017-08-30-oh-glamour-of-open-source/index.md":54314,"./2017-09-07-typescript-webpack-super-pursuit-mode/index.md":23082,"./2017-09-12-fork-ts-checker-webpack-plugin-code/index.md":42794,"./2017-10-19-working-with-extrahop-on-webpack-and-ts/index.md":28890,"./2017-10-20-typescript-definitions-webpack-and-module-types/index.md":11802,"./2017-11-19-the-typescript-webpack-pwa/index.md":55752,"./2017-12-24-ts-loader-2017-retrospective/index.md":90505,"./2018-01-14-auth0-typescript-and-aspnet-core/index.md":49039,"./2018-01-28-webpack-4-ts-loader-fork-ts-checker/index.md":9361,"./2018-01-29-finding-webpack-4-use-map/index.md":56334,"./2018-02-25-ts-loader-400-fork-ts-checker-webpack/index.md":88151,"./2018-03-07-its-not-dead-webpack-and-dead-code/index.md":59683,"./2018-03-25-uploading-images-to-cloudinary-with-fetch/index.md":30196,"./2018-03-26-its-not-dead-2-mobx-react-devtools-and-the-undead/index.md":93013,"./2018-04-28-using-reflection-to-identify-unwanted-dependencies/index.md":49709,"./2018-05-13-compromising-guide-for-developers/index.md":85003,"./2018-06-16-vsts-yaml-up/index.md":65041,"./2018-06-24-vsts-and-ef-core-migrations/index.md":57374,"./2018-07-09-cypress-and-auth0/index.md":79714,"./2018-07-28-azure-app-service-web-app-containers-asp-net-nested-configuration/index.md":53286,"./2018-08-21-typescript-webpack-alias-goodbye-relative-paths/index.md":57013,"./2018-09-15-semantic-versioning-and-definitely-typed/index.md":1573,"./2018-09-23-ts-loader-project-references-first-blood/index.md":84112,"./2018-10-07-font-awesome-brand-icons-react/index.md":10546,"./2018-10-27-making-a-programmer/index.md":98883,"./2018-11-17-snapshot-testing-for-c/index.md":37047,"./2018-12-10-cache-rules-everything-around-me/index.md":97139,"./2018-12-22-you-might-not-need-thread-loader/index.md":19083,"./2019-01-05-github-actions-and-yarn/index.md":409,"./2019-01-13-typescript-and-webpack-watch-it/index.md":65007,"./2019-02-22-aspnet-core-allowlist-proxying-http-requests/index.md":47588,"./2019-03-06-fork-ts-checker-webpack-plugin-v1/index.md":60105,"./2019-03-22-google-analytics-api-and-aspnet-core/index.md":95708,"./2019-03-24-template-tricks-for-dainty-dom/index.md":39665,"./2019-04-27-react-select-with-less-typing-lag/index.md":9309,"./2019-05-23-typescript-and-high-cpu-usage-watch/index.md":58118,"./2019-06-07-typescript-webpack-you-down-with-pnp/index.md":22456,"./2019-07-13-typescript-and-eslint-meet-fork-ts-checker-webpack-plugin/index.md":82627,"./2019-08-02-asp-net-authentication-hard-coding-claims/index.md":86163,"./2019-08-17-symbiotic-definitely-typed/index.md":23065,"./2019-09-14-coming-soon-definitely-typed/index.md":6804,"./2019-09-30-start-me-up-ts-loader-meet-tsbuildinfo/index.md":9397,"./2019-10-08-definitely-typed-the-movie/index.md":69982,"./2019-12-18-teams-notification-webhooks/index.md":45952,"./2020-01-02-ef-core-31-breaks-left-join-with-no-navigation-property/index.md":54596,"./2020-01-21-license-to-kill-your-pwa/index.md":68956,"./2020-01-31-from-create-react-app-to-pwa/index.md":40296,"./2020-02-21-web-workers-comlink-typescript-and-react/index.md":33038,"./2020-03-22-dual-boot-authentication-with-aspnetcore/index.md":1104,"./2020-03-29-offline-storage-in-pwa/index.md":9306,"./2020-04-04-up-to-clouds/index.md":38023,"./2020-05-10-from-react-window-to-react-virtual/index.md":11610,"./2020-05-21-autofac-webapplicationfactory-integration-tests/index.md":43206,"./2020-06-21-taskwhenall-select-is-footgun/index.md":19886,"./2020-07-11-devcontainers-and-ssl-interception/index.md":68994,"./2020-08-09-devcontainers-aka-performance-in-secure/index.md":75124,"./2020-09-04-why-your-team-needs-newsfeed/index.md":16968,"./2020-10-02-autofac-6-integration-tests-and-generic-hosting/index.md":74541,"./2020-10-19-safari-empty-download-content-type/index.md":62466,"./2020-10-31-azure-devops-node-api-git-api-getrefs-wiki-api/index.md":69137,"./2020-11-10-throttle-data-requests-with-react-hooks/index.md":95018,"./2020-11-14-bulletproof-uniq-with-typescript/index.md":28376,"./2020-11-28-images-in-markdown-for-azure-devops-marketplace/index.md":6876,"./2020-12-09-azure-pipelines-task-lib-and-isoutput-setvariable/index.md":91174,"./2020-12-20-nullable-reference-types-csharp-strictnullchecks/index.md":31056,"./2020-12-21-how-to-make-azure-ad-403/index.md":51990,"./2020-12-22-prettier-your-csharp-with-dotnet-format-and-lint-staged/index.md":97120,"./2020-12-30-azure-pipelines-meet-jest/index.md":68539,"./2021-01-02-create-react-app-with-ts-loader-and-craco/index.md":8511,"./2021-01-03-strongly-typing-react-query-s-usequeries/index.md":4573,"./2021-01-14-azure-easy-auth-and-roles-with-dotnet-and-core/index.md":46541,"./2021-01-17-azure-easy-auth-and-roles-with-net-and-microsoft-identity-web/index.md":39058,"./2021-01-29-surfacing-azure-pipelines-build-info-in-an-aspnet-react-app/index.md":16992,"./2021-01-30-aspnet-serilog-and-application-insights/index.md":69841,"./2021-02-08-arm-templates-security-role-assignments/index.md":90124,"./2021-02-11-azure-app-service-health-checks-and-zero-downtime-deployments/index.md":53706,"./2021-02-16-easy-auth-tokens-survive-releases-on-linux-azure-app-service/index.md":90488,"./2021-02-27-goodbye-client-affinity-hello-data-protection-with-azure/index.md":96093,"./2021-03-06-generate-typescript-and-csharp-clients-with-nswag/index.md":27106,"./2021-03-10-managed-identity-azure-sql-entity-framework/index.md":68051,"./2021-03-15-definitive-guide-to-migrating-from-blogger-to-docusaurus/index.md":57855,"./2021-03-17-rss-update-we-moved-to-docusaurus/index.md":30739,"./2021-03-20-bicep-meet-azure-pipelines/index.md":99994,"./2021-03-23-bicep-meet-azure-pipelines-2/index.md":27319,"./2021-04-10-hello-world-bicep/index.md":75890,"./2021-04-20-ts-loader-goes-webpack-5/index.md":55797,"./2021-04-24-service-now-api-and-typescript-conditional-types/index.md":53640,"./2021-05-01-blog-archive-for-docusaurus/index.md":59778,"./2021-05-08-create-pipeline-with-azure-devops-api/index.md":57941,"./2021-05-15-azurite-and-table-storage-dev-container/index.md":77207,"./2021-06-11-azure-functions-dotnet-5-query-params-di-bicep/index.md":86725,"./2021-06-30-react-18-and-typescript/index.md":989,"./2021-07-01-c-sharp-9-azure-functions-in-process/index.md":10575,"./2021-07-07-output-connection-strings-and-keys-from-azure-bicep/index.md":46710,"./2021-07-11-webpack-esbuild-why-not-both/index.md":16381,"./2021-07-14-directory-build-props-c-sharp-9-for-all/index.md":71560,"./2021-08-01-typescript-abstract-classes-and-constructors/index.md":14425,"./2021-08-14-typescript-4-4-more-readable-code/index.md":79844,"./2021-08-15-bicep-azure-static-web-apps-azure-devops/index.md":81635,"./2021-08-19-bicep-syntax-highlighting-with-prismjs/index.md":40391,"./2021-09-10-google-apis-authentication-with-typescript/index.md":98089,"./2021-09-12-permissioning-azure-pipelines-bicep-role-assignments/index.md":71502,"./2021-10-15-structured-data-seo-and-react/index.md":90187,"./2021-10-18-docusaurus-meta-tags-and-google-discover/index.md":90029,"./2021-10-31-nswag-generated-c-sharp-client-property-name-clash/index.md":18661,"./2021-11-18-azure-standard-tests-with-bicep/index.md":62037,"./2021-11-22-typescript-vs-jsdoc-javascript/index.md":29820,"./2021-12-05-azure-static-web-app-deploy-previews-with-azure-devops/index.md":62979,"./2021-12-12-open-graph-sharing-previews-guide/index.md":94516,"./2021-12-19-azure-container-apps-bicep-and-github-actions/index.md":5544,"./2021-12-27-azure-container-apps-build-and-deploy-with-bicep-and-github-actions/index.md":75259,"./2021-12-28-azure-cli-show-query-output-properties/index.md":9929,"./2021-12-29-preload-fonts-with-docusaurus/index.md":35044,"./2022-01-22-azure-container-apps-dapr-bicep-github-actions-debug-devcontainer/index.md":66830,"./2022-02-01-migrating-from-github-pages-to-azure-static-web-apps/index.md":38171,"./2022-02-02-lazy-loading-images-with-docusaurus/index.md":32313,"./2022-02-08-azure-static-web-apps-a-netlify-alternative/index.md":59159,"./2022-03-06-swashbuckle-inheritance-multiple-return-types/index.md":79408,"./2022-03-20-lighthouse-meet-github-actions/index.md":31345,"./2022-03-30-azure-devops-consume-private-nuget-artifact-feed/index.md":32673,"./2022-04-06-eslint-your-csharp-in-vs-code-with-roslyn-analyzers/index.md":73155,"./2022-04-16-type-annotations-strong-types-weakly-held/index.md":76187,"./2022-05-01-upgrading-to-react-18-typescript/index.md":547,"./2022-05-07-static-web-apps-azure-devops-named-preview-environments/index.md":63298,"./2022-05-28-azure-static-web-apps-node-16-oryx/index.md":83928,"./2022-06-07-typescript-4-7-and-ecmascript-module-support/index.md":43037,"./2022-06-21-azure-container-apps-pubsub/index.md":83054,"./2022-07-07-static-web-apps-failed-to-deploy-the-azure-functions/index.md":24753,"./2022-07-10-azure-devops-api-build-validations/index.md":49963,"./2022-07-23-terry-pratchett-x-clacks-overhead-azure-static-webapps/index.md":23122,"./2022-08-31-swashbuckle-schemaid-already-used/index.md":24598,"./2022-09-03-reverse-engineering-azure-app-insights-transactions-url/index.md":83878,"./2022-09-20-react-usesearchparamsstate/index.md":52566,"./2022-09-29-faster-docusaurus-build-swc-loader/index.md":35468,"./2022-10-01-typescript-unit-tests-with-debug-support/index.md":26917,"./2022-10-14-bicep-static-web-apps-linked-backends/index.md":60533,"./2022-10-20-web-monetization-api/index.md":35779,"./2022-11-11-debugging-azure-functions-vs-code-mac-os/index.md":68257,"./2022-11-17-azure-ad-claims-static-web-apps-azure-functions/index.md":96743,"./2022-11-22-xml-read-and-write-with-node-js/index.md":41185,"./2022-11-25-adding-lastmod-to-sitemap-git-commit-date/index.md":19969,"./2022-12-01-docusaurus-using-fontaine-to-reduce-custom-font-cumulative-layout-shift/index.md":84119,"./2022-12-04-azure-static-web-apps-easyauth-deeplink/index.md":26529,"./2022-12-11-publishing-docusaurus-to-devto-with-devto-api/index.md":71120,"./2022-12-18-azure-static-web-apps-build-app-externally/index.md":57662,"./2022-12-22-azure-static-web-apps-dynamic-redirects-azure-functions/index.md":61322,"./2022-12-26-docusaurus-image-cloudinary-rehype-plugin/index.md":5182,"./2023-01-01-application-insights-bicep-azure-static-web-apps/index.md":88082,"./2023-01-05-azure-pipelines-custom-pipelines-task-extension-node-16/index.md":21215,"./2023-01-15-how-i-ruined-my-seo/index.md":69189,"./2023-01-18-docusaurus-improve-core-web-vitals-fetchpriority/index.md":81252,"./2023-01-22-image-optimisation-tinypng-api/index.md":89234,"./2023-01-28-docusaurus-createfeeditems-api-git-commit-date/index.md":25420,"./2023-02-05-docusaurus-blogs-adding-breadcrumb-structured-data/index.md":61860,"./2023-02-11-in-defence-of-pull-requests/index.md":30720,"./2023-03-09-node-18-axios-and-unsafe-legacy-renegotiation-disabled/index.md":32221,"./2023-03-18-migrating-from-ts-node-to-bun/index.md":51877,"./2023-03-20-playwright-github-actions-and-azure-static-web-apps-staging-environments/index.md":27546};function o(e){var t=i(e);return n(t)}function i(e){if(!n.o(a,e)){var t=new Error("Cannot find module '"+e+"'");throw t.code="MODULE_NOT_FOUND",t}return a[e]}o.keys=function(){return Object.keys(a)},o.resolve=i,e.exports=o,o.id=84681},3905:(e,t,n)=>{"use strict";n.d(t,{Zo:()=>u,kt:()=>m});var a=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=a.createContext({}),p=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},u=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,i=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),c=p(n),h=o,m=c["".concat(l,".").concat(h)]||c[h]||d[h]||i;return n?a.createElement(m,r(r({ref:t},u),{},{components:n})):a.createElement(m,r({ref:t},u))}));function m(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=n.length,r=new Array(i);r[0]=h;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[c]="string"==typeof e?e:o,r[1]=s;for(var p=2;p<i;p++)r[p]=n[p];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}h.displayName="MDXCreateElement"},83741:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a={heroBanner:"heroBanner_UJJx",buttons:"buttons_pzbO",features:"features_keug",featureImage:"featureImage_yA8i",profileImage:"profileImage_oCg8"}},43400:(e,t,n)=>{"use strict";n.r(t),n.d(t,{default:()=>h});var a=n(67294),o=n(86010),i=n(19536),r=n(61596),s=n(83741);function l(){return l=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},l.apply(this,arguments)}var p;const u=(p=n(84681)).keys().reduce(((e,t,n)=>{const a=p(t),{date:o,formattedDate:i,title:r,permalink:s}=a.metadata;return[...e,{date:o,formattedDate:i,title:r,permalink:s}]}),[]).reduceRight(((e,t)=>{const n=t.date.split("-")[0],a=e.get(n)||[];return e.set(n,[t,...a])}),new Map),c=Array.from(u,(([e,t])=>({year:e,posts:t})));function d({year:e,posts:t}){return a.createElement("div",{className:(0,o.Z)("col col--4",s.Z.feature)},a.createElement("h3",null,e),a.createElement("ul",null,t.map((e=>a.createElement("li",{key:e.date},a.createElement(r.Z,{to:e.permalink},e.formattedDate," - ",e.title))))))}const h=function(){return a.createElement(i.Z,{title:"Blog Archive"},a.createElement("header",{className:(0,o.Z)("hero hero--primary",s.Z.heroBanner)},a.createElement("div",{className:"container"},a.createElement("h1",{className:"hero__title"},"Blog Archive"),a.createElement("p",{className:"hero__subtitle"},"Historic posts"))),a.createElement("main",null,c&&c.length>0&&a.createElement("section",{className:s.Z.features},a.createElement("div",{className:"container"},a.createElement("div",{className:"row"},c.map(((e,t)=>a.createElement(d,l({key:t},e)))))))))}},98624:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"standing-on-shoulders-of-giants",title:"Standing on the Shoulders of Giants...",authors:"johnnyreilly",hide_table_of_contents:!1},s=void 0,l={permalink:"/standing-on-shoulders-of-giants",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-01-07-standing-on-shoulders-of-giants/index.md",source:"@site/blog/2012-01-07-standing-on-shoulders-of-giants/index.md",title:"Standing on the Shoulders of Giants...",description:"It started with Scott Hanselman. I had no particular plans to start a blog at all. However, I was reading Scott Hanselman's turn of the year post and I was struck with an idea.",date:"2012-01-07T00:00:00.000Z",formattedDate:"January 7, 2012",tags:[],readingTime:3.23,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"standing-on-shoulders-of-giants",title:"Standing on the Shoulders of Giants...",authors:"johnnyreilly",hide_table_of_contents:!1},prevItem:{title:"jqGrid - it's just a far better grid",permalink:"/jqgrid-its-just-far-better-grid"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"It started with Scott Hanselman. I had no particular plans to start a blog at all. However, I was reading Scott Hanselman's turn of the year ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.hanselman.com/blog/YourBlogIsTheEngineOfCommunity.aspx"}),"post")," and I was struck with an idea."),(0,a.kt)("p",null,"First, let me give a little background about myself. I'm a software developer. I've been in the industry for coming up to 15 years. I started out professionally writing call centre software. I moved on to code in a variety of different industries from straight IT to marketing and, for the last 7 years, finance."),(0,a.kt)("p",null,'Though I initially started out writing in Delphi I fast found myself moving toward the Microsoft "stack of love". I should say that this move was not because I instinctively liked Microsofts stuff (in fact in the beginning I actively disliked it - moving from Delphi 3.0 to Visual Studio 5 left me finding Microsoft\'s offering very much wanting). Rather it was pragmatic. I needed a job and at the time VB was a far more transferable skill than Delphi. What with the all encompassing ',(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Dot-com_bubble"}),"dot-com bubble")," of the late 90's I soon found myself working in the webtastic world of classic ASP (weep) and VB server components (remember them?)."),(0,a.kt)("p",null,"Though things can improve - and in my opinion they really did when Microsoft coughed up the first furball of ASP.NET Beta in (I think) 2001. I grabbed on with both hands. Since that point I've been earning my bread pretty much, though not exclusively, in the ASP.NET universe."),(0,a.kt)("p",null,"The one thing that might not be clear from the above curriculum vitae is this: ",(0,a.kt)("strong",{parentName:"p"},"I AM A COMPLETE AMATEUR.")," I mean this in both senses of the word:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"I have no formal training to speak of - I didn't do a computer sciences degree. In fact my first real coding experience was writing a program in ",(0,a.kt)("a",o({parentName:"li"},{href:"http://en.wikipedia.org/wiki/Locomotive_BASIC"}),"Locomotive Basic")," for my father on our humble Amstrad CPC."),(0,a.kt)("li",{parentName:"ol"},"That said, I love it. I find writing code an intellectually, emotionally, creatively satisfying act. And whilst I undoubtedly have less of the theoretical knowledge which most professional developers seem to have, I probably counter-balance that with a hunger to keep learning and keep trying new things. And since software never sits still that's probably just as well. Keep watching the horizon - there will be something coming over it! And it's worth saying, I have an instinct for developing which serves me pretty well. I'm good at coming up with elegant and pragmatic solutions. Put simply: I'm good at making code work.")),(0,a.kt)("p",null,"So back to the point. In my daily work life, like any other developer, I am repeatedly called on to turn someones requirement into a reality. Very rarely do I achieve this on my own. Like most of us I'm a dwarf standing on the shoulders of giants. There's a lot of people out there who come up with useful tools / components / plug-ins that make it possible for me to deliver much more than I would given my own abilities."),(0,a.kt)("p",null,"So that's what I want to do: I want to talk about the tools, components and techniques that I have found useful in the everyday working life of a developer. It's likely to be quite a \"webby\" blog as I probably find that the most interesting area of development at the moment."),(0,a.kt)("p",null,"I don't know how often I will write but my plan is that when I do, each time I'll talk about something I've found useful - why I found it useful, what problems it solved, what issues it still presented me with and so on. This is probably not going to be a \"techie techie\" blog. Rather a blog that deals with the situations that can confront a developer and how I've responded to them. I hope you find it interesting. And if you don't; please keep it to yourself :-)"))}d.isMDXComponent=!0},27378:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"jqgrid-its-just-far-better-grid",title:"jqGrid - it's just a far better grid",authors:"johnnyreilly",tags:["jqgrid","ajax","jquery"],hide_table_of_contents:!1},s=void 0,l={permalink:"/jqgrid-its-just-far-better-grid",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-01-14-jqgrid-its-just-far-better-grid/index.md",source:"@site/blog/2012-01-14-jqgrid-its-just-far-better-grid/index.md",title:"jqGrid - it's just a far better grid",description:'The year was 2010 (not really that long ago I know) and the project that I was working on was sorely in need of a new grid component. It was an ASP.NET WebForms project and for some time we\'d been using what was essentially a glorified datagrid which had a few extra features implemented to allow us to change column order / columns displayed / copy contents to clipboard etc. Our grid worked perfectly fine - it gave us the functionality we needed. However, it looked pretty terrible, and had some "quirky" approaches in place for supporting IE and Firefox side by side. Also, at the time we were attempting to make our app seem new and exciting again for the users. The surprising truth is that users seem to be more impressed with a visual revamp than with new or amended functionality. So I was looking for something which would make them sit up and say "oooh - isn\'t it pretty!". Unfortunately the nature of the organisation I was working for was not one that lended itself to paying for components. They were occasionally willing to do that but the hoops that would have to be jumped through first, the forms that would need to be signed in triplicate by people that had nearly nothing to do with the project made that an unattractive prospect. So I began my search initially looking at the various open source offerings that were around. As a minimum I was looking for something that would do what our home-grown component did already (change column order / columns displayed / copy contents to clipboard etc) but hopefully in a "nicer" way. Also, I had long been unhappy with the fact that to get our current grid to render results we did a \\*full postback\\* to the server and re-rendered the whole page. Pointless! Why should you need to do all this each time when you only wanted to refresh the data? Instead I was thinking about using an Ajax approach; a grid that could just get the data that it needed and render it to the client. This seemed to me a vastly "cleaner" solution - why update a whole screen when you only want to update a small part of it? Why not save yourself the trouble of having to ensure that all other screen controls are persisted just as you\'d like them after the postback? I also thought it was probably something that would scale better as it would massively reduce the amount of data moving backwards and forwards between client and server. No need for a full page life cycle on the server each time the grid refreshes. Just simple data travelling down the pipes of web. With the above criteria in mind I set out on my Google quest for a grid. Quite soon I found that there was a component out there which seemed to do all that I wanted and far more besides. It was called jqGrid:',date:"2012-01-14T00:00:00.000Z",formattedDate:"January 14, 2012",tags:[{label:"jqgrid",permalink:"/tags/jqgrid"},{label:"ajax",permalink:"/tags/ajax"},{label:"jquery",permalink:"/tags/jquery"}],readingTime:5.41,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"jqgrid-its-just-far-better-grid",title:"jqGrid - it's just a far better grid",authors:"johnnyreilly",tags:["jqgrid","ajax","jquery"],hide_table_of_contents:!1},prevItem:{title:"What on earth is jQuery?  And why should I care?",permalink:"/what-on-earth-is-jquery-and-why-should"},nextItem:{title:"Standing on the Shoulders of Giants...",permalink:"/standing-on-shoulders-of-giants"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The year was 2010 (not really that long ago I know) and the project that I was working on was sorely in need of a new grid component. It was an ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.asp.net/web-forms"}),"ASP.NET WebForms")," project and for some time we'd been using what was essentially a glorified ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/system.web.ui.webcontrols.datagrid.aspx"}),"datagrid"),' which had a few extra features implemented to allow us to change column order / columns displayed / copy contents to clipboard etc. Our grid worked perfectly fine - it gave us the functionality we needed. However, it looked pretty terrible, and had some "quirky" approaches in place for supporting IE and Firefox side by side. Also, at the time we were attempting to make our app seem new and exciting again for the users. The surprising truth is that users seem to be more impressed with a visual revamp than with new or amended functionality. So I was looking for something which would make them sit up and say "oooh - isn\'t it pretty!". Unfortunately the nature of the organisation I was working for was not one that lended itself to paying for components. They were occasionally willing to do that but the hoops that would have to be jumped through first, the forms that would need to be signed in triplicate by people that had nearly nothing to do with the project made that an unattractive prospect. So I began my search initially looking at the various open source offerings that were around. As a minimum I was looking for something that would do what our home-grown component did already (change column order / columns displayed / copy contents to clipboard etc) but hopefully in a "nicer" way. Also, I had long been unhappy with the fact that to get our current grid to render results we did a ',"*",(0,a.kt)("strong",{parentName:"p"},"full postback"),"*"," to the server and re-rendered the whole page. Pointless! Why should you need to do all this each time when you only wanted to refresh the data? Instead I was thinking about using an ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Ajax_%28programming%29"}),"Ajax"),' approach; a grid that could just get the data that it needed and render it to the client. This seemed to me a vastly "cleaner" solution - why update a whole screen when you only want to update a small part of it? Why not save yourself the trouble of having to ensure that all other screen controls are persisted just as you\'d like them after the postback? I also thought it was probably something that would scale better as it would massively reduce the amount of data moving backwards and forwards between client and server. No need for a full page life cycle on the server each time the grid refreshes. Just simple data travelling down the pipes of web. With the above criteria in mind I set out on my Google quest for a grid. Quite soon I found that there was a component out there which seemed to do all that I wanted and far more besides. It was called ',(0,a.kt)("a",o({parentName:"p"},{href:"http://www.trirand.com/blog/"}),"jqGrid"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(20164).Z,width:"320",height:"224"})),(0,a.kt)("p",null,"Oooh look at the goodness! It had both column re-ordering and column choosing built in!: This was a ","*",(0,a.kt)("strong",{parentName:"p"},"very promising sign"),"*","! Now it's time for me to demonstrate my ignorance. According to the website this grid component was a \"jQuery plugin\". At the time I read this I had no idea what jQuery was at all - let alone what a plugin for it was. Anyway, I don't want to get diverted so let's just say that reading this lead to me getting an urgent education about some of the client side aspects of the modern web that I had been previously unaware of. I digress. This component did exactly what I wanted in terms of just sending data down the pipe. jqGrid worked with a whole number of possible data sources; XML, Array but the most exciting for me was obviously ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.json.org/"}),"JSON"),". Take a look a the grid rendered below and the JSON that powered it (all from a simple ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.trirand.com/blog/jqgrid/server.php?q=2&_search=false&nd=1326531357333&rows=10&page=1&sidx=id&sord=desc"}),"GET")," request):"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(58824).Z,width:"320",height:"264"})),(0,a.kt)("p",null,"As you can see from the above screenshot, the grid has populated itself using the results of a web request. The only information that has gone to the server are the relevant criteria to drive the search results. The only information that has come back from the server is the data needed to drive the grid. Simple. Beautiful. I loved it and I wanted to use it. So I did! I had to take a few steps that most people thinking about using a grid component probably wont need to. First of all I had to write an ASP.Net WebForms wrapper for jqGrid which could be implemented in a similar way to our current custom datagrid. This was because, until the users were convinced that the new grid was better than the old both had to co-exist in the project and the user would have the option to switch between the two. This WebForms wrapper plugged into our old school XML column definition files and translated them into JSON for the grid. It also took ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/system.data.dataset.aspx"}),"datasets")," (which drove our old grid) and translated them into jqGrid-friendly JSON. I wanted to power the jqGrid using WebMethods on ASPX's. After a little digging I found ",(0,a.kt)("a",o({parentName:"p"},{href:"http://encosia.com/using-jquery-to-directly-call-aspnet-ajax-page-methods/"}),"Dave Ward of Encosia's post")," which made it very simple (and in line with this I switched over from ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/GET_%28HTTP%29#Request_methods"}),"GET")," requests to ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/POST_%28HTTP%29"}),"POSTs"),"). Finally I wrote some custom javascript which added a button to jqGrid which, if clicked, would copy the contents of the jqGrid to the clipboard (this was the only bit of functionality that didn't appear to be implemented out of the box with jqGrid). I think I'm going to leave it there for now but I just wanted to say that I think jqGrid is a fantastic component and it's certainly made my life better! It's: - well supported, there is lots on ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/questions/tagged/jqgrid"}),"StackOverflow")," and the like about it"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"there are regular ",(0,a.kt)("a",o({parentName:"li"},{href:"http://www.trirand.com/blog/"}),"releases / upgrades")),(0,a.kt)("li",{parentName:"ul"},"there are good online ",(0,a.kt)("a",o({parentName:"li"},{href:"http://trirand.com/blog/jqgrid/jqgrid.html"}),"demonstrations")," and ",(0,a.kt)("a",o({parentName:"li"},{href:"http://www.trirand.com/jqgridwiki/doku.php"}),"documentation"))),(0,a.kt)("p",null,"I think Tony Tomov (the man behind jqGrid) has come up with something truly brilliant. It's worth saying that the equally brilliant jQueryUI team are in the process of writing an official ",(0,a.kt)("a",o({parentName:"p"},{href:"http://wiki.jqueryui.com/w/page/34246941/Grid"}),"jQuery UI grid component"),' which uses jqGrid as one of its inspirations. However, this is still a long way from even a "zero feature" release. In the meantime jqGrid is continuing to go from strength to strength and as such I heartily recommend it. Finally, you can take a look at jqGrid\'s source on ',(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/tonytomov/jqGrid"}),"GitHub"),"."))}d.isMDXComponent=!0},19785:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"what-on-earth-is-jquery-and-why-should",title:"What on earth is jQuery?  And why should I care?",authors:"johnnyreilly",tags:["jqgrid","ajax","jquery"],hide_table_of_contents:!1},s=void 0,l={permalink:"/what-on-earth-is-jquery-and-why-should",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-01-24-what-on-earth-is-jquery-and-why-should/index.md",source:"@site/blog/2012-01-24-what-on-earth-is-jquery-and-why-should/index.md",title:"What on earth is jQuery?  And why should I care?",description:"What on earth is jQuery? What's a jQuery plugin?",date:"2012-01-24T00:00:00.000Z",formattedDate:"January 24, 2012",tags:[{label:"jqgrid",permalink:"/tags/jqgrid"},{label:"ajax",permalink:"/tags/ajax"},{label:"jquery",permalink:"/tags/jquery"}],readingTime:4.53,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"what-on-earth-is-jquery-and-why-should",title:"What on earth is jQuery?  And why should I care?",authors:"johnnyreilly",tags:["jqgrid","ajax","jquery"],hide_table_of_contents:!1},prevItem:{title:"JavaScript - getting to know the beast...",permalink:"/javascript-getting-to-know-beast"},nextItem:{title:"jqGrid - it's just a far better grid",permalink:"/jqgrid-its-just-far-better-grid"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"What on earth is jQuery? What's a jQuery plugin?"),(0,a.kt)("p",null,'These were the questions I was asking myself shortly after discovering that jqGrid was a "jQuery plugin". I\'d been vaguely aware of the phrase "jQuery" being increasingly mentioned on various techical websites since about 2009. But for some reason I\'d felt no urge to find out what it was. I seem to remember that I read the name "jQuery" and jumped to the perfectly logical (in my head) conclusion that this must be a Java SQL engine of some sort. (After all "j" as a prefix to anything so far had generally been Java and "Query" just rang of databases to me.) Clearly I was wrong - life\'s full of surprises.'),(0,a.kt)("p",null,"I soon discovered that, contrary to expectations, jQuery had nothing to do with Java ","*",(0,a.kt)("strong",{parentName:"p"},"and"),"*"," nothing to do with databases either. It was in fact a JavaScript library written by the amazing ",(0,a.kt)("a",o({parentName:"p"},{href:"http://ejohn.org/about/"}),"John Resig"),". At the time I had no love for JavaScript. I now realise I knew nearly nothing about it but my feeling was that JavaScript was awful - evil even. However, given JavaScripts ubiquity in the world of web it seemed to be a necessary evil."),(0,a.kt)("p",null,"I took a look at the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://jquery.com/"}),"jQuery website")," and after reading round a bit I noticed that it could be used for ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Ajax_%28programming%29"}),"Ajax")," operations. This lead to me reaching the (incorrect) conclusion that jQuery was basically an alternative to the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/ASP.NET_AJAX#Microsoft_Ajax_Library"}),"Microsoft Ajax library")," which we were already using to call various Web Services. But I remained frankly suspicious of jQuery. What was the point of this library? Why did it exist?"),(0,a.kt)("p",null,"I read the the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://weblogs.asp.net/scottgu/archive/2008/09/28/jquery-and-microsoft.aspx"}),"blog")," by Scott Gu announcing Microsoft was going to start shipping jQuery with Visual Studio. The Great Gu trusted it. Therefore, I figured, it must be okay... Right?"),(0,a.kt)("p",null,"The thing was, I was quite happy with the Microsoft Ajax library. I was familiar with it. It worked. Why switch? I saw the various operations Scott Gu was doing to divs on the screen using jQuery. I didn't want to do anything like that at all. As I said; I had no love for JavaScript - I viewed it as C#'s simple-minded idiot cousin. My unofficial motto when doing web stuff was \"wherever possible, do it on the server\"."),(0,a.kt)("p",null,"I think I would have ignored jQuery entirely but for the fact of jqGrid. If I wanted to use jqGrid I had to use jQuery as well. In the end I decided I'd allow it house room just for the sake of jqGrid and I'd just ignore it apart from that. And that's how it was for a while."),(0,a.kt)("p",null,"Then I had an epiphany. Okay - that's overplaying it. What actually happened was I realised that something we were doing elsewhere could be done faster and easier with jQuery. It's something so ridiculously feeble that I feel vaguely embarrassed sharing it. Anyway."),(0,a.kt)("p",null,"So, you know the css hover behaviour is only implemented for anchor tags in IE6? No? Well read this ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/questions/36605/ie-6-css-hover-non-anchor-tag"}),"Stack Overflow"),' entry - it\'ll clarify. Well, the app that I was working on was an internal web application only used by people with the corporate installation of IE 6 on their desktops. And it was "terribly important" that buttons had hover behaviour. For reasons that now escape me we were doing this by manually adding inline onmouseover / onmouseout event handlers to each input button on the screen in turn in every page in the ',(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/ms178472.aspx"}),"Page_Load")," event server side. I think we were aware it wasn't fantastic to have to wire up each button in turn. But it worked and as with so many development situations we had other pressures, other requirements to fulfil and other fish to fry - so we left it at that."),(0,a.kt)("p",null,"And then it occurred to me... What about using the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://api.jquery.com/class-selector/"}),"jQuery class selector")," in conjunction with the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://api.jquery.com/hover/"}),"jQuery hover event"),"? I could have one method that I called on a page which would wire up all of my hover behaviours in one fell swoop. I wouldn't need to do input-by-input wireups anymore! Hallelujah! This is what I did:"),(0,a.kt)("p",null,"The buttons I would like to style:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<input type="button" value="I am a button" class="itIsAButton" />\n<input type="button" value="So am I" class="itIsAButton" />\n<input type="button" value="Me too" class="itIsAButton" />\n')),(0,a.kt)("p",null,"My CSS (filter, by the way, is just linear gradients in IE 6-9):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-css"}),".itIsAButton {\n  filter: progid:DXImageTransform.Microsoft.Gradient (GradientType=0,StartColorStr='#ededed',EndColorStr='#cdcdcd');\n}\n\n.itIsAButton:hover, .itIsAButton_hover /* \"_hover\" is for IE6 */ {\n  filter: progid:DXImageTransform.Microsoft.Gradient (GradientType=0,StartColorStr='#f6f6f6',EndColorStr='#efefef');\n}\n")),(0,a.kt)("p",null,"My jQuery:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"$(document).ready(function () {\n  //Add hover behaviour on picker buttons for IE6\n  if ($.browser.msie && parseInt($.browser.version, 10) < 7) {\n    var fnButtonHover = function (handlerInOut) {\n      var $btn = $(this);\n      var sOriginalClass = $btn.prop('class');\n\n      if (handlerInOut.type === 'mouseenter') {\n        //If not already hovering class then apply it\n        if (sOriginalClass.indexOf('_hover') === -1) {\n          $btn.prop('class', sOriginalClass + '_hover');\n        }\n      } else if (handlerInOut.type === 'mouseleave') {\n        //If not already non-hovering class then apply it\n        if (sOriginalClass.indexOf('_hover') !== -1) {\n          $btn.prop('class', sOriginalClass.split('_')[0]);\n        }\n      }\n    };\n\n    $('.itIsAButton').hover(fnButtonHover);\n  }\n});\n")),(0,a.kt)("p",null,"And it worked. I didn't really understand this much about this jQuery \"thing\" at that point but I could now see that it clearly had at least one use. I've come to appreciate that jQuery is one of the best pieces of software I've ever encountered. Over time I may go further into some of the good stuff of jQuery. It is, quite simply, brilliant."))}d.isMDXComponent=!0},34607:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"javascript-getting-to-know-beast",title:"JavaScript - getting to know the beast...",authors:"johnnyreilly",tags:["javascript","c#"],hide_table_of_contents:!1},s=void 0,l={permalink:"/javascript-getting-to-know-beast",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-01-30-javascript-getting-to-know-beast/index.md",source:"@site/blog/2012-01-30-javascript-getting-to-know-beast/index.md",title:"JavaScript - getting to know the beast...",description:"So it's 2010 and I've started using jQuery. jQuery is a JavaScript library. This means that I'm writing JavaScript... Gulp! I should say that at this point in time I \\*hated\\* JavaScript (I have mentioned this previously). But what I know now is that I barely understood the language at all. All the JavaScript I knew was the result of copying and pasting after I'd hit \"view source\". I don't feel too bad about this - not because my ignorance was laudable but because I certainly wasn't alone in this. It seems that up until recently hardly anyone knew anything about JavaScript. It puzzles me now that I thought this was okay. I suppose like many people I didn't think JavaScript was capable of much and hence felt time spent researching it would be wasted. Just to illustrate where I was then, here is 2009 John's idea of some pretty \"advanced\" JavaScript:",date:"2012-01-30T00:00:00.000Z",formattedDate:"January 30, 2012",tags:[{label:"javascript",permalink:"/tags/javascript"},{label:"c#",permalink:"/tags/c"}],readingTime:5.81,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"javascript-getting-to-know-beast",title:"JavaScript - getting to know the beast...",authors:"johnnyreilly",tags:["javascript","c#"],hide_table_of_contents:!1},prevItem:{title:"A Potted History of using Ajax (on the Microsoft Stack of Love)",permalink:"/potted-history-of-using-ajax-on"},nextItem:{title:"What on earth is jQuery?  And why should I care?",permalink:"/what-on-earth-is-jquery-and-why-should"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"So it's 2010 and I've started using jQuery. jQuery is a JavaScript library. This means that I'm writing JavaScript... Gulp! I should say that at this point in time I ","*",(0,a.kt)("strong",{parentName:"p"},"hated"),"*"," JavaScript (I have mentioned this previously). But what I know now is that I barely understood the language at all. All the JavaScript I knew was the result of copying and pasting after I'd hit \"view source\". I don't feel too bad about this - not because my ignorance was laudable but because I certainly wasn't alone in this. It seems that up until recently hardly anyone knew anything about JavaScript. It puzzles me now that I thought this was okay. I suppose like many people I didn't think JavaScript was capable of much and hence felt time spent researching it would be wasted. Just to illustrate where I was then, here is 2009 John's idea of some pretty \"advanced\" JavaScript:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'function GiveMeASum(iNum1, iNum2) { var dteDate = new Date(); var iTotal = iNum1\n+ iNum2; return "This is your total: " + iTotal + ", at this time: " +\ndteDate.toString(); }\n\n<input type="text" id="Number1" value="4" />\n<input type="text" id="Number2" value="6" />\n<input\n  type="button"\n  value="Click Me To Add"\n  onclick="alert(GiveMeASum(parseInt(document.getElementById(Number1).value, 10), parseInt(document.getElementById(Number2).value, 10)))"\n/>\n')),(0,a.kt)("p",null,"I know - I'm not to proud of it... Certainly if it was a horse you'd shoot it. Basically, at that point I knew the following: - JavaScript had functions (but I knew only one way to use them - see above)"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"It had some concept of numbers (but I had no idea of the type of numbers I was dealing with; integer / float / decimal / who knows?)"),(0,a.kt)("li",{parentName:"ul"},"It had some concept of strings"),(0,a.kt)("li",{parentName:"ul"},"It had a date object")),(0,a.kt)("p",null,"This was about the limit of my knowledge. If I was right, and that's all there was to JavaScript then my evaluation of it as utter rubbish would have been accurate. I was wrong. SOOOOOOOOOOOO WRONG! I first realised how wrong I was when I opened up the jQuery source to have a read. Put simply I had ","*",(0,a.kt)("strong",{parentName:"p"},"no"),"*"," idea what I was looking at. For a while I wondered if I was actually looking at JavaScript; the code was so different to what I was expecting that for a goodly period I considered jQuery to be some kind of strange black magic; written in a language I did not understand. I was half right. jQuery wasn't black magic. But it was written in a language I didn't understand; namely JavaScript. :-( Here beginneth the lessons... I started casting around looking for information about JavaScript. Before very long I discovered one ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.elijahmanor.com/"}),"Elijah Manor")," who had helpfully done a number of talks and blog posts directed at C# developers (which I was) about JavaScript. My man! - ",(0,a.kt)("a",o({parentName:"p"},{href:"http://enterprisejquery.com/2010/10/how-good-c-habits-can-encourage-bad-javascript-habits-part-1/"}),"How good C# habits can encourage bad JavaScript habits part 1")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://enterprisejquery.com/2010/10/how-good-c-habits-can-encourage-bad-javascript-habits-part-2/"}),"How good C# habits can encourage bad JavaScript habits part 2")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://enterprisejquery.com/2010/10/how-good-c-habits-can-encourage-bad-javascript-habits-part-3/"}),"How good C# habits can encourage bad JavaScript habits part 3")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://blogs.msdn.com/b/ukmsdn/archive/2011/06/10/javascript-for-the-c-developer.aspx"}),"Video of Elijah Manor talking through the above material"))),(0,a.kt)("p",null,'For me this was all massively helpful. In my development life so far I had only ever dealt with strongly typed, compiled "classical" languages. I had little to no experience of functional, dynamic and loosely typed languages (essentially what JavaScript is). Elijahs work opened up my eyes to some of the massive differences that exist. He also pointed me in the direction of the (never boring) Doug Crockford, author of the best programming book I have ever purchased: ',(0,a.kt)("a",o({parentName:"p"},{href:"http://www.amazon.co.uk/JavaScript-Good-Parts-Douglas-Crockford/dp/0596517742"}),"JavaScript: The Good Parts"),". Who could not like a book about JavaScript which starts each chapter with a quote from Shakespeare and still comes in at only a 100 pages? It's also worth watching the man in person as he's a thoroughly engaging presence. There's loads of videos of him out there but this one is pretty good: ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.youtube.com/watch?v=v2ifWcnQs6M"}),"Douglas Crockford: The JavaScript Programming Language"),". I don't want to waste your time by attempting to rehash what these guys have done already. I think it's always best to go to the source so I'd advise you to check them out for yourselves. That said it's probably worth summarising some of the main points I took away from them (you can find better explanations of all of these through looking at their posts): 1. JavaScript has objects but has no classes. Instead it has (what I still consider to be) the weirdest type of inheritance going: prototypical inheritance. 2. JavaScript has the simplest and loveliest way of creating a new object out there; the \"JavaScript Object Literal\". Using this we can simply ",(0,a.kt)("inlineCode",{parentName:"p"},'var myCar = { wheels: 4, colour: "blue" }')," and ladies and gents we have ourselves a car! (object) 3. In JavaScript functions are ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/First-class_function"}),"first class objects"),". This means functions can be assigned to variables (as easily as you'd assign a string to a variable) and crucially you can pass them as parameters to a function and pass them back as a return type. Herein lies power! 4. JavaScript has 6 possible values (false, null, undefined, empty strings, 0 and NaN) which it evaluates as false. These are known as the \"false-y\" values. It's a bit weird but on the plus side this can lead to some nicely terse code. 5. To perform comparisons in JavaScript you should avoid == and != and instead use === and !==. Before I discovered this I had been using == and != and then regularly puzzling over some truly odd behaviour. Small though it may sound, this may be the most important discovery of the lot as it was this that lead to me actually ","*",(0,a.kt)("strong",{parentName:"p"},"trusting"),"*"," the language. Prior to this I vaguely thought I was picking up on some kind of bug in the JavaScript language which I plain didn't understand. (After all, in any sane universe should this really evaluate to true?: ",(0,a.kt)("inlineCode",{parentName:"p"},'0 == ""'),') 6. Finally JavaScript has function scope rather than block scope. Interestingly it "hoists" variable declaration to the top of each function which can lead to some very surprising behaviour if you don\'t realise what is happening.'),(0,a.kt)("p",null,"I now realise that JavaScript is a fantastic language because of it's flexibility. It is also a deeply flawed language; in part due to it's unreasonably forgiving nature (you haven't finished your line with a semi-colon; that's okay - I can see you meant to so I'll stick one in / you haven't declared your variable; not a problem I won't tell you but I'll create a new variable stick it in global scope and off we go etc). It is without question the easiest language with which to create a proper dogs breakfast. To get the best out of JavaScript we need to understand the quirks of the language and we need good patterns. If you're interested in getting to grips with it I really advise you to check out the Elijah and Dougs work - it really helped me."))}d.isMDXComponent=!0},32630:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"potted-history-of-using-ajax-on",title:"A Potted History of using Ajax (on the Microsoft Stack of Love)",authors:"johnnyreilly",tags:["ajax","jquery","json","microsoft"],hide_table_of_contents:!1},s=void 0,l={permalink:"/potted-history-of-using-ajax-on",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-02-05-potted-history-of-using-ajax-on/index.md",source:"@site/blog/2012-02-05-potted-history-of-using-ajax-on/index.md",title:"A Potted History of using Ajax (on the Microsoft Stack of Love)",description:"This post originally started out as an explanation of JSON. However as I wrote this quickly got abandoned in favour of writing about how I came to use JSON in the first place - which was through the use of Ajax. Having written a goodly amount I've now decided to move the actual JSON stuff into another post since I think Ajax is probably worth thinking about by itself rather than as an aside. So let me start at the beginning and explain how I came to use Ajax in the first place (this may take some time so please bear with me). In late 2004 I first started working on a project which I was to remain involved with (on and off) for a very long time indeed. The project was part financial reporting system and part sales incentivisation tool; it was used internally in the investment bank in which I was working. The project had been in existence for a number of years and had a web front end which at that point would been built in a combination of HTML, JavaScript, classic ASP and with a Visual Basic 6.0 back end. One of the reasons I had been brought on to the project was to help \".Net-ify\" the thing and migrate it to ASP.NET and C#. I digress. The interesting thing about this app was that there were actually some quite advanced things being done with it (despite the classic ASP / VB). The users could enter trades into the system which represented actual trades that had been entered into a trading system elsewhere in the organisation. These trades would be assigned a reporting value which would be based on their various attributes. (Stay with me people this will get more interesting I \\*promise\\*.) The calculation of the reporting value was quite an in depth process and needed to be performed server-side. However, the users had decreed that it wasn't acceptable to do a full postback to the server to perform this calculation; they wanted it done \"on-the-fly\". Now if you asked me at the time I'd have said \"can't be done\". Fortunately the other people working on the project then weren't nearly so defeatist. Instead they went away and found Microsoft's webservice.htc library. For those of you that don't know this was a JavaScript library that Microsoft came up with to enable the access of Web Services on the client. Given that it was designed to work with IE 5 I suspect it was created between 1999-2001 (but I'm not certain about that). Now it came as a revelation to me but this was a JavaScript library that talked to our web services through the medium of XML. In short it was my first encounter with anything remotely Ajax\\-y. It was exciting! However, the possibilities of what we could do didn't actually become apparent to me for some years. It's worth saying that the way we were using webservice.htc was exceedingly simplistic and rather than investigating further I took the limited ways we were using it as indications of the limitations of Ajax and / or webservice.htc. So for a long time I thought the following: - The only way to pass multiple arguments to a web service was to package up arguments into a single string with delimiters which you could split and unpackage as your first step on the server.",date:"2012-02-05T00:00:00.000Z",formattedDate:"February 5, 2012",tags:[{label:"ajax",permalink:"/tags/ajax"},{label:"jquery",permalink:"/tags/jquery"},{label:"json",permalink:"/tags/json"},{label:"microsoft",permalink:"/tags/microsoft"}],readingTime:7.24,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"potted-history-of-using-ajax-on",title:"A Potted History of using Ajax (on the Microsoft Stack of Love)",authors:"johnnyreilly",tags:["ajax","jquery","json","microsoft"],hide_table_of_contents:!1},prevItem:{title:"WCF Transport Windows authentication using NetTcpBinding in an Intranet environment",permalink:"/wcf-transport-windows-authentication"},nextItem:{title:"JavaScript - getting to know the beast...",permalink:"/javascript-getting-to-know-beast"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'This post originally started out as an explanation of JSON. However as I wrote this quickly got abandoned in favour of writing about how I came to use JSON in the first place - which was through the use of Ajax. Having written a goodly amount I\'ve now decided to move the actual JSON stuff into another post since I think Ajax is probably worth thinking about by itself rather than as an aside. So let me start at the beginning and explain how I came to use Ajax in the first place (this may take some time so please bear with me). In late 2004 I first started working on a project which I was to remain involved with (on and off) for a very long time indeed. The project was part financial reporting system and part sales incentivisation tool; it was used internally in the investment bank in which I was working. The project had been in existence for a number of years and had a web front end which at that point would been built in a combination of HTML, JavaScript, classic ASP and with a Visual Basic 6.0 back end. One of the reasons I had been brought on to the project was to help ".Net-ify" the thing and migrate it to ASP.NET and C#. I digress. The interesting thing about this app was that there were actually some quite advanced things being done with it (despite the classic ASP / VB). The users could enter trades into the system which represented actual trades that had been entered into a trading system elsewhere in the organisation. These trades would be assigned a reporting value which would be based on their various attributes. (Stay with me people this will get more interesting I ',"*",(0,a.kt)("strong",{parentName:"p"},"promise"),"*",".) The calculation of the reporting value was quite an in depth process and needed to be performed server-side. However, the users had decreed that it wasn't acceptable to do a full postback to the server to perform this calculation; they wanted it done \"on-the-fly\". Now if you asked me at the time I'd have said \"can't be done\". Fortunately the other people working on the project then weren't nearly so defeatist. Instead they went away and found Microsoft's ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/ie/ms531033%28v=vs.85%29.aspx"}),"webservice.htc")," library. For those of you that don't know this was a JavaScript library that Microsoft came up with to enable the access of Web Services on the client. Given that it was designed to work with IE 5 I suspect it was created between 1999-2001 (but I'm not certain about that). Now it came as a revelation to me but this was a JavaScript library that talked to our web services through the medium of XML. In short it was my first encounter with anything remotely ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Ajax_(programming)"}),"Ajax"),"-","y. It was exciting! However, the possibilities of what we could do didn't actually become apparent to me for some years. It's worth saying that the way we were using webservice.htc was exceedingly simplistic and rather than investigating further I took the limited ways we were using it as indications of the limitations of Ajax and / or webservice.htc. So for a long time I thought the following: - The only way to pass multiple arguments to a web service was to package up arguments into a single string with delimiters which you could ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Comparison_of_programming_languages_(string_functions)#split"}),"split")," and unpackage as your first step on the server."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"The only valid return type was a single string. And so if you wanted to return a number of numeric values (as we did) the only way to do this was to package up return values into a very long string with delimiters in and (you guessed it!) ",(0,a.kt)("a",o({parentName:"li"},{href:"http://en.wikipedia.org/wiki/Comparison_of_programming_languages_(string_functions)#split"}),"split")," and unpackage as your first step on the client."),(0,a.kt)("li",{parentName:"ul"},"The only thing that you could (or would want to) send back and forth between client and server was XML")),(0,a.kt)("p",null,"So to recap, I'm now aware that it's possible for JavaScript to interact with the server through the use of web services. It's possible, but ugly, not that quick and requires an awful lot of manual serialization / deserialization operations. It's clearly powerful but not much fun at all. And that's where I left it for a number of years. Let's fade to black... It's now 2007 and Microsoft have released ASP.NET Ajax, the details of which are well explained in this ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/magazine/cc163499.aspx"}),"article")," (which I have only recently discovered). Now I'm always interested in \"the new\" and so I was naturally interested in this. Just to be completely upfront about this I should confess that when I first discovered ASP.NET Ajax I didn't clock the power of it at all. Initially I just switched over from using webservice.htc to ASP.NET Ajax. This alone gave us a ","*",(0,a.kt)("strong",{parentName:"p"},"massive"),"*",' performance improvement (I know it was massive since we actually received a "well done" email from our users which is testament to the difference it was making to their experience of the system). But we were still performing our manual serialisation / deserialisation of values on the client and the server. ie. Using Ajax was now much faster but still not too much fun. Let\'s jump forward in time again to around 2010 to the point in time when I was discovering jQuery and that JavaScript wasn\'t actually evil. It\'s not unusual for me to play around with "what if" scenarios in my code, just to see what might might be possible. Sometimes I discover things. So it was with JSON. We had a web service in the system that allowed us to look up a counterparty (ie a bank account) with an identifier. Once we looked it up we packaged up the counterparty details (eg name, location etc) into a big long string with delimiters and sent it back to client. One day I decided to change the return type on the web service from a string to the actual counterparty class. So we went from something like this:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[WebService(Namespace = "http://tempuri.org/")]\n[WebServiceBinding(ConformsTo = WsiProfiles.BasicProfile1_1)]\n[ScriptService]\npublic class CounterpartyWebService : System.Web.Services.WebService\n{\n  [WebMethod]\n  public string GetCounterparty(string parameters)\n  {\n    string[] aParameters = parameters.Split("|");\n    int counterpartyId = int.Parse(aParameters[0]);\n    bool includeLocation = (aParameters[1] == "1");\n    Counterparty counterparty = \\_counterpartyDb\n    .GetCounterparty(counterpartyId);\n\n        string returnValue = counterparty.Id +\n                          "|" + counterparty.Name +\n                          (includeLocation\n                            ? "|" + counterparty.Location\n                            : "");\n\n        return returnValue;\n  }\n}\n')),(0,a.kt)("p",null,"To something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[WebMethod]\npublic Counterparty GetCounterparty(string parameters)\n{\n  string[] aParameters = parameters.Split("|");\n  int counterpartyId = int.Parse(aParameters[0]);\n  bool includeLocation = (aParameters[1] == "1");\n  Counterparty counterparty = _counterpartyDb\n    .GetCounterparty(counterpartyId);\n\n  return counterparty;\n}\n')),(0,a.kt)("p",null,"I genuinely expected that this was just going to break. It didn't. Suddenly on the client I'm sat there with a full blown object that looks just like the object I had on the server."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"WHAT STRANGE MAGIC COULD THIS BE??????????")," Certain that I'd discovered witchcraft I decided to try something else. What would happen if I changed the signature on the method so it received individual parameters and passed my individual parameters to the web service instead of packaging them up into a string? I tried this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"[WebMethod]\npublic Counterparty GetCounterparty(int counterpartyId, bool includeLocation)\n{\n  Counterparty counterparty = \\_counterpartyDb\n  .GetCounterparty(counterpartyId);\n\n  return counterparty;\n}\n")),(0,a.kt)("p",null,"And it worked! ",(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("a",o({parentName:"strong"},{href:"http://www.youtube.com/watch?v=N_dWpCy8rdc&feature=related"}),"IT WORKED!!!!!!!!!!!!!!!!!!!!!"))," (And yes I know I wasn't actually using the includeLocation parameter - but the point was it was being passed to the server and I could have used it if I'd wanted to.) I couldn't believe it. For ",(0,a.kt)("strong",{parentName:"p"},"years")," I'd been using Ajax and without ",(0,a.kt)("strong",{parentName:"p"},"any")," idea of the power available to me. The ignorance! The stupidity of the man! To my complete surprise it turned out that: - Ajax could be quick! ASP.NET Ajax was lightening fast when compared to webservice.htc"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"You could send multiple arguments to a web service without all that packaging nonsense"),(0,a.kt)("li",{parentName:"ul"},"You could return complex objects without the need for packaging it all up yourself.")),(0,a.kt)("p",null,"Essentially the source of all this goodness was the magic of JSON. I wouldn't really come to comprehend this until I moved away from using the ASP.NET Ajax client libraries in favour of using the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://api.jquery.com/jQuery.ajax/"}),"jQuery.ajax")," functionality. (Yes, having mostly rattled on about using webservice.htc and ASP.NET Ajax I should clarify that I have now forsaken both for jQuery as I find it more powerful and more configurable - but it's the journey that counts I guess!) It's abysmal that I didn't discover the power of Ajax sooner but the difference this discovery made to me was immense. Approaches that I would have dismissed or shied away from previously because of the amount of \"plumbing\" involved now became easy. This massively contributed to my ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.hanselman.com/blog/HanselminutesPodcast260NETAPIDesignThatOptimizesForProgrammerJoyWithJonathanCarter.aspx"}),"programmer joy"),"! Next time I promise I'll aim to actually get onto JSON."))}d.isMDXComponent=!0},86702:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"wcf-transport-windows-authentication",title:"WCF Transport Windows authentication using NetTcpBinding in an Intranet environment",authors:"johnnyreilly",tags:["WCF","Authentication"],hide_table_of_contents:!1},s=void 0,l={permalink:"/wcf-transport-windows-authentication",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-02-15-wcf-transport-windows-authentication/index.md",source:"@site/blog/2012-02-15-wcf-transport-windows-authentication/index.md",title:"WCF Transport Windows authentication using NetTcpBinding in an Intranet environment",description:"Update",date:"2012-02-15T00:00:00.000Z",formattedDate:"February 15, 2012",tags:[{label:"WCF",permalink:"/tags/wcf"},{label:"Authentication",permalink:"/tags/authentication"}],readingTime:4.545,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"wcf-transport-windows-authentication",title:"WCF Transport Windows authentication using NetTcpBinding in an Intranet environment",authors:"johnnyreilly",tags:["WCF","Authentication"],hide_table_of_contents:!1},prevItem:{title:"The Joy of JSON",permalink:"/joy-of-json"},nextItem:{title:"A Potted History of using Ajax (on the Microsoft Stack of Love)",permalink:"/potted-history-of-using-ajax-on"}},p={authorsImageUrls:[void 0]},u=[{value:"Update",id:"update",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"update"}),"Update"),(0,a.kt)("p",null,"Since I wrote this initial post I've taken thinks on a bit further. ",(0,a.kt)("a",o({parentName:"p"},{href:"/wcf-moving-from-config-to-code-simple"}),"Take a look at this post to see what I mean.")," I know I said I'd write about JSON this time. I will get to that but not this time. This time WCF authentication quirks. I've been working on a project that uses .NET Remoting to have a single central point to which web applications and Windows services can call into. This is used in an intranet environment and all the websites and Windows services were hosted on the same single server along with our .NET Remoting Windows service. (They could quite easily have been on different servers but there was no need in this case.) It was decided to \"embrace the new\" by migrating this .NET Remoting project over to WCF. The plan wasn't to do anything revolutionary, just to move from one approach to the other as easily as possible. I found the following useful article on MSDN: ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/aa730857%28v=vs.80%29.aspx"}),"http://msdn.microsoft.com/en-us/library/aa730857%28v=vs.80%29.aspx")," This particular article was helpful and following the steps enclosed I was quickly up and running with a basic WCF service hosted in a Windows service. It was at this point I started thinking about security. The existing .NET Remoting approach had no security in place. This wasn't ideal but also probably wasn't the worry you might think. It was hosted in an intranet environment and hence not so exposed to the rigours of the Wild Wild Web. However, since I was looking at WCF I thought it would be a good opportunity to get some basic security in place. This generally pleases auditors. I opted to use ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/ms733089.aspx"}),"Windows Transport authentication")," as this seemed pretty appropriate for an intranet environment. The idea being that we'd authenticate with Windows for an account in our domain. After headbutting Windows for some time I managed to get a successful client call going from the website running on my development machine to the (separate) development server that was hosting our WCF Window service using Transport Windows authentication. However, when deploying the website to the development server I discovered we would experience the following error when the website attempted to call the WCF service (on the same server)."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"Event Type: Failure Audit\nEvent Source: Security\nEvent Category: Logon/Logoff\nEvent ID: 537\nDate: 15/02/2012\nTime: 16:32:04\nUser: NT AUTHORITY\\SYSTEM\nComputer: MINE999\nDescription:\nLogon Failure:\nReason: An error occurred during logon\nLogon Type: 3\nLogon Process: ^\nAuthentication Package: NTLM\nStatus code: 0xC000006D\n")),(0,a.kt)("p",null,'Not terribly helpful. At the end of the day it seemed we were suffering from a security "feature" introduced by Microsoft to prevent services calling services on the same box with a fully qualified name. An explanation of this can be found here: ',(0,a.kt)("a",o({parentName:"p"},{href:"http://developers.de/blogs/damir_dobric/archive/2009/08/28/authentication-problems-by-using-of-ntlm.aspx"}),"http://developers.de/blogs/damir_dobric/archive/2009/08/28/authentication-problems-by-using-of-ntlm.aspx")," Using method 1 in the enclosed link I initially worked round this by amending the registry and rebooting the server: ",(0,a.kt)("a",o({parentName:"p"},{href:"http://support.microsoft.com/kb/887993"}),"http://support.microsoft.com/kb/887993")," This was not a fantastic solution. Fortunately I subsequently found a better one but since the resources on the web are ","*",(0,a.kt)("strong",{parentName:"p"},"ATROCIOUS"),"*"," on this point I thought I should take the time to note down the full explanation since otherwise it'll be lost in the mists of time. Here we go: The equivalent security to the previous .NET Remoting solution in WCF was to use this config setting on client and service:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<security mode="None" />\n')),(0,a.kt)("p",null,'As I\'ve said, this is an intranet environment and so having this "none" security setting in place is made less worrying by the fact that the network itself is secured. But obviously this is not ideal and unlikely to be audit compliant. To use Windows security you need this netTcpBinding config setting on client and service:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<security mode="Transport">\n<transport clientCredentialType="Windows" />\n</security>\n')),(0,a.kt)("p",null,"To call the service with this setting in place you will need to be an authenticated Windows user. (Or at the very least impersonating one - but you knew that.) ",(0,a.kt)("strong",{parentName:"p"},"NOW FOR THE MOST IMPORTANT BIT.....")," The endpoint addresses ","*",(0,a.kt)("strong",{parentName:"p"},"must"),"*",' be "localhost" for ',(0,a.kt)("em",{parentName:"p"},"both"),' client and service when both are deployed to the same server. If this is not the case then you will suffer from the aforementioned security "feature" which will provide you with unhelpful "the server has rejected the client credentials" messages and ',"*",(0,a.kt)("strong",{parentName:"p"},"nothing"),"*"," else. ",(0,a.kt)("strong",{parentName:"p"},"OK FINISHED - MOVE ALONG NOW... NOTHING MORE TO SEE HERE"),' With WCF Windows Transport authentication in place you can interrogate the calling user id within the service methods by simply evaluating ServiceSecurityContext.Current.PrimaryIdentity.Name (which will be something like "myDomain\\myUserName"). So we you wanted to, we could have a simple step which evaluated if the calling user is on the "approved" / "authorised" list. I\'m sure this could be made more sophisticated by using groups etc I guess - though I haven\'t investigated it further as yet. In fact, I suspect Microsoft may have something even more sophisticated still available for use which I\'m unaware of - if anyone knows a simple explanation of this then please do let me know! In closing, I do think Microsoft could work on providing more helpful error messages than "the server has rejected the client credentials". Going by what I read as I researched this error many people seem to have struggled much as I did before eventually bailing out and ended up chancing it by turning security off in their applications. Clearly it is not desirable to have people so confused by errors that they give up and settle for a less secure solution.'))}d.isMDXComponent=!0},81295:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"joy-of-json",title:"The Joy of JSON",authors:"johnnyreilly",tags:["json"],hide_table_of_contents:!1},s=void 0,l={permalink:"/joy-of-json",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-02-23-joy-of-json/index.md",source:"@site/blog/2012-02-23-joy-of-json/index.md",title:"The Joy of JSON",description:"So back to JSON. For those of you that don't know JSON stands for JavaScript Object Notation and is lightweight text based data interchange format. Rather than quote other people verbatim you can find thorough explanations of JSON here: - Introducing JSON",date:"2012-02-23T00:00:00.000Z",formattedDate:"February 23, 2012",tags:[{label:"json",permalink:"/tags/json"}],readingTime:3.55,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"joy-of-json",title:"The Joy of JSON",authors:"johnnyreilly",tags:["json"],hide_table_of_contents:!1},prevItem:{title:"jQuery Unobtrusive Remote Validation",permalink:"/jquery-unobtrusive-remote-validation"},nextItem:{title:"WCF Transport Windows authentication using NetTcpBinding in an Intranet environment",permalink:"/wcf-transport-windows-authentication"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"So back to JSON. For those of you that don't know JSON stands for JavaScript Object Notation and is lightweight text based data interchange format. Rather than quote other people verbatim you can find thorough explanations of JSON here: - ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.json.org/"}),"Introducing JSON")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://www.json.org/js.html"}),"JSON in Javascript"))),(0,a.kt)("p",null,"As mentioned in my previous ",(0,a.kt)("a",o({parentName:"p"},{href:"/potted-history-of-using-ajax-on"}),"post on Ajax")," I came upon JSON quite by accident and was actually using it for some time without having any idea. But let's pull back a bit. Let's start with the JavaScript Object Literal. Some years ago I came upon this article by Christan Heilmann about the JavaScript Object Literal which had been published all the way back in 2006: ",(0,a.kt)("a",o({parentName:"p"},{href:"http://christianheilmann.com/2006/02/16/show-love-to-the-object-literal/"}),"Show love to the JavaScript Object Literal")," Now when I read this it was a revelation to me. I hadn't really used JavaScript objects a great deal at this point (yes I am one of those people that started using JavaScript without actually learning the thing) and when I had used them is was through the ",(0,a.kt)("inlineCode",{parentName:"p"},"var obj = new Object()")," pattern (as that's the only approach I knew). So it was wonderful to discover that instead of the needlessly verbose:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var myCar = new Object();\nmyCar.wheels = 4;\nmyCar.colour = 'blue';\n")),(0,a.kt)("p",null,"I could simply use the much more concise object literal syntax to declare an object instead:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var myCar = { wheels: 4, colour: 'blue' };\n")),(0,a.kt)("p",null,"Lovely. Henceforth I adopted this approach in my code as I'm generally a believer that brevity is best. It was sometime later that I happened upon JSON (when I started looking into ",(0,a.kt)("a",o({parentName:"p"},{href:"/jqgrid-its-just-far-better-grid"}),"jqGrid"),"). Basically I was looking to pass complex data structures backward and forward to the server and, as far as I knew, there was no way to achieve this simply in JavaScript. I was expecting that I would have to manually serialise and deserialise (yes dammit I will use the English spellings!) objects when ever I wanted to do this sort of thing. However, I was reading the the fantastic Dave Ward's ",(0,a.kt)("a",o({parentName:"p"},{href:"http://encosia.com/"}),"Encosia")," blog which on this occasion was talking about the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://encosia.com/why-aspnet-ajax-updatepanels-are-dangerous/"}),"troubles of UpdatePanels")," (a subject close to my heart by the way) and more interestingly the use of PageMethods in ASP.NET. This is what he said that made me prick up my ears: ",(0,a.kt)("em",{parentName:"p"},'"Page methods allow ASP.NET AJAX pages to directly execute a page\u2019s static methods, using JSON (JavaScript Object Notation). JSON is basically a minimalistic version of SOAP, which is perfectly suited for light weight communication between client and server."')," JSON is a lightweight SOAP eh? I've used SOAP. I wonder if I could use this.... To my complete surprise, and may I say delight, I discovered that a wonderful fellow called Douglas Crockford, he of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.amazon.co.uk/JavaScript-Good-Parts-Douglas-Crockford/dp/0596517742"}),"JavaScript, The Good Parts"),' fame had quietly come up with JSON some time ago. JSON, from my perspective, turned out to be a simple way to turn an object into a string and then from a string back into an object. So simple that it consists of 2 methods on a JSON object: - JSON.stringify(myObject) - take an object and make me a JSON string. (and by the way isn\'t "stringify" just the loveliest method name ever?)'),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"JSON.parse(myJSONString) - take a JSON string and make me an object")),(0,a.kt)("p",null,"Let me illustrate the above method names using the myCar example from earlier:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),'var myCar = { wheels: 4, colour: \'blue\' };\n// myCar is an object\n\nvar myCarJSON = JSON.stringify(myCar);\n//myCarJSON will look like this: \'{"wheels":4,"colour":"blue"}\'\n\nvar anotherCarMadeFromMyJSON = JSON.parse(myCarJSON);\n//anotherCarMadeFromMyJSON will be a brand new "car" object\n')),(0,a.kt)("p",null,"I've also demonstrated this using the Chrome Console:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(41221).Z,width:"320",height:"77"})),(0,a.kt)("p",null,"Crockford initially invented/discovered JSON himself and wrote a little helper library which provided a JSON object to be used by all and sundry. This can be found here: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/douglascrockford/JSON-js"}),"JSON on GitHub")," Because JSON was so clearly wonderful, glorious and useful it ended up becoming a part of the EcmaScript 5 spec (in fact it's worth reading the brilliant ",(0,a.kt)("a",o({parentName:"p"},{href:"http://ejohn.org/blog/ecmascript-5-strict-mode-json-and-more/"}),"John Resig's blog post")," on this). This has lead to JSON being offered ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/JSON#Native_encoding_and_decoding_in_browsers"}),"natively in browsers")," for quite some time. However, for those of us (and I am one alas) still supporting IE 6 and the like we still have Crockfords JSON2.js to fall back on."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"")))}d.isMDXComponent=!0},45372:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"jquery-unobtrusive-remote-validation",title:"jQuery Unobtrusive Remote Validation",authors:"johnnyreilly",tags:["jquery","jquery validation","jquery unobtrusive validation"],hide_table_of_contents:!1},s=void 0,l={permalink:"/jquery-unobtrusive-remote-validation",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-03-03-jquery-unobtrusive-remote-validation/index.md",source:"@site/blog/2012-03-03-jquery-unobtrusive-remote-validation/index.md",title:"jQuery Unobtrusive Remote Validation",description:"Just recently I have been particularly needing to make use of remote / server-side validation in my ASP.NET MVC application and found that the unobtrusive way of using this seemed to be rather inadequately documented (of course it's possible that it's well documented and I just didn't find the resources). Anyway I've rambled on much longer than I intended to in this post so here's the TL;DR:",date:"2012-03-03T00:00:00.000Z",formattedDate:"March 3, 2012",tags:[{label:"jquery",permalink:"/tags/jquery"},{label:"jquery validation",permalink:"/tags/jquery-validation"},{label:"jquery unobtrusive validation",permalink:"/tags/jquery-unobtrusive-validation"}],readingTime:9,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"jquery-unobtrusive-remote-validation",title:"jQuery Unobtrusive Remote Validation",authors:"johnnyreilly",tags:["jquery","jquery validation","jquery unobtrusive validation"],hide_table_of_contents:!1},prevItem:{title:"Striving for (JavaScript) Convention",permalink:"/striving-for-javascript-convention"},nextItem:{title:"The Joy of JSON",permalink:"/joy-of-json"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Just recently I have been particularly needing to make use of remote / server-side validation in my ASP.NET MVC application and found that the unobtrusive way of using this seemed to be rather inadequately documented (of course it's possible that it's well documented and I just didn't find the resources). Anyway I've rambled on much longer than I intended to in this post so here's the TL;DR:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"You ","*",(0,a.kt)("strong",{parentName:"li"},"can"),"*"," use remote validation driven by unobtrusive data attributes"),(0,a.kt)("li",{parentName:"ul"},"Using remote validation you can supply ","*",(0,a.kt)("strong",{parentName:"li"},"multiple"),"*"," parameters to be evaluated"),(0,a.kt)("li",{parentName:"ul"},"It is possible to block validation and force it to be re-evaluted - although using a slightly hacky method which I document here. For what it's worth I acknowledge up front that this is ","*",(0,a.kt)("strong",{parentName:"li"},"not"),"*"," an ideal solution but it does seem to work. I really hope there is a better solution out there and if anyone knows about it then please get in contact and let me know.")),(0,a.kt)("p",null,"Off we go... So, jQuery unobtrusive validation; clearly the new cool right?"),(0,a.kt)("p",null,"I'd never been particularly happy with the validation that I had traditionally been using with ASP.NET classic. It worked... but it always seemed a little... clunky? I realise that's not the most well expressed concern. For basic scenarios it seemed fine, but I have recollections of going through some pain as soon as I stepped outside of the basic form validation. Certainly when it came to validating custom controls that we had developed it never seemed entirely straightforward to get validation to play nice."),(0,a.kt)("p",null,"Based on this I was keen to try something new and the opportunity presented itself when we started integrating MVC into our classic WebForms app. (By the way if you didn't know that MVC and ASP.NET could live together in perfect harmony, well, they can! And a good explanation on how to achieve it is offered by Colin Farr ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.britishdeveloper.co.uk/2011/05/convert-web-forms-mvc3-how-to.html"}),"here"),".)"),(0,a.kt)("p",null,"J\xf6rn Zaefferer came out with the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://bassistance.de/jquery-plugins/jquery-plugin-validation/"}),"jQuery validation plug-in")," way back in 2006. And mighty fine it is too. Microsoft (gor' bless 'em) really brought something new to the jQuery validation party when they came out with their unobtrusive javascript validation library along with MVC 3. What this library does, in short, is allows for jQuery validation to be driven by ",(0,a.kt)("inlineCode",{parentName:"p"},"data-val-*")," attributes alone as long as the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://ajax.aspnetcdn.com/ajax/jquery.validate/1.9/jquery.validate.js"}),"jquery.validate.js")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"http://ajax.aspnetcdn.com/ajax/mvc/3.0/jquery.validate.unobtrusive.js"}),"jquery.validate.unobtrusive.js")," libraries are included in the screen (I have assumed you are already including jQuery). I know; powerful stuff!"),(0,a.kt)("p",null,"A good explanation of unobtrusive validation is given by Brad Wilson ",(0,a.kt)("a",o({parentName:"p"},{href:"http://bradwilson.typepad.com/blog/2010/10/mvc3-unobtrusive-validation.html"}),"here"),"."),(0,a.kt)("p",null,"Anyway, to my point: what about remote validation? That is to say, what about validation which needs to go back to the server to perform the necessary tests? Well I struggled to find decent examples of how to use this. Those that I did find seemed to universally be php examples; not so useful for an ASP.NET user. Also, when I did root out an ASP.NET example there seemed to be a fundamental flaw. Namely, if remote validation hadn't been triggered and completed successfully then the submit could fire anyway. This seems to be down to the asynchronous nature of the test; ie because it is ","*",(0,a.kt)("strong",{parentName:"p"},"not"),"*",' synchronous there is no "block" to the submit. And out of the box with unobtrusive validation there seems no way to make this synchronous. I could of course wire this up manually and simply side-step the restrictions of unobtrusive validation but that wasn\'t what I wanted.'),(0,a.kt)("p",null,"*","*","*","Your mission John, should you decide to accept it, is this: ",(0,a.kt)("u",null,"block the submit until remote validation has completed successfully")),(0,a.kt)("p",null,". As always, should you or any of your I.M. Force be caught or killed, the Secretary will disavow any knowledge of your actions.","*","*","*"),(0,a.kt)("p",null,"So that's what I wanted to do. Make it act like it's synchronous even though it's asynchronous. Bit horrible but I had a deadline to meet and so this is my pragmatic solution. There may be better alternatives but this worked for me."),(0,a.kt)("p",null,"First of all the HTML:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<form\n  action="/Dummy/ValidationDemo.mvc/SaveUser"\n  id="ValidationForm"\n  method="post"\n>\n  First name:\n  <input\n    data-val="true"\n    data-val-required="First Name required"\n    id="FirstName"\n    name="FirstName"\n    type="text"\n    value=""\n  />\n\n  Last name:\n  <input\n    data-val="true"\n    data-val-required="Last Name required"\n    id="LastName"\n    name="LastName"\n    type="text"\n    value=""\n  />\n\n  User name:\n  <input\n    id="UserName"\n    name="UserName"\n    type="text"\n    value=""\n    data-val="true"\n    data-val-required="You must enter a user name before we can validate it remotely"\n    data-val-remote="&amp;#39;UserNameInput&amp;#39; is invalid."\n    data-val-remote-additionalfields="*.FirstName,*.LastName"\n    data-val-remote-url="/Dummy/ValidationDemo/IsUserNameValid"\n  />\n\n  <input\n    id="SaveMyDataButton"\n    name="SaveMyDataButton"\n    type="button"\n    value="Click to Save"\n  />\n</form>\n')),(0,a.kt)("p",null,"I should mention that on my actual page (a cshtml partial view) the HTML for the inputs is generated by the use of the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/system.web.mvc.html.inputextensions.textboxfor.aspx"}),"InputExtensions.TextBoxFor")," method which is lovely. It takes your model and using the validation attributes that decorate your models properties it generates the relevant jQuery unobtrusive validation data attributes so you don't have to do it manually."),(0,a.kt)("p",null,"But for the purposes of seeing what's \"under the bonnet\" I thought it would be more useful to post the raw HTML so it's entirely clear what is being used. Also there doesn't appear to be a good way (that I've yet seen) for automatically generating Remote validation data attributes in the way that I've found works. So I'm manually specifying the ",(0,a.kt)("inlineCode",{parentName:"p"},"data-val-remote-*")," attributes using the htmlAttributes parameter of the TextBoxFor (",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/questions/4844001/html5-data-with-asp-net-mvc-textboxfor-html-attributes"}),'using "',"_",'" to replace "-"')," obviously)."),(0,a.kt)("p",null,"Next the JavaScript that performs the validation:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"$(document).ready(function () {\n  var intervalId = null,\n    //\n    // DECLARE FUNCTION EXPRESSIONS\n    //\n\n    //======================================================\n    // function that triggers update when remote validation\n    // completes successfully\n    //======================================================\n    pendingValidationComplete = function () {\n      var i, errorList, errorListForUsers;\n      var $ValidationForm = $('#ValidationForm');\n      if ($ValidationForm.data('validator').pendingRequest === 0) {\n        clearInterval(intervalId);\n\n        //Force validation to present to user\n        //(this will *not* retrigger remote validation)\n        if ($ValidationForm.valid()) {\n          alert('Validation has succeeded - you can now submit');\n        } else {\n          //Validation failed!\n          errorList = $ValidationForm.data('validator').errorList;\n          errorListForUsers = [];\n          for (i = 0; i < errorList.length; i++) {\n            errorListForUsers.push(errorList[i].message);\n          }\n\n          alert(errorListForUsers.join('\\r\\n'));\n        }\n      }\n    },\n    //======================================================\n    // Trigger validation\n    //======================================================\n    triggerValidation = function (evt) {\n      //Removed cached values where remote is concerned\n      // so remote validation is retriggered\n      $('#UserName').removeData('previousValue');\n\n      //Trigger validation\n      $('#ValidationForm').valid();\n\n      //Setup interval which will evaluate validation\n      //(this approach because of remote validation)\n      intervalId = setInterval(pendingValidationComplete, 50);\n    };\n\n  //\n  //ASSIGN EVENT HANDLERS\n  //\n  $('#SaveMyDataButton').click(triggerValidation);\n});\n")),(0,a.kt)("p",null,"And finally the Controller:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public JsonResult IsUserNameValid(string UserName,\n                                  string FirstName,\n                                  string LastName)\n{\n  var userNameIsUnique = IsUserNameUnique(UserName);\n  if (userNameIsUnique)\n    return Json(true, JsonRequestBehavior.AllowGet);\n  else\n    return Json(string.Format(\n                  "{0} is already taken I\'m afraid {1} {2}",\n                  UserName, FirstName, LastName),\n                JsonRequestBehavior.AllowGet);\n}\n\nprivate bool IsUserNameUnique(string potentialUserName)\n{\n  return false;\n}\n')),(0,a.kt)("p",null,"So what happens here exactly? Well it's like this:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},'The user enters their first name, last name and desired user name and hits the "Click to Save" button.'),(0,a.kt)("li",{parentName:"ol"},"This forces validation by first removing any cached validation values stored in ",(0,a.kt)("inlineCode",{parentName:"li"},"previousValue")," data attribute and then triggering the ",(0,a.kt)("inlineCode",{parentName:"li"},"valid")," method. Disclaimer: I KNOW THIS IS A LITTLE HACKY. I would have expected there would be some way in the API to manually re-force validation. Unless I've missed something there doesn't appear to be. (",(0,a.kt)("a",o({parentName:"li"},{href:"http://stackoverflow.com/a/3797712/761388"}),"And the good citizens of Stack Overflow would seem to concur."),") I would guess that the underlying assumption is that if nothing has changed on the client then that's all that matters. Clearly that's invalid for our remote example given that a username could be \"claimed\" at any time; eg in between people first entering their username (when validation should have fired automatically) and actually submitting the form. Anyway - this approach seems to get us round the problem."),(0,a.kt)("li",{parentName:"ol"},"When validation takes place the IsUserNameValid action / method on our controller will be called. It's important to note that I have set up a method that takes 3 inputs; UserName, which is supplied by default as the UserName input is the one which is decorated with remote validation attributes as well as the 2 extra inputs of FirstName and LastName. In the example I've given I don't actually need these extra attributes. I'm doing this because I know that I have situations in remote validation where I ","*",(0,a.kt)("strong",{parentName:"li"},"need"),"*"," to supply multiple inputs and so essentially I did it here as a proof of concept. The addition of these 2 extra inputs was achieved through the use of the ",(0,a.kt)("inlineCode",{parentName:"li"},"data-val-remote-additionalfields")," attribute. When searching for documentation about this I found absolutely ",(0,a.kt)("u",null,"none"))),(0,a.kt)("p",null,". I assume there is some out there - if anyone knows then I'd very pleased to learn about it. I only learned about it in the end by finding an example of someone using this out in the great wide world and understanding how to use it based on their example. To understand how the ",(0,a.kt)("inlineCode",{parentName:"p"},"data-val-remote-additionalfields")," attribute works you can look at jquery.validate.unobtrusive.js. If you're just looking to get up and running then I found that the following works: ",(0,a.kt)("inlineCode",{parentName:"p"},'data-val-remote-additionalfields="*.FirstName,*.LastName"')," You will notice that: - Each parameter is supplied in the format ",(0,a.kt)("em",{parentName:"p"},"*",".","[InputName]"),' and inputs are delimited by ","\'s - Name is a ',(0,a.kt)("u",null,"required")),(0,a.kt)("p",null,"attribute for an input if you wish it to be evaluated with unobtrusive validation. (Completely obvious statement I realise; I'm writing that sentence more for my benefit than yours) - Finally, our validation always fails. That's deliberate - I just wanted to be clear on the approach used to get remote unobtrusive validation with extra parameters up and running. 4. Using ",(0,a.kt)("inlineCode",{parentName:"p"},"setInterval")," we intend to trigger the ",(0,a.kt)("inlineCode",{parentName:"p"},"pendingValidationComplete")," function to check if remote validation has completed every 50ms - again I try to avoid setInterval wherever possible but this seems to be the most sensible solution in this case. 5. When the remote request finally completes (ie when ",(0,a.kt)("inlineCode",{parentName:"p"},"pendingRequest")," has a value of 0) then we can safely proceed on the basis of our validation results. In the example above I'm simply alerting to the screen based on my results; this is ","*",(0,a.kt)("strong",{parentName:"p"},"not"),"*"," advised for any finished work; I'm just using this mechanism here to demonstrate the principle."),(0,a.kt)("p",null,"Validation in action:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(35615).Z,width:"315",height:"320"})),(0,a.kt)("p",null,"Well I've gone on for far too long but I am happy to have an approach that does what I need. It does feel like a slightly hacky solution and I expect that there is a better approach for this that I'm not aware of. As much as anything else I've written this post in the hope that someone who knows this better approach will set me straight. In summary, this works. But if you're aware of a better solution then please do get in contact - I'd love to know!"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"PS:"),"Just in case you're in the process of initially getting up and running with unobtrusive validation I've listed below a couple of general helpful bits of config etc:"),(0,a.kt)("p",null,"The following setting is essential for Application_Start in Global.asax.cs:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"DataAnnotationsModelValidatorProvider.AddImplicitRequiredAttributeForValueTypes = false;\n")),(0,a.kt)("p",null,"The following settings should be used in your Web.Config:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<appSettings>\n  <add key="ClientValidationEnabled" value="true" />\n  <add key="UnobtrusiveJavaScriptEnabled" value="true "/>\n</appSettings>\n')),(0,a.kt)("p",null,"My example used the following scripts:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<script src="Scripts/jquery-1.7.1.js"><\/script>\n<script src="Scripts/jquery.validate.js"><\/script>\n<script src="Scripts/jquery.validate.unobtrusive.js"><\/script>\n<script src="Scripts/ValidationDemo.js"><\/script>\n')))}d.isMDXComponent=!0},21706:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"striving-for-javascript-convention",title:"Striving for (JavaScript) Convention",authors:"johnnyreilly",tags:["javascript"],hide_table_of_contents:!1},s=void 0,l={permalink:"/striving-for-javascript-convention",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-03-12-striving-for-javascript-convention/index.md",source:"@site/blog/2012-03-12-striving-for-javascript-convention/index.md",title:"Striving for (JavaScript) Convention",description:"Update",date:"2012-03-12T00:00:00.000Z",formattedDate:"March 12, 2012",tags:[{label:"javascript",permalink:"/tags/javascript"}],readingTime:9.635,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"striving-for-javascript-convention",title:"Striving for (JavaScript) Convention",authors:"johnnyreilly",tags:["javascript"],hide_table_of_contents:!1},prevItem:{title:"Using the PubSub / Observer pattern to emulate constructor chaining without cluttering up global scope",permalink:"/using-pubsub-observer-pattern-to"},nextItem:{title:"jQuery Unobtrusive Remote Validation",permalink:"/jquery-unobtrusive-remote-validation"}},p={authorsImageUrls:[void 0]},u=[{value:"Update",id:"update",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"update"}),"Update"),(0,a.kt)("p",null,"The speed of change makes fools of us all. Since I originally wrote this post all of 3 weeks ago Visual Studio 11 beta has been released and the issues I was seeking to solve have pretty much been resolved by the new innovations found therein. It's nicely detailed in ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.twitter.com/carlbergenhem"}),"@carlbergenhem"),"'s blog post: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.telerik.com/blogs/posts/12-03-26/my-top-5-visual-studio-11-designer-improvements-for-asp-net-4-5-development.aspx"}),"My Top 5 Visual Studio 11 Designer Improvements for ASP.NET 4.5 Development"),". I've left the post in place below but much of what I said (particularly with regard to Hungarian Notation) I've now moved away from. That was originally my intention anyway so that's no bad thing. The one HN artefact that I've held onto is using \"$\" as a prefix for jQuery objects. I think that still makes sense. I would have written my first line of JavaScript in probably 2000. It probably looked something like this: ",(0,a.kt)("inlineCode",{parentName:"p"},"alert('hello world')"),". I know. Classy. As I've mentioned before it was around 2010 before I took JavaScript in any way seriously. Certainly it was then when I started to actively learn the language. Because up until this point I'd been studiously avoiding writing any JavaScript at all I'd never really given thought to forms and conventions. When I wrote any JavaScript I just used the same style and approaches as I used in my main development language (of C#). By and large I have been following the .net naming conventions which are ably explained by Pete Brown ",(0,a.kt)("a",o({parentName:"p"},{href:"http://10rem.net/articles/net-naming-conventions-and-programming-standards---best-practices"}),"here"),". Over time I have started to move away from this approach. Without a deliberate intention to do so I have found myself adopting a different style for my JavaScript code as compared with anything else I write. I wouldn't go so far as to say I'm completely happy with the style I'm currently using. But I find it more helpful than not and thought it might be worth talking about. It was really 2 things that started me down the road of \"rolling my own\" convention: dynamic typing and the lack of safety nets. Let's take each in turn.... ### 1","."," Dynamic typing"),(0,a.kt)("p",null,"Having grown up (in a development sense) using compiled and strongly-typed languages I was used to the IDE making it pretty clear what was what through friendly tooltips and the like:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(37553).Z,width:"174",height:"58"})),(0,a.kt)("p",null,"JavaScript is loosely / dynamically typed (",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/questions/9154388/does-untyped-also-mean-dynamically-typed-in-the-academic-cs-world"}),'occasionally called "untyped" but let\'s not go there'),"). This means that the IDE can't easily determine what's what. So no tooltips for you sunshine. ### 2","."," The lack of safety nets / running with scissors"),(0,a.kt)("p",null,"Now I've come to love it but what I realised pretty quickly when getting into JavaScript was this: you are running with scissors. If you're not careful and you don't take precautions it can bloody quickly. If I'm writing C# I have a lot of safety nets. Not the least of which is \"does it compile\"? If I declare an integer and then subsequently try to assign a string value to it ",(0,a.kt)("u",null,"it won't let me")),(0,a.kt)("p",null,". But JavaScript is forgiving. Some would say too forgiving. Let's do something mad:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var iAmANumber = 77;\n\nconsole.log(iAmANumber); //Logs a number\n\niAmANumber = \"It's a string\";\n\nconsole.log(iAmANumber); //Logs a string\n\niAmANumber = {\n  description: 'I am an object',\n};\n\nconsole.log(iAmANumber); //Logs an object\n\niAmANumber = function (myVariable) {\n  console.log(myVariable);\n};\n\nconsole.log(iAmANumber); //Logs a function\niAmANumber('I am not a number, I am a free man!'); //Calls a function which performs a log\n")),(0,a.kt)("p",null,"Now if I were to attempt something similar in C# fuggedaboudit but JavaScript; no I'm romping home free:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(28067).Z,width:"320",height:"251"})),(0,a.kt)("p",null,"Now I'm not saying that you should ever do the above, and thinking about it I can't think of a situation where you'd want to (suggestions on a postcard). But the point is it's possible. And because it's possible to do this deliberately, it's doubly possible to do this accidentally. My point is this: it's easy to make bugs in JavaScript. ## What ",(0,a.kt)("del",{parentName:"p"},"Katy")," Johnny Did Next"),(0,a.kt)("p",null,"I'd started making more and more extensive use of JavaScript. I was beginning to move in the direction of using the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Single-page_application"}),"single-page application")," approach (",(0,a.kt)("em",{parentName:"p"},"although more in the sense of giving application style complexity to individual pages rather than ensuring that entire applications ended up in a single page"),"). This meant that whereas in the past I'd had the occasional 2 lines of JavaScript I now had a multitude of functions which were all interacting in response to user input. All these functions would contain a number of different variables. As well as this I was making use of jQuery for both Ajax purposes and to smooth out the DOM inconsistencies between various browsers. This only added to the mix as variables in one of my functions could be any one of the following: - a number"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"a string"),(0,a.kt)("li",{parentName:"ul"},"a boolean"),(0,a.kt)("li",{parentName:"ul"},"a date"),(0,a.kt)("li",{parentName:"ul"},"an object"),(0,a.kt)("li",{parentName:"ul"},"an array"),(0,a.kt)("li",{parentName:"ul"},"a function"),(0,a.kt)("li",{parentName:"ul"},"a jQuery object - not strictly a distinct JavaScript type obviously but treated pretty much as one in the sense that it has a particular functions / properties etc associated with it")),(0,a.kt)("p",null,"As I started doing this sort of work I made no changes to my coding style. Wherever possible I did ","*",(0,a.kt)("strong",{parentName:"p"},"exactly"),"*"," what I would have been doing in C# in JavaScript. And it worked fine. Until.... Okay there is no \"until\" as such, it did work fine. But what I found was that I would do a piece of work, check it into source control, get users to test it, release the work into Production and promptly move onto the next thing. However, a little way down the line there would be a request to add a new feature or perhaps a bug was reported and I'd find myself back looking at the code. And, as is often the case, despite the comments I would realise that it wasn't particularly clear why something worked in the way it did. (Happily it's not just me that has this experience, paranoia has lead me to ask many a fellow developer and they have confessed to similar) When it came to bug hunting in particular I found myself cursing the lack of friendly tooltips and the like. Each time I wanted to look at a variable I'd find myself tracking back through the function, looking for the initial use of the variable to determine the type. Then I'd be tracking forward through the function for each subsequent use to ensure that it conformed. Distressingly, I would find examples of where it looked like I'd forgotten the type of the variable towards the end of a function (for which I can only, regrettably, blame myself). Most commonly I would have a situation like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var tableCell = $('#ItIsMostDefinitelyATableCell'); //I jest ;-)\n\n/* ...THERE WOULD BE SOME CODE DOING SOMETHING HERE... */\n\ntableCell.className = 'makeMeProminent'; //Oh dear - not good.\n")),(0,a.kt)("p",null,"You see what happened above? I forgot I had a jQuery object and instead treated it like it was a standard DOM element. Oh dear. ## Spinning my own safety net; Hungarian style"),(0,a.kt)("p",null,'After I\'d experienced a few of the situations described above I decided that steps needed to be taken to minimise the risk of this. In this case, I decided that "steps" meant ',(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Hungarian_notation"}),"Hungarian notation"),". I know. I bet you're wincing right now. For those of you that don't remember HN was pretty much the standard way of coding at one point (although at the point that I started coding professionally it had already started to decline). It was adopted in simpler times long before the modern IDE's that tell you what each variable is became the norm. Back when you couldn't be sure of the types you were dealing with. In short, kind of like my situation with JavaScript right now. There's not much to it. By and large HN simply means having a lowercase prefix of 1-3 characters on all your variables indicating type. It doesn't solve all your problems. It doesn't guarantee to stop bugs. But because each instance of the variables use implicitly indicates it's type it makes bugs more glaringly obvious. This means when writing code I'm less likely to misuse a variable (eg ",(0,a.kt)("inlineCode",{parentName:"p"},'iNum = "JIKJ"'),") because part of my brain would be bellowing: \"that just looks wrong... pay better attention lad!\". Likewise, if I'm scanning through some JavaScript and searching for a bug then this can make it more obvious. Here's some examples of different types of variables declared using the style I have adopted:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var iInteger = 4;\nvar dDecimal = 10.5;\nvar sString = 'I am a string';\nvar bBoolean = true;\nvar dteDate = new Date();\nvar oObject = {\n  description: 'I am an object',\n};\nvar aArray = [34, 77];\nvar fnFunction = function () {\n  //Do something\n};\nvar $jQueryObject = $('#ItIsMostDefinitelyATableCell');\n")),(0,a.kt)("p",null,"Some of you have read this and thought \"hold on a minute... JavaScript doesn't have integers / decimals etc\". You're quite right. My style is not specifically stating the type of a variable. More it is seeking to provide a guide on how a variable should be used. JavaScript does not have integers. But oftentimes I'll be using a number variable which i will only ever want to treat as an integer. And so I'll name it accordingly. ## Spinning a better safety net; DOJO style"),(0,a.kt)("p",null,"I would be the first to say that alternative approaches are available. And here's one I recently happened upon that I rather like the look of: look 2/3rds down at the parameters section of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://dojotoolkit.org/community/styleGuide"}),"the DOJO styleguide")," Essentially they advise specifying parameter types through the use of prefixed comments. See the examples below:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"function(/*String*/ foo, /*int*/ bar)...\n")),(0,a.kt)("p",null,"or"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"function(/_String?_/ foo, /_int_/ bar, /_String[]?_/ baz)...\n")),(0,a.kt)("p",null,"I really rather like this approach and I'm thinking about starting to adopt it. It's not possible in Hungarian Notation to be so clear about the purpose of a variable. At least not without starting to adopt all kinds of kooky conventions that take in all the possible permutations of variable types. And if you did that you'd really be defeating yourself anyway as it would simply reduce the clarity of your code and make bugs more likely. ## Spinning a better safety net; unit tests"),(0,a.kt)("p",null,"Despite being quite used to writing unit tests for all my server-side code I have not yet fully embraced unit testing on the client. Partly I've been holding back because of the variety of JavaScript testing frameworks available. I wasn't sure which to start with. But given that it is so easy to introduce bugs into JavaScript I have come to the conclusion that it's better to have some tests in place rather than none. Time to embrace the new. ## Conclusion"),(0,a.kt)("p",null,"I've found using Hungarian Notation useful whilst working in JavaScript. Not everyone will feel the same and I think that's fair enough; within reason I think it's generally a good idea to go with what you find useful. However, I am giving genuine consideration to moving to the DOJO style and moving back to my more standard camel-cased variable names instead of Hungarian Notation. Particularly since I strive to keep my functions short with the view that ideally each should 1 thing well. Keep it simple etc... And so in a perfect world the situation of forgetting a variables purpose shouldn't really arise... I think once I've got up and running with JavaScript unit tests I may make that move. Hungarian Notation may have proved to be just a stop-gap measure until better techniques were employed..."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"")))}d.isMDXComponent=!0},17667:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"using-pubsub-observer-pattern-to",title:"Using the PubSub / Observer pattern to emulate constructor chaining without cluttering up global scope",authors:"johnnyreilly",tags:["javascript"],hide_table_of_contents:!1},s=void 0,l={permalink:"/using-pubsub-observer-pattern-to",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-03-17-using-pubsub-observer-pattern-to/index.md",source:"@site/blog/2012-03-17-using-pubsub-observer-pattern-to/index.md",title:"Using the PubSub / Observer pattern to emulate constructor chaining without cluttering up global scope",description:"Yes the title of this post is \\*painfully\\* verbose. Sorry about that. Couple of questions for you: - Have you ever liked the way you can have base classes in C# which can then be inherited and subclassed in a different file / class",date:"2012-03-17T00:00:00.000Z",formattedDate:"March 17, 2012",tags:[{label:"javascript",permalink:"/tags/javascript"}],readingTime:5.48,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"using-pubsub-observer-pattern-to",title:"Using the PubSub / Observer pattern to emulate constructor chaining without cluttering up global scope",authors:"johnnyreilly",tags:["javascript"],hide_table_of_contents:!1},prevItem:{title:"WCF - moving from Config to Code, a simple WCF service harness (plus implementing your own Authorization)",permalink:"/wcf-moving-from-config-to-code-simple"},nextItem:{title:"Striving for (JavaScript) Convention",permalink:"/striving-for-javascript-convention"}},p={authorsImageUrls:[void 0]},u=[{value:"The Problem",id:"the-problem",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Yes the title of this post is ","*",(0,a.kt)("strong",{parentName:"p"},"painfully"),"*"," verbose. Sorry about that. Couple of questions for you: - Have you ever liked the way you can have base classes in C# which can then be inherited and subclassed ",(0,a.kt)("u",null,"in a different file / class")),(0,a.kt)("p",null,"?"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Have you ever thought; gosh it'd be nice to do something like that in JavaScript..."),(0,a.kt)("li",{parentName:"ul"},"Have you then looked at JavaScripts prototypical inheritance and thought \"right.... I'm sure it's possible but this going to end up like ",(0,a.kt)("a",o({parentName:"li"},{href:"http://en.wikipedia.org/wiki/War_and_Peace"}),"War and Peace"),'"'),(0,a.kt)("li",{parentName:"ul"},"Have you then subsequently thought \"and hold on a minute... even if I did implement this using the prototype and split things between different files / modules wouldn't I have to pollute the global scope to achieve that? And wouldn't that mean that my code was exposed to the vagaries of any other scripts on the page? Hmmm...\""),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://www.thrillingdetective.com/eyes/oxford.html"}),"Men! Are you skinny? Do bullies kick sand in your face?")," (Just wanted to see if you were still paying attention...)")),(0,a.kt)("h2",o({},{id:"the-problem"}),"The Problem"),(0,a.kt)("p",null,"Well, the above thoughts occurred to me just recently. I had a situation where I was working on an MVC project and needed to build up quite large objects within JavaScript representing various models. The models in question were already implemented on the server side using classes and made extensive use of inheritance because many of the properties were shared between the various models. That is to say we would have models which were implemented through the use of a class inheriting a base class which in turn inherits a further base class. With me? Good. Perhaps I can make it a little clearer with an example. Here are my 3 classes. First BaseReilly.cs:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public class BaseReilly\n{\n    public string LastName { get; set; }\n\n        public BaseReilly()\n        {\n            LastName = "Reilly";\n        }\n    }\n')),(0,a.kt)("p",null,"Next BoyReilly.cs (which inherits from BaseReilly):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public class BoyReilly : BaseReilly\n{\n    public string Sex { get; set; }\n\n    public BoyReilly()\n        : base()\n    {\n        Sex = "It is a manchild";\n    }\n}\n')),(0,a.kt)("p",null,"And finally JohnReilly.cs (which inherits from BoyReilly which in turn inherits from BaseReilly):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public class JohnReilly : BoyReilly\n{\n    public string FirstName { get; set; }\n\n    public JohnReilly()\n        : base()\n    {\n        FirstName = "John";\n    }\n}\n')),(0,a.kt)("p",null,'Using the above I can create myself my very own "JohnReilly" like so:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"var johnReilly = new JohnReilly();\n")),(0,a.kt)("p",null,"And it will look like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(90672).Z,width:"320",height:"140"})),(0,a.kt)("p",null,"I was looking to implement something similar on the client and within JavaScript. I was keen to ensure ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Code_reuse"}),"code reuse"),". And my inclination to keep things simple made me wary of making use of the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://bonsaiden.github.com/JavaScript-Garden/#object.prototype"}),"prototype"),". It is undoubtedly powerful but I don't think even the mighty ",(0,a.kt)("a",o({parentName:"p"},{href:"http://javascript.crockford.com/prototypal.html"}),"Crockford"),' would consider it "simple". Also I had the reservation of exposing my object to the global scope. So what to do? I had an idea.... ## The Big Idea'),(0,a.kt)("p",null,"For a while I've been making use explicit use of the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Observer_pattern"}),"Observer pattern"),' in my JavaScript, better known by most as the publish/subscribe (or "PubSub") pattern. There\'s a million JavaScript libraries that facilitate this and after some experimentation I finally settled on ',(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/phiggins42/bloody-jquery-plugins/blob/master/pubsub.js"}),"higgins")," implementation as it's simple and I saw a ",(0,a.kt)("a",o({parentName:"p"},{href:"http://jsperf.com/pubsubjs-vs-jquery-custom-events/11"}),"JSPerf")," which demonstrated it as either the fastest or second fastest in class. Up until now my main use for it had been to facilitate loosely coupled GUI interactions. If I wanted one component on the screen to influence anothers behaviour I simply needed to get the first component to publish out the relevant events and the second to subscribe to these self-same events. One of the handy things about publishing out events this way is that with them you can also include data. This data can be useful when driving the response in the subscribers. However, it occurred to me that it would be equally possible to pass an object when publishing an event. ","*","*",(0,a.kt)("u",null,"And the subscribers could enrich that object with data as they saw fit.")),(0,a.kt)("p",null,"*","*"," Now this struck me as a pretty useful approach. It's not rock solid secure as it's always possible that someone could subscribe to your events and get access to your object as you published out. However, that's pretty unlikely to happen accidentally; certainly far less likely than someone else's global object clashing with your global object. ## What might this look like in practice?"),(0,a.kt)("p",null,"So this is what it ended up looking like when I turned my 3 classes into JavaScript files / modules. First BaseReilly.js:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"$(function () {\n  $.subscribe('PubSub.Inheritance.Emulation', function (obj) {\n    obj.LastName = 'Reilly';\n  });\n});\n")),(0,a.kt)("p",null,"Next BoyReilly.js:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"$(function () {\n  $.subscribe('PubSub.Inheritance.Emulation', function (obj) {\n    obj.Sex = 'It is a manchild';\n  });\n});\n")),(0,a.kt)("p",null,"And finally JohnReilly.js:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"$(function () {\n  $.subscribe('PubSub.Inheritance.Emulation', function (obj) {\n    obj.FirstName = 'John';\n  });\n});\n")),(0,a.kt)("p",null,'If the above scripts have been included in a page I can create myself my very own "JohnReilly" in JavaScript like so:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),'var oJohnReilly = {}; //Empty object\n\n$.publish(\'PubSub.Inheritance.Emulation\', [oJohnReilly]); //Empty object "published" so it can be enriched by subscribers\n\nconsole.log(JSON.stringify(oJohnReilly)); //Show me this thing you call "JohnReilly"\n')),(0,a.kt)("p",null,"And it will look like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(62991).Z,width:"320",height:"137"})),(0,a.kt)("p",null,"And it works. Obviously the example I've given above it somewhat naive - in reality my object properties are driven by GUI components rather than hard-coded. But I hope this illustrates the point. This technique allows you to simply share functionality between different JavaScript files and so keep your codebase tight. I certainly wouldn't recommend it for all circumstances but when you're doing something as simple as building up an object to be used to pass data around (as I am) then it works very well indeed. ## A Final Thought on Script Ordering"),(0,a.kt)("p",null,"A final thing that maybe worth mentioning is script ordering. The order in which functions are called is driven by the order in which subscriptions are made. In my example I was registering the scripts in this order:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<script src="/Scripts/PubSubInheritanceDemo/BaseReilly.js"><\/script>\n<script src="/Scripts/PubSubInheritanceDemo/BoyReilly.js"><\/script>\n<script src="/Scripts/PubSubInheritanceDemo/JohnReilly.js"<>/script>\n')),(0,a.kt)("p",null,"So when my event was published out the functions in the above JS files would be called in this order: 1. BaseReilly.js 2. BoyReilly.js 3. JohnReilly.js"),(0,a.kt)("p",null,"If you were so inclined you could use this to emulate inheritance in behaviour. Eg you could set a property in ",(0,a.kt)("inlineCode",{parentName:"p"},"BaseReilly.js")," which was subsequently overridden in ",(0,a.kt)("inlineCode",{parentName:"p"},"JohnReilly.js")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"BoyReilly.js")," if you so desired. I'm not doing that myself but it occurred as a possibility. ## PS"),(0,a.kt)("p",null,"If you're interested in learning more about JavaScript stabs at inheritance you could do far worse than look at Bob Inces in depth StackOverflow ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/1598077/761388"}),"answer"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"")))}d.isMDXComponent=!0},38008:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"wcf-moving-from-config-to-code-simple",title:"WCF - moving from Config to Code, a simple WCF service harness (plus implementing your own Authorization)",authors:"johnnyreilly",tags:["WCF","authorization"],hide_table_of_contents:!1},s=void 0,l={permalink:"/wcf-moving-from-config-to-code-simple",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-03-22-wcf-moving-from-config-to-code-simple/index.md",source:"@site/blog/2012-03-22-wcf-moving-from-config-to-code-simple/index.md",title:"WCF - moving from Config to Code, a simple WCF service harness (plus implementing your own Authorization)",description:"Last time I wrote about WCF I was getting up and running with WCF Transport Windows authentication using NetTcpBinding in an Intranet environment. I ended up with a WCF service hosted in a Windows Service which did pretty much what the previous post name implies.",date:"2012-03-22T00:00:00.000Z",formattedDate:"March 22, 2012",tags:[{label:"WCF",permalink:"/tags/wcf"},{label:"authorization",permalink:"/tags/authorization"}],readingTime:10.655,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"wcf-moving-from-config-to-code-simple",title:"WCF - moving from Config to Code, a simple WCF service harness (plus implementing your own Authorization)",authors:"johnnyreilly",tags:["WCF","authorization"],hide_table_of_contents:!1},prevItem:{title:"Making PDFs from HTML in C# using WKHTMLtoPDF",permalink:"/making-pdfs-from-html-in-c-using"},nextItem:{title:"Using the PubSub / Observer pattern to emulate constructor chaining without cluttering up global scope",permalink:"/using-pubsub-observer-pattern-to"}},p={authorsImageUrls:[void 0]},u=[{value:"Moving from Config to Code",id:"moving-from-config-to-code",level:2},{value:"Show me your harness",id:"show-me-your-harness",level:2},{value:"Locking down Authorization to a single Windows account",id:"locking-down-authorization-to-a-single-windows-account",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Last time I wrote about WCF I was getting up and running with ",(0,a.kt)("a",o({parentName:"p"},{href:"/wcf-transport-windows-authentication"}),"WCF Transport Windows authentication using NetTcpBinding in an Intranet environment"),". I ended up with a WCF service hosted in a Windows Service which did pretty much what the previous post name implies."),(0,a.kt)("p",null,"Since writing that I've taken things on a bit further and I thought it worth recording my approach whilst it's still fresh in my mind. There's 3 things I want to go over:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},'I\'ve moved away from the standard config driven WCF approach to a more "code-first" style'),(0,a.kt)("li",{parentName:"ol"},"I've established a basic Windows Service hosted WCF service / client harness which is useful if you're trying to get up and running with a WCF service quickly"),(0,a.kt)("li",{parentName:"ol"},"I've locked down the WCF authorization to a single Windows account through the use of my own ",(0,a.kt)("a",o({parentName:"li"},{href:"http://msdn.microsoft.com/en-us/library/ms731774.aspx"}),"ServiceAuthorizationManager"))),(0,a.kt)("h2",o({},{id:"moving-from-config-to-code"}),"Moving from Config to Code"),(0,a.kt)("p",null,"So, originally I was doing what all the cool kids are doing and driving the configuration of my WCF service and all its clients through config files. And why not? I'm in good company."),(0,a.kt)("p",null,"Here's why not: it gets ","*",(0,a.kt)("strong",{parentName:"p"},"very"),"*"," verbose ","*",(0,a.kt)("strong",{parentName:"p"},"very"),"*"," quickly...."),(0,a.kt)("p",null,"Okay - that's not the end of the world. My problem was that I had ","~","10 Windows Services and 3 Web applications that needed to call into my WCF Service. I didn't want to have to separately tweak 15 or so configs each time I wanted to make one standard change to WCF configuration settings. I wanted everything in one place."),(0,a.kt)("p",null,"Now there's newer (and probably hipper) ways of achieving this. ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/2814286"}),"Here's one possibility I happened upon on StackOverflow that looks perfectly fine.")),(0,a.kt)("p",null,"Well I didn't use a hip new approach - no I went Old School with my old friend the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/ms228154.aspx"}),"appSettings file attribute"),". Remember that? It's just a simple way to have all your common appSettings configuration settings in a single file which can be linked to from as many other apps as you like. It's wonderful and I've been using it for a long time now. Unfortunately it's pretty basic in that it's only the appSettings section that can be shared out; no ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;system.serviceModel&gt;")," or similar."),(0,a.kt)("p",null,"But that wasn't really a problem from my perspective. I realised that there were actually very few things that needed to be configurable for my WCF service. Really I wanted a basic WCF harness that could be initialised in code which implicitly set all the basic configuration with settings that worked (ie it was set up with defaults like maximum message size which were sufficiently sized). On top of that I would allow myself to configure just those things that I needed to through the use of my own custom WCF config settings in the shared appSettings.config file."),(0,a.kt)("p",null,"Once done I massively reduced the size of my configs from frankly gazillions of entries to just these appSettings.config entries which were shared across each of my WCF service clients and by my Windows Service harness:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<appSettings>\n  <add key="WcfBaseAddressForClient" value="net.tcp://localhost:9700/"/>\n  <add key="WcfWindowsSecurityApplied" value="true" />\n  <add key="WcfCredentialsUserName" value="myUserName" />\n  <add key="WcfCredentialsPassword" value="myPassword" />\n  <add key="WcfCredentialsDomain" value="myDomain" />\n  </appSettings>\n')),(0,a.kt)("p",null,"And these config settings used only by my Windows Service harness:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<appSettings file="../Shared/AppSettings.config">\n    <add key="WcfBaseAddressForService" value="net.tcp://localhost:9700/"/>\n  </appSettings>\n')),(0,a.kt)("h2",o({},{id:"show-me-your-harness"}),"Show me your harness"),(0,a.kt)("p",null,'I ended up with a quite a nice basic "vanilla" framework that allowed me to quickly set up Windows Service hosted WCF services. The framework also provided me with a simple way to consume these WCF services with a minimum of code an configuration. No muss. No fuss. :-) So pleased with it was I that I thought I\'d go through it here much in the manner of a chef baking a cake...'),(0,a.kt)("p",null,'To start with I created myself a Windows Service in Visual Studio which I grandly called "WcfWindowsService". The main service class looked like this:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public class WcfWindowsService: ServiceBase\n  {\n    public static string WindowsServiceName = "WCF Windows Service";\n    public static string WindowsServiceDescription = "Windows service that hosts a WCF service.";\n\n    private static readonly log4net.ILog _logger = log4net.LogManager.GetLogger(System.Reflection.MethodBase.GetCurrentMethod().DeclaringType);\n\n    public List<ServiceHost> _serviceHosts = null;\n\n    public WcfWindowsService()\n    {\n      ServiceName = WindowsServiceName;\n    }\n\n    public static void Main()\n    {\n      ServiceBase.Run(new WcfWindowsService());\n    }\n\n    /// <summary>\n    /// The Windows Service is starting\n    /// </summary>\n    /// <param name="args"></param>\n    protected override void OnStart(string[] args)\n    {\n      try\n      {\n        CloseAndClearServiceHosts();\n\n        //Make log4net startup\n        XmlConfigurator.Configure();\n        _logger.Warn("WCF Windows Service starting...");\n        _logger.Info("Global.WcfWindowsSecurityApplied = " + Global.WcfWindowsSecurityApplied.ToString().ToLower());\n\n        if (Global.WcfWindowsSecurityApplied)\n        {\n          _logger.Info("Global.WcfOnlyAuthorizedForWcfCredentials = " + Global.WcfOnlyAuthorizedForWcfCredentials.ToString().ToLower());\n\n          if (Global.WcfOnlyAuthorizedForWcfCredentials)\n          {\n            _logger.Info("Global.WcfCredentialsDomain = " + Global.WcfCredentialsDomain);\n            _logger.Info("Global.WcfCredentialsUserName = " + Global.WcfCredentialsUserName);\n          }\n        }\n\n        //Create binding\n        var wcfBinding = WcfHelper.CreateBinding(Global.WcfWindowsSecurityApplied);\n\n        // Create a servicehost and endpoints for each service and open each\n        _serviceHosts = new List<ServiceHost>();\n        _serviceHosts.Add(WcfServiceFactory<IHello>.CreateAndOpenServiceHost(typeof(HelloService), wcfBinding));\n        _serviceHosts.Add(WcfServiceFactory<IGoodbye>.CreateAndOpenServiceHost(typeof(GoodbyeService), wcfBinding));\n\n        _logger.Warn("WCF Windows Service started.");\n      }\n      catch (Exception exc)\n      {\n        _logger.Error("Problem starting up", exc);\n\n        throw exc;\n      }\n    }\n\n    /// <summary>\n    /// The Windows Service is stopping\n    /// </summary>\n    protected override void OnStop()\n    {\n      CloseAndClearServiceHosts();\n\n      _logger.Warn("WCF Windows Service stopped");\n    }\n\n    /// <summary>\n    /// Close and clear service hosts in list and clear it down\n    /// </summary>\n    private void CloseAndClearServiceHosts()\n    {\n      if (_serviceHosts != null)\n      {\n        foreach (var serviceHost in _serviceHosts)\n        {\n          CloseAndClearServiceHost(serviceHost);\n        }\n\n        _serviceHosts.Clear();\n      }\n    }\n\n    /// <summary>\n    /// Close and clear the passed service host\n    /// </summary>\n    /// <param name="serviceHost"></param>\n    private void CloseAndClearServiceHost(ServiceHost serviceHost)\n    {\n      if (serviceHost != null)\n      {\n        _logger.Info(string.Join(", ", serviceHost.BaseAddresses) + " is closing...");\n\n        serviceHost.Close();\n\n        _logger.Info(string.Join(", ", serviceHost.BaseAddresses) + " is closed");\n      }\n    }\n  }\n')),(0,a.kt)("p",null,"As you've no doubt noticed this makes use of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://logging.apache.org/log4net/"}),"Log4Net")," for logging purposes (I'll assume you're aware of it). My Windows Service implements such fantastic WCF services as HelloService and GoodbyeService. Each revolutionary in their own little way. To give you a taste of the joie de vivre that these services exemplify take a look at this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'// Implement the IHello service contract in a service class.\n  public class HelloService : WcfServiceAuthorizationManager, IHello\n  {\n    // Implement the IHello methods.\n    public string GreetMe(string thePersonToGreet)\n    {\n      return "well hello there " + thePersonToGreet;\n    }\n  }\n')),(0,a.kt)("p",null,'Exciting! WcfWindowsService also references another class called "Global" which is a helper class - to be honest not much more than a wrapper for my config settings. It looks like this:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'static public class Global\n  {\n    #region Properties\n\n    // eg "net.tcp://localhost:9700/"\n    public static string WcfBaseAddressForService { get { return ConfigurationManager.AppSettings["WcfBaseAddressForService"]; } }\n\n    // eg true\n    public static bool WcfWindowsSecurityApplied { get { return bool.Parse(ConfigurationManager.AppSettings["WcfWindowsSecurityApplied"]); } }\n\n    // eg true\n    public static bool WcfOnlyAuthorizedForWcfCredentials { get { return bool.Parse(ConfigurationManager.AppSettings["WcfOnlyAuthorizedForWcfCredentials"]); } }\n\n    // eg "myDomain"\n    public static string WcfCredentialsDomain { get { return ConfigurationManager.AppSettings["WcfCredentialsDomain"]; } }\n\n    // eg "myUserName"\n    public static string WcfCredentialsUserName { get { return ConfigurationManager.AppSettings["WcfCredentialsUserName"]; } }\n\n    // eg "myPassword" - this should *never* be stored unencrypted and is only ever used by clients that are not already running with the approved Windows credentials\n    public static string WcfCredentialsPassword { get { return ConfigurationManager.AppSettings["WcfCredentialsPassword"]; } }\n\n    #endregion\n  }\n')),(0,a.kt)("p",null,"WcfWindowsService creates and hosts a HelloService and a GoodbyeService when it starts up. It does this using my handy WcfServiceFactory:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public class WcfServiceFactory<TInterface>\n  {\n    private static readonly log4net.ILog _logger = log4net.LogManager.GetLogger(System.Reflection.MethodBase.GetCurrentMethod().DeclaringType);\n\n    public static ServiceHost CreateAndOpenServiceHost(Type serviceType, NetTcpBinding wcfBinding)\n    {\n      var serviceHost = new ServiceHost(serviceType, new Uri(Global.WcfBaseAddressForService + ServiceHelper<TInterface>.GetServiceName()));\n      serviceHost.AddServiceEndpoint(typeof(TInterface), wcfBinding, "");\n      serviceHost.Authorization.ServiceAuthorizationManager = new WcfServiceAuthorizationManager(); // This allows us to control authorisation within WcfServiceAuthorizationManager\n      serviceHost.Open();\n\n      _logger.Info(string.Join(", ", serviceHost.BaseAddresses) + " is now listening.");\n\n      return serviceHost;\n    }\n  }\n')),(0,a.kt)("p",null,"To do this it also uses my equally handy WcfHelper class:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'static public class WcfHelper\n  {\n    /// <summary>\n    /// Create a NetTcpBinding\n    /// </summary>\n    /// <param name="useWindowsSecurity"></param>\n    /// <returns></returns>\n    public static NetTcpBinding CreateBinding(bool useWindowsSecurity)\n    {\n      var wcfBinding = new NetTcpBinding();\n      if (useWindowsSecurity)\n      {\n        wcfBinding.Security.Mode = SecurityMode.Transport;\n        wcfBinding.Security.Transport.ClientCredentialType = TcpClientCredentialType.Windows;\n      }\n      else\n        wcfBinding.Security.Mode = SecurityMode.None;\n\n      wcfBinding.MaxBufferSize = int.MaxValue;\n      wcfBinding.MaxReceivedMessageSize = int.MaxValue;\n      wcfBinding.ReaderQuotas.MaxArrayLength = int.MaxValue;\n      wcfBinding.ReaderQuotas.MaxDepth = int.MaxValue;\n      wcfBinding.ReaderQuotas.MaxStringContentLength = int.MaxValue;\n      wcfBinding.ReaderQuotas.MaxBytesPerRead = int.MaxValue;\n\n      return wcfBinding;\n    }\n  }\n\n  /// <summary>\n  /// Create a WCF Client for use anywhere (be it Windows Service or ASP.Net web application)\n  /// nb Credential fields are optional and only likely to be needed by web applications\n  /// </summary>\n  /// <typeparam name="TInterface"></typeparam>\n  public class WcfClientFactory<TInterface>\n  {\n    public static TInterface CreateChannel(bool useWindowsSecurity, string wcfBaseAddress, string wcfCredentialsUserName = null, string wcfCredentialsPassword = null, string wcfCredentialsDomain = null)\n    {\n      //Create NetTcpBinding using universally\n      var wcfBinding = WcfHelper.CreateBinding(useWindowsSecurity);\n\n      //Get Service name from examining the ServiceNameAttribute decorating the interface\n      var serviceName = ServiceHelper<TInterface>.GetServiceName();\n\n      //Create the factory for creating your channel\n      var factory = new ChannelFactory<TInterface>(\n        wcfBinding,\n        new EndpointAddress(wcfBaseAddress + serviceName)\n        );\n\n      //if credentials have been supplied then use them\n      if (!string.IsNullOrEmpty(wcfCredentialsUserName))\n      {\n        factory.Credentials.Windows.ClientCredential = new System.Net.NetworkCredential(wcfCredentialsUserName, wcfCredentialsPassword, wcfCredentialsDomain);\n      }\n\n      //Create the channel\n      var channel = factory.CreateChannel();\n\n      return channel;\n    }\n  }\n')),(0,a.kt)("p",null,"Now the above WcfHelper class and it's comrade-in-arms the WcfClientFactory don't live in the WcfWindowsService project with the other classes. No. They live in a separate project called the WcfWindowsServiceContracts project with their old mucker the ServiceHelper:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public class ServiceHelper<T>\n  {\n    public static string GetServiceName()\n    {\n      var customAttributes = typeof(T).GetCustomAttributes(false);\n      if (customAttributes.Length > 0)\n      {\n        foreach (var customAttribute in customAttributes)\n        {\n          if (customAttribute is ServiceNameAttribute)\n          {\n            return ((ServiceNameAttribute)customAttribute).ServiceName;\n          }\n        }\n      }\n\n      throw new ArgumentException("Interface is missing ServiceNameAttribute");\n    }\n  }\n\n  [AttributeUsage(AttributeTargets.Interface, AllowMultiple = false)]\n  public class ServiceNameAttribute : System.Attribute\n  {\n    public ServiceNameAttribute(string serviceName)\n    {\n      this.ServiceName = serviceName;\n    }\n\n    public string ServiceName { get; set; }\n  }\n')),(0,a.kt)("p",null,"Now can you guess what the WcfWindowsServiceContracts project might contain? Yes; contracts for your services (oh the excitement)! What might one of these contracts look like I hear you ask... Well, like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[ServiceContract()]\n  [ServiceName("HelloService")]\n  public interface IHello\n  {\n    [OperationContract]\n    string GreetMe(string thePersonToGreet);\n  }\n')),(0,a.kt)("p",null,"The WcfWindowsServiceContracts project is included in ","*",(0,a.kt)("strong",{parentName:"p"},"any"),"*"," WCF client solution that wants to call your WCF services. It is also included in the WCF service solution. It facilitates the calling of services. What you're no doubt wondering is how this might be achieved. Well here's how, it uses our old friend the ",(0,a.kt)("inlineCode",{parentName:"p"},"WcfClientFactory"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'var helloClient = WcfClientFactory<IHello>\n    .CreateChannel(\n      useWindowsSecurity:     Global.WcfWindowsSecurityApplied,  // eg true\n      wcfBaseAddress:         Global.WcfBaseAddressForClient,    // eg "net.tcp://localhost:9700/"\n      wcfCredentialsUserName: Global.WcfCredentialsUserName,     // eg "myUserName" - Optional parameter - only passed by web applications that need to impersonate the valid user\n      wcfCredentialsPassword: Global.WcfCredentialsPassword,     // eg "myPassword" - Optional parameter - only passed by web applications that need to impersonate the valid user\n      wcfCredentialsDomain:   Global.WcfCredentialsDomain        // eg "myDomain" - Optional parameter - only passed by web applications that need to impersonate the valid user\n    );\n  var greeting = helloClient.GreetMe("John"); //"well hello there John"\n')),(0,a.kt)("p",null,'See? Simple as simple. The eagle eyed amongst you will have noticed that client example above is using "',(0,a.kt)("inlineCode",{parentName:"p"},"Global"),'" which is essentially a copy of the ',(0,a.kt)("inlineCode",{parentName:"p"},"Global")," class mentioned above that is part of the WcfWindowsService project."),(0,a.kt)("h2",o({},{id:"locking-down-authorization-to-a-single-windows-account"}),"Locking down Authorization to a single Windows account"),(0,a.kt)("p",null,"I can tell you think i've forgotten something. \"Tell me about this locking down to the single Windows account / what is this mysterious ",(0,a.kt)("inlineCode",{parentName:"p"},"WcfServiceAuthorizationManager")," class that all your WCF services inherit from? Don't you fob me off now.... etc\""),(0,a.kt)("p",null,"Well ensuring that only a single Windows account is authorised (yes dammit the original English spelling) to access our WCF services is achieved by implementing our own ",(0,a.kt)("inlineCode",{parentName:"p"},"ServiceAuthorizationManager")," class. This implementation is used for authorisation by your ",(0,a.kt)("inlineCode",{parentName:"p"},"ServiceHost")," and the logic sits in the overridden ",(0,a.kt)("inlineCode",{parentName:"p"},"CheckAccessCore")," method. All of our WCF service classes will inherit from our ",(0,a.kt)("inlineCode",{parentName:"p"},"ServiceAuthorizationManager")," class and so trigger the ",(0,a.kt)("inlineCode",{parentName:"p"},"CheckAccessCore")," authorisation each time they are called."),(0,a.kt)("p",null,"As you can see from the code below, depending on our configuration, we lock down access to all our WCF services to a specific Windows account. This is far from the only approach that you might want to take to authorisation; it's simply the one that we've been using. However the power of being able to implement your own authorisation in the ",(0,a.kt)("inlineCode",{parentName:"p"},"CheckAccessCore")," method allows you the flexibility to do pretty much anything you want:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public class WcfServiceAuthorizationManager : ServiceAuthorizationManager\n  {\n    protected static readonly log4net.ILog _logger = log4net.LogManager.GetLogger(System.Reflection.MethodBase.GetCurrentMethod().DeclaringType);\n\n    protected override bool CheckAccessCore(OperationContext operationContext)\n    {\n      if (Global.WcfWindowsSecurityApplied)\n      {\n        if ((operationContext.ServiceSecurityContext.IsAnonymous) ||\n          (operationContext.ServiceSecurityContext.PrimaryIdentity == null))\n        {\n          _logger.Error("WcfWindowsSecurityApplied = true but no credentials have been supplied");\n          return false;\n        }\n\n        if (Global.WcfOnlyAuthorizedForWcfCredentials)\n        {\n          if (operationContext.ServiceSecurityContext.PrimaryIdentity.Name.ToLower() == Global.WcfCredentialsDomain.ToLower() + "\\\\" + Global.WcfCredentialsUserName.ToLower())\n          {\n            _logger.Debug("WcfOnlyAuthorizedForWcfCredentials = true and the valid user (" + operationContext.ServiceSecurityContext.PrimaryIdentity.Name + ") has been supplied and access allowed");\n            return true;\n          }\n          else\n          {\n            _logger.Error("WcfOnlyAuthorizedForWcfCredentials = true and an invalid user (" + operationContext.ServiceSecurityContext.PrimaryIdentity.Name + ") has been supplied and access denied");\n            return false;\n          }\n        }\n        else\n        {\n          _logger.Debug("WcfOnlyAuthorizedForWcfCredentials = false, credentials were supplied (" + operationContext.ServiceSecurityContext.PrimaryIdentity.Name + ") so access allowed");\n          return true;\n        }\n      }\n      else\n      {\n        _logger.Info("WcfWindowsSecurityApplied = false so we are allowing unfettered access");\n        return true;\n      }\n    }\n  }\n')),(0,a.kt)("p",null,"Phewwww... I know this has ended up as a bit of a brain dump but hopefully people will find it useful. At some point I'll try to put up the above solution on GitHub so people can grab it easily for themselves."))}d.isMDXComponent=!0},4631:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"making-pdfs-from-html-in-c-using",title:"Making PDFs from HTML in C# using WKHTMLtoPDF",authors:"johnnyreilly",tags:["wkhtmltopdf","c#","pdf"],hide_table_of_contents:!1},s=void 0,l={permalink:"/making-pdfs-from-html-in-c-using",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-04-05-making-pdfs-from-html-in-c-using/index.md",source:"@site/blog/2012-04-05-making-pdfs-from-html-in-c-using/index.md",title:"Making PDFs from HTML in C# using WKHTMLtoPDF",description:"Updated 03/01/2013",date:"2012-04-05T00:00:00.000Z",formattedDate:"April 5, 2012",tags:[{label:"wkhtmltopdf",permalink:"/tags/wkhtmltopdf"},{label:"c#",permalink:"/tags/c"},{label:"pdf",permalink:"/tags/pdf"}],readingTime:8.735,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"making-pdfs-from-html-in-c-using",title:"Making PDFs from HTML in C# using WKHTMLtoPDF",authors:"johnnyreilly",tags:["wkhtmltopdf","c#","pdf"],hide_table_of_contents:!1},prevItem:{title:"A Simple Technique for Initialising Properties with Internal Setters for Unit Testing",permalink:"/simple-technique-for-initialising"},nextItem:{title:"WCF - moving from Config to Code, a simple WCF service harness (plus implementing your own Authorization)",permalink:"/wcf-moving-from-config-to-code-simple"}},p={authorsImageUrls:[void 0]},u=[{value:"Updated 03/01/2013",id:"updated-03012013",level:2},{value:"Making PDFs from HTML",id:"making-pdfs-from-html",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"updated-03012013"}),"Updated 03/01/2013"),(0,a.kt)("p",null,"I've written a subsequent post which builds on the work of this original post. The new post exposes this functionality via a WCF service and can be found ",(0,a.kt)("a",o({parentName:"p"},{href:"/html-to-pdf-using-wcf-service"}),"here"),"."),(0,a.kt)("h2",o({},{id:"making-pdfs-from-html"}),"Making PDFs from HTML"),(0,a.kt)("p",null,"I wanted to talk about an approach I've discovered for making PDFs directly from HTML. I realise that in these wild and crazy days of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://mozilla.github.com/pdf.js/"}),"PDF.js"),' and the like that techniques like this must seem very old hat. That said, this technique works and more importantly it solves a problem I was faced with but without forcing the users to move the "newest hottest version of X". Much as many of would love to solve problems this way, alas many corporations move slower than that and in the meantime we still have to deliver - we still have to meet requirements. Rather than just say "I did this" I thought I\'d record how I got to this point in the first place. I don\'t know about you but I find the reasoning behind why different technical decisions get made quite an interesting topic...'),(0,a.kt)("p",null,'For some time I\'ve been developing / supporting an application which is used in an intranet environment where the company mandated browser is still IE 6. It was a requirement that there be "print" functionality in this application. As is well known (even by Microsoft themselves) the print functionality in IE 6 was never fantastic. But the requirement for usable printouts remained.'),(0,a.kt)("p",null,'The developers working on the system before me decided to leverage Crystal Reports (remember that?). Essentially there was a reporting component to the application at the time which created custom reports using Crystal and rendered them to the user in the form of PDFs (which have been eminently printable for as long as I care to remember). One of the developers working on the system realised that it would be perfectly possible to create some "reports" within Crystal which were really "print to PDF" screens for the app.'),(0,a.kt)("p",null,"It worked well and this solution stayed in place for a very long time. However, some years down the line the Crystal Reports was discarded as the reporting mechanism for the app. But we were unable to decommission Crystal entirely because we still needed it for printing."),(0,a.kt)("p",null,"I'd never really liked the Crystal solution for a number of reasons:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"We needed custom stored procs to drive the Crystal print screens which were near duplicates of the main app procs. This duplication of effort never felt right."),(0,a.kt)("li",{parentName:"ol"},"We had to switch IDEs whenever we were maintaining our print screens. And the Crystal IDE is not a joy to use."),(0,a.kt)("li",{parentName:"ol"},"Perhaps most importantly, for certain users we needed to hide bits of information from the print. The version of Crystal we were using did not make the dynamic customisation of our print screens a straightforward proposition. (In its defence we weren't really using it for what it was designed for.) As a result the developers before me had ended up creating various versions of each print screen revealing different levels of information. As you can imagine, this meant that the effort involved in making changes to the print screens had increased exponentially")),(0,a.kt)("p",null,"It occurred to me that it would be good if we could find some way of generating our own PDF reports without using Crystal that would be a step forward. It was shortly after this that I happened upon ",(0,a.kt)("a",o({parentName:"p"},{href:"http://code.google.com/p/wkhtmltopdf/"}),"WKHTMLtoPDF"),". This is an open source project which describes itself as a ",(0,a.kt)("em",{parentName:"p"},'"Simple shell utility to convert html to pdf using the webkit rendering engine, and qt."')," I tested it out on various websites and it worked. It wasn't by any stretch of the imagination a perfect HTML to PDF tool but the quality it produced greatly outstripped the presentation currently in place via Crystal."),(0,a.kt)("p",null,"This was just the ticket. Using WKHTMLtoPDF I could have simple web pages in the application which could be piped into WKHTMLtoPDF to make a PDF as needed. It could be dynamic - because ASP.NET is dynamic. We wouldn't need to write and maintain custom stored procs anymore. And happily we would no longer need to use Crystal."),(0,a.kt)("p",null,"Before we could rid ourselves of Crystal though, I needed a way that I could generate these PDFs on the fly within the website. For this I ended up writing a simple wrapper class for WKHTMLtoPDF which could be used to invoke it on the fly. In fact a good portion of this was derived from various contributions on ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/q/1331926"}),"a post on StackOverflow"),". It ended up looking like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Security;\nusing System.Web;\nusing System.Web.Hosting;\n\nnamespace PdfGenerator\n{\n    public class PdfGenerator\n    {\n        /// <summary>\n        /// Convert Html page at a given URL to a PDF file using open-source tool wkhtml2pdf\n        ///   wkhtml2pdf can be found at: http://code.google.com/p/wkhtmltopdf/\n        ///   Useful code used in the creation of this I love the good folk of StackOverflow!: http://stackoverflow.com/questions/1331926/calling-wkhtmltopdf-to-generate-pdf-from-html/1698839\n        ///   An online manual can be found here: http://madalgo.au.dk/~jakobt/wkhtmltoxdoc/wkhtmltopdf-0.9.9-doc.html\n        ///\n        /// Ensure that the output folder specified is writeable by the ASP.NET process of IIS running on your server\n        ///\n        /// This code requires that the Windows installer is installed on the relevant server / client.  This can either be found at:\n        ///   http://code.google.com/p/wkhtmltopdf/downloads/list - download wkhtmltopdf-0.9.9-installer.exe\n        /// </summary>\n        /// <param name="pdfOutputLocation"></param>\n        /// <param name="outputFilenamePrefix"></param>\n        /// <param name="urls"></param>\n        /// <param name="options"></param>\n        /// <param name="pdfHtmlToPdfExePath"></param>\n        /// <returns>the URL of the generated PDF</returns>\n        public static string HtmlToPdf(string pdfOutputLocation, string outputFilenamePrefix, string[] urls,\n            string[] options = null,\n            string pdfHtmlToPdfExePath = "C:\\\\Program Files (x86)\\\\wkhtmltopdf\\\\wkhtmltopdf.exe")\n        {\n            string urlsSeparatedBySpaces = string.Empty;\n            try\n            {\n                //Determine inputs\n                if ((urls == null) || (urls.Length == 0))\n                    throw new Exception("No input URLs provided for HtmlToPdf");\n                else\n                    urlsSeparatedBySpaces = String.Join(" ", urls); //Concatenate URLs\n\n                string outputFolder = pdfOutputLocation;\n                string outputFilename = outputFilenamePrefix + "_" + DateTime.Now.ToString("yyyy-MM-dd-hh-mm-ss-fff") + ".PDF"; // assemble destination PDF file name\n\n                var p = new System.Diagnostics.Process()\n                {\n                    StartInfo =\n                    {\n                        FileName = pdfHtmlToPdfExePath,\n                        Arguments = ((options == null) ? "" : String.Join(" ", options)) + " " + urlsSeparatedBySpaces + " " + outputFilename,\n                        UseShellExecute = false, // needs to be false in order to redirect output\n                        RedirectStandardOutput = true,\n                        RedirectStandardError = true,\n                        RedirectStandardInput = true, // redirect all 3, as it should be all 3 or none\n                        WorkingDirectory = HttpContext.Current.Server.MapPath(outputFolder)\n                    }\n                };\n\n                p.Start();\n\n                // read the output here...\n                var output = p.StandardOutput.ReadToEnd();\n                var errorOutput = p.StandardError.ReadToEnd();\n\n                // ...then wait n milliseconds for exit (as after exit, it can\'t read the output)\n                p.WaitForExit(60000);\n\n                // read the exit code, close process\n                int returnCode = p.ExitCode;\n                p.Close();\n\n                // if 0 or 2, it worked so return path of pdf\n                if ((returnCode == 0) || (returnCode == 2))\n                    return outputFolder + outputFilename;\n                else\n                    throw new Exception(errorOutput);\n            }\n            catch (Exception exc)\n            {\n                throw new Exception("Problem generating PDF from HTML, URLs: " + urlsSeparatedBySpaces + ", outputFilename: " + outputFilenamePrefix, exc);\n            }\n        }\n    }\n}\n')),(0,a.kt)("p",null,"With this wrapper I could pass in URLs and extract out PDFs. Here's a couple of examples of me doing just that:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'//Create PDF from a single URL\n    var pdfUrl = PdfGenerator.HtmlToPdf(pdfOutputLocation: "~/PDFs/",\n        outputFilenamePrefix: "GeneratedPDF",\n        urls: new string[] { "http://news.bbc.co.uk" });\n\n    //Create PDF from multiple URLs\n    var pdfUrl = PdfGenerator.HtmlToPdf(pdfOutputLocation: "~/PDFs/",\n        outputFilenamePrefix: "GeneratedPDF",\n        urls: new string[] { "http://www.google.co.uk", "http://news.bbc.co.uk" });\n')),(0,a.kt)("p",null,"As you can see from the second example above it's possible to pipe a number of URLs into the wrapper all to be rendered to a single PDF. Most of the time this was surplus to our requirements but it's good to know it's possible. Take a look at the BBC website PDF generated by the first example:"),(0,a.kt)("iframe",{src:"https://docs.google.com/file/d/0B87K8-qxOZGFYktEWGtXRXJSSS1ZWFR4emFfMmVxZw/preview",width:"500",height:"500"}),(0,a.kt)("p",null,"Pretty good, no? As you can see it's not perfect from looking at the titles (bit squashed) but I deliberately picked a more complicated page to show what WKHTMLtoPDF was capable of. The print screens I had in mind to build would be significantly simpler than this."),(0,a.kt)("p",null,'Once this was in place I was able to scrap the Crystal solution. It was replaced with a couple of "print to PDF" ASPXs in the main web app which would be customised when rendering to hide the relevant bits of data from the user. These ASPXs would be piped into the HtmlToPdf method as needed and then the user would be redirected to that PDF. If for some reason the PDF failed to render the users would see the straight "print to PDF" ASPX - just not as a PDF if you see what I mean. I should say that it was pretty rare for a PDF to not render but this was my failsafe.'),(0,a.kt)("p",null,"This new solution had a number of upsides from our perspective:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Development maintenance time (and consequently cost for our customers) for print screens was significantly reduced. This was due to the print screens being part of the main web app. This meant they shared styling etc with all the other web screens and the dynamic nature of ASP.NET made customising a screen on the fly simplicity itself."),(0,a.kt)("li",{parentName:"ul"},"We were now able to regionalise our print screens for the users in the same way as we did with our main web app. This just wasn't realistic with the Crystal solution because of the amount of work involved."),(0,a.kt)("li",{parentName:"ul"},"I guess this is kind of a ",(0,a.kt)("a",o({parentName:"li"},{href:"http://en.wikipedia.org/wiki/Don%27t_repeat_yourself"}),"DRY")," solution :-)")),(0,a.kt)("p",null,"You can easily make use of the above approach yourself. All you need do is download and install ",(0,a.kt)("a",o({parentName:"p"},{href:"http://code.google.com/p/wkhtmltopdf/"}),"WKHTMLtoPDF")," on your machine. I advise using version 0.9.9 as the later release candidates appear slightly buggy at present."),(0,a.kt)("p",null,"Couple of gotchas:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Make sure that you pass the correct installation path to the HtmlToPdf method if you installed it anywhere other than the default location. You'll see that the class assumes the default if it wasn't passed"),(0,a.kt)("li",{parentName:"ol"},"Ensure that Read and Execute rights are granted to the wkhtmltopdf folder for the relevant process"),(0,a.kt)("li",{parentName:"ol"},"Ensure that Write rights are granted for the location you want to create your PDFs for the relevant process")),(0,a.kt)("p",null,"In our situation we are are invoking this directly in our web application on demand. I have no idea how this would scale - perhaps not well. This is not really an issue for us as our user base is fairly small and this functionality isn't called excessively. I think if this was used much more than it is I'd be tempted to hive off this functionality into a separate app. But this works just dandy for now."))}d.isMDXComponent=!0},97428:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"simple-technique-for-initialising",title:"A Simple Technique for Initialising Properties with Internal Setters for Unit Testing",authors:"johnnyreilly",tags:["unit testing","MOQ"],hide_table_of_contents:!1},s=void 0,l={permalink:"/simple-technique-for-initialising",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-04-16-simple-technique-for-initialising/index.md",source:"@site/blog/2012-04-16-simple-technique-for-initialising/index.md",title:"A Simple Technique for Initialising Properties with Internal Setters for Unit Testing",description:"I was recently working with my colleagues on refactoring a legacy application. We didn't have an immense amount of time available for this but the plan was to try and improve what was there as much as possible. In its initial state the application had no unit tests in place at all and so the plan was to refactor the code base in such a way as to make testing it a realistic proposition. To that end the domain layer was being heavily adjusted and the GUI was being migrated from WebForms to MVC 3. The intention was to build up a pretty solid collection of unit tests. However, as we were working on this we realised we had a problem with properties on our models with internal setters...",date:"2012-04-16T00:00:00.000Z",formattedDate:"April 16, 2012",tags:[{label:"unit testing",permalink:"/tags/unit-testing"},{label:"MOQ",permalink:"/tags/moq"}],readingTime:5.7,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"simple-technique-for-initialising",title:"A Simple Technique for Initialising Properties with Internal Setters for Unit Testing",authors:"johnnyreilly",tags:["unit testing","MOQ"],hide_table_of_contents:!1},prevItem:{title:"JSHint - Customising your hurt feelings",permalink:"/jshint-customising-your-hurt-feelings"},nextItem:{title:"Making PDFs from HTML in C# using WKHTMLtoPDF",permalink:"/making-pdfs-from-html-in-c-using"}},p={authorsImageUrls:[void 0]},u=[{value:"Background",id:"background",level:2},{value:"What&#39;s our problem?",id:"whats-our-problem",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I was recently working with my colleagues on refactoring a legacy application. We didn't have an immense amount of time available for this but the plan was to try and improve what was there as much as possible. In its initial state the application had no unit tests in place at all and so the plan was to refactor the code base in such a way as to make testing it a realistic proposition. To that end the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Domain_layer"}),"domain layer")," was being heavily adjusted and the GUI was being migrated from WebForms to MVC 3. The intention was to build up a pretty solid collection of unit tests. However, as we were working on this we realised we had a problem with properties on our models with ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/7c5ka91b(v=vs.80).aspx"}),(0,a.kt)("inlineCode",{parentName:"a"},"internal"))," setters..."),(0,a.kt)("h2",o({},{id:"background"}),"Background"),(0,a.kt)("p",null,"The entities of the project in question used an approach which would store pertinent bits of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Database_normalization"}),"normalised")," data for read-only purposes in related entities. I've re-read that sentence and realise it's as clear as mud. Here is an example to clarify:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public class Person\n{\n  public int Id { get; set; }\n  public string FirstName { get; set; }\n  public string LastName { get; set; }\n  public string Address { get; set; }\n  public DateTime DateOfBirth { get; set; }\n  /* Other fascinating properties... */\n}\n\npublic class Order\n{\n  public int Id { get; set; }\n  public string ProductOrdered { get; set; }\n  public string OrderedById { get; set; }\n  public string OrderedByFirstName { get; internal set; }\n  public string OrderedByLastName { get; internal set; }\n}\n")),(0,a.kt)("p",null,"In the example above you have 2 types of entity: ",(0,a.kt)("inlineCode",{parentName:"p"},"Person")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"Order"),". The ",(0,a.kt)("inlineCode",{parentName:"p"},"Order")," entity makes use of the the ",(0,a.kt)("inlineCode",{parentName:"p"},"Id"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"FirstName")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"LastName")," properties of the ",(0,a.kt)("inlineCode",{parentName:"p"},"Person")," entity in the properties ",(0,a.kt)("inlineCode",{parentName:"p"},"OrderedById"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"OrderedByFirstName")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"OrderedByLastName"),". For persistence (ie saving to the database) purposes the only necessary ",(0,a.kt)("inlineCode",{parentName:"p"},"Person")," property is ",(0,a.kt)("inlineCode",{parentName:"p"},"OrderedById")," identity. ",(0,a.kt)("inlineCode",{parentName:"p"},"OrderedByFirstName")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"OrderedByLastName"),' are just "nice to haves" - essentially present to make implementing the GUI more straightforward.'),(0,a.kt)("p",null,"To express this behaviour / intention in the object model the setters for ",(0,a.kt)("inlineCode",{parentName:"p"},"OrderedByFirstName")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"OrderedByLastName")," are marked as ",(0,a.kt)("inlineCode",{parentName:"p"},"internal"),'. The implication of this is that properties like this can only be initialised within the current assembly - or any explicitly associated "friend" assemblies. In practice this meant that internally set properties were only populated when an object was read in from the database. It wasn\'t possible to set these properties in other assemblies which meant less code was written (',(0,a.kt)("u",null,"a good thing")),(0,a.kt)("p",null,") - after all, why set a property when you don't need to?"),(0,a.kt)("p",null,"Background explanation over. It may still be a little unclear but I hope you get the gist."),(0,a.kt)("h2",o({},{id:"whats-our-problem"}),"What's our problem?"),(0,a.kt)("p",null,"I was writing unit tests for the controllers in our main web application and was having problems with my arrangements. I was mocking the database calls in my controllers much in the manner that you might expect:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),'// Arrange\n  var orderDb = new Mock<IOrderDb>();\n  orderDb\n    .Setup(x => x.GetOrder(It.IsAny<int>()))\n    .Returns(new Order{\n      Id = 123,\n      ProductOrdered = "Packet of coffee",\n      OrderedById = 987456,\n      OrderedByFirstName = "John",\n      OrderedByLastName = "Reilly"\n    });\n}\n')),(0,a.kt)("p",null,"All looks fine doesn't it? It's not. Because ",(0,a.kt)("inlineCode",{parentName:"p"},"OrderedByFirstName")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"OrderedByLastName")," have internal setters we are ",(0,a.kt)("u",null,"unable")),(0,a.kt)("p",null,"to initialise them from within the context of our test project. So what to do?"),(0,a.kt)("p",null,"We toyed with 3 approaches and since each has merits I thought it worth going through each of them:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"To the MOQumentation Batman!: ",(0,a.kt)("a",o({parentName:"p"},{href:"http://code.google.com/p/moq/wiki/QuickStart"}),"http://code.google.com/p/moq/wiki/QuickStart"),"! Looking at the MOQ documentation it states the following:"),(0,a.kt)("p",{parentName:"li"},(0,a.kt)("em",{parentName:"p"},"Mocking internal types of another project: add the following assembly attributes (typically to the AssemblyInfo.cs) to the project containing the internal types:")),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'// This assembly is the default dynamic assembly generated Castle DynamicProxy,\n// used by Moq. Paste in a single line.\n[assembly:InternalsVisibleTo("DynamicProxyGenAssembly2,PublicKey=0024000004800000940000000602000000240000525341310004000001000100c547cac37abd99c8db225ef2f6c8a3602f3b3606cc9891605d02baa56104f4cfc0734aa39b93bf7852f7d9266654753cc297e7d2edfe0bac1cdcf9f717241550e0a7b191195b7667bb4f64bcb8e2121380fd1d9d46ad2d92d2d15605093924cceaf74c4861eff62abf69b9291ed0a340e113be11e6a7d3113e92484cf7045cc7")]\n[assembly: InternalsVisibleTo("The.NameSpace.Of.Your.Unit.Test")] //I\'d hope it was shorter than that...\n')),(0,a.kt)("p",{parentName:"li"},"This looked to be exactly what we needed and in most situations it would make sense to go with this. Unfortunately for us there was a gotcha. Certain core shared parts of our application platform were ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Global_Assembly_Cache"}),"GAC"),"'d. A requirement for GAC-ing an assembly is that it is ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/xc31ft41.aspx"}),"signed"),"."),(0,a.kt)("p",{parentName:"li"},"The upshot of this was that if we wanted to use the ",(0,a.kt)("inlineCode",{parentName:"p"},"InternalsVisibleTo")," approach then we would need to sign our web application test project. We weren't particularly averse to that and initially did so without much thought. It was then we remembered that every assembly referenced by a signed assembly must also be signed as well. We didn't really want to sign our main web application purely for testing purposes. We could and if there weren't viable alternatives we well might have. But it just seemed like the wrong reason to be taking that decision. Like using a sledgehammer to crack a nut.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"The next approach we took was using mock objects. Instead of using our objects straight we would mock them as below:"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'//Create mock and set internal properties\n      var orderMock = new Mock<Order>();\n      orderMock.SetupGet(x => x.OrderedByFirstName).Returns("John");\n      orderMock.SetupGet(x => x.OrderedByLastName).Returns("Reilly");\n\n      //Set up standard properties\n      orderMock.SetupAllProperties();\n      var orderStub = orderMock.Object;\n      orderStub.Id = 123;\n      orderStub.ProductOrdered = "Packet of coffee";\n      orderStub.OrderedById = 987456;\n')),(0,a.kt)("p",{parentName:"li"},"Now this approach worked fine but had a couple of snags:"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"As you can see it's pretty verbose and much less clear to read than it was previously.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"It required that we add the ",(0,a.kt)("inlineCode",{parentName:"p"},"virtual")," keyword to all our internally set properties like so:"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public class Order\n{\n  // ....\n  public virtual string OrderedByFirstName { get; internal set; }\n  public virtual string OrderedByLastName { get; internal set; }\n  // ...\n}\n"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Our standard constructor already initialised the value of our internally set properties. So adding ",(0,a.kt)("inlineCode",{parentName:"p"},"virtual")," to the internally set properties generated ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.jetbrains.com/resharper/"}),"ReSharper")," warnings aplenty about virtual properties being initialised in the constructor. Fair enough."))),(0,a.kt)("p",{parentName:"li"},"Because of the snags it still felt like we were in nutcracking territory...")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"... and this took us to the approach that we ended up adopting: a special mocking constructor for each class we wanted to test, for example:"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"/// <summary>\n/// Mocking constructor used to initialise internal properties\n/// </summary>\npublic Order(string orderedByFirstName = null, string orderedByLastName = null)\n: this()\n{\nOrderedByFirstName = orderedByFirstName;\nOrderedByLastName = orderedByLastName;\n}\n\n")),(0,a.kt)("p",{parentName:"li"},"Thanks to the ever lovely ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/dd264739.aspx"}),"Named and Optional Arguments")," feature of C# combined with ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/bb397680.aspx"}),"Object Initializers")," it meant it was possible to write quite expressive, succinct code using this approach; for example:"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'var order = new Order(\n        orderedByFirstName: "John",\n        orderedByLastName: "Reilly"\n      )\n      {\n        Id = 123,\n        ProductOrdered = "Packet of coffee",\n        OrderedById = 987456\n      };\n')),(0,a.kt)("p",{parentName:"li"},"Here we're calling the mocking constructor to set the internally set properties and subsequently initialising the other properties using the object initialiser mechanism."),(0,a.kt)("p",{parentName:"li"},"Implementing these custom constructors wasn't a massive piece of work and so we ended up settling on this technique for initialising internal properties."))))}d.isMDXComponent=!0},16558:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"jshint-customising-your-hurt-feelings",title:"JSHint - Customising your hurt feelings",authors:"johnnyreilly",tags:["JSLint","JSHint","ESLint"],hide_table_of_contents:!1},s=void 0,l={permalink:"/jshint-customising-your-hurt-feelings",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-04-23-jshint-customising-your-hurt-feelings/index.md",source:"@site/blog/2012-04-23-jshint-customising-your-hurt-feelings/index.md",title:"JSHint - Customising your hurt feelings",description:"As I've started making greater use of JavaScript to give a richer GUI experience the amount of JS in my ASP.NET apps has unsurprisingly ballooned. If I'm honest, I hadn't given much consideration to the code quality of my JavaScript in the past. However, if I was going to make increasing use of it (and given the way the web is going at the moment I'd say that's a given) I didn't think this was tenable position to maintain. A friend of mine works for Coverity which is a company that provides tools for analysing code quality. I understand, from conversations with him, that their tools provide static analysis for compiled languages such as C++ / C# / Java etc. I was looking for something similar for JavaScript. Like many, I have read and loved Douglas Crockford's \"JavaScript",date:"2012-04-23T00:00:00.000Z",formattedDate:"April 23, 2012",tags:[{label:"JSLint",permalink:"/tags/js-lint"},{label:"JSHint",permalink:"/tags/js-hint"},{label:"ESLint",permalink:"/tags/es-lint"}],readingTime:4.505,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"jshint-customising-your-hurt-feelings",title:"JSHint - Customising your hurt feelings",authors:"johnnyreilly",tags:["JSLint","JSHint","ESLint"],hide_table_of_contents:!1},prevItem:{title:"Beg, Steal or Borrow a Decent JavaScript DateTime Converter",permalink:"/beg-steal-or-borrow-decent-javascript"},nextItem:{title:"A Simple Technique for Initialising Properties with Internal Setters for Unit Testing",permalink:"/simple-technique-for-initialising"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"As I've started making greater use of JavaScript to give a richer GUI experience the amount of JS in my ASP.NET apps has unsurprisingly ballooned. If I'm honest, I hadn't given much consideration to the code quality of my JavaScript in the past. However, if I was going to make increasing use of it (and given the way the web is going at the moment I'd say that's a given) I didn't think this was tenable position to maintain. A friend of mine works for ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.coverity.com/"}),"Coverity")," which is a company that provides tools for analysing code quality. I understand, from conversations with him, that their tools provide static analysis for compiled languages such as C++ / C# / Java etc. I was looking for something similar for JavaScript. Like many, I have read and loved ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.amazon.com/JavaScript-Good-Parts-Douglas-Crockford/dp/0596517742"}),'Douglas Crockford\'s "JavaScript: The Good Parts"'),"; it is by some margin the most useful and interesting software related book I have read.So I was aware that Crockford had come up with his own JavaScript code quality tool called ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.jslint.com/"}),"JSLint"),". JSLint is quite striking when you first encounter it:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(21613).Z,width:"320",height:"192"})),(0,a.kt)("p",null,"It's the \"Warning! JSLint will hurt your feelings.\" that grabs you. And it's not wrong. I've copied and pasted code that I've written into JSLint and then gasped at the reams of errors JSLint would produce. I subsequently tried JSLint-ing various well known JS libraries (jQuery etc) and saw that JSLint considered they were thoroughly problematic as well. This made me feel slightly better. It was when I started examining some of the \"errors\" JSLint reported that I took exception. Yes, I took exception to exceptions! (I'm ","*",(0,a.kt)("strong",{parentName:"p"},"very"),"*"," pleased with that!) Here's a few of the errors generated by JSLint when inspecting ",(0,a.kt)("a",o({parentName:"p"},{href:"http://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.js"}),"jquery-1.7.2.js"),": - ",(0,a.kt)("inlineCode",{parentName:"p"},"Problem at line 16 character 10: Expected exactly one space between 'function' and '('.")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Problem at line 25 character 1: Expected 'var' at column 13, not column 1.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Problem at line 31 character 5: Unexpected dangling '_' in '_jQuery'."))),(0,a.kt)("p",null,"JSLint is, much like it's creator, quite opinionated. Which is no bad thing. Many of Crockfords opinions are clearly worth their salt. It's just I didn't want all of them enforced upon me. As you can see above most of these \"problems\" are essentially complaints about a different style rather than bugs or potential issues. Now there are options in JSLint that you can turn on and off which looked quite promising. But before I got to investigating them I heard about ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.jshint.com"}),"JSHint"),", brainchild of Anton Kovalyov and Paul Irish. In their own words: ",(0,a.kt)("em",{parentName:"p"},"JSHint is a fork of JSLint, the tool written and maintained by Douglas Crockford. The project originally started as an effort to make a more configurable version of JSLint\u2014one that doesn't enforce one particular coding style on its users\u2014but then transformed into a separate static analysis tool with its own goals and ideals.")," This sounded right up my alley! So I thought I'd repeat my jQuery test. Here's a sample of what JSHint threw back at me, with its default settings in place: - ",(0,a.kt)("inlineCode",{parentName:"p"},"Line 230: return num == null ? Expected '===' and instead saw '=='. ")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Line 352: if ( (options = arguments[ i ]) != null ) { Expected '!==' and instead saw '!='. ")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Line 354: for ( name in options ) { The body of a for in should be wrapped in an if statement to filter unwanted properties from the prototype. "))),(0,a.kt)("p",null,'These were much more the sort of "issues" I was interested in. Plus it seemed there was plenty of scope to tweak my options. Excellent. This was good. The icing on my cake would have been a plug-in for Visual Studio which would allow me to evaluate my JS files from within my IDE. Happily the world seems to be full of developers doing good turns for one another. I discovered an extension for VS called ',(0,a.kt)("a",o({parentName:"p"},{href:"http://jslint4vs2010.codeplex.com/"}),"JSLint for Visual Studio 2010"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(34535).Z,width:"320",height:"186"})),(0,a.kt)("p",null,"This was an extension that provided either JSLint ","*",(0,a.kt)("strong",{parentName:"p"},"or"),"*"," JSHint evaluation as you preferred from within Visual Studio. Fantastic! With this extension in play you could add JavaScript static code analysis to your compilation process and so learn of all the issues in your code at the same time, whether they lay in C# or JS or ","[insert language here]",'. You could control how JS problems were reported; as warnings, errors etc. You could straightforwardly exclude files from evaluation (essential if you\'re reliant on a number of 3rd party JS libraries which you are not responsible for maintaining). You could cater for predefined variables; allow for jQuery or DOJO. You could simply evaluate a single file in your solution by right clicking it and hitting the "JS Lint" option in the context menu. And it was simplicity itself to activate and deactivate the JSHint / JSLint extension as required. For a more exhaustive round up of the options available I advise taking a look here: ',(0,a.kt)("a",o({parentName:"p"},{href:"http://jslint4vs2010.codeplex.com/"}),"http://jslint4vs2010.codeplex.com"),". I would heartily recommend using JSHint if you're looking to improve your JS code quality. I'm grateful to Crockford for making JSHint possible by first writing JSLint. For my part though I think JSHint is the more pragmatic and useful tool and likely to be the one I stick with. For interest (and frankly sheer entertainment value at the crotchetiness of Crockford) it's definitely worth having a read up on how JSHint came to pass: - ",(0,a.kt)("a",o({parentName:"p"},{href:"http://anton.kovalyov.net/2011/02/20/why-i-forked-jslint-to-jshint/"}),"http://anton.kovalyov.net/2011/02/20/why-i-forked-jslint-to-jshint/")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://badassjs.com/post/3364925033/jshint-an-community-driven-fork-of-jslint"}),"http://badassjs.com/post/3364925033/jshint-an-community-driven-fork-of-jslint"))))}d.isMDXComponent=!0},85826:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"beg-steal-or-borrow-decent-javascript",title:"Beg, Steal or Borrow a Decent JavaScript DateTime Converter",authors:"johnnyreilly",tags:["javascript","Serialization",".NET"],hide_table_of_contents:!1},s=void 0,l={permalink:"/beg-steal-or-borrow-decent-javascript",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-04-28-beg-steal-or-borrow-decent-javascript/index.md",source:"@site/blog/2012-04-28-beg-steal-or-borrow-decent-javascript/index.md",title:"Beg, Steal or Borrow a Decent JavaScript DateTime Converter",description:"I've so named this blog post because it shamelessly borrows from the fine work of others 1. http 2. http://n8v.enteuxis.org/2010/12/parsing-iso-8601-dates-in-javascript/",date:"2012-04-28T00:00:00.000Z",formattedDate:"April 28, 2012",tags:[{label:"javascript",permalink:"/tags/javascript"},{label:"Serialization",permalink:"/tags/serialization"},{label:".NET",permalink:"/tags/net"}],readingTime:9.47,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"beg-steal-or-borrow-decent-javascript",title:"Beg, Steal or Borrow a Decent JavaScript DateTime Converter",authors:"johnnyreilly",tags:["javascript","Serialization",".NET"],hide_table_of_contents:!1},prevItem:{title:"Globalize.js - number and date localisation made easy",permalink:"/globalizejs-number-and-date"},nextItem:{title:"JSHint - Customising your hurt feelings",permalink:"/jshint-customising-your-hurt-feelings"}},p={authorsImageUrls:[void 0]},u=[{value:"DateTime, JSON, JavaScript Dates....",id:"datetime-json-javascript-dates",level:2},{value:"Getting your web services to use the ISO 8601 DateTime Converter",id:"getting-your-web-services-to-use-the-iso-8601-datetime-converter",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I've so named this blog post because it shamelessly borrows from the fine work of others: Sebastian Markb\xe5ge and Nathan Vonnahme. Sebastian wrote a blog post documenting a good solution to the ASP.NET JavaScriptSerializer DateTime problem at the tail end of last year. However, his solution didn't get me 100% of the way there when I tried to use it because of a need to support IE 8 which lead me to use Nathan Vonnahme's ISO 8601 JavaScript Date parser. I thought it was worth documenting this, hence this post, but just so I'm clear; the hard work here was done by Sebastian Markb\xe5ge and Nathan Vonnahme and not me. Consider me just a curator in this case. The original blog posts that I am drawing upon can be found here: 1. ",(0,a.kt)("a",o({parentName:"p"},{href:"http://blog.calyptus.eu/seb/2011/12/custom-datetime-json-serialization/"}),"http://blog.calyptus.eu/seb/2011/12/custom-datetime-json-serialization/")," and here: 2. ",(0,a.kt)("a",o({parentName:"p"},{href:"http://n8v.enteuxis.org/2010/12/parsing-iso-8601-dates-in-javascript/"}),"http://n8v.enteuxis.org/2010/12/parsing-iso-8601-dates-in-javascript/")),(0,a.kt)("h2",o({},{id:"datetime-json-javascript-dates"}),"DateTime, JSON, JavaScript Dates...."),(0,a.kt)("p",null,"Like many, I've long been frustrated with the quirky DateTime serialisation employed by the ",(0,a.kt)("inlineCode",{parentName:"p"},"System.Web.Script.Serialization.JavaScriptSerializer")," class. When serialising DateTimes so they can be JSON.parsed on the client, this serialiser uses the following approach: (from MSDN) ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/system.web.script.serialization.javascriptserializer.aspx"}),(0,a.kt)("em",{parentName:"a"},'Date object, represented in JSON as "\\/Date(number of ticks)\\/". The number of ticks is a positive or negative long value that indicates the number of ticks (milliseconds) that have elapsed since midnight 01 January, 1970 UTC."'))," Now this is not particularly helpful in my opinion because it's not human readable (at least not this human; perhaps ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/users/22656/jon-skeet"}),"Jon Skeet"),"...) When consuming your data from web services / PageMethods using ",(0,a.kt)("a",o({parentName:"p"},{href:"http://api.jquery.com/jQuery.ajax/"}),"jQuery.ajax")," you are landed with the extra task of having to convert what were DateTimes on the server from Microsofts string Date format (eg ",(0,a.kt)("inlineCode",{parentName:"p"},'"\\/Date(1293840000000)\\/"'),") into actual JavaScript Dates. It's also unhelpful because it's divergent from the approach to DateTime / Date serialisation used by a native JSON serialisers:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(76705).Z,width:"320",height:"144"})),(0,a.kt)("p",null,"Just as an aside it's worth emphasising that one of the limitations of JSON is that the JSON.parsing of a JSON.stringified date will ","*",(0,a.kt)("strong",{parentName:"p"},"not"),"*"," return you to a JavaScript Date but rather an ISO 8601 date string which will need to be subsequently converted into a Date. Not JSON's fault - essentially down to the absence of a Date literal within JavaScript. ## Making JavaScriptSerializer behave more JSON'y"),(0,a.kt)("p",null,"Anyway, I didn't think there was anything I could really do about this in an ASP.NET classic / WebForms world because, to my knowledge, it is not possible to swap out the serialiser that is used. JavaScriptSerializer is the only game in town. (Though I am optimistic about the future; given the announcement that I first picked up on Rick Strahl's blog that ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.west-wind.com/weblog/posts/2012/Mar/09/Using-an-alternate-JSON-Serializer-in-ASPNET-Web-API"}),"Json.NET was going to be adopted as the default JSON serializer for ASP.NET Web API"),"; what with Json.NET having out-of-the-box ",(0,a.kt)("a",o({parentName:"p"},{href:"http://james.newtonking.com/archive/2009/02/20/good-date-times-with-json-net.aspx"}),"ISO 8601 support"),". I digress...) Because it can make debugging a much more straightforward process I place a lot of value on being able to read the network traffic that web apps generate. It's much easier to drop into Fiddler / FireBug / Chrome dev tools etc and watch what's happening there and then instead of having to manually process the data separately first so that you can understand it. I think this is nicely aligned with the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/KISS_principle"}),"KISS principle"),". For that reason I've been generally converting DateTimes to ISO 8601 strings on the server before returning them to the client. A bit of extra overhead but generally worth it for the gains in clarity in my opinion. So I was surprised and delighted when I happened upon ",(0,a.kt)("a",o({parentName:"p"},{href:"http://blog.calyptus.eu/seb/2011/12/custom-datetime-json-serialization/"}),"Sebastian Markb\xe5ge's blog post")," which provided a DateTime JavaScriptConverter that could be plugged into the JavaScriptSerializer. You can see the code below (or on Sebastian's original post with a good explanation of how it works):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Collections;\nusing System.Collections.Generic;\nusing System.Web.Script.Serialization;\n\nnamespace MyNamespace\n{\n  /// <summary>\n  /// A custom DateTime JavaScriptConverter courtesy of these good folks: http://blog.calyptus.eu/seb/2011/12/custom-datetime-json-serialization/\n  /// Using this forces DataTimes to be serialised as ISO 8601 rather "\\/Date(1249335477787)\\/" style\n  /// </summary>\n  public class DateTimeJavaScriptConverter : JavaScriptConverter\n  {\n    public override object Deserialize(IDictionary<string, object> dictionary, Type type, JavaScriptSerializer serializer)\n    {\n      return new JavaScriptSerializer().ConvertToType(dictionary, type);\n    }\n\n    public override IDictionary<string, object> Serialize(object obj, JavaScriptSerializer serializer)\n    {\n      if (!(obj is DateTime)) return null;\n      return new CustomString(((DateTime)obj).ToUniversalTime().ToString("O"));\n    }\n\n    public override IEnumerable<Type> SupportedTypes\n    {\n      get { return new[] { typeof(DateTime) }; }\n    }\n\n    private class CustomString : Uri, IDictionary<string, object>\n    {\n      public CustomString(string str)\n        : base(str, UriKind.Relative)\n      {\n      }\n\n      void IDictionary<string, object>.Add(string key, object value) { throw new NotImplementedException(); }\n      bool IDictionary<string, object>.ContainsKey(string key) { throw new NotImplementedException(); }\n      ICollection<string> IDictionary<string, object>.Keys { get { throw new NotImplementedException(); } }\n      bool IDictionary<string, object>.Remove(string key) { throw new NotImplementedException(); }\n      bool IDictionary<string, object>.TryGetValue(string key, out object value) { throw new NotImplementedException(); }\n      ICollection<object> IDictionary<string, object>.Values { get { throw new NotImplementedException(); } }\n      object IDictionary<string, object>.this[string key]\n      {\n        get { throw new NotImplementedException(); }\n        set { throw new NotImplementedException(); }\n      }\n      void ICollection<KeyValuePair<string, object>>.Add(KeyValuePair<string, object> item) { throw new NotImplementedException(); }\n      void ICollection<KeyValuePair<string, object>>.Clear() { throw new NotImplementedException(); }\n      bool ICollection<KeyValuePair<string, object>>.Contains(KeyValuePair<string, object> item) { throw new NotImplementedException(); }\n      void ICollection<KeyValuePair<string, object>>.CopyTo(KeyValuePair<string, object>[] array, int arrayIndex) { throw new NotImplementedException(); }\n      int ICollection<KeyValuePair<string, object>>.Count { get { throw new NotImplementedException(); } }\n      bool ICollection<KeyValuePair<string, object>>.IsReadOnly { get { throw new NotImplementedException(); } }\n      bool ICollection<KeyValuePair<string, object>>.Remove(KeyValuePair<string, object> item) { throw new NotImplementedException(); }\n      IEnumerator<KeyValuePair<string, object>> IEnumerable<KeyValuePair<string, object>>.GetEnumerator() { throw new NotImplementedException(); }\n      IEnumerator IEnumerable.GetEnumerator() { throw new NotImplementedException(); }\n    }\n  }\n}\n')),(0,a.kt)("p",null,"Using this converter meant that a DateTime that previously would have been serialised as ",(0,a.kt)("inlineCode",{parentName:"p"},'"\\/Date(1293840000000)\\/"')," would now be serialised as ",(0,a.kt)("inlineCode",{parentName:"p"},'"2011-01-01T00:00:00.0000000Z"')," instead. This is entirely agreeable because 1. it's entirely clear what a ",(0,a.kt)("inlineCode",{parentName:"p"},'"2011-01-01T00:00:00.0000000Z"')," style date represents and 2. this is more in line with native browser JSON implementations and ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;statingTheObvious&gt;"),"consistency is a good thing.",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;/statingTheObvious&gt;")),(0,a.kt)("h2",o({},{id:"getting-your-web-services-to-use-the-iso-8601-datetime-converter"}),"Getting your web services to use the ISO 8601 DateTime Converter"),(0,a.kt)("p",null,"Sebastian alluded in his post to a ",(0,a.kt)("inlineCode",{parentName:"p"},"web.config")," setting that could be used to get web services / pagemethods etc. implementing his custom DateTime serialiser. This is it:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<configuration>\n  <system.web.extensions>\n    <scripting>\n      <webServices>\n        \x3c!--\n          This line of config means that when a JavaScriptSerializer is used by a web service / page method\n          it will automatically register the DateTimeJavaScriptConverter to use.  To use the converter directly in code you would need to enter the below:\n\n          var serializer = new System.Web.Script.Serialization.JavaScriptSerializer();\n          serializer.RegisterConverters(new JavaScriptConverter[] { new DateTimeJavaScriptConverter() });\n\n        --\x3e\n        <jsonSerialization>\n          <converters>\n            <add name="DateTimeJavaScriptConverter" type="MyNamespace.DateTimeJavaScriptConverter"/>\n          </converters>\n        </jsonSerialization>\n\n      </webServices>\n      <scriptResourceHandler enableCompression="false" enableCaching="true"/>\n    </scripting>\n  </system.web.extensions>\n</configuration>\n')),(0,a.kt)("p",null,"With this in place your web services / page methods will happily be able to serialise / deserialise ISO style date strings to your hearts content. ## What no ISO 8601 date string Date constructor?"),(0,a.kt)("p",null,"As I mentioned earlier, Sebastian's solution didn't get me 100% of the way there. There was still a fly in the ointment in the form of IE 8. Unfortunately IE 8 doesn't have JavaScript ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Date/parse"}),"Date constructor that takes ISO 8601 date strings"),". This lead me to using Nathan Vonnahme's ISO 8601 JavaScript Date parser, the code of which is below (or see his original post ",(0,a.kt)("a",o({parentName:"p"},{href:"http://n8v.enteuxis.org/2010/12/parsing-iso-8601-dates-in-javascript/"}),"here"),"):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),'//===============================================================================\n// Parse ISO 8601 Date Format date string and return a date - equivalent to https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Date/parse\n// Found here: n8v.enteuxis.org/2010/12/parsing-iso-8601-dates-in-javascript/\n//===============================================================================\nfunction parseISO8601Date(s) {\n  // parenthese matches:\n  // year month day    hours minutes seconds\n  // dotmilliseconds\n  // tzstring plusminus hours minutes\n  var re =\n    /(\\d{4})-(\\d\\d)-(\\d\\d)T(\\d\\d):(\\d\\d):(\\d\\d)(\\.\\d+)?(Z|([+-])(\\d\\d):(\\d\\d))/;\n\n  var d = [];\n  d = s.match(re);\n\n  // "2010-12-07T11:00:00.000-09:00" parses to:\n  //  ["2010-12-07T11:00:00.000-09:00", "2010", "12", "07", "11",\n  //     "00", "00", ".000", "-09:00", "-", "09", "00"]\n  // "2010-12-07T11:00:00.000Z" parses to:\n  //  ["2010-12-07T11:00:00.000Z",      "2010", "12", "07", "11",\n  //     "00", "00", ".000", "Z", undefined, undefined, undefined]\n\n  if (!d) {\n    throw "Couldn\'t parse ISO 8601 date string \'" + s + "\'";\n  }\n\n  // parse strings, leading zeros into proper ints\n  var a = [1, 2, 3, 4, 5, 6, 10, 11];\n  for (var i in a) {\n    d[a[i]] = parseInt(d[a[i]], 10);\n  }\n  d[7] = parseFloat(d[7]);\n\n  // Date.UTC(year, month[, date[, hrs[, min[, sec[, ms]]]]])\n  // note that month is 0-11, not 1-12\n  // see https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Date/UTC\n  var ms = Date.UTC(d[1], d[2] - 1, d[3], d[4], d[5], d[6]);\n\n  // if there are milliseconds, add them\n  if (d[7] > 0) {\n    ms += Math.round(d[7] * 1000);\n  }\n\n  // if there\'s a timezone, calculate it\n  if (d[8] != \'Z\' && d[10]) {\n    var offset = d[10] * 60 * 60 * 1000;\n    if (d[11]) {\n      offset += d[11] * 60 * 1000;\n    }\n    if (d[9] == \'-\') {\n      ms -= offset;\n    } else {\n      ms += offset;\n    }\n  }\n\n  return new Date(ms);\n}\n')),(0,a.kt)("p",null,"With this in place I could parse ISO 8601 Dates just like anyone else. Great stuff. ",(0,a.kt)("inlineCode",{parentName:"p"},'parseISO8601Date("2011-01-01T00:00:00.0000000Z")')," would give me a JavaScript Date of ",(0,a.kt)("inlineCode",{parentName:"p"},"Sat Jan 1 00:00:00 UTC 2011"),". Obviously in the fullness of time the parseISO8601Date solution should no longer be necessary because ",(0,a.kt)("a",o({parentName:"p"},{href:"http://es5.github.com/#x15.9.3.2"}),"EcmaScript 5 specifies an ISO 8601 date string constructor"),". However, in the interim Nathan's solution is a lifesaver. Thanks again both to Sebastian Markb\xe5ge and Nathan Vonnahme who have both generously allowed me use their work as the basis for this post. ## PS And it would have worked if it wasn't for that pesky IE 9..."),(0,a.kt)("p",null,"Subsequent to writing this post I thought I'd check that IE 9 had implemented a JavaScript Date constructor that would process an ISO 8601 date string like this: ",(0,a.kt)("inlineCode",{parentName:"p"},'new Date("2011-01-01T00:00:00.0000000Z")'),". It hasn't. Take a look:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(22170).Z,width:"320",height:"86"})),(0,a.kt)("p",null,"This is slightly galling as the above code works dandy in Firefox and Chrome. As you can see from the screenshot you can get the JavaScript IE 9 Date constructor to play nice by trimming off the final 4 \"0\"'s from the string. Frustrating. Obviously we can still use Nathan's solution but it's a shame that we can't use the native support. Based on what I've read ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/az4se3k1.aspx#Roundtrip"}),"here")," I think it would be possible to amend Sebastians serializer to fall in line with IE 9's pendantry by changing this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'return new CustomString(((DateTime)obj).ToUniversalTime()\n  .ToString(<b>"O"</b>)\n);\n')),(0,a.kt)("p",null,"To this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"return new CustomString(((DateTime)obj).ToUniversalTime()\n  .ToString(<b>\"yyyy'-'MM'-'dd'T'HH':'mm':'ss'.'fffzzz\"</b>)\n);\n")),(0,a.kt)("p",null,"I've held off from doing this myself as I rather like Sebastian's idea of being able to use Microsoft's Round-trip (\"O\", \"o\") Format Specifier. And it seems perverse that we should have to move away from using Microsoft's Round-trip Format Specifier purely because of (Microsoft's) IE! But it's a possibility to consider and so I put it out there. I would hope that MS will improve their JavaScript Date constructor with IE 10. A missed opportunity if they don't I think. ## PPS Just when you thought is over... IE 9 was right!"),(0,a.kt)("p",null,"Sebastian got in contact after I first published this post and generously pointed out that, contrary to my expectation, IE 9 technically had the correct implementation. According to the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://es5.github.com/#x15.9.1.15"}),"EMCAScript standard")," the Date constructor should not allow more than millisecond precision. In this case, Chrome and Firefox are being less strict - not more correct. On reflection this does rather make sense as the result of a ",(0,a.kt)("inlineCode",{parentName:"p"},"JSON.stringify(new Date())"),' never results in an ISO date string to the 10 millionths of a second detail. Sebastian has himself stopped using Microsoft\'s Round-trip ("O", "o") Format Specifier in favour of this format string: ```cs\nreturn new CustomString(((DateTime)obj).ToUniversalTime()'),(0,a.kt)("p",null,".ToString(",(0,a.kt)("b",null,'"yyyy-MM-ddTHH:mm:ss.fffZ"'),")"),(0,a.kt)("p",null,");"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"\n This results in date strings that comply perfectly with the ECMAScript spec. I suspect I'll switch to using this also now. Though I'll probably leave the first part of the post intact as I think the background remains interesting. Thanks again Sebastian!\n")))}d.isMDXComponent=!0},9219:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"globalizejs-number-and-date",title:"Globalize.js - number and date localisation made easy",authors:"johnnyreilly",tags:["javascript","ASP.NET AJAX","Globalization"],hide_table_of_contents:!1},s=void 0,l={permalink:"/globalizejs-number-and-date",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-05-07-globalizejs-number-and-date/index.md",source:"@site/blog/2012-05-07-globalizejs-number-and-date/index.md",title:"Globalize.js - number and date localisation made easy",description:"I wanted to write about a JavaScript library which seems to have had very little attention so far. And that surprises me as it's",date:"2012-05-07T00:00:00.000Z",formattedDate:"May 7, 2012",tags:[{label:"javascript",permalink:"/tags/javascript"},{label:"ASP.NET AJAX",permalink:"/tags/asp-net-ajax"},{label:"Globalization",permalink:"/tags/globalization"}],readingTime:7.52,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"globalizejs-number-and-date",title:"Globalize.js - number and date localisation made easy",authors:"johnnyreilly",tags:["javascript","ASP.NET AJAX","Globalization"],hide_table_of_contents:!1},prevItem:{title:"Dad Didn't Buy Any Games",permalink:"/dad-didnt-buy-any-games"},nextItem:{title:"Beg, Steal or Borrow a Decent JavaScript DateTime Converter",permalink:"/beg-steal-or-borrow-decent-javascript"}},p={authorsImageUrls:[void 0]},u=[{value:"Why does this matter?",id:"why-does-this-matter",level:2},{value:"Why does this matter to me?",id:"why-does-this-matter-to-me",level:2},{value:"JavaScript Date / Number Localisation - the Status Quo",id:"javascript-date--number-localisation---the-status-quo",level:2},{value:"Microsoft doing *good things*",id:"microsoft-doing-good-things",level:2},{value:"Microsoft doing *even better things* (Scott Gu to the rescue!)",id:"microsoft-doing-even-better-things-scott-gu-to-the-rescue",level:2},{value:"History takes a funny course...",id:"history-takes-a-funny-course",level:2},{value:"Stick a fork in it - it&#39;s done",id:"stick-a-fork-in-it---its-done",level:2},{value:"The Future?",id:"the-future",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I wanted to write about a JavaScript library which seems to have had very little attention so far. And that surprises me as it's"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Brilliant!"),(0,a.kt)("li",{parentName:"ol"},"Solves a common problem that faces many app developers who work in the wonderful world of web; myself included")),(0,a.kt)("p",null,"The library is called Globalize.js and can be found on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jquery/globalize"}),"GitHub here"),". Globalize.js is a simple JavaScript library that allows you to format and parse numbers and dates in culture specific fashion."),(0,a.kt)("h2",o({},{id:"why-does-this-matter"}),"Why does this matter?"),(0,a.kt)("p",null,"Because different countries and cultures do dates and numbers in different ways. Christmas Day this year in England will be ",(0,a.kt)("inlineCode",{parentName:"p"},"25/12/2012")," (dd/MM/yyyy). But for American eyes this should be ",(0,a.kt)("inlineCode",{parentName:"p"},"12/25/2012")," (M/d/yyyy). And for German ",(0,a.kt)("inlineCode",{parentName:"p"},"25.12.2012"),' (dd.MM.yyyy). Likewise, if I was to express numerically the value of "one thousand exactly - to 2 decimal places", as a UK citizen I would do it like so: ',(0,a.kt)("inlineCode",{parentName:"p"},"1,000.00"),". But if I was French I'd express it like this: ",(0,a.kt)("inlineCode",{parentName:"p"},"1.000,00"),". You see my point?"),(0,a.kt)("h2",o({},{id:"why-does-this-matter-to-me"}),"Why does this matter to me?"),(0,a.kt)("p",null,"For a number of years I've been working on applications that are used globally, from London to Frankfurt to Shanghai to New York to Singapore and many other locations besides. The requirement has always been to serve up localised dates and numbers so users experience of the system is more natural. Since our applications are all ASP.NET we've never really had a problem server-side. Microsoft have blessed us with all the goodness of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/system.globalization.aspx"}),"System.Globalization")," which covers hundreds of different cultures and localisations. It makes it frankly easy:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System.Globalization;\n\n//Produces: "06.05.2012"\nnew DateTime(2012,5,6).ToString("d", new CultureInfo("de-DE"));\n\n//Produces: "45,56"\n45.56M.ToString("n", new CultureInfo("fr-FR"));\n')),(0,a.kt)("p",null,"The problem has always been client-side. If you need to localise dates and numbers on the client what do you do?"),(0,a.kt)("h2",o({},{id:"javascript-date--number-localisation---the-status-quo"}),"JavaScript Date / Number Localisation - the Status Quo"),(0,a.kt)("p",null,"Well to be frank - it's a bit rubbish really. What's on offer natively at present basically amounts to this:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Date/toLocaleDateString"}),"Date.toLocaleDateString")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Number/ToLocaleString"}),"Number.ToLocaleString"))),(0,a.kt)("p",null,"This is better than nothing - but not by much. There's no real control or flexibility here. If you don't like the native localisation format or you want something slightly different then tough. This is all you've got to play with."),(0,a.kt)("p",null,"For the longest time this didn't matter too much. Up until relatively recently the world of web was far more about the thin client and the fat server. It would be quite standard to have all HTML generated on the server. And, as we've seen .NET (and many other back end enviroments as well) give you all the flexiblility you might desire given this approach."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"http://www.youtube.com/watch?v=k2sYIIjS-cQ"}),"But the times they are a-changing"),". And given the ongoing explosion of HTML 5 the rich client is very definitely with us. So we need tools."),(0,a.kt)("h2",o({},{id:"microsoft-doing-good-things"}),"Microsoft doing ","*","good things","*"),(0,a.kt)("p",null,"Hands up who remembers when Microsoft first shipped it's ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/magazine/cc163300.aspx"}),"ASP.NET AJAX")," library back in 2007?"),(0,a.kt)("p",null,"Well a small part of this was the extensions ASP.NET AJAX added to JavaScripts native Date and Number objects.... These extensions allowed the localisation of Dates and Numbers to the current UI culture and the subsequent string parsing of these back into Dates / Numbers. These extensions pretty much gave JavaScript the functionality that the server already had in ",(0,a.kt)("inlineCode",{parentName:"p"},"System.Globalization"),". (not quite like-for-like but near enough the mark)"),(0,a.kt)("p",null,"I'm not aware of a great fuss ever being made about this - a fact I find surprising since one would imagine this is a common need. There's good documentation about this on MSDN - here's some useful links:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://msdn.microsoft.com/en-us/library/bb386572.aspx"}),"Ajax Script Globalization and Localization")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://msdn.microsoft.com/en-us/library/bb386581.aspx"}),"Walkthrough: Globalizing a Date by Using Client Script")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://msdn.microsoft.com/en-us/library/bb397506.aspx"}),"JavaScript Base Type Extensions")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://msdn.microsoft.com/en-us/library/bb397521.aspx"}),"Date.parseLocale")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://msdn.microsoft.com/en-us/library/bb383816.aspx"}),"Date.localeFormat")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://msdn.microsoft.com/en-us/library/bb310813.aspx"}),"Number.localeFormat")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://msdn.microsoft.com/en-us/library/bb310985.aspx"}),"Number.parseLocale"))),(0,a.kt)("p",null,"When our team became aware of this we started to make use of it in our web applications. I imagine we weren't alone..."),(0,a.kt)("h2",o({},{id:"microsoft-doing-even-better-things-scott-gu-to-the-rescue"}),"Microsoft doing ","*","even better things","*"," (Scott Gu to the rescue!)"),(0,a.kt)("p",null,"I started to think about this again when MVC reared it's lovely head."),(0,a.kt)("p",null,"Like many, I found I preferred the separation of concerns / testability etc that MVC allowed. As such, our team was planning to, over time, migrate our ASP.NET WebForms applications over to MVC. However, before we could even begin to do this we had a problem. Our JavaScript localisation was dependant on the ScriptManager. The ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/system.web.ui.scriptmanager.aspx"}),"ScriptManager")," is very much a WebForms construct."),(0,a.kt)("p",null,"What to do? To the users it wouldn't be acceptable to remove the localisation functionality from the web apps. The architecture of an application is, to a certain extent, meaningless from the users perspective - they're only interested in what directly impacts them. That makes sense, even if it was a problem for us."),(0,a.kt)("p",null,"Fortunately the Great Gu had it in hand. Lo and behold the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://forum.jquery.com/topic/proposal-for-a-globalization-plugin-jquery-glob-js"}),"this post")," appeared on the jQuery forum and the following post appeared on Guthrie's blog:"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"http://weblogs.asp.net/scottgu/archive/2010/06/10/jquery-globalization-plugin-from-microsoft.aspx"}),"http://weblogs.asp.net/scottgu/archive/2010/06/10/jquery-globalization-plugin-from-microsoft.aspx")),(0,a.kt)("p",null,"Yes that's right. Microsoft were giving back to the jQuery community by contributing a jQuery globalisation plug-in. They'd basically taken the work done with ASP.NET AJAX Date / Number extensions, jQuery-plug-in-ified it and put it out there. Fantastic!"),(0,a.kt)("p",null,"Using this we could localise / globalise dates and numbers whether we were working in WebForms or in MVC. Or anything else for that matter. If we were suddenly seized with a desire to re-write our apps in PHP we'd ","*",(0,a.kt)("strong",{parentName:"p"},"still"),"*"," be able to use Globalize.js on the client to handle our regionalisation of dates and numbers."),(0,a.kt)("h2",o({},{id:"history-takes-a-funny-course"}),"History takes a funny course..."),(0,a.kt)("p",null,"Now for my part I would have expected that this announcement to be followed in short order by dancing in the streets and widespread adoption. Surprisingly, not so. All went quiet on the globalisation front for some time and then out of the blue the following comment appeared on the jQuery forum by ",(0,a.kt)("a",o({parentName:"p"},{href:"http://rdworth.org/blog/"}),"Richard D. Worth")," (he of jQuery UI fame):"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"http://blog.jquery.com/2011/04/16/official-plugins-a-change-in-the-roadmap/#comment-527484"}),"http://blog.jquery.com/2011/04/16/official-plugins-a-change-in-the-roadmap/#comment-527484")),(0,a.kt)("p",null,"The long and short of which was:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"The jQuery UI team were now taking care of (the re-named) Globalize.js library as the grid control they were developing had a need for some of Globalize.js's goodness. Consequently a home for Globalize.js appeared on the jQuery UI website: ",(0,a.kt)("a",o({parentName:"li"},{href:"http://wiki.jqueryui.com/Globalize"}),"http://wiki.jqueryui.com/Globalize")),(0,a.kt)("li",{parentName:"ul"},"The source of Globalize.js moved to this location on GitHub: ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/jquery/globalize/"}),"https://github.com/jquery/globalize/")),(0,a.kt)("li",{parentName:"ul"},"Perhaps most significantly, the jQuery globalisation plug-in as developed by Microsoft had now been made a standalone JavaScript library. This was clearly brilliant news for Node.js developers as they would now be able to take advantage of this and perform localisation / globalisation server-side - they wouldn't need to have jQuery along for the ride. Also, this would be presumably be good news for users of other client side JavaScript libraries like Dojo / YUI etc.")),(0,a.kt)("p",null,"Globalize.js clearly has a rosy future in front of it. Using the new Globalize.js library was still simplicity itself. Here's some examples of localising dates / numbers using the German culture:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),'<script\n  src="/Scripts/Globalize/globalize.js"\n  type="text/javascript"><\/script>\n<script\n  src="/Scripts/Globalize/cultures/globalize.culture.de-DE.js"\n  type="text/javascript"><\/script>\n\nGlobalize.culture("de-DE");\n\n//"2012-05-06" - ISO 8601 format\nGlobalize.format(new Date(2012,4,6), "yyyy-MM-dd");\n\n//"06.05.2012" - standard German short date format of dd.MM.yyyy\nGlobalize.format(new Date(2012,4,6), Globalize.culture().calendar.patterns.d);\n\n//"4.576,3" - a number rendered to 1 decimal place\nGlobalize.format(4576.34, "n1");\n')),(0,a.kt)("h2",o({},{id:"stick-a-fork-in-it---its-done"}),"Stick a fork in it - it's done"),(0,a.kt)("p",null,"The entry for Globalize.js on the jQuery UI site reads as follows:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("em",{parentName:"p"},'"version: 0.1.0a1 (not a jQuery UI version number, as this is a standalone utility) status: in development (part of Grid project)"'))),(0,a.kt)("p",null,"I held back from making use of the library for some time, deterred by the \"in development\" status. However, I had a bit of dialog with one of the jQuery UI team (I forget exactly who) who advised that the API was unlikely to change further and that the codebase was actually pretty stable. Our team did some testing of Globalize.js and found this very much to be case. Everything worked just as we expected and hoped. We're now using Globalize.js in a production environment with no problems reported; it's been doing a grand job."),(0,a.kt)("p",null,"In my opinion, Number / Date localisation on the client is ready for primetime right now - it works! Unfortunately, because Globalize.js has been officially linked in with the jQuery UI grid project it seems unlikely that this will officially ship until the grid does. Looking at the jQuery UI ",(0,a.kt)("a",o({parentName:"p"},{href:"http://wiki.jqueryui.com/Roadmap"}),"roadmap")," the grid is currently slated to release with jQuery UI 2.1. There isn't yet a release date for jQuery UI 1.9 and so it could be a long time before the grid actually sees the light of day."),(0,a.kt)("p",null,'I\'m hoping that the jQuery UI team will be persuaded to "officially" release Globalize.js long before the grid actually ships. Obviously people can use Globalize.js as is right now (as we are) but it seems a shame that many others will be missing out on using this excellent functionality, deterred by the "in development" status. Either way, ',(0,a.kt)("a",o({parentName:"p"},{href:"http://www.youtube.com/watch?v=qEMytPF8YuY"}),"the campaign to release Globalise.js officially starts here!")),(0,a.kt)("h2",o({},{id:"the-future"}),"The Future?"),(0,a.kt)("p",null,"There are plans to bake globalisation right into JavaScript natively with EcmaScript 5.1. There's a good post on the topic ",(0,a.kt)("a",o({parentName:"p"},{href:"http://generatedcontent.org/post/59403168016/esintlapi"}),"here"),". And here's a couple of historical links worth reading too:"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"http://norbertlindenberg.com/2012/02/ecmascript-internationalization-api/"}),"http://norbertlindenberg.com/2012/02/ecmascript-internationalization-api/"),(0,a.kt)("a",o({parentName:"p"},{href:"http://wiki.ecmascript.org/doku.php?id=globalization:specification_drafts"}),"http://wiki.ecmascript.org/doku.php?id=globalization:specification_drafts")))}d.isMDXComponent=!0},48840:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"dad-didnt-buy-any-games",title:"Dad Didn't Buy Any Games",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},s=void 0,l={permalink:"/dad-didnt-buy-any-games",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-05-30-dad-didnt-buy-any-games/index.md",source:"@site/blog/2012-05-30-dad-didnt-buy-any-games/index.md",title:"Dad Didn't Buy Any Games",description:"Inspired by Hanselmans post on how he got started in programming I thought I'd shared my own tale about how it all began... I grew up the 80's just outside London. For those of you of a different vintage let me paint a picture. These were the days when \"Personal Computers\", as they were then styled, were taking the world by storm. Every house would be equipped with either a ZX Spectrum, a Commodore 64 or an Amstrad CPC. These were 8 bit computers which were generally plugged into the family television and spent a good portion of their time loading games like Target",date:"2012-05-30T00:00:00.000Z",formattedDate:"May 30, 2012",tags:[],readingTime:2.06,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"dad-didnt-buy-any-games",title:"Dad Didn't Buy Any Games",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},prevItem:{title:"Reasons to be Cheerful (why now is a good time to be a dev)",permalink:"/reasons-to-be-cheerful-why-now-is-good"},nextItem:{title:"Globalize.js - number and date localisation made easy",permalink:"/globalizejs-number-and-date"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Inspired by ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.hanselman.com/blog/SheLetMeTakeTheComputerHomeHowDidYouGetStartedInComputersAndProgramming.aspx"}),"Hanselmans post on how he got started in programming")," I thought I'd shared my own tale about how it all began... I grew up the 80's just outside London. For those of you of a different vintage let me paint a picture. These were the days when \"Personal Computers\", as they were then styled, were taking the world by storm. Every house would be equipped with either a ZX Spectrum, a Commodore 64 or an Amstrad CPC. These were 8 bit computers which were generally plugged into the family television and spent a good portion of their time loading games like ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Target:_Renegade"}),"Target: Renegade")," from an audio cassette. But not in our house; we didn't have a computer. I remember mournfully pedalling home from friends houses on a number of occasions, glum as I compared my lot with theirs. Whereas my friends would be spending their evenings gleefully battering their keyboards as they thrashed the life out of various end-of-level bosses I was reduced to ","*",(0,a.kt)("strong",{parentName:"p"},"wasting"),"*"," my time reading. That's right Enid Blyton - you were second best in my head. Then one happy day (and it may have been a Christmas present although I'm not certain) our family became the proud possessors of an ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Amstrad_CPC"}),"Amstrad CPC 6128"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(91257).Z,width:"320",height:"201"})),(0,a.kt)("p",null,'Glory be! I was going to play so many games! I would have such larks! My evenings would be filled with pixelated keyboard related destruction! Hallelujah!! But I was wrong. I had reckoned without my father. For reasons that I\'ve never really got to the bottom of Dad had invested in the computer but not in the games. Whilst I was firmly of the opinion that these 2 went together like Lennon and McCartney he was having none of it. "You can write your own son" he intoned and handed over a manual which contained listings for games:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(35745).Z,width:"241",height:"320"})),(0,a.kt)("p",null,"And that's where it first began really. I would spend my evenings typing the Locomotive Basic listings for computer games into the family computer. Each time I started I would be filled with great hopes for what might result. Each time I tended to be rewarded with something that looked a bit like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(69826).Z,width:"268",height:"188"})),(0,a.kt)("p",null,"I'm not sure that it's possible to learn to program by osmosis but if it is I'm definitely a viable test case. I didn't become an expert Locomotive Basic programmer (was there ever such a thing?) but I did undoubtedly begin my understanding of software.... Thanks Dad!"))}d.isMDXComponent=!0},28985:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"reasons-to-be-cheerful-why-now-is-good",title:"Reasons to be Cheerful (why now is a good time to be a dev)",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},s=void 0,l={permalink:"/reasons-to-be-cheerful-why-now-is-good",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-06-04-reasons-to-be-cheerful-why-now-is-good/index.md",source:"@site/blog/2012-06-04-reasons-to-be-cheerful-why-now-is-good/index.md",title:"Reasons to be Cheerful (why now is a good time to be a dev)",description:"I've been a working as a developer in some way, shape or form for just over 10 years now. And it occurred to me the other day that I can't think of a better time to be a software developer than right now",date:"2012-06-04T00:00:00.000Z",formattedDate:"June 4, 2012",tags:[],readingTime:7.53,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"reasons-to-be-cheerful-why-now-is-good",title:"Reasons to be Cheerful (why now is a good time to be a dev)",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},prevItem:{title:"Optimally Serving Up JavaScript",permalink:"/how-im-structuring-my-javascript-in-web"},nextItem:{title:"Dad Didn't Buy Any Games",permalink:"/dad-didnt-buy-any-games"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I've been a working as a developer in some way, shape or form for just over 10 years now. And it occurred to me the other day that I can't think of a better time to be a software developer than ",(0,a.kt)("u",null,"right now")),(0,a.kt)("p",null,". This year was better than last year. Last year was better than the year before. This is a happily recurring theme. So why? Well I guess there are a whole host of reasons; this is my effort to identify just some of them... ## Google and the World Wide Web (other search providers are available)"),(0,a.kt)("p",null,"When I first started out as a humble Delphi developer back in 1999 learning was not the straightforward proposition it is today. If you want to know how to do something these days a good place to start is firing up your browser and putting your question into Google. If I was to ask the question ",(0,a.kt)("em",{parentName:"p"},'"how do I use AJAX"')," of a search engine 10 years ago and now I would see very different things."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(7353).Z,width:"320",height:"167"})),(0,a.kt)("p",null,"On the left the past, on the right the present. Do try not to let the presence of W3Schools in the search results detract... And also best ignore that the term AJAX wasn't coined until 2006... What I'm getting at is that finding out information these days is can be done really quickly. Excellent search engines are now the norm. Back when I started out this was not the case and you were essentially reliant on what had been written down in books and the kindliness of more experienced developers. Google (and others like them) have done us a great service. They've made it easier to learn. ## Blogs / Screencasts / Training websites"),(0,a.kt)("p",null,"Something else that has made it easier to learn is the rise and rise of blogs, screencasts and training websites. Over the last 5 years the internet has been filling up with people writing blogs talking about tools, techniques and approaches they are using. When you're searching for advice on how to do something you can pretty much guarantee these days that some good soul will have written about it already. The most generous devs out there have gone a step further producing screencasts demonstrating them coding and sharing it with the world ","*",(0,a.kt)("strong",{parentName:"p"},"for free"),"*",". See an example from the ever awesome Rebecca Murphey below:"),(0,a.kt)("iframe",{src:"https://player.vimeo.com/video/20457625",width:"500",height:"281",frameBorder:"0",mozallowfullscreen:"",allowFullScreen:""}),(0,a.kt)("p",null,"Similarly, there are now a number of commercially available screencasts which make it really easy to ramp up and learn. There's ",(0,a.kt)("a",o({parentName:"p"},{href:"http://tekpub.com/"}),"TekPub"),", there's ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.pluralsight-training.net"}),"Pluralsight")," (who have massively improved my commute with their mobile app by the way). All of these help tug away the curtain away from the software development Wizard of Oz. All this is a very wonderful thing indeed! ## Podcasts"),(0,a.kt)("p",null,"If you're a Boogie Down Productions fan then you may be aware of the concept of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Edutainment_(album)"}),"Edutainment"),". That is to say, the bridge that can exist between entertainment and education. This is what I've found podcasts to be. I listen to a lot. ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.hanselminutes.com/"}),"Hanselminutes"),". ",(0,a.kt)("a",o({parentName:"p"},{href:"http://herdingcode.com/"}),"Herding Code"),". ",(0,a.kt)("a",o({parentName:"p"},{href:"http://javascriptjabber.com/"}),"JavaScript Jabber"),". ",(0,a.kt)("a",o({parentName:"p"},{href:"http://javascriptshow.com/"}),"The JavaScript Show"),". ",(0,a.kt)("a",o({parentName:"p"},{href:"http://jesseliberty.com/podcast/"}),"Yet Another Podcast"),". There's more. There's something wonderful about about listening to other developers who are passionate about what they are doing. Interested in their work. Enthusiastic about their projects. It's infectious. It makes you want to grab a keyboard and start trying things out. I can't imagine I'm the only dev that feels this way. And of course I couldn't fail to mention my favourite podcast: ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.thisdeveloperslife.com/"}),"This Developer's Life"),". Put together by Scott Hanselman and Rob Conery (I love these guys by the way), and inspired by ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.thisamericanlife.org/"}),"This American Life"),", this show tells some of the stories experienced by developers. It gives an insight into what it's like to be a developer. This podcast is more entertaining than educational but it's absolutely ","*",(0,a.kt)("strong",{parentName:"p"},"fantastic"),"*",". ## JavaScript (and HTML and CSS too)"),(0,a.kt)("p",null,"All of the above have eased the learning path of developers and made it easier to keep in touch with the latest and greatest happenings in the dev world. Along with this there has, in my opinion, also been something of a unifying of purpose in the developer community of late. I attribute this to JavaScript, HTML and CSS. Back when I started out it seemed much more the case that developers were split into different tribes. There was the Delphi tribe, the Visual Basic tribe, the C++ tribe, the Java tribe (very much the \"hip young gunslingers\" tribe back then - I guess these days it'd be the Node.JS guys) as well as many others. And each tribe more or less seemed to keep themselves to themselves. This wasn't malicious that I could tell; that just seemed to be the way it was. But shortly after I started out the idea of the web application took off in a major way. I was involved in this coming from the position of being an early adopter of ASP.NET (which I used, and loved, since it was first in beta). Many other web application technologies were available; JSP, PHP, Perl and the like. But what they all had in common was this: they all pumped out HTML and CSS to the user. Suddenly all these developers from subtly different backgrounds were all targeting the same technology for their GUI. This unifying effect has been ","*",(0,a.kt)("strong",{parentName:"p"},"massively"),"*"," reinforced by JavaScript. Whereas HTML is a markup language, JavaScript is a programming language. And more by accident than grand design JavaScript has kind of become the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.hanselman.com/blog/JavaScriptIsAssemblyLanguageForTheWebPart2MadnessOrJustInsanity.aspx"}),"VM of the web"),". Given the rise and rise of the rich web client (driven onwards and upwards by the popularity of AJAX, Backbone.JS etc) this has meant that devs of all creeds and colours have been forced to pitch a tent on the same patch of dirt. Pretty much all of the tribes now have an embassy in JavaScript land. So there are all these devs out there who are used to working with different server-side technologies from each other. But when it comes to the client, we are all sharing the common language of JavaScript. To a certain extent we're all creating data services that just pump out JSON to the client. Through forums like ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/"}),"StackOverflow")," devs of all the tribes are helping each other with web client \"stuff\". They're all interacting in ways that they probably wouldn't otherwise if the web client environment was as diverse as the server-side environment... ## The Browser Wars Begin Again"),(0,a.kt)("p",null,"Didn't things seem a little dull around 2003/2004? IE 6 had come out 3 years previously and had vanquished all comers. Microsoft was really the only game in town browser-wise. Things had stopped changing; it seemed like browsers were \"done\". You know, good enough and there was no need to take things any further. Then came Firefox. This lone browser appeared as an alternative to might of IE. I must admit the thing that first attracted me to Firefox was the fact it had tabs. I mean technically I knew Firefox was more secure than IE but honestly it was the tabs that attracted me in the first place. (This may offer some insight as to why so many people still smoke...) And somehow Firefox managed to jolt Microsoft out of it's inertia on the web. Microsoft started caring about IE again. (Not enough until quite recently in my book but you've got to start somewhere.) I'm a firm believer that change for it's own sake can often be a good thing. Change makes you think about why you do what you do and wonder if there might be better approaches that could be used instead. And these changes kind of feed into... ## ...HTML 5!"),(0,a.kt)("p",null,"That's right HTML 5 which is all about change. It's taking HTML as we know and love it and bolting on new stuff. New elements (canvas), new styling (CSS 3), new JavaScript APIs, faster JavaScript engines, support for JavaScript 5. The list goes on... And all this new stuff is exciting, whizzy, fun to play with. That which wasn't possible yesterday is possible now. Playing with new toys is half the fun of being a dev. There's a lot of new toys about right now. ## The Feeling of Possibilites"),(0,a.kt)("p",null,"This is what it comes down to I think. It's so easy to learn these days and there's so much to learn about. Right now lots of things are happening above and beyond what I've mentioned above. Open source has come of age and gone mainstream. Github is with us. Google are making contentious forays into new languages with Dart and Native Client. Microsoft aren't remotely evil empire-like these days; they've made .NET like a Swiss army knife. You can even run Node.js on IIS these days! Signal-R, Websockets, Coffeescript, JS.Next, Backbone.JS, Entity Framework, LINQ, the mobile web, ASP.NET MVC, Razor, Knockout.JS, the cloud, Windows Azure... So much is happening right now. People are making things. It's a very interesting time to be a dev. There are many reasons to be cheerful."))}d.isMDXComponent=!0},61945:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"how-im-structuring-my-javascript-in-web",title:"Optimally Serving Up JavaScript",authors:"johnnyreilly",tags:["asp.net mvc","javascript","cassette"],hide_table_of_contents:!1},s=void 0,l={permalink:"/how-im-structuring-my-javascript-in-web",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-07-01-how-im-structuring-my-javascript-in-web/index.md",source:"@site/blog/2012-07-01-how-im-structuring-my-javascript-in-web/index.md",title:"Optimally Serving Up JavaScript",description:"I have occasionally done some server-side JavaScript with Rhino and Node.js but this is the exception rather than the rule. Like most folk at the moment, almost all the JavaScript I write is in a web context.",date:"2012-07-01T00:00:00.000Z",formattedDate:"July 1, 2012",tags:[{label:"asp.net mvc",permalink:"/tags/asp-net-mvc"},{label:"javascript",permalink:"/tags/javascript"},{label:"cassette",permalink:"/tags/cassette"}],readingTime:13.48,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"how-im-structuring-my-javascript-in-web",title:"Optimally Serving Up JavaScript",authors:"johnnyreilly",tags:["asp.net mvc","javascript","cassette"],hide_table_of_contents:!1},prevItem:{title:"Rendering Partial View to a String",permalink:"/rendering-partial-view-to-string"},nextItem:{title:"Reasons to be Cheerful (why now is a good time to be a dev)",permalink:"/reasons-to-be-cheerful-why-now-is-good"}},p={authorsImageUrls:[void 0]},u=[{value:"What are you up to?",id:"what-are-you-up-to",level:2},{value:"&quot;Render first. JS second.&quot;",id:"render-first-js-second",level:2},{value:"I want to serve you...",id:"i-want-to-serve-you",level:2},{value:"Minification - I want to serve you less...",id:"minification---i-want-to-serve-you-less",level:2},{value:"CDNs (they want to serve you)",id:"cdns-they-want-to-serve-you",level:2},{value:"TL:DR",id:"tldr",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I have occasionally done some server-side JavaScript with Rhino and Node.js but this is the exception rather than the rule. Like most folk at the moment, almost all the JavaScript I write is in a web context."),(0,a.kt)("p",null,"Over time I've come to adopt a roughly standard approach to how I structure my JavaScript; both the JavaScript itself and how it is placed / rendered in the an HTML document. I wanted to write about the approach I'm using. Partly just to document the approach but also because I often find writing about something crystalises my feelings on the subject in one way or another. I think that most of what I'm doing is sensible and rational but maybe as I write about this I'll come to some firmer conclusions about my direction of travel."),(0,a.kt)("h2",o({},{id:"what-are-you-up-to"}),"What are you up to?"),(0,a.kt)("p",null,"Before I get started it's probably worth mentioning the sort of web development I'm generally called to do (as this has obviously influenced my decisions)."),(0,a.kt)("p",null,"Most of my work tends to be on web applications used internally within a company. That is to say, web applications accessible on a Company intranet. Consequently, the user base for my applications tends to be smaller than the Amazons and Googles of this world. It almost invariably sits on the ASP.NET stack in some way. Either classic WebForms or MVC."),(0,a.kt)("h2",o({},{id:"render-first-js-second"}),'"Render first. JS second."'),(0,a.kt)("p",null,"I took 2 things away from ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.stevesouders.com/blog/2010/09/30/render-first-js-second/"}),"Steve Souder's article"),":"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Async script loading is better than synchronous script loading"),(0,a.kt)("li",{parentName:"ol"},"Get your screen rendered and ","*",(0,a.kt)("strong",{parentName:"li"},"then"),"*"," execute your JavaScript")),(0,a.kt)("p",null,"I'm not doing any async script loading as yet; although I am thinking of giving it a try at some point. In terms of choosing a loader I'll probably give RequireJS first crack of the whip (purely as it looks like most people are tending it's direction and that can't be without reason)."),(0,a.kt)("p",null,"However - it seems that the concept of async script loading is kind of conflict with one of the other tenets of web wisdom: script bundling. Script bundling, if you're not already aware, is the idea that you should combine all your scripts into a single file and then just serve that. This prevents multiple HTTP requests as each script loads in. Async script loading is obviously okay with multiple HTTP requests, presumably because of the asynchronous non-blocking pattern of loading. So. 2 different ideas. And there's further movement on this front right now as ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.hanselman.com/blog/VisualStudio2012RCIsReleasedTheBigWebRollup.aspx"}),"Microsoft are baking in script bundling to .NET 4.5"),"."),(0,a.kt)("p",null,'Rather than divide myself between these 2 horses I have at the moment tried to follow the "JS second" part of this advice in my own (perhaps slightly old fashioned) way...'),(0,a.kt)("h2",o({},{id:"i-want-to-serve-you"}),"I want to serve you..."),(0,a.kt)("p",null,"I have been making sure that scripts are the last thing served to the screen by using a customised version of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://frugalcoder.us/post/2009/06/29/Handling-Scripts-in-ASPNet-MVC.aspx"}),"Michael J. Ryan's HtmlHelper"),". This lovely helper allows you to add script references as required from a number of different sources (layout page, view, partial view etc - even the controller if you so desired). It's simple to control the ordering of scripts by allowing you to set a priority for each script which determines the render order."),(0,a.kt)("p",null,"Then as a final step before rendering the ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;/body&gt;")," tag the scripts can be rendered in one block. By this point the web page is rendered visually and a marginal amount of blocking is, in my view, acceptable."),(0,a.kt)("p",null,"If anyone is curious - the class below is my own version of Michael's helper. My contribution is the go faster stripes relating to the caching suffix and the ability to specify dependancies using script references rather than using numeric priority mechanism):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Web;\nusing System.Web.Mvc;\nusing System.IO;\nusing System.Text;\n\nnamespace DummyMvc.Helpers\n{\n    /// <summary>\n    /// This helper makes creation of script tags within a view straightforward.\n    /// If the specified file is missing an error is raised at runtime.  A v= suffix\n    /// is added to URLs using the VersionHelper to make caching behave as desired\n    /// both during development (where we don\'t want to cache as we make changes to code)\n    /// and during production (where we do want to cache to improve the user loading experience)\n    ///\n    /// There are 2 approaches available using this helper.\n    ///\n    /// 1. Straight script tag creation using the Script method.\n    ///\n    /// A usage of:\n    ///\n    /// @Html.Script("~/Scripts/jquery.js")\n    ///\n    /// Would immediatedly render a tag as below: (please note the v= suffix to the URL)\n    ///\n    /// <script src="/Scripts/jquery.tools.min.js?v=634765611410213405" type="text/javascript"><\/script>\n    ///\n    /// 2. Script bundling\n    ///\n    /// This approach allows you to build up the scripts to be rendered across multiple\n    /// views / partial views / layout etc and then have them rendered in one hit (ideally\n    /// just prior to the body tag being rendered as at this point the screen will be visually\n    /// set up for the user and any script loading that causes blocking should not be a presentational\n    /// issue). This is heavily based on Michael Ryans work; see links below.\n    ///\n    /// [Links]\n    /// http://frugalcoder.us/post/2009/06/29/Handling-Scripts-in-ASPNet-MVC.aspx\n    /// http://stackoverflow.com/questions/5598167/mvc3-need-help-with-html-helper\n    ///\n    /// [Usage]\n    /// --- From each view / partial view ---\n    /// @Html.AddClientScript("~/Scripts/jquery.js")\n    /// @Html.AddClientScript("~/Scripts/jquery-ui.js", dependancies: new string[] {"~/Scripts/jquery.js"})\n    /// @Html.AddClientScript("~/Scripts/site.js", dependancies: new string[] {"~/Scripts/jquery.js"})\n    /// @Html.AddClientScript("~/Scripts/views/myview.js", dependancies: new string[] {"~/Scripts/jquery.js"})\n    ///\n    /// --- From the main Master/View (just before last Body tag so all "registered" scripts are included) ---\n    /// @Html.ClientScripts()\n    /// </summary>\n    public static class ScriptExtensions\n    {\n        #region Public\n\n        /// <summary>\n        /// Render a Script element given a URL\n        /// </summary>\n        /// <param name="helper"></param>\n        /// <param name="url">URL of script to render</param>\n        /// <returns></returns>\n        public static MvcHtmlString Script(\n          this HtmlHelper helper,\n          string url)\n        {\n            return MvcHtmlString.Create(MakeScriptTag(helper, url));\n        }\n\n        /// <summary>\n        /// Add client script files to list of script files that will eventually be added to the view\n        /// </summary>\n        /// <param name="scriptPath">path to script file</param>\n        /// <param name="dependancies">OPTIONAL: a string array of any script dependancies</param>\n        /// <returns>always MvcHtmlString.Empty</returns>\n        public static MvcHtmlString AddClientScript(this HtmlHelper helper, string scriptPath, string[] dependancies = null)\n        {\n            //If script list does not already exist then initialise\n            if (!helper.ViewContext.HttpContext.Items.Contains("client-script-list"))\n                helper.ViewContext.HttpContext.Items["client-script-list"] = new Dictionary<string, KeyValuePair<string, string[]>>();\n\n            var scripts = helper.ViewContext.HttpContext.Items["client-script-list"] as Dictionary<string, KeyValuePair<string, string[]>>;\n\n            //Ensure scripts are not added twice\n            var scriptFilePath = helper.ViewContext.HttpContext.Server.MapPath(DetermineScriptToRender(helper, scriptPath));\n            if (!scripts.ContainsKey(scriptFilePath))\n                scripts.Add(scriptFilePath, new KeyValuePair<string, string[]>(scriptPath, dependancies));\n\n            return MvcHtmlString.Empty;\n        }\n\n        /// <summary>\n        /// Add a script tag for each "registered" script associated with the current view.\n        /// Output script tags with order depending on script dependancies\n        /// </summary>\n        /// <returns>MvcHtmlString</returns>\n        public static MvcHtmlString ClientScripts(this HtmlHelper helper)\n        {\n            var url = new UrlHelper(helper.ViewContext.RequestContext, helper.RouteCollection);\n            var scripts = helper.ViewContext.HttpContext.Items["client-script-list"] as Dictionary<string, KeyValuePair<string, string[]>> ?? new Dictionary<string, KeyValuePair<string, string[]>>();\n\n            //Build script tag block\n            var scriptList = new List<string>();\n            if (scripts.Count > 0)\n            {\n                //Check all script dependancies exist and throw an exception if any do not\n                var distinctDependancies = scripts.Where(s => s.Value.Value != null)\n                                                  .SelectMany(s => s.Value.Value)\n                                                  .Distinct()\n                                                  .Select(s => GetScriptFilePath(helper, s)) //Exception will be thrown here if file does not exist\n                                                  .ToList();\n\n                var missingDependancies = distinctDependancies.Except(scripts.Select(s => s.Key)).ToList();\n                if (missingDependancies.Count > 0)\n                {\n                    throw new KeyNotFoundException("The following dependancies are missing: " + Environment.NewLine +\n                        Environment.NewLine +\n                        string.Join(Environment.NewLine, missingDependancies));\n                }\n\n                //Serve scripts without dependancies first\n                scriptList.AddRange(scripts.Where(s => s.Value.Value == null).Select(s => s.Value.Key));\n\n                //Get all scripts which have dependancies\n                var scriptsAndDependancies = scripts.Where(s => s.Value.Value != null)\n                                                    .OrderBy(s => s.Value.Value.Length)\n                                                    .Select(s => s.Value)\n                                                    .ToList();\n\n                //Loop round adding scripts to the scriptList until all are done\n                do\n                {\n                    //Loop backwards through list so items can be removed mid loop\n                    for (var i = scriptsAndDependancies.Count - 1; i >= 0; i--)\n                    {\n                        var script = scriptsAndDependancies[i].Key;\n                        var dependancies = scriptsAndDependancies[i].Value;\n\n                        //Check if all the dependancies have been added to scriptList yet\n                        bool currentScriptDependanciesAdded = !dependancies.Except(scriptList).Any();\n                        if (currentScriptDependanciesAdded)\n                        {\n                            //Move script to scriptList\n                            scriptList.Add(script);\n                            scriptsAndDependancies.RemoveAt(i);\n                        }\n                    }\n                } while (scriptsAndDependancies.Count > 0);\n            }\n\n            //Generate a script tag for each script\n            var scriptsToRender = scriptList.Select(s => MakeScriptTag(helper, s)).ToList();\n#if DEBUG\n            scriptsToRender.Insert(0, "\x3c!-- BEGIN - HtmlHelperScriptExtensions.ClientScripts() --\x3e");\n            scriptsToRender.Insert(scriptsToRender.Count, "\x3c!-- END - HtmlHelperScriptExtensions.ClientScripts() --\x3e");\n#endif\n\n            //Output script tag block at point in view where method is called (by returning an MvcHtmlString)\n            return (scriptsToRender.Count > 0\n                ? MvcHtmlString.Create(string.Join(Environment.NewLine, scriptsToRender))\n                : MvcHtmlString.Empty);\n        }\n\n        /// <summary>\n        /// Add client script block to list of script blocks that will eventually be added to the view\n        /// </summary>\n        /// <param name="key">unique identifier for script block</param>\n        /// <param name="scriptBlock">script block</param>\n        /// <param name="dependancies">OPTIONAL: a string array of any script block dependancies</param>\n        /// <returns>always MvcHtmlString.Empty</returns>\n        public static MvcHtmlString AddClientScriptBlock(this HtmlHelper helper, string key, string scriptBlock, string[] dependancies = null)\n        {\n            //If script list does not already exist then initialise\n            if (!helper.ViewContext.HttpContext.Items.Contains("client-script-block-list"))\n                helper.ViewContext.HttpContext.Items["client-script-block-list"] = new Dictionary<string, KeyValuePair<string, string[]>>();\n\n            var scriptBlocks = helper.ViewContext.HttpContext.Items["client-script-block-list"] as Dictionary<string, KeyValuePair<string, string[]>>;\n\n            //Prevent duplication\n            if (scriptBlocks.ContainsKey(key)) return MvcHtmlString.Empty;\n\n            scriptBlocks.Add(key, new KeyValuePair<string, string[]>(scriptBlock, dependancies));\n\n            return MvcHtmlString.Empty;\n        }\n\n        /// <summary>\n        /// Output all "registered" script blocks associated with the current view.\n        /// Output script tags with order depending on script dependancies\n        /// </summary>\n        /// <returns>MvcHtmlString</returns>\n        public static MvcHtmlString ClientScriptBlocks(this HtmlHelper helper)\n        {\n            var scriptBlocks = helper.ViewContext.HttpContext.Items["client-script-block-list"] as Dictionary<string, KeyValuePair<string, string[]>> ?? new Dictionary<string, KeyValuePair<string, string[]>>();\n\n            //Build script tag block\n            var scriptBlockList = new List<string>();\n            if (scriptBlocks.Count > 0)\n            {\n                //Check all script dependancies exist and throw an exception if any do not\n                var distinctDependancies = scriptBlocks.Where(s => s.Value.Value != null)\n                                                       .SelectMany(s => s.Value.Value)\n                                                       .Distinct()\n                                                       .ToList();\n\n                var missingDependancies = distinctDependancies.Except(scriptBlocks.Select(s => s.Key)).ToList();\n                if (missingDependancies.Count > 0)\n                {\n                    throw new KeyNotFoundException("The following dependancies are missing: " + Environment.NewLine +\n                        Environment.NewLine +\n                        string.Join(Environment.NewLine, missingDependancies));\n                }\n\n                //Serve script blocks without dependancies first\n                scriptBlockList.AddRange(scriptBlocks.Where(s => s.Value.Value == null).Select(s => s.Value.Key));\n\n                //Get all script blocks which have dependancies\n                var scriptBlocksAndDependancies = scriptBlocks.Where(s => s.Value.Value != null)\n                                                              .OrderBy(s => s.Value.Value.Length)\n                                                              .Select(s => s.Value)\n                                                              .ToList();\n\n                //Loop round adding scripts to the scriptList until all are done\n                do\n                {\n                    //Loop backwards through list so items can be removed mid loop\n                    for (var i = scriptBlocksAndDependancies.Count - 1; i >= 0; i--)\n                    {\n                        var scriptBlock = scriptBlocksAndDependancies[i].Key;\n                        var dependancies = scriptBlocksAndDependancies[i].Value;\n\n                        //Check if all the dependancies have been added to scriptList yet\n                        bool currentScriptBlockDependanciesAdded = !dependancies.Except(scriptBlockList).Any();\n                        if (currentScriptBlockDependanciesAdded)\n                        {\n                            //Move script to scriptList\n                            scriptBlockList.Add(scriptBlock);\n                            scriptBlocksAndDependancies.RemoveAt(i);\n                        }\n                    }\n                } while (scriptBlocksAndDependancies.Count > 0);\n            }\n\n            //Generate a script tag for each script\n            var scriptBlocksToRender = scriptBlockList.Select(s => string.Format("<script type=\\"text/javascript\\">{0}{1}<\/script>", Environment.NewLine, s)).ToList();\n#if DEBUG\n            scriptBlocksToRender.Insert(0, "\x3c!-- BEGIN - HtmlHelperScriptExtensions.ClientScriptBlocks() --\x3e");\n            scriptBlocksToRender.Insert(scriptBlocksToRender.Count, "\x3c!-- END - HtmlHelperScriptExtensions.ClientScriptBlocks() --\x3e");\n#endif\n\n            //Output script tag block at point in view where method is called (by returning an MvcHtmlString)\n            return (scriptBlocksToRender.Count > 0\n                ? MvcHtmlString.Create(string.Join(Environment.NewLine, scriptBlocksToRender))\n                : MvcHtmlString.Empty);\n        }\n\n        #endregion\n\n        #region Private\n\n        /// <summary>\n        /// Take a URL, resolve it and a version suffix.  In Debug this will be based on DateTime.Now to prevent caching\n        /// on a development machine.  In Production this will be based on the version number of the appplication.\n        /// This means when the version number is incremented in subsequent releases script files should be recached automatically.\n        /// </summary>\n        /// <param name="helper"></param>\n        /// <param name="url">URL to resolve and add suffix to</param>\n        /// <returns></returns>\n        private static string ResolveUrlWithVersion(HtmlHelper helper, string url)\n        {\n#if DEBUG\n            var suffix = DateTime.Now.Ticks.ToString();\n#else\n            var suffix = System.Reflection.Assembly.GetExecutingAssembly().GetName().Version.ToString();\n#endif\n\n            var urlWithVersionSuffix = string.Format("{0}?v={1}", url, suffix);\n            var urlResolved = new UrlHelper(helper.ViewContext.RequestContext, helper.RouteCollection).Content(urlWithVersionSuffix);\n\n            return urlResolved;\n        }\n\n        /// <summary>\n        /// Create the string that represents a script tag\n        /// </summary>\n        /// <param name="helper"></param>\n        /// <param name="url"></param>\n        /// <returns></returns>\n        private static string MakeScriptTag(HtmlHelper helper, string url)\n        {\n            var scriptToRender = DetermineScriptToRender(helper, url);\n\n            //Render script tag\n            var scriptTag = new TagBuilder("script");\n            scriptTag.Attributes["type"] = "text/javascript"; //This isn\'t really required with HTML 5 as this is the default.  As it does no real harm so I have left it for now. http://stackoverflow.com/a/9659074/761388\n            scriptTag.Attributes["src"] = SharedExtensions.ResolveUrlWithVersion(helper, scriptToRender);\n\n            var scriptTagString = scriptTag.ToString();\n            return scriptTagString;\n        }\n\n        /// <summary>\n        /// Author      : John Reilly\n        /// Description : Get the script that should be served to the user - throw an exception if it doesn\'t exist and minify if in release mode\n        /// </summary>\n        /// <param name="helper"></param>\n        /// <param name="url"></param>\n        /// <param name="minifiedSuffix">OPTIONAL - this allows you to directly specify the minified suffix if it differs from the standard\n        /// of "min.js" - unlikely this will ever be used but possible</param>\n        /// <returns></returns>\n        private static string DetermineScriptToRender(HtmlHelper helper, string url, string minifiedSuffix = "min.js")\n        {\n            //Initialise a list that will contain potential scripts to render\n            var possibleScriptsToRender = new List<string>() { url };\n\n#if DEBUG\n            //Don\'t add minified scripts in debug mode\n#else\n            //Add minified path of script to list\n            possibleScriptsToRender.Insert(0, Path.ChangeExtension(url, minifiedSuffix));\n#endif\n\n            var validScriptsToRender = possibleScriptsToRender.Where(s => File.Exists(helper.ViewContext.HttpContext.Server.MapPath(s)));\n            if (!validScriptsToRender.Any())\n                throw new FileNotFoundException("Unable to render " + url + " as none of the following scripts exist:" +\n                    string.Join(Environment.NewLine, possibleScriptsToRender));\n            else\n                return validScriptsToRender.First(); //Return first existing file in list (minified file in release mode)\n        }\n\n        #endregion\n    }\n}\n')),(0,a.kt)("h2",o({},{id:"minification---i-want-to-serve-you-less"}),"Minification - I want to serve you less..."),(0,a.kt)("p",null,"Another tweak I made to the script helper meant that when compiling either the debug or production (minified) versions of common JS files will be included if available. This means in a production environment the users get minified JS files so faster loading. And in a development environment we get the full JS files which make debugging more straightforward."),(0,a.kt)("p",null,"What I haven't started doing is minifying my own JS files as yet. I know I'm being somewhat inconsistent here by sometimes serving minified files and sometimes not. I'm not proud. Part of my rationale for this that since most of my users use my apps on a daily basis they will for the most part be using cached JS files. Obviously there'll be slightly slower load times the first time they go to a page but nothing that significant I hope."),(0,a.kt)("p",null,"I have thought of starting to do my own minification as a build step but have held off for now. Again this is something being baked into .NET 4.5; another reason why I have held off doing this a different way for now."),(0,a.kt)("p",null,"Update"),(0,a.kt)("p",null,"It now looks like this Microsofts optimisations have become ",(0,a.kt)("a",o({parentName:"p"},{href:"http://nuget.org/packages/Microsoft.AspNet.Web.Optimization"}),"this Nuget package"),". It's early days (well it was released on 15th August 2012 and I'm writing this on the 16th) but I think this looks not to be tied to MVC 4 or .NET 4.5 in which case I could use it in my current MVC 3 projects. I hope so..."),(0,a.kt)("p",null,"By the way there's a ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.pluralsight.com/training/Courses/TableOfContents/mvc4#mvc4-m3-optimization"}),"nice rundown of how to use this by K. Scott Allen of Pluralsight"),". It's fantastic. Recommended."),(0,a.kt)("p",null,"Update 2"),(0,a.kt)("p",null,"Having done a little asking around I now understand that this ","*",(0,a.kt)("strong",{parentName:"p"},"can"),"*"," be used with MVC 3 / .NET 4.0. Excellent!"),(0,a.kt)("p",null,"One rather nice alternative script serving mechanism I've seen (but not yet used) is Andrew Davey's ",(0,a.kt)("a",o({parentName:"p"},{href:"http://getcassette.net"}),"Cassette")," which I mean to take for a test drive soon. This looks fantastic (and is available as a ",(0,a.kt)("a",o({parentName:"p"},{href:"http://nuget.org/packages/Cassette"}),"Nuget package")," ","-"," 10 points!)."),(0,a.kt)("h2",o({},{id:"cdns-they-want-to-serve-you"}),"CDNs (they want to serve you)"),(0,a.kt)("p",null,"I've never professionally made use of CDNs at all. There are ",(0,a.kt)("a",o({parentName:"p"},{href:"http://encosia.com/3-reasons-why-you-should-let-google-host-jquery-for-you/"}),"clearly good reasons why you should")," but most of those good reasons relate most to public facing web apps."),(0,a.kt)("p",null,"As I've said, the applications I tend to work on sit behind firewalls and it's not always guaranteed what my users can see from the grand old world of web beyond. (Indeed what they see can change on hour by hour basis sometimes...) Combined with that, because my apps are only accessible by a select few I don't face the pressure to reduce load on the server that public web apps can face."),(0,a.kt)("p",null,"So while CDN's are clearly a good thing. I don't use them at present. And that's unlikely to change in the short term."),(0,a.kt)("h2",o({},{id:"tldr"}),"TL:DR"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"I don't use CDNs - they're clearly useful but they don't suit my particular needs"),(0,a.kt)("li",{parentName:"ol"},"I serve each JavaScript file individually just before the body tag. I don't bundle."),(0,a.kt)("li",{parentName:"ol"},"I don't minify my own scripts (though clearly it wouldn't be hard) but I do serve the minified versions of 3rd party libraries (eg jQuery) in a Production environment."),(0,a.kt)("li",{parentName:"ol"},"I don't use async script loaders at present. I may in future; we shall see.")),(0,a.kt)("p",null,"I expect some of the above may change (well, possibly not point #1) but this general approach is working well for me at present."),(0,a.kt)("p",null,"I haven't touched at all on how I'm structuring my JavaScript code itself. Perhaps next time."))}d.isMDXComponent=!0},71522:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"rendering-partial-view-to-string",title:"Rendering Partial View to a String",authors:"johnnyreilly",tags:["asp.net mvc"],hide_table_of_contents:!1},s=void 0,l={permalink:"/rendering-partial-view-to-string",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-07-16-rendering-partial-view-to-string/index.md",source:"@site/blog/2012-07-16-rendering-partial-view-to-string/index.md",title:"Rendering Partial View to a String",description:"Well done that man!",date:"2012-07-16T00:00:00.000Z",formattedDate:"July 16, 2012",tags:[{label:"asp.net mvc",permalink:"/tags/asp-net-mvc"}],readingTime:4.06,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"rendering-partial-view-to-string",title:"Rendering Partial View to a String",authors:"johnnyreilly",tags:["asp.net mvc"],hide_table_of_contents:!1},prevItem:{title:"jQuery Unobtrusive Validation (+ associated gotchas)",permalink:"/jquery-unobtrusive-validation"},nextItem:{title:"Optimally Serving Up JavaScript",permalink:"/how-im-structuring-my-javascript-in-web"}},p={authorsImageUrls:[void 0]},u=[{value:"Well done that man!",id:"well-done-that-man",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"well-done-that-man"}),"Well done that man!"),(0,a.kt)("p",null,"Every now and then I'm thinking to myself \"",(0,a.kt)("em",{parentName:"p"},"wouldn't it be nice if you could do x..."),"\" And then I discover that someone else has thought the self same thoughts and better yet they have the answer! I had this situation recently and discovered the wonderful Kevin Craft had been there, done that and made the T-shirt. Here's his blog: ",(0,a.kt)("a",o({parentName:"p"},{href:"http://craftycodeblog.com/2010/05/15/asp-net-mvc-render-partial-view-to-string/"}),"http://craftycodeblog.com/2010/05/15/asp-net-mvc-render-partial-view-to-string/")," I wanted to talk about how this simple post provided me with an elegant solution to something I've found niggling and unsatisfactory for a while now... ## How it helped"),(0,a.kt)("p",null,"Just last week I was thinking about ",(0,a.kt)("inlineCode",{parentName:"p"},"Partial Views"),". Some background. I'm working on an ASP.NET MVC 3 project which provides users with a nice web interface to manage the workflow surrounding certain types of financial asset. The user is presented with a web page which shows a kind of grid to the user. As the user hovers over a row they are presented with a context menu which allows them to perform certain workflow actions. If they perform an action then that row will need to be updated to reflect this. Back in the day this would have been achieved by doing a full postback to the server. At the server the action would be taken, the persistent storage updated and then the whole page would be served up to the user again with the relevant row of HTML updated but everything else staying as is. Now there's nothing wrong with this approach as such. I mean it works just fine. But in my case since I knew that it was only that single row of HTML that was going to be updated and so I was loath to re-render the whole page. It seemed a waste to get so much data back from the server when only a marginal amount was due to change. And also I didn't want the user to experience the screen refresh flash. Looks ugly. Now in the past when I've had a solution to this problem which from a UI perspective is good but from a development perspective slightly unsatisfactory. I would have my page call a controller method (via ",(0,a.kt)("inlineCode",{parentName:"p"},"jQuery.ajax"),") to perform the action. This controller would return a ",(0,a.kt)("inlineCode",{parentName:"p"},"JsonResult")," indicating success or failure and any data necessary to update the screen. Then in the ",(0,a.kt)("inlineCode",{parentName:"p"},"success")," function I would manually update the HTML on the screen using the data provided. Now this solution works but there's a problem. ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Rolf_Harris"}),"Can you tell what it is yet?")," It's not very DRY. I'm repeating myself. When the page is initially rendered I have a ",(0,a.kt)("inlineCode",{parentName:"p"},"View")," which renders (in this example) all the relevant HTML for the screen ","*","including","*"," the HTML for my rows of data. And likewise I have my JavaScript method for updating the screen too. So with this solution I have duplicated my GUI logic. If I update 1, I need to update the other. It's not a massive hardship but it is, as I say, unsatisfactory. I was recently thinking that it would be nice if I could refactor my row HTML into a ",(0,a.kt)("inlineCode",{parentName:"p"},"Partial View")," which I could then use in 2 places: 1. In my standard ",(0,a.kt)("inlineCode",{parentName:"p"},"View")," as I iterated through each element for display and 2. Nested inside a ",(0,a.kt)("inlineCode",{parentName:"p"},"JsonResult"),"..."),(0,a.kt)("p",null,"The wonderful thing about approach 2 is that it allows me to massively simplify my ",(0,a.kt)("inlineCode",{parentName:"p"},"success")," to this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"$('myRowSelector').empty().html(data.RowHTML); //Where RowHTML is the property that\n//contains my stringified PartialView\n")),(0,a.kt)("p",null,"and if I later make changes to the ",(0,a.kt)("inlineCode",{parentName:"p"},"Partial View")," these changes will not require me to make any changes to my JavaScript at all. Brilliant! And entirely satisfactory. On the grounds that someone else might have had the same idea I did a little googling around. Sure enough I discovered ",(0,a.kt)("a",o({parentName:"p"},{href:"http://craftycodeblog.com/2010/05/15/asp-net-mvc-render-partial-view-to-string/"}),"Kevin Craft's post")," which was just the ticket. It does exactly what I'd hoped. Besides being a nice and DRY solution this approach has a number of other advantages as well: - Given it's a ",(0,a.kt)("inlineCode",{parentName:"p"},"Partial View")," the Visual Studio IDE provides a nice experience when coding it up with regards to intellisense / highlighting etc. Not something available when you're hand coding up a string which contains the HTML you'd like passed back..."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"A wonderful debug experience. You can debug the rendering of a ",(0,a.kt)("inlineCode",{parentName:"li"},"Partial View")," being rendered to a string in the same way as if the ASP.NET MVC framework was serving it up. I could have lived without this but it's fantastic to have it available."),(0,a.kt)("li",{parentName:"ul"},"It's possible to nest ","*",(0,a.kt)("strong",{parentName:"li"},"multiple"),"*"," ",(0,a.kt)("inlineCode",{parentName:"li"},"Partial Views")," within your ",(0,a.kt)("inlineCode",{parentName:"li"},"JsonResult"),". THIS IS WONDERFUL!!! This means that if several parts of your screen need to be updated (perhaps the row and a status panel as well) then as long as both are refactored into a ",(0,a.kt)("inlineCode",{parentName:"li"},"Partial View")," you can generate them on the fly and pass them back.")),(0,a.kt)("p",null,"Excellent stuff!"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"")))}d.isMDXComponent=!0},91094:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"jquery-unobtrusive-validation",title:"jQuery Unobtrusive Validation (+ associated gotchas)",authors:"johnnyreilly",tags:["jquery unobtrusive validation"],hide_table_of_contents:!1},s=void 0,l={permalink:"/jquery-unobtrusive-validation",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-08-06-jquery-unobtrusive-validation/index.md",source:"@site/blog/2012-08-06-jquery-unobtrusive-validation/index.md",title:"jQuery Unobtrusive Validation (+ associated gotchas)",description:"I was recently working on a project which had client side validation manually set up which essentially duplicated the same logic on the server. Like many things this had started out small and grown and grown until it became arduos and tedious to maintain.",date:"2012-08-06T00:00:00.000Z",formattedDate:"August 6, 2012",tags:[{label:"jquery unobtrusive validation",permalink:"/tags/jquery-unobtrusive-validation"}],readingTime:4.48,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"jquery-unobtrusive-validation",title:"jQuery Unobtrusive Validation (+ associated gotchas)",authors:"johnnyreilly",tags:["jquery unobtrusive validation"],hide_table_of_contents:!1},prevItem:{title:"ClosedXML - the real SDK for Excel",permalink:"/closedxml-real-sdk-for-excel"},nextItem:{title:"Rendering Partial View to a String",permalink:"/rendering-partial-view-to-string"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I was recently working on a project which had client side validation manually set up which essentially duplicated the same logic on the server. Like many things this had started out small and grown and grown until it became arduos and tedious to maintain."),(0,a.kt)("p",null,"Time to break out the unobtrusive jQuery validation."),(0,a.kt)("p",null,"If you\u2019re not aware of this, as part of MVC 3 Microsoft leveraged the pre-existing ",(0,a.kt)("a",o({parentName:"p"},{href:"http://bassistance.de/jquery-plugins/jquery-plugin-validation/"}),"jQuery Validate library")," and introduced an \u201cunobtrusive\u201d extension to this which allows the library to be driven by HTML 5 data attributes. I have mentioned this lovely extension before but I haven't been using it for the last 6 months or so. And coming back to it I realised that I had forgotten a few of the details / quirks."),(0,a.kt)("p",null,'First up, "where do these HTML 5 data attributes come from?" I hear you cry. Why from the ',(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/system.componentmodel.dataannotations.validationattribute.aspx"}),"Validation attributes that live in System.ComponentModel.DataAnnotations"),"."),(0,a.kt)("p",null,"Let me illustrate. This decoration:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[Required(),\n   Range(0.01, Double.MaxValue, ErrorMessage = "A positive value is required for Price"),\n   Display(Name = "My Price")]\n  public double Price { get; set; }\n')),(0,a.kt)("p",null,"specifies that the Price field on the model is required, that it requires a positive numeric value and that it\u2019s official name is \u201cMy Price\u201d. As a result of this decoration, when you use syntax like this in your view:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'@Html.LabelFor(x => x.Price)\n  @Html.TextBoxFor(x => x.Price, new { id = "itsMyPrice", type = "number" })\n')),(0,a.kt)("p",null,"You end up with this HTML:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<label for="Price">My Price</label>\n  <input data-val="true" data-val-number="The field My Price must be a number." data-val-range="A positive value is required for My Price" data-val-range-max="1.79769313486232E+308" data-val-range-min="0.01" data-val-required="The My Price field is required." id="itsMyPrice" name="Price" type="number" value="">\n')),(0,a.kt)("p",null,"As you can see MVC has done the hard work of translating these data annotations into HTML 5 data attributes so you don\u2019t have to. With this in place you can apply your validation in 1 place (the model) and 1 place only. This reduces the code you need to write exponentially. It also reduces duplication and therefore reduces the likelihood of mistakes."),(0,a.kt)("p",null,"To validate a form it\u2019s as simple as this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"$('form').validate();\n")),(0,a.kt)("p",null,"Or if you wanted to validate a single element:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"$('form').validate().element('elementSelector');\n")),(0,a.kt)("p",null,"Or if you wanted to prevent default form submission until validation was passed:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"$('form').submit(function (event) {\n  var isValid = $(this).validate().valid();\n\n  return isValid; //True will allow submission, false will not\n});\n")),(0,a.kt)("p",null,"See what I mean? Simple!"),(0,a.kt)("p",null,"If you want to read up on this further I recommend these links:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://bassistance.de/jquery-plugins/jquery-plugin-validation/"}),"The home of jQuery Validate")," ","-"," by the way it seems to be important to work with the latest version (1.9 at time of writing). I found some strange AJAX issues when using 1.7..."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://bradwilson.typepad.com/blog/2010/10/mvc3-unobtrusive-validation.html"}),"Brad Wilson's walkthrough of unobtrusive client validation")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://www.devtrends.co.uk/blog/the-complete-guide-to-validation-in-asp.net-mvc-3-part-2"}),"An example of how to implement your own custom validation both server side ","*","and","*"," client side")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://xhalent.wordpress.com/2011/01/24/applying-unobtrusive-validation-to-dynamic-content/"}),"How to apply unobtrusive jQuery validation to dynamic content")," ","-"," handy if you're creating HTML on the client which you want to be validated."),(0,a.kt)("li",{parentName:"ul"},"And finally, a workaround for ",(0,a.kt)("a",o({parentName:"li"},{href:"http://aspnet.codeplex.com/workitem/7629"}),"a bug in MVC 3")," which means that data attributes aren\u2019t emitted when using DropDownListFor for nested objects: ",(0,a.kt)("a",o({parentName:"li"},{href:"http://forums.asp.net/t/1649193.aspx/1/10"}),"http://forums.asp.net/t/1649193.aspx/1/10"),". In fact because I've only seen this on a forum I've copied and the pasted the code there to below because I feared it being lost: ",(0,a.kt)("strong",{parentName:"li"},"Update: It turns out the self-same issue exists for TextAreaFor as well. Details of this and a workaround can be found ",(0,a.kt)("a",o({parentName:"strong"},{href:"http://aspnet.codeplex.com/workitem/8576"}),"here"),"... "))),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'/// <summary>\n    /// MVC HtmlHelper extension methods - html element extensions\n    /// These are drop down list extensions that work round a bug in MVC 3: http://aspnet.codeplex.com/workitem/7629\n    /// These workarounds were taken from here: http://forums.asp.net/t/1649193.aspx/1/10\n    /// </summary>\n    public static class DropDownListExtensions\n    {\n        [SuppressMessage("Microsoft.Design", "CA1006:DoNotNestGenericTypesInMemberSignatures", Justification = "This is an appropriate nesting of generic types")]\n        public static MvcHtmlString SelectListFor<TModel, TProperty>(this HtmlHelper<TModel> htmlHelper, Expression<Func<TModel, TProperty>> expression, IEnumerable<SelectListItem> selectList)\n        {\n            return SelectListFor(htmlHelper, expression, selectList, null /* optionLabel */, null /* htmlAttributes */);\n        }\n\n\n        [SuppressMessage("Microsoft.Design", "CA1006:DoNotNestGenericTypesInMemberSignatures", Justification = "This is an appropriate nesting of generic types")]\n        public static MvcHtmlString SelectListFor<TModel, TProperty>(this HtmlHelper<TModel> htmlHelper, Expression<Func<TModel, TProperty>> expression, IEnumerable<SelectListItem> selectList, object htmlAttributes)\n        {\n            return SelectListFor(htmlHelper, expression, selectList, null /* optionLabel */, new RouteValueDictionary(htmlAttributes));\n        }\n\n\n        [SuppressMessage("Microsoft.Design", "CA1006:DoNotNestGenericTypesInMemberSignatures", Justification = "This is an appropriate nesting of generic types")]\n        public static MvcHtmlString SelectListFor<TModel, TProperty>(this HtmlHelper<TModel> htmlHelper, Expression<Func<TModel, TProperty>> expression, IEnumerable<SelectListItem> selectList, IDictionary<string, object> htmlAttributes)\n        {\n            return SelectListFor(htmlHelper, expression, selectList, null /* optionLabel */, htmlAttributes);\n        }\n\n\n        [SuppressMessage("Microsoft.Design", "CA1006:DoNotNestGenericTypesInMemberSignatures", Justification = "This is an appropriate nesting of generic types")]\n        public static MvcHtmlString SelectListFor<TModel, TProperty>(this HtmlHelper<TModel> htmlHelper, Expression<Func<TModel, TProperty>> expression, IEnumerable<SelectListItem> selectList, string optionLabel)\n        {\n            return SelectListFor(htmlHelper, expression, selectList, optionLabel, null /* htmlAttributes */);\n        }\n\n\n        [SuppressMessage("Microsoft.Design", "CA1006:DoNotNestGenericTypesInMemberSignatures", Justification = "This is an appropriate nesting of generic types")]\n        public static MvcHtmlString SelectListFor<TModel, TProperty>(this HtmlHelper<TModel> htmlHelper, Expression<Func<TModel, TProperty>> expression, IEnumerable<SelectListItem> selectList, string optionLabel, object htmlAttributes)\n        {\n            return SelectListFor(htmlHelper, expression, selectList, optionLabel, new RouteValueDictionary(htmlAttributes));\n        }\n\n\n        [SuppressMessage("Microsoft.Design", "CA1011:ConsiderPassingBaseTypesAsParameters", Justification = "Users cannot use anonymous methods with the LambdaExpression type")]\n        [SuppressMessage("Microsoft.Design", "CA1006:DoNotNestGenericTypesInMemberSignatures", Justification = "This is an appropriate nesting of generic types")]\n        public static MvcHtmlString SelectListFor<TModel, TProperty>(this HtmlHelper<TModel> htmlHelper, Expression<Func<TModel, TProperty>> expression, IEnumerable<SelectListItem> selectList, string optionLabel, IDictionary<string, object> htmlAttributes)\n        {\n            if (expression == null)\n            {\n                throw new ArgumentNullException("expression");\n            }\n\n\n            ModelMetadata metadata = ModelMetadata.FromLambdaExpression(expression, htmlHelper.ViewData);\n\n\n            IDictionary<string, object> validationAttributes = htmlHelper\n                .GetUnobtrusiveValidationAttributes(ExpressionHelper.GetExpressionText(expression), metadata);\n\n\n            if (htmlAttributes == null)\n                htmlAttributes = validationAttributes;\n            else\n                htmlAttributes = htmlAttributes.Concat(validationAttributes).ToDictionary(k => k.Key, v => v.Value);\n\n\n            return SelectExtensions.DropDownListFor(htmlHelper, expression, selectList, optionLabel, htmlAttributes);\n        }\n    }\n')))}d.isMDXComponent=!0},96120:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"closedxml-real-sdk-for-excel",title:"ClosedXML - the real SDK for Excel",authors:"johnnyreilly",tags:["Open XML","Excel","ClosedXML"],hide_table_of_contents:!1},s=void 0,l={permalink:"/closedxml-real-sdk-for-excel",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-08-16-closedxml-real-sdk-for-excel/index.md",source:"@site/blog/2012-08-16-closedxml-real-sdk-for-excel/index.md",title:"ClosedXML - the real SDK for Excel",description:"Simplicity appeals to me. It always has. Something that is simple is straightforward to comprehend and is consequently easy to use. It's clarity.",date:"2012-08-16T00:00:00.000Z",formattedDate:"August 16, 2012",tags:[{label:"Open XML",permalink:"/tags/open-xml"},{label:"Excel",permalink:"/tags/excel"},{label:"ClosedXML",permalink:"/tags/closed-xml"}],readingTime:3.745,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"closedxml-real-sdk-for-excel",title:"ClosedXML - the real SDK for Excel",authors:"johnnyreilly",tags:["Open XML","Excel","ClosedXML"],hide_table_of_contents:!1},prevItem:{title:"How to attribute encode a PartialView in MVC (Razor)",permalink:"/how-to-attribute-encode-partialview-in"},nextItem:{title:"jQuery Unobtrusive Validation (+ associated gotchas)",permalink:"/jquery-unobtrusive-validation"}},p={authorsImageUrls:[void 0]},u=[{value:"Open XML",id:"open-xml",level:2},{value:"Closed XML - Open XML&#39;s DbContext",id:"closed-xml---open-xmls-dbcontext",level:2},{value:"Support - This is how it should be done!",id:"support---this-is-how-it-should-be-done",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Simplicity appeals to me. It always has. Something that is simple is straightforward to comprehend and is consequently easy to use. It's clarity."),(0,a.kt)("h2",o({},{id:"open-xml"}),"Open XML"),(0,a.kt)("p",null,"So imagine my joy when I first encountered ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/office/bb265236.aspx"}),"Open XML"),". In Microsofts own words:"),(0,a.kt)("p",null,'ECMA Office Open XML ("Open XML") is an international, open standard for word-processing documents, presentations, and spreadsheets that can be freely implemented by multiple applications on multiple platforms.'),(0,a.kt)("p",null,"What does that actually mean? Well, from my perspective in the work I was doing I needed to be able to programmatically interact with Excel documents from C#. I needed to be able to create spreadsheets, to use existing template spreadsheets which I could populate dynamically in code. I needed to do Excel. And according to Microsoft, the Open XML SDK was how I did this."),(0,a.kt)("p",null,"What can I say about it? Open XML works. The API functions. You can use this to achieve your aims; and I did (initially). However, there's a but and it's this: it became quickly apparent just how hard Open XML makes you work to achieve relatively simple goals. Things that ought to be, in my head, a doddle require reams and reams of obscure code. Sadly, I feel that Open XML is probably the most frustrating API that I have yet encountered (and I've coded against the old school Lotus Notes API)."),(0,a.kt)("h2",o({},{id:"closed-xml---open-xmls-dbcontext"}),"Closed XML - Open XML's DbContext"),(0,a.kt)("p",null,"As I've intimated I found Open XML to be enormously frustrating. I'd regularly find myself thinking I'd achieved my goal. I may have written War and Peace code-wise but it compiled, it looked right - the end was in sight. More fool me. I'd run, sit back watch my Excel doc get created / updated / whatever. Then I'd open it and be presented with some obscure error about a corrupt file. Not great."),(0,a.kt)("p",null,"As I was Googling around looking for answers to my problem that I discovered an open source project on CodePlex called ",(0,a.kt)("a",o({parentName:"p"},{href:"http://closedxml.codeplex.com/"}),"Closed XML"),". I wasn't alone in frustrations with Open XML - there were many of us sharing the same opinion. And some fantastic person had stepped into the breach to save us! In ClosedXMLs own words:"),(0,a.kt)("p",null,"ClosedXML makes it easier for developers to create Excel 2007/2010 files. It provides a nice object oriented way to manipulate the files (similar to VBA) without dealing with the hassles of XML Documents. It can be used by any .NET language like C# and Visual Basic (VB)."),(0,a.kt)("p",null,"Hallelujah!!!"),(0,a.kt)("p",null,"The way it works (as far as I understand) is that ClosedXML sits on top of Open XML and exposes a really straightforward API for you to interact with. I haven't looked into the guts of it but my guess is that it internally uses Open XML to achieve this (as to use ClosedXML you must reference DocumentFormat.OpenXml.dll)."),(0,a.kt)("p",null,"I've found myself thinking of ClosedXML's relationship to Open XML in the same way as I think about Entity Frameworks DbContexts relationship to ObjectContext. They do the same thing but the former in both cases offers a better API. They makes achieving the same goals ","*",(0,a.kt)("strong",{parentName:"p"},"much"),"*"," easier. (Although in fairness to the EF team I should say that ObjectContext was not particularly problematic to use; just DbContext made life even easier.)"),(0,a.kt)("h2",o({},{id:"support---this-is-how-it-should-be-done"}),"Support - This is how it should be done!"),(0,a.kt)("p",null,"Shortly after I started using ClosedXML I was asked if we could use it to perform a certain task. I tested. We couldn't."),(0,a.kt)("p",null,"When I discovered this ",(0,a.kt)("a",o({parentName:"p"},{href:"http://closedxml.codeplex.com/workitem/8174"}),"I raised a ticket")," against the project asking if the functionality was likely to be added at any point. I honestly didn't expect to hear back any time soon and was mentally working out ways to get round the issue for now."),(0,a.kt)("p",null,"To my surprise within ",(0,a.kt)("em",{parentName:"p"},"5 hours"),(0,a.kt)("a",o({parentName:"p"},{href:"http://www.codeplex.com/site/users/view/MDeLeon"}),"MDeLeon")," the developer behind ClosedXML had released a patch to the source code! By any stretch of the imagination that is fast! As it happened there were a few bugs that needed ironing out and over the course of the next 3 working days MDeLeon performed a number of fixes and left me quickly in the position of having a version of ClosedXML which allowed me to achieve my goal."),(0,a.kt)("p",null,"So this blog post exists in part to point anyone who is battling Open XML to ClosedXML. It's brilliant, well documented and I'd advise anyone to use it. You won't be disappointed. And in part I wanted to say thanks and well done to MDeLeon who quite made my week! Thank you!"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"http://closedxml.codeplex.com/"}),"http://closedxml.codeplex.com/")))}d.isMDXComponent=!0},14293:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"how-to-attribute-encode-partialview-in",title:"How to attribute encode a PartialView in MVC (Razor)",authors:"johnnyreilly",tags:["asp.net mvc","razor"],hide_table_of_contents:!1},s=void 0,l={permalink:"/how-to-attribute-encode-partialview-in",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-08-24-how-to-attribute-encode-partialview-in/index.md",source:"@site/blog/2012-08-24-how-to-attribute-encode-partialview-in/index.md",title:"How to attribute encode a PartialView in MVC (Razor)",description:"This post is plagiarism. But I'm plagiarising myself so I don't feel too bad.",date:"2012-08-24T00:00:00.000Z",formattedDate:"August 24, 2012",tags:[{label:"asp.net mvc",permalink:"/tags/asp-net-mvc"},{label:"razor",permalink:"/tags/razor"}],readingTime:3.19,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"how-to-attribute-encode-partialview-in",title:"How to attribute encode a PartialView in MVC (Razor)",authors:"johnnyreilly",tags:["asp.net mvc","razor"],hide_table_of_contents:!1},prevItem:{title:"Globalize and jQuery Validation",permalink:"/globalize-and-jquery-validate"},nextItem:{title:"ClosedXML - the real SDK for Excel",permalink:"/closedxml-real-sdk-for-excel"}},p={authorsImageUrls:[void 0]},u=[{value:"The Question",id:"the-question",level:2},{value:"The Answer",id:"the-answer",level:2},{value:"Final thoughts",id:"final-thoughts",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This post is plagiarism. But I'm plagiarising myself so I don't feel too bad."),(0,a.kt)("p",null,"I posted a ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/q/12093005/761388"}),"question")," on StackOverflow recently asking if there was a simple way to attribute encode a PartialView in Razor / ASP.NET MVC. I ended up answering my own question and since I thought it was a useful solution it might be worth sharing."),(0,a.kt)("h2",o({},{id:"the-question"}),"The Question"),(0,a.kt)("p",null,"In the project I was working on I was using PartialViews to store the HTML that would be rendered in a tooltip in my ASP.NET MVC application. (In case you're curious I was using the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://jquerytools.org/demos/tooltip/index.html"}),"jQuery Tools library for my tooltip")," effect.)"),(0,a.kt)("p",null,"I had thought that Razor, clever beast that it is, would automatically attribute encode anything sat between quotes in my HTML. Unfortunately this doesn't appear to be the case. In the short term I was able to workaround this by using single quotation marks to encapsulate my PartialViews HTML. See below for an example:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<div class="tooltip"\n     title=\'@Html.Partial("_MyTooltipInAPartial")\'>\n    Some content\n</div>\n')),(0,a.kt)("p",null,"Now this worked just fine but I was aware that if any PartialView needed to use single quotation marks I would have a problem. Let's say for a moment that ",(0,a.kt)("inlineCode",{parentName:"p"},"_MyTooltipInAPartial.cshtml")," contained this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<span style="color:green">fjkdsjf\'lksdjdlks</span>\n')),(0,a.kt)("p",null,"Well when I used my handy little single quote workaround, the following would result:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<div class="tooltip"\n     title=\'<span style="color:green">fjkdsjf\'lksdjdlks</span>\'>\n    Some content\n</div>\n')),(0,a.kt)("p",null,"Which although it doesn't show up so well in the code sample above is definite ",(0,a.kt)("em",{parentName:"p"},'"does not compute, does not compute, does not compute ',"*","LOUD EXPLOSION","*",'"')," territory."),(0,a.kt)("h2",o({},{id:"the-answer"}),"The Answer"),(0,a.kt)("p",null,"This took me back to my original intent which was to encapsulate the HTML in double quotes like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<div class="tooltip"\n     title="@Html.Partial("_MyTooltipInAPartial")">\n    Some content\n</div>\n')),(0,a.kt)("p",null,"Though with the example discussed above we clearly had a problem whether we used single or double quotes. What to do?"),(0,a.kt)("p",null,"Well the answer wasn't too complicated. After a little pondering I ended up scratching my own itch by writing an HTML helper method called ",(0,a.kt)("inlineCode",{parentName:"p"},"PartialAttributeEncoded")," which made use of ",(0,a.kt)("inlineCode",{parentName:"p"},"HttpUtility.HtmlAttributeEncode")," to HTML attribute encode a PartialView."),(0,a.kt)("p",null,"Here's the code:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System.Web;\nusing System.Web.Mvc;\nusing System.Web.Mvc.Html;\n\nnamespace My.Helpers\n{\n    /// <summary>\n    /// MVC HtmlHelper extension methods - html element extensions\n    /// </summary>\n    public static class PartialExtensions\n    {\n        /// <summary>\n        /// Allows a partial to be rendered within quotation marks.\n        /// I use this with jQuery tooltips where we store the tooltip HMTL within a partial.\n        /// See example usage below:\n        /// <div class="tooltip" title="@Html.PartialAttributeEncoded("_MyTooltipInAPartial")">Some content</div>\n        /// </summary>\n        /// <param name="helper"></param>\n        /// <param name="partialViewName"></param>\n        /// <param name="model"></param>\n        /// <returns></returns>\n        public static MvcHtmlString PartialAttributeEncoded(\n          this HtmlHelper helper,\n          string partialViewName,\n          object model = null\n        )\n        {\n            //Create partial using the relevant overload (only implemented ones I used)\n            var partialString = (model == null)\n                ? helper.Partial(partialViewName)\n                : helper.Partial(partialViewName, model);\n\n            //Attribute encode the partial string - note that we have to .ToString() this to get back from an MvcHtmlString\n            var partialStringAttributeEncoded = HttpUtility.HtmlAttributeEncode(partialString.ToString());\n\n            //Turn this back into an MvcHtmlString\n            var partialMvcStringAttributeEncoded = MvcHtmlString.Create(partialStringAttributeEncoded);\n\n            return partialMvcStringAttributeEncoded;\n        }\n    }\n}\n')),(0,a.kt)("p",null,"Using the above helper is simplicity itself:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<div class="tooltip"\n     title="@Html.PartialAttributeEncoded("_MyTooltipInAPartial")">\n    Some content\n</div>\n')),(0,a.kt)("p",null,"And, given the example I've been going through, it would provide you with this output:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<div class="tooltip"\n     title="&lt;span style=&quot;color:green&quot;>fjkdsjf&#39;lksdjdlks</span>">\n    Some content\n</div>\n')),(0,a.kt)("p",null,"Now the HTML in the title attribute above might be an unreadable mess - but it's the unreadable mess you need. That's what the HTML we've been discussing looks like when it's been encoded."),(0,a.kt)("h2",o({},{id:"final-thoughts"}),"Final thoughts"),(0,a.kt)("p",null,"I was surprised that Razor didn't handle this out of the box. I wonder if this is something that will come along with a later version? It's worth saying that I experienced this issue when working on an MVC 3 application. It's possible that this issue may actually have been solved with MVC 4 already; I haven't had chance to check yet though."))}d.isMDXComponent=!0},24955:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"globalize-and-jquery-validate",title:"Globalize and jQuery Validation",authors:"johnnyreilly",tags:["asp.net mvc","Globalize","jQuery Validation"],hide_table_of_contents:!1},s=void 0,l={permalink:"/globalize-and-jquery-validate",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-09-06-globalize-and-jquery-validate/index.md",source:"@site/blog/2012-09-06-globalize-and-jquery-validate/index.md",title:"Globalize and jQuery Validation",description:"Updated 05/10/2015",date:"2012-09-06T00:00:00.000Z",formattedDate:"September 6, 2012",tags:[{label:"asp.net mvc",permalink:"/tags/asp-net-mvc"},{label:"Globalize",permalink:"/tags/globalize"},{label:"jQuery Validation",permalink:"/tags/j-query-validation"}],readingTime:5.49,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"globalize-and-jquery-validate",title:"Globalize and jQuery Validation",authors:"johnnyreilly",tags:["asp.net mvc","Globalize","jQuery Validation"],hide_table_of_contents:!1},prevItem:{title:"Giving OData to CRM 4.0",permalink:"/giving-odata-to-crm-40"},nextItem:{title:"How to attribute encode a PartialView in MVC (Razor)",permalink:"/how-to-attribute-encode-partialview-in"}},p={authorsImageUrls:[void 0]},u=[{value:"Updated 05/10/2015",id:"updated-05102015",level:2},{value:"Updated 27/08/2013",id:"updated-27082013",level:2},{value:"Background",id:"background",level:2},{value:"jQuery Global is dead... Long live Globalize!",id:"jquery-global-is-dead-long-live-globalize",level:2},{value:"Wait, where&#39;s <code>html lang</code> getting set?",id:"wait-wheres-html-lang-getting-set",level:2},{value:"Serving up the right Globalize culture files",id:"serving-up-the-right-globalize-culture-files",level:2},{value:"Putting it all together",id:"putting-it-all-together",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"updated-05102015"}),"Updated 05/10/2015"),(0,a.kt)("p",null,"If you're after a version of this that works with Globalize 1.x then take a look ",(0,a.kt)("a",o({parentName:"p"},{href:"/jquery-validation-globalize-hits-10"}),"here"),"."),(0,a.kt)("h2",o({},{id:"updated-27082013"}),"Updated 27/08/2013"),(0,a.kt)("p",null,"To make it easier for people to use the approach detailed in this post I have created a repository for ",(0,a.kt)("inlineCode",{parentName:"p"},"jquery.validate.globalize.js")," on GitHub ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/jquery-validation-globalize"}),"here"),"."),(0,a.kt)("p",null,"This is also available as a nuget package ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.nuget.org/packages/jQuery.Validation.Globalize/"}),"here"),"."),(0,a.kt)("p",null,"To see a good demo take a look ",(0,a.kt)("a",o({parentName:"p"},{href:"http://jqueryvalidationunobtrusivenative.azurewebsites.net/AdvancedDemo/Globalize"}),"here"),"."),(0,a.kt)("h2",o({},{id:"background"}),"Background"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"/globalizejs-number-and-date"}),"I've written before about a great little library called Globalize")," which makes locale specific number / date formatting simple within JavaScript. And I've just stumbled upon an ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.hanselman.com/blog/GlobalizationInternationalizationAndLocalizationInASPNETMVC3JavaScriptAndJQueryPart1.aspx"}),"old post written by Scott Hanselman about the business of Globalisation / Internationalisation / Localisation within ASP.NET"),". It's a great post and I recommend reading it (I'm using many of the approaches he discusses)."),(0,a.kt)("h2",o({},{id:"jquery-global-is-dead-long-live-globalize"}),"jQuery Global is dead... Long live Globalize!"),(0,a.kt)("p",null,"However, there's one tweak I would make to Scotts suggestions and that's to use Globalize in place of the jQuery Global plugin. The jQuery Global plugin has now effectively been reborn as Globalize (with no dependancy on jQuery). As far as I can tell jQuery Global is now disappearing from the web - certainly the link in Scotts post is dead now at least. I've ",(0,a.kt)("del",{parentName:"p"},"ripped off"),' been inspired by the "Globalized jQuery Unobtrusive Validation" section of Scotts article and made ',(0,a.kt)("inlineCode",{parentName:"p"},"jquery.validate.globalize.js"),"."),(0,a.kt)("p",null,"And for what it's worth ",(0,a.kt)("inlineCode",{parentName:"p"},"jquery.validate.globalize.js")," applies equally to standard jQuery Validation as well as to jQuery Unobtrusive Validation. I say that as the above JavaScript is effectively a monkey patch to the number / date / range / min / max methods of jQuery.validate.js which forces these methods to use Globalize's parsing support instead."),(0,a.kt)("p",null,"Here's the JavaScript:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"(function ($, Globalize) {\n  // Clone original methods we want to call into\n  var originalMethods = {\n    min: $.validator.methods.min,\n    max: $.validator.methods.max,\n    range: $.validator.methods.range,\n  };\n\n  // Tell the validator that we want numbers parsed using Globalize\n\n  $.validator.methods.number = function (value, element) {\n    var val = Globalize.parseFloat(value);\n    return this.optional(element) || $.isNumeric(val);\n  };\n\n  // Tell the validator that we want dates parsed using Globalize\n\n  $.validator.methods.date = function (value, element) {\n    var val = Globalize.parseDate(value);\n    return this.optional(element) || val;\n  };\n\n  // Tell the validator that we want numbers parsed using Globalize,\n  // then call into original implementation with parsed value\n\n  $.validator.methods.min = function (value, element, param) {\n    var val = Globalize.parseFloat(value);\n    return originalMethods.min.call(this, val, element, param);\n  };\n\n  $.validator.methods.max = function (value, element, param) {\n    var val = Globalize.parseFloat(value);\n    return originalMethods.max.call(this, val, element, param);\n  };\n\n  $.validator.methods.range = function (value, element, param) {\n    var val = Globalize.parseFloat(value);\n    return originalMethods.range.call(this, val, element, param);\n  };\n})(jQuery, Globalize);\n\n$(document).ready(function () {\n  // Set Globalize to the current culture driven by the html lang property\n  var currentCulture = $('html').prop('lang');\n  if (currentCulture) {\n    Globalize.culture(currentCulture);\n  }\n});\n")),(0,a.kt)("p",null,"The above script does 2 things. Firstly it monkey patches jquery.validate.js to make use of Globalize.js number and date parsing in place of the defaults. Secondly it initialises Globalize to relevant current culture driven by the ",(0,a.kt)("inlineCode",{parentName:"p"},"html lang")," property. So if the html tag looked like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<html lang="de-DE">\n  ...\n</html>\n')),(0,a.kt)("p",null,'Then Globalize would be initialised with the "de-DE" culture assuming that culture was available and had been served up to the client. (By the way, the Globalize initialisation logic has only been placed in the code above to demonstrate that Globalize needs to be initialised to the culture. It\'s more likely that this initialisation step would sit elsewhere in a "proper" app.)'),(0,a.kt)("h2",o({},{id:"wait-wheres-html-lang-getting-set"}),"Wait, where's ",(0,a.kt)("inlineCode",{parentName:"h2"},"html lang")," getting set?"),(0,a.kt)("p",null,"In Scott's article he created a ",(0,a.kt)("inlineCode",{parentName:"p"},"MetaAcceptLanguage")," helper to generate a META tag like this: ",(0,a.kt)("inlineCode",{parentName:"p"},'&lt;meta name="accept-language" content="en-GB" /&gt;')," which he used to drive Globalizes specified culture."),(0,a.kt)("p",null,"Rather than generating a meta tag I've chosen to use the ",(0,a.kt)("inlineCode",{parentName:"p"},"lang")," attribute of the ",(0,a.kt)("inlineCode",{parentName:"p"},"html")," tag to specify the culture. I've chosen to do this as it's more in line with the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.w3.org/TR/i18n-html-tech-lang/#ri20030510.102829377"}),"W3C spec"),". But it should be noted this is just a different way of achieving exactly the same end."),(0,a.kt)("p",null,"So how's it getting set? Well, it's no great shakes; in my ",(0,a.kt)("inlineCode",{parentName:"p"},"_Layout.cshtml")," file my html tag looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<html lang="@System.Globalization.CultureInfo.CurrentUICulture.Name"></html>\n')),(0,a.kt)("p",null,"And in my ",(0,a.kt)("inlineCode",{parentName:"p"},"web.config")," I have following setting set:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<configuration>\n  <system.web>\n    <globalization culture="auto" uiCulture="auto" />\n    \x3c!--- Other stuff.... --\x3e\n  </system.web>\n</configuration>\n')),(0,a.kt)("p",null,"With both of these set this means I get ",(0,a.kt)("inlineCode",{parentName:"p"},'&lt;html lang="de-DE"&gt;')," or ",(0,a.kt)("inlineCode",{parentName:"p"},'&lt;html lang="en-GB"&gt;')," etc. depending on a users culture."),(0,a.kt)("h2",o({},{id:"serving-up-the-right-globalize-culture-files"}),"Serving up the right Globalize culture files"),(0,a.kt)("p",null,"In order that I send the correct Globalize culture to the client I've come up with this static class which provides the user with the relevant culture URL (falling back to the en-GB culture if it can't find one based your culture):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Web;\nusing System.Web.Hosting;\nusing System.IO;\nusing System.Globalization;\n\nnamespace My.Helpers\n{\n    /// <summary>\n    /// Static class that is a store for commonly used filenames\n    /// (so if the files are updated they only need to be amended in a single place)\n    /// </summary>\n    public static class GlobalizeUrls\n    {\n\n        /// <summary>\n        /// URL for Globalize: https://github.com/jquery/globalize\n        /// </summary>\n        public static string Globalize { get { return "~/Scripts/globalize.js"; } }\n\n        /// <summary>\n        /// URL for the specific Globalize culture\n        /// </summary>\n        public static string GlobalizeCulture\n        {\n            get\n            {\n                //Determine culture - GUI culture for preference, user selected culture as fallback\n                var currentCulture = CultureInfo.CurrentCulture;\n                var filePattern = "~/scripts/globalize/globalize.culture.{0}.js";\n                var regionalisedFileToUse = string.Format(filePattern, "en-GB"); //Default localisation to use\n\n                //Try to pick a more appropriate regionalisation\n                if (File.Exists(HostingEnvironment.MapPath(string.Format(filePattern, currentCulture.Name)))) //First try for a globalize.culture.en-GB.js style file\n                    regionalisedFileToUse = string.Format(filePattern, currentCulture.Name);\n                else if (File.Exists(HostingEnvironment.MapPath(string.Format(filePattern, currentCulture.TwoLetterISOLanguageName)))) //That failed; now try for a globalize.culture.en.js style file\n                    regionalisedFileToUse = string.Format(filePattern, currentCulture.TwoLetterISOLanguageName);\n\n                return regionalisedFileToUse;\n            }\n        }\n    }\n}\n')),(0,a.kt)("h2",o({},{id:"putting-it-all-together"}),"Putting it all together"),(0,a.kt)("p",null,"To make use of all of this together you'll need to have the ",(0,a.kt)("inlineCode",{parentName:"p"},"html lang")," attribute set as described earlier and some scripts output in your layout page like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<script src="@Url.Content("~/Scripts/jquery.js")" type="text/javascript"><\/script>\n<script src="@Url.Content(GlobalizeUrls.Globalize)" type="text/javascript"><\/script>\n<script src="@Url.Content(GlobalizeUrls.GlobalizeCulture)" type="text/javascript"><\/script>\n<script src="@Url.Content("~/Scripts/jquery.validate.js")" type="text/javascript"><\/script>\n<script src="@Url.Content("~/scripts/jquery.validate.globalize.js")" type="text/javascript"><\/script>\n\n@* Only serve the following script if you need it: *@\n<script src="@Url.Content("~/scripts/jquery.validate.unobtrusive.js")" type="text/javascript"><\/script>\n')),(0,a.kt)("p",null,"Which will render something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<script src="/Scripts/jquery.js" type="text/javascript"><\/script>\n<script src="/Scripts/globalize.js" type="text/javascript"><\/script>\n<script\n  src="/scripts/globalize/globalize.culture.en-GB.js"\n  type="text/javascript"\n><\/script>\n<script src="/Scripts/jquery.validate.js" type="text/javascript"><\/script>\n<script\n  src="/Scripts/jquery.validate.globalize.js"\n  type="text/javascript"\n><\/script>\n<script\n  src="/Scripts/jquery.validate.unobtrusive.js"\n  type="text/javascript"\n><\/script>\n')),(0,a.kt)("p",null,"This will load up jQuery, Globalize, your Globalize culture, jQuery Validate, jQuery Validates unobtrusive extensions (which you don't need if you're not using them) and the jQuery Validate Globalize script which will set up culture aware validation."),(0,a.kt)("p",null,"Finally and just to re-iterate, it's highly worthwhile to give ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.hanselman.com/blog/GlobalizationInternationalizationAndLocalizationInASPNETMVC3JavaScriptAndJQueryPart1.aspx"}),"Scott Hanselman's original article a look"),". Most all the ideas in here were taken wholesale from him!"))}d.isMDXComponent=!0},17196:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"giving-odata-to-crm-40",title:"Giving OData to CRM 4.0",authors:"johnnyreilly",tags:["OData","WCF","CRM","LINQ"],hide_table_of_contents:!1},s=void 0,l={permalink:"/giving-odata-to-crm-40",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-09-24-giving-odata-to-crm-40/index.md",source:"@site/blog/2012-09-24-giving-odata-to-crm-40/index.md",title:"Giving OData to CRM 4.0",description:"Just recently I was tasked with seeing if we could provide a way to access our Dynamics CRM instance via OData. My initial investigations made it seem like there was nothing for me to do; CRM 2011 provides OData support out of the box. Small problem. We were running CRM 4.0.",date:"2012-09-24T00:00:00.000Z",formattedDate:"September 24, 2012",tags:[{label:"OData",permalink:"/tags/o-data"},{label:"WCF",permalink:"/tags/wcf"},{label:"CRM",permalink:"/tags/crm"},{label:"LINQ",permalink:"/tags/linq"}],readingTime:6.27,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"giving-odata-to-crm-40",title:"Giving OData to CRM 4.0",authors:"johnnyreilly",tags:["OData","WCF","CRM","LINQ"],hide_table_of_contents:!1},prevItem:{title:"Unit Testing and Entity Framework: The Filth and the Fury",permalink:"/unit-testing-and-entity-framework-filth"},nextItem:{title:"Globalize and jQuery Validation",permalink:"/globalize-and-jquery-validate"}},p={authorsImageUrls:[void 0]},u=[{value:"LINQ to CRM",id:"linq-to-crm",level:2},{value:"Make me an OData Service",id:"make-me-an-odata-service",level:2},{value:"Now, a warning...",id:"now-a-warning",level:2},{value:"Finishing off",id:"finishing-off",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Just recently I was tasked with seeing if we could provide a way to access our Dynamics CRM instance via OData. My initial investigations made it seem like there was nothing for me to do; ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/gg309461.aspx"}),"CRM 2011 provides OData support out of the box"),". Small problem. We were running CRM 4.0."),(0,a.kt)("p",null,"It could well have ended there apart from the fact that Microsoft makes it astonishingly easy to to create your own OData service using WCF Data Services. Because it's so straightforward I was able to get an OData solution for CRM 4.0 up and running with very little heavy lifting at all. Want to know how it's done?"),(0,a.kt)("h2",o({},{id:"linq-to-crm"}),"LINQ to CRM"),(0,a.kt)("p",null,"To start with you're going to need the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.microsoft.com/en-us/download/details.aspx?id=38"}),"CRM SDK 4.0"),'. This contains a "vanilla" LINQ to CRM client which is used in each of the example applications that can be found in ',(0,a.kt)("inlineCode",{parentName:"p"},"microsoft.xrm\\samples"),". We want this client (or something very like it) to use as the basis for our OData service."),(0,a.kt)("p",null,"In order to get a LINQ to CRM provider that caters for your own customised CRM instance you need to use the ",(0,a.kt)("inlineCode",{parentName:"p"},"crmsvcutil")," utility from the CRM SDK (found in the ",(0,a.kt)("inlineCode",{parentName:"p"},"microsoft.xrm\\tools\\")," directory). Detailed instructions on how to use this can be found in this Word document: ",(0,a.kt)("inlineCode",{parentName:"p"},"microsoft.xrm\\advanced_developer_extensions_-_developers_guide.docx"),". Extra information around the topic can be found using these links:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://msdn.microsoft.com/en-us/library/ff681559"}),"MSDN docs on xRM")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://msdn.microsoft.com/en-us/library/ff681573"}),"MSDN examples of LINQ queries")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://www.dynamicscrmtrickbag.com/"}),"CRM blog site")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://community.adxstudio.com/products/adxstudio-portals/developers-guide/archive/linq-to-crm-22/"}),"Another site listing examples of LINQ to CRM"))),(0,a.kt)("p",null,"You should end up with custom generated data context classes which look not dissimilar to similar classes that you may already have in place for Entity Framework etc. With your ",(0,a.kt)("inlineCode",{parentName:"p"},"Xrm.DataContext")," in hand (a subclass of ",(0,a.kt)("inlineCode",{parentName:"p"},"Microsoft.Xrm.Client.Data.Services.CrmDataContext"),") you'll be ready to move forwards."),(0,a.kt)("h2",o({},{id:"make-me-an-odata-service"}),"Make me an OData Service"),(0,a.kt)("p",null,"As I said, Microsoft makes it fantastically easy to get an OData service up and running. ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-US/library/dd728275"}),"In this example")," an entity context model is created from the Northwind database and then exposed as an OData service. To create my CRM OData service I followed a similar process. But rather than creating an entity context model using a database I plugged in the ",(0,a.kt)("inlineCode",{parentName:"p"},"Xrm.DataContext")," instance of CRM that we created a moment ago. These are the steps I followed to make my service:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},'Create a new ASP.NET Web Application called "CrmOData" (in case it\'s relevant I was using Visual Studio 2010 to do this).')),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Remove all ASPXs / JavaScript / CSS files etc leaving you with an essentially empty project.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Add references to the following DLLs that come with the SDK: - microsoft.crm.sdk.dll"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"microsoft.crm.sdktypeproxy.dll"),(0,a.kt)("li",{parentName:"ul"},"microsoft.crm.sdktypeproxy.xmlserializers.dll"),(0,a.kt)("li",{parentName:"ul"},"microsoft.xrm.client.dll"),(0,a.kt)("li",{parentName:"ul"},"microsoft.xrm.portal.dll"),(0,a.kt)("li",{parentName:"ul"},"microsoft.xrm.portal.files.dll"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Add the ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;microsoft.xrm.client&gt;")," config section to your web.config (not forgetting the associated Xrm connection string)")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Add this new file below to the root of the project:"))),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Collections.Generic;\nusing System.Data.Services;\nusing System.Data.Services.Common;\nusing System.Linq;\nusing System.Web;\nusing System.ServiceModel.Web;\nusing Microsoft.Xrm.Client;\nusing log4net;\n\nnamespace CrmOData\n{\n\n    /// <summary>\n    /// Exposes an OData service providing access to CRM\n    ///\n    /// Examples of how to use service.\n    ///\n    /// URI     : http://myWebServer/CrmOData/Crm.svc\n    /// Purpose : Demonstrates exposed endpoints\n    ///\n    /// URI     : http://myWebServer/CrmOData/Crm.svc/myCustomer\n    /// Purpose : Demonstrates how to retrieve all customers\n    ///\n    /// URI     : http://myWebServer/CrmOData/Crm.svc/myCustomer?$filter=lastName eq \'Reilly\'\n    /// Purpose : Demonstrates how to retrieve all customers with the Surname "Reilly"\n    ///\n    /// URI     : http://myWebServer/CrmOData/Crm.svc/myCustomer?$select=firstName,lastName\n    /// Output  : Does not work.\n    ///\n    /// "$select statements are not supported. This problem is being discussed\n    ///  here http://social.msdn.microsoft.com/Forums/en/adodotnetdataservices/thread/366086ee-dcef-496a-ad15-f461788ae678\n    ///  and is caused by the fact that CrmDataContext implements the IExpandProvider interface which in turn causes\n    ///  the DataService to lose support for $select projections"\n    ///\n    ///  See http://social.microsoft.com/Forums/en/crmdevelopment/thread/31daedb4-3d75-483a-8d7f-269af3375d74 for original post discussing this\n    ///\n    ///  URI     : http://myWebServer/CrmOData/Crm.svc/myCustomer(guid\'783323a1-b1f1-4910-b5be-a2f37e62d0ba\')/currentBalance\n    ///  Purpose : Retrieves the current balance of the customers account\n    ///\n    ///  URI     : http://myWebServer/CrmOData/Crm.svc/myCustomer(guid\'783323a1-b1f1-4910-b5be-a2f37e62d0ba\')/currentBalance/$value\n    ///  Output  : 321186905.8600\n    ///  Purpose : The raw value\n    ///\n    ///  URI     : http://myWebServer/CrmOData/Crm.svc/myCustomer(guid\'783323a1-b1f1-4910-b5be-a2f37e62d0ba\')?$expand=transactions\n    ///  Purpose : Retrieves a customer by their guid\'783323a1-b1f1-4910-b5be-a2f37e62d0ba\', with the transactions property expanded (the equivalent of Include in Entity Framework I guess)\n    /// </summary>\n    public class Crm : DataService< Xrm.DataContext >\n    {\n        private static ILog _log;\n\n        /// <summary>\n        /// Initialise the service (this method is called only once to initialize service-wide policies.)\n        /// </summary>\n        /// <param name="config"></param>\n        public static void InitializeService(DataServiceConfiguration config)\n        {\n            //Allows access to everything\n            config.SetEntitySetAccessRule("*", EntitySetRights.AllRead);\n            config.SetEntitySetPageSize("*", 10); //Only allow access to 10 items at a time - don\'t want to bring down CRM\n            config.SetServiceOperationAccessRule("*", ServiceOperationRights.AllRead);\n\n            config.DataServiceBehavior.MaxProtocolVersion = DataServiceProtocolVersion.V2;\n\n            // set cache policy to this page\n            HttpContext context = HttpContext.Current;\n            HttpCachePolicy cachePolicy = HttpContext.Current.Response.Cache;\n\n            // server&private: server and client side cache only - not at proxy servers\n            cachePolicy.SetCacheability(HttpCacheability.ServerAndPrivate);\n\n            // default cache expire: 60 seconds\n            cachePolicy.SetExpires(HttpContext.Current.Timestamp.AddSeconds(60));\n\n            // cached output depends on: accept, charset, encoding, and all parameters (like $filter, etc)\n            cachePolicy.VaryByHeaders["Accept"] = true;\n            cachePolicy.VaryByHeaders["Accept-Charset"] = true;\n            cachePolicy.VaryByHeaders["Accept-Encoding"] = true;\n            cachePolicy.VaryByParams["*"] = true;\n\n            //allow client to send Cache-Control: nocache headers to invalidate cache\n            cachePolicy.SetValidUntilExpires(false);\n\n            //Log service startup initialisation\n            _log = log4net.LogManager.GetLogger("Crm.svc");\n            _log.Info("Crm.svc initialising...");\n        }\n\n        /// <summary>\n        /// Allows the user to get the id of a specific CrmEntity given a supplied entity name\n        /// and a supplied predicate which consists of a propertyName and a string propertyValue (eg "112001-S").\n        ///\n        /// If there is a need for a predicate with different type of value (eg int / datetime / decimal)\n        /// then it could be introduced\n        ///\n        /// Example URI : http://myWebServer/CrmOData/Crm.svc/GetId?entityName=\'myCustomer\'&propertyName=\'customerNumber\'&propertyValue=\'23456KL-P\'\n        /// </summary>\n        /// <param name="entityName">eg "myCustomer"</param>\n        /// <param name="propertyName">eg "customerNumber"</param>\n        /// <param name="propertyValue">eg "23456KL-P"</param>\n        /// <returns></returns>\n        [WebGet]\n        public Guid? GetEntityId(string entityName, string propertyName, string propertyValue)\n        {\n            var entities = CurrentDataSource.GetEntities(entityName);\n\n            var entitiesWhere = entities.Where(x => (x.GetPropertyValue(propertyName) as string) == propertyValue);\n\n            var guid = entitiesWhere.Select(x => x.Id)\n                                    .SingleOrDefault();\n\n            return guid;\n        }\n\n        /// <summary>\n        /// Handle exceptions\n        /// </summary>\n        /// <param name="args"></param>\n        protected override void HandleException(HandleExceptionArgs args)\n        {\n            base.HandleException(args);\n\n            //Log all exceptions\n            _log.Error(string.Format("\\r\\nResponseContentType: {0}\\r\\nResponseStatusCode: {1}\\r\\nResponseWritten: {2}\\r\\nUser: {3}{4}",\n                args.ResponseContentType, args.ResponseStatusCode, args.ResponseWritten, HttpContext.Current.User.Identity.Name, args.Exception.GetExceptionDetails()),\n                args.Exception);\n        }\n    }\n}\n')),(0,a.kt)("p",null,"And that's it - done. When you run this web application you will find an OData service exposed at ",(0,a.kt)("inlineCode",{parentName:"p"},"http://localhost:12345/Crm.svc"),". You could have it even simpler if you wanted - you could pull out the logging that's in place and leave only the ",(0,a.kt)("inlineCode",{parentName:"p"},"InitializeService")," there. That's all you need. (The ",(0,a.kt)("inlineCode",{parentName:"p"},"GetEntityById")," method is a helper method of my own for identifying the GUIDs of CRM.)"),(0,a.kt)("p",null,"You may have noticed that I have made use of caching for my OData service following the steps I found ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.com/b/peter_qian/archive/2010/11/17/using-asp-net-output-caching-with-wcf-data-services.aspx"}),"here"),". Again you may or may not want to use this."),(0,a.kt)("h2",o({},{id:"now-a-warning"}),"Now, a warning..."),(0,a.kt)("p",null,"Okay - not so much a warning as a limitation. Whilst most aspects of the OData service work as you would hope there is no support for the $select operator. I had a frustrating time trying to discover why and then came upon this explanation:"),(0,a.kt)("p",null,(0,a.kt)("em",{parentName:"p"},'"$select statements are not supported. This problem is being discussed here ',(0,a.kt)("a",o({parentName:"em"},{href:"http://social.msdn.microsoft.com/Forums/en/adodotnetdataservices/thread/366086ee-dcef-496a-ad15-f461788ae678"}),"http://social.msdn.microsoft.com/Forums/en/adodotnetdataservices/thread/366086ee-dcef-496a-ad15-f461788ae678"),' and is caused by the fact that CrmDataContext implements the IExpandProvider interface which in turn causes the DataService to lose support for $select projections"')),(0,a.kt)("p",null,"You can also see ",(0,a.kt)("a",o({parentName:"p"},{href:"http://social.microsoft.com/Forums/en/crmdevelopment/thread/31daedb4-3d75-483a-8d7f-269af3375d74"}),"here")," for the original post discussing this."),(0,a.kt)("h2",o({},{id:"finishing-off"}),"Finishing off"),(0,a.kt)("p",null,"In the example I set out here I used the version of WCF Data Services that shipped with Visual Studio 2010. WCF Data Services now ships separately from the .NET Framework and you can ",(0,a.kt)("a",o({parentName:"p"},{href:"http://nuget.org/packages?q=wcf+data+services"}),"pick up the latest and greatest from Nuget"),". I understand that you could easily switch over to using the latest versions but since I didn't see any feature that I needed on this occasion I haven't."),(0,a.kt)("p",null,"I hope you find this useful."))}d.isMDXComponent=!0},41235:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"unit-testing-and-entity-framework-filth",title:"Unit Testing and Entity Framework: The Filth and the Fury",authors:"johnnyreilly",tags:["unit testing","Entity Framework","MOQ"],hide_table_of_contents:!1},s=void 0,l={permalink:"/unit-testing-and-entity-framework-filth",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-10-03-unit-testing-and-entity-framework-filth/index.md",source:"@site/blog/2012-10-03-unit-testing-and-entity-framework-filth/index.md",title:"Unit Testing and Entity Framework: The Filth and the Fury",description:"Just recently I've noticed that there appears to be something of a controversy around Unit Testing and Entity Framework. I first came across it as I was Googling around for useful posts on using MOQ in conjunction with EF. I've started to notice the topic more and more and as I have mixed feelings on the subject (that is to say I don't have a settled opinion) I thought I'd write about this and see if I came to any kind of conclusion...",date:"2012-10-03T00:00:00.000Z",formattedDate:"October 3, 2012",tags:[{label:"unit testing",permalink:"/tags/unit-testing"},{label:"Entity Framework",permalink:"/tags/entity-framework"},{label:"MOQ",permalink:"/tags/moq"}],readingTime:7.32,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"unit-testing-and-entity-framework-filth",title:"Unit Testing and Entity Framework: The Filth and the Fury",authors:"johnnyreilly",tags:["unit testing","Entity Framework","MOQ"],hide_table_of_contents:!1},prevItem:{title:"Using Web Optimization with MVC 3",permalink:"/using-web-optimization-with-mvc-3"},nextItem:{title:"Giving OData to CRM 4.0",permalink:"/giving-odata-to-crm-40"}},p={authorsImageUrls:[void 0]},u=[{value:"The Setup",id:"the-setup",level:2},{value:"Using the Repository / Unit of Work Patterns",id:"using-the-repository--unit-of-work-patterns",level:2},{value:"Or maybe I&#39;m wrong, maybe you can MOQ DbContext?",id:"or-maybe-im-wrong-maybe-you-can-moq-dbcontext",level:2},{value:"Here come the nagging doubts...",id:"here-come-the-nagging-doubts",level:2},{value:"1. Just because it compiles and passes unit tests don&#39;t imagine that means it works...",id:"1-just-because-it-compiles-and-passes-unit-tests-dont-imagine-that-means-it-works",level:3},{value:"2. Complex queries",id:"2-complex-queries",level:3},{value:"3. Lazy Loading",id:"3-lazy-loading",level:3},{value:"Where does this leave us?",id:"where-does-this-leave-us",level:2},{value:"Update",id:"update",level:2},{value:"Updated 2",id:"updated-2",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Just recently I've noticed that there appears to be something of a controversy around Unit Testing and Entity Framework. I first came across it as I was Googling around for useful posts on using MOQ in conjunction with EF. I've started to notice the topic more and more and as I have mixed feelings on the subject (that is to say I don't have a settled opinion) I thought I'd write about this and see if I came to any kind of conclusion..."),(0,a.kt)("h2",o({},{id:"the-setup"}),"The Setup"),(0,a.kt)("p",null,"It started as I was working on a new project. We were using ASP.NET MVC 3 and Entity Framework with DbContext as our persistence layer. Rather than crowbarring the tests in afterwards the intention was to write tests to support the ongoing development. Not quite test driven development but certainly ",(0,a.kt)("a",o({parentName:"p"},{href:"http://blog.troyd.net/Test+Supported+Development+TSD+Is+NOT+Test+Driven+Development+TDD.aspx"}),"test supported development"),". (Let's not get into the internecine conflict as to whether this is black belt testable code or not - it isn't but he who pays the piper etc.) Oh and we were planning to use MOQ as our mocking library."),(0,a.kt)("p",null,"It was the first time I'd used DbContext rather than ObjectContext and so I thought I'd do a little research on how people were using DbContext with regards to testability. I had expected to find that there was some kind of consensus and an advised way forwards. I didn't get that at all. Instead I found a number of conflicting opinions."),(0,a.kt)("h2",o({},{id:"using-the-repository--unit-of-work-patterns"}),"Using the Repository / Unit of Work Patterns"),(0,a.kt)("p",null,"One thread of advice that came out was that people advised using the Repository / Unit of Work patterns as wrappers when it came to making testable code. This is kind of interesting in itself as to the best of my understanding ObjectSet / ObjectContext and DbSet / DbContext are both in themselves implementations of the Repository / Unit of Work patterns. So the advice was to build a Repository / Unit of Work pattern to wrap an existing Repository / Unit of Work pattern."),(0,a.kt)("p",null,"Not as mad as it sounds. The reason for the extra abstraction is that ObjectContext / DbContext in the raw are not MOQ-able."),(0,a.kt)("h2",o({},{id:"or-maybe-im-wrong-maybe-you-can-moq-dbcontext"}),"Or maybe I'm wrong, maybe you can MOQ DbContext?"),(0,a.kt)("p",null,"No you can't. Well that's not true. You can and it's documented ",(0,a.kt)("a",o({parentName:"p"},{href:"http://romiller.com/2012/02/14/testing-with-a-fake-dbcontext/"}),"here")," but there's a \"but\". You need to be using Entity Frameworks Code First approach; actually coding up your DbContext yourself. Before I'd got on board the project had already begun and we were already some way down the road of using the Database First approach. So this didn't seem to be a go-er really."),(0,a.kt)("p",null,"The best article I found on testability and Entity Framework was ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/ff714955.aspx"}),"this one")," by ",(0,a.kt)("a",o({parentName:"p"},{href:"http://odetocode.com/"}),"K. Scott Allen")," which essentially detailed how you could implement the Repository / Unit of Work patterns on top of ObjectSet / ObjectContext. In the end I adapted this to do the same thing sat on top of DbSet / DbContext instead."),(0,a.kt)("p",null,"With this in place I had me my testable code. I was quite happy with this as it seemed quite intelligible. My new approach looked similar to the existing DbSet / DbContext code and so there wasn't a great deal of re-writing to do. Sorted, right?"),(0,a.kt)("h2",o({},{id:"here-come-the-nagging-doubts"}),"Here come the nagging doubts..."),(0,a.kt)("p",null,"I did wonder, given that I found a number of articles about applying the Repository / Unit of Work patterns on top of ObjectSet / ObjectContext that there didn't seem to be many examples to do the same for DbSet / DbContext. (I did find a few examples of this but none that felt satisfactory to me for a variety of reasons.) This puzzled me."),(0,a.kt)("p",null,"I also started to notice that a 1 man war was being waged against the approach I was using by ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.ladislavmrnka.com/about/"}),"Ladislav Mrnka"),". Here are a couple of examples of his crusade:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://stackoverflow.com/a/6904479/761388"}),"An answer on StackOverflow")," (there's quite a few similar answers around on StackOverflow saying similar)"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"http://romiller.com/2012/02/14/testing-with-a-fake-dbcontext/#div-comment-1620"}),"A comment on Rowan Millers post about fake DbContexts"))),(0,a.kt)("p",null,"Ladislav is quite strongly of the opinion that wrapping DbSet / DbContext (and I presume ObjectSet / ObjectContext too) in a further Repository / Unit of Work is an antipattern. To quote him: ",(0,a.kt)("em",{parentName:"p"},'"The reason why I don\u2019t like it is leaky abstraction in Linq-to-entities queries ... In your test you have Linq-to-Objects which is superset of Linq-to-entities and only subset of queries written in L2O is translatable to L2E"'),". It's worth looking at ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.youtube.com/watch?v=gNeSZYke-_Q"}),'Jon Skeets explanation of "leaky abstractions"')," which he did for TekPub."),(0,a.kt)("p",null,"As much as I didn't want to admit it - I have come to the conclusion Ladislav probably has a point for a number of reasons:"),(0,a.kt)("h3",o({},{id:"1-just-because-it-compiles-and-passes-unit-tests-dont-imagine-that-means-it-works"}),"1","."," Just because it compiles and passes unit tests don't imagine that means it works..."),(0,a.kt)("p",null,"Unfortunately, a LINQ query that looks right, compiles and has passing unit tests written for it doesn't necessarily work. You can take a query that fails when executed against Entity Framework and come up with test data that will pass that unit test. As Ladislav rightly points out: ",(0,a.kt)("inlineCode",{parentName:"p"},"LINQ-to-Objects != LINQ-to-Entities"),"."),(0,a.kt)("p",null,"So in this case unit tests of this sort don't provide you with any security. What you need are ","*","*",(0,a.kt)("u",null,"integration")),(0,a.kt)("p",null,"*","*"," tests. Tests that run against an instance of the database and demonstrate that LINQ will actually translate queries / operations into valid SQL."),(0,a.kt)("h3",o({},{id:"2-complex-queries"}),"2","."," Complex queries"),(0,a.kt)("p",null,"You can write some pretty complex LINQ queries if you want. This is made particularly easy if you're using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.com/b/ericlippert/archive/2009/12/07/query-transformations-are-syntactic.aspx"}),"comprehension syntax"),". Whilst these queries may be simple to write it can be uphill work to generate test data to satisfy this. So much so that at times it can feel you've made a rod for your own back using this approach."),(0,a.kt)("h3",o({},{id:"3-lazy-loading"}),"3","."," Lazy Loading"),(0,a.kt)("p",null,"By default Entity Framework employs lazy loading. This a useful approach which reduces the amount of data that is transported. Sometimes this approach forces you to specify up front if you require a particular entity through use of ",(0,a.kt)("inlineCode",{parentName:"p"},"Include")," statements. This again doesn't lend itself to testing particularly well."),(0,a.kt)("h2",o({},{id:"where-does-this-leave-us"}),"Where does this leave us?"),(0,a.kt)("p",null,"Having considered all of the above for a while and tried out various different approaches I think I'm coming to the conclusion that Ladislav is probably right. Implementing the Repository / Unit of Work patterns on top of ObjectSet / ObjectContext or DbSet / DbContext doesn't seem a worthwhile effort in the end."),(0,a.kt)("p",null,"So what's a better idea? I think that in the name of simplicity you might as well have a simple class which wraps all of your Entity Framework code. This class could implement an interface and hence be straightforwardly MOQ-able (or alternatively all methods could be virtual and you could forego the interface). Along with this you should have integration tests in place which test the execution of the actual Entity Framework code against a test database."),(0,a.kt)("p",null,"Now I should say this approach is not necessarily my final opinion. It seems sensible and practical. I think it is likely to simplify the tests that are written around a project. It will certainly be more reliable than just having unit tests in place."),(0,a.kt)("p",null,"In terms of the project I'm working on at the moment we're kind of doing this in a halfway house sense. That is to say, we're still using our Repository / Unit of Work wrappers for DbSet / DbContext but where things move away from simple operations we're adding extra methods to our Unit of Work class or Repository classes which wrap this functionality and then testing it using our integration tests."),(0,a.kt)("p",null,"I'm open to the possibility that my opinion may be modified further. And I'd be very interested to know what other people think on the subject."),(0,a.kt)("h2",o({},{id:"update"}),"Update"),(0,a.kt)("p",null,"It turns out that I'm not alone in thinking about this issue and indeed others have expressed this rather better than me - take a look at Jimmy Bogard's post for an example: ",(0,a.kt)("a",o({parentName:"p"},{href:"http://lostechies.com/jimmybogard/2012/09/20/limiting-your-abstractions/"}),"http://lostechies.com/jimmybogard/2012/09/20/limiting-your-abstractions/"),"."),(0,a.kt)("h2",o({},{id:"updated-2"}),"Updated 2"),(0,a.kt)("p",null,"I've also recently watched the following Pluralsight course by Julie Lerman: ",(0,a.kt)("a",o({parentName:"p"},{href:"http://pluralsight.com/training/Courses/TableOfContents/efarchitecture#efarchitecture-m3-archrepo"}),"http://pluralsight.com/training/Courses/TableOfContents/efarchitecture#efarchitecture-m3-archrepo"),'. In this course Julie talks about different implementations of the Repository and Unit of Work patterns in conjunction with Entity Framework. Julie is in favour of using this approach but in this module she elaborates on different "flavours" of these patterns that you might want to use for different reasons (bounded contexts / reference contexts etc). She makes a compelling case and helpfully she is open enough to say that this a point of contention in the community. At the end of watching this I think I felt happy that our "halfway house" approach seems to fit and seems to work. More than anything else Julie made clear that there isn\'t one definitively "true" approach. Rather many different but similar approaches for achieving the same goal. Good stuff Julie!'))}d.isMDXComponent=!0},72070:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"using-web-optimization-with-mvc-3",title:"Using Web Optimization with MVC 3",authors:"johnnyreilly",tags:["asp.net"],hide_table_of_contents:!1},s=void 0,l={permalink:"/using-web-optimization-with-mvc-3",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-10-05-using-web-optimization-with-mvc-3/index.md",source:"@site/blog/2012-10-05-using-web-optimization-with-mvc-3/index.md",title:"Using Web Optimization with MVC 3",description:"A while ago I wrote about optimally serving up JavaScript in web applications. I mentioned that Microsoft had come up with a NuGet package called Microsoft ASP.NET Web Optimization which could help with that by minifying and bundling CSS and JavaScript. At the time I was wondering if I would be able to to use this package with pre-existing MVC 3 projects (given that the package had been released together with MVC 4). Happily it turns out you can. But it's not quite as straightforward as I might have liked so I've documented how to get going with this here...",date:"2012-10-05T00:00:00.000Z",formattedDate:"October 5, 2012",tags:[{label:"asp.net",permalink:"/tags/asp-net"}],readingTime:5.845,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"using-web-optimization-with-mvc-3",title:"Using Web Optimization with MVC 3",authors:"johnnyreilly",tags:["asp.net"],hide_table_of_contents:!1},prevItem:{title:"MVC 3 meet Dictionary",permalink:"/mvc-3-meet-dictionary"},nextItem:{title:"Unit Testing and Entity Framework: The Filth and the Fury",permalink:"/unit-testing-and-entity-framework-filth"}},p={authorsImageUrls:[void 0]},u=[{value:"Getting the Basics in Place",id:"getting-the-basics-in-place",level:2},{value:"Switching over _Layout.cshtml to use Web Optimization",id:"switching-over-_layoutcshtml-to-use-web-optimization",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"A while ago I ",(0,a.kt)("a",o({parentName:"p"},{href:"http://icanmakethiswork.blogspot.com/2012/06/how-im-structuring-my-javascript-in-web.html#WebOptimization"}),"wrote")," about optimally serving up JavaScript in web applications. I mentioned that Microsoft had come up with a NuGet package called ",(0,a.kt)("a",o({parentName:"p"},{href:"http://nuget.org/packages/Microsoft.AspNet.Web.Optimization"}),"Microsoft ASP.NET Web Optimization")," which could help with that by minifying and bundling CSS and JavaScript. At the time I was wondering if I would be able to to use this package with pre-existing MVC 3 projects (given that the package had been released together with MVC 4). Happily it turns out you can. But it's not quite as straightforward as I might have liked so I've documented how to get going with this here..."),(0,a.kt)("h2",o({},{id:"getting-the-basics-in-place"}),"Getting the Basics in Place"),(0,a.kt)("p",null,'To keep it simple I\'m going to go through taking a "vanilla" MVC 3 app and enhancing it to work with Web Optimization. To start, follow these basic steps:'),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Open Visual Studio (bet you didn't see that coming!)"),(0,a.kt)("li",{parentName:"ol"},"Create a new MVC 3 application (I called mine \"WebOptimizationWithMvc3\" to demonstrate my imaginative flair). It doesn't really matter which sort of MVC 3 project you create - I chose an Intranet application but really that's by the by."),(0,a.kt)("li",{parentName:"ol"},"Update pre-existing NuGet packages"),(0,a.kt)("li",{parentName:"ol"},'At the NuGet console type: "',(0,a.kt)("inlineCode",{parentName:"li"},"Install-Package Microsoft.AspNet.Web.Optimization"),'"')),(0,a.kt)("p",null,"Whilst the NuGet package adds the necessary references to your MVC 3 project it doesn't add the corresponding namespaces to the web.configs. To fix this manually add the following child XML element to the ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;namespaces&gt;")," element in your root and Views web.config files:"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},'&lt;add namespace="System.Web.Optimization" /&gt;')),(0,a.kt)("p",null,"This gives you access to ",(0,a.kt)("inlineCode",{parentName:"p"},"Scripts")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"Styles")," in your views without needing the fully qualified namespace. For reasons best known to Microsoft I had to close down and restart Visual Studio before intellisense started working. You may need to do likewise."),(0,a.kt)("p",null,"Next up we want to get some JavaScript / CSS bundles in place. To do this, create a folder in the root of your project called \"App_Start\". There's nothing magical about this to my knowledge; this is just a convention that's been adopted to store all the bits of startup in one place and avoid clutterage. (I think this grew out of Nuget; see ",(0,a.kt)("a",o({parentName:"p"},{href:"http://blog.davidebbo.com/2011/02/appstart-folder-convention-for-nuget.html"}),"David Ebbo talking about this here"),".) Inside your new folder you should add a new class called ",(0,a.kt)("inlineCode",{parentName:"p"},"BundleConfig.cs")," which looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System.Web;\nusing System.Web.Optimization;\n\nnamespace WebOptimizationWithMvc3.App_Start\n{\n    public class BundleConfig\n    {\n        // For more information on Bundling, visit http://go.microsoft.com/fwlink/?LinkId=254725\n        public static void RegisterBundles(BundleCollection bundles)\n        {\n            bundles.Add(new ScriptBundle("~/bundles/jquery").Include(\n                        "~/Scripts/jquery-{version}.js"));\n\n            bundles.Add(new ScriptBundle("~/bundles/jqueryui").Include(\n                        "~/Scripts/jquery-ui-{version}.js"));\n\n            bundles.Add(new ScriptBundle("~/bundles/jqueryval").Include(\n                        "~/Scripts/jquery.unobtrusive*",\n                        "~/Scripts/jquery.validate*"));\n\n            // Use the development version of Modernizr to develop with and learn from. Then, when you\'re\n            // ready for production, use the build tool at http://modernizr.com to pick only the tests you need.\n            bundles.Add(new ScriptBundle("~/bundles/modernizr").Include(\n                        "~/Scripts/modernizr-*"));\n\n            bundles.Add(new StyleBundle("~/Content/css").Include("~/Content/site.css"));\n\n            bundles.Add(new StyleBundle("~/Content/themes/base/css").Include(\n                        "~/Content/themes/base/jquery.ui.core.css",\n                        "~/Content/themes/base/jquery.ui.resizable.css",\n                        "~/Content/themes/base/jquery.ui.selectable.css",\n                        "~/Content/themes/base/jquery.ui.accordion.css",\n                        "~/Content/themes/base/jquery.ui.autocomplete.css",\n                        "~/Content/themes/base/jquery.ui.button.css",\n                        "~/Content/themes/base/jquery.ui.dialog.css",\n                        "~/Content/themes/base/jquery.ui.slider.css",\n                        "~/Content/themes/base/jquery.ui.tabs.css",\n                        "~/Content/themes/base/jquery.ui.datepicker.css",\n                        "~/Content/themes/base/jquery.ui.progressbar.css",\n                        "~/Content/themes/base/jquery.ui.theme.css"));\n        }\n    }\n}\n')),(0,a.kt)("p",null,"The above is what you get when you create a new MVC 4 project (as it includes Web Optimization out of the box). All it does is create some JavaScript and CSS bundles relating to jQuery, jQuery UI, jQuery Validate, Modernizr and the standard site CSS. Nothing radical here but this example should give you an idea of how bundling can be configured and used. To make use of ",(0,a.kt)("inlineCode",{parentName:"p"},"BundleConfig.cs")," you should modify your ",(0,a.kt)("inlineCode",{parentName:"p"},"Global.asax.cs")," so it looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Web;\nusing System.Web.Mvc;\nusing System.Web.Routing;\nusing WebOptimizationWithMvc3.App_Start; //NEW MAGIC GOODNESS\nusing System.Web.Optimization;           //NEW MAGIC GOODNESS\n\nnamespace WebOptimizationWithMvc3\n{\n    // Note: For instructions on enabling IIS6 or IIS7 classic mode,\n    // visit http://go.microsoft.com/?LinkId=9394801\n\n    public class MvcApplication : System.Web.HttpApplication\n    {\n        public static void RegisterGlobalFilters(GlobalFilterCollection filters)\n        {\n            filters.Add(new HandleErrorAttribute());\n        }\n\n        public static void RegisterRoutes(RouteCollection routes)\n        {\n            routes.IgnoreRoute("{resource}.axd/{*pathInfo}");\n\n            routes.MapRoute(\n                "Default", // Route name\n                "{controller}/{action}/{id}", // URL with parameters\n                new { controller = "Home", action = "Index", id = UrlParameter.Optional } // Parameter defaults\n            );\n\n        }\n\n        protected void Application_Start()\n        {\n            AreaRegistration.RegisterAllAreas();\n\n            RegisterGlobalFilters(GlobalFilters.Filters);\n            RegisterRoutes(RouteTable.Routes);\n\n            //NEW MAGIC GOODNESS START\n            BundleConfig.RegisterBundles(BundleTable.Bundles);\n            //NEW MAGIC GOODNESS END\n        }\n    }\n}\n')),(0,a.kt)("p",null,"Once you've done this you're ready to start using Web Optimization in your MVC 3 application."),(0,a.kt)("h2",o({},{id:"switching-over-_layoutcshtml-to-use-web-optimization"}),"Switching over ","_","Layout.cshtml to use Web Optimization"),(0,a.kt)("p",null,'With a "vanilla" MVC 3 app the only use of CSS and JavaScript files is found in ',(0,a.kt)("inlineCode",{parentName:"p"},"_Layout.cshtml"),". To switch over to using Web Optimization you should replace the existing ",(0,a.kt)("inlineCode",{parentName:"p"},"_Layout.cshtml")," with this: (you'll see that the few differences that there are between the 2 are solely around the replacement of link / script tags with references to ",(0,a.kt)("inlineCode",{parentName:"p"},"Scripts")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"Styles")," instead)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<!DOCTYPE html>\n<html>\n  <head>\n    <title>@ViewBag.Title</title>\n    @Styles.Render("~/Content/css", "~/Content/themes/base/css")\n    @Scripts.Render("~/bundles/modernizr")\n  </head>\n  <body>\n    <div class="page">\n      <div id="header">\n        <div id="title">\n          <h1>My MVC Application</h1>\n        </div>\n        <div id="logindisplay">\n          Welcome <strong>@User.Identity.Name</strong>!\n        </div>\n        <div id="menucontainer">\n          <ul id="menu">\n            <li>@Html.ActionLink("Home", "Index", "Home")</li>\n            <li>@Html.ActionLink("About", "About", "Home")</li>\n          </ul>\n        </div>\n      </div>\n      <div id="main">@RenderBody()</div>\n      <div id="footer"></div>\n    </div>\n    @Scripts.Render("~/bundles/jquery", "~/bundles/jqueryui",\n    "~/bundles/jqueryval") @RenderSection("scripts", required: false)\n  </body>\n</html>\n')),(0,a.kt)("p",null,"Do note that in the above ",(0,a.kt)("inlineCode",{parentName:"p"},"Scripts.Render")," call we're rendering out 3 bundles; jQuery, jQuery UI and jQuery Validate. We're not using any of these in ",(0,a.kt)("inlineCode",{parentName:"p"},"_Layout.cshtml")," but rendering these (and their associated link tags) gives us a chance to demonstrate that everything is working as expected."),(0,a.kt)("p",null,"In your root web.config file make sure that the following tag is in place: ",(0,a.kt)("inlineCode",{parentName:"p"},'&lt;compilation debug="<b>true</b>" targetFramework="4.0"&gt;'),". Then run, the generated HTML should look something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<!DOCTYPE html>\n<html>\n  <head>\n    <title>Home Page</title>\n    <link href="/Content/site.css" rel="stylesheet" />\n    <link href="/Content/themes/base/jquery.ui.core.css" rel="stylesheet" />\n    <link\n      href="/Content/themes/base/jquery.ui.resizable.css"\n      rel="stylesheet"\n    />\n    <link\n      href="/Content/themes/base/jquery.ui.selectable.css"\n      rel="stylesheet"\n    />\n    <link\n      href="/Content/themes/base/jquery.ui.accordion.css"\n      rel="stylesheet"\n    />\n    <link\n      href="/Content/themes/base/jquery.ui.autocomplete.css"\n      rel="stylesheet"\n    />\n    <link href="/Content/themes/base/jquery.ui.button.css" rel="stylesheet" />\n    <link href="/Content/themes/base/jquery.ui.dialog.css" rel="stylesheet" />\n    <link href="/Content/themes/base/jquery.ui.slider.css" rel="stylesheet" />\n    <link href="/Content/themes/base/jquery.ui.tabs.css" rel="stylesheet" />\n    <link\n      href="/Content/themes/base/jquery.ui.datepicker.css"\n      rel="stylesheet"\n    />\n    <link\n      href="/Content/themes/base/jquery.ui.progressbar.css"\n      rel="stylesheet"\n    />\n    <link href="/Content/themes/base/jquery.ui.theme.css" rel="stylesheet" />\n\n    <script src="/Scripts/modernizr-2.6.2.js"><\/script>\n  </head>\n  <body>\n    <div class="page">\n      <div id="header">\n        <div id="title">\n          <h1>My MVC Application</h1>\n        </div>\n        <div id="logindisplay">Welcome <strong>LNR\\jreilly</strong>!</div>\n        <div id="menucontainer">\n          <ul id="menu">\n            <li><a href="/">Home</a></li>\n            <li><a href="/Home/About">About</a></li>\n          </ul>\n        </div>\n      </div>\n      <div id="main">\n        <h2>Welcome to ASP.NET MVC!</h2>\n        <p>\n          To learn more about ASP.NET MVC visit\n          <a href="http://asp.net/mvc" title="ASP.NET MVC Website"\n            >http://asp.net/mvc</a\n          >.\n        </p>\n      </div>\n      <div id="footer"></div>\n    </div>\n    <script src="/Scripts/jquery-1.8.2.js"><\/script>\n    <script src="/Scripts/jquery-ui-1.8.24.js"><\/script>\n    <script src="/Scripts/jquery.unobtrusive-ajax.js"><\/script>\n    <script src="/Scripts/jquery.validate.js"><\/script>\n    <script src="/Scripts/jquery.validate.unobtrusive.js"><\/script>\n  </body>\n</html>\n')),(0,a.kt)("p",null,"This demonstrates that when the application has debug set to true you see the full scripts / links being rendered out as you would hope (to make your debugging less painful)."),(0,a.kt)("p",null,"Now go back to your root ",(0,a.kt)("inlineCode",{parentName:"p"},"web.config")," file and chance the debug tag to false: ",(0,a.kt)("inlineCode",{parentName:"p"},'&lt;compilation debug="<b>false</b>" targetFramework="4.0"&gt;'),". This time when you run, the generated HTML should look something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<!DOCTYPE html>\n<html>\n  <head>\n    <title>Home Page</title>\n    <link\n      href="/Content/css?v=zA21MEZPkFOTy3OUxWWonyifZGPNxI-SSbBOWkDhsHk1"\n      rel="stylesheet"\n    />\n    <link\n      href="/Content/themes/base/css?v=myqT7npwmF2ABsuSaHqt8SCvK8UFWpRv7T4M8r3kiK01"\n      rel="stylesheet"\n    />\n\n    <script src="/bundles/modernizr?v=QZTpgFA-zRi28FHInjPOp9lXJl6mFGrWHlv3QhMpqSw1"><\/script>\n  </head>\n  <body>\n    <div class="page">\n      <div id="header">\n        <div id="title">\n          <h1>My MVC Application</h1>\n        </div>\n        <div id="logindisplay">Welcome <strong>LNR\\jreilly</strong>!</div>\n        <div id="menucontainer">\n          <ul id="menu">\n            <li><a href="/">Home</a></li>\n            <li><a href="/Home/About">About</a></li>\n          </ul>\n        </div>\n      </div>\n      <div id="main">\n        <h2>Welcome to ASP.NET MVC!</h2>\n        <p>\n          To learn more about ASP.NET MVC visit\n          <a href="http://asp.net/mvc" title="ASP.NET MVC Website"\n            >http://asp.net/mvc</a\n          >.\n        </p>\n      </div>\n      <div id="footer"></div>\n    </div>\n    <script src="/bundles/jquery?v=-3plyJYF8LQ0YVYbKtEZnEbkML7BIL0Iul_dNlwGXq41"><\/script>\n    <script src="/bundles/jqueryui?v=RuyxWjtbiK02VYPQGF4OyBZcxNB-W9FsvN6HJTZj4NA1"><\/script>\n    <script src="/bundles/jqueryval?v=E3jxQivD8ilGcNEk6JrH6Jx2wDop7sWW2YKDc6Kq8gY1"><\/script>\n  </body>\n</html>\n')),(0,a.kt)("p",null,"This time you can see that in non-debug mode (ie how it would run in Production) minified bundles of scripts and css files are being served up instead of the raw files. And that's it; done."))}d.isMDXComponent=!0},39839:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"mvc-3-meet-dictionary",title:"MVC 3 meet Dictionary",authors:"johnnyreilly",tags:[".NET Framework"],hide_table_of_contents:!1},s=void 0,l={permalink:"/mvc-3-meet-dictionary",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-10-22-mvc-3-meet-dictionary/index.md",source:"@site/blog/2012-10-22-mvc-3-meet-dictionary/index.md",title:"MVC 3 meet Dictionary",description:"Documenting a JsonValueProviderFactory Gotcha",date:"2012-10-22T00:00:00.000Z",formattedDate:"October 22, 2012",tags:[{label:".NET Framework",permalink:"/tags/net-framework"}],readingTime:3.07,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"mvc-3-meet-dictionary",title:"MVC 3 meet Dictionary",authors:"johnnyreilly",tags:[".NET Framework"],hide_table_of_contents:!1},prevItem:{title:"XSD/XML Schema Generator + Xsd.exe:Taking the pain out of manual XML",permalink:"/xsdxml-schema-generator-xsdexe-taking"},nextItem:{title:"Using Web Optimization with MVC 3",permalink:"/using-web-optimization-with-mvc-3"}},p={authorsImageUrls:[void 0]},u=[{value:"Documenting a JsonValueProviderFactory Gotcha",id:"documenting-a-jsonvalueproviderfactory-gotcha",level:2},{value:"The Problem",id:"the-problem",level:2},{value:"The Workaround",id:"the-workaround",level:2},{value:"Summary and a PS",id:"summary-and-a-ps",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"documenting-a-jsonvalueproviderfactory-gotcha"}),"Documenting a JsonValueProviderFactory Gotcha"),(0,a.kt)("p",null,"About a year ago I was involved in the migration of an ASP.NET WebForms application over to MVC 3. We'd been doing a lot of AJAX-y / Single Page Application-y things in the project and had come to the conclusion that MVC might be a slightly better fit since we intended to continue down this path."),(0,a.kt)("p",null,"During the migration we encountered a bug in MVC 3 concerning Dictionary deserialization. This bug has subsequently tripped me up a few more times as I failed to remember the nature of the problem correctly. So I've written the issue up here as an aide to my own lamentable memory."),(0,a.kt)("p",null,"Before I begin I should say that the problem ","*",(0,a.kt)("u",null,"has been resolved in MVC 4")),(0,a.kt)("p",null,"*",". However given that I imagine many MVC 3 projects will not upgrade instantly there's probably some value in documenting the issue (and how to work around it). By the way, you can see my initial plea for assistance in ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/q/6881440/761388"}),"this StackOverflow question"),"."),(0,a.kt)("h2",o({},{id:"the-problem"}),"The Problem"),(0,a.kt)("p",null,"The problem is that deserialization of Dictionary objects does not behave in the expected and desired fashion. When you fire off a dictionary it arrives at your endpoint as the enormously unhelpful ",(0,a.kt)("inlineCode",{parentName:"p"},"null"),". To see this for yourself you can try using this JavaScript:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"$.ajax('PostDictionary', {\n  type: 'POST',\n  contentType: 'application/json',\n  data: JSON.stringify({\n    myDictionary: {\n      This: 'is',\n      a: 'dictionary',\n    },\n  }),\n  success: function (result) {\n    alert(JSON.stringify(result));\n  },\n});\n")),(0,a.kt)("p",null,"With this C#:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"        //...\n\n        [HttpPost]\n        public ActionResult PostDictionary(Dictionary<string, string> myDictionary)\n        {\n            return Json(myDictionary);\n        }\n\n        //...\n")),(0,a.kt)("p",null,"You get a null ",(0,a.kt)("inlineCode",{parentName:"p"},"null")," dictionary."),(0,a.kt)("p",null,"After a long time googling around on the topic I eventually discovered, much to my surprise, that I was actually tripping over a bug in MVC 3. It was filed by ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/users/29407/darin-dimitrov"}),"Darin Dimitrov")," of Stack Overflow fame and I found details about it filed as an official bug ",(0,a.kt)("a",o({parentName:"p"},{href:"http://connect.microsoft.com/VisualStudio/feedback/details/636647/make-jsonvalueproviderfactory-work-with-dictionary-types-in-asp-net-mvc"}),"here"),". To quote Darin:"),(0,a.kt)("p",null,'"',(0,a.kt)("em",{parentName:"p"},"The System.Web.Mvc.JsonValueProviderFactory introduced in ASP.NET MVC 3 enables action methods to send and receive JSON-formatted text and to model-bind the JSON text to parameters of action methods. Unfortunately it doesn't work with dictionaries"),'"'),(0,a.kt)("h2",o({},{id:"the-workaround"}),"The Workaround"),(0,a.kt)("p",null,"My colleague found a workaround for the issue ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/5397743/761388"}),"here"),". There are 2 parts to this:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Dictionaries in JavaScript are simple JavaScript Object Literals. In order to workaround this issue it is necessary to ",(0,a.kt)("inlineCode",{parentName:"li"},"JSON.stringify")," our Dictionary / JOL before sending it to the endpoint. This is done so a string can be picked up at the endpoint."),(0,a.kt)("li",{parentName:"ol"},"The signature of your action is switched over from a Dictionary reference to a string reference. Deserialization is then manually performed back from the string to a Dictionary within the Action itself.")),(0,a.kt)("p",null,"I've adapted my example from earlier to demonstrate this; first the JavaScript:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"$.ajax('PostDictionary', {\n  type: 'POST',\n  contentType: 'application/json',\n  data: JSON.stringify({\n    myDictionary: JSON.stringify({\n      //Note the deliberate double JSON.stringify\n      This: 'is',\n      a: 'dictionary',\n    }),\n  }),\n  success: function (result) {\n    alert(JSON.stringify(result));\n  },\n});\n")),(0,a.kt)("p",null,"Then the C#:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"        //...\n\n        [HttpPost]\n        public ActionResult PostDictionary(string myDictionary)\n        {\n            var actualDictionary = new System.Web.Script.Serialization.JavaScriptSerializer()\n                .Deserialize<Dictionary<string, string>>(myDictionary);\n\n            return Json(actualDictionary);\n        }\n\n        //...\n")),(0,a.kt)("p",null,"And now we're able to get a dictionary."),(0,a.kt)("h2",o({},{id:"summary-and-a-ps"}),"Summary and a PS"),(0,a.kt)("p",null,"So that's it; a little unglamourous but this works. I'm slightly surprised that that wasn't picked up before MVC 3 was released but at least it's been fixed for MVC 4. I look forward to this blog post being irrelevant and out of date \u263a."),(0,a.kt)("p",null,"For what it's worth in my example above we're using the trusty old ",(0,a.kt)("inlineCode",{parentName:"p"},"System.Web.Script.Serialization.JavaScriptSerializer")," to perform deserialization. My preference is actually to use ",(0,a.kt)("a",o({parentName:"p"},{href:"http://james.newtonking.com/projects/json-net.aspx"}),"JSON.Nets")," implementation but for the sake of simplicity I went with .NETs internal one here. To be honest, either is fine to my knowledge."))}d.isMDXComponent=!0},44765:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"xsdxml-schema-generator-xsdexe-taking",title:"XSD/XML Schema Generator + Xsd.exe:Taking the pain out of manual XML",authors:"johnnyreilly",tags:["XSD","LINQ to XML"],hide_table_of_contents:!1},s=void 0,l={permalink:"/xsdxml-schema-generator-xsdexe-taking",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-11-02-xsdxml-schema-generator-xsdexe-taking/index.md",source:"@site/blog/2012-11-02-xsdxml-schema-generator-xsdexe-taking/index.md",title:"XSD/XML Schema Generator + Xsd.exe:Taking the pain out of manual XML",description:"Is it 2003 again?!?",date:"2012-11-02T00:00:00.000Z",formattedDate:"November 2, 2012",tags:[{label:"XSD",permalink:"/tags/xsd"},{label:"LINQ to XML",permalink:"/tags/linq-to-xml"}],readingTime:7.815,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"xsdxml-schema-generator-xsdexe-taking",title:"XSD/XML Schema Generator + Xsd.exe:Taking the pain out of manual XML",authors:"johnnyreilly",tags:["XSD","LINQ to XML"],hide_table_of_contents:!1},prevItem:{title:"Getting up to speed with Bloomberg's Open API...",permalink:"/a-nicer-net-api-for-bloombergs-open-api"},nextItem:{title:"MVC 3 meet Dictionary",permalink:"/mvc-3-meet-dictionary"}},p={authorsImageUrls:[void 0]},u=[{value:"Is it 2003 again?!?",id:"is-it-2003-again",level:2},{value:"To the XML Batman!",id:"to-the-xml-batman",level:2},{value:"We Don&#39;t Need No Validation...",id:"we-dont-need-no-validation",level:2},{value:"Tools of the Trade",id:"tools-of-the-trade",level:2},{value:"Justify Your Actions",id:"justify-your-actions",level:2},{value:"Serialization / Deserialization Helper",id:"serialization--deserialization-helper",level:2},{value:"Updated - using Xsd.exe to generate XSD from XML",id:"updated---using-xsdexe-to-generate-xsd-from-xml",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"is-it-2003-again"}),"Is it 2003 again?!?"),(0,a.kt)("p",null,"I've just discovered Xsd.exe. It's not new. Or shiny. And in fact it's been around since .NET 1.1. Truth be told, I've been aware of it for years but up until now I've not had need of it. But now now I've investigated it a bit I've found that it, combined with the XSD/XML Schema Generator can make for a nice tool to add to the utility belt."),(0,a.kt)("p",null,"Granted XML has long since stopped being sexy. But if you need it, as I did recently, then this is for you."),(0,a.kt)("h2",o({},{id:"to-the-xml-batman"}),"To the XML Batman!"),(0,a.kt)("p",null,"Now XML is nothing new to me (or I imagine anyone who's been developing within the last 10 years). But most of the time when I use XML I'm barely aware that it's going on - by and large it's XML doing the heavy lifting underneath my web services. But the glory of this situation is, I never have to think about it. It just works. All I have to deal with are nice strongly typed objects which makes writing robust code a doddle."),(0,a.kt)("p",null,"I recently came upon a situation where I was working with XML in the raw; that is to say strings. I was going to be supplied with strings of XML which would represent various objects. It would be my job to take the supplied XML, extract out the data I needed and proceed accordingly."),(0,a.kt)("h2",o({},{id:"we-dont-need-no-validation"}),"We Don't Need No Validation..."),(0,a.kt)("p",null,"I lied!"),(0,a.kt)("p",null,"In order to write something reliable I needed to be able to validate that the supplied XML was as I expected. So, ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/XML_Schema_(W3C)"}),"XSD")," time. If you're familiar with XML then you're probably equally familar with XSD which, to quote Wikipedia ",(0,a.kt)("em",{parentName:"p"},"\"can be used to express a set of rules to which an XML document must conform in order to be considered 'valid'\""),"."),(0,a.kt)("p",null,"Now I've written my fair share of XSDs over the years and I've generally found it a slightly tedious exercise. So I was delighted to discover an online tool to simplify the task. It's called the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.freeformatter.com/xsd-generator.html"}),"XSD/XML Schema Generator"),". What this marvellous tool does is allow you to enter an example of your XML which it then uses to reverse engineer an XSD."),(0,a.kt)("p",null,"Here's an example. I plugged in this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<?xml version="1.0" encoding="utf-8" ?>\n<contact type="personal">\n  <firstName>John</firstName>\n  <lastName>Reilly</lastName>\n  <heightInInches>76</heightInInches>\n</contact>\n')),(0,a.kt)("p",null,"And pulled out this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xsd"}),'<xs:schema attributeFormDefault="unqualified" elementFormDefault="qualified" xmlns:xs="http://www.w3.org/2001/XMLSchema">\n  <xs:element name="contact">\n    <xs:complexType>\n      <xs:sequence>\n        <xs:element type="xs:string" name="firstName"/>\n        <xs:element type="xs:string" name="lastName"/>\n        <xs:element type="xs:byte" name="heightInInches"/>\n      </xs:sequence>\n      <xs:attribute type="xs:string" name="type"/>\n    </xs:complexType>\n  </xs:element>\n</xs:schema>\n')),(0,a.kt)("p",null,"Fantastic! It doesn't matter if the tool gets something slightly wrong; you can tweak the generated XSD to your hearts content. This is great because it does the hard work for you, allowing you to step back, mop your brow and then heartily approve the results. This tool is a labour saving device. Put simply, it's a dishwasher."),(0,a.kt)("h2",o({},{id:"tools-of-the-trade"}),"Tools of the Trade"),(0,a.kt)("p",null,"How to get to the actual data? I was initially planning to break out the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/system.xml.linq.xdocument(v=vs.100).aspx"}),(0,a.kt)("inlineCode",{parentName:"a"},"XDocument")),", plug in my XSD and use the ",(0,a.kt)("inlineCode",{parentName:"p"},"Validate")," method. Which would do the job just dandy."),(0,a.kt)("p",null,"However I resisted. As much as I like LINQ to XML I turned to use ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/x6c1kb0s(v=vs.100).aspx"}),"Xsd.exe")," instead. As I've mentioned, this tool is as old as the hills. But there's gold in them thar hills, listen: ",(0,a.kt)("em",{parentName:"p"},'"The XML Schema Definition (Xsd.exe) tool generates XML schema or common language runtime classes from XDR, XML, and XSD files, or from classes in a runtime assembly."')),(0,a.kt)("p",null,"Excited? Thought not. But what this means is we can hurl our XSD at this tool and it will toss back a nicely formatted C# class for me to use. Good stuff! So how's it done? Well MSDN is roughly as informative as it ever is (which is to say, not terribly) but fortunately there's not a great deal to it. You fire up the Visual Studio Command Prompt (and I advise doing this in Administrator mode to escape permissions pain). Then you enter a command to generate your class. Here's an example using the Contact.xsd file we generated earlier:"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},'xsd.exe "C:\\\\Contact.xsd" /classes /out:"C:\\\\" /namespace:"MyNameSpace"')),(0,a.kt)("p",null,"And you're left with the lovely Contact.cs class:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'//------------------------------------------------------------------------------\n// <auto-generated>\n//     This code was generated by a tool.\n//     Runtime Version:4.0.30319.239\n//\n//     Changes to this file may cause incorrect behavior and will be lost if\n//     the code is regenerated.\n// </auto-generated>\n//------------------------------------------------------------------------------\n\n//\n// This source code was auto-generated by xsd, Version=4.0.30319.1.\n//\nnamespace MyNameSpace {\n    using System.Xml.Serialization;\n\n\n    /// <remarks/>\n    [System.CodeDom.Compiler.GeneratedCodeAttribute("xsd", "4.0.30319.1")]\n    [System.SerializableAttribute()]\n    [System.Diagnostics.DebuggerStepThroughAttribute()]\n    [System.ComponentModel.DesignerCategoryAttribute("code")]\n    [System.Xml.Serialization.XmlTypeAttribute(AnonymousType=true)]\n    [System.Xml.Serialization.XmlRootAttribute(Namespace="", IsNullable=false)]\n    public partial class contact {\n\n        private string firstNameField;\n\n        private string lastNameField;\n\n        private sbyte heightInInchesField;\n\n        private string typeField;\n\n        /// <remarks/>\n        public string firstName {\n            get {\n                return this.firstNameField;\n            }\n            set {\n                this.firstNameField = value;\n            }\n        }\n\n        /// <remarks/>\n        public string lastName {\n            get {\n                return this.lastNameField;\n            }\n            set {\n                this.lastNameField = value;\n            }\n        }\n\n        /// <remarks/>\n        public sbyte heightInInches {\n            get {\n                return this.heightInInchesField;\n            }\n            set {\n                this.heightInInchesField = value;\n            }\n        }\n\n        /// <remarks/>\n        [System.Xml.Serialization.XmlAttributeAttribute()]\n        public string type {\n            get {\n                return this.typeField;\n            }\n            set {\n                this.typeField = value;\n            }\n        }\n    }\n}\n')),(0,a.kt)("h2",o({},{id:"justify-your-actions"}),"Justify Your Actions"),(0,a.kt)("p",null,"But why is this good stuff? Indeed why is this more interesting than the newer, and hence obviously cooler, LINQ to XML? Well for my money it's the following reasons that are important:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Intellisense - I have always loved this. Call me lazy but I think intellisense frees up the mind to think about what problem you're actually trying to solve. Xsd.exe's generated classes give me that; I don't need to hold the whole data structure in my head as I code."),(0,a.kt)("li",{parentName:"ol"},"Terse code - I'm passionate about less code. I think that a noble aim in software development is to write as little code as possible in order to achieve your aims. I say this as generally I have found that writing a minimal amount of code expresses the intention of the code in a far clearer fashion. In service of that aim Xsd.exe's generated classes allow me to write less code than would be required with LINQ to XML."),(0,a.kt)("li",{parentName:"ol"},'To quote Scott Hanselman "',(0,a.kt)("a",o({parentName:"li"},{href:"http://www.hanselman.com/blog/NuGetPackageOfTheWeek6DynamicMalleableEnjoyableExpandoObjectsWithClay.aspx"}),"successful compilation is just the first unit test"),"\". That it is but it's a doozy. If I'm making changes to the code and I've been using LINQ to XML I'm not going to see the benefits of strong typing that I would with Xsd.exe's generated classes. I like learning if I've broken the build sooner rather than later; strong typing gives me that safety net.")),(0,a.kt)("h2",o({},{id:"serialization--deserialization-helper"}),"Serialization / Deserialization Helper"),(0,a.kt)("p",null,"As you read this you're no doubt thinking \"but wait he's shown us how to create XSDs from XML and classes from XSDs but how do we take XML and turn it into objects? And how do we turn those objects back into XML?\""),(0,a.kt)("p",null,"See how I read your mind just there? It's a gift. Well, I've written a little static helper class for the very purpose:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System.IO;\nusing System.Linq;\nusing System.Text;\nusing System.Xml.Serialization;\n\nnamespace My.Helpers\n{\n    public static class XmlConverter<T>\n    {\n        private static XmlSerializer _serializer = null;\n\n        #region Static Constructor\n\n        /// <summary>\n        /// Static constructor that initialises the serializer for this type\n        /// </summary>\n        static XmlConverter()\n        {\n            _serializer = new XmlSerializer(typeof(T));\n        }\n\n        #endregion\n\n        #region Public\n\n        /// <summary>\n        /// Deserialize the supplied XML into an object\n        /// </summary>\n        /// <param name="xml"></param>\n        /// <returns></returns>\n        public static T ToObject(string xml)\n        {\n            return (T)_serializer.Deserialize(new StringReader(xml));\n        }\n\n        /// <summary>\n        /// Serialize the supplied object into XML\n        /// </summary>\n        /// <param name="obj"></param>\n        /// <returns></returns>\n        public static string ToXML(T obj)\n        {\n            using (var memoryStream = new MemoryStream())\n            {\n                _serializer.Serialize(memoryStream, obj);\n\n                return Encoding.UTF8.GetString(memoryStream.ToArray());\n            }\n        }\n\n        #endregion\n    }\n}\n')),(0,a.kt)("p",null,"And here's an example of how to use it:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using MyNameSpace;\n\n//Make a new contact\ncontact myContact = new contact();\n\n//Serialize the contact to XML\nstring myContactXML = XmlConverter<contact>.ToXML(myContact);\n\n//Deserialize the XML back into an object\ncontact myContactAgain = XmlConverter<contact>.ToObject(myContactXML);\n")),(0,a.kt)("p",null,"I was tempted to name my methods in tribute to Crockford's JSON (namely ",(0,a.kt)("inlineCode",{parentName:"p"},"ToXML")," becoming ",(0,a.kt)("inlineCode",{parentName:"p"},"stringify")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"ToObject")," becoming ",(0,a.kt)("inlineCode",{parentName:"p"},"parse"),"). Maybe later."),(0,a.kt)("p",null,"And that's us done. Whilst it's no doubt unfashionable I think that this is a very useful approach indeed and I commend it to the interweb!"),(0,a.kt)("h2",o({},{id:"updated---using-xsdexe-to-generate-xsd-from-xml"}),"Updated - using Xsd.exe to generate XSD from XML"),(0,a.kt)("p",null,"I was chatting to a friend about this blog post and he mentioned that you can actually use Xsd.exe to generate XSD files from XML as well. He's quite right - this feature does exist. To go back to our example from earlier we can execute the following command:"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},'xsd.exe "C:\\\\Contact.xml" /out:"C:\\\\"')),(0,a.kt)("p",null,"And this will generate the following file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xsd"}),'<?xml version="1.0" encoding="utf-8"?>\n<xs:schema id="NewDataSet" xmlns="" xmlns:xs="http://www.w3.org/2001/XMLSchema" xmlns:msdata="urn:schemas-microsoft-com:xml-msdata">\n  <xs:element name="contact">\n    <xs:complexType>\n      <xs:sequence>\n        <xs:element name="firstName" type="xs:string" minOccurs="0" msdata:Ordinal="0" />\n        <xs:element name="lastName" type="xs:string" minOccurs="0" msdata:Ordinal="1" />\n        <xs:element name="heightInInches" type="xs:string" minOccurs="0" msdata:Ordinal="2" />\n      </xs:sequence>\n      <xs:attribute name="type" type="xs:string" />\n    </xs:complexType>\n  </xs:element>\n  <xs:element name="NewDataSet" msdata:IsDataSet="true" msdata:UseCurrentLocale="true">\n    <xs:complexType>\n      <xs:choice minOccurs="0" maxOccurs="unbounded">\n        <xs:element ref="contact" />\n      </xs:choice>\n    </xs:complexType>\n  </xs:element>\n</xs:schema>\n')),(0,a.kt)("p",null,"However, the XSD generated above is very much a \"Microsoft XSD\"; it's an XSD which features MS properties and so on. It's fine but I think that generally I prefer my XSDs to be as vanilla as possible. To that end I'm likely to stick to using the XSD/XML Schema Generator as it doesn't appear to be possible to get Xsd.exe to generate \"vanilla XSD\"."),(0,a.kt)("p",null,"Thanks to Ajay for bringing it to my attention though."))}d.isMDXComponent=!0},85410:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"a-nicer-net-api-for-bloombergs-open-api",title:"Getting up to speed with Bloomberg's Open API...",authors:"johnnyreilly",tags:[".NET","c#","Bloomberg","Open API"],hide_table_of_contents:!1},s=void 0,l={permalink:"/a-nicer-net-api-for-bloombergs-open-api",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2012-11-13-a-nicer-net-api-for-bloombergs-open-api/index.md",source:"@site/blog/2012-11-13-a-nicer-net-api-for-bloombergs-open-api/index.md",title:"Getting up to speed with Bloomberg's Open API...",description:"A good portion of any devs life is usually spent playing with APIs. If you need to integrate some other system into the system you're working on (and it's rare to come upon a situation where this doesn't happen at some point) then it's API time.",date:"2012-11-13T00:00:00.000Z",formattedDate:"November 13, 2012",tags:[{label:".NET",permalink:"/tags/net"},{label:"c#",permalink:"/tags/c"},{label:"Bloomberg",permalink:"/tags/bloomberg"},{label:"Open API",permalink:"/tags/open-api"}],readingTime:11.39,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"a-nicer-net-api-for-bloombergs-open-api",title:"Getting up to speed with Bloomberg's Open API...",authors:"johnnyreilly",tags:[".NET","c#","Bloomberg","Open API"],hide_table_of_contents:!1},prevItem:{title:"HTML to PDF using a WCF Service",permalink:"/html-to-pdf-using-wcf-service"},nextItem:{title:"XSD/XML Schema Generator + Xsd.exe:Taking the pain out of manual XML",permalink:"/xsdxml-schema-generator-xsdexe-taking"}},p={authorsImageUrls:[void 0]},u=[{value:"Research",id:"research",level:2},{value:"Hello World?",id:"hello-world",level:2},{value:"He&#39;s the Bloomberg, I&#39;m the Wrapper",id:"hes-the-bloomberg-im-the-wrapper",level:2},{value:"Updated (07/12/2012)",id:"updated-07122012",level:2},{value:"Note to self (because I keep forgetting)",id:"note-to-self-because-i-keep-forgetting",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"A good portion of any devs life is usually spent playing with APIs. If you need to integrate some other system into the system you're working on (and it's rare to come upon a situation where this doesn't happen at some point) then it's API time."),(0,a.kt)("p",null,"Some APIs are well documented and nice to use. Some aren't. I recently spent a goodly period of time investigating ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.openbloomberg.com/open-api/"}),"Bloomberg's Open API")," and it was a slightly painful experience. So much so that I thought it best to write up my own experiences and maybe I can save others time and a bit of pain."),(0,a.kt)("p",null,"Also, as I investigated the Bloomberg Open API I found myself coming up with my own little mini-C#-API. (It's generally a sure sign you've found an API you don't love if you end up writing your own wrapper.) This mini API did the heavy lifting for me and just handed back nicely structured data to deal with. I have included this wrapper here as well."),(0,a.kt)("h2",o({},{id:"research"}),"Research"),(0,a.kt)("p",null,"The initial plan was to, through code, extract Libor and Euribor rates from Bloomberg. I had access to a Bloomberg terminal and I had access to the internet - what could stop me? After digging around for a little while I found some useful resources that could be accessed from the Bloomberg terminal:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Typing \u201c",(0,a.kt)("inlineCode",{parentName:"li"},"WAPI&lt;GO&gt;"),"\u201d into Bloomberg lead me to the Bloomberg API documentation."),(0,a.kt)("li",{parentName:"ol"},"Typing \u201c",(0,a.kt)("inlineCode",{parentName:"li"},"DOCS 2055451&lt;GO&gt;"),"\u201d into Bloomberg (I know - it's a bit cryptic) provided me with samples of how to use the Bloomberg API in VBA")),(0,a.kt)("p",null,"To go with this I found some useful documentation of the Bloomberg Open API ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.openbloomberg.com/files/2012/10/blpapi-developers-guide.pdf"}),"here")," and I found the .NET Bloomberg Open API itself ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.openbloomberg.com/open-api/"}),"here"),"."),(0,a.kt)("h2",o({},{id:"hello-world"}),"Hello World?"),(0,a.kt)("p",null,"The first goal when getting up to speed with an API is getting it to do something. Anything. Just stick a fork into it and see if it croaks. Sticking a fork into Open API was achieved by taking the 30-odd example apps included in the Bloomberg Open API and running each in turn on the Bloomberg box until I had my \"he's alive!!\" moment. (I did find it surprising that not all of the examples worked - I don't know if there's a good reason for this...)"),(0,a.kt)("p",null,"However, when I tried to write my own C# console application to interrogate the Open API it wasn't as plain sailing as I'd hoped. I'd write something that looked correct, compiled successfully and deploy it onto the Bloomberg terminal only to have it die a sad death whenever I tried to fire it off."),(0,a.kt)("p",null,"I generally find the fastest way to get up and running with an API is to debug it. To make calls to the API and then examine, field by field and method by method, what is actually there. This wasn't really an option with my console app though. I was using a shared Bloomberg terminal with very limited access. No Visual Studio on the box and no remote debugging enabled."),(0,a.kt)("p",null,"It was then that I had something of a eureka moment. I realised that the code in the VBA samples I'd downloaded from Bloomberg looked quite similar to the C# code samples that shipped with Open API. Hmmmm.... Shortly after this I found myself sat at the Bloomberg machine debugging the Bloomberg API using the VBA IDE in Excel. (For the record, these debugging tools are aren't too bad at all - they're nowhere near as slick as their VS counterparts but they do the job.) This was my ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Rosetta_Stone"}),"Rosetta Stone")," ","-"," I could take what I'd learned from the VBA samples and translate that into equivalent C# / .NET code (bearing in mind what I'd learned from debugging in Excel and in fact sometimes bringing along the VBA comments themselves if they provided some useful insight)."),(0,a.kt)("h2",o({},{id:"hes-the-bloomberg-im-the-wrapper"}),"He's the Bloomberg, I'm the Wrapper"),(0,a.kt)("p",null,"So I'm off and romping... I have something that works. Hallelujah! Now that that hurdle had been crossed I found myself examining the actual Bloomberg API code itself. It functioned just fine but it did a couple of things that I wasn't too keen on:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"The Bloomberg API came with custom data types. I didn't want to use these unless it was absolutely necessary - I just wanted to stick to the standard .NET types. This way if I needed to hand data onto another application I wouldn't be making each of these applications dependant on the Bloomberg Open API."),(0,a.kt)("li",{parentName:"ol"},"To get the data out of the Bloomberg API there was an awful lot of boilerplate. Code which handled the possibilities of very large responses that might be split into several packages. Code which walked the element tree returned from Bloomberg parsing out the data. It wasn't a beacon of simplicity.")),(0,a.kt)("p",null,'I wanted an API that I could simply invoke with security codes and required fields. And in return I wanted to be passed nicely structured data. As I\'ve already mentioned a desire to not introduce unnecessary dependencies I thought it might well suit to make use of nested Dictionaries. I came up with a simple C# Console project / application which had a reference to the Bloomberg Open API. It contained the following class; essentially my wrapper for Open API operations: (please note this is deliberately a very "bare-bones" implementation)'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\n\nusing Bloomberglp.Blpapi;\n\nnamespace BloombergConsole\n{\n    class BloombergApi\n    {\n        #region Members / Contructors\n\n        private Session _session = null;\n        private Service _refDataService = null;\n\n        private readonly string _serverHost;\n        private readonly int _serverPort;\n\n        public BloombergApi(string serverHost = "localhost", int serverPort = 8194)\n        {\n            _serverHost = serverHost;\n            _serverPort = serverPort;\n        }\n\n        /// <summary>\n        /// Initialise the Session and the Service\n        /// </summary>\n        internal void InitialiseSessionAndService()\n        {\n            if (_session == null)\n            {\n                var sessionOptions = new SessionOptions\n                {\n                    ServerHost = _serverHost,\n                    ServerPort = _serverPort\n                };\n\n                //Console.WriteLine("Connecting to {0}:{1}", sessionOptions.ServerHost, sessionOptions.ServerPort);\n\n                _session = new Session(sessionOptions);\n\n                if (!_session.Start())\n                    throw new Exception("Failed to connect!");\n\n                if (!_session.OpenService("//blp/refdata"))\n                {\n                    _session.Stop();\n                    _session = null;\n\n                    throw new Exception("Failed to open //blp/refdata");\n                }\n\n                _refDataService = _session.GetService("//blp/refdata");\n            }\n        }\n\n        /// <summary>\n        /// Dispose the Session and the Service\n        /// </summary>\n        internal void DisposeSessionAndService()\n        {\n            _refDataService = null;\n\n            //Stop the session\n            if (_session != null)\n            {\n                _session.Stop();\n                _session = null;\n            }\n        }\n\n        #endregion\n\n        #region Methods\n\n        internal Dictionary<string,    //Security\n            Dictionary<string, object> //Fields and values\n            > GetSecuritiesFields(string[] securities, string[] fields)\n        {\n            var securitiesFields = new Dictionary<string, Dictionary<string, object>>();\n\n            //Create request\n            var referenceDataRequest = _refDataService.CreateRequest("ReferenceDataRequest");\n\n            //Securities\n            var securitiesElement = referenceDataRequest.GetElement("securities");\n            foreach (var security in securities)\n                securitiesElement.AppendValue(security);\n\n            //Fields\n            var fieldsElement = referenceDataRequest.GetElement("fields");\n            foreach (var field in fields)\n                fieldsElement.AppendValue(field);\n\n            //   Send off request\n            _session.SendRequest(referenceDataRequest, null);\n\n            //   Start with our flag set to False for not done\n            var done = false;\n\n            //   Continue as long as we are not done\n            while (!done)\n            {\n                //   Retrieve next event from the server\n                var eventObj = _session.NextEvent();\n\n                //   As long as we have a partial or final response, start to process data\n                if (eventObj.Type == Event.EventType.RESPONSE ||\n                    eventObj.Type == Event.EventType.PARTIAL_RESPONSE)\n                {\n                    //  Loop through messages\n                    foreach (Message msg in eventObj)\n                    {\n                        //   Error handler in case of problem which throws meaningful exception\n                        if (msg.AsElement.HasElement("responseError"))\n                            throw new Exception("Response error:  " + msg.GetElement("responseError").GetElement("message"));\n\n                        //   Extract the securityData top layer and the field data\n                        //   History comes back on a single security basis so no looping there\n                        var securityDataArray = msg.GetElement("securityData");\n\n                        //   Loop through each security\n                        for (var i = 0; i < securityDataArray.NumValues; i++)\n                        {\n                            //   First take out the security object...\n                            var security = securityDataArray.GetValueAsElement(i);\n\n                            var securityName = security.GetElementAsString("security");\n\n                            //   ... then extract the fieldData object\n                            var fieldData = security.GetElement("fieldData");\n\n                            //If we need to add a new security to the securitiesFields dictionary then do so\n                            Dictionary<string, object> results = null;\n                            if (!securitiesFields.ContainsKey(securityName))\n                                securitiesFields.Add(securityName, new Dictionary<string, object>());\n\n                            //Get the fieldsByDate dictionary from the securitiesFields dictionary\n                            results = securitiesFields[securityName];\n\n                            //Extract results and store in results dictionary\n                            foreach (var dataElement in fieldData.Elements)\n                            {\n                                var dataElementName = dataElement.Name.ToString();\n\n                                //Not using this at present - just demonstrating that we can\n                                switch (dataElement.Datatype)\n                                {\n                                    //Special handling to co-erce bloomberg datetimes back to standard .NET datetimes\n                                    case Schema.Datatype.DATE:\n                                        results.Add(dataElementName, dataElement.GetValueAsDate().ToSystemDateTime());\n                                        break;\n                                    case Schema.Datatype.DATETIME:\n                                        results.Add(dataElementName, dataElement.GetValueAsDatetime().ToSystemDateTime());\n                                        break;\n                                    case Schema.Datatype.TIME:\n                                        results.Add(dataElementName, dataElement.GetValueAsDatetime().ToSystemDateTime());\n                                        break;\n\n                                    //Standard handling\n                                    default:\n                                        results.Add(dataElementName, dataElement.GetValue());\n                                        break;\n                                }\n                            }\n                        }\n                    }\n\n                    //   Once we have a response we are done\n                    if (eventObj.Type == Event.EventType.RESPONSE) done = true;\n                }\n            }\n\n            return securitiesFields;\n        }\n\n        internal Dictionary<string,     //Security\n            Dictionary<DateTime,        //DateTime of security\n            Dictionary<string, object>> //Fields and values\n            > GetSecuritiesFieldsByDate(string[] securities, string[] fields, DateTime startDate, DateTime endDate)\n        {\n            var securitiesFieldsByDate = new Dictionary<string, Dictionary<DateTime, Dictionary<string, object>>>();\n\n            //Create request\n            var historyDataRequest = _refDataService.CreateRequest("HistoricalDataRequest");\n\n            //Securities\n            var securitiesElement = historyDataRequest.GetElement("securities");\n            foreach (var security in securities)\n                securitiesElement.AppendValue(security);\n\n            //Fields\n            var fieldsElement = historyDataRequest.GetElement("fields");\n            foreach (var field in fields)\n                fieldsElement.AppendValue(field);\n\n            //   Set the start date and end date as YYYYMMDD strings\n            historyDataRequest.Set("startDate", startDate.ToString("yyyyMMdd"));\n            historyDataRequest.Set("endDate", endDate.ToString("yyyyMMdd"));\n\n            //   Send off request\n            _session.SendRequest(historyDataRequest, null);\n\n            //   Start with our flag set to False for not done\n            var done = false;\n\n            //   Continue as long as we are not done\n            while (!done)\n            {\n                //   Retrieve next event from the server\n                var eventObj = _session.NextEvent();\n\n                //   As long as we have a partial or final response, start to process data\n                if (eventObj.Type == Event.EventType.RESPONSE ||\n                    eventObj.Type == Event.EventType.PARTIAL_RESPONSE)\n                {\n                    //  Loop through messages\n                    foreach (Message msg in eventObj)\n                    {\n                        //   Error handler in case of problem which throws meaningful exception\n                        if (msg.AsElement.HasElement("responseError"))\n                            throw new Exception("Response error:  " + msg.GetElement("responseError").GetElement("message"));\n\n                        //   Extract the securityData top layer and the field data\n                        //   History comes back on a single security basis so no looping there\n                        var security = msg.GetElement("securityData");\n                        var securityName = security.GetElementAsString("security");\n                        var fieldData = security.GetElement("fieldData");\n\n                        //   Extract the data for each requested field\n                        for (var i = 0; i < fieldData.NumValues; i++)\n                        {\n                            var data = fieldData.GetValueAsElement(i);\n\n                            //   First get the date - this is our key\n                            var date = data.GetElementAsDate("date").ToSystemDateTime();\n\n                            //If we need to add a new security to the securitiesFieldsByDate dictionary then do so\n                            Dictionary<DateTime, Dictionary<string, object>> fieldsByDate = null;\n                            if (!securitiesFieldsByDate.ContainsKey(securityName))\n                                securitiesFieldsByDate.Add(securityName, new Dictionary<DateTime, Dictionary<string, object>>());\n\n                            //Get the fieldsByDate dictionary from the securitiesFieldsByDate dictionary\n                            fieldsByDate = securitiesFieldsByDate[securityName];\n\n                            //Extract results and store in results dictionary\n                            var results = new Dictionary<string, object>();\n                            foreach (var dataElement in data.Elements)\n                            {\n                                var dataElementName = dataElement.Name.ToString();\n\n                                //Not using this at present - just demonstrating that we can\n                                switch (dataElement.Datatype)\n                                {\n                                    //Special handling to co-erce bloomberg datetimes back to standard .NET datetimes\n                                    case Schema.Datatype.DATE:\n                                        results.Add(dataElementName, dataElement.GetValueAsDate().ToSystemDateTime());\n                                        break;\n                                    case Schema.Datatype.DATETIME:\n                                        results.Add(dataElementName, dataElement.GetValueAsDatetime().ToSystemDateTime());\n                                        break;\n                                    case Schema.Datatype.TIME:\n                                        results.Add(dataElementName, dataElement.GetValueAsDatetime().ToSystemDateTime());\n                                        break;\n\n                                    //Standard handling\n                                    default:\n                                        results.Add(dataElementName, dataElement.GetValue());\n                                        break;\n                                }\n                            }\n\n                            //Save results dictionary to fieldsByDate dictionary\n                            fieldsByDate.Add(date, results);\n                        }\n                    }\n\n                    //   Once we have a response we are done\n                    if (eventObj.Type == Event.EventType.RESPONSE) done = true;\n                }\n            }\n\n            return securitiesFieldsByDate;\n        }\n\n        #endregion\n    }\n}\n')),(0,a.kt)("p",null,"The project also contained this class which demonstrates how I made use of my wrapper:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\n\n\nnamespace BloombergConsole\n{\n    class NicerBloombergApiDemo\n    {\n        internal const string PX_LAST = "PX_LAST";\n        internal const string PREV_CLOSE_VALUE_REALTIME = "PREV_CLOSE_VALUE_REALTIME";\n        internal const string CHG_NET_1D = "CHG_NET_1D";\n        internal const string CHG_PCT_1D = "CHG_PCT_1D";\n        internal const string CHG_PCT_YTD = "CHG_PCT_YTD";\n\n        internal const string LIBOR_1_MONTH = "BP0001M Index";\n        internal const string LIBOR_3_MONTH = "BP0003M Index";\n        internal const string LIBOR_6_MONTH = "BP0006M Index";\n        internal const string EURIBOR_1_MONTH = "EUR001M Index";\n        internal const string EURIBOR_3_MONTH = "EUR003M Index";\n        internal const string EURIBOR_6_MONTH = "EUR006M Index";\n\n        /// <summary>\n        /// A demo of the nicer client\n        /// </summary>\n        /// <param name="args"></param>\n        public static void Main(String[] args)\n        {\n            System.Console.WriteLine("Bloomberg console demo...");\n\n            var startDateTime = DateTime.Today.AddDays(-3);\n            var endDateTime = DateTime.Today;\n\n            var nicerApi = new BloombergApi();\n            nicerApi.InitialiseSessionAndService();\n            try\n            {\n                //Get fields for given dates\n                var securitiesFieldsByDate = nicerApi.GetSecuritiesFieldsByDate(\n                    new string[] { LIBOR_1_MONTH, LIBOR_3_MONTH, LIBOR_6_MONTH, EURIBOR_1_MONTH, EURIBOR_3_MONTH, EURIBOR_6_MONTH\n                    },\n                    new string[] { PREV_CLOSE_VALUE_REALTIME, PX_LAST, CHG_NET_1D, CHG_PCT_1D, CHG_PCT_YTD\n                    },\n                    startDateTime, endDateTime);\n                Console.WriteLine("\\r\\nGetSecuritiesFieldsByDate");\n\n                //Loop by security\n                foreach (var security in securitiesFieldsByDate)\n                {\n                    Console.WriteLine("Security: {0}", security.Key);\n\n                    //Loop by date\n                    foreach (var dateAndFields in security.Value.OrderBy(d => d.Key))\n                    {\n                        Console.WriteLine(dateAndFields.Key.ToString("yyyy-MM-dd"));\n\n                        //Loop by field\n                        foreach (var keyValue in dateAndFields.Value)\n                        {\n                            Console.WriteLine("{0}: {1} ({2})", keyValue.Key, keyValue.Value, keyValue.Value.GetType());\n                        }\n                    }\n                }\n                Console.WriteLine();\n\n                //Get current rates\n                var flashRates = nicerApi.GetSecuritiesFields(\n                    new string[] { LIBOR_1_MONTH, LIBOR_3_MONTH, LIBOR_6_MONTH, EURIBOR_1_MONTH, EURIBOR_3_MONTH, EURIBOR_6_MONTH\n                    },\n                    new string[] { PREV_CLOSE_VALUE_REALTIME, PX_LAST, CHG_NET_1D, CHG_PCT_1D, CHG_PCT_YTD\n                    });\n                foreach (var securityAndFields in flashRates.OrderBy(d => d.Key))\n                {\n                    Console.WriteLine(securityAndFields.Key);\n                    foreach (var keyValue in securityAndFields.Value)\n                        Console.WriteLine("{0}: {1} ({2})", keyValue.Key, keyValue.Value, keyValue.Value.GetType());\n                }\n                Console.WriteLine();\n            }\n            catch (Exception e)\n            {\n                System.Console.WriteLine(e.ToString());\n            }\n\n            System.Console.WriteLine("Press ENTER to quit");\n            try\n            {\n                System.Console.Read();\n            }\n            catch (System.IO.IOException)\n            {\n            }\n        }\n    }\n}\n')),(0,a.kt)("p",null,"This covered my bases. It was simple, it was easy to consume and it didn't require any custom types. My mini-API is only really catering for my own needs (unsurprisingly). However, there's lots more to the Bloomberg Open API and I may end up taking this further in the future if I encounter use cases that my current API doesn't cover."),(0,a.kt)("h2",o({},{id:"updated-07122012"}),"Updated (07/12/2012)"),(0,a.kt)("p",null,"Finally, a PS. I found in the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.openbloomberg.com/faq/"}),"Open API FAQs")," that ",(0,a.kt)("em",{parentName:"p"},'"Testing any of that functionality currently requires a valid Bloomberg Desktop API (DAPI), Server API (SAPI) or Managed B-Pipe subscription. Bloomberg is planning on releasing a stand-alone simulator which will not require a subscription."')," There isn't any word yet on this stand-alone simulator. I emailed Bloomberg at ",(0,a.kt)("a",o({parentName:"p"},{href:"mailto:open-tech@bloomberg.net"}),"open-tech@bloomberg.net")," to ask about this. They kindly replied that ",(0,a.kt)("em",{parentName:"p"},'"Unfortunately it is not yet available. We understand that this makes testing API applications somewhat impractical, so we\'re continuing to work on this tool."')," Fingers crossed for something we can test soon!"),(0,a.kt)("h2",o({},{id:"note-to-self-because-i-keep-forgetting"}),"Note to self (because I keep forgetting)"),(0,a.kt)("p",null,"If you're looking to investigate what data is available about a security in Bloomberg it's worth typing \u201c",(0,a.kt)("inlineCode",{parentName:"p"},"FLDS&lt;GO&gt;"),"\u201d into Bloomberg. This is the Bloomberg Fields Finder. Likewise, if you're trying to find a security you could try typing \u201c",(0,a.kt)("inlineCode",{parentName:"p"},"SECF&lt;GO&gt;"),"\u201d into Bloomberg as this is the Security Finder."))}d.isMDXComponent=!0},10528:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"html-to-pdf-using-wcf-service",title:"HTML to PDF using a WCF Service",authors:"johnnyreilly",tags:["wkhtmltopdf","WCF","pdf"],hide_table_of_contents:!1},s=void 0,l={permalink:"/html-to-pdf-using-wcf-service",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-01-03-html-to-pdf-using-wcf-service/index.md",source:"@site/blog/2013-01-03-html-to-pdf-using-wcf-service/index.md",title:"HTML to PDF using a WCF Service",description:'TL; DR - "Talk is cheap. Show me the code."',date:"2013-01-03T00:00:00.000Z",formattedDate:"January 3, 2013",tags:[{label:"wkhtmltopdf",permalink:"/tags/wkhtmltopdf"},{label:"WCF",permalink:"/tags/wcf"},{label:"pdf",permalink:"/tags/pdf"}],readingTime:3.13,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"html-to-pdf-using-wcf-service",title:"HTML to PDF using a WCF Service",authors:"johnnyreilly",tags:["wkhtmltopdf","WCF","pdf"],hide_table_of_contents:!1},prevItem:{title:"Twitter.Bootstrap.MVC4 meet Bootstrap Datepicker",permalink:"/twitterbootstrapmvc4-meet-bootstrap"},nextItem:{title:"Getting up to speed with Bloomberg's Open API...",permalink:"/a-nicer-net-api-for-bloombergs-open-api"}},p={authorsImageUrls:[void 0]},u=[{value:"TL; DR - &quot;Talk is cheap. Show me the code.&quot;",id:"tl-dr---talk-is-cheap-show-me-the-code",level:2},{value:"A little more detail",id:"a-little-more-detail",level:2},{value:"That which binds us",id:"that-which-binds-us",level:2},{value:"Good behaviour",id:"good-behaviour",level:2},{value:"Test Harness",id:"test-harness",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"tl-dr---talk-is-cheap-show-me-the-code"}),'TL; DR - "Talk is cheap. Show me the code."'),(0,a.kt)("p",null,"Some time ago I wrote a ",(0,a.kt)("a",o({parentName:"p"},{href:"/making-pdfs-from-html-in-c-using"}),"post which demonstrated how you could make PDFs from HTML")," using C# and ",(0,a.kt)("a",o({parentName:"p"},{href:"http://code.google.com/p/wkhtmltopdf/"}),"wkhtmltopdf"),". To my lasting surprise this has been the most popular post I've written. I recently put together an ASP.NET WCF service which exposed this functionality which I thought might be worth sharing. The code can be found on GitHub ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/PdfMakerWcfService"}),"here"),"."),(0,a.kt)("h2",o({},{id:"a-little-more-detail"}),"A little more detail"),(0,a.kt)("p",null,"I should say up front that I'm still a little ambivalent about how sensible an idea this is. Behind the scenes this WCF service is remotely firing up wkhtmltopdf using ",(0,a.kt)("inlineCode",{parentName:"p"},"System.Diagnostics.Process"),". I feel a little wary about recommending this as a solution for a variety of not particularly defined reasons. However, I have to say I've found this pretty stable and reliable. Bottom line it seems to work and work consistently. But I though I should include a caveat emptor; there is probably a better approach than this available. Anyway..."),(0,a.kt)("p",null,"There isn't actually a great deal to say about this WCF service. It should (hopefully) just do what it says on the tin. Putting it together didn't involve a great deal of work; essentially it takes the code from the initial blog post and just wraps it in a WCF service called ",(0,a.kt)("inlineCode",{parentName:"p"},"PdfMaker"),". The service exposes 2 methods:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"GetPdf")," ","-"," given a supplied URL this method creates a PDF and then returns it as a Stream to the client"),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"GetPdfUrl")," ","-"," given a supplied URL this method creates a PDF and then returns the location of it to the client")),(0,a.kt)("p",null,"Both of these methods also set a Location header in the response indicating the location of the created PDF."),(0,a.kt)("h2",o({},{id:"that-which-binds-us"}),"That which binds us"),(0,a.kt)("p",null,"The service uses ",(0,a.kt)("inlineCode",{parentName:"p"},"webHttpBinding"),'. This is commonly employed when people want to expose a RESTful WCF service. The reason I\'ve used this binding is I wanted a simple "in" when calling the service. I wanted to be able to call the service via AJAX as well as directly by browsing to the service and supplying a URL-encoded URL like this:'),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"http://localhost:59002/PdfMaker.svc/GetPdf?url=http%3A%2F%2Fnews.ycombinator.com/"),"You may wonder why I'm using ",(0,a.kt)("a",o({parentName:"p"},{href:"http://news.ycombinator.com"}),"http://news.ycombinator.com")," for the example above. I chose this as Hacker News is a very simple site; very few resources and a small page size. This means the service has less work to do when creating the PDF; it's a quick demo."),(0,a.kt)("p",null,"I should say that this service is arguably ","*","*","not","*","*"," completely RESTful as each GET operation behind the scenes attempts to create a new PDF (arguably a side-effect). These should probably be POST operations as they create a new resource each time they're hit. However, if they were I wouldn't be able to just enter a URL into a browser for testing and that's really useful. So tough, I shake my fist at the devotees of pure REST on this occasion. (If I should be attacked in the street shortly after this blog is posted then the police should be advised this is good line of inquiry...)"),(0,a.kt)("h2",o({},{id:"good-behaviour"}),"Good behaviour"),(0,a.kt)("p",null,"It's worth noting that ",(0,a.kt)("inlineCode",{parentName:"p"},"automaticFormatSelectionEnabled")," set to true on the behaviour so that content negotiation is enabled. Obviously for the ",(0,a.kt)("inlineCode",{parentName:"p"},"GetPdf")," action this is rather meaningless as it's a stream that's passed back. However, for the ",(0,a.kt)("inlineCode",{parentName:"p"},"GetPdfUrl")," action the returned string can either be JSON or XML. The Fiddler screenshots below demonstrate this in action."),(0,a.kt)("h2",o({},{id:"test-harness"}),"Test Harness"),(0,a.kt)("p",null,"As a final touch I added in a test harness in the form of ",(0,a.kt)("inlineCode",{parentName:"p"},"Demo.aspx"),". Here's an example of the output generated when pointing at Hacker News:"),(0,a.kt)("iframe",{src:"https://docs.google.com/file/d/0B87K8-qxOZGFMGNCUWRneUFsVFU/preview",width:"500",height:"500"}),(0,a.kt)("p",null,"And that's it. If there was a need this service could be easily extended to leverage the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://madalgo.au.dk/~jakobt/wkhtmltoxdoc/wkhtmltopdf-0.9.9-doc.html"}),"various options")," that wkhtmltopdf makes available. Hope people find it useful."))}d.isMDXComponent=!0},23579:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"twitterbootstrapmvc4-meet-bootstrap",title:"Twitter.Bootstrap.MVC4 meet Bootstrap Datepicker",authors:"johnnyreilly",tags:["asp.net mvc","Bootstrap"],hide_table_of_contents:!1},s=void 0,l={permalink:"/twitterbootstrapmvc4-meet-bootstrap",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-01-09-twitterbootstrapmvc4-meet-bootstrap/index.md",source:"@site/blog/2013-01-09-twitterbootstrapmvc4-meet-bootstrap/index.md",title:"Twitter.Bootstrap.MVC4 meet Bootstrap Datepicker",description:"Updated 14/01/2013",date:"2013-01-09T00:00:00.000Z",formattedDate:"January 9, 2013",tags:[{label:"asp.net mvc",permalink:"/tags/asp-net-mvc"},{label:"Bootstrap",permalink:"/tags/bootstrap"}],readingTime:3.81,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"twitterbootstrapmvc4-meet-bootstrap",title:"Twitter.Bootstrap.MVC4 meet Bootstrap Datepicker",authors:"johnnyreilly",tags:["asp.net mvc","Bootstrap"],hide_table_of_contents:!1},prevItem:{title:"Twitter.Bootstrap.MVC4 meet Bootstrap Datepicker *and* get your Internationalization on...",permalink:"/twitterbootstrapmvc4-meet-bootstrap_14"},nextItem:{title:"HTML to PDF using a WCF Service",permalink:"/html-to-pdf-using-wcf-service"}},p={authorsImageUrls:[void 0]},u=[{value:"Updated 14/01/2013",id:"updated-14012013",level:2},{value:"Getting Responsive",id:"getting-responsive",level:2},{value:"I like ASP.Net MVC...",id:"i-like-aspnet-mvc",level:2},{value:"Bootstrap Datepicker",id:"bootstrap-datepicker",level:2},{value:"Shake hands and play nice...",id:"shake-hands-and-play-nice",level:2},{value:"Still to do",id:"still-to-do",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"updated-14012013"}),"Updated 14/01/2013"),(0,a.kt)("p",null,"Since I wrote this I've taken things on a little further - to read about that go ",(0,a.kt)("a",o({parentName:"p"},{href:"/twitterbootstrapmvc4-meet-bootstrap_14"}),"here"),"."),(0,a.kt)("h2",o({},{id:"getting-responsive"}),"Getting Responsive"),(0,a.kt)("p",null,"It's the new year, it's time for new things. Long on my list of \"things to do\" was getting up to speed with ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Responsive_web_design"}),"Responsive web design"),". No doubt like everyone else I've been hearing more and more about this over the last year (by the way there was a ",(0,a.kt)("a",o({parentName:"p"},{href:"http://mashable.com/2012/12/11/responsive-web-design/"}),"good article on Mashable")," about this last month). RWD (in case you don't already know) is pretty much about having web interfaces that format their presentation based on the device they're running to provide a good user experience. (I kind of think of it as a ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Write_once,_run_anywhere"}),"write once, run anywhere")," approach - though hopefully without the negative connotations...)"),(0,a.kt)("p",null,"Rather than diving straight in myself I'd heard at a user group that it might be worth taking ",(0,a.kt)("a",o({parentName:"p"},{href:"http://twitter.github.com/bootstrap/"}),"Twitter Bootstrap")," as a baseline. I'm a ",(0,a.kt)("strike",null,"lazy")),(0,a.kt)("p",null,"busy fellow so this sounded ideal."),(0,a.kt)("h2",o({},{id:"i-like-aspnet-mvc"}),"I like ASP.Net MVC..."),(0,a.kt)("p",null,"... and this flavoured my investigations. I quickly stumbled on an ",(0,a.kt)("a",o({parentName:"p"},{href:"http://lostechies.com/erichexter/2012/11/20/twitter-bootstrap-mvc4-the-template-nuget-package-for-asp-net-mvc4-projects/"}),"article written by Eric Hexter"),". Eric had brought together Twitter Bootstrap and ASP.Net MVC 4 in a ",(0,a.kt)("a",o({parentName:"p"},{href:"http://nuget.org/packages/twitter.bootstrap.mvc4"}),"NuGet package"),". Excellent work chap!"),(0,a.kt)("p",null,"To get up and running with Eric's work was a straightforward proposition. I..."),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Created new MVC 4 application in Visual Studio called \u201cBootstrapMvcSample\u201d using the \u201cEmpty\u201d Project Template."),(0,a.kt)("li",{parentName:"ol"},"Executed the following commands at the NuGet Package Manager Console: - ",(0,a.kt)("inlineCode",{parentName:"li"},"Install-Package twitter.bootstrap.mvc4"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Install-Package twitter.bootstrap.mvc4.sample"))))),(0,a.kt)("p",null,"This is just 1 page, with ",(0,a.kt)("inlineCode",{parentName:"p"},"@media")," queries doing the heavy lifting."),(0,a.kt)("h2",o({},{id:"bootstrap-datepicker"}),"Bootstrap Datepicker"),(0,a.kt)("p",null,"The eagle-eyed amongst you will have noticed that the edit screen above features a date field. I've long been a fan of datepickers to allow users to enter a date in an application in an intuitive fashion. Until native browser datepickers become the norm we'll be relying on some kind of component. Up until now my datepicker of choice has been the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://jqueryui.com/datepicker/"}),"jQuery UI one"),". Based on a quick Google it seemed that jQuery UI and Twitter Bootstrap were not necessarily natural bedfellows. (Though ",(0,a.kt)("a",o({parentName:"p"},{href:"http://addyosmani.github.com/jquery-ui-bootstrap/"}),"Addy Osmani's jQuery UI Bootstrap")," shows some promise...)"),(0,a.kt)("p",null,"Since I feared ending up down a blind alley I found myself casting around for a Twitter Bootstrap datepicker. I quickly happened upon ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.eyecon.ro/bootstrap-datepicker/"}),"Stefan Petre's Bootstrap Datepicker")," which looked just the ticket."),(0,a.kt)("h2",o({},{id:"shake-hands-and-play-nice"}),"Shake hands and play nice..."),(0,a.kt)("p",null,"Incorporating the Bootstrap Datepicker into Twitter.Bootstrap.MVC4 was actually a pretty straightforward affair. I added the following datepicker assets to the ASP.Net MVC project as follows:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"bootstrap-datepicker.js")," was added to ",(0,a.kt)("inlineCode",{parentName:"li"},"~\\Scripts"),"."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"datepicker.css")," was added to ",(0,a.kt)("inlineCode",{parentName:"li"},"~\\Content"),". I renamed this file to ",(0,a.kt)("inlineCode",{parentName:"li"},"bootstrap-datepicker.css")," to stay in line with the other css files.")),(0,a.kt)("p",null,"Once this was done I amended the ",(0,a.kt)("inlineCode",{parentName:"p"},"BootstrapBundleConfig.cs")," bundles to include these assets. Once this was done the bundle file looked like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System.Web;\nusing System.Web.Mvc;\nusing System.Web.Optimization;\n\nnamespace BootstrapSupport\n{\n    public class BootstrapBundleConfig\n    {\n        public static void RegisterBundles(BundleCollection bundles)\n        {\n            bundles.Add(new ScriptBundle("~/js").Include(\n                "~/Scripts/jquery-1.*",\n                "~/Scripts/bootstrap.js",\n                "~/Scripts/bootstrap-datepicker.js", // ** NEW for Bootstrap Datepicker\n                "~/Scripts/jquery.validate.js",\n                "~/scripts/jquery.validate.unobtrusive.js",\n                "~/Scripts/jquery.validate.unobtrusive-custom-for-bootstrap.js"\n                ));\n\n            bundles.Add(new StyleBundle("~/content/css").Include(\n                "~/Content/bootstrap.css",\n                "~/Content/bootstrap-datepicker.css" // ** NEW for Bootstrap Datepicker\n                ));\n\n            bundles.Add(new StyleBundle("~/content/css-responsive").Include(\n                "~/Content/bootstrap-responsive.css"\n                ));\n        }\n    }\n}\n')),(0,a.kt)("p",null,"I then created this folder:",(0,a.kt)("inlineCode",{parentName:"p"},"~\\Views\\Shared\\EditorTemplates"),". To this folder I added the following ",(0,a.kt)("inlineCode",{parentName:"p"},"Date.cshtml")," Partial to hold the datepicker EditorTemplate: (Having this in place meant that properties with the ",(0,a.kt)("inlineCode",{parentName:"p"},"[DataType(DataType.Date)]")," attribute would automatically use this EditorTemplate when rendering an editor - I understand ",(0,a.kt)("inlineCode",{parentName:"p"},"[UIHint]")," attributes can be used to the same end.)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'@model DateTime?\n@Html.TextBox("", (Model.HasValue ? Model.Value.ToShortDateString() : string.Empty), new {\n    @class = "datepicker",\n    data_date_format = System.Globalization.CultureInfo.CurrentCulture.DateTimeFormat.ShortDatePattern.ToLower()\n})\n')),(0,a.kt)("p",null,"And finally I amended the ",(0,a.kt)("inlineCode",{parentName:"p"},"Create.cshtml")," View (which perhaps more accurately might be called the Edit View?) to include a bit of JavaScript at the bottom to initialise any datepickers on the screen."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'@using BootstrapSupport\n@model Object\n@using (Html.BeginForm())\n{\n    @Html.ValidationSummary(true)\n    <fieldset class="form-horizontal">\n        <legend>@Model.GetLabel() <small>Details</small></legend>\n        @foreach (var property in Model.VisibleProperties())\n        {\n            @Html.BeginControlGroupFor(property.Name)\n                @Html.Label(property.Name.ToSeparatedWords(), new { @class = "control-label" })\n                <div class="controls">\n                    @Html.Editor(property.Name, new { @class = "input-xlarge" })\n                    @Html.ValidationMessage(property.Name, null, new { @class = "help-inline" })\n            </div>\n            @Html.EndControlGroup()\n        }\n        <div class="form-actions">\n            <button type="submit" class="btn btn-primary">Save changes</button>\n            @Html.ActionLink("Cancel",  "Index", null, new {@class = "btn "})\n          </div>\n    </fieldset>\n}\n<div>\n    @Html.ActionLink("Back to List", "Index")\n</div>\n\n@section Scripts {\n<script type="text/javascript">\n    $(\'.datepicker\').datepicker(); //Initialise any date pickers\n<\/script>\n}\n')),(0,a.kt)("p",null,"Et voil\xe0 - it works!"),(0,a.kt)("p",null,"My thanks to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/ehexter"}),"Eric Hexter")," and Stefan Petre for doing all the hard work!"),(0,a.kt)("h2",o({},{id:"still-to-do"}),"Still to do"),(0,a.kt)("p",null,"I haven't really tested how this all fits together (if at all) with browsers running a non-English culture. There may still be a little tinkering require to get that working..."))}d.isMDXComponent=!0},25770:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"twitterbootstrapmvc4-meet-bootstrap_14",title:"Twitter.Bootstrap.MVC4 meet Bootstrap Datepicker *and* get your Internationalization on...",authors:"johnnyreilly",tags:["Globalization","Bootstrap"],hide_table_of_contents:!1},s=void 0,l={permalink:"/twitterbootstrapmvc4-meet-bootstrap_14",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-01-14-twitterbootstrapmvc4-meet-bootstrap_14/index.md",source:"@site/blog/2013-01-14-twitterbootstrapmvc4-meet-bootstrap_14/index.md",title:"Twitter.Bootstrap.MVC4 meet Bootstrap Datepicker *and* get your Internationalization on...",description:"Last time I wrote about marrying up Twitter.Bootstrap.MVC4 and Bootstrap Datepicker. It came together quite nicely but when I took a more in depth look at what I'd done I discovered a problem. The brief work on regionalisation / internationalisation / localisation / globalisation / whatever it's called this week... wasn't really working. We had problems with the validation.",date:"2013-01-14T00:00:00.000Z",formattedDate:"January 14, 2013",tags:[{label:"Globalization",permalink:"/tags/globalization"},{label:"Bootstrap",permalink:"/tags/bootstrap"}],readingTime:5.565,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"twitterbootstrapmvc4-meet-bootstrap_14",title:"Twitter.Bootstrap.MVC4 meet Bootstrap Datepicker *and* get your Internationalization on...",authors:"johnnyreilly",tags:["Globalization","Bootstrap"],hide_table_of_contents:!1},prevItem:{title:"Using Expressions with Constructors",permalink:"/using-expressions-with-constructors"},nextItem:{title:"Twitter.Bootstrap.MVC4 meet Bootstrap Datepicker",permalink:"/twitterbootstrapmvc4-meet-bootstrap"}},p={authorsImageUrls:[void 0]},u=[{value:"Going global down in Acapulco",id:"going-global-down-in-acapulco",level:2},{value:"Culture-specific script bundles",id:"culture-specific-script-bundles",level:2},{value:"Where have we got to?",id:"where-have-we-got-to",level:2},{value:"International Bootstrap Datepicker",id:"international-bootstrap-datepicker",level:2},{value:"Summary",id:"summary",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"/twitterbootstrapmvc4-meet-bootstrap"}),"Last time")," I wrote about marrying up Twitter.Bootstrap.MVC4 and Bootstrap Datepicker. It came together quite nicely but when I took a more in depth look at what I'd done I discovered a problem. The brief work on regionalisation / internationalisation / localisation / globalisation / whatever it's called this week... wasn't really working. We had problems with the validation."),(0,a.kt)("p",null,"I also discovered that Stefan Petre's Bootstrap Datepicker appears to have been abandoned. Andrew Rowls has taken it on and created a GitHub repository for it ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/eternicode/bootstrap-datepicker"}),"here"),". Besides bug fixes he's also introduced the ability for the Bootstrap Datepicker to customised for different cultures."),(0,a.kt)("p",null,"Since these 2 subjects are linked I tackled them together and thought it might be worth writing up here. You can find the conclusion of my work in a GitHub repository I created ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/BootstrapMvcSample"}),"here"),"."),(0,a.kt)("h2",o({},{id:"going-global-down-in-acapulco"}),"Going global down in Acapulco"),(0,a.kt)("p",null,"First step in internationalising any ASP.Net web app is adding the following to the ",(0,a.kt)("inlineCode",{parentName:"p"},"web.config"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<?xml version="1.0" encoding="utf-8"?>\n<configuration>\n  <system.web>\n\n    \x3c!-- Other stuff here... --\x3e\n\n    <globalization\n      culture="auto"\n      uiCulture="auto"\n      enableClientBasedCulture="true" />\n  </system.web>\n\n  \x3c!-- ...and here --\x3e\n\n</configuration>\n')),(0,a.kt)("p",null,"Then I pulled ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jquery/globalize"}),"Globalize")," and the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/eternicode/bootstrap-datepicker"}),"Andrew Rowls fork of Bootstrap Datepicker")," into the project (replacing Stefan's original assets). As well as this I pulled in the ",(0,a.kt)("inlineCode",{parentName:"p"},"jQuery.validate.globalize.js")," extension ",(0,a.kt)("a",o({parentName:"p"},{href:"/globalize-and-jquery-validate"}),"I wrote about here"),". (This replaces some of the default jQuery Validate functionality for culture-specific functionality based on Globalize.) This extension depends on a meta tag that is generated using the following file (which also handles the serving up of the relevant JavaScript culture bundles, more of which shortly):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Collections.Generic;\nusing System.IO;\nusing System.Globalization;\nusing System.Linq;\nusing System.Web;\n\nnamespace System.Web.Mvc\n{\n    public static class GlobalizationHelpers\n    {\n        /// <summary>\n        /// Taken from Scott Hanselman\'s blog post: http://www.hanselman.com/blog/GlobalizationInternationalizationAndLocalizationInASPNETMVC3JavaScriptAndJQueryPart1.aspx\n        /// </summary>\n        /// <typeparam name="t"></typeparam>\n        /// <param name="htmlHelper"></param>\n        /// <returns></returns>\n        public static IHtmlString MetaAcceptLanguage<t>(this HtmlHelper<t> htmlHelper)\n        {\n            var acceptLanguage = HttpUtility.HtmlAttributeEncode(CultureInfo.CurrentUICulture.ToString());\n            return new HtmlString(string.Format("<meta name=\\"accept-language\\" content=\\"{0}\\" />", acceptLanguage));\n        }\n\n        /// <summary>\n        /// Return the JavaScript bundle for this users culture\n        /// </summary>\n        /// <typeparam name="t"></typeparam>\n        /// <param name="htmlHelper"></param>\n        /// <returns>a culture bundle that looks something like this: "~/js-culture.en-GB"</returns>\n        public static string JsCultureBundle<t>(this HtmlHelper<t> htmlHelper)\n        {\n            return "~/js-culture." + CultureInfo.CurrentUICulture.ToString();\n        }\n    }\n}\n')),(0,a.kt)("h2",o({},{id:"culture-specific-script-bundles"}),"Culture-specific script bundles"),(0,a.kt)("p",null,"With all of my dependancies in place I was now ready to press on. Since both Globalize and the new Bootstrap Datepicker come with their own culture-specific JavaScript files it seemed a good idea to make use of ASP.Nets new bundling functionality. This I did here:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Web;\nusing System.Web.Mvc;\nusing System.Web.Optimization;\nusing System.Globalization;\nusing System.IO;\nusing System.Linq;\n\nnamespace BootstrapSupport\n{\n    public class BootstrapBundleConfig\n    {\n        public static void RegisterBundles(BundleCollection bundles)\n        {\n            bundles.Add(new ScriptBundle("~/js").Include(\n                "~/Scripts/jquery-*",\n                "~/Scripts/globalize.js", //The Globalize library\n                "~/Scripts/bootstrap.js",\n                "~/Scripts/bootstrap-datepicker.js", //This is the brand new internationalised Bootstrap Datepicker\n                "~/Scripts/jquery.validate.js",\n                "~/Scripts/jquery.validate.unobtrusive.js",\n                "~/Scripts/jquery.validate.unobtrusive-custom-for-bootstrap.js",\n                "~/Scripts/jquery.validate.globalize.js" //My jQuery Validate extension which depends on Globalize\n                ));\n\n            //Create culture specific bundles which contain the JavaScript files that should be served for each culture\n            foreach (var culture in CultureInfo.GetCultures(CultureTypes.AllCultures))\n            {\n                bundles.Add(new ScriptBundle("~/js-culture." + culture.Name).Include( //example bundle name would be "~/js-culture.en-GB"\n                    DetermineCultureFile(culture, "~/Scripts/globalize-cultures/globalize.culture.{0}.js"),             //The Globalize locale-specific JavaScript file\n                    DetermineCultureFile(culture, "~/Scripts/bootstrap-datepicker-locales/bootstrap-datepicker.{0}.js") //The Bootstrap Datepicker locale-specific JavaScript file\n                ));\n            }\n\n            bundles.Add(new StyleBundle("~/content/css").Include(\n                "~/Content/bootstrap.css",\n                "~/Content/bootstrap-datepicker.css"\n                ));\n\n            bundles.Add(new StyleBundle("~/content/css-responsive").Include(\n                "~/Content/bootstrap-responsive.css"\n                ));\n        }\n\n        /// <summary>\n        /// Given the supplied culture, determine the most appropriate Globalize culture script file that should be served up\n        /// </summary>\n        /// <param name="culture"></param>\n        /// <param name="filePattern">a file pattern, eg "~/Scripts/globalize-cultures/globalize.culture.{0}.js"</param>\n        /// <param name="defaultCulture">Default culture string to use (eg "en-GB") if one cannot be found for the supplied culture</param>\n        /// <returns></returns>\n        private static string DetermineCultureFile(CultureInfo culture,\n            string filePattern,\n            string defaultCulture = "en-GB" // I\'m a Brit and this is my default\n            )\n        {\n            //Determine culture - GUI culture for preference, user selected culture as fallback\n            var regionalisedFileToUse = string.Format(filePattern, defaultCulture);\n\n            //Try to pick a more appropriate regionalisation if there is one\n            if (File.Exists(HttpContext.Current.Server.MapPath(string.Format(filePattern, culture.Name)))) //First try for a globalize.culture.en-GB.js style file\n                regionalisedFileToUse = string.Format(filePattern, culture.Name);\n            else if (File.Exists(HttpContext.Current.Server.MapPath(string.Format(filePattern, culture.TwoLetterISOLanguageName)))) //That failed; now try for a globalize.culture.en.js style file\n                regionalisedFileToUse = string.Format(filePattern, culture.TwoLetterISOLanguageName);\n\n            return regionalisedFileToUse;\n        }\n\n    }\n}\n')),(0,a.kt)("p",null,"The code above creates a script bundle for each culture when the application starts up. This script bundle contains the culture-specific Globalize and Bootstrap Datepicker JavaScript files. If further culture-specific components were added to the application it would make sense to include these here as well."),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"_BootstrapLayout.basic.cshtml")," has been amended to make use of the new bundles and also to include a meta tag that will used to drive regionalisation:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<!DOCTYPE html>\n<html lang="en">\n  <head>\n    \x3c!-- Existing head content goes here --\x3e\n\n    \x3c!-- Added to the head to serve a meta tag like this: <meta name="accept-language" content="en-GB" /> --\x3e\n    @Html.MetaAcceptLanguage()\n\n    \x3c!-- Existing head content continues here --\x3e\n  </head>\n  <body>\n    \x3c!-- Existing body content goes here --\x3e\n\n    \x3c!-- Replaces the existing @Scripts.Render --\x3e\n    @Scripts.Render( "~/js", Html.JsCultureBundle() //Serves up the\n    "~/js-culture.de-DE" bundle for example )\n\n    \x3c!-- Existing body content continues here --\x3e\n  </body>\n</html>\n')),(0,a.kt)("p",null,"To illustrate how this works, a German user running a machine with the de-DE culture would be served up the following 2 files:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"globalize.culture.de-DE.js")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"bootstrap-datepicker.de.js"))),(0,a.kt)("h2",o({},{id:"where-have-we-got-to"}),"Where have we got to?"),(0,a.kt)("p",null,"With all this done we have now fixed the validation issues we were experiencing previously. This was done by including the Globalize library, the accept-language meta tag and the jQuery Validate Globalize extensions."),(0,a.kt)("p",null,"Besides this we've laid the groundwork for introducing internationalised datepickers by introducing Andrew Rowls fork of the Bootstrap Datepicker. That's what we'll do next..."),(0,a.kt)("h2",o({},{id:"international-bootstrap-datepicker"}),"International Bootstrap Datepicker"),(0,a.kt)("p",null,"The final steps of switching over to using a culture-specific date picker are achieved by making a change to the Scripts section in the ",(0,a.kt)("inlineCode",{parentName:"p"},"Create.cshtml")," file. The existing (and very simple) section should be replaced with this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'@section Scripts {\n<script type="text/javascript">\n    var currentCulture = $("meta[name=\'accept-language\']").prop("content"),\n        language;\n    // Set Globalize to the current culture driven by the meta tag (if any)\n    if (currentCulture) {\n        language = (currentCulture in $.fn.datepicker.dates)\n            ? currentCulture //a language exists which looks like "zh-CN" so we\'ll use it\n            : currentCulture.split("-")[0]; //we\'ll try for a language that looks like "de" and use it if it exists (otherwise it will fall back to the default)\n    }\n    //Initialise any date pickers\n    $(\'.datepicker\').datepicker({ language: language });\n<\/script>\n}\n')),(0,a.kt)("p",null,'The script above takes the region from the accept-language meta tag and attempts to look up an associated "language" for the Bootstrap Datepicker. If it finds one it uses it, if not then the default language of "en" / English will be used.'),(0,a.kt)("h2",o({},{id:"summary"}),"Summary"),(0,a.kt)("p",null,"In this post we:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"fixed the validation issues we'd introduced by marrying up Twitter.Bootstrap.MVC4 and the Bootstrap Datepicker"),(0,a.kt)("li",{parentName:"ol"},"switched over to using the Andrew Rowls fork of Bootstrap Datepicker and made use of the internationalisation functionality it exposes.")))}d.isMDXComponent=!0},7550:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"using-expressions-with-constructors",title:"Using Expressions with Constructors",authors:"johnnyreilly",tags:[".NET"],hide_table_of_contents:!1},s=void 0,l={permalink:"/using-expressions-with-constructors",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-02-13-using-expressions-with-constructors/index.md",source:"@site/blog/2013-02-13-using-expressions-with-constructors/index.md",title:"Using Expressions with Constructors",description:"Every now and then you think \"x should be easy\" - and it isn't. I had one of those situations this morning. Something I thought would take 5 minutes had me still pondering 30 minutes later. I finally cracked it (with the help of a colleague - thanks Marc!) and I wanted to note down what I did since I'm sure to forget this.",date:"2013-02-13T00:00:00.000Z",formattedDate:"February 13, 2013",tags:[{label:".NET",permalink:"/tags/net"}],readingTime:2.835,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"using-expressions-with-constructors",title:"Using Expressions with Constructors",authors:"johnnyreilly",tags:[".NET"],hide_table_of_contents:!1},prevItem:{title:"Unit testing MVC controllers / Mocking UrlHelper",permalink:"/unit-testing-mvc-controllers-mocking"},nextItem:{title:"Twitter.Bootstrap.MVC4 meet Bootstrap Datepicker *and* get your Internationalization on...",permalink:"/twitterbootstrapmvc4-meet-bootstrap_14"}},p={authorsImageUrls:[void 0]},u=[{value:"So what&#39;s the problem?",id:"so-whats-the-problem",level:2},{value:"So what&#39;s the solution?",id:"so-whats-the-solution",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Every now and then you think \"x should be easy\" - and it isn't. I had one of those situations this morning. Something I thought would take 5 minutes had me still pondering 30 minutes later. I finally cracked it (with the help of a colleague - thanks Marc!) and I wanted to note down what I did since I'm sure to forget this."),(0,a.kt)("h2",o({},{id:"so-whats-the-problem"}),"So what's the problem?"),(0,a.kt)("p",null,"In our project we had a very simple validation class. It looked a bit like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"    public class FieldValidation\n    {\n        public FieldValidation(string fieldName, string message)\n        {\n            FieldName = fieldName;\n            Message = message;\n        }\n\n        public string FieldName { get; set; }\n        public string Message { get; set; }\n    }\n")),(0,a.kt)("p",null,"I wanted to take this class and extend it to have a constructor which allowed me to specify a Type and subsequently an Expression of that Type that allowed me to specify a property. 10 points if you read the last sentence and understood it without reading it a second time."),(0,a.kt)("p",null,"Code is a better illustration; take a look below. I wanted to go from #1 to #2:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'//#1 Specify field name up front - how we currently use this\nvar oldSchoolValidation = new FieldValidation(\n  "WithAProperty", "Message of some kind...");\n\n//#2 Field name driven directly by property - how we want to use this\nvar newSchoolValidation = new FieldValidation<AnObject>(\n  x => x.WithAProperty, "Message of some kind...");\n\n/// <summary>\n/// Example class for demo\n/// </summary>\npublic class AnObject\n{\n  public bool WithAProperty { get; set; }\n}\n')),(0,a.kt)("p",null,'"Why?" I hear you ask. Well we had a swathe of statements in the code which test each property for a problem and would create a ',(0,a.kt)("inlineCode",{parentName:"p"},"FieldValidation")," with the very same property name if one was found. There's no real problem with that but I'm a man that likes to refactor. Property names change and I didn't want to have to remember to manually go through each ",(0,a.kt)("inlineCode",{parentName:"p"},"FieldValidation")," keeping these in line. If I was using the actual property name to drive the creation of my ",(0,a.kt)("inlineCode",{parentName:"p"},"FieldValidations")," then that problem disappears. And I like that."),(0,a.kt)("h2",o({},{id:"so-whats-the-solution"}),"So what's the solution?"),(0,a.kt)("p",null,"Well it's this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'    public class FieldValidation\n    {\n        public FieldValidation(string fieldName, string message)\n        {\n            FieldName = fieldName;\n            Message = message;\n        }\n\n        public string FieldName { get; set; }\n        public string Message { get; set; }\n    }\n\n    public class FieldValidation<T> : FieldValidation where T : class\n    {\n        public FieldValidation(\n            Expression<Func<T, object>> expression,\n            string message)\n        {\n            //Will work for reference types\n            var body = expression.Body as MemberExpression;\n\n            if (body == null)\n            {\n                //Will work for value types\n                var uBody = (UnaryExpression)expression.Body;\n                body = uBody.Operand as MemberExpression;\n            }\n\n\n            if (body == null)\n                throw new ArgumentException("Invalid property expression");\n\n            FieldName = body.Member.Name;\n            Message = message;\n        }\n    }\n')),(0,a.kt)("p",null,"As you can see we have taken the original FieldValidation class and added in a generic constructor which instead of taking ",(0,a.kt)("inlineCode",{parentName:"p"},"string fieldName")," as a first argument it takes ",(0,a.kt)("inlineCode",{parentName:"p"},"Expression&lt;Func&lt;T, object&gt;&gt; expression"),". LINQ's Expression magic is used to determine the supplied property name which is smashing. If you were wondering, the first ",(0,a.kt)("inlineCode",{parentName:"p"},"MemberExpression")," code is used for ",(0,a.kt)("em",{parentName:"p"},"reference")," types. The ",(0,a.kt)("inlineCode",{parentName:"p"},"UnaryExpression")," wrapping a ",(0,a.kt)("inlineCode",{parentName:"p"},"MemberExpression")," code is used for ",(0,a.kt)("em",{parentName:"p"},"value")," types. A good explanation of this can be found ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/12975480/761388"}),"here"),"."),(0,a.kt)("p",null,"My colleague directed me to ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/2916344"}),"this crucial StackOverflow answer")," which provided some much needed direction when I was thrashing. And that's it; we're done, home free."))}d.isMDXComponent=!0},9120:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"unit-testing-mvc-controllers-mocking",title:"Unit testing MVC controllers / Mocking UrlHelper",authors:"johnnyreilly",tags:["asp.net"],hide_table_of_contents:!1},s=void 0,l={permalink:"/unit-testing-mvc-controllers-mocking",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-02-18-unit-testing-mvc-controllers-mocking/index.md",source:"@site/blog/2013-02-18-unit-testing-mvc-controllers-mocking/index.md",title:"Unit testing MVC controllers / Mocking UrlHelper",description:"I have put a name to my pain...",date:"2013-02-18T00:00:00.000Z",formattedDate:"February 18, 2013",tags:[{label:"asp.net",permalink:"/tags/asp-net"}],readingTime:5.72,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"unit-testing-mvc-controllers-mocking",title:"Unit testing MVC controllers / Mocking UrlHelper",authors:"johnnyreilly",tags:["asp.net"],hide_table_of_contents:!1},prevItem:{title:"Unit testing ModelState",permalink:"/unit-testing-modelstate"},nextItem:{title:"Using Expressions with Constructors",permalink:"/using-expressions-with-constructors"}},p={authorsImageUrls:[void 0]},u=[{value:"I have put a name to my pain...",id:"i-have-put-a-name-to-my-pain",level:2},{value:"Getting disillusioned",id:"getting-disillusioned",level:2},{value:"MvcMockControllers updated",id:"mvcmockcontrollers-updated",level:2},{value:"What I want to test",id:"what-i-want-to-test",level:2},{value:"Enough of the waffle - show me a unit test",id:"enough-of-the-waffle---show-me-a-unit-test",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"i-have-put-a-name-to-my-pain"}),"I have put a name to my pain..."),(0,a.kt)("p",null,"And it is unit testing ASP.Net MVC controllers."),(0,a.kt)("p",null,"Well perhaps that's unfair. I have no problem unit testing MVC controllers.... ",(0,a.kt)("strong",{parentName:"p"},"until"),' it comes to making use of the "innards" of MVC. Let me be more specific. This week I had a controller action that I needed to test. It looked a little like this:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System.Collections.Generic;\nusing System.Linq;\nusing System.Web.Mvc;\n\nnamespace DemoApp.Areas.Demo.Controllers\n{\n    public class DemoController : System.Web.Mvc.Controller\n    {\n        //....\n\n        public JsonResult Edit(AnObject anObject)\n        {\n            //Indicate to the client we have saved and pass back the redirect URL\n            return Json(new {\n                Saved = true,\n                RedirectUrl = Url.Action("Details", anObject.AnotherTypeOfId)\n                });\n        }\n\n        //....\n    }\n}\n')),(0,a.kt)("p",null,"Looks fine right? It's an action that takes a simple object as an argument. That's ok. It returns a JsonResult. No worries. The JsonResult consists of an anonymous class. De nada. The anonymous class has one property that is driven by the controllers ",(0,a.kt)("inlineCode",{parentName:"p"},"UrlHelper"),". Yeah that shouldn't be an issue... ",(0,a.kt)("strong",{parentName:"p"},"Hold your horses sunshine - you're going nowhere!")),(0,a.kt)("h2",o({},{id:"getting-disillusioned"}),"Getting disillusioned"),(0,a.kt)("p",null,"Yup, the minute you start pumping in asserts around that ",(0,a.kt)("inlineCode",{parentName:"p"},"UrlHelper")," driven property you're going to be mighty disappointed. What, you didn't expect the result to be ",(0,a.kt)("inlineCode",{parentName:"p"},"null"),"? Damn shame."),(0,a.kt)("p",null,"Despite ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/magazine/dd942838.aspx"}),"articles"),' on MSDN about how the intention is for MVC to be deliberately testable the sad fact of the matter is that there is a yawning hole around the testing support for controllers in ASP.Net MVC. Whenever you try to test something that makes use of controller "gubbins" you have ',(0,a.kt)("strong",{parentName:"p"},"serious")," problems. And unfortunately I didn't find anyone out there who could offer the whole solution."),(0,a.kt)("p",null,"After what I can best describe as a day of pain I found a way to scratch my particular itch. I found a way to write unit tests for controllers that made use of UrlHelper. As a bonus I managed to include the unit testing of Routes and Areas (well kind of) too."),(0,a.kt)("h2",o({},{id:"mvcmockcontrollers-updated"}),"MvcMockControllers updated"),(0,a.kt)("p",null,"This solution is heavily based on the work of Scott Hanselman who ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.hanselman.com/blog/ASPNETMVCSessionAtMix08TDDAndMvcMockHelpers.aspx"}),"wrote and blogged about ",(0,a.kt)("inlineCode",{parentName:"a"},"MvcMockHelpers"))," back in 2008. Essentially I've taken this and tweaked it so I could achieve my ends. My version of ",(0,a.kt)("inlineCode",{parentName:"p"},"MvcMockHelpers")," looks a little like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using Moq;\nusing System;\nusing System.Collections.Specialized;\nusing System.Web;\nusing System.Web.Mvc;\nusing System.Web.Routing;\n\nnamespace UnitTest.TestUtilities\n{\n    /// <summary>\n    /// This class of MVC Mock helpers is originally based on Scott Hanselman\'s 2008 post:\n    /// http://www.hanselman.com/blog/ASPNETMVCSessionAtMix08TDDAndMvcMockHelpers.aspx\n    ///\n    /// This has been updated and tweaked to work with MVC 3 / 4 projects (it hasn\'t been tested with MVC\n    /// 1 / 2 but may work there) and also based my use cases\n    /// </summary>\n    public static class MvcMockHelpers\n    {\n        #region Mock HttpContext factories\n\n        public static HttpContextBase MockHttpContext()\n        {\n            var context = new Mock<HttpContextBase>();\n            var request = new Mock<HttpRequestBase>();\n            var response = new Mock<HttpResponseBase>();\n            var session = new Mock<HttpSessionStateBase>();\n            var server = new Mock<HttpServerUtilityBase>();\n\n            request.Setup(r => r.AppRelativeCurrentExecutionFilePath).Returns("/");\n            request.Setup(r => r.ApplicationPath).Returns("/");\n\n            response.Setup(s => s.ApplyAppPathModifier(It.IsAny<string>())).Returns<string>(s => s);\n            response.SetupProperty(res => res.StatusCode, (int)System.Net.HttpStatusCode.OK);\n\n            context.Setup(h => h.Request).Returns(request.Object);\n            context.Setup(h => h.Response).Returns(response.Object);\n\n            context.Setup(ctx => ctx.Request).Returns(request.Object);\n            context.Setup(ctx => ctx.Response).Returns(response.Object);\n            context.Setup(ctx => ctx.Session).Returns(session.Object);\n            context.Setup(ctx => ctx.Server).Returns(server.Object);\n\n            return context.Object;\n        }\n\n        public static HttpContextBase MockHttpContext(string url)\n        {\n            var context = MockHttpContext();\n            context.Request.SetupRequestUrl(url);\n            return context;\n        }\n\n        #endregion\n\n        #region Extension methods\n\n        public static void SetMockControllerContext(this Controller controller,\n            HttpContextBase httpContext = null,\n            RouteData routeData = null,\n            RouteCollection routes = null)\n        {\n            //If values not passed then initialise\n            routeData = routeData ?? new RouteData();\n            routes = routes ?? RouteTable.Routes;\n            httpContext = httpContext ?? MockHttpContext();\n\n            var requestContext = new RequestContext(httpContext, routeData);\n            var context = new ControllerContext(requestContext, controller);\n\n            //Modify controller\n            controller.Url = new UrlHelper(requestContext, routes);\n            controller.ControllerContext = context;\n        }\n\n        public static void SetHttpMethodResult(this HttpRequestBase request, string httpMethod)\n        {\n            Mock.Get(request).Setup(req => req.HttpMethod).Returns(httpMethod);\n        }\n\n        public static void SetupRequestUrl(this HttpRequestBase request, string url)\n        {\n            if (url == null)\n                throw new ArgumentNullException("url");\n\n            if (!url.StartsWith("~/"))\n                throw new ArgumentException("Sorry, we expect a virtual url starting with \\"~/\\".");\n\n            var mock = Mock.Get(request);\n\n            mock.Setup(req => req.QueryString).Returns(GetQueryStringParameters(url));\n            mock.Setup(req => req.AppRelativeCurrentExecutionFilePath).Returns(GetUrlFileName(url));\n            mock.Setup(req => req.PathInfo).Returns(string.Empty);\n        }\n\n\n        /// <summary>\n        /// Facilitates unit testing of anonymouse types - taken from here:\n        /// http://stackoverflow.com/a/5012105/761388\n        /// </summary>\n        public static object GetReflectedProperty(this object obj, string propertyName)\n        {\n            obj.ThrowIfNull("obj");\n            propertyName.ThrowIfNull("propertyName");\n\n            var property = obj.GetType().GetProperty(propertyName);\n\n            if (property == null)\n                return null;\n\n            return property.GetValue(obj, null);\n        }\n\n        public static T ThrowIfNull<T>(this T value, string variableName) where T : class\n        {\n            if (value == null)\n                throw new NullReferenceException(\n                    string.Format("Value is Null: {0}", variableName));\n\n            return value;\n        }\n\n        #endregion\n\n        #region Private\n\n        static string GetUrlFileName(string url)\n        {\n            return (url.Contains("?"))\n                ? url.Substring(0, url.IndexOf("?"))\n                : url;\n        }\n\n        static NameValueCollection GetQueryStringParameters(string url)\n        {\n            if (url.Contains("?"))\n            {\n                var parameters = new NameValueCollection();\n\n                var parts = url.Split("?".ToCharArray());\n                var keys = parts[1].Split("&".ToCharArray());\n\n                foreach (var key in keys)\n                {\n                    var part = key.Split("=".ToCharArray());\n                    parameters.Add(part[0], part[1]);\n                }\n\n                return parameters;\n            }\n\n            return null;\n        }\n\n        #endregion\n    }\n}\n')),(0,a.kt)("h2",o({},{id:"what-i-want-to-test"}),"What I want to test"),(0,a.kt)("p",null,"I want to be able to unit test the controller ",(0,a.kt)("inlineCode",{parentName:"p"},"Edit")," method I mentioned earlier. This method calls the ",(0,a.kt)("inlineCode",{parentName:"p"},"Action")," method on the controllers ",(0,a.kt)("inlineCode",{parentName:"p"},"Url")," member (which is, in turn, a ",(0,a.kt)("inlineCode",{parentName:"p"},"UrlHelper"),") to generate a URL for passing pack to the client. The URL generated should fit with the routing mechanism I have set up. In this case the route we expect a URL for was mapped by the following area registration:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System.Web.Mvc;\n\nnamespace DemoApp.Areas.Demo\n{\n    public class DemoAreaRegistration : AreaRegistration\n    {\n        public override string AreaName\n        {\n            get\n            {\n                return "DemoArea";\n            }\n        }\n\n        public override void RegisterArea(AreaRegistrationContext context)\n        {\n            context.MapRoute(\n                "DemoArea_default",\n                "Demo/{oneTypeOfId}/{anotherTypeOfId}/{controller}/{action}/{id}",\n                new { oneTypeOfId = 0, anotherTypeOfId = 0, action = "Index", id = UrlParameter.Optional }\n            );\n        }\n    }\n}\n')),(0,a.kt)("h2",o({},{id:"enough-of-the-waffle---show-me-a-unit-test"}),"Enough of the waffle - show me a unit test"),(0,a.kt)("p",null,"Now to the meat; here's a unit test which demonstrates how this is used:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System.Collections.Generic;\nusing System.Linq;\nusing System.Web.Mvc;\nusing System.Web.Routing;\nusing Microsoft.VisualStudio.TestTools.UnitTesting;\nusing Moq;\n\nnamespace UnitTest.Areas.Demo.Controllers\n{\n    [TestClass]\n    public class UnitTestingAnAreaUsingUrlHelper\n    {\n        private DemoController _controller;\n\n        [TestInitialize]\n        public void InitializeTest()\n        {\n            _controller = new DemoController();\n        }\n\n        [TestMethod]\n        public void Edit_updates_the_object_and_returns_a_JsonResult_containing_the_redirect_URL()\n        {\n            // Arrange\n            int anotherTypeOfId = 5332;\n\n            //Register the area as well as standard routes\n            RouteTable.Routes.Clear();\n            var areaRegistration = new DemoAreaRegistration();\n            var areaRegistrationContext = new AreaRegistrationContext(\n                areaRegistration.AreaName, RouteTable.Routes);\n            areaRegistration.RegisterArea(areaRegistrationContext);\n\n            RouteConfig.RegisterRoutes(RouteTable.Routes);\n\n            //Initialise the controller and setup the context so MVC can pick up the relevant route data\n            var httpContext = MvcMockHelpers.MockHttpContext(\n                "~/Demo/77969/" + anotherTypeOfId + "/Company/Edit");\n            var routeData = RouteTable.Routes.GetRouteData(httpContext);\n            _controller.SetMockControllerContext(\n                httpContext, routeData, RouteTable.Routes);\n\n            // Act\n            var result = _controller.Edit(\n                new AnObject{\n                    WithAProperty = "Something",\n                    AnotherTypeOfId = anotherTypeOfId });\n\n            // Assert\n            Assert.AreEqual("DemoArea", areaRegistration.AreaName);\n\n            Assert.IsInstanceOfType(result, typeof(JsonResult));\n\n            Assert.IsNotNull(result.Data,\n                "There should be some data for the JsonResult");\n            Assert.AreEqual(true,\n                result.Data.GetReflectedProperty("Saved"));\n            Assert.AreEqual("/Demo/77969/" + anotherTypeOfId + "/Company/Details",\n                result.Data.GetReflectedProperty("RedirectUrl"));\n        }\n\n    }\n}\n')),(0,a.kt)("p",null,"Let's go through this unit test and breakdown what's happening:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Arrange"),(0,a.kt)("li",{parentName:"ol"},"Act"),(0,a.kt)("li",{parentName:"ol"},"Assert")),(0,a.kt)("p",null,"The most interesting thing you'll note is the controller's UrlHelper is now generating a URL as we might have hoped. The URL is generated making use of our routing, yay! Finally we're also managing to unit test a route registered by our area."))}d.isMDXComponent=!0},65876:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"unit-testing-modelstate",title:"Unit testing ModelState",authors:"johnnyreilly",tags:["asp.net mvc","unit testing"],hide_table_of_contents:!1},s=void 0,l={permalink:"/unit-testing-modelstate",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-03-03-unit-testing-modelstate/index.md",source:"@site/blog/2013-03-03-unit-testing-modelstate/index.md",title:"Unit testing ModelState",description:'- Me: "It can\'t be done"',date:"2013-03-03T00:00:00.000Z",formattedDate:"March 3, 2013",tags:[{label:"asp.net mvc",permalink:"/tags/asp-net-mvc"},{label:"unit testing",permalink:"/tags/unit-testing"}],readingTime:5.27,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"unit-testing-modelstate",title:"Unit testing ModelState",authors:"johnnyreilly",tags:["asp.net mvc","unit testing"],hide_table_of_contents:!1},prevItem:{title:"DecimalModelBinder for nullable Decimals",permalink:"/decimalmodelbinder-for-nullable-decimals"},nextItem:{title:"Unit testing MVC controllers / Mocking UrlHelper",permalink:"/unit-testing-mvc-controllers-mocking"}},p={authorsImageUrls:[void 0]},u=[{value:"Simple scenario",id:"simple-scenario",level:2},{value:"Back to the dispute",id:"back-to-the-dispute",level:2},{value:"Now I get to learn something",id:"now-i-get-to-learn-something",level:2},{value:"An example",id:"an-example",level:2},{value:"Wrapping up",id:"wrapping-up",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},'Me: "It can\'t be done"'),(0,a.kt)("li",{parentName:"ul"},'Him: "Yes it can"'),(0,a.kt)("li",{parentName:"ul"},'Me: "No it can\'t"'),(0,a.kt)("li",{parentName:"ul"},'Him: "Yes it can, I\'ve just done it"'),(0,a.kt)("li",{parentName:"ul"},'Me: "Ooooh! Show me ..."')),(0,a.kt)("p",null,"The above conversation (or one much like it) took place between my colleague Marc Talary and myself a couple of weeks ago. It was one of those faintly embarrassing situations where you state your case with absolute certainty only to subsequently discover that you were ","*",(0,a.kt)("strong",{parentName:"p"},"completely"),"*"," wrong. Ah arrogance, thy name is Reilly..."),(0,a.kt)("p",null,"The disputed situation in this case was ModelState validation in ASP.Net MVC. How can you unit test a models validation driven by ",(0,a.kt)("inlineCode",{parentName:"p"},"DataAnnotations"),"? If at all. Well it can be done, and here's how."),(0,a.kt)("h2",o({},{id:"simple-scenario"}),"Simple scenario"),(0,a.kt)("p",null,"Let's start with a simple model:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.ComponentModel.DataAnnotations;\n\nnamespace MyNamespace.Model\n{\n    public class CarModel\n    {\n        [Required,\n         Display(Name = "Purchased"),\n         DisplayFormat(DataFormatString = "{0:d}", ApplyFormatInEditMode = true)]\n        public DateTime Purchased { get; set; }\n\n        [Required,\n         Display(Name = "Colour")]\n        public string Colour{ get; set; }\n    }\n}\n')),(0,a.kt)("p",null,"And let's have a controller which makes use of that model:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System.Web.Mvc;\n\nnamespace MyApp\n{\n    public class CarController : Controller\n    {\n        //...\n\n        public ActionResult Edit(CarModel model)\n        {\n            if (ModelState.IsValid) {\n              //Save the model\n              return View("Details", model);\n            }\n\n            return View(model);\n        }\n\n        //...\n    }\n}\n')),(0,a.kt)("p",null,"When I was first looking at unit testing this I was slightly baffled by the behaviour I witnessed. I took an invalid model (where the properties set on the model were violating the model's validation ",(0,a.kt)("inlineCode",{parentName:"p"},"DataAnnotations"),"):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"var car = new CarModel\n{\n    Puchased = null, //This is a required property and so this value is invalid\n    Colour = null //This is a required property and so this value is invalid\n};\n")),(0,a.kt)("p",null,"I passed the invalid model to the ",(0,a.kt)("inlineCode",{parentName:"p"},"Edit")," controller action inside a unit test. My expectation was that the ",(0,a.kt)("inlineCode",{parentName:"p"},"ModelState.IsValid")," code path would ","*",(0,a.kt)("strong",{parentName:"p"},"not"),"*"," be followed as this was ","*",(0,a.kt)("strong",{parentName:"p"},"not"),"*"," a valid model. So ",(0,a.kt)("inlineCode",{parentName:"p"},"ModelState.IsValid")," should evaluate to ",(0,a.kt)("inlineCode",{parentName:"p"},"false"),", right? Wrong!"),(0,a.kt)("p",null,"Contrary to my expectation the validity of ",(0,a.kt)("inlineCode",{parentName:"p"},"ModelState")," is not evaluated on the fly inside the controller. Rather it is determined during the model binding that takes place ","*",(0,a.kt)("strong",{parentName:"p"},"before"),"*"," the actual controller action method is called. And that completely explains why during my unit test with an invalid model we find we're following the ",(0,a.kt)("inlineCode",{parentName:"p"},"ModelState.IsValid")," code path."),(0,a.kt)("h2",o({},{id:"back-to-the-dispute"}),"Back to the dispute"),(0,a.kt)("p",null,"As this blog post started off I was slightly missing Marc's point. I thought he was saying we should be testing the ",(0,a.kt)("inlineCode",{parentName:"p"},"ModelState.IsValid == false")," code path. And given that ",(0,a.kt)("inlineCode",{parentName:"p"},"ModelState")," is determined before we reach the controller my view was that the only way to achieve this was through making use of ",(0,a.kt)("inlineCode",{parentName:"p"},"ModelState.AddModelError")," in our unit test (you can read a good explanation of that ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/3816143/761388"}),"here"),"). And indeed we were already testing for this; we were surfacing errors via a ",(0,a.kt)("inlineCode",{parentName:"p"},"JsonResult")," and so had a test in place to ensure that ",(0,a.kt)("inlineCode",{parentName:"p"},"ModelState")," errors were transformed in the manner we would expect."),(0,a.kt)("p",null,"However, Marc's point was actually that we should have unit tests that enforced our design. That is to say, if we'd decided a certain property on a model was mandatory we should have a test that checked that this was indeed the case. If someone came along later and removed the ",(0,a.kt)("inlineCode",{parentName:"p"},"Required")," data annotation then we wanted that test to fail."),(0,a.kt)("p",null,"It's worth saying, we didn't want a unit test to ensure that ASP.Net MVC worked as expected. Rather, where we had used DataAnnotations against our models to drive validation, we wanted to ensure the validation didn't disappear further down the track. Just to be clear: we wanted to test our code, not Microsoft's."),(0,a.kt)("h2",o({},{id:"now-i-get-to-learn-something"}),"Now I get to learn something"),(0,a.kt)("p",null,"When I grasped Marc's point I thought that the the only way to write these tests would be to make use of reflection. And whilst we could certainly do that I wasn't entirely happy with that as a solution. To my mind it was kind of testing \"at one remove\", if you see what I mean. What I really wanted was to see that MVC was surfacing validations in the manner I might have hoped. And you can!"),(0,a.kt)("p",null,".... Drum roll... Ladies and gents may I present Marc's ",(0,a.kt)("inlineCode",{parentName:"p"},"ModelStateTestController"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using System.Web.Mvc;\nusing Moq;\n\nnamespace UnitTests.TestUtilities\n{\n    /// <summary>\n    /// Instance of a controller for testing things that use controller methods i.e. controller.TryValidateModel(model)\n    /// </summary>\n    public class ModelStateTestController : Controller\n    {\n        public ModelStateTestController()\n        {\n            ControllerContext = (new Mock<ControllerContext>()).Object;\n        }\n\n        public bool TestTryValidateModel(object model)\n        {\n            return TryValidateModel(model);\n        }\n    }\n}\n")),(0,a.kt)("p",null,"This class is, as you can see, incredibly simple. It is a controller, it inherits from ",(0,a.kt)("inlineCode",{parentName:"p"},"System.Web.Mvc.Controller")," and establishes a mock context in the constructor using MOQ. This controller exposes a single method: ",(0,a.kt)("inlineCode",{parentName:"p"},"TestTryValidateModel"),". This method internally determines the controller's ",(0,a.kt)("inlineCode",{parentName:"p"},"ModelState")," given the supplied object by calling off to Mvc's (protected) ",(0,a.kt)("inlineCode",{parentName:"p"},"TryValidateModel")," method (",(0,a.kt)("inlineCode",{parentName:"p"},"TryValidateModel")," evaluates ",(0,a.kt)("inlineCode",{parentName:"p"},"ModelState"),")."),(0,a.kt)("p",null,"This simple class allows us to test the validations on a model in a simple fashion that stays close to the way our models will actually be used in the wild. It's pragmatic and it's useful."),(0,a.kt)("h2",o({},{id:"an-example"}),"An example"),(0,a.kt)("p",null,"Let me wrap up with an example unit test. The test below makes use of the ",(0,a.kt)("inlineCode",{parentName:"p"},"ModelStateTestController")," to check the application of the DataAnnotations on our model:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[TestMethod]\npublic void Unit_Test_CarModel_ModelState_validations_are_thrown()\n{\n    // Arrange\n    var controller = new ModelStateTestController();\n    var car = new CarModel\n    {\n        Puchased = null, //This is a required property and so this value is invalid\n        Colour = null //This is a required property and so this value is invalid\n    };\n\n    // Act\n    var result = controller.TestTryValidateModel(company);\n\n    // Assert\n    Assert.IsFalse(result);\n\n    var modelState = controller.ModelState;\n\n    Assert.AreEqual(2, modelState.Keys.Count);\n\n    Assert.IsTrue(modelState.Keys.Contains("Purchased"));\n    Assert.IsTrue(modelState["Purchased"].Errors.Count == 1);\n    Assert.AreEqual("The Purchased field is required.", modelState["Purchased"].Errors[0].ErrorMessage);\n\n    Assert.IsTrue(modelState.Keys.Contains("Colour"));\n    Assert.IsTrue(modelState["Colour"].Errors.Count == 1);\n    Assert.AreEqual("The Colour field is required.", modelState["Colour"].Errors[0].ErrorMessage);\n}\n')),(0,a.kt)("h2",o({},{id:"wrapping-up"}),"Wrapping up"),(0,a.kt)("p",null,"In a way I think it's a shame that ",(0,a.kt)("inlineCode",{parentName:"p"},"TryValidateModel")," is a protected method. If it weren't it would be simplicity to write a unit test which tested the ModelState directly in context of the action method. It would be possible to get round this by establishing a base controller class which all our controllers would inherit from which implemented the ",(0,a.kt)("inlineCode",{parentName:"p"},"TestTryValidateModel")," method from above. On the other hand maybe it's good to have clarity of the difference between testing model validations and testing controller actions. Something to ponder..."))}d.isMDXComponent=!0},55675:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"decimalmodelbinder-for-nullable-decimals",title:"DecimalModelBinder for nullable Decimals",authors:"johnnyreilly",tags:["Globalization",".NET"],hide_table_of_contents:!1},s=void 0,l={permalink:"/decimalmodelbinder-for-nullable-decimals",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-03-11-decimalmodelbinder-for-nullable-decimals/index.md",source:"@site/blog/2013-03-11-decimalmodelbinder-for-nullable-decimals/index.md",title:"DecimalModelBinder for nullable Decimals",description:"My memory appears to be a sieve. Twice in the last year I've forgotten that MVCs ModelBinding doesn't handle regionalised numbers terribly well. Each time I've thought \"hmmmm.... best Google that\" and lo and behold come upon this post on the issue by the fantastic Phil Haack:",date:"2013-03-11T00:00:00.000Z",formattedDate:"March 11, 2013",tags:[{label:"Globalization",permalink:"/tags/globalization"},{label:".NET",permalink:"/tags/net"}],readingTime:1.78,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"decimalmodelbinder-for-nullable-decimals",title:"DecimalModelBinder for nullable Decimals",authors:"johnnyreilly",tags:["Globalization",".NET"],hide_table_of_contents:!1},prevItem:{title:"Death to compatibility mode",permalink:"/death-to-compatibility-mode"},nextItem:{title:"Unit testing ModelState",permalink:"/unit-testing-modelstate"}},p={authorsImageUrls:[void 0]},u=[{value:"And now a question...",id:"and-now-a-question",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"My memory appears to be a sieve. Twice in the last year I've forgotten that MVCs ModelBinding doesn't handle regionalised numbers terribly well. Each time I've thought \"hmmmm.... best Google that\" and lo and behold come upon this post on the issue by the fantastic Phil Haack:"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"http://haacked.com/archive/2011/03/19/fixing-binding-to-decimals.aspx"}),"http://haacked.com/archive/2011/03/19/fixing-binding-to-decimals.aspx")),(0,a.kt)("p",null,"This post has got me 90% of the way there, the last 10% being me tweaking it so the model binder can handle nullable decimals as well."),(0,a.kt)("p",null,"In the expectation I that I may forget this again I thought I'd note down my tweaks now and hopefully save myself sometime when I'm next looking at this next..."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using System;\nusing System.Globalization;\nusing System.Web.Mvc;\n\nnamespace My.ModelBinders\n{\n    /// <summary>\n    /// Thank you Phil Haack: used to model bind multiple culture decimals\n    /// http://haacked.com/archive/2011/03/19/fixing-binding-to-decimals.aspx\n    ///\n    /// Use by adding these 2 lines to Application_Start in Global.asax.cs:\n    ///\n    /// System.Web.Mvc.ModelBinders.Binders.Add(typeof(decimal), new ModelBinders.DecimalModelBinder());\n    /// System.Web.Mvc.ModelBinders.Binders.Add(typeof(decimal?), new ModelBinders.DecimalModelBinder());\n    /// </summary>\n    public class DecimalModelBinder : IModelBinder\n    {\n        public object BindModel(ControllerContext controllerContext,\n            ModelBindingContext bindingContext)\n        {\n            ValueProviderResult valueResult = bindingContext.ValueProvider\n                .GetValue(bindingContext.ModelName);\n            ModelState modelState = new ModelState { Value = valueResult };\n            object actualValue = null;\n            try\n            {\n                //Check if this is a nullable decimal and a null or empty string has been passed\n                var isNullableAndNull = (bindingContext.ModelMetadata.IsNullableValueType &&\n                                         string.IsNullOrEmpty(valueResult.AttemptedValue));\n\n                //If not nullable and null then we should try and parse the decimal\n                if (!isNullableAndNull)\n                {\n                    actualValue = decimal.Parse(valueResult.AttemptedValue, NumberStyles.Any, CultureInfo.CurrentCulture);\n                }\n            }\n            catch (FormatException e)\n            {\n                modelState.Errors.Add(e);\n            }\n\n            bindingContext.ModelState.Add(bindingContext.ModelName, modelState);\n            return actualValue;\n        }\n    }\n}\n")),(0,a.kt)("h2",o({},{id:"and-now-a-question"}),"And now a question..."),(0,a.kt)("p",null,"Why hasn't MVC got an out-of-the-box model binder that does this anyway? In Phil Haack's original post it looks like they were considering putting this into MVC itself at some point:"),(0,a.kt)("p",null,'"',(0,a.kt)("em",{parentName:"p"},"... In that case, the DefaultModelBinder chokes on the value. This is unfortunate because jQuery Validate allows that value just fine. I\u2019ll talk to the rest of my team about whether we should fix this in the next version of ASP.NET MVC, but for now it\u2019s good to know there\u2019s a workaround..."),'"'),(0,a.kt)("p",null,"If anyone knows the reason this never made it into core I'd love to know. Maybe there's a good reason?"))}d.isMDXComponent=!0},63460:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"death-to-compatibility-mode",title:"Death to compatibility mode",authors:"johnnyreilly",tags:["internet explorer"],hide_table_of_contents:!1},s=void 0,l={permalink:"/death-to-compatibility-mode",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-04-01-death-to-compatibility-mode/index.md",source:"@site/blog/2013-04-01-death-to-compatibility-mode/index.md",title:"Death to compatibility mode",description:'For just over 10 years my bread and butter has been the development and maintenance of line of business apps. More particularly, web apps built on the Microsoft stack of love (\xa9 Scott Hanselman). These sort of apps are typically accessed via the company intranet and since "bring your own device" is still a relatively new innovation these apps are invariably built for everyones favourite browser: Internet Explorer. As we all know, enterprises are generally not that speedy when it comes to upgrades. So we\'re basically talking IE 9 at best, but more often than not, IE 8.',date:"2013-04-01T00:00:00.000Z",formattedDate:"April 1, 2013",tags:[{label:"internet explorer",permalink:"/tags/internet-explorer"}],readingTime:6.35,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"death-to-compatibility-mode",title:"Death to compatibility mode",authors:"johnnyreilly",tags:["internet explorer"],hide_table_of_contents:!1},prevItem:{title:"Making IE 10's clear field (X) button and jQuery UI autocomplete play nice",permalink:"/making-ie-10s-clear-field-x-button-and"},nextItem:{title:"DecimalModelBinder for nullable Decimals",permalink:"/decimalmodelbinder-for-nullable-decimals"}},p={authorsImageUrls:[void 0]},u=[{value:"A Brief History",id:"a-brief-history",level:2},{value:"There&#39;s the rub",id:"theres-the-rub",level:2},{value:"Solution 1: Custom HTTP Header through web.config",id:"solution-1-custom-http-header-through-webconfig",level:2},{value:"Solution 2: Custom HTTP Header the hard way",id:"solution-2-custom-http-header-the-hard-way",level:2},{value:"Solution 3: Meta Tags are go!",id:"solution-3-meta-tags-are-go",level:2},{value:"And for bonus points: <code>IFRAME</code>s!",id:"and-for-bonus-points-iframes",level:2},{value:"That&#39;s it",id:"thats-it",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"For just over 10 years my bread and butter has been the development and maintenance of line of business apps. More particularly, web apps built on the Microsoft stack of love (",(0,a.kt)("a",o({parentName:"p"},{href:"https://channel9.msdn.com/Events/MIX/MIX11/FRM02"}),"\xa9 Scott Hanselman"),'). These sort of apps are typically accessed via the company intranet and since "bring your own device" is still a relatively new innovation these apps are invariably built for everyones favourite browser: Internet Explorer. As we all know, enterprises are generally not that speedy when it comes to upgrades. So we\'re basically talking IE 9 at best, but more often than not, IE 8.'),(0,a.kt)("p",null,"Now, unlike many people, I don't regard IE as a work of evil. I spent a fair number of years working for an organization which had IE 6 as the only installed browser on company desktops. (In fact, this was still the case as late as 2012!) Now, because JavaScript is so marvellously flexible I was still able to do a great deal with the help of a number of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://paulirish.com/2011/the-history-of-the-html5-shiv/"}),"shivs / shims"),"."),(0,a.kt)("p",null,'But rendering and CSS - well that\'s another matter. Because here we\'re at the mercy of "compatibility mode". Perhaps a quick history lesson is in order. What is this "compatibility mode" of which you speak?'),(0,a.kt)("h2",o({},{id:"a-brief-history"}),"A Brief History"),(0,a.kt)("p",null,"Well it all started when Microsoft released IE 8. To quote them:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("em",{parentName:"p"},'A fundamental problem discussed during each and every Internet Explorer release is balancing new features and functionality with site compatibility for the existing Web. On the one hand, new features and functionality push the Web forward. On the other hand, the Web is a large expanse; requiring every legacy page to support the "latest and greatest" browser version immediately at product launch just isn\'t feasible. Internet Explorer 8 addresses this challenge by introducing compatibility modes which gives a way to introduce new features and stricter compliance to standards while enabling it to be backward compliant.')," ","-"," excerpted from ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.com/b/askie/archive/2009/03/23/understanding-compatibility-modes-in-internet-explorer-8.aspx"}),"understanding compatibility modes in Internet Explorer 8"),".")),(0,a.kt)("h2",o({},{id:"theres-the-rub"}),"There's the rub"),(0,a.kt)("p",null,"Sounds fair enough? Of course it does. Microsoft have generally bent over backwards to facilitate backwards compatibility. Quite right too - good business sense and all that. However, one of the choices made around backwards compatibility I've come to regard as somewhat irksome. Later down in the article you'll find this doozy: (emphasis mine)"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("em",{parentName:"p"},'"',(0,a.kt)("strong",{parentName:"em"},"for Intranet pages, 7 (IE 7 Standards) rendering mode is used by default"),' and can be changed."'))),(0,a.kt)("p",null,"For whatever reason, this decision was not particularly well promoted. As a result, a fair number of devs I've encountered have little or no knowledge of compatibility mode. Certainly it came as a surprise to me. Here was I, developing away on my desktop. I'd fire up the app hosted on my machine and test on my local install of IE 8. All would look new and shiny (well non-anchor tags would have ",(0,a.kt)("inlineCode",{parentName:"p"},":hover")," support). Happy and content, I'd push to our test system and browse to it. Wait, what's happened? Where's the new style rendering? What's up with my CSS? This is a bug right?"),(0,a.kt)("p",null,"Obviously I know now it's not a bug it's a \"feature\". And I have learned how to get round the intranet default of compatibility mode through cunning deployment of meta tags and custom http headers. Recently compatibility mode has come to bite me for the second time (in this case I was building for IE 9 and was left wondering where all my rounded corners had vanished to when I deployed...)."),(0,a.kt)("p",null,'For my own sanity I thought it might be good to document the various ways that exist to solve this particular problem. Just to clarify terms, "solve" in this context means "force IE to render in the most standards compliant / like other browsers fashion it can muster". You can use compatibility mode to do more than just that and if you\'re interested in more about this then I recommend ',(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/6771584/761388"}),"this Stack Overflow answer"),"."),(0,a.kt)("h2",o({},{id:"solution-1-custom-http-header-through-webconfig"}),"Solution 1: Custom HTTP Header through web.config"),(0,a.kt)("p",null,"If you're running IIS7 or greater then, for my money, this is the simplest and most pain free solution. All you need do is include the following snippet in your web config file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<?xml version="1.0"?>\n<configuration>\n\n  \x3c!-- ... --\x3e\n\n  <system.webServer>\n    <httpProtocol>\n      <customHeaders>\n        <add name="X-UA-Compatible" value="IE=edge" />\n      </customHeaders>\n    </httpProtocol>\n  </system.webServer>\n\n  \x3c!-- ... --\x3e\n\n<configuration>\n')),(0,a.kt)("p",null,"This will make IIS serve up the above custom response HTTP header with each page."),(0,a.kt)("h2",o({},{id:"solution-2-custom-http-header-the-hard-way"}),"Solution 2: Custom HTTP Header the hard way"),(0,a.kt)("p",null,"Maybe you're running II6 and so you making a change to the web.config won't make a difference. That's fine, you can still get the same behaviour by going to the HTTP headers tab in IIS (see below) and adding the ",(0,a.kt)("inlineCode",{parentName:"p"},"X-UA-Compatible: IE=edge")," header by hand."),(0,a.kt)("p",null,"Or, if you don't have access to IIS (don't laugh - it happens) you can fall back to doing this in code like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'Response.AppendHeader("X-UA-Compatible", "IE=edge");\n')),(0,a.kt)("p",null,"Obviously there's a whole raft of ways you could get this in, using ",(0,a.kt)("inlineCode",{parentName:"p"},"Application_BeginRequest")," in ",(0,a.kt)("inlineCode",{parentName:"p"},"Global.asax.cs")," would probably as good an approach as any."),(0,a.kt)("h2",o({},{id:"solution-3-meta-tags-are-go"}),"Solution 3: Meta Tags are go!"),(0,a.kt)("p",null,"The final approach uses meta tags. And, in my experience it is the most quirky approach - it doesn't always seem to work. First up, what do we do? Well, in each page served we include the following meta tag like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<!DOCTYPE html>\n<html>\n  <head>\n    <meta http-equiv="X-UA-Compatible" content="IE=edge" />\n    \x3c!-- See how the meta tag is the first inside the head?  That\'s *important* --\x3e\n  </head>\n  <body></body>\n</html>\n')),(0,a.kt)("p",null,"Having crawled over the WWW equivalent of broken glass I now know why this ","*",(0,a.kt)("strong",{parentName:"p"},"sometimes"),"*"," doesn't work. (And credit where it's due the answer came from ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/3960197/761388"}),"here"),".) It's all down to the positioning of the meta tag:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("em",{parentName:"p"},"The X-UA-compatible header is not case sensitive; however, it must appear in the Web page's header (the HEAD section) before all other elements, except for the title element and other meta elements.")," ","-"," excerpted from ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-gb/library/jj676915(v=vs.85).aspx"}),"specifying legacy document modes"))),(0,a.kt)("p",null,"That's right, get your meta tag in the wrong place and things won't work. And you won't know why. Lovely. But get it right and it's all gravy. This remains the most unsatisfactory approach in my book though."),(0,a.kt)("h2",o({},{id:"and-for-bonus-points-iframes"}),"And for bonus points: ",(0,a.kt)("inlineCode",{parentName:"h2"},"IFRAME"),"s!"),(0,a.kt)("p",null,"Before I finish off I thought it worth sharing a little known feature of ",(0,a.kt)("inlineCode",{parentName:"p"},"IFRAME"),"s. If page is running in compatibility mode and it contains an ",(0,a.kt)("inlineCode",{parentName:"p"},"IFRAME")," then the page loaded in that ",(0,a.kt)("inlineCode",{parentName:"p"},"IFRAME")," will ",(0,a.kt)("strong",{parentName:"p"},"also run in compatibility mode"),". No ifs, no buts."),(0,a.kt)("p",null,"In the case that I encountered this behaviour, the application was being hosted in an ",(0,a.kt)("inlineCode",{parentName:"p"},"IFRAME")," inside Sharepoint. Because of the way our Sharepoint was configured it ended up that the only real game in town for us was the meta tags approach - which happily worked once we'd correctly placed our meta tag."),(0,a.kt)("p",null,"Again, it's lamentable that this behaviour isn't better documented - hopefully the act of writing this here will mean that it becomes a little better known. There's probably a good reason for this behaviour, though I'm frankly, I don't know what it is. If anyone does, I'd be interested."),(0,a.kt)("h2",o({},{id:"thats-it"}),"That's it"),(0,a.kt)("p",null,"Armed with the above I hope you have less compatibility mode pain than I have. The following blog entry is worth a read by the way:"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.com/b/ie/archive/2009/02/16/just-the-facts-recap-of-compatibility-view.aspx"}),"https://blogs.msdn.com/b/ie/archive/2009/02/16/just-the-facts-recap-of-compatibility-view.aspx")),(0,a.kt)("p",null,"Finally, I have an open question about compatibility mode. I ",(0,a.kt)("em",{parentName:"p"},"think")," (but I don't know) that even in compatibility mode IE runs using the same JavaScript engine. However I suspect it has a different DOM to play with. If anyone knows a little more about this and wants to let me know that'd be fantastic."))}d.isMDXComponent=!0},85785:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"making-ie-10s-clear-field-x-button-and",title:"Making IE 10's clear field (X) button and jQuery UI autocomplete play nice",authors:"johnnyreilly",tags:["jQuery UI"],hide_table_of_contents:!1},s=void 0,l={permalink:"/making-ie-10s-clear-field-x-button-and",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-04-09-making-ie-10s-clear-field-x-button-and/index.md",source:"@site/blog/2013-04-09-making-ie-10s-clear-field-x-button-and/index.md",title:"Making IE 10's clear field (X) button and jQuery UI autocomplete play nice",description:"This morning when I logged on I was surprised to discover IE 10 had been installed onto my machine. I hadn't taken any action to trigger this myself and so I\u2019m assuming that this was part of the general Windows Update mechanism. I know Microsoft had planned to push IE 10 out through this mechanism.",date:"2013-04-09T00:00:00.000Z",formattedDate:"April 9, 2013",tags:[{label:"jQuery UI",permalink:"/tags/j-query-ui"}],readingTime:1.69,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"making-ie-10s-clear-field-x-button-and",title:"Making IE 10's clear field (X) button and jQuery UI autocomplete play nice",authors:"johnnyreilly",tags:["jQuery UI"],hide_table_of_contents:!1},prevItem:{title:"IE 10 Install Torches JavaScript Debugging in Visual Studio 2012 Through Auto Update (Probably)",permalink:"/ie-10-install-torches-javascript"},nextItem:{title:"Death to compatibility mode",permalink:"/death-to-compatibility-mode"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This morning when I logged on I was surprised to discover IE 10 had been installed onto my machine. I hadn't taken any action to trigger this myself and so I\u2019m assuming that this was part of the general Windows Update mechanism. I know ",(0,a.kt)("a",o({parentName:"p"},{href:"http://technet.microsoft.com/en-us/ie/jj898508.aspx"}),"Microsoft had planned to push IE 10 out through this mechanism"),"."),(0,a.kt)("p",null,"I was a little surprised that my work desktop had been upgraded without any notice. And I was initially rather concerned given that most of my users have IE 9 and now I didn't have a test harness on my development machine any more. (I've generally found that having the majority users browser on your own machine is a good idea.) However, I wasn't too concerned as I didn\u2019t think it would makes much of a difference to my development experience. I say that because IE10, as far as I understand, is basically IE 9 + more advanced CSS 3 and extra HTML 5 features. The rendering of my existing content developed for the IE 9 target should look pixel for pixel identical in IE 10. That\u2019s the theory anyway."),(0,a.kt)("p",null,"However, I have found one exception to this rule already. IE 10 provides clear field buttons in text boxes."),(0,a.kt)("p",null,"Unhappily I found these were clashing with our jQuery UI auto complete loading gif."),(0,a.kt)("p",null,"I know; ugly isn't it? Happily I was able to resolve this with a CSS ",(0,a.kt)("del",{parentName:"p"},"hack")),(0,a.kt)("p",null,"fix which looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-css"}),"/* jQuery auto completes add the class below when loading */\n.ui-autocomplete-loading {\n  background: url('/images/ajax_loader.gif') no-repeat right 0.5em center;\n}\n\n/* How'd you like them apples IE 10? */\n.ui-autocomplete-loading::-ms-clear {\n  display: none;\n}\n")),(0,a.kt)("p",null,"And now the jQuery UI autocomplete looks like we expect during the loading phase."),(0,a.kt)("p",null,"But happily when the autocomplete is not in the loading phase we still have access to the IE 10 clear field button. This works because the CSS selector above only applies to the ",(0,a.kt)("em",{parentName:"p"},"ui-autocomplete-loading")," class (which is only applied to the textbox when the loading is taking place)."))}d.isMDXComponent=!0},40704:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"ie-10-install-torches-javascript",title:"IE 10 Install Torches JavaScript Debugging in Visual Studio 2012 Through Auto Update (Probably)",authors:"johnnyreilly",tags:["Visual Studio","javascript","IE 10"],hide_table_of_contents:!1},s=void 0,l={permalink:"/ie-10-install-torches-javascript",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-04-17-ie-10-install-torches-javascript/index.md",source:"@site/blog/2013-04-17-ie-10-install-torches-javascript/index.md",title:"IE 10 Install Torches JavaScript Debugging in Visual Studio 2012 Through Auto Update (Probably)",description:"OK the title of this post is a little verbose. I've just wasted a morning of my life trying to discover what happened to my ability to debug JavaScript in Visual Studio 2012. If you don't want to experience the same pain then read on...",date:"2013-04-17T00:00:00.000Z",formattedDate:"April 17, 2013",tags:[{label:"Visual Studio",permalink:"/tags/visual-studio"},{label:"javascript",permalink:"/tags/javascript"},{label:"IE 10",permalink:"/tags/ie-10"}],readingTime:1.175,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"ie-10-install-torches-javascript",title:"IE 10 Install Torches JavaScript Debugging in Visual Studio 2012 Through Auto Update (Probably)",authors:"johnnyreilly",tags:["Visual Studio","javascript","IE 10"],hide_table_of_contents:!1},prevItem:{title:"A navigation animation (for your users delectation)",permalink:"/a-navigation-animation-for-your-users"},nextItem:{title:"Making IE 10's clear field (X) button and jQuery UI autocomplete play nice",permalink:"/making-ie-10s-clear-field-x-button-and"}},p={authorsImageUrls:[void 0]},u=[{value:"The Symptoms",id:"the-symptoms",level:2},{value:"The Cure",id:"the-cure",level:2},{value:"The Probable Cause",id:"the-probable-cause",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"OK the title of this post is a little verbose. I've just wasted a morning of my life trying to discover what happened to my ability to debug JavaScript in Visual Studio 2012. If you don't want to experience the same pain then read on..."),(0,a.kt)("h2",o({},{id:"the-symptoms"}),"The Symptoms"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"I'm not hitting my JavaScript breakpoints when I hit F5 in Visual Studio."),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",o({parentName:"li"},{href:"http://msdn.microsoft.com/en-us/library/bb385621.aspx"}),"Script Documents")," is missing from the Solution Explorer when I'm debugging in Visual Studio.")),(0,a.kt)("h2",o({},{id:"the-cure"}),"The Cure"),(0,a.kt)("p",null,"In the end, after a great deal of frustration, I happened upon ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/15908391/761388"}),"this answer")," on Stack Overflow. It set me in the right direction."),(0,a.kt)("p",null,"I was seeing exactly the same as this list but with ",(0,a.kt)("strong",{parentName:"p"},"TWO")," instances of Internet Explorer in the list instead of one. Odd, I know."),(0,a.kt)("p",null,"I fixed this up by selecting Google Chrome as my target instead of IE, running it and then setting it back to IE. And interestingly, when I went to set it back to IE there was only one instance of Internet Explorer in the list again."),(0,a.kt)("h2",o({},{id:"the-probable-cause"}),"The Probable Cause"),(0,a.kt)("p",null,"My machine was auto updated from IE 9 to IE 10 just the other day. I ","*",(0,a.kt)("strong",{parentName:"p"},"think"),"*",' my JavaScript debugging issue appeared at the same time. This would explain to me why I had two instances of "Internet Explorer" in my list. Not certain but I\'d say the evidence is fairly compelling.'),(0,a.kt)("p",null,"Painful Microsoft. Painful"))}d.isMDXComponent=!0},42600:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"a-navigation-animation-for-your-users",title:"A navigation animation (for your users delectation)",authors:"johnnyreilly",tags:["CSS"],hide_table_of_contents:!1},s=void 0,l={permalink:"/a-navigation-animation-for-your-users",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-04-26-a-navigation-animation-for-your-users/index.md",source:"@site/blog/2013-04-26-a-navigation-animation-for-your-users/index.md",title:"A navigation animation (for your users delectation)",description:"The Vexation",date:"2013-04-26T00:00:00.000Z",formattedDate:"April 26, 2013",tags:[{label:"CSS",permalink:"/tags/css"}],readingTime:6.88,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"a-navigation-animation-for-your-users",title:"A navigation animation (for your users delectation)",authors:"johnnyreilly",tags:["CSS"],hide_table_of_contents:!1},prevItem:{title:"How I'm Using Cassette part 1:Getting Up and Running",permalink:"/how-im-using-cassette"},nextItem:{title:"IE 10 Install Torches JavaScript Debugging in Visual Studio 2012 Through Auto Update (Probably)",permalink:"/ie-10-install-torches-javascript"}},p={authorsImageUrls:[void 0]},u=[{value:"The Vexation",id:"the-vexation",level:2},{value:"The Agreeable Resolution",id:"the-agreeable-resolution",level:2},{value:"How&#39;s that work then guv?",id:"hows-that-work-then-guv",level:2},{value:"Oh, and a final PS",id:"oh-and-a-final-ps",level:2},{value:"Better make that a PPS - catering for IE 9 and earlier",id:"better-make-that-a-pps---catering-for-ie-9-and-earlier",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"the-vexation"}),"The Vexation"),(0,a.kt)("p",null,"The current application I'm working on lives within an ",(0,a.kt)("inlineCode",{parentName:"p"},"iframe"),". A side effect of that is that my users no longer get the visual feedback that they're used to as they navigate around the site. By \"visual feedback\" what I mean are the little visual tics that are displayed in the browser when you're in the process of navigating from one screen to the next."),(0,a.kt)("p",null,"When an application is nested in an ",(0,a.kt)("inlineCode",{parentName:"p"},"iframe")," it seems that these visual tics aren't propogated up to the top frame of the browser as the user navigates around. Clicking on links results in a short lag whilst nothing appears to be happening and then, BANG!, a new page is rendered. This is not a great user experience. There's nothing to indicate that the link has been clicked on and the browser is doing something. Well, not in Internet Explorer at least - Chrome (my browser of choice) appears to do just that. But that's really by the by, the people using my app will be using the corporate browser, IE; so I need to think about them."),(0,a.kt)("p",null,"Now I'm fully aware that this is more in the region of nice-to-have rather than absolute necessity. That said, my experience is that when users think an application isn't responding fast enough their action point is usually \"click it again, and maybe once more for luck\". To prevent this from happening, I wanted to give the users back some kind of steer when they were in the process of navigation, ",(0,a.kt)("inlineCode",{parentName:"p"},"iframe")," or no ",(0,a.kt)("inlineCode",{parentName:"p"},"iframe"),"."),(0,a.kt)("h2",o({},{id:"the-agreeable-resolution"}),"The Agreeable Resolution"),(0,a.kt)("p",null,"To that end, I've come up with something that I feel does the job, and does it well. I've taken a CSS animation courtesy of the good folk at ",(0,a.kt)("a",o({parentName:"p"},{href:"http://cssload.net/"}),"CSS Load")," and embedded it in the layout of my application. This animation is hidden from view until the user navigates to another page. At that point, the CSS animation appears in the header of the screen and remains in place until the new screen is rendered."),(0,a.kt)("h2",o({},{id:"hows-that-work-then-guv"}),"How's that work then guv?"),(0,a.kt)("p",null,"You're no doubt dazzled by the glory of it all. How was it accomplished? Well, it was actually a great deal easier than you might think. First of all we have the html:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<div class="float-right hidden" id="navigationAnimation">\n  <div id="circleG">\n    <div id="circleG_1" class="circleG"></div>\n    <div id="circleG_2" class="circleG"></div>\n    <div id="circleG_3" class="circleG"></div>\n  </div>\n</div>\n')),(0,a.kt)("p",null,"Apart from the outer ",(0,a.kt)("inlineCode",{parentName:"p"},"div")," tag (#navigationAnimation) all of this is the HTML taken from ",(0,a.kt)("a",o({parentName:"p"},{href:"http://cssload.net/"}),"CSS Load"),". If you wanted to use a different navigation animation you could easily replace the inner HTML with something else instead. Next up is the CSS, again courtesy of CSS Load (and it's this that turns this simple HTML into sumptuous animated goodness):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-css"}),"#navigationAnimation {\n  margin-top: 7px;\n}\n\n#circleG {\n  width: 46.666666666666664px;\n}\n\n.circleG {\n  background-color: #ffffff;\n  float: left;\n  height: 10px;\n  margin-left: 5px;\n  width: 10px;\n  -moz-border-radius: 7px;\n  -webkit-border-radius: 7px;\n  border-radius: 7px;\n  -moz-animation-name: bounce_circleG;\n  -moz-animation-duration: 0.6000000000000001s;\n  -moz-animation-iteration-count: infinite;\n  -moz-animation-direction: linear;\n  -webkit-animation-name: bounce_circleG;\n  -webkit-animation-duration: 0.6000000000000001s;\n  -webkit-animation-iteration-count: infinite;\n  -webkit-animation-direction: linear;\n  -ms-animation-name: bounce_circleG;\n  -ms-animation-duration: 0.6000000000000001s;\n  -ms-animation-iteration-count: infinite;\n  -ms-animation-direction: linear;\n  animation-name: bounce_circleG;\n  animation-duration: 0.6000000000000001s;\n  animation-iteration-count: infinite;\n  animation-direction: linear;\n}\n\n#circleG_1 {\n  -moz-animation-delay: 0.12000000000000002s;\n  -webkit-animation-delay: 0.12000000000000002s;\n  -ms-animation-delay: 0.12000000000000002s;\n  animation-delay: 0.12000000000000002s;\n}\n\n#circleG_2 {\n  -moz-animation-delay: 0.28s;\n  -webkit-animation-delay: 0.28s;\n  -ms-animation-delay: 0.28s;\n  animation-delay: 0.28s;\n}\n\n#circleG_3 {\n  -moz-animation-delay: 0.36s;\n  -webkit-animation-delay: 0.36s;\n  -ms-animation-delay: 0.36s;\n  animation-delay: 0.36s;\n}\n\n@-moz-keyframes bounce_circleG {\n  50% {\n    background-color: #000000;\n  }\n}\n\n@-webkit-keyframes bounce_circleG {\n  50% {\n    background-color: #000000;\n  }\n}\n\n@-ms-keyframes bounce_circleG {\n  50% {\n    background-color: #000000;\n  }\n}\n\n@keyframes bounce_circleG {\n  50% {\n    background-color: #000000;\n  }\n}\n\n/* classes below are not part of CSS animation */\n\n.hidden {\n  display: none;\n}\n\n.float-right {\n  float: right;\n  margin-left: 1em;\n}\n")),(0,a.kt)("p",null,"And finally we have the JavaScript which is responsible for showing animation when the user starts navigating:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"/*!\n * Initialise the navigation animation\n */\n$(document).ready(function () {\n  var navigationAnimationVisible, navigationFallback, $navigationAnimation;\n\n  // initialises the navigation animation (including fallback for browsers without CSS animations)\n  function initialiseNavigationAnimation() {\n    navigationAnimationVisible = false;\n    $navigationAnimation = $('#navigationAnimation');\n    navigationFallback =\n      '<img src=\"/images/navigationAnimation.gif\" width=\"43\" height=\"11\" />';\n\n    // fallback - initial call to ensure the image is cached before subsequent re-use (present flash to users of unloaded gif)\n    if (!Modernizr.cssanimations) {\n      $navigationAnimation.html(navigationFallback);\n    }\n  }\n\n  // Show or hide the navigation animation\n  function showNavigating(makeVisible) {\n    if (makeVisible && !navigationAnimationVisible) {\n      // Show\n      $navigationAnimation.removeClass('hidden');\n      navigationAnimationVisible = true;\n    } else if (!makeVisible && navigationAnimationVisible) {\n      // Hide\n      $navigationAnimation.addClass('hidden');\n      navigationAnimationVisible = false;\n    }\n  }\n\n  // Initialise\n  initialiseNavigationAnimation();\n\n  // Show navigation animation on screen change\n  $(window).on('beforeunload', function () {\n    // fallback\n    if (!Modernizr.cssanimations) {\n      $navigationAnimation.html(navigationFallback);\n    }\n\n    showNavigating(true);\n  });\n});\n")),(0,a.kt)("p",null,"It's helped along with a little jQuery here but this could easily be accomplished with vanilla JS if you fancied. The approach works by hooking into the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/DOM/Mozilla_event_reference/beforeunload"}),"beforeunload"),' event that fires when "',(0,a.kt)("em",{parentName:"p"},"the window, the document and its resources are about to be unloaded"),"\". There's a little bit more to the functionality in the JavaScript abover which I go into in the PPS below. Essentially that covers backwards compatibility with earlier versions of IE."),(0,a.kt)("p",null,"I've coded this up in a manner that lends itself to re-use. I can imagine that you might also want to make use of the navigation animation if, for example, you had an expensive AJAX operation on a page and you didn't want the users to despair. So the navigation animation could become a kind of a generic \"I am doing something\" animation instead - I leave it to your disgression."),(0,a.kt)("h2",o({},{id:"oh-and-a-final-ps"}),"Oh, and a final PS"),(0,a.kt)("p",null,"I had initially planned to use an old school animated GIF instead of a CSS animation. The thing that stopped me taking this course of action is that, to quote an ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/780617/761388"}),"answer on Stack Overflow"),' "',(0,a.kt)("em",{parentName:"p"},"IE assumes that the clicking of a link heralds a new navigation where the current page contents will be replaced. As part of the process for perparing for that it halts the code that animates the GIFs."),'". So I needed animation that stayed animated. And lo, there were CSS animations...'),(0,a.kt)("h2",o({},{id:"better-make-that-a-pps---catering-for-ie-9-and-earlier"}),"Better make that a PPS - catering for IE 9 and earlier"),(0,a.kt)("p",null,"I spoke a touch too soon when I expounded on how CSS animations were going to get me out of a hole. Unfortunately, and to my lasting regret, they aren't supported in IE 9. And yes, at least for now that is what the users have. To get round this I've delved a little bit further and discovered a frankly hacky way to make animated gifs stay animated after beforeunload has fired. It works by rendering an animated gif to the screen when beforeunload is fired. Why this works I couldn't say - but if you're interested to research more then take a look at ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/1904931/761388"}),"this answer on Stack Overflow"),". In my case I've found an animated gif on ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.ajaxload.info/"}),"AjaxLoad")," which looks pretty similar to the CSS animation:"),(0,a.kt)("p",null,"This is now saved away as ",(0,a.kt)("inlineCode",{parentName:"p"},"navigationAnimation.gif")," in the application. The JavaScript uses Modernizr to detect if CSS animations are in play. If they're not then the animated gif is rendered to the screen in place of the CSS animation HTML. Ugly, but it seems to work well; I think this will work on IE 6 - 9. The CSS animations will work on IE 10+."))}d.isMDXComponent=!0},49201:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"how-im-using-cassette",title:"How I'm Using Cassette part 1:Getting Up and Running",authors:"johnnyreilly",tags:["asp.net mvc","cassette"],hide_table_of_contents:!1},s=void 0,l={permalink:"/how-im-using-cassette",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-05-04-how-im-using-cassette/index.md",source:"@site/blog/2013-05-04-how-im-using-cassette/index.md",title:"How I'm Using Cassette part 1:Getting Up and Running",description:"Backing into the light",date:"2013-05-04T00:00:00.000Z",formattedDate:"May 4, 2013",tags:[{label:"asp.net mvc",permalink:"/tags/asp-net-mvc"},{label:"cassette",permalink:"/tags/cassette"}],readingTime:8.755,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"how-im-using-cassette",title:"How I'm Using Cassette part 1:Getting Up and Running",authors:"johnnyreilly",tags:["asp.net mvc","cassette"],hide_table_of_contents:!1},prevItem:{title:"How I'm Using Cassette part 2:Get Cassette to Serve Scripts in Dependency Order",permalink:"/how-im-using-cassette-part-2"},nextItem:{title:"A navigation animation (for your users delectation)",permalink:"/a-navigation-animation-for-your-users"}},p={authorsImageUrls:[void 0]},u=[{value:"Backing into the light",id:"backing-into-the-light",level:2},{value:"Adding Cassette to a raw MVC 4 project",id:"adding-cassette-to-a-raw-mvc-4-project",level:2},{value:"How Web Optimization and Cassette Differ",id:"how-web-optimization-and-cassette-differ",level:2},{value:"Making use of our Bundles",id:"making-use-of-our-bundles",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"backing-into-the-light"}),"Backing into the light"),(0,a.kt)("p",null,"For a while now, I've been seeking a bulletproof way to handle the following scenarios... all at the same time in the context of an ASP.Net MVC application:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"How to serve full-fat JavaScript in debug mode and minified in release mode"),(0,a.kt)("li",{parentName:"ol"},"When debugging, ensure that the full-fat JS being served is definitely the latest version; and ","*",(0,a.kt)("strong",{parentName:"li"},"not"),"*"," from the cache. (The time I've wasted due to ",(0,a.kt)("a",o({parentName:"li"},{href:"http://en.wikipedia.org/wiki/List_of_HTTP_status_codes#304"}),"304's"),"...)"),(0,a.kt)("li",{parentName:"ol"},"How to add Javascript assets that need to be served up from any point in an ASP.Net MVC application (including views, layouts, partial views... even controllers if so desired) whilst preventing duplicate scripts from being served."),(0,a.kt)("li",{parentName:"ol"},"How to ensure that Javascript files are served up last to any web page to ensure a speedy feel to users (don't want JS blocking rendering)."),(0,a.kt)("li",{parentName:"ol"},"And last but certainly not least the need to load Javascript files in dependency order. If ",(0,a.kt)("inlineCode",{parentName:"li"},"myView.js")," depends on jQuery then clearly ",(0,a.kt)("inlineCode",{parentName:"li"},"jQuery-latest.js")," needs to be served before ",(0,a.kt)("inlineCode",{parentName:"li"},"myView.js"),".")),(0,a.kt)("p",null,"Now the best, most comprehensive and solid looking solution to this problem has for some time seemed to me to be ",(0,a.kt)("a",o({parentName:"p"},{href:"http://aboutcode.net/"}),"Andrew Davey's"),(0,a.kt)("a",o({parentName:"p"},{href:"http://getcassette.net/"}),"Cassette"),". This addresses all my issues in one way or another, as well as bringing in a raft of other features (support for Coffeescript etc)."),(0,a.kt)("p",null,"However, up until now I've slightly shied away from using Cassette as I was under the impression it had a large number of dependencies. That doesn't appear to be the case at all. I also had some vague notion that I could quite simply build my own solution to these problems making use of Microsoft's ",(0,a.kt)("a",o({parentName:"p"},{href:"http://nuget.org/packages/Microsoft.AspNet.Web.Optimization/1.0.0"}),"Web Optimization")," which nicely handles my #1 problem above. However, looking again at the documentation Cassette was promising to handle scenarios #1 - #5 without breaking sweat. How could I ignore that? I figured I should do the sensible thing and take another look at it. And, lo and behold, when I started evaluating it again it seemed to be just what I needed."),(0,a.kt)("p",null,"With the minumum of fuss I was able to get an ASP.Net MVC 4 solution up and running, integrated with Cassette, which dealt with all my scenarios very nicely indeed. I thought it might be good to write this up over a short series of posts and share what my finished code looks like. If you follow the steps I go through below it'll get you started using Cassette. Or you could skip to the end of this post and look at the repo on GitHub. Here we go..."),(0,a.kt)("h2",o({},{id:"adding-cassette-to-a-raw-mvc-4-project"}),"Adding Cassette to a raw MVC 4 project"),(0,a.kt)("p",null,"Fire up Visual Studio and create a new MVC 4 project (I used the internet template to have some content in place)."),(0,a.kt)("p",null,'Go to the Package Manager Console and key in "',(0,a.kt)("inlineCode",{parentName:"p"},"Install-Package Cassette.Aspnet"),'". Cassette will install itself.'),(0,a.kt)("p",null,"Now you've got Cassette in place you may as well pull out usage of Web Optimization as you're not going to need it any more.Be ruthless, delete App_Start/BundleConfig.cs and delete the line of code that references it in Global.asax.cs. If you take the time to run the app now you'll see you've miraculously lost your CSS and your JavaScript. The code referencing it is still in place but there's nothing for it to serve up. Don't worry about that - we're going to come back and Cassette-ify things later on..."),(0,a.kt)("p",null,"You'll also notice you now have a CassetteConfiguration.cs file in your project. Open it. Replace the contents with this (I've just commented out the default code and implemented my own CSS and Script bundles based on what is available in the default template of an MVC 4 app):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using Cassette;\nusing Cassette.Scripts;\nusing Cassette.Stylesheets;\n\nnamespace CassetteDemo\n{\n    /// <summary>\n    /// Configures the Cassette asset bundles for the web application.\n    /// </summary>\n    public class CassetteBundleConfiguration : IConfiguration<BundleCollection>\n    {\n        public void Configure(BundleCollection bundles)\n        {\n            // TODO: Configure your bundles here...\n            // Please read http://getcassette.net/documentation/configuration\n\n            // This default configuration treats each file as a separate \'bundle\'.\n            // In production the content will be minified, but the files are not combined.\n            // So you probably want to tweak these defaults!\n            //bundles.AddPerIndividualFile<StylesheetBundle>("Content");\n            //bundles.AddPerIndividualFile<ScriptBundle>("Scripts");\n\n            // To combine files, try something like this instead:\n            //   bundles.Add<StylesheetBundle>("Content");\n            // In production mode, all of ~/Content will be combined into a single bundle.\n\n            // If you want a bundle per folder, try this:\n            //   bundles.AddPerSubDirectory<ScriptBundle>("Scripts");\n            // Each immediate sub-directory of ~/Scripts will be combined into its own bundle.\n            // This is useful when there are lots of scripts for different areas of the website.\n\n            AddStylesheetBundles(bundles);\n            AddScriptBundles(bundles);\n        }\n\n        private static void AddStylesheetBundles(BundleCollection bundles)\n        {\n            bundles.Add<StylesheetBundle>("~/bundles/css",\n                                          "~/Content/Site.css",\n                                          "~/Content/themes/base/jquery-ui.css"\n                );\n        }\n\n        private static void AddScriptBundles(BundleCollection bundles)\n        {\n            // A bundle of the scripts that will need to be added to the head (likely only ever to be Modernizr but you never know)\n            bundles.Add<ScriptBundle>("~/bundles/head",\n                                      new[] {"~/Scripts/modernizr-2.6.2.js"},\n                                      bundle => bundle.PageLocation = "head"\n                );\n\n            // A bundle of the core scripts that will likely be used on every page of the app\n            bundles.Add<ScriptBundle>("~/bundles/core",\n                                      new[]\n                                          {\n                                              "~/Scripts/jquery-1.8.2.js",\n                                              "~/Scripts/jquery-ui-1.8.24.js"\n                                          });\n\n            // Validation scripts; only likely necessary on date entry screens\n            bundles.Add<ScriptBundle>("~/bundles/validate",\n                                      new[]\n                                          {\n                                              "~/Scripts/jquery.validate.js",\n                                              "~/Scripts/jquery.validate.unobtrusive.js"\n                                          },\n                                      bundle => bundle.AddReference("~/bundles/core")\n                );\n\n            // Create a per file bundle for all areas / views\n            //bundles.AddPerIndividualFile<ScriptBundle>("~/Scripts/Views");\n        }\n    }\n}\n')),(0,a.kt)("p",null,"In the script above I've created 4 bundles, 1 stylesheet bundle and 3 JavaScript bundles - each of these is roughly equivalent to Web Optimization bundles that are part of the MVC 4 template:"),(0,a.kt)("dl",null,(0,a.kt)("dt",null,"~/bundles/css"),(0,a.kt)("dd",null,"Our site CSS - this includes both our own CSS and the jQuery UI CSS as well. This is the rough equivalent of the Web Optimization bundles ",(0,a.kt)("em",null,"~/Content/css")," and ",(0,a.kt)("em",null,"~/Content/themes/base/css")," brought together."),(0,a.kt)("dt",null,"~/bundles/head"),(0,a.kt)("dd",null,"What scripts we want served in the head tag - Modernizr basically. Do note the setting of the ",(0,a.kt)("em",null,"PageLocation")," property - the purpose of this will become apparent later. This is the direct equivalent of the Web Optimization bundle: ",(0,a.kt)("em",null,"~/bundles/modernizr"),"."),(0,a.kt)("dt",null,"~/bundles/core"),(0,a.kt)("dd",null,"The scripts we want served on every page. For this example project I've picked jQuery and jQuery UI. This is the rough equivalent of the Web Optimization bundles ",(0,a.kt)("em",null,"~/bundles/jquery")," and ",(0,a.kt)("em",null,"~/bundles/jqueryui")," brought together."),(0,a.kt)("dt",null,"~/bundles/validate"),(0,a.kt)("dd",null,"The validation scripts (that are dependent on the core scripts). This is the rough equivalent of the Web Optimization bundle: ",(0,a.kt)("em",null,"~/bundles/jqueryval"),".")),(0,a.kt)("p",null,"At this point we've set up Cassette in our project - although we're not making use of it yet. If you want to double check that everything is working properly then you can fire up your project and browse to \"Cassette.axd\" in the root."),(0,a.kt)("h2",o({},{id:"how-web-optimization-and-cassette-differ"}),"How Web Optimization and Cassette Differ"),(0,a.kt)("p",null,"If you're more familiar with the workings of Web Optimization than Cassette then it's probably worth taking a moment to appreciate an important distinction between the slightly different ways each works."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Web Optimization")),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Create bundles as desired."),(0,a.kt)("li",{parentName:"ol"},"Serve up bundles and / or straight JavaScript files as you like within your MVC views / partial views / layouts.")),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Cassette")),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Create bundles for ","*",(0,a.kt)("strong",{parentName:"li"},"all"),"*",' JavaScript files you wish to serve up. You may wish to create some bundles which consist of a number of a number of JavaScript files pushed together. But for each individual file you wish to serve you also need to create an individual bundle. (Failure to do so may mean you fall prey to the "',(0,a.kt)("em",{parentName:"li"},'Cannot find an asset bundle containing the path "',"~",'/Scripts/somePath.js".'),'")'),(0,a.kt)("li",{parentName:"ol"},"Reference bundles and / or individual JavaScript files in their individual bundles as you like within your MVC views / partial views / layouts / controllers / HTML helpers... the list goes on!"),(0,a.kt)("li",{parentName:"ol"},"Render the referenced scripts to the page (typically just before the closing ",(0,a.kt)("inlineCode",{parentName:"li"},"body")," tag)")),(0,a.kt)("h2",o({},{id:"making-use-of-our-bundles"}),"Making use of our Bundles"),(0,a.kt)("p",null,"Now we've created our bundles let's get the project serving up CSS and JavaScript using Cassette. First the layout file. Take the ",(0,a.kt)("inlineCode",{parentName:"p"},"_Layout.cshtml")," file from this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<!DOCTYPE html>\n<html lang="en">\n  <head>\n    <meta charset="utf-8" />\n    <title>@ViewBag.Title - My ASP.NET MVC Application</title>\n    <link href="~/favicon.ico" rel="shortcut icon" type="image/x-icon" />\n    <meta name="viewport" content="width=device-width" />\n    @Styles.Render("~/Content/css") @Scripts.Render("~/bundles/modernizr")\n  </head>\n  <body>\n    <header>\n      <div class="content-wrapper">\n        <div class="float-left">\n          <p class="site-title">\n            @Html.ActionLink("your logo here", "Index", "Home")\n          </p>\n        </div>\n        <div class="float-right">\n          <section id="login">@Html.Partial("_LoginPartial")</section>\n          <nav>\n            <ul id="menu">\n              <li>@Html.ActionLink("Home", "Index", "Home")</li>\n              <li>@Html.ActionLink("About", "About", "Home")</li>\n              <li>@Html.ActionLink("Contact", "Contact", "Home")</li>\n            </ul>\n          </nav>\n        </div>\n      </div>\n    </header>\n    <div id="body">\n      @RenderSection("featured", required: false)\n      <section class="content-wrapper main-content clear-fix">\n        @RenderBody()\n      </section>\n    </div>\n    <footer>\n      <div class="content-wrapper">\n        <div class="float-left">\n          <p>&copy; @DateTime.Now.Year - My ASP.NET MVC Application</p>\n        </div>\n      </div>\n    </footer>\n\n    @Scripts.Render("~/bundles/jquery") @RenderSection("scripts", required:\n    false)\n  </body>\n</html>\n')),(0,a.kt)("p",null,"To this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'@{ Bundles.Reference("~/bundles/css"); Bundles.Reference("~/bundles/head");\nBundles.Reference("~/bundles/core"); }\n<!DOCTYPE html>\n<html lang="en">\n  <head>\n    <meta charset="utf-8" />\n    <title>@ViewBag.Title - My ASP.NET MVC Application</title>\n    <link href="~/favicon.ico" rel="shortcut icon" type="image/x-icon" />\n    <meta name="viewport" content="width=device-width" />\n    @Bundles.RenderStylesheets() @Bundles.RenderScripts("head")\n  </head>\n  <body>\n    <header>\n      <div class="content-wrapper">\n        <div class="float-left">\n          <p class="site-title">\n            @Html.ActionLink("your logo here", "Index", "Home")\n          </p>\n        </div>\n        <div class="float-right">\n          <section id="login">@Html.Partial("_LoginPartial")</section>\n          <nav>\n            <ul id="menu">\n              <li>@Html.ActionLink("Home", "Index", "Home")</li>\n              <li>@Html.ActionLink("About", "About", "Home")</li>\n              <li>@Html.ActionLink("Contact", "Contact", "Home")</li>\n            </ul>\n          </nav>\n        </div>\n      </div>\n    </header>\n    <div id="body">\n      @RenderSection("featured", required: false)\n      <section class="content-wrapper main-content clear-fix">\n        @RenderBody()\n      </section>\n    </div>\n    <footer>\n      <div class="content-wrapper">\n        <div class="float-left">\n          <p>&copy; @DateTime.Now.Year - My ASP.NET MVC Application</p>\n        </div>\n      </div>\n    </footer>\n\n    @Bundles.RenderScripts()\n  </body>\n</html>\n')),(0,a.kt)("p",null,"And now let's take one of the views, ",(0,a.kt)("inlineCode",{parentName:"p"},"Login.cshtml")," and take it from this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'@model CassetteDemo.Models.LoginModel @{ ViewBag.Title = "Log in"; }\n\n<hgroup class="title">\n  <h1>@ViewBag.Title.</h1>\n</hgroup>\n\n<section id="loginForm">\n  <h2>Use a local account to log in.</h2>\n  @using (Html.BeginForm(new { ReturnUrl = ViewBag.ReturnUrl })) {\n  @Html.AntiForgeryToken() @Html.ValidationSummary(true)\n\n  <fieldset>\n    <legend>Log in Form</legend>\n    <ol>\n      <li>\n        @Html.LabelFor(m => m.UserName) @Html.TextBoxFor(m => m.UserName)\n        @Html.ValidationMessageFor(m => m.UserName)\n      </li>\n      <li>\n        @Html.LabelFor(m => m.Password) @Html.PasswordFor(m => m.Password)\n        @Html.ValidationMessageFor(m => m.Password)\n      </li>\n      <li>\n        @Html.CheckBoxFor(m => m.RememberMe) @Html.LabelFor(m => m.RememberMe,\n        new { @class = "checkbox" })\n      </li>\n    </ol>\n    <input type="submit" value="Log in" />\n  </fieldset>\n  <p>@Html.ActionLink("Register", "Register") if you don\'t have an account.</p>\n  }\n</section>\n\n<section class="social" id="socialLoginForm">\n  <h2>Use another service to log in.</h2>\n  @Html.Action("ExternalLoginsList", new { ReturnUrl = ViewBag.ReturnUrl })\n</section>\n\n@section Scripts { @Scripts.Render("~/bundles/jqueryval") }\n')),(0,a.kt)("p",null,"To this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'@model CassetteDemo.Models.LoginModel @{ ViewBag.Title = "Log in";\nBundles.Reference("~/bundles/validate"); }\n\n<hgroup class="title">\n  <h1>@ViewBag.Title.</h1>\n</hgroup>\n\n<section id="loginForm">\n  <h2>Use a local account to log in.</h2>\n  @using (Html.BeginForm(new { ReturnUrl = ViewBag.ReturnUrl })) {\n  @Html.AntiForgeryToken() @Html.ValidationSummary(true)\n\n  <fieldset>\n    <legend>Log in Form</legend>\n    <ol>\n      <li>\n        @Html.LabelFor(m => m.UserName) @Html.TextBoxFor(m => m.UserName)\n        @Html.ValidationMessageFor(m => m.UserName)\n      </li>\n      <li>\n        @Html.LabelFor(m => m.Password) @Html.PasswordFor(m => m.Password)\n        @Html.ValidationMessageFor(m => m.Password)\n      </li>\n      <li>\n        @Html.CheckBoxFor(m => m.RememberMe) @Html.LabelFor(m => m.RememberMe,\n        new { @class = "checkbox" })\n      </li>\n    </ol>\n    <input type="submit" value="Log in" />\n  </fieldset>\n  <p>@Html.ActionLink("Register", "Register") if you don\'t have an account.</p>\n  }\n</section>\n\n<section class="social" id="socialLoginForm">\n  <h2>Use another service to log in.</h2>\n  @Html.Action("ExternalLoginsList", new { ReturnUrl = ViewBag.ReturnUrl })\n</section>\n')),(0,a.kt)("p",null,"So now you should be up and running with Cassette. If you want the code behind this then take I've put it on GitHub ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/CassetteDemo"}),"here"),"."))}d.isMDXComponent=!0},68888:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"how-im-using-cassette-part-2",title:"How I'm Using Cassette part 2:Get Cassette to Serve Scripts in Dependency Order",authors:"johnnyreilly",tags:["RequireJS","cassette"],hide_table_of_contents:!1},s=void 0,l={permalink:"/how-im-using-cassette-part-2",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-06-06-how-im-using-cassette-part-2/index.md",source:"@site/blog/2013-06-06-how-im-using-cassette-part-2/index.md",title:"How I'm Using Cassette part 2:Get Cassette to Serve Scripts in Dependency Order",description:"Last time I wrote about Cassette I was talking about how to generally get up and running. How to use Cassette within an ASP.Net MVC project. What I want to write about now is (in my eyes) the most useful feature of Cassette by a country mile. This is Cassettes ability to ensure scripts are served in dependency order.",date:"2013-06-06T00:00:00.000Z",formattedDate:"June 6, 2013",tags:[{label:"RequireJS",permalink:"/tags/require-js"},{label:"cassette",permalink:"/tags/cassette"}],readingTime:7.445,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"how-im-using-cassette-part-2",title:"How I'm Using Cassette part 2:Get Cassette to Serve Scripts in Dependency Order",authors:"johnnyreilly",tags:["RequireJS","cassette"],hide_table_of_contents:!1},prevItem:{title:"jQuery Validation - Native Unobtrusive Validation Support!",permalink:"/jquery-validate-native-unobtrusive-validation"},nextItem:{title:"How I'm Using Cassette part 1:Getting Up and Running",permalink:"/how-im-using-cassette"}},p={authorsImageUrls:[void 0]},u=[{value:"Why does this matter?",id:"why-does-this-matter",level:2},{value:"It Depends",id:"it-depends",level:2},{value:"Enter Cassette, riding a white horse",id:"enter-cassette-riding-a-white-horse",level:2},{value:"Declaring References Server-Side",id:"declaring-references-server-side",level:2},{value:"Declaring References in your JavaScript itself",id:"declaring-references-in-your-javascript-itself",level:2},{value:"Avoiding the Gotcha",id:"avoiding-the-gotcha",level:2},{value:"Go Forth and Reference",id:"go-forth-and-reference",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"/how-im-using-cassette"}),"Last time")," I wrote about Cassette I was talking about how to generally get up and running. How to use Cassette within an ASP.Net MVC project. What I want to write about now is (in my eyes) the most useful feature of Cassette by a country mile. This is Cassettes ability to ensure scripts are served in dependency order."),(0,a.kt)("h2",o({},{id:"why-does-this-matter"}),"Why does this matter?"),(0,a.kt)("p",null,"You might well ask. If we go back 10 years or so then really this wasn't a problem. No-one was doing a great deal with JavaScript. And if they did anything it tended to be code snippets in amongst the HTML; nothing adventurous. But unless you've had your head in the sand for the last 3 years then you will have clearly noticed that JavaScript is in rude health and being used for all kinds of things you'd never have imagined. In fact some would have it that it's the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.hanselman.com/blog/JavaScriptisAssemblyLanguagefortheWebPart2MadnessorjustInsanity.aspx"}),"assembly language of the web"),"."),(0,a.kt)("p",null,"For my part, I've been doing more and more with JavaScript. And as I do more and more with it I seek to modularise my code; (",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Separation_of_concerns"}),"like any good developer would"),") breaking it up into discrete areas of functionality. I aim to only serve up the JavaScript that I need on a given page. And that would be all well and good but for one of the languages shortcomings. Modules. JavaScript doesn't yet have a good module loading story to tell. (Apparently one's coming in ",(0,a.kt)("a",o({parentName:"p"},{href:"http://wiki.ecmascript.org/doku.php?id=harmony:modules"}),"EcmaScript 6"),"). (I don't want to get diverted into this topic as it's a big area. But if you're interested then you can read up a little on different approaches being used ",(0,a.kt)("a",o({parentName:"p"},{href:"http://requirejs.org/docs/whyamd.html#today"}),"here"),". The ongoing contest between RequireJS and CommonJS frankly makes me want to keep my distance for now.)"),(0,a.kt)("h2",o({},{id:"it-depends"}),"It Depends"),(0,a.kt)("p",null,"Back to my point, JavaScripts native handling of script dependencies is non-existent. It's real \"here be dragons\" territory. If you serve up, for example, Slave.js that depends on things set up in Master.js before you've actually served up Master.js, well it's not a delightful debugging experience. The errors tend be obscure and it's not always obvious what the correct ordering should be."),(0,a.kt)("p",null,"Naturally this creates something of a headache around my own JavaScript modules. A certain amount of jiggery-pokery is required to ensure that scripts are served in the correct order so that they run as expected. And as your application becomes more complicated / modular, the number of problems around this area increase exponentially. It's ",(0,a.kt)("strong",{parentName:"p"},"really")," tedious. I don't want to be thinking about managing that as I'm developing - I want to be focused on solving the problem at hand."),(0,a.kt)("p",null,"In short, what I want to do is reference a script file somewhere in my server-side pipeline. I could be in a view, a layout, a controller, a partial view, a HTML helper... - I just want to know that that script is going to turn up at the client in the right place in the HTML so it works. Always. And I don't want to have to think about it any further than that."),(0,a.kt)("h2",o({},{id:"enter-cassette-riding-a-white-horse"}),"Enter Cassette, riding a white horse"),(0,a.kt)("p",null,"And this is where Cassette takes the pain away. To quote the documentation:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},'"',(0,a.kt)("em",{parentName:"p"},"Some assets must be included in a page before others. For example, your code may use jQuery, so the jQuery script must be included first. Cassette will sort all assets based on references they declare."),'"')),(0,a.kt)("p",null,"Just the ticket!"),(0,a.kt)("h2",o({},{id:"declaring-references-server-side"}),"Declaring References Server-Side"),(0,a.kt)("p",null,"What does this look like in reality? Let's build on what I did last time to demonstrate how I make use of Asset References to ensure my scripts turn up in the order I require."),(0,a.kt)("p",null,"In my ",(0,a.kt)("inlineCode",{parentName:"p"},"_Layout.cshtml")," file I'm going to remove the following reference from the head of the file:"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},'Bundles.Reference("~/bundles/core");')),(0,a.kt)("p",null,"I'm pulling this out of my layout page because it's presence means that ",(0,a.kt)("strong",{parentName:"p"},"every")," page MVC serves up is also serving up jQuery and jQuery UI (which is what ",(0,a.kt)("inlineCode",{parentName:"p"},"~/bundles/core")," is). If a page doesn't actually make use of jQuery and / or jQuery UI then there's no point in doing this."),(0,a.kt)("p",null,'"',(0,a.kt)("em",{parentName:"p"},"But wait!"),'", I hear you cry, "',(0,a.kt)("em",{parentName:"p"},"Haven't you just caused a bug with your reckless action? I distinctly recall that the ",(0,a.kt)("inlineCode",{parentName:"em"},"Login.cshtml")," page has the following code in place:"),'"'),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},'Bundles.Reference("~/bundles/validate");')),(0,a.kt)("p",null,'"',(0,a.kt)("em",{parentName:"p"},"And now with your foolhardy, nay, reckless attitude to the ",(0,a.kt)("inlineCode",{parentName:"em"},"~/bundles/core")," bundle you've broken your Login screen. How can jQuery Validation be expected to work if there's no jQuery there to extend?"),'"'),(0,a.kt)("p",null,"Well, I understand your concerns but really you needn't worry - Cassette's got my back. Look closely at the code below:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'// A bundle of the core scripts that will likely be used on every page of the app\nbundles.Add<ScriptBundle>("~/bundles/core",\n                          new[]\n                              {\n                                  "~/Scripts/jquery-1.8.2.js",\n                                  "~/Scripts/jquery-ui-1.8.24.js"\n                              });\n\n// Validation scripts; only likely necessary on data entry screens\nbundles.Add<ScriptBundle>("~/bundles/validate",\n                          new[]\n                              {\n                                  "~/Scripts/jquery.validate.js",\n                                  "~/Scripts/jquery.validate.unobtrusive.js"\n                              },\n                          bundle => bundle.AddReference("~/bundles/core")\n    );\n')),(0,a.kt)("p",null,"See it? The ",(0,a.kt)("inlineCode",{parentName:"p"},"~/bundles/validate")," bundle declares a reference to the ",(0,a.kt)("inlineCode",{parentName:"p"},"~/bundles/core")," bundle. The upshot of this is, that if you tell Cassette to reference ",(0,a.kt)("inlineCode",{parentName:"p"},"~/bundles/validate")," it will ensure that before it renders that bundle it first renders any bundles that bundle depends on (in this case the ",(0,a.kt)("inlineCode",{parentName:"p"},"~/bundles/core")," bundle)."),(0,a.kt)("p",null,"This is a very simple demonstration of the feature but I can't underplay just how useful I find this."),(0,a.kt)("h2",o({},{id:"declaring-references-in-your-javascript-itself"}),"Declaring References in your JavaScript itself"),(0,a.kt)("p",null,"And the good news doesn't stop there. Let's say you ",(0,a.kt)("strong",{parentName:"p"},"don't")," want to maintain your references in a separate file. You'd rather declare references inside your JavaScript files themselves. Well - you can. Cassette caters for this through the usage of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://getcassette.net/documentation/v1/AssetReferences"}),"Asset References"),"."),(0,a.kt)("p",null,"Let's demo this. First of all add the following file at this location in the project: ",(0,a.kt)("inlineCode",{parentName:"p"},"~/Scripts/Views/Home/Index.js")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"// @reference ~/bundles/core\n\n$(document).ready(function () {\n  var $body = $('#body');\n\n  $body.fadeOut(1000, function () {\n    $body\n      .html(\n        '<div style=\"width: 150px; margin: 0 auto;\">' +\n          'I made it all go away...</div>'\n      )\n      .fadeIn();\n  });\n});\n")),(0,a.kt)("p",null,"The eagle-eyed amongst you will have noticed"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"I'm mirroring the MVC folder structure inside the Scripts directory. (There's nothing special about that by the way - it's just a file structure I've come to find useful. It's very easy to find the script associated with a View if the scripts share the same organisational approach as the Views.)."),(0,a.kt)("li",{parentName:"ol"},"The purpose of the script is very simple, it fades out the main body of the screen, re-writes the HTML in that tag and then fades back in. It's purpose is just to do something that is obvious to the user - so they can see the evidence of JavaScript executing."),(0,a.kt)("li",{parentName:"ol"},"Lastly and most importantly, do you notice that ",(0,a.kt)("inlineCode",{parentName:"li"},"// @reference ~/bundles/core")," is the first line of the file? This is our script reference. It's this that Cassette will be reading to pick up references.")),(0,a.kt)("p",null,"To make sure Cassette is picking up our brand new file let's take a look at ",(0,a.kt)("inlineCode",{parentName:"p"},"CassetteConfiguration.cs")," and uncomment the line of code below:"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},'bundles.AddPerIndividualFile<scriptbundle>("~/Scripts/Views");</scriptbundle>')),(0,a.kt)("p",null,"With this in place Cassette will render out a bundle for each script in the Views subdirectory. Let's see if it works. Add the following reference to our new JavaScript file in ",(0,a.kt)("inlineCode",{parentName:"p"},"~/Views/Home/Index.cshtml"),":"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},'Bundles.Reference("~/Scripts/Views/Home/Index.js");')),(0,a.kt)("p",null,"Now ",(0,a.kt)("inlineCode",{parentName:"p"},"Index.js")," is served up by Cassette. And more importantly before ",(0,a.kt)("inlineCode",{parentName:"p"},"Index.js")," was served the referenced ",(0,a.kt)("inlineCode",{parentName:"p"},"~/bundles/core")," was served too."),(0,a.kt)("h2",o({},{id:"avoiding-the-gotcha"}),"Avoiding the Gotcha"),(0,a.kt)("p",null,"There is a gotcha which I've discovered whilst using Cassette's Asset References. Strictly speaking it's a Visual Studio gotcha rather than a Cassette gotcha. It concerns Cassette's support for Visual Studio XML style reference comments. In the example above I could have written this:"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},'/// &lt;reference path="~/bundles/core" /&gt;')),(0,a.kt)("p",null,"Instead of this:"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"// @reference ~/bundles/core")),(0,a.kt)("p",null,"It would fulfil exactly the same purpose and would work identically. But there's a problem. Using Visual Studio XML style reference comments to refer to Cassette bundles appears to trash the Visual Studios JavaScript Intellisense. You'll lose the Intellisense that's driven by ",(0,a.kt)("inlineCode",{parentName:"p"},"~/Scripts/_references.js")," in VS 2012. So if you value your Intellisense (and I do) my advice is to stick to using the standard Cassette references style instead."),(0,a.kt)("h2",o({},{id:"go-forth-and-reference"}),"Go Forth and Reference"),(0,a.kt)("p",null,"There is also support in Cassette for CSS referencing (as well as other types of referencing relating to LESS and even CoffeeScript). I haven't made use of CSS referencing myself as, in stark contrast to my JS, my CSS is generally one bundle of styles which I'm happy to be rendered on each page. But it's nice to know the option is there if I wanted it."),(0,a.kt)("p",null,"Finally, as last time you can see what I've done in this post by just looking at the repository on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/CassetteDemo/tree/References"}),"GitHub"),". The changes I made are on the References branch of that particular repository."))}d.isMDXComponent=!0},145:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"jquery-validate-native-unobtrusive-validation",title:"jQuery Validation - Native Unobtrusive Validation Support!",authors:"johnnyreilly",tags:["jQuery Validation"],hide_table_of_contents:!1},s=void 0,l={permalink:"/jquery-validate-native-unobtrusive-validation",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-06-26-jquery-validate-native-unobtrusive-validation/index.md",source:"@site/blog/2013-06-26-jquery-validate-native-unobtrusive-validation/index.md",title:"jQuery Validation - Native Unobtrusive Validation Support!",description:"Did you know that jQuery Validation natively supports the use of HTML 5 data attributes to drive validation unobtrusively? Neither did I - I haven't seen any documentation for it. However, I was reading the jQuery Validation test suite and that's what I spotted being used in some of the tests.",date:"2013-06-26T00:00:00.000Z",formattedDate:"June 26, 2013",tags:[{label:"jQuery Validation",permalink:"/tags/j-query-validation"}],readingTime:3.39,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"jquery-validate-native-unobtrusive-validation",title:"jQuery Validation - Native Unobtrusive Validation Support!",authors:"johnnyreilly",tags:["jQuery Validation"],hide_table_of_contents:!1},prevItem:{title:"How I'm Using Cassette part 3:Cassette and TypeScript Integration",permalink:"/how-im-using-cassette-part-3-typescript"},nextItem:{title:"How I'm Using Cassette part 2:Get Cassette to Serve Scripts in Dependency Order",permalink:"/how-im-using-cassette-part-2"}},p={authorsImageUrls:[void 0]},u=[{value:"Why is this useful?",id:"why-is-this-useful",level:2},{value:"Wrapping up",id:"wrapping-up",level:2},{value:"Updated 09/08/2012",id:"updated-09082012",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Did you know that jQuery Validation natively supports the use of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://ejohn.org/blog/html-5-data-attributes/"}),"HTML 5 data attributes")," to drive validation unobtrusively? Neither did I - I haven't seen any documentation for it. However, I was reading the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jzaefferer/jquery-validation/blob/master/test/index.html"}),"jQuery Validation test suite")," and that's what I spotted being used in some of the tests."),(0,a.kt)("p",null,"I was quite keen to give it a try as I've found the Microsoft produced ",(0,a.kt)("a",o({parentName:"p"},{href:"http://nuget.org/packages/jQuery.Validation.Unobtrusive/"}),"unobtrusive extensions")," both fantastic and frustrating in nearly equal measure. Fantastic because they work and they're ",(0,a.kt)("a",o({parentName:"p"},{href:"/jquery-unobtrusive-validation"}),"integrated nicely with MVC"),". Frustrating, because they don't allow you do all the things that jQuery Validate in the raw does."),(0,a.kt)("p",null,"So when I realised that there was native alternative available I was delighted. Enough with the fine words - what we want is a demo:"),(0,a.kt)("iframe",{src:"https://htmlpreview.github.io/?http://gist.github.com/johnnyreilly/5867188/raw/272b1b42f4773fe6df843550b3e3d457013522a8/Demo.html",width:"100%",height:"575"}),(0,a.kt)("p",null,"Not particularly exciting? Not noticably different to any other jQuery Validate demo you've ever seen? Fair enough. Now look at the source:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<!DOCTYPE html>\n<html lang="en">\n  <head>\n    <meta charset="utf-8" />\n    <link\n      href="http://netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css"\n      rel="stylesheet"\n    />\n    <style>\n      form {\n        padding: 10px;\n      }\n      .error {\n        color: red;\n      }\n    </style>\n  </head>\n  <body>\n    <form>\n      <label for="RequiredDateDemo"\n        >A date is required (eg "15 June 2012"):</label\n      >\n      <input\n        data-msg-date="The field RequiredDateDemo must be a date."\n        data-msg-required="The RequiredDateDemo field is required."\n        data-rule-date="true"\n        data-rule-required="true"\n        id="RequiredDateDemo"\n        name="RequiredDateDemo"\n        type="text"\n        value=""\n      />\n\n      <hr />\n\n      <label for="StringLengthAndRequiredDemo"\n        >A string is required between 5 and 10 characters long:</label\n      >\n      <input\n        data-msg-maxlength="The field StringLengthAndRequiredDemo must be a string with a minimum length of 5 and a maximum length of 10."\n        data-msg-minlength="The field StringLengthAndRequiredDemo must be a string with a minimum length of 5 and a maximum length of 10."\n        data-msg-required="The StringLengthAndRequiredDemo field is required."\n        data-rule-maxlength="10"\n        data-rule-minlength="5"\n        data-rule-required="true"\n        id="StringLengthAndRequiredDemo"\n        name="StringLengthAndRequiredDemo"\n        type="text"\n        value=""\n      />\n\n      <hr />\n\n      <label for="RangeAndNumberDemo"\n        >Must be a number between -20 and 40:</label\n      >\n      <input\n        data-msg-number="The field RangeAndNumberDemo must be a number."\n        data-msg-range="The field RangeAndNumberDemo must be between -20 and 40."\n        data-rule-number="true"\n        data-rule-range="[-20,40]"\n        id="RangeAndNumberDemo"\n        name="RangeAndNumberDemo"\n        type="text"\n        value="-21"\n      />\n\n      <hr />\n\n      <label for="RangeAndNumberDemo">An option must be selected:</label>\n      <select\n        data-msg-required="The DropDownRequiredDemo field is required."\n        data-rule-required="true"\n        id="DropDownRequiredDemo"\n        name="DropDownRequiredDemo"\n      >\n        <option value="">Please select</option>\n        <option value="An Option">An Option</option>\n      </select>\n\n      <hr />\n\n      <button type="submit">Validate</button>\n    </form>\n\n    <script\n      src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.9.1.js"\n      type="text/javascript"\n    ><\/script>\n    <script\n      src="http://ajax.aspnetcdn.com/ajax/jQuery.validate/1.11.1/jquery.validate.js"\n      type="text/javascript"\n    ><\/script>\n    <script type="text/javascript">\n      var $form = $(\'form\');\n      $form.validate();\n      $form.submit(function (event) {\n        if ($form.validate().valid()) {\n          event.preventDefault();\n\n          alert(\'Valid!\');\n        }\n      });\n    <\/script>\n  </body>\n</html>\n')),(0,a.kt)("p",null,"Do you see what I see? Data attributes (both ",(0,a.kt)("inlineCode",{parentName:"p"},"data-rule-*")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"data-msg-*"),"s) being used to drive the validation unobtrusively! And if you look at the JavaScript files referenced you will see ","*",(0,a.kt)("strong",{parentName:"p"},"no sign"),"*"," of ",(0,a.kt)("inlineCode",{parentName:"p"},"jquery.validate.unobtrusive.js")," ","-"," this is all raw jQuery Validate. Nothing else."),(0,a.kt)("h2",o({},{id:"why-is-this-useful"}),"Why is this useful?"),(0,a.kt)("p",null,"First of all, I'm of the opinion that it makes intuitive sense to have the validation information relevant to various DOM elements stored directly with those DOM elements. There will be occasions where you may not want to use this approach but, in the main, I think it's very sensible. It saves you bouncing back and forth between your HTML and your JavaScript and it means when you read the HTML you know there and then what validation applies to your form."),(0,a.kt)("p",null,"I think this particularly applies when it comes to adding elements to the DOM dynamically. If I use data attributes to drive my validation and I dynamically add elements then jQuery Validate will parse the validation rules for me. I won't have to subsequently apply validation to those new elements once they've been added to the DOM. 1 step instead of 2. It makes for simpler code and that's always a win."),(0,a.kt)("h2",o({},{id:"wrapping-up"}),"Wrapping up"),(0,a.kt)("p",null,"For myself I'm in the early stages of experimenting with this but I thought it might be good to get something out there to show how this works. If anyone knows of any official documentation for this please do let me know - I'd love to have a read of it. Maybe it's been out there all along and it's just my Googling powers are inadequate."),(0,a.kt)("h2",o({},{id:"updated-09082012"}),"Updated 09/08/2012"),(0,a.kt)("p",null,"If you're using ASP.Net MVC 3+ and this post has been of interest to you then you might want to take a look at ",(0,a.kt)("a",o({parentName:"p"},{href:"/announcing-jquery-validation"}),"this"),"."))}d.isMDXComponent=!0},9573:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"how-im-using-cassette-part-3-typescript",title:"How I'm Using Cassette part 3:Cassette and TypeScript Integration",authors:"johnnyreilly",tags:["typescript","javascript","cassette"],hide_table_of_contents:!1},s=void 0,l={permalink:"/how-im-using-cassette-part-3-typescript",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-07-06-how-im-using-cassette-part-3-typescript/index.md",source:"@site/blog/2013-07-06-how-im-using-cassette-part-3-typescript/index.md",title:"How I'm Using Cassette part 3:Cassette and TypeScript Integration",description:"The modern web is JavaScript. There's no two ways about it. HTML 5 has new CSS, new HTML but the most important aspect of it from an application development point of view is JavaScript. It's the engine. Without it HTML 5 wouldn't be the exciting application platform that it is. Half the posts on Hacker News would vanish.",date:"2013-07-06T00:00:00.000Z",formattedDate:"July 6, 2013",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"javascript",permalink:"/tags/javascript"},{label:"cassette",permalink:"/tags/cassette"}],readingTime:6.065,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"how-im-using-cassette-part-3-typescript",title:"How I'm Using Cassette part 3:Cassette and TypeScript Integration",authors:"johnnyreilly",tags:["typescript","javascript","cassette"],hide_table_of_contents:!1},prevItem:{title:"Announcing jQuery Validation Unobtrusive Native...",permalink:"/announcing-jquery-validation"},nextItem:{title:"jQuery Validation - Native Unobtrusive Validation Support!",permalink:"/jquery-validate-native-unobtrusive-validation"}},p={authorsImageUrls:[void 0]},u=[{value:"Cassette and TypeScript",id:"cassette-and-typescript",level:2},{value:"The Fly in the Ointment: Asset References",id:"the-fly-in-the-ointment-asset-references",level:2},{value:"Pulling the Fly from the Ointment",id:"pulling-the-fly-from-the-ointment",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The modern web is JavaScript. There's no two ways about it. HTML 5 has new CSS, new HTML but the most important aspect of it from an application development point of view is JavaScript. It's the engine. Without it HTML 5 wouldn't be the exciting application platform that it is. Half the posts on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://news.ycombinator.com/"}),"Hacker News")," would vanish."),(0,a.kt)("p",null,"It's easy to break a JavaScript application. One false keypress and you can mysteriously turn a fully functioning app into toast. And not know why. There's tools you can use to help yourself - ",(0,a.kt)("a",o({parentName:"p"},{href:"/jshint-customising-your-hurt-feelings"}),"JSHint / JSLint")," but whilst these make error detection a little easier it remains very easy to shoot yourself in the foot with JavaScript. Because of this I've come to really rather love ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.typescriptlang.org/"}),"TypeScript"),". If you didn't already know, TypeScript can be summed up as JavaScript with optional static typing. It's a ",(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("em",{parentName:"strong"},"superset"))," of JavaScript - JavaScript with go-faster stripes. When run through the compiler TypeScript is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Source-to-source_compiler"}),"transpiled")," into JavaScript. And importantly, if you have bugs in your code, the compiler should catch them at this point and let you know."),(0,a.kt)("p",null,"Now very few of us are working on greenfield applications. Most of us have existing applications to maintain and support. Happily, TypeScript fits very well with this purely because TypeScript is a superset of JavaScript. That is to say: all JavaScript is valid TypeScript in the same way that all CSS is valid ",(0,a.kt)("a",o({parentName:"p"},{href:"http://lesscss.org/"}),"LESS"),". This means that you can take an existing ",(0,a.kt)("inlineCode",{parentName:"p"},".js")," file, rename it to have a ",(0,a.kt)("inlineCode",{parentName:"p"},".ts")," suffix, run the TypeScript compiler over it and out will pop your JavaScript file just as it was before. You're then free to enrich your TypeScript file with the relevant type annotations at your own pace. Increasing the robustness of your codebase is a choice left to you."),(0,a.kt)("p",null,"The project I am working on has recently started to incorporate TypeScript. It's an ASP.Net MVC 4 application which makes use of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://knockoutjs.com/"}),"Knockout"),". The reason we started to incorporate TypeScript is because certain parts of the app, particularly the Knockout parts, were becoming more complex. This complexity wasn't really an issue when we were writing the relevant JavaScript. However, when it came to refactoring and handing files from one team member to another we realised it was very easy to introduce bugs into the codebase, particularly around the JavaScript. Hence TypeScript."),(0,a.kt)("h2",o({},{id:"cassette-and-typescript"}),"Cassette and TypeScript"),(0,a.kt)("p",null,"Enough of the pre-amble. The project was making use of Cassette for serving up its CSS and JavaScript. Because Cassette rocks. One of the reasons we use it is that we're making extensive use of ",(0,a.kt)("a",o({parentName:"p"},{href:"/how-im-using-cassette-part-2"}),"Cassette's ability to serve scripts in dependency order"),". So if we were to move to using TypeScript it was important that TypeScript and Cassette would play well together."),(0,a.kt)("p",null,"I'm happy to report that Cassettes and TypeScript do work well together, but there are a few things that you need to get up and running. Or, to be a little clearer, if you want to make use of Cassette's in-file Asset Referencing then you'll need to follow these steps. If you don't need Asset Referencing then you'll be fine using Cassette with TypeScript generated JavaScript as is ","*",(0,a.kt)("strong",{parentName:"p"},"provided"),"*"," you ensure the TypeScript compiler is not preserving comments in the generated JavaScript."),(0,a.kt)("h2",o({},{id:"the-fly-in-the-ointment-asset-references"}),"The Fly in the Ointment: Asset References"),(0,a.kt)("p",null,"TypeScript is designed to allow you to break up your application into modules. However, the referencing mechanism which allows you to reference one TypeScript file / module from another is exactly the same as the existing Visual Studio XML reference comments mechanism that was originally introduced to drive JavaScript Intellisense in Visual Studio. To quote the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.typescriptlang.org/Content/TypeScript%20Language%20Specification.pdf"}),"TypeScript spec"),":"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("em",{parentName:"li"},"A comment of the form /// ",(0,a.kt)("reference",{path:"\u2026"})," adds a dependency on the source file specified in the path argument. The path is resolved relative to the directory of the containing source file.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("em",{parentName:"li"},"An external import declaration that specifies a relative external module name (section 11.2.1) resolves the name relative to the directory of the containing source file. If a source file with the resulting path and file extension \u2018.ts\u2019 exists, that file is added as a dependency. Otherwise, if a source file with the resulting path and file extension \u2018.d.ts\u2019 exists, that file is added as a dependency."))),(0,a.kt)("p",null,"The problem is that ",(0,a.kt)("a",o({parentName:"p"},{href:"http://getcassette.net/documentation/v1/AssetReferences"}),"Cassette ","*",(0,a.kt)("strong",{parentName:"a"},"also"),"*"," supports Visual Studio XML reference comments to drive Asset References"),". The upshot of this is, that Cassette will parse the ",(0,a.kt)("inlineCode",{parentName:"p"},'/// &lt;reference path="*.ts"/&gt;'),"s and will attempt to serve up the TypeScript files in the browser... Calamity!"),(0,a.kt)("h2",o({},{id:"pulling-the-fly-from-the-ointment"}),"Pulling the Fly from the Ointment"),(0,a.kt)("p",null,"Again I'm going to take the demo from last time (",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/CassetteDemo/tree/References"}),"the References branch of my CassetteDemo project"),") and build on top of it. First of all, we need to update the Cassette package. This is because to get Cassette working with TypeScript you need to be running at least Cassette 2.1. So let's let NuGet do it's thing:"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"Update-Package Cassette.Aspnet")),(0,a.kt)("p",null,"And whilst we're at it let's grab the jQuery TypeScript typings - we'll need them later:"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"Install-Package jquery.TypeScript.DefinitelyTyped")),(0,a.kt)("p",null,"Now we need to add a couple of classes to the project. First of all this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing Cassette.Scripts;\n\nnamespace CassetteDemo\n{\n    public class ParseJavaScriptNotTypeScriptReferences : ParseJavaScriptReferences\n    {\n        protected override bool ShouldAddReference(string referencePath)\n        {\n            return !referencePath.EndsWith(".ts", StringComparison.OrdinalIgnoreCase); // Will exclude TypeScript files from being served\n        }\n    }\n}\n')),(0,a.kt)("p",null,"Which subclasses ",(0,a.kt)("inlineCode",{parentName:"p"},"ParseJavaScriptReferences")," and ensures TypeScript files are excluded when JavaScript references are being parsed. And to make sure that Cassette makes use of ",(0,a.kt)("inlineCode",{parentName:"p"},"ParseJavaScriptNotTypeScriptReferences")," in place of ",(0,a.kt)("inlineCode",{parentName:"p"},"ParseJavaScriptReferences")," we need this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using Cassette.BundleProcessing;\nusing Cassette.Scripts;\n\nnamespace CassetteDemo\n{\n    public class InsertIntoPipelineParseJavaScriptNotTypeScriptReferences : IBundlePipelineModifier<ScriptBundle>\n    {\n        public IBundlePipeline<ScriptBundle> Modify(IBundlePipeline<ScriptBundle> pipeline)\n        {\n            var positionOfJavaScriptReferenceParser = pipeline.IndexOf<ParseJavaScriptReferences>();\n\n            pipeline.RemoveAt(positionOfJavaScriptReferenceParser);\n            pipeline.Insert<ParseJavaScriptNotTypeScriptReferences>(positionOfJavaScriptReferenceParser);\n            return pipeline;\n        }\n    }\n}\n")),(0,a.kt)("p",null,"Now we're in a position to use TypeScript with Cassette. To demonstrate this let's take the ",(0,a.kt)("inlineCode",{parentName:"p"},"Index.js")," and rename it to ",(0,a.kt)("inlineCode",{parentName:"p"},"Index.ts"),". And now it's TypeScript. However before it can compile it needs to know what jQuery is - so we drag in the jQuery typings from ",(0,a.kt)("a",o({parentName:"p"},{href:"http://github.com/borisyankov/DefinitelyTyped"}),"Definitely Typed"),". And now it can compile from this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"/// <reference path=\"../../typings/jquery/jquery.d.ts\" />\n// @reference ~/bundles/core\n\n$(document).ready(function () {\n  var $body = $('#body');\n\n  $body.fadeOut(1000, function () {\n    $body\n      .html(\n        '<div style=\"width: 150px; margin: 0 auto;\">I made it all go away...</div>'\n      )\n      .fadeIn();\n  });\n});\n")),(0,a.kt)("p",null,"To this: (Please note that I get the TypeScript compiler to preserve my comments in order that I can continue to use Cassettes Asset Referencing)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"/// <reference path=\"../../typings/jquery/jquery.d.ts\" />\n// @reference ~/bundles/core\n$(document).ready(function () {\n  var $body = $('#body');\n\n  $body.fadeOut(1000, function () {\n    $body\n      .html(\n        '<div style=\"width: 150px; margin: 0 auto;\">I made it all go away...</div>'\n      )\n      .fadeIn();\n  });\n});\n//@ sourceMappingURL=Index.js.map\n")),(0,a.kt)("p",null,"As you can see the output JavaScript has both the TypeScript and the Cassette references in place. However thanks to ",(0,a.kt)("inlineCode",{parentName:"p"},"ParseJavaScriptNotTypeScriptReferences")," those TypeScript references will be ignored by Cassette."),(0,a.kt)("p",null,"So that's it - we're home free. Before I finish off I'd like to say thanks to Cassette's ",(0,a.kt)("a",o({parentName:"p"},{href:"http://twitter.com/andrewdavey"}),"Andrew Davey")," who ",(0,a.kt)("a",o({parentName:"p"},{href:"https://groups.google.com/forum/?fromgroups=#!topic/cassette/SM3Rxh48D7Q"}),"set me on the right path")," when trying to work out how to do this. A thousand thank yous Andrew!"),(0,a.kt)("p",null,"And finally, again as last time you can see what I've done in this post by just looking at the repository on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/CassetteDemo/tree/TypeScript"}),"GitHub"),". The changes I made are on the TypeScript branch of that particular repository."))}d.isMDXComponent=!0},73297:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"announcing-jquery-validation",title:"Announcing jQuery Validation Unobtrusive Native...",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},s=void 0,l={permalink:"/announcing-jquery-validation",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-08-08-announcing-jquery-validation/index.md",source:"@site/blog/2013-08-08-announcing-jquery-validation/index.md",title:"Announcing jQuery Validation Unobtrusive Native...",description:"I've been busy working on an open source project called jQuery Validation Unobtrusive Native. To see it in action take a look here.",date:"2013-08-08T00:00:00.000Z",formattedDate:"August 8, 2013",tags:[],readingTime:2.295,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"announcing-jquery-validation",title:"Announcing jQuery Validation Unobtrusive Native...",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},prevItem:{title:"Using Bootstrap Tooltips to display jQuery Validation error messages",permalink:"/using-bootstrap-tooltips-to-display"},nextItem:{title:"How I'm Using Cassette part 3:Cassette and TypeScript Integration",permalink:"/how-im-using-cassette-part-3-typescript"}},p={authorsImageUrls:[void 0]},u=[{value:"A Little Background",id:"a-little-background",level:2},{value:"So... What is jQuery Validation Unobtrusive Native?",id:"so-what-is-jquery-validation-unobtrusive-native",level:2},{value:"Future Plans",id:"future-plans",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I've been busy working on an open source project called ",(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("a",o({parentName:"strong"},{href:"https://github.com/johnnyreilly/jQuery.Validation.Unobtrusive.Native"}),"jQuery Validation Unobtrusive Native")),". ",(0,a.kt)("a",o({parentName:"p"},{href:"https://johnnyreilly.github.io/jQuery.Validation.Unobtrusive.Native/"}),"To see it in action take a look here"),"."),(0,a.kt)("h2",o({},{id:"a-little-background"}),"A Little Background"),(0,a.kt)("p",null,"I noticed a little while ago that jQuery Validation was now providing native support for validation driven by HTML 5 data attributes. As you may be aware, Microsoft shipped ",(0,a.kt)("a",o({parentName:"p"},{href:"http://bradwilson.typepad.com/blog/2010/10/mvc3-unobtrusive-validation.html"}),"jquery.validate.unobtrusive.js")," back with MVC 3. (",(0,a.kt)("a",o({parentName:"p"},{href:"/jquery-unobtrusive-validation"}),"I have written about it before."),") It provided a way to apply data model validations to the client side using a combination of jQuery Validation and HTML 5 data attributes."),(0,a.kt)("p",null,"The principal of this was and is fantastic. But since that time the jQuery Validation project has implemented its own support for driving validation unobtrusively (shipping with ",(0,a.kt)("a",o({parentName:"p"},{href:"http://jquery.bassistance.de/validate/changelog.txt"}),"jQuery Validation 1.11.0"),"). I've been looking at a way to directly use the native support instead of jquery.validate.unobtrusive.js."),(0,a.kt)("h2",o({},{id:"so-what-is-jquery-validation-unobtrusive-native"}),"So... What is jQuery Validation Unobtrusive Native?"),(0,a.kt)("p",null,"jQuery Validation Unobtrusive Native is a collection of ASP.Net MVC HTML helper extensions. These make use of jQuery Validation's native support for validation driven by HTML 5 data attributes. The advantages of the native support over jquery.validate.unobtrusive.js are:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Dynamically created form elements are parsed automatically. jquery.validate.unobtrusive.js does not support this whilst jQuery Validation does. ",(0,a.kt)("a",o({parentName:"li"},{href:"http://johnnyreilly.github.io/jQuery.Validation.Unobtrusive.Native/AdvancedDemo/Knockout.html"}),"Take a look at a demo using Knockout.")),(0,a.kt)("li",{parentName:"ul"},"jquery.validate.unobtrusive.js restricts how you use jQuery Validation. If you want to use showErrors or something similar then you may find that you need to go native (or at least you may find that significantly easier than working with the jquery.validate.unobtrusive.js defaults)..."),(0,a.kt)("li",{parentName:"ul"},"Send less code to your browser, make your browser to do less work and even get a (marginal) performance benefit .")),(0,a.kt)("p",null,"This project intends to be a bridge between MVC's inbuilt support for driving validation from data attributes and jQuery Validation's native support for the same. This is achieved by hooking into the MVC data attribute creation mechanism and using it to generate the data attributes natively supported by jQuery Validation."),(0,a.kt)("h2",o({},{id:"future-plans"}),"Future Plans"),(0,a.kt)("p",null,"So far the basic set of the HtmlHelpers and their associated unobtrusive mappings have been implemented. If any have been missed then let me know. As time goes by I intend to:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"fill in any missing gaps there may be"),(0,a.kt)("li",{parentName:"ul"},"maintain MVC 3, 4 (and when the time comes 5+) versions of this on Nuget"),(0,a.kt)("li",{parentName:"ul"},"not all data annotations generate client data attributes - if it makes sense I may look to implement some of these where it seems sensible. (eg the ",(0,a.kt)("a",o({parentName:"li"},{href:"http://msdn.microsoft.com/en-us/library/system.componentmodel.dataannotations.minlengthattribute.aspx"}),"MinLengthAttribute")," annotation could be mapped to ",(0,a.kt)("a",o({parentName:"li"},{href:"http://jqueryvalidation.org/minlength-method/"}),"minlength")," validation...)"),(0,a.kt)("li",{parentName:"ul"},"get the unit test coverage to a good level and finally (and perhaps most importantly)"),(0,a.kt)("li",{parentName:"ul"},"create some really useful ",(0,a.kt)("a",o({parentName:"li"},{href:"http://johnnyreilly.github.io/jQuery.Validation.Unobtrusive.Native/Demo.html"}),"demos and documentation"),".")),(0,a.kt)("p",null,"Help is appreciated so feel free to pitch in! You can find the project on GitHub ",(0,a.kt)("a",o({parentName:"p"},{href:"http://github.com/johnnyreilly/jQuery.Validation.Unobtrusive.Native"}),"here"),"..."))}d.isMDXComponent=!0},36185:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"using-bootstrap-tooltips-to-display",title:"Using Bootstrap Tooltips to display jQuery Validation error messages",authors:"johnnyreilly",tags:["Tooltip","Bootstrap","jQuery Validation"],hide_table_of_contents:!1},s=void 0,l={permalink:"/using-bootstrap-tooltips-to-display",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-08-17-using-bootstrap-tooltips-to-display/index.md",source:"@site/blog/2013-08-17-using-bootstrap-tooltips-to-display/index.md",title:"Using Bootstrap Tooltips to display jQuery Validation error messages",description:"I love jQuery Validation. I was recently putting together a screen which had a lot of different bits of validation going on. And the default jQuery Validation approach of displaying the validation messages next to the element being validated wasn't working for me. That is to say, because of the amount of elements on the form, the appearance of validation messages was really making a mess of the presentation. So what to do?",date:"2013-08-17T00:00:00.000Z",formattedDate:"August 17, 2013",tags:[{label:"Tooltip",permalink:"/tags/tooltip"},{label:"Bootstrap",permalink:"/tags/bootstrap"},{label:"jQuery Validation",permalink:"/tags/j-query-validation"}],readingTime:2.855,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"using-bootstrap-tooltips-to-display",title:"Using Bootstrap Tooltips to display jQuery Validation error messages",authors:"johnnyreilly",tags:["Tooltip","Bootstrap","jQuery Validation"],hide_table_of_contents:!1},prevItem:{title:"Migrating from jquery.validate.unobtrusive.js to jQuery.Validation.Unobtrusive.Native",permalink:"/migrating-from-jquery.validate.unobtrusive.js-to-jQuery.Validation.Unobtrusive.Native"},nextItem:{title:"Announcing jQuery Validation Unobtrusive Native...",permalink:"/announcing-jquery-validation"}},p={authorsImageUrls:[void 0]},u=[{value:"Tooltips to the rescue!",id:"tooltips-to-the-rescue",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I love jQuery Validation. I was recently putting together a screen which had a lot of different bits of validation going on. And the default jQuery Validation approach of displaying the validation messages next to the element being validated wasn't working for me. That is to say, because of the amount of elements on the form, the appearance of validation messages was really making a mess of the presentation. So what to do?"),(0,a.kt)("h2",o({},{id:"tooltips-to-the-rescue"}),"Tooltips to the rescue!"),(0,a.kt)("p",null,"I was chatting to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://plus.google.com/u/0/116859810359377785616/posts"}),"Marc Talary")," about this and he had the bright idea of using tooltips to display the error messages. Tooltips would allow the existing presentation of the form to remain as is whilst still displaying the messages to the users. Brilliant idea!"),(0,a.kt)("p",null,"After a certain amount of fiddling I came up with a fairly solid mechanism for getting jQuery Validation to display error messages as tooltips which I'll share here. It's worth saying that for the application that Marc and I were working on we already had ",(0,a.kt)("a",o({parentName:"p"},{href:"http://jqueryui.com/"}),"jQuery UI")," in place and so we decided to use the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://jqueryui.com/tooltip/"}),"jQuery UI tooltip"),". This example will use the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://getbootstrap.com/javascript/#tooltips"}),"Bootstrap tooltip")," instead. As much as anything else this demonstrates that you could swap out the tooltip mechanism here with any of your choosing."),(0,a.kt)("iframe",{src:"https://htmlpreview.github.io/?https://gist.github.com/johnnyreilly/5867188/raw/2543a12fbd5c0aaad1da6793b7a7437492be3baf/DemoTooltip.html",width:"100%",height:"350"}),(0,a.kt)("p",null,"Beautiful isn't it? Now look at the source:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<!DOCTYPE html>\n<html lang="en">\n  <head>\n    <meta charset="utf-8" />\n    <link\n      href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css"\n      rel="stylesheet"\n    />\n    <style>\n      form {\n        padding: 10px;\n      }\n      .error {\n        border: 1px solid #b94a48 !important;\n        background-color: #fee !important;\n      }\n    </style>\n  </head>\n  <body>\n    <form>\n      <div class="row">\n        <label for="RequiredDateDemo"\n          >A date is required (eg "15 June 2012"):</label\n        >\n        <input\n          data-msg-date="The field RequiredDateDemo must be a date."\n          data-msg-required="The RequiredDateDemo field is required."\n          data-rule-date="true"\n          data-rule-required="true"\n          id="RequiredDateDemo"\n          name="RequiredDateDemo"\n          type="text"\n          value=""\n        />\n      </div>\n\n      <div class="row">\n        <label for="StringLengthAndRequiredDemo"\n          >A string is required between 5 and 10 characters long:</label\n        >\n        <input\n          data-msg-maxlength="The field StringLengthAndRequiredDemo must be a string with a minimum length of 5 and a maximum length of 10."\n          data-msg-minlength="The field StringLengthAndRequiredDemo must be a string with a minimum length of 5 and a maximum length of 10."\n          data-msg-required="The StringLengthAndRequiredDemo field is required."\n          data-rule-maxlength="10"\n          data-rule-minlength="5"\n          data-rule-required="true"\n          id="StringLengthAndRequiredDemo"\n          name="StringLengthAndRequiredDemo"\n          type="text"\n          value=""\n        />\n      </div>\n\n      <div class="row">\n        <label for="RangeAndNumberDemo"\n          >Must be a number between -20 and 40:</label\n        >\n        <input\n          data-msg-number="The field RangeAndNumberDemo must be a number."\n          data-msg-range="The field RangeAndNumberDemo must be between -20 and 40."\n          data-rule-number="true"\n          data-rule-range="[-20,40]"\n          id="RangeAndNumberDemo"\n          name="RangeAndNumberDemo"\n          type="text"\n          value="-21"\n        />\n      </div>\n\n      <div class="row">\n        <label for="RangeAndNumberDemo">An option must be selected:</label>\n        <select\n          data-msg-required="The DropDownRequiredDemo field is required."\n          data-rule-required="true"\n          id="DropDownRequiredDemo"\n          name="DropDownRequiredDemo"\n        >\n          <option value="">Please select</option>\n          <option value="An Option">An Option</option>\n        </select>\n      </div>\n\n      <div class="row">\n        <button type="submit">Validate</button>\n      </div>\n    </form>\n\n    <script\n      src="//ajax.aspnetcdn.com/ajax/jQuery/jquery-1.9.1.js"\n      type="text/javascript"\n    ><\/script>\n    <script\n      src="//ajax.aspnetcdn.com/ajax/jQuery.validate/1.11.1/jquery.validate.js"\n      type="text/javascript"\n    ><\/script>\n    <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"><\/script>\n    <script type="text/javascript">\n      $(\'form\').validate({\n        showErrors: function (errorMap, errorList) {\n          // Clean up any tooltips for valid elements\n          $.each(this.validElements(), function (index, element) {\n            var $element = $(element);\n\n            $element\n              .data(\'title\', \'\') // Clear the title - there is no error associated anymore\n              .removeClass(\'error\')\n              .tooltip(\'destroy\');\n          });\n\n          // Create new tooltips for invalid elements\n          $.each(errorList, function (index, error) {\n            var $element = $(error.element);\n\n            $element\n              .tooltip(\'destroy\') // Destroy any pre-existing tooltip so we can repopulate with new tooltip content\n              .data(\'title\', error.message)\n              .addClass(\'error\')\n              .tooltip(); // Create a new tooltip based on the error messsage we just set in the title\n          });\n        },\n\n        submitHandler: function (form) {\n          alert(\'This is a valid form!\');\n        },\n      });\n    <\/script>\n  </body>\n</html>\n')),(0,a.kt)("p",null,"All the magic is in the JavaScript, specifically the ",(0,a.kt)("inlineCode",{parentName:"p"},"showErrors")," function that's passed as an option to jQuery Validation. Enjoy!"))}d.isMDXComponent=!0},67223:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"migrating-from-jquery.validate.unobtrusive.js-to-jQuery.Validation.Unobtrusive.Native",title:"Migrating from jquery.validate.unobtrusive.js to jQuery.Validation.Unobtrusive.Native",authors:"johnnyreilly",tags:["jQuery Validation"],hide_table_of_contents:!1},s=void 0,l={permalink:"/migrating-from-jquery.validate.unobtrusive.js-to-jQuery.Validation.Unobtrusive.Native",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-10-04-migrating-from-jquery.validate.unobtrusive.js-to-jQuery.Validation.Unobtrusive.Native/index.md",source:"@site/blog/2013-10-04-migrating-from-jquery.validate.unobtrusive.js-to-jQuery.Validation.Unobtrusive.Native/index.md",title:"Migrating from jquery.validate.unobtrusive.js to jQuery.Validation.Unobtrusive.Native",description:"So, you're looking at jQuery.Validation.Unobtrusive.Native. You're thinking to yourself \"Yeah, I'd really like to use the native unobtrusive support in jQuery Validation. But I've already got this app which is using jquery.validate.unobtrusive.js \\- actually how easy is switching over?\" Well I'm here to tell you that it's pretty straightforward - here's a walkthrough of how it might be done.",date:"2013-10-04T00:00:00.000Z",formattedDate:"October 4, 2013",tags:[{label:"jQuery Validation",permalink:"/tags/j-query-validation"}],readingTime:3.715,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"migrating-from-jquery.validate.unobtrusive.js-to-jQuery.Validation.Unobtrusive.Native",title:"Migrating from jquery.validate.unobtrusive.js to jQuery.Validation.Unobtrusive.Native",authors:"johnnyreilly",tags:["jQuery Validation"],hide_table_of_contents:!1},prevItem:{title:"Getting TypeScript Compile-on-Save and Continuous Integration to play nice",permalink:"/getting-typescript-compile-on-save-and-continous-integration-to-play-nice"},nextItem:{title:"Using Bootstrap Tooltips to display jQuery Validation error messages",permalink:"/using-bootstrap-tooltips-to-display"}},p={authorsImageUrls:[void 0]},u=[{value:"I need something to migrate",id:"i-need-something-to-migrate",level:2},{value:"Hit me up NuGet!",id:"hit-me-up-nuget",level:2},{value:"Migrating...",id:"migrating",level:2},{value:"Rounding off",id:"rounding-off",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"So, you're looking at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/jQuery.Validation.Unobtrusive.Native"}),"jQuery.Validation.Unobtrusive.Native"),". You're thinking to yourself \"Yeah, I'd really like to use the native unobtrusive support in jQuery Validation. But I've already got this app which is using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.nuget.org/packages/jQuery.Validation.Unobtrusive/"}),"jquery.validate.unobtrusive.js")," ","-"," actually how easy is switching over?\" Well I'm here to tell you that it's pretty straightforward - here's a walkthrough of how it might be done."),(0,a.kt)("h2",o({},{id:"i-need-something-to-migrate"}),"I need something to migrate"),(0,a.kt)("p",null,'So let\'s File > New Project ourselves a new MVC 4 application using the Internet Application template. I\'ve picked this template as I know it ships with account registration / login screens in place which make use of jquery.validate.unobtrusive.js. To demo this just run the project, click the "Log in" link and then click the "Log in" button.'),(0,a.kt)("p",null,"What you've just witnessed is jquery.validate.unobtrusive.js doing its thing. Both the ",(0,a.kt)("inlineCode",{parentName:"p"},"UserName")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"Password")," properties on the ",(0,a.kt)("inlineCode",{parentName:"p"},"LoginModel")," are decorated with the ",(0,a.kt)("inlineCode",{parentName:"p"},"Required")," data annotation which, in the above scenario, causes the validation to be triggered on the client thanks to MVC rendering data attributes in the HTML which jquery.validate.unobtrusive.js picks up on. The question is, how can we take the log in screen above and migrate it across to to using jQuery.Validation.Unobtrusive.Native?"),(0,a.kt)("h2",o({},{id:"hit-me-up-nuget"}),"Hit me up NuGet!"),(0,a.kt)("p",null,"Time to dive into NuGet and install jQuery.Validation.Unobtrusive.Native. We'll install the MVC 4 version using this command:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"Install-Package jQuery.Validation.Unobtrusive.Native.MVC4\n")),(0,a.kt)("p",null,"What has this done to my project? Well 2 things"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"It's upgraded jQuery Validation (",(0,a.kt)("a",o({parentName:"li"},{href:"http://jqueryvalidation.org/"}),"jquery.validate.js"),") from v1.10.0 (the version that is currently part of the MVC 4 template) to v1.11.1 (the latest and greatest jQuery Validation as of the time of writing)"),(0,a.kt)("li",{parentName:"ol"},"It's added a reference to the jQuery.Validation.Unobtrusive.Native.MVC4 assembly, like so:")),(0,a.kt)("p",null,"In case you were wondering, doing this hasn't broken the existing jquery.validate.unobtrusive.js - if you head back to the Log in screen you'll still see the same behaviour as before."),(0,a.kt)("h2",o({},{id:"migrating"}),"Migrating..."),(0,a.kt)("p",null,"We need to switch our TextBox and Password helpers over to using jQuery.Validation.Unobtrusive.Native, which we achieve by simply passing a second argument of ",(0,a.kt)("inlineCode",{parentName:"p"},"true")," to ",(0,a.kt)("inlineCode",{parentName:"p"},"useNativeUnobtrusiveAttributes"),". So we go from this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"// ...\n@Html.TextBoxFor(m => m.UserName)\n// ...\n@Html.PasswordFor(m => m.Password)\n// ...\n")),(0,a.kt)("p",null,"To this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"// ...\n@Html.TextBoxFor(m => m.UserName, true)\n// ...\n@Html.PasswordFor(m => m.Password, true)\n// ...\n")),(0,a.kt)("p",null,"With these minor tweaks in place the natively supported jQuery Validation data attributes will be rendered into the textbox / password elements instead of the jquery.validate.unobtrusive.js ones."),(0,a.kt)("p",null,"Next lets do the JavaScript. If you take a look at the bottom of the ",(0,a.kt)("inlineCode",{parentName:"p"},"Login.cshtml")," view you'll see this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'@section Scripts {\n    @Scripts.Render("~/bundles/jqueryval")\n}\n')),(0,a.kt)("p",null,"Which renders the following scripts:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<script src="/Scripts/jquery.unobtrusive-ajax.js"><\/script>\n<script src="/Scripts/jquery.validate.js"><\/script>\n<script src="/Scripts/jquery.validate.unobtrusive.js"><\/script>\n')),(0,a.kt)("p",null,"In our brave new world we're only going to need jquery.validate.js - so let's create ourselves a new bundle in ",(0,a.kt)("inlineCode",{parentName:"p"},"BundleConfig.cs")," which only contains that single file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'bundles.Add(new ScriptBundle("~/bundles/jqueryvalnative")\n    .Include("~/Scripts/jquery.validate.js"));\n')),(0,a.kt)("p",null,"To finish off our migrated screen we need to do 2 things. First we need to switch over the ",(0,a.kt)("inlineCode",{parentName:"p"},"Login.cshtml")," view to only render the jquery.validate.js script (in the form of our new bundle). Secondly, the other thing that jquery.validate.unobtrusive.js did was to trigger validation for the current form. So we need to do that ourselves now. So our finished Scripts section looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),"@section Scripts { @Scripts.Render(\"~/bundles/jqueryvalnative\")\n<script>\n  $('form').validate();\n<\/script>\n}\n")),(0,a.kt)("p",null,"Which renders the following script:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),"<script src=\"/Scripts/jquery.validate.js\"><\/script>\n<script>\n  $('form').validate();\n<\/script>\n")),(0,a.kt)("p",null,"And, pretty much, that's it. If you run the app now and go to the Log in screen and try to log in without credentials."),(0,a.kt)("p",null,"Which is functionally exactly the same as previously. The eagle eyed will notice some styling differences but that's all it comes down to really; style. And if you were so inclined you could easily style this up as you liked using CSS and the options you can pass to jQuery Validation (in fact a quick rummage through jquery.validate.unobtrusive.js should give you everything you need)."),(0,a.kt)("h2",o({},{id:"rounding-off"}),"Rounding off"),(0,a.kt)("p",null,"Before I sign off I'd like to illustrate how little we've had to change the code to start using jQuery.Validation.Unobtrusive.Native."),(0,a.kt)("p",null,"As you see, it takes very little effort to migrate from one approach to the other. And it's ","*",(0,a.kt)("strong",{parentName:"p"},"your"),"*"," choice. If you want to have one screen that uses jQuery.Validation.Unobtrusive.Native and one screen that uses jquery.validation.unobtrusive.js then you can! Including jQuery.Validation.Unobtrusive.Native in your project gives you the ",(0,a.kt)("strong",{parentName:"p"},"option")," to use it. It doesn't force you to, you can do so as you need to and when you want to. It's down to you."))}d.isMDXComponent=!0},80977:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"getting-typescript-compile-on-save-and-continous-integration-to-play-nice",title:"Getting TypeScript Compile-on-Save and Continuous Integration to play nice",authors:"johnnyreilly",tags:["TFS","typescript"],hide_table_of_contents:!1},s=void 0,l={permalink:"/getting-typescript-compile-on-save-and-continous-integration-to-play-nice",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-10-30-getting-typescript-compile-on-save-and-continous-integration-to-play-nice/index.md",source:"@site/blog/2013-10-30-getting-typescript-compile-on-save-and-continous-integration-to-play-nice/index.md",title:"Getting TypeScript Compile-on-Save and Continuous Integration to play nice",description:'Well sort of... Perhaps this post should more accurately called "How to get CI to ignore your TypeScript whilst Visual Studio still compiles it..."',date:"2013-10-30T00:00:00.000Z",formattedDate:"October 30, 2013",tags:[{label:"TFS",permalink:"/tags/tfs"},{label:"typescript",permalink:"/tags/typescript"}],readingTime:3.93,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"getting-typescript-compile-on-save-and-continous-integration-to-play-nice",title:"Getting TypeScript Compile-on-Save and Continuous Integration to play nice",authors:"johnnyreilly",tags:["TFS","typescript"],hide_table_of_contents:!1},prevItem:{title:"TypeScript: Don't forget Build Action for Implicit Referencing...",permalink:"/typescript-dont-forget-build-action-for-implicit-referencing"},nextItem:{title:"Migrating from jquery.validate.unobtrusive.js to jQuery.Validation.Unobtrusive.Native",permalink:"/migrating-from-jquery.validate.unobtrusive.js-to-jQuery.Validation.Unobtrusive.Native"}},p={authorsImageUrls:[void 0]},u=[{value:"Once there was Web Essentials",id:"once-there-was-web-essentials",level:2},{value:"But there is still Compile on Save hope!",id:"but-there-is-still-compile-on-save-hope",level:2},{value:"So what now?",id:"so-what-now",level:2},{value:"A solution",id:"a-solution",level:2},{value:"Final thoughts",id:"final-thoughts",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'Well sort of... Perhaps this post should more accurately called "How to get CI to ignore your TypeScript whilst Visual Studio still compiles it..."'),(0,a.kt)("h2",o({},{id:"once-there-was-web-essentials"}),"Once there was Web Essentials"),(0,a.kt)("p",null,"When I first started using TypeScript, I was using it in combination with Web Essentials. Those were happy days. I saved my TS file and Web Essentials would kick off TypeScript compilation. Ah bliss. But the good times couldn't last forever and sure enough when version 3.0 of Web Essentials shipped it ",(0,a.kt)("a",o({parentName:"p"},{href:"http://madskristensen.net/post/Web-Essentials-2013-Where-is-the-TypeScript-support"}),"pulled support for TypeScript"),"."),(0,a.kt)("p",null,"This made me, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://typescript.codeplex.com/workitem/1616"}),"and others"),", very sad. Essentially we were given the choice between sticking with an old version of Web Essentials (2.9 - the last release before 3.0) and keeping our Compile-on-Save ","*",(0,a.kt)("strong",{parentName:"p"},"or"),"*"," keeping with the latest version of Web Essentials and losing it. And since I understood that newer versions of TypeScript had differences in the compiler flags which slightly broke compatibility with WE 2.9 the latter choice seemed the most sensible..."),(0,a.kt)("h2",o({},{id:"but-there-is-still-compile-on-save-hope"}),"But there is still Compile on Save hope!"),(0,a.kt)("p",null,"The information was that we need not lose our Compile on Save. We just need to follow the instructions ",(0,a.kt)("a",o({parentName:"p"},{href:"https://typescript.codeplex.com/wikipage?title=Compile-on-Save"}),"here"),". Or to quote them:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Then additionally add (or replace if you had an older PreBuild action for TypeScript) the following at the end of your project file to include TypeScript compilation in your project."),(0,a.kt)("p",{parentName:"blockquote"},"..."),(0,a.kt)("p",{parentName:"blockquote"},"For C#-style projects (.csproj):"),(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),"<PropertyGroup Condition=\"'$(Configuration)' == 'Debug'\">\n    <TypeScriptTarget>ES5</TypeScriptTarget>\n    <TypeScriptIncludeComments>true</TypeScriptIncludeComments>\n    <TypeScriptSourceMap>true</TypeScriptSourceMap>\n  </PropertyGroup>\n  <PropertyGroup Condition=\"'$(Configuration)' == 'Release'\">\n    <TypeScriptTarget>ES5</TypeScriptTarget>\n    <TypeScriptIncludeComments>false</TypeScriptIncludeComments>\n    <TypeScriptSourceMap>false</TypeScriptSourceMap>\n  </PropertyGroup>\n  <Import Project=\"$(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion)\\TypeScript\\Microsoft.TypeScript.targets\" />\n"))),(0,a.kt)("p",null,"I followed these instructions (well I had to tweak the ",(0,a.kt)("inlineCode",{parentName:"p"},"Import Project")," location) and I was in business again. But I when I came to check my code into TFS I came unstuck. The automated build kicked off and then, in short order, kicked me:"),(0,a.kt)("blockquote",null,(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",o({parentName:"pre"},{}),'C:\\Builds\\1\\MyApp\\MyApp Continuous Integration\\src\\MyApp\\MyApp.csproj (1520): The imported project "C:\\Program Files (x86)\\MSBuild\\Microsoft\\VisualStudio\\v11.0\\TypeScript\\Microsoft.TypeScript.targets" was not found. Confirm that the path in the <import> declaration is correct, and that the file exists on disk.\nC:\\Builds\\1\\MyApp\\MyApp Continuous Integration\\src\\MyApp\\MyApp.csproj (1520): The imported project "C:\\Program Files (x86)\\MSBuild\\Microsoft\\VisualStudio\\v11.0\\TypeScript\\Microsoft.TypeScript.targets" was not found. Confirm that the path in the <import> declaration is correct, and that the file exists on disk.\n</import></import>\n'))),(0,a.kt)("p",null,"That's right, TypeScript wasn't installed on the build server. And since TypeScript was now part of the build process my builds were now failing. Ouch."),(0,a.kt)("h2",o({},{id:"so-what-now"}),"So what now?"),(0,a.kt)("p",null,"I did a little digging and found ",(0,a.kt)("a",o({parentName:"p"},{href:"https://typescript.codeplex.com/workitem/1518"}),"this issue report on the TypeScript CodePlex site"),". To quote the issue, it seemed there were 2 possible solutions to get continuous integration and typescript playing nice:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Install TypeScript on the build server"),(0,a.kt)("li",{parentName:"ol"},"Copy the required files for Microsoft.TypeScript.targets to a different source-controlled folder and change the path references in the csproj file to this folder.")),(0,a.kt)("p",null,"#","1 wasn't an option for us - we couldn't install on the build server. And covering both #1 and #2, I wasn't particularly inclined to kick off builds on the build server since I was wary of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://typescript.codeplex.com/workitem/1432"}),"reported problems with memory leaks")," etc with the TS compiler. I may feel differently later when TS is no longer in Alpha and has stabilised but it didn't seem like the right time."),(0,a.kt)("h2",o({},{id:"a-solution"}),"A solution"),(0,a.kt)("p",null,"So, to sum up, what I wanted was to be able to compile TypeScript in Visual Studio on my machine, and indeed in VS on the machine of anyone else working on the project. But I ","*",(0,a.kt)("strong",{parentName:"p"},"didn't"),"*"," want TypeScript compilation to be part of the build process on the server."),(0,a.kt)("p",null,"The solution in the end was pretty simple - I replaced the ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj")," changes with the code below:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),"<PropertyGroup Condition=\"'$(Configuration)' == 'Debug'\">\n    <TypeScriptTarget>ES5</TypeScriptTarget>\n    <TypeScriptRemoveComments>false</TypeScriptRemoveComments>\n    <TypeScriptSourceMap>false</TypeScriptSourceMap>\n    <TypeScriptModuleKind>AMD</TypeScriptModuleKind>\n    <TypeScriptNoImplicitAny>true</TypeScriptNoImplicitAny>\n  </PropertyGroup>\n  <PropertyGroup Condition=\"'$(Configuration)' == 'Release'\">\n    <TypeScriptTarget>ES5</TypeScriptTarget>\n    <TypeScriptRemoveComments>false</TypeScriptRemoveComments>\n    <TypeScriptSourceMap>false</TypeScriptSourceMap>\n    <TypeScriptModuleKind>AMD</TypeScriptModuleKind>\n    <TypeScriptNoImplicitAny>true</TypeScriptNoImplicitAny>\n  </PropertyGroup>\n  <Import Project=\"$(VSToolsPath)\\TypeScript\\Microsoft.TypeScript.targets\" Condition=\"Exists('$(VSToolsPath)\\TypeScript\\Microsoft.TypeScript.targets')\" />\n")),(0,a.kt)("p",null,"What this does is enable TypeScript compilation ","*",(0,a.kt)("strong",{parentName:"p"},"only"),"*"," if TypeScript is installed. So when I'm busy developing with Visual Studio on my machine with the plugin installed I can compile TypeScript. But when I check in the TypeScript compilation is ","*",(0,a.kt)("strong",{parentName:"p"},"not"),"*"," performed on the build server. This is because TypeScript is not installed on the build server and we are only compiling if it is installed. (Just to completely labour the point.)"),(0,a.kt)("h2",o({},{id:"final-thoughts"}),"Final thoughts"),(0,a.kt)("p",null,"I do consider this an interim solution. As I mentioned earlier, when TypeScript has stabilised I think I'd like TS compilation to be part of the build process. Like with any other code I think compiling on check-in to catch bugs early is an excellent idea. But I think I'll wait until there's some clearer guidance on the topic from the TypeScript team before I take this step."))}d.isMDXComponent=!0},23138:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-dont-forget-build-action-for-implicit-referencing",title:"TypeScript: Don't forget Build Action for Implicit Referencing...",authors:"johnnyreilly",tags:["typescript","Definitely Typed","typescript","nuget"],hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-dont-forget-build-action-for-implicit-referencing",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-11-04-typescript-dont-forget-build-action-for-implicit-referencing/index.md",source:"@site/blog/2013-11-04-typescript-dont-forget-build-action-for-implicit-referencing/index.md",title:"TypeScript: Don't forget Build Action for Implicit Referencing...",description:"As part of the known breaking changes between 0.9 and 0.9.1 there was this subtle but significant switch:",date:"2013-11-04T00:00:00.000Z",formattedDate:"November 4, 2013",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"Definitely Typed",permalink:"/tags/definitely-typed"},{label:"nuget",permalink:"/tags/nuget"}],readingTime:1.96,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-dont-forget-build-action-for-implicit-referencing",title:"TypeScript: Don't forget Build Action for Implicit Referencing...",authors:"johnnyreilly",tags:["typescript","Definitely Typed","typescript","nuget"],hide_table_of_contents:!1},prevItem:{title:"Rolling your own confirm mechanism using Promises and jQuery UI",permalink:"/rolling-your-own-confirm-mechanism"},nextItem:{title:"Getting TypeScript Compile-on-Save and Continuous Integration to play nice",permalink:"/getting-typescript-compile-on-save-and-continous-integration-to-play-nice"}},p={authorsImageUrls:[void 0]},u=[{value:"Wrong!",id:"wrong",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"As part of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://typescript.codeplex.com/wikipage?title=Known%20breaking%20changes%20between%200.8%20and%200.9&referringTitle=Documentation"}),"known breaking changes between 0.9 and 0.9.1")," there was this subtle but significant switch:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"In Visual Studio, all TypeScript files in a project are considered to be referencing each other"),(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("em",{parentName:"p"},"Description:")," Previously, all TypeScript files in a project had to reference each other explicitly. With 0.9.1, they now implicitly reference all other TypeScript files in the project. For existing projects that fit multiple projects into a single projects, these will now have to be separate projects."),(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("em",{parentName:"p"},"Reason:")," This greatly simplifies using TypeScript in the project context.")),(0,a.kt)("p",null,"Having been ",(0,a.kt)("a",o({parentName:"p"},{href:"https://typescript.codeplex.com/workitem/1471"}),"initially resistant")," to this change I recently decided to give it a try. That is to say I started pulling out the ",(0,a.kt)("inlineCode",{parentName:"p"},"/// &lt;reference"),"'s from my TypeScript files. However, to my surprise, pulling out these references stopped my TypeScript from compiling and killed my Intellisense. After wrestling with this for a couple of hours I finally ",(0,a.kt)("a",o({parentName:"p"},{href:"https://typescript.codeplex.com/workitem/1855"}),"filed an issue on the TypeScript CodePlex site"),". (Because clearly the problem was with TypeScript and not how I was using it, right?)"),(0,a.kt)("h2",o({},{id:"wrong"}),"Wrong!"),(0,a.kt)("p",null,"When I looked through my typing files (","*",'.d.ts) I found that, pretty much without exception, all had a Build Action of "Content" and not "TypeScriptCompile". I went through the project and switched the files over to being "TypeScriptCompile". This resolved the issue and I was then able to pull out the remaining ',(0,a.kt)("inlineCode",{parentName:"p"},"/// &lt;reference")," comments from the codebase (though I did have to restart Visual Studio to get the Intellisense working)."),(0,a.kt)("p",null,"Most, if not all, of the typing files had been pulled in from NuGet and are part of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped"}),"DefinitelyTyped"),' project on GitHub. Unfortunately, at present, when TypeScript NuGet packages are added they are added without the "TypeScriptCompile" Build Action. I was going to post an issue there and ask if it\'s possible for NuGet packages to pull in typings files as "TypeScriptCompile" from the off - fortunately a chap called Natan Vivo ',(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped/issues/1138"}),"already has"),"."),(0,a.kt)("p",null,"So until this issue is resolved it's probably a good idea to check that your TypeScript files are set to the correct Build Action in your project. And every time you upgrade your TypeScript NuGet packages double check that you still have the correct Build Action afterwards (and to get Intellisense working in VS 2012 at least you'll need to close and re-open the solution as well)."))}d.isMDXComponent=!0},61419:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"rolling-your-own-confirm-mechanism",title:"Rolling your own confirm mechanism using Promises and jQuery UI",authors:"johnnyreilly",tags:["jQuery UI"],hide_table_of_contents:!1},s=void 0,l={permalink:"/rolling-your-own-confirm-mechanism",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-11-26-rolling-your-own-confirm-mechanism/index.md",source:"@site/blog/2013-11-26-rolling-your-own-confirm-mechanism/index.md",title:"Rolling your own confirm mechanism using Promises and jQuery UI",description:"We're here to talk about the confirm dialog. Or, more specifically, how we can make our own confirm dialog.",date:"2013-11-26T00:00:00.000Z",formattedDate:"November 26, 2013",tags:[{label:"jQuery UI",permalink:"/tags/j-query-ui"}],readingTime:4.33,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"rolling-your-own-confirm-mechanism",title:"Rolling your own confirm mechanism using Promises and jQuery UI",authors:"johnnyreilly",tags:["jQuery UI"],hide_table_of_contents:!1},prevItem:{title:"Simple fading in and out using CSS transitions and classes",permalink:"/simple-fading-in-and-out-using-css-transitions"},nextItem:{title:"TypeScript: Don't forget Build Action for Implicit Referencing...",permalink:"/typescript-dont-forget-build-action-for-implicit-referencing"}},p={authorsImageUrls:[void 0]},u=[{value:"Making confirm 2.0",id:"making-confirm-20",level:2},{value:"Going from <code>window.confirm</code> to <code>confirmDialog</code>",id:"going-from-windowconfirm-to-confirmdialog",level:2},{value:"And finally a demo...",id:"and-finally-a-demo",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"We're here to talk about the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/API/Window.confirm"}),"confirm")," dialog. Or, more specifically, how we can make our own confirm dialog."),(0,a.kt)("p",null,"JavaScript in the browser has had the ",(0,a.kt)("inlineCode",{parentName:"p"},"window.confirm"),' method for the longest time. This method takes a string as an argument and displays it in the form of a dialog, giving the user the option to click on either an "OK" or a "Cancel" button. If the user clicks "OK" the method returns ',(0,a.kt)("inlineCode",{parentName:"p"},"true"),', if the user clicks "Cancel" the method returns ',(0,a.kt)("inlineCode",{parentName:"p"},"false"),"."),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"window.confirm")," is wonderful in one way - it has a simple API which is easy to grok. But regardless of the browser, ",(0,a.kt)("inlineCode",{parentName:"p"},"window.confirm")," is always as ugly as sin. Look at the first picture in this blog post; hideous. Or, put more dispassionately, it's not terribly configurable; want to change the button text? You can't. Want to change the styling of the dialog? You can't. You get the picture."),(0,a.kt)("h2",o({},{id:"making-confirm-20"}),"Making confirm 2.0"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"http://jqueryui.com/dialog/#modal-confirmation"}),"jQuery UI's dialog")," has been around for a long time. I've been using it for a long time. But, if you look at the API, you'll see it works in a very different way to ",(0,a.kt)("inlineCode",{parentName:"p"},"window.confirm")," ","-"," basically it's all about the callbacks. My intention was to create a mechanism which allowed me to prompt the user with jQuery UI's tried and tested dialog, but to expose it in a way that embraced the simplicity of the ",(0,a.kt)("inlineCode",{parentName:"p"},"window.confirm")," API."),(0,a.kt)("p",null,"How to do this? Promises! To quote ",(0,a.kt)("a",o({parentName:"p"},{href:"http://martinfowler.com/bliki/JavascriptPromise.html"}),"Martin Fowler")," (makes you look smart when you do that):"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("em",{parentName:"p"},'"In Javascript, promises are objects which represent the pending result of an asynchronous operation. You can use these to schedule further activity after the asynchronous operation has completed by supplying a callback."'))),(0,a.kt)("p",null,'When we show our dialog we are in asynchronous land; waiting for the user to click "OK" or "Cancel". When they do, we need to act on their response. So if our custom confirm dialog returns a promise of a boolean (',(0,a.kt)("inlineCode",{parentName:"p"},"true"),' when the users click "OK", ',(0,a.kt)("inlineCode",{parentName:"p"},"false")," otherwise) then that should be exactly what we need. I'm going to use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/kriskowal/q"}),"Q")," for promises. (Nothing particularly special about Q - it's one of many ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/promises-aplus/promises-spec/blob/master/implementations/index.md"}),"Promises / A+")," compliant implementations available.)"),(0,a.kt)("p",null,"Here's my custom confirm dialog:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"/**\n * Show a \"confirm\" dialog to the user (using jQuery UI's dialog)\n *\n * @param {string} message The message to display to the user\n * @param {string} okButtonText OPTIONAL - The OK button text, defaults to \"Yes\"\n * @param {string} cancelButtonText OPTIONAL - The Cancel button text, defaults to \"No\"\n * @param {string} title OPTIONAL - The title of the dialog box, defaults to \"Confirm...\"\n * @returns {Q.Promise<boolean>} A promise of a boolean value\n */\nfunction confirmDialog(message, okButtonText, cancelButtonText, title) {\n  okButtonText = okButtonText || 'Yes';\n  cancelButtonText = cancelButtonText || 'No';\n  title = title || 'Confirm...';\n\n  var deferred = Q.defer();\n  $('<div title=\"' + title + '\">' + message + '</div>').dialog({\n    modal: true,\n    buttons: [\n      {\n        // The OK button\n        text: okButtonText,\n        click: function () {\n          // Resolve the promise as true indicating the user clicked \"OK\"\n          deferred.resolve(true);\n          $(this).dialog('close');\n        },\n      },\n      {\n        // The Cancel button\n        text: cancelButtonText,\n        click: function () {\n          $(this).dialog('close');\n        },\n      },\n    ],\n    close: function (event, ui) {\n      // Destroy the jQuery UI dialog and remove it from the DOM\n      $(this).dialog('destroy').remove();\n\n      // If the promise has not yet been resolved (eg the user clicked the close icon)\n      // then resolve the promise as false indicating the user did *not* click \"OK\"\n      if (deferred.promise.isPending()) {\n        deferred.resolve(false);\n      }\n    },\n  });\n\n  return deferred.promise;\n}\n")),(0,a.kt)("p",null,"What's happening here? Well first of all, if ",(0,a.kt)("inlineCode",{parentName:"p"},"okButtonText"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"cancelButtonText")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"title")," have false-y values then they are initialised to defaults. Next, we create a deferred object with Q. Then we create our modal dialog using jQuery UI. There's a few things worth noting about this:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"We're not dependent on the dialog markup being in our HTML from the off. We create a brand new element which gets added to the DOM when the dialog is created. (I draw attention to this as the jQuery UI dialog documentation doesn't mention that you can use this approach - and frankly I prefer it.)"),(0,a.kt)("li",{parentName:"ul"},'The "OK" and "Cancel" buttons are initialised with the string values stored in ',(0,a.kt)("inlineCode",{parentName:"li"},"okButtonText")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"cancelButtonText"),'. So by default, "Yes" and "No".'),(0,a.kt)("li",{parentName:"ul"},'If the user clicks the "OK" button then the promise is resolved with a value of ',(0,a.kt)("inlineCode",{parentName:"li"},"true"),"."),(0,a.kt)("li",{parentName:"ul"},"If the dialog closes and the promise has not been resolved then the promise is resolved with a value of ",(0,a.kt)("inlineCode",{parentName:"li"},"false"),'. This covers people clicking on the "Cancel" button as well as closing the dialog through other means.')),(0,a.kt)("p",null,"Finally we return the promise from our deferred object."),(0,a.kt)("h2",o({},{id:"going-from-windowconfirm-to-confirmdialog"}),"Going from ",(0,a.kt)("inlineCode",{parentName:"h2"},"window.confirm")," to ",(0,a.kt)("inlineCode",{parentName:"h2"},"confirmDialog")),(0,a.kt)("p",null,"It's very simple to move from using ",(0,a.kt)("inlineCode",{parentName:"p"},"window.confirm")," to ",(0,a.kt)("inlineCode",{parentName:"p"},"confirmDialog"),". Take this example:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"if (window.confirm('Are you sure?')) {\n  // Do something\n}\n")),(0,a.kt)("p",null,"Becomes:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"confirmDialog('Are you sure?').then(function (confirmed) {\n  if (confirmed) {\n    // Do something\n  }\n});\n")),(0,a.kt)("p",null,"There's no more to it than that."),(0,a.kt)("h2",o({},{id:"and-finally-a-demo"}),"And finally a demo..."),(0,a.kt)("p",null,'With the JSFiddle below you can create your own custom dialogs and see the result of clicking on either the "OK" or "Cancel" buttons.'),(0,a.kt)("iframe",{width:"100%",height:"500",src:"https://jsfiddle.net/johnny_reilly/ARWL5/embedded/result,js,html,css",allowFullScreen:"allowFullScreen",frameBorder:"0"}))}d.isMDXComponent=!0},75678:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"simple-fading-in-and-out-using-css-transitions",title:"Simple fading in and out using CSS transitions and classes",authors:"johnnyreilly",tags:["CSS"],hide_table_of_contents:!1},s=void 0,l={permalink:"/simple-fading-in-and-out-using-css-transitions",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-12-04-simple-fading-in-and-out-using-css-transitions/index.md",source:"@site/blog/2013-12-04-simple-fading-in-and-out-using-css-transitions/index.md",title:"Simple fading in and out using CSS transitions and classes",description:"Caveat emptor folks... Let me start off by putting my hands up and saying I am no expert on CSS. And furthermore let me say that this blog post is essentially the distillation of a heady session of googling on the topic of CSS transitions. The credit for the technique detailed here belongs to many others, I'm just documenting it for my own benefit (and for anyone who stumbles upon this).",date:"2013-12-04T00:00:00.000Z",formattedDate:"December 4, 2013",tags:[{label:"CSS",permalink:"/tags/css"}],readingTime:3.64,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"simple-fading-in-and-out-using-css-transitions",title:"Simple fading in and out using CSS transitions and classes",authors:"johnnyreilly",tags:["CSS"],hide_table_of_contents:!1},prevItem:{title:"NuGet and WebMatrix: How to install a specific version of a package",permalink:"/nuget-and-webmatrix-how-to-install"},nextItem:{title:"Rolling your own confirm mechanism using Promises and jQuery UI",permalink:"/rolling-your-own-confirm-mechanism"}},p={authorsImageUrls:[void 0]},u=[{value:"What do we want to do?",id:"what-do-we-want-to-do",level:2},{value:"I&#39;m sold - let&#39;s do it!",id:"im-sold---lets-do-it",level:2},{value:"Now, a warning...",id:"now-a-warning",level:2},{value:"A halfway there solution to the <code>display: none</code>",id:"a-halfway-there-solution-to-the-display-none",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Caveat emptor folks... Let me start off by putting my hands up and saying I am no expert on CSS. And furthermore let me say that this blog post is essentially the distillation of a heady session of googling on the topic of CSS transitions. The credit for the technique detailed here belongs to many others, I'm just documenting it for my own benefit (and for anyone who stumbles upon this)."),(0,a.kt)("h2",o({},{id:"what-do-we-want-to-do"}),"What do we want to do?"),(0,a.kt)("p",null,"Most web developers have likely reached at some point for jQuery's ",(0,a.kt)("a",o({parentName:"p"},{href:"http://api.jquery.com/fadeIn/"}),(0,a.kt)("inlineCode",{parentName:"a"},"fadeIn"))," and ",(0,a.kt)("a",o({parentName:"p"},{href:"http://api.jquery.com/fadeOut/"}),(0,a.kt)("inlineCode",{parentName:"a"},"fadeOut"))," awesomeness. What could be cooler than fading in or out your UI, right?"),(0,a.kt)("p",null,"Behind the scenes of ",(0,a.kt)("inlineCode",{parentName:"p"},"fadeIn")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"fadeOut")," JavaScript is doing an awful lot of work to create that animation. And in our modern world we simply don't need to do that work anymore; it's gone native and is covered by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/Guide/CSS/Using_CSS_transitions"}),"CSS transitions"),"."),(0,a.kt)("p",null,'Added to the "',(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/George_Mallory"}),"because it's there"),'" reason for using CSS transitions to do fading there is a more important reason; let me quote ',(0,a.kt)("a",o({parentName:"p"},{href:"http://www.html5rocks.com/en/tutorials/speed/html5/#toc-css3-transitions"}),"HTML5 rocks"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},'"',(0,a.kt)("em",{parentName:"p"},"CSS Transitions make style animation trivial for everyone, but they also are a smart performance feature. Because a CSS transition is managed by the browser, the fidelity of its animation can be greatly improved, and in many cases hardware accelerated. Currently WebKit (Chrome, Safari, iOS) have hardware accelerated CSS transforms, but it's coming quickly to other browsers and platforms."),'"')),(0,a.kt)("p",null,"Added to this, if you have mobile users then the usage of native functionality (as opposed to doing it manually in JavaScript) actually saves battery life."),(0,a.kt)("h2",o({},{id:"im-sold---lets-do-it"}),"I'm sold - let's do it!"),(0,a.kt)("p",null,"This is the CSS we'll need:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-css"}),".fader {\n  -moz-transition: opacity 0.7s linear;\n  -o-transition: opacity 0.7s linear;\n  -webkit-transition: opacity 0.7s linear;\n  transition: opacity 0.7s linear;\n}\n\n.fader.fadedOut {\n  opacity: 0;\n}\n")),(0,a.kt)("p",null,"Note we have 2 CSS classes:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"fader")," ","-"," if this class is applied to an element then when the opacity of that element is changed it will be an animated change. The duration of the transition and the timing function used are customisable - in this case it takes 0.7 seconds and is linear."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"fadedOut")," ","-"," when used in conjunction with ",(0,a.kt)("inlineCode",{parentName:"li"},"fader")," this class creates a fading in or fading out effect as it is removed or applied respectively. (This relies upon the default value of opacity being 1.)")),(0,a.kt)("p",null,"Let's see it in action:"),(0,a.kt)("iframe",{width:"100%",height:"200",src:"https://jsfiddle.net/johnny_reilly/86amq/embedded/result,js,html,css",allowFullScreen:"allowFullScreen",frameBorder:"0"}),(0,a.kt)("p",null,"It goes without saying that one day in the not too distant future (I hope) we'll be able to leave behind the horrible world of vendor prefixes. Then we'll be down to just the single ",(0,a.kt)("inlineCode",{parentName:"p"},"transition")," statement. One day..."),(0,a.kt)("h2",o({},{id:"now-a-warning"}),"Now, a warning..."),(0,a.kt)("p",null,"Unfortunately the technique detailed above differs from ",(0,a.kt)("a",o({parentName:"p"},{href:"http://api.jquery.com/fadeIn/"}),(0,a.kt)("inlineCode",{parentName:"a"},"fadeIn"))," and ",(0,a.kt)("a",o({parentName:"p"},{href:"http://api.jquery.com/fadeOut/"}),(0,a.kt)("inlineCode",{parentName:"a"},"fadeOut"))," in one important way. When the ",(0,a.kt)("inlineCode",{parentName:"p"},"fadeOut")," animation completes it sets removes the element from the flow of the DOM using ",(0,a.kt)("inlineCode",{parentName:"p"},"display: none"),". However, display is not a property that can be animated and so you can't include this in your CSS transition. If removing the element from the flow of the DOM is something you need then you'll need to bear this in mind. If anyone has any suggestions for an nice way to approach this I'd love to hear from you."),(0,a.kt)("h2",o({},{id:"a-halfway-there-solution-to-the-display-none"}),"A halfway there solution to the ",(0,a.kt)("inlineCode",{parentName:"h2"},"display: none")),(0,a.kt)("p",null,"Andrew Davey tweeted me the suggestion below:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/johnny_reilly"}),"@johnny_reilly")," Yep, transitions are sweet. You could use the transitionend event to remove the element from the DOM ",(0,a.kt)("a",o({parentName:"p"},{href:"http://t.co/Q1oWy3g8Lp"}),"http://t.co/Q1oWy3g8Lp")),(0,a.kt)("p",{parentName:"blockquote"},"\u2014 Andrew Davey (@andrewdavey) ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/andrewdavey/statuses/408545283606212608"}),"December 5, 2013"))),(0,a.kt)("script",{async:"",src:"//platform.twitter.com/widgets.js",charSet:"utf-8"}),(0,a.kt)("p",null,"So I thought I'd give it a go. However, whilst we've a ",(0,a.kt)("inlineCode",{parentName:"p"},"transitionend")," event to play with we don't have a corresponding ",(0,a.kt)("inlineCode",{parentName:"p"},"transitionstart")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"transitionbegin"),". So I tried this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"$('#showHideButton').click(function () {\n  var $alertDiv = $('#alertDiv');\n  if ($alertDiv.hasClass('fadedOut')) {\n    $alertDiv.removeClass('fadedOut').css('display', '');\n  } else {\n    $('#alertDiv').addClass('fadedOut');\n  }\n});\n\n$(document).on(\n  'webkitTransitionEnd transitionend oTransitionEnd',\n  '.fader',\n  function (evnt) {\n    var $faded = $(evnt.target);\n    if ($faded.hasClass('fadedOut')) {\n      $faded.css('display', 'none');\n    }\n  }\n);\n")),(0,a.kt)("p",null,"Essentially, on the ",(0,a.kt)("inlineCode",{parentName:"p"},"transitionend")," event ",(0,a.kt)("inlineCode",{parentName:"p"},"display: none")," is applied to the element in question. Groovy. In the absence of a ",(0,a.kt)("inlineCode",{parentName:"p"},"transitionstart")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"transitionbegin"),", when removing the ",(0,a.kt)("inlineCode",{parentName:"p"},"fadeOut")," class I'm first manually clearing out the ",(0,a.kt)("inlineCode",{parentName:"p"},"display: none"),". Whilst this works in terms of adding it back into the flow of the DOM it takes away all the ",(0,a.kt)("inlineCode",{parentName:"p"},"fadeIn")," gorgeousness. So it's not quite the fully featured solution you might hope for. But it's a start."))}d.isMDXComponent=!0},47222:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"nuget-and-webmatrix-how-to-install",title:"NuGet and WebMatrix: How to install a specific version of a package",authors:"johnnyreilly",tags:["jquery","NuGet"],hide_table_of_contents:!1},s=void 0,l={permalink:"/nuget-and-webmatrix-how-to-install",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2013-12-13-nuget-and-webmatrix-how-to-install/index.md",source:"@site/blog/2013-12-13-nuget-and-webmatrix-how-to-install/index.md",title:"NuGet and WebMatrix: How to install a specific version of a package",description:"I've recently been experimenting with WebMatrix. If you haven't heard of it, WebMatrix is Microsoft's \"free, lightweight, cloud-connected web development tool\". All marketing aside, it's pretty cool. You can whip up a site in next to no time, it has source control, publishing abilities, intellisense. Much good stuff. And one thing it has, that I genuinely hadn't expected is NuGet. Brilliant!",date:"2013-12-13T00:00:00.000Z",formattedDate:"December 13, 2013",tags:[{label:"jquery",permalink:"/tags/jquery"},{label:"NuGet",permalink:"/tags/nu-get"}],readingTime:2.38,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"nuget-and-webmatrix-how-to-install",title:"NuGet and WebMatrix: How to install a specific version of a package",authors:"johnnyreilly",tags:["jquery","NuGet"],hide_table_of_contents:!1},prevItem:{title:"Upgrading to TypeScript 0.9.5 - A Personal Memoir",permalink:"/upgrading-to-typescript-095-personal"},nextItem:{title:"Simple fading in and out using CSS transitions and classes",permalink:"/simple-fading-in-and-out-using-css-transitions"}},p={authorsImageUrls:[void 0]},u=[{value:"NuGet, by hook or by crook",id:"nuget-by-hook-or-by-crook",level:2},{value:"Now for bonus points",id:"now-for-bonus-points",level:2},{value:"Rounding off",id:"rounding-off",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I've recently been experimenting with WebMatrix. If you haven't heard of it, WebMatrix is Microsoft's ",(0,a.kt)("em",{parentName:"p"},(0,a.kt)("a",o({parentName:"em"},{href:"http://www.microsoft.com/web/webmatrix/"}),'"free, lightweight, cloud-connected web development tool"')),". All marketing aside, it's pretty cool. You can whip up a site in next to no time, it has source control, publishing abilities, intellisense. Much good stuff. And one thing it has, that I genuinely hadn't expected is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.nuget.org/"}),"NuGet"),". Brilliant!"),(0,a.kt)("p",null,"But like any free product there are disadvantages. As a long time Visual Studio user I've become very used to the power of the NuGet command line. I've been spoiled. You don't have this in WebMatrix. You have a nice UI."),(0,a.kt)("p",null,"Looks great right? However, if you want to install a specific version of a NuGet package... well let's see what happens..."),(0,a.kt)("p",null,"As you're probably aware jQuery currently exists in 2 branches; the 1.10.x branch which supports IE 6-8 and the 2.0.x branch which doesn't. However there is only 1 jQuery inside NuGet. Let's click on install and see if we can select a specific version."),(0,a.kt)("p",null,"Hmmm.... As you can see it's 2.0.3 or bust. We can't select a specific version; we're forced to go with the latest and greatest which is a problem if you need to support IE 6-8. So the obvious strategy if you're in this particular camp is to forego NuGet entirely. Go old school. And we could. But let's say we want to keep using NuGet, mindful that a little while down the road we'll be ready to do that upgrade. Can it be done? Let's find out."),(0,a.kt)("h2",o({},{id:"nuget-by-hook-or-by-crook"}),"NuGet, by hook or by crook"),(0,a.kt)("p",null,"I've created a new site in WebMatrix using the Empty Site template."),(0,a.kt)("p",null,"Lovely."),(0,a.kt)("p",null,"Now to get me some jQuery 1.10.2 goodness. To the console Batman! We've already got the NuGet command line installed (if you haven't you could get it from ",(0,a.kt)("a",o({parentName:"p"},{href:"http://nuget.org/nuget.exe"}),"here"),") and so we follow these steps:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"At the ",(0,a.kt)("inlineCode",{parentName:"li"},"C:\\")," prompt we enter ",(0,a.kt)("inlineCode",{parentName:"li"},"nuget install jQuery -Version 1.10.2")," and down comes jQuery 1.10.2."),(0,a.kt)("li",{parentName:"ul"},"We move ",(0,a.kt)("inlineCode",{parentName:"li"},"C:\\jQuery.1.10.2")," to ",(0,a.kt)("inlineCode",{parentName:"li"},"C:\\Users\\me\\Documents\\My Web Sites\\Empty Site\\App_Data\\packages\\jQuery.1.10.2"),"."),(0,a.kt)("li",{parentName:"ul"},"Then we delete the ",(0,a.kt)("inlineCode",{parentName:"li"},"C:\\Users\\me\\Documents\\My Web Sites\\Empty Site\\App_Data\\packages\\jQuery.1.10.2\\Tools")," subfolder."),(0,a.kt)("li",{parentName:"ul"},"We move ",(0,a.kt)("inlineCode",{parentName:"li"},"C:\\Users\\me\\Documents\\My Web Sites\\Empty Site\\App_Data\\packages\\jQuery.1.10.2\\Content\\Scripts")," to ",(0,a.kt)("inlineCode",{parentName:"li"},"C:\\Users\\me\\Documents\\My Web Sites\\Empty Site\\Scripts"),"."),(0,a.kt)("li",{parentName:"ul"},"And finally we delete the ",(0,a.kt)("inlineCode",{parentName:"li"},"C:\\Users\\me\\Documents\\My Web Sites\\Empty Site\\App_Data\\packages\\jQuery.1.10.2\\Content")," folder.")),(0,a.kt)("p",null,'If we go to NuGet and select updates you\'ll see that jQuery is now considered "installed" and an update is available. So, in short, our plan worked - yay!'),(0,a.kt)("h2",o({},{id:"now-for-bonus-points"}),"Now for bonus points"),(0,a.kt)("p",null,'Just to prove that you can upgrade using the WebMatrix tooling following our manual install let\'s do it. Click "Update", then "Yes" and finally "I Accept" to the EULA. You\'ll now see we\'re now on jQuery 2.0.3.'),(0,a.kt)("h2",o({},{id:"rounding-off"}),"Rounding off"),(0,a.kt)("p",null,"In my example I'm only looking at a simple JavaScript library. But the same principal should be able to be applied to any NuGet package as far as I'm aware. Hope that helps!"))}d.isMDXComponent=!0},7503:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"upgrading-to-typescript-095-personal",title:"Upgrading to TypeScript 0.9.5 - A Personal Memoir",authors:"johnnyreilly",tags:["typescript"],hide_table_of_contents:!1},s=void 0,l={permalink:"/upgrading-to-typescript-095-personal",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-01-09-upgrading-to-typescript-095-personal/index.md",source:"@site/blog/2014-01-09-upgrading-to-typescript-095-personal/index.md",title:"Upgrading to TypeScript 0.9.5 - A Personal Memoir",description:"I recently made the step to upgrade from TypeScript 0.9.1.1 to 0.9.5. To my surprise this process was rather painful and certainly not an unalloyed pleasure. Since I'm now on the other side, so to speak, I thought I'd share my experience and cast back a rope bridge to those about to journey over the abyss.",date:"2014-01-09T00:00:00.000Z",formattedDate:"January 9, 2014",tags:[{label:"typescript",permalink:"/tags/typescript"}],readingTime:7.725,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"upgrading-to-typescript-095-personal",title:"Upgrading to TypeScript 0.9.5 - A Personal Memoir",authors:"johnnyreilly",tags:["typescript"],hide_table_of_contents:!1},prevItem:{title:"Integration Testing with Entity Framework and Snapshot Backups",permalink:"/integration-testing-with-entity"},nextItem:{title:"NuGet and WebMatrix: How to install a specific version of a package",permalink:"/nuget-and-webmatrix-how-to-install"}},p={authorsImageUrls:[void 0]},u=[{value:"TL;DR",id:"tldr",level:2},{value:"Upgrading the Plugin",id:"upgrading-the-plugin",level:2},{value:"Declaration Merging is dead... Sort of",id:"declaration-merging-is-dead-sort-of",level:2},{value:"The Promised Land",id:"the-promised-land",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I recently made the step to upgrade from TypeScript 0.9.1.1 to 0.9.5. To my surprise this process was rather painful and certainly not an unalloyed pleasure. Since I'm now on the other side, so to speak, I thought I'd share my experience and cast back a rope bridge to those about to journey over the abyss."),(0,a.kt)("h2",o({},{id:"tldr"}),"TL;DR"),(0,a.kt)("p",null,"TypeScript 0.9.5 is worth making the jump to. However, if you are using Visual Studio (as I would guess many are) then you should be aware of a number of problems with the TypeScript Visual Studio tooling for TS 0.9.5. These problems can be worked around if you follow the instructions in this post."),(0,a.kt)("h2",o({},{id:"upgrading-the-plugin"}),"Upgrading the Plugin"),(0,a.kt)("p",null,"At home I upgraded the moment TS 0.9.5 was released. This allowed me to help with migrating the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped"}),"Definitely Typed typings")," over from 0.9.1.1. And allowed me to give TS 0.9.5 a little test drive. However, I deliberately held off performing the upgrade at work until I knew that all the Definitely Typed typings had been upgraded. This was completed ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped/pull/1385"}),"by the end of 2013"),". So in the new year it seemed a good time to make the move."),(0,a.kt)("p",null,"If, like me, you are using TypeScript inside Visual Studio then you'd imagine it's as simple as closing down VS, uninstalling TypeScript 0.9.1.1 from Programs and Features and then installing the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.typescriptlang.org/#Download"}),"new plugin"),". And it is if you are running IE 10 or IE 11 on your Windows machine. If you are running a lower IE version then there is a problem."),(0,a.kt)("p",null,"Regrettably, the TypeScript 0.9.5 plugin installer has a dependency on IE 10. Fortunately TypeScript itself has no dependency on IE 10 at all (and why would it?). This dependency appears to have been a mistake. I ",(0,a.kt)("a",o({parentName:"p"},{href:"https://typescript.codeplex.com/workitem/1975"}),"raised it as an issue")," and the TS team have said that this will be resolved in the next major release."),(0,a.kt)("p",null,"Happily there is a workaround if you're running IE 9 or lower which has been noted in the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.com/b/typescript/archive/2013/12/05/announcing-typescript-0-9-5.aspx"}),"comments underneath the TS 0.9.5 release blog post"),". All you do is set the ",(0,a.kt)("inlineCode",{parentName:"p"},"HKEY_LOCAL_MACHINE\\SOFTWARE\\Wow6432Node\\Microsoft\\Internet Explorer\\svcVersion")," registry key value to ",(0,a.kt)("inlineCode",{parentName:"p"},"10.0.9200.16384")," for the duration of the install."),(0,a.kt)("p",null,"First hurdle jumped, the upgrade continues simple enough. Then the fun starts..."),(0,a.kt)("h2",o({},{id:"declaration-merging-is-dead-sort-of"}),"Declaration Merging is dead... Sort of"),(0,a.kt)("p",null,"Having upgraded my plugin I opened up the project I'm working on in Visual Studio. I used NuGet to upgrade all the Definitely Typed packages to the latest (TS 0.9.5) versions. Then I tried, and failed, to compile. It was the the most obscure error I've seen in a while:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"VSTSC : tsc.js(37574, 25) Microsoft JScript runtime error : Unable to get value of the property 'wrapsSomeTypeParameter': object is null or undefined\n")),(0,a.kt)("p",null,"As you can see there was no indication where in my code the problem was being caused. Fortunately someone had already suffered this particular problem and logged an issue ",(0,a.kt)("a",o({parentName:"p"},{href:"https://typescript.codeplex.com/workitem/1995"}),"here"),". Digging through the comments I found a common theme; everyone experiencing the problem was using the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped/blob/master/q/Q.d.ts"}),"Q typings"),". So what's up with that?"),(0,a.kt)("p",null,"Strangely, if you directly referenced the Q typings everything was okay - which is how the Definitely Typed tests came to pass in the first place. But if you wanted to make use of these typings with implicit referencing (in Visual Studio since TS 0.9.1, all TypeScript files in a project are considered to be referencing each other) - well it doesn't work."),(0,a.kt)("p",null,"I decided to take a look at the Q typings at this point to see what was so upsetting about them. The one thing that was obvious was that these typings make use of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.com/b/typescript/archive/2013/06/18/announcing-typescript-0-9.aspx"}),"Declaration Merging"),". And this made them slightly different to most of the other typing libraries that I was using. So I decided to refactor the Q typings to use the more interface driven approach the other typing libraries used in the hope that might resolve the issue."),(0,a.kt)("p",null,"Roughly speaking I went from:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"declare function Q<T>(promise: Q.IPromise<T>): Q.Promise<T>;\ndeclare function Q<T>(promise: JQueryPromise<T>): Q.Promise<T>;\ndeclare function Q<T>(value: T): Q.Promise<T>;\n\ndeclare module Q {\n  //\u2026 functions etc in here\n}\n\ndeclare module 'q' {\n  export = Q;\n}\n")),(0,a.kt)("p",null,"To:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),'interface QIPromise<T> {\n    //\u2026 functions etc in here\n}\n\ninterface QDeferred<T> {\n    //\u2026 functions etc in here\n}\n\ninterface QPromise<T> {\n    //\u2026 functions etc in here\n}\n\ninterface QPromiseState<T> {\n    //\u2026 functions etc in here\n}\n\ninterface QStatic {\n\n    <t>(promise: QIPromise<T>): QPromise<T>;\n    <t>(promise: JQueryPromise<T>): QPromise<T>;\n    <t>(value: T): QPromise<T>;\n\n    //\u2026 other functions etc continue here\n}\n\ndeclare module "q" {\n    export = Q;\n}\ndeclare var Q: QStatic;\n</t></t></t>\n')),(0,a.kt)("p",null,"And that fixed the obscure 'wrapsSomeTypeParameter' error. The full source code of these amended typings can be found as a GitHub Repo ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/Q-TS-0.9.5-WorkAround"}),"here")," in case you want to use it yourself. (I did originally consider adding this to Definitely Typed but opted not to in the end - ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped/pull/1497"}),"see discussion on GitHub"),".)"),(0,a.kt)("h2",o({},{id:"the-promised-land"}),"The Promised Land"),(0,a.kt)("p",null,"You're there. You've upgraded to the new plugin and the new typings. All is compiling as it should and the language service is working as well. Was it worth it? I think yes, for the following reasons:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"TS 0.9.5 compiles faster, and hogs less memory."),(0,a.kt)("li",{parentName:"ol"},"When we compiled with TS 0.9.5 we found there were a couple of bugs in our codebase which the tightened up compiler was now detecting. Essentially where we'd assumed types were flowing through to functions there were a couple of occasions with TS 0.9.1.1 where they weren't. Where we'd assumed we had a type of ",(0,a.kt)("inlineCode",{parentName:"li"},"T")," available in a function whereas it was actually a type of ",(0,a.kt)("inlineCode",{parentName:"li"},"any"),". I was really surprised that this was the case since we were already making use of ",(0,a.kt)("inlineCode",{parentName:"li"},"noImplicitAny")," compiler flag in our project. So where a type had changed and a retired property was being referenced TS 0.9.5 picked up an error that TS 0.9.1.1 had not. Good catch!"),(0,a.kt)("li",{parentName:"ol"},"And finally (and I know these are really minor), the compiled JS is a little different now. Firstly, the compiled JS features all of TypeScript comments in the positions that you might hope for. Previously it seemed that about 75% came along for the ride and ended up in some strange locations sometimes. Secondly, enums are treated differently during compilation now - where it makes sense the actual backing value of an enum is used rather than going through the JavaScript construct. So it's a bit like a ",(0,a.kt)("inlineCode",{parentName:"li"},"const")," I guess - presumably this allows JavaScript engines to optimise a little more.")),(0,a.kt)("p",null,"I hope I haven't put you off with this post. I think TypeScript 0.9.5 is well worth making the leap for - and hopefully by reading this you'll have saved yourself from a few of the rough edges."))}d.isMDXComponent=!0},76689:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"integration-testing-with-entity",title:"Integration Testing with Entity Framework and Snapshot Backups",authors:"johnnyreilly",tags:["Database Snapshots","Integration Testing","SQL Server"],hide_table_of_contents:!1},s=void 0,l={permalink:"/integration-testing-with-entity",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-01-24-integration-testing-with-entity/index.md",source:"@site/blog/2014-01-24-integration-testing-with-entity/index.md",title:"Integration Testing with Entity Framework and Snapshot Backups",description:"I've written before about how unit testing Entity Framework is a contentious and sometimes pointless activity. The TL;DR is that LINQ-to-Objects != Linq-to-Entities and so if you want some useful tests around your data tier then integration tests that actually hit a database are what you want.",date:"2014-01-24T00:00:00.000Z",formattedDate:"January 24, 2014",tags:[{label:"Database Snapshots",permalink:"/tags/database-snapshots"},{label:"Integration Testing",permalink:"/tags/integration-testing"},{label:"SQL Server",permalink:"/tags/sql-server"}],readingTime:14.39,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"integration-testing-with-entity",title:"Integration Testing with Entity Framework and Snapshot Backups",authors:"johnnyreilly",tags:["Database Snapshots","Integration Testing","SQL Server"],hide_table_of_contents:!1},prevItem:{title:"WPF and Mystic Meg or Playing Futurologist",permalink:"/wpf-and-mystic-meg-or-playing"},nextItem:{title:"Upgrading to TypeScript 0.9.5 - A Personal Memoir",permalink:"/upgrading-to-typescript-095-personal"}},p={authorsImageUrls:[void 0]},u=[{value:"Our Mission",id:"our-mission",level:2},{value:"We need a database",id:"we-need-a-database",level:2},{value:"Assemble me your finest DbContext",id:"assemble-me-your-finest-dbcontext",level:2},{value:"Let There be Repositories!",id:"let-there-be-repositories",level:2},{value:"And Now Let&#39;s Start Integration Testing!",id:"and-now-lets-start-integration-testing",level:2},{value:"Database Snapshotting Time",id:"database-snapshotting-time",level:2},{value:"Prove it!",id:"prove-it",level:2},{value:"Rounding off",id:"rounding-off",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I've written before about how unit testing ",(0,a.kt)("a",o({parentName:"p"},{href:"/unit-testing-and-entity-framework-filth"}),"Entity Framework is a contentious and sometimes pointless activity"),". The TL;DR is that LINQ-to-Objects != Linq-to-Entities and so if you want some useful tests around your data tier then integration tests that actually hit a database are what you want."),(0,a.kt)("p",null,"However hitting an actual database is has serious implications. For a start you need a database server and you need a database. But the real issue lies around cleanup. When you write a test that amends data in the database you need the test to clean up after itself. If it doesn't then the next test that runs may trip over the amended data and that's your test pack instantly useless."),(0,a.kt)("p",null,"What you want is a way to wipe the slate clean - to return the database back to the state that it was in before your test ran. Kind of like a database restore - except that would be slow. And this is where ",(0,a.kt)("a",o({parentName:"p"},{href:"http://technet.microsoft.com/en-us/library/ms189548(v=sql.105).aspx"}),"SQL Server's snapshot backups")," have got your back. To quote MSDN:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"*","Snapshot backups have the following primary benefits:"),(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"},"A backup can be created quickly, typically measured in seconds, with little or no effect on the server."),(0,a.kt)("li",{parentName:"ul"},"A restore operation can be accomplished from a disk backup just as quickly."),(0,a.kt)("li",{parentName:"ul"},"Backup to tape can be accomplished by another host without an effect on the production system."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"A copy of a production database can be created instantly for reporting or testing."))),(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"}))),(0,a.kt)("p",null,"Just the ticket."),(0,a.kt)("h2",o({},{id:"our-mission"}),"Our Mission"),(0,a.kt)("p",null,"In this post I want to go through the process of taking an existing database, pointing Entity Framework at it, setting up some repositories and then creating an integration test pack that uses snapshot backups to cleanup after each test runs. The code detailed in this post is available in this ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/SnapshotBackupsIntegrationTesting"}),"GitHub repo")," if you want to have a go yourself."),(0,a.kt)("h2",o({},{id:"we-need-a-database"}),"We need a database"),(0,a.kt)("p",null,"You can find a whole assortment of databases ",(0,a.kt)("a",o({parentName:"p"},{href:"https://msftdbprodsamples.codeplex.com/releases"}),"here"),". I'm going to use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://msftdbprodsamples.codeplex.com/wikipage?title=AWLTDocs"}),"AdventureWorksLT")," as it's small and simple. So I'll download ",(0,a.kt)("a",o({parentName:"p"},{href:"https://msftdbprodsamples.codeplex.com/downloads/get/478217"}),"this")," and unzip it. I'll drop ",(0,a.kt)("inlineCode",{parentName:"p"},"AdventureWorksLT2008R2_Data/index.mdf")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"AdventureWorksLT2008R2_log.LDF")," in my data folder and attach AdventureWorksLT2008R2 to my database server. And now I have a database."),(0,a.kt)("h2",o({},{id:"assemble-me-your-finest-dbcontext"}),"Assemble me your finest DbContext"),(0,a.kt)("p",null,"Or in English: we want to point Entity Framework at our new shiny database. So let's fire up Visual Studio (I'm using 2013) and create a new solution called \"AdventureWorks\"."),(0,a.kt)("p",null,'To our solution let\'s add a new class library project called "AdventureWorks.EntityFramework". And to that we\'ll add an ADO.NET Entity Data Model which we\'ll call "AdventureWorks.edmx". When the wizard fires up we\'ll use the "Generate from database" option, click Next and select "New Connection". In the dialog we\'ll select our newly attached AdventureWorksLT2008R2 database. We\'ll leave the "save entity connection settings in App.Config" option selected and click Next. I\'m going to use Entity Framework 6.0 - though I think that any version would do. I\'m going to pull in all tables / store procs and views. And now Entity Framework is pointing at my database.'),(0,a.kt)("h2",o({},{id:"let-there-be-repositories"}),"Let There be Repositories!"),(0,a.kt)("p",null,"In the name of testability let's create a new project to house repositories called \"AdventureWorks.Repositories\". I'm going to use ",(0,a.kt)("a",o({parentName:"p"},{href:"http://odetocode.com/about/scott-allen"}),"K. Scott Allen"),"'s fine ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/ff714955.aspx"}),"article on MSDN")," to create a very basic set of repositories wrapped in a unit of work."),(0,a.kt)("p",null,"In my new project I'll add a reference to the ",(0,a.kt)("inlineCode",{parentName:"p"},"AdventureWorks.EntityFramework")," project and create a new ",(0,a.kt)("inlineCode",{parentName:"p"},"IRepository")," interface that looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using System;\nusing System.Linq;\nusing System.Linq.Expressions;\n\nnamespace AdventureWorks.Repositories\n{\n    public interface IRepository<T> where T : class\n    {\n        IQueryable<T> FindAll();\n        IQueryable<T> FindWhere(Expression<Func<T, bool>> predicate);\n        T Add(T newEntity);\n        T Remove(T entity);\n    }\n}\n")),(0,a.kt)("p",null,"And a new ",(0,a.kt)("inlineCode",{parentName:"p"},"IUnitOfWork")," interface that looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using AdventureWorks.EntityFramework;\n\nnamespace AdventureWorks.Repositories\n{\n    public interface IUnitOfWork\n    {\n        public IRepository<ErrorLog> ErrorLogs { get; }\n        public IRepository<Address> Addresses { get; }\n        public IRepository<Customer> Customers { get; }\n        public IRepository<CustomerAddress> CustomerAddresses { get; }\n        public IRepository<Product> Products { get; }\n        public IRepository<ProductCategory> ProductCategories { get; }\n        public IRepository<ProductDescription> ProductDescriptions { get; }\n        public IRepository<ProductModel> ProductModels { get; }\n        public IRepository<ProductModelProductDescription> ProductModelProductDescriptions { get; }\n        public IRepository<SalesOrderDetail> SalesOrderDetails { get; }\n        public IRepository<SalesOrderHeader> SalesOrderHeaders { get; }\n        public IRepository<BuildVersion> BuildVersions { get; }\n\n        void Commit();\n    }\n}\n")),(0,a.kt)("p",null,"Now for the implementation of ",(0,a.kt)("inlineCode",{parentName:"p"},"IRepository"),". For this we'll need a reference to Entity Framework in our project. Then we'll create a class called ",(0,a.kt)("inlineCode",{parentName:"p"},"SqlRepository"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using System;\nusing System.Data.Entity;\nusing System.Linq;\nusing System.Linq.Expressions;\n\nnamespace AdventureWorks.Repositories\n{\n    public class SqlRepository<T> : IRepository<T> where T : class\n    {\n        public SqlRepository(DbContext context)\n        {\n            _dbSet = context.Set<T>();\n        }\n\n        public IQueryable<T> FindAll()\n        {\n            return _dbSet;\n        }\n\n        public IQueryable<T> FindWhere(Expression<Func<T, bool>> predicate)\n        {\n            return _dbSet.Where(predicate);\n        }\n\n        public T Add(T newEntity)\n        {\n            return _dbSet.Add(newEntity);\n        }\n\n        public T Remove(T entity)\n        {\n            return _dbSet.Remove(entity);\n        }\n\n        protected DbSet<T> _dbSet;\n    }\n}\n")),(0,a.kt)("p",null,"And we also need the implementation of ",(0,a.kt)("inlineCode",{parentName:"p"},"IUnitOfWork"),". So we'll create a class called ",(0,a.kt)("inlineCode",{parentName:"p"},"SqlUnitOfWork"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using System;\nusing System.Linq;\nusing System.Data.Entity;\nusing AdventureWorks.EntityFramework;\n\nnamespace AdventureWorks.Repositories\n{\n    public class SqlUnitOfWork : IUnitOfWork\n    {\n        public SqlUnitOfWork()\n        {\n            _context = new AdventureWorksLT2008R2Entities();\n        }\n\n        public IRepository<ErrorLog> ErrorLogs\n        {\n            get\n            {\n                if (_errorLogs == null) _errorLogs = new SqlRepository<ErrorLog>(_context);\n                return _errorLogs;\n            }\n        }\n\n        public IRepository<Address> Addresses\n        {\n            get\n            {\n                if (_addresses == null) _addresses = new SqlRepository<Address>(_context);\n                return _addresses;\n            }\n        }\n\n        public IRepository<Customer> Customers\n        {\n            get\n            {\n                if (_customers == null) _customers = new SqlRepository<Customer>(_context);\n                return _customers;\n            }\n        }\n\n        public IRepository<CustomerAddress> CustomerAddresses\n        {\n            get\n            {\n                if (_customerAddresses == null) _customerAddresses = new SqlRepository<CustomerAddress>(_context);\n                return _customerAddresses;\n            }\n        }\n\n        public IRepository<Product> Products\n        {\n            get\n            {\n                if (_products == null) _products = new SqlRepository<Product>(_context);\n                return _products;\n            }\n        }\n\n        public IRepository<ProductCategory> ProductCategories\n        {\n            get\n            {\n                if (_productCategories == null) _productCategories = new SqlRepository<ProductCategory>(_context);\n                return _productCategories;\n            }\n        }\n\n        public IRepository<ProductDescription> ProductDescriptions\n        {\n            get\n            {\n                if (_productDescriptions == null) _productDescriptions = new SqlRepository<ProductDescription>(_context);\n                return _productDescriptions;\n            }\n        }\n\n        public IRepository<ProductModel> ProductModels\n        {\n            get\n            {\n                if (_productModels == null) _productModels = new SqlRepository<ProductModel>(_context);\n                return _productModels;\n            }\n        }\n\n        public IRepository<ProductModelProductDescription> ProductModelProductDescriptions\n        {\n            get\n            {\n                if (_productModelProductDescriptions == null) _productModelProductDescriptions = new SqlRepository<ProductModelProductDescription>(_context);\n                return _productModelProductDescriptions;\n            }\n        }\n\n        public IRepository<SalesOrderDetail> SalesOrderDetails\n        {\n            get\n            {\n                if (_salesOrderDetails == null) _salesOrderDetails = new SqlRepository<SalesOrderDetail>(_context);\n                return _salesOrderDetails;\n            }\n        }\n\n        public IRepository<SalesOrderHeader> SalesOrderHeaders\n        {\n            get\n            {\n                if (_salesOrderHeaders == null) _salesOrderHeaders = new SqlRepository<SalesOrderHeader>(_context);\n                return _salesOrderHeaders;\n            }\n        }\n\n        public IRepository<BuildVersion> BuildVersions\n        {\n            get\n            {\n                if (_buildVersions == null) _buildVersions = new SqlRepository<BuildVersion>(_context);\n                return _buildVersions;\n            }\n        }\n\n        public void Commit()\n        {\n            _context.SaveChanges();\n        }\n\n        SqlRepository<ErrorLog> _errorLogs = null;\n        SqlRepository<Address> _addresses = null;\n        SqlRepository<Customer> _customers = null;\n        SqlRepository<CustomerAddress> _customerAddresses = null;\n        SqlRepository<Product> _products = null;\n        SqlRepository<ProductCategory> _productCategories = null;\n        SqlRepository<ProductDescription> _productDescriptions = null;\n        SqlRepository<ProductModel> _productModels = null;\n        SqlRepository<ProductModelProductDescription> _productModelProductDescriptions = null;\n        SqlRepository<SalesOrderDetail> _salesOrderDetails = null;\n        SqlRepository<SalesOrderHeader> _salesOrderHeaders = null;\n        SqlRepository<BuildVersion> _buildVersions = null;\n\n        readonly DbContext _context;\n    }\n}\n")),(0,a.kt)("h2",o({},{id:"and-now-lets-start-integration-testing"}),"And Now Let's Start Integration Testing!"),(0,a.kt)("p",null,'Let\'s create a new Unit Test project called "AdventureWorks.Repositories.IntegrationTests". (And just to be clear: this is ',"*","not","*"," a unit test project - it is an ",(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("em",{parentName:"strong"},"integration"))," test project.) We'll add a reference back to our ",(0,a.kt)("inlineCode",{parentName:"p"},"AdventureWorks.Repositories")," project for the repositories and one back to ",(0,a.kt)("inlineCode",{parentName:"p"},"AdventureWorks.EntityFramework")," for our domain models. And finally you'll need a reference to Entity Framework in your IntegrationTest project as well as well."),(0,a.kt)("p",null,"We'll copy across the ",(0,a.kt)("inlineCode",{parentName:"p"},"app.config")," from ",(0,a.kt)("inlineCode",{parentName:"p"},"AdventureWorks.EntityFramework")," to ",(0,a.kt)("inlineCode",{parentName:"p"},"AdventureWorks.Repositories.IntegrationTests")," as it contains the database connection details. It'll look something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<?xml version="1.0" encoding="utf-8"?>\n<configuration>\n    <configSections>\n        <section name="entityFramework" type="System.Data.Entity.Internal.ConfigFile.EntityFrameworkSection, EntityFramework, Version=6.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089" requirePermission="false" />\n        \x3c!-- For more information on Entity Framework configuration, visit http://go.microsoft.com/fwlink/?LinkID=237468 --\x3e\n    </configSections>\n    <connectionStrings>\n        <add name="AdventureWorksLT2008R2Entities"\n             connectionString="metadata=res://*/AdventureWorks.csdl|res://*/AdventureWorks.ssdl|res://*/AdventureWorks.msl;provider=System.Data.SqlClient;provider connection string=&quot;data source=.;initial catalog=AdventureWorksLT2008R2;integrated security=True;MultipleActiveResultSets=True;App=EntityFramework&quot;"\n             providerName="System.Data.EntityClient" />\n    </connectionStrings>\n    <entityFramework>\n        <defaultConnectionFactory type="System.Data.Entity.Infrastructure.SqlConnectionFactory, EntityFramework" />\n        <providers>\n            <provider invariantName="System.Data.SqlClient" type="System.Data.Entity.SqlServer.SqlProviderServices, EntityFramework.SqlServer" />\n        </providers>\n    </entityFramework>\n</configuration>\n')),(0,a.kt)("p",null,"Now we're ready for a test. We'll add ourselves a class called ",(0,a.kt)("inlineCode",{parentName:"p"},"BuildVersionTests"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Linq;\nusing System.Linq.Expressions;\nusing Microsoft.VisualStudio.TestTools.UnitTesting;\n\nnamespace AdventureWorks.Repositories.IntegrationTests\n{\n    [TestClass]\n    public class BuildVersionTests\n    {\n        [TestMethod]\n        public void BuildVersions_should_return_the_correct_version_information()\n        {\n            // Arrange\n            var uow = new SqlUnitOfWork();\n\n            // Act\n            var buildVersions = uow.BuildVersions.FindAll().ToList();\n\n            // Assert\n            Assert.AreEqual(1, buildVersions.Count);\n            Assert.AreEqual("10.00.80404.00", buildVersions[0].Database_Version);\n            Assert.AreEqual(new DateTime(2008, 4, 4), buildVersions[0].ModifiedDate);\n            Assert.AreEqual(1, buildVersions[0].SystemInformationID);\n            Assert.AreEqual(new DateTime(2008, 4, 4), buildVersions[0].VersionDate);\n        }\n    }\n}\n')),(0,a.kt)("p",null,"This is as simple as it gets - our test creates a new unit of work and queries the ",(0,a.kt)("inlineCode",{parentName:"p"},"BuildVersions")," table to see what we can see. All it's really doing is demonstrating that we can now hit our database through our repositories. As a side note, we could have the exact same test operating directly on the ",(0,a.kt)("inlineCode",{parentName:"p"},"DbContext")," like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[TestMethod]\n        public void DbContext_BuildVersions_should_return_the_correct_version_information()\n        {\n            // Arrange\n            var dbContext = new AdventureWorks.EntityFramework.AdventureWorksLT2008R2Entities();\n\n            // Act\n            var buildVersions = dbContext.BuildVersions.ToList();\n\n            // Assert\n            Assert.AreEqual(1, buildVersions.Count);\n            Assert.AreEqual("10.00.80404.00", buildVersions[0].Database_Version);\n            Assert.AreEqual(new DateTime(2008, 4, 4), buildVersions[0].ModifiedDate);\n            Assert.AreEqual(1, buildVersions[0].SystemInformationID);\n            Assert.AreEqual(new DateTime(2008, 4, 4), buildVersions[0].VersionDate);\n        }\n')),(0,a.kt)("p",null,"For the most part we won't be doing this but I wanted to be clear that full power of Entity Framework is available to you as you're putting together your integration tests."),(0,a.kt)("h2",o({},{id:"database-snapshotting-time"}),"Database Snapshotting Time"),(0,a.kt)("p",null,"Up until this point we've essentially been laying our infrastructure and doing our plumbing. We now have a database, domain models and data access courtesy of Entity Framework, a testable repository layer and finally an integration test pack. What we want now is to get our database snapshot / backup and restore mechanism set up and integrated into the test pack."),(0,a.kt)("p",null,"Let's add references to the ",(0,a.kt)("inlineCode",{parentName:"p"},"System.Data")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"System.Configuration")," assemblies to our integration testing project and then add a new class called ",(0,a.kt)("inlineCode",{parentName:"p"},"DatabaseSnapshot"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System.Configuration;\nusing System.Data;\nusing System.Data.SqlClient;\n\nnamespace AdventureWorks.Repositories.IntegrationTests\n{\n    public static class DatabaseSnapshot\n    {\n        private const string SpCreateSnapShotName = "SnapshotBackup_Create";\n        private const string SpCreateSnapShot =\n@"CREATE PROCEDURE [dbo].[" + SpCreateSnapShotName + @"]\n    @databaseName        varchar(512),\n    @databaseLogicalName varchar(512),\n    @snapshotBackupPath  varchar(512),\n    @snapshotBackupName  varchar(512)\nAS\nBEGIN\n    SET NOCOUNT ON;\n\n    DECLARE @sql varchar(500)\n    SELECT @sql = \'CREATE DATABASE \' + @snapshotBackupName +\n                  \' ON (NAME=[\' + @databaseLogicalName +\n                  \'], FILENAME=\'\'\' + @snapshotBackupPath + @snapshotBackupName +\n                  \'\'\') AS SNAPSHOT OF [\' + @databaseName + \']\'\n    EXEC(@sql)\nEND";\n\n        private const string SpRestoreSnapShotName = "SnapshotBackup_Restore";\n        private const string SpRestoreSnapShot =\n@"CREATE PROCEDURE [dbo].[" + SpRestoreSnapShotName + @"]\n    @databaseName varchar(512),\n    @snapshotBackupName varchar(512)\nAS\nBEGIN\n    SET NOCOUNT ON;\n\n    DECLARE @sql varchar(500)\n    SET @sql  = \'ALTER DATABASE [\' + @databaseName + \'] SET SINGLE_USER WITH ROLLBACK IMMEDIATE\'\n    EXEC (@sql)\n\n    RESTORE DATABASE @databaseName\n    FROM DATABASE_SNAPSHOT = @snapshotBackupName\n\n    SET @sql = \'ALTER DATABASE [\' + @databaseName + \'] SET MULTI_USER\'\n    EXEC (@sql)\nEND";\n\n        private const string SpDeleteSnapShotName = "SnapshotBackup_Delete";\n        private const string SpDeleteSnapShot =\n@"CREATE PROCEDURE [dbo].[" + SpDeleteSnapShotName + @"]\n    @snapshotBackupName varchar(512)\nAS\nBEGIN\n    SET NOCOUNT ON;\n\n    DECLARE @sql varchar(500)\n\n    SELECT @sql = \'DROP DATABASE \' + @snapshotBackupName\n    EXEC(@sql)\nEND";\n\n        private static string _masterDbConnectionString;\n        private static string _dbName;\n        private static ConnectionStringSettings _dbConnectionStringSettings;\n\n        private static ConnectionStringSettings DbConnectionStringSettings\n        {\n            get\n            {\n                if (_dbConnectionStringSettings == null)\n                    _dbConnectionStringSettings = ConfigurationManager.ConnectionStrings["SnapshotBackup"];\n\n                return _dbConnectionStringSettings;\n            }\n        }\n\n        /// <summary>\n        /// Stored procedures should be executed against master database\n        /// </summary>\n        private static string MasterDbConnectionString\n        {\n            get\n            {\n                if (string.IsNullOrEmpty(_masterDbConnectionString))\n                {\n                    var sqlConnection = new SqlConnection(DbConnectionStringSettings.ConnectionString);\n                    _masterDbConnectionString = DbConnectionStringSettings.ConnectionString.Replace(sqlConnection.Database, "master");\n                }\n                return _masterDbConnectionString;\n            }\n        }\n\n        private static string DbName\n        {\n            get\n            {\n                if (string.IsNullOrEmpty(_dbName))\n                    _dbName = new SqlConnection(DbConnectionStringSettings.ConnectionString).Database.TrimStart(\'[\').TrimEnd(\']\');\n\n                return _dbName;\n            }\n        }\n\n        public static void SetupStoredProcedures()\n        {\n            using (var conn = new SqlConnection(MasterDbConnectionString))\n            {\n                conn.Open();\n\n                // Drop the existing stored procedures\n                SqlCommand cmd;\n                const string dropProcSql = "IF EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N\'[dbo].[{0}]\') AND type in (N\'P\', N\'PC\')) DROP PROCEDURE [dbo].[{0}]";\n                foreach (var spName in new[] { SpCreateSnapShotName, SpDeleteSnapShotName, SpRestoreSnapShotName })\n                {\n                    cmd = new SqlCommand(string.Format(dropProcSql, spName), conn);\n                    cmd.ExecuteNonQuery();\n                }\n\n                // Create the stored procedures anew\n                foreach (var createProcSql in new[] { SpCreateSnapShot, SpDeleteSnapShot, SpRestoreSnapShot })\n                {\n                    cmd = new SqlCommand(createProcSql, conn);\n                    cmd.ExecuteNonQuery();\n                }\n\n                conn.Close();\n            }\n        }\n\n        public static void CreateSnapShot()\n        {\n            var databaseName = new SqlParameter { ParameterName = "@databaseName", SqlValue = SqlDbType.VarChar, Value = DbName };\n            var databaseLogicalName = new SqlParameter { ParameterName = "@databaseLogicalName", SqlValue = SqlDbType.VarChar, Value = ConfigurationManager.AppSettings["DatabaseLogicalName"] };\n            var snapshotBackupPath = new SqlParameter { ParameterName = "@snapshotBackupPath", SqlValue = SqlDbType.VarChar, Value = ConfigurationManager.AppSettings["SnapshotBackupPath"] };\n            var snapshotBackupName = new SqlParameter { ParameterName = "@snapshotBackupName", SqlValue = SqlDbType.VarChar, Value = ConfigurationManager.AppSettings["SnapshotBackupName"] };\n\n            ExecuteStoredProcAgainstMaster(SpCreateSnapShotName, new[] { databaseName, databaseLogicalName, snapshotBackupPath, snapshotBackupName });\n        }\n\n        public static void DeleteSnapShot()\n        {\n            var snapshotBackupName = new SqlParameter { ParameterName = "@snapshotBackupName", SqlValue = SqlDbType.VarChar, Value = ConfigurationManager.AppSettings["SnapshotBackupName"] };\n\n            ExecuteStoredProcAgainstMaster(SpDeleteSnapShotName, new[] { snapshotBackupName });\n        }\n\n        public static void RestoreSnapShot()\n        {\n            var databaseName = new SqlParameter { ParameterName = "@databaseName", SqlValue = SqlDbType.VarChar, Value = DbName };\n            var snapshotBackupName = new SqlParameter { ParameterName = "@snapshotBackupName", SqlValue = SqlDbType.VarChar, Value = ConfigurationManager.AppSettings["SnapshotBackupName"] };\n\n            ExecuteStoredProcAgainstMaster(SpRestoreSnapShotName, new[] { databaseName, snapshotBackupName });\n        }\n\n        private static void ExecuteStoredProcAgainstMaster(string storedProc, SqlParameter[] parameters)\n        {\n            using (var conn = new SqlConnection(MasterDbConnectionString))\n            {\n                conn.Open();\n                var cmd = new SqlCommand(storedProc, conn) { CommandType = CommandType.StoredProcedure };\n                cmd.Parameters.AddRange(parameters);\n                cmd.ExecuteNonQuery();\n                conn.Close();\n            }\n        }\n    }\n}\n')),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"DatabaseSnapshot")," class exposes 4 methods:"),(0,a.kt)("dl",null,(0,a.kt)("dt",null,"SetupStoredProcedures"),(0,a.kt)("dd",null,"This method creates 3 stored procedures on the master database: ",(0,a.kt)("code",null,"SnapshotBackup_Create"),", ",(0,a.kt)("code",null,"SnapshotBackup_Restore")," and ",(0,a.kt)("code",null,"SnapshotBackup_Delete"),". These procs do pretty much what their names suggest and the other 3 methods call these stored procedures when creating, restoring and deleting snapshot backups respectively. You can see the (fairly minimal) SQL for these stored procs at the top of the",(0,a.kt)("code",null,"DatabaseSnapshot")," class."),(0,a.kt)("dt",null,"CreateSnapShot"),(0,a.kt)("dd",null,"This method creates a snapshot backup of the database at this point in time."),(0,a.kt)("dt",null,"RestoreSnapShot"),(0,a.kt)("dd",null,"This method restores the database back to state it was in when the snapshot backup was created."),(0,a.kt)("dt",null,"DeleteSnapShot"),(0,a.kt)("dd",null,"This method attempts to delete the existing snapshot backup.")),(0,a.kt)("p",null,"In order that we can use the ",(0,a.kt)("inlineCode",{parentName:"p"},"DatabaseSnapshot")," class we need to add the following entries to our ",(0,a.kt)("inlineCode",{parentName:"p"},"app.config"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<configuration>\n\n    <connectionStrings>\n\n        <add name="SnapshotBackup"\n             connectionString="data source=.;initial catalog=AdventureWorksLT2008R2;Trusted_Connection=true;Connection Timeout=200" />\n\n    </connectionStrings>\n\n    <appSettings>\n        <add key="DatabaseLogicalName" value="AdventureWorksLT2008_Data" />\n        <add key="SnapshotBackupPath" value="C:\\DbSnapshots\\" />\n        <add key="SnapshotBackupName" value="AdventureWorksLT2008R2_Snapshot" />\n    </appSettings>\n</configuration>\n')),(0,a.kt)("p",null,"These settings allow have the following purposes:"),(0,a.kt)("dl",null,(0,a.kt)("dt",null,"SnapshotBackup"),(0,a.kt)("dd",null,"A connection string that allows ",(0,a.kt)("code",null,"DatabaseSnapshot")," to connect to the database."),(0,a.kt)("dt",null,"DatabaseLogicalName"),(0,a.kt)("dd",null,"The logical name of the database you want to backup. (This can be found on the Files tab of the Database Properties in SSMS)"),(0,a.kt)("dt",null,"SnapshotBackupPath"),(0,a.kt)("dd",null,"The location where the snapshot backup is to be stored. You need to make sure that this exists on your machine."),(0,a.kt)("dt",null,"SnapshotBackupName"),(0,a.kt)("dd",null,"The name of the snapshot backup that will be created.")),(0,a.kt)("p",null,"Now to make use of ",(0,a.kt)("inlineCode",{parentName:"p"},"DatabaseSnapshot"),". Let's add a new class called ",(0,a.kt)("inlineCode",{parentName:"p"},"SetUpTearDown"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using Microsoft.VisualStudio.TestTools.UnitTesting;\n\nnamespace AdventureWorks.Repositories.IntegrationTests\n{\n    [TestClass]\n    public static class SetUpTearDown\n    {\n        [AssemblyInitialize]\n        public static void TestRunInitialize(TestContext context)\n        {\n            try\n            {\n                // Try to delete the snapshot in case it was left over from aborted test runs\n                DatabaseSnapshot.DeleteSnapShot();\n            }\n            catch { /* this should fail with snapshot does not exist */ }\n\n            DatabaseSnapshot.SetupStoredProcedures();\n            DatabaseSnapshot.CreateSnapShot();\n        }\n\n\n        [AssemblyCleanup]\n        public static void TestRunCleanup()\n        {\n            DatabaseSnapshot.DeleteSnapShot();\n        }\n    }\n}\n")),(0,a.kt)("p",null,"At the start of the test run this will create a snapshot in case one doesn't exist already. And at the end of the test run it will be a good citizen and delete the snapshot. We'll also add an extra method to our ",(0,a.kt)("inlineCode",{parentName:"p"},"BuildVersionTests")," class:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"namespace AdventureWorks.Repositories.IntegrationTests\n{\n    [TestClass]\n    public class BuildVersionTests\n    {\n        // ...\n\n        [TestCleanup]\n        public void TestCleanup()\n        {\n            DatabaseSnapshot.RestoreSnapShot();\n        }\n    }\n}\n")),(0,a.kt)("p",null,"This will ensure that after each test runs the database will be restored back to the snapshot created in ",(0,a.kt)("inlineCode",{parentName:"p"},"SetUpTearDown"),". Now if you re-run your tests, in between each test the restore back to the snapshot is taking place."),(0,a.kt)("h2",o({},{id:"prove-it"}),"Prove it!"),(0,a.kt)("p",null,"Of course the tests we have in place at present don't actually change the data at all. So I could be lying. I'm not. Let's prove it by adding one more class called ",(0,a.kt)("inlineCode",{parentName:"p"},"CustomerTests"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Linq;\nusing System.Linq.Expressions;\nusing Microsoft.VisualStudio.TestTools.UnitTesting;\nusing AdventureWorks.EntityFramework;\n\nnamespace AdventureWorks.Repositories.IntegrationTests\n{\n    [TestClass]\n    public class CustomerTests\n    {\n        [TestMethod]\n        public void Should_change_a_customers_first_and_last_name()\n        {\n            // Arrange\n            var uow = new SqlUnitOfWork();\n\n            // Act\n            var customer = uow.Customers.FindWhere(x => x.FirstName == "Jay" && x.LastName == "Adams").First();\n            var customerId = customer.CustomerID;\n            customer.FirstName = "John";\n            customer.LastName = "Reilly";\n            uow.Commit();\n\n            // Assert\n            Assert.IsNotNull(uow.Customers.FindWhere(x => x.FirstName == "John" && x.LastName == "Reilly" && x.CustomerID == customerId).SingleOrDefault());\n        }\n\n        [TestCleanup]\n        public void TestCleanup()\n        {\n            DatabaseSnapshot.RestoreSnapShot();\n        }\n    }\n}\n')),(0,a.kt)("p",null,"The above test checks that you can look up an existing customer, Mr Jay Adams, and change his name to my name - to John Reilly. If I execute the test above and there was no restore in place then subsequently when I came to exercise this test it should start to fail as it no longer has a Mr Jay Adams to lookup. But with this restore mechanism in place I can execute this test repeatedly without worrying."),(0,a.kt)("h2",o({},{id:"rounding-off"}),"Rounding off"),(0,a.kt)("p",null,"And that's us finished - we now have a database snapshot restore mechanism in place. With this we can develop integration tests that thoroughly change the data in our database secure in the knowledge that once the test is complete our database will be restored back to it's initial state."),(0,a.kt)("p",null,"Obviously there are other alternative approaches for integration testing available to that which I've laid out in this post. But I can imagine that this approach is very useful for applying to legacy applications that you might inherit and need to continue supporting. Also, this approach should fit in well with a continuous integration setup. It would be pretty straightforward to have database that existed purely for testing purposes against which all the integration tests could be set to run at the point of each check in."),(0,a.kt)("p",null,"Thanks to Marc Talary, Sandeep Deo and Tishul Vadher who all contributed to ",(0,a.kt)("inlineCode",{parentName:"p"},"DatabaseSnapshot"),". Credit is also due to Google due to the hundreds of articles the team ended up reading on snapshot backups."))}d.isMDXComponent=!0},44278:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"wpf-and-mystic-meg-or-playing",title:"WPF and Mystic Meg or Playing Futurologist",authors:"johnnyreilly",tags:["SPA"],hide_table_of_contents:!1},s=void 0,l={permalink:"/wpf-and-mystic-meg-or-playing",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-02-12-wpf-and-mystic-meg-or-playing/index.md",source:"@site/blog/2014-02-12-wpf-and-mystic-meg-or-playing/index.md",title:"WPF and Mystic Meg or Playing Futurologist",description:"Time for an unusual post. Most of what gets put down here is technical \"how-to's\". It's usually prompted by something I've been working on and serves, as much as anything else, as an aide-memoire. Not this time.",date:"2014-02-12T00:00:00.000Z",formattedDate:"February 12, 2014",tags:[{label:"SPA",permalink:"/tags/spa"}],readingTime:2.92,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"wpf-and-mystic-meg-or-playing",title:"WPF and Mystic Meg or Playing Futurologist",authors:"johnnyreilly",tags:["SPA"],hide_table_of_contents:!1},prevItem:{title:"TypeScript and RequireJS (Keep It Simple)",permalink:"/typescript-and-requirejs-keep-it-simple"},nextItem:{title:"Integration Testing with Entity Framework and Snapshot Backups",permalink:"/integration-testing-with-entity"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Time for an unusual post. Most of what gets put down here is technical \"how-to's\". It's usually prompted by something I've been working on and serves, as much as anything else, as an aide-memoire. Not this time."),(0,a.kt)("p",null,"I\u2019ve been watching the changes in the world of development of the last couple of years and I\u2019ve come to a controversial conclusion... So I wanted to write about it. Hopefully I'll be able to return to this in 5 years and say \"wow - I'm so insightful - almost visionary really\". Or not. Either way, let's put it out there - it's sink or swim time. Ready for it? Here\u2019s my bet: WPF will die."),(0,a.kt)("p",null,"Sounds dramatic right? OK - I've overstated my case just to get you to read on (I should work for the tabloids). Let me flesh this out a little. First of all, I think WPF is a fine technology - great apps are built with it. My personal favourite being the fantastic ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/blog/1151-designing-github-for-windows"}),"GitHub for Windows"),". And actually I don't think WPF will die at all. What I think will happen is that it will become a more niche way to build applications."),(0,a.kt)("p",null,"More broadly, I think that native client apps (be they Windows, Mac, iOS, Android etc) will eventually come to be replaced by ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Single-page_application"}),"rich web apps / SPAs")," of the Angular / Ember / Durandal ilk. I realise that at the moment that seems like a ludicrous statement \u2013 native apps are heavily used throughout enterprises worldwide and certainly will continue to be used and actively developed for at least the next 5 years."),(0,a.kt)("p",null,"But as the web comes to ",(0,a.kt)("a",o({parentName:"p"},{href:"http://arstechnica.com/information-technology/2013/05/native-level-performance-on-the-web-a-brief-examination-of-asm-js/"}),"perform like native"),", as ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jashkenas/coffee-script/wiki/List-of-languages-that-compile-to-JS"}),"JavaScript become a compile target"),", as ",(0,a.kt)("a",o({parentName:"p"},{href:"http://davidwalsh.name/canvas-demos"}),"HTML 5 provides rich UI")," and as ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en/docs/WebSockets"}),"interactive communication becomes possible")," I reckon this is a fairly probable scenario. Particularly when you consider the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/Apps/Reference"}),"API work Firefox is doing around Firefox OS"),". I could be wrong, but my expectation is that the day will come when people will have apps that they can access from anywhere, on any platform and those apps can be deployed without infrastructure having to push out new versions to each client machine."),(0,a.kt)("p",null,"The web undeniably has issues but I think it will likely win out. And the cost case for a single client app is pretty compelling to anyone funding a system."),(0,a.kt)("p",null,"As a dev I\u2019m always working with an ever-evolving grab bag of technology whether it be front end, middle tier, database or services. In fact that will likely always be the case (change being the only constant in the world of software). But on the basis of my expectations I\u2019m planning to always keep at least a toe in the world of web apps as a form of \u201ccareer future-proofing\u201d."),(0,a.kt)("p",null,"Going less broad again when I look at the Microsoft stack, I think XAML will live on for some time. Obviously Silverlight is no longer being actively developed but MS are using it in Windows 8 (Phone and WinJS) as well as WPF. But I do kind of wonder if it will become like a bit like VB.Net, still around, still in use, but slowly dropping off in terms of popularity. Particularly as you can write WinJS apps in HTML / CSS / JavaScript."),(0,a.kt)("p",null,"As I say, I could very much be wrong about all of this. I don\u2019t know what your view of the future of the development landscape is? You may have a different insight? I\u2019d be intrigued to know!"))}d.isMDXComponent=!0},31743:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-and-requirejs-keep-it-simple",title:"TypeScript and RequireJS (Keep It Simple)",authors:"johnnyreilly",tags:["typescript"],hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-and-requirejs-keep-it-simple",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-02-27-typescript-and-requirejs-keep-it-simple/index.md",source:"@site/blog/2014-02-27-typescript-and-requirejs-keep-it-simple/index.md",title:"TypeScript and RequireJS (Keep It Simple)",description:"I'm not the first to take a look at mixing TypeScript and RequireJS but I wanted to get it clear in my head. Also, I've always felt the best way to learn is to do. So here we go. I'm going to create a TypeScript and RequireJS demo based on John Papa's \"Keep It Simple RequireJS Demo\".",date:"2014-02-27T00:00:00.000Z",formattedDate:"February 27, 2014",tags:[{label:"typescript",permalink:"/tags/typescript"}],readingTime:4.06,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-and-requirejs-keep-it-simple",title:"TypeScript and RequireJS (Keep It Simple)",authors:"johnnyreilly",tags:["typescript"],hide_table_of_contents:!1},prevItem:{title:"Caching and cache-busting with RequireJS",permalink:"/caching-and-cache-busting-with-requirejs"},nextItem:{title:"WPF and Mystic Meg or Playing Futurologist",permalink:"/wpf-and-mystic-meg-or-playing"}},p={authorsImageUrls:[void 0]},u=[{value:"Closing Thoughts",id:"closing-thoughts",level:2},{value:"Finally for bonus points....",id:"finally-for-bonus-points",level:2},{value:"Want the code for your very own?",id:"want-the-code-for-your-very-own",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I'm not the first to take a look at mixing TypeScript and RequireJS but I wanted to get it clear in my head. Also, I've always felt the best way to learn is to do. So here we go. I'm going to create a TypeScript and RequireJS demo based on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnpapa/kis-requirejs-demo/"}),'John Papa\'s "Keep It Simple RequireJS Demo"'),"."),(0,a.kt)("p",null,"So let's fire up Visual Studio 2013 and create a new ASP.NET Web Application called \u201cRequireJSandTypeScript\u201d (the empty project template is fine)."),(0,a.kt)("p",null,"Add a new HTML file to the root called \u201cindex.html\u201d and base it on \u201cindex3.html\u201d from ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnpapa/kis-requirejs-demo/blob/master/ModularDemo/index3.html"}),"John Papa\u2019s demo"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<!DOCTYPE html>\n<html>\n  <head>\n    <title>TypeScript with RequireJS</title>\n  </head>\n  <body>\n    <div>\n      <h1>TypeScript with RequireJS loading jQuery in Visual Studio land</h1>\n    </div>\n\n    \x3c!-- use jquery to load this message--\x3e\n    <p id="message"></p>\n\n    \x3c!-- Shortcut to load require and then load main--\x3e\n    <script\n      src="/scripts/require.js"\n      data-main="/scripts/main"\n      type="text/javascript"\n    ><\/script>\n  </body>\n</html>\n')),(0,a.kt)("p",null,"John\u2019s demo depends on jQuery and RequireJS (not too surprisingly) so let\u2019s fire up Nuget and get them:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),"Install-Package RequireJS\nInstall-Package jQuery\n")),(0,a.kt)("p",null,"Whilst we\u2019re at it, let\u2019s get the Definitely Typed typings as well:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),"Install-Package jQuery.TypeScript.DefinitelyTyped\n")),(0,a.kt)("p",null,"To my surprise this popped up a dialog."),(0,a.kt)("p",null,'By "Your project has been configured to support TypeScript." it means that the csproj file has had the following entries added:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<Project ToolsVersion="12.0" DefaultTargets="Build" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">\n  <Import Project="$(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion)\\TypeScript\\Microsoft.TypeScript.Default.props" Condition="Exists(\'$(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion)\\TypeScript\\Microsoft.TypeScript.Default.props\')" />\n  ...\n  <PropertyGroup>\n    ...\n    <TypeScriptToolsVersion>0.9</TypeScriptToolsVersion>\n  </PropertyGroup>\n  ...\n  <Import Project="$(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion)\\TypeScript\\Microsoft.TypeScript.targets" Condition="Exists(\'$(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion)\\TypeScript\\Microsoft.TypeScript.targets\')" />\n  ...\n</Project>\n')),(0,a.kt)("p",null,"I\u2019m not sure when this tweak to the Visual Studio tooling was added was added. Perhaps it's part of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.com/b/typescript/archive/2014/02/25/announcing-typescript-1-0rc.aspx"}),"TypeScript 1.0 RC release"),"; either way it\u2019s pretty nice. Let's press on."),(0,a.kt)("p",null,"Whilst we\u2019re at it let\u2019s make sure that we\u2019re compiling to AMD (to be RequireJS friendly) by adding in the following csproj tweaks just before the Microsoft.TypeScript.targets Project import statement:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),"<PropertyGroup Condition=\"'$(Configuration)' == 'Debug'\">\n    <TypeScriptModuleKind>amd</TypeScriptModuleKind>\n  </PropertyGroup>\n  <PropertyGroup Condition=\"'$(Configuration)' == 'Release'\">\n    <TypeScriptModuleKind>amd</TypeScriptModuleKind>\n  </PropertyGroup>\n")),(0,a.kt)("p",null,"Where was I? Oh yes, typings. So let\u2019s get the RequireJS typings too:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),"Install-Package requirejs.TypeScript.DefinitelyTyped\n")),(0,a.kt)("p",null,"Right \u2013 looking at index.html we can see from the data-main tag that the first file loaded by RequireJS, our bootstrapper if you will, is main.js. So let\u2019s add ourselves a main.ts based on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnpapa/kis-requirejs-demo/blob/master/ModularDemo/Scripts3/main.js"}),"John's example")," (which will in turn generate a main.js):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"(function () {\n  requirejs.config({\n    baseUrl: 'scripts',\n    paths: {\n      jquery: 'jquery-2.1.0',\n    },\n  });\n\n  require(['alerter'], (alerter) => {\n    alerter.showMessage();\n  });\n})();\n")),(0,a.kt)("p",null,"main.ts depends upon ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnpapa/kis-requirejs-demo/blob/master/ModularDemo/Scripts3/alerter.js"}),"alerter")," so let\u2019s add ourselves an alerter.ts as well:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"define('alerter', ['jquery', 'dataservice'], function ($, dataservice) {\n  var name = 'John',\n    showMessage = function () {\n      var msg = dataservice.getMessage();\n\n      $('#message').text(msg + ', ' + name);\n    };\n\n  return {\n    showMessage: showMessage,\n  };\n});\n")),(0,a.kt)("p",null,"And a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnpapa/kis-requirejs-demo/blob/master/ModularDemo/Scripts3/dataservice.js"}),"dataservice.ts"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"define('dataservice', [], function () {\n  var msg = 'Welcome to Code Camp',\n    getMessage = function () {\n      return msg;\n    };\n\n  return {\n    getMessage: getMessage,\n  };\n});\n")),(0,a.kt)("p",null,"That all compiles fine. But we\u2019re missing a trick. We\u2019re supposed to be using TypeScripts AMD support so let\u2019s change the code to do just that. First dataservice.ts:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"var msg = 'Welcome to Code Camp';\n\nexport function getMessage() {\n  return msg;\n}\n")),(0,a.kt)("p",null,"Then alerter.ts:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import $ = require('jquery');\nimport dataservice = require('dataservice');\n\nvar name = 'John';\n\nexport function showMessage() {\n  var msg = dataservice.getMessage();\n\n  $('#message').text(msg + ', ' + name);\n}\n")),(0,a.kt)("p",null,"I know both of the above look slightly different but if you look close you'll see it's really only boilerplate changes. The actual application code is unaffected. Finally, main.ts remains as it is and that's us done; we have ourselves a working demo... Yay!"),(0,a.kt)("p",null,"Thanks to John Papa for creating such a simple demo I could use as the basis for my own demo."),(0,a.kt)("h2",o({},{id:"closing-thoughts"}),"Closing Thoughts"),(0,a.kt)("p",null,"Unfortunately there is no typing on the alerter reference within main.ts. To my knowledge there is no way to implicitly import the typings here \u2013 the only thing you can do is specify them manually. (By the way, if I'm wrong about this then please do set me straight!) That said, this is not so bad really since this main.ts file is essentially just a bootstrapper that kicks things off. All the other files contain the real application code and they have have typings a-go-go. So we're happy."),(0,a.kt)("h2",o({},{id:"finally-for-bonus-points"}),"Finally for bonus points...."),(0,a.kt)("p",null,"I\u2019ve included the js and js.map files in the project file as they don't seem to be added into the project by Visual Studio when the TS file is created or when it is compiled for the first time. I've also ensured that these files are dependent upon the typescript files they were generated from."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<TypeScriptCompile Include="Scripts\\alerter.ts" />\n    <Content Include="Scripts\\alerter.js">\n        <DependentUpon>alerter.ts</DependentUpon>\n    </Content>\n    <Content Include="Scripts\\alerter.js.map">\n        <DependentUpon>alerter.ts</DependentUpon>\n    </Content>\n    <TypeScriptCompile Include="Scripts\\dataservice.ts" />\n    <Content Include="Scripts\\dataservice.js">\n        <DependentUpon>dataservice.ts</DependentUpon>\n    </Content>\n    <Content Include="Scripts\\dataservice.js.map">\n        <DependentUpon>dataservice.ts</DependentUpon>\n    </Content>\n    <TypeScriptCompile Include="Scripts\\main.ts" />\n    <Content Include="Scripts\\main.js">\n        <DependentUpon>main.ts</DependentUpon>\n    </Content>\n    <Content Include="Scripts\\main.js.map">\n        <DependentUpon>main.ts</DependentUpon>\n    </Content>\n')),(0,a.kt)("h2",o({},{id:"want-the-code-for-your-very-own"}),"Want the code for your very own?"),(0,a.kt)("p",null,"Well you can grab it from ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/RequireJSandTypeScript"}),"GitHub"),"."))}d.isMDXComponent=!0},73485:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"caching-and-cache-busting-with-requirejs",title:"Caching and cache-busting with RequireJS",authors:"johnnyreilly",tags:["asp.net","RequireJS","cache","caching"],hide_table_of_contents:!1},s=void 0,l={permalink:"/caching-and-cache-busting-with-requirejs",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-03-05-caching-and-cache-busting-with-requirejs/index.md",source:"@site/blog/2014-03-05-caching-and-cache-busting-with-requirejs/index.md",title:"Caching and cache-busting with RequireJS",description:"Having put together a demo of using TypeScript with RequireJS my attention turned quickly to caching. Or rather, IE forced me to think about caching.",date:"2014-03-05T00:00:00.000Z",formattedDate:"March 5, 2014",tags:[{label:"asp.net",permalink:"/tags/asp-net"},{label:"RequireJS",permalink:"/tags/require-js"},{label:"cache",permalink:"/tags/cache"},{label:"caching",permalink:"/tags/caching"}],readingTime:8.925,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"caching-and-cache-busting-with-requirejs",title:"Caching and cache-busting with RequireJS",authors:"johnnyreilly",tags:["asp.net","RequireJS","cache","caching"],hide_table_of_contents:!1},prevItem:{title:"Knockout + Globalize = valueNumber Binding Handler",permalink:"/knockout-globalize-valuenumber-binding"},nextItem:{title:"TypeScript and RequireJS (Keep It Simple)",permalink:"/typescript-and-requirejs-keep-it-simple"}},p={authorsImageUrls:[void 0]},u=[{value:"Research",id:"research",level:2},{value:"Implementation",id:"implementation",level:2},{value:"Let\u2019s get the server involved!",id:"lets-get-the-server-involved",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Having put together a demo of using TypeScript with RequireJS my attention turned quickly to caching. Or rather, IE forced me to think about caching."),(0,a.kt)("p",null,"Everyone has their own workflow, their own tools. The things they like to use as they put things together. And for me I\u2019m a Visual Studio man \u2013 it\u2019s not everyone\u2019s bag but I really like it. I find the JavaScript tooling is now really solid combined with IE and it (generally) makes me more productive. I want to use it. But, as you know, nothing is perfect..."),(0,a.kt)("p",null,"So there I was, delighted with the TypeScript / RequireJS demo. It was working just lovely. I started investigating the debugging story. What would happen if I change a script file on the fly? When I refresh IE does it pick up the tweaks?"),(0,a.kt)("p",null,"Let\u2019s find out. I'll open up alerter.ts and change this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"var name = 'John';\n")),(0,a.kt)("p",null,"to this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var name = 'Bobby';\n")),(0,a.kt)("p",null,"And ","*",(0,a.kt)("strong",{parentName:"p"},"boom"),"*",'! Nothing. I\u2019ve refreshed IE and I\u2019m expecting to see \u201cWelcome to Code Camp, Bobby\u201d. But I\u2019m still reading \u201cWelcome to Code Camp, John\u201d... I bet Chrome wouldn\u2019t do this to me... And I\u2019m right! It doesn\u2019t. I don\u2019t want to get too much into the details of this but it looks like it comes down to Chrome sending an "If-Modified-Since" request header where IE does not. I\u2019m pretty sure that IE could be configured to behave likewise but I\u2019d rather not have to remember that. (And furthermore I don\u2019t want to have to remind every person that works on the app to do that as well.)'),(0,a.kt)("p",null,"This raises a number of issues but essentially it gets me to think about the sort of caching I want. Like most of you I have 2 significant use cases:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Development"),(0,a.kt)("li",{parentName:"ol"},"Production")),(0,a.kt)("p",null,"For Development I want any changes to JavaScript files to be picked up \u2013 I do ","*",(0,a.kt)("strong",{parentName:"p"},"not"),"*"," want caching. For Production I want caching in order that users have better performance / faster loading. If I ship a new version of the app to Production I also want users to pick up the new versions of a file and cache those."),(0,a.kt)("h2",o({},{id:"research"}),"Research"),(0,a.kt)("p",null,"I did a little digging. The most useful information I found was ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/q/8315088/761388"}),"a StackOverflow post on RequireJS and caching"),". Actually I\u2019d recommend anyone reading this to head over and read that from top to bottom. Read the question and all of the answers as well \u2013 pretty much everything will add to your understanding of RequireJS."),(0,a.kt)("p",null,"As with any set of answers there are different and conflicting views. ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/8479953/761388"}),"Phil McCull\u2019s (accepted) answer")," was for my money the most useful. It pointed ",(0,a.kt)("a",o({parentName:"p"},{href:"http://requirejs.org/docs/api.html#config-urlArgs"}),"back to the RequireJS documentation"),"."),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"*",'"urlArgs: Extra query string arguments appended to URLs that RequireJS uses to fetch resources. Most useful to cache bust when the browser or server is not configured correctly. Example cache bust setting for urlArgs:'),(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"urlArgs: 'bust=' + new Date().getTime();\n")),(0,a.kt)("p",{parentName:"blockquote"},'During development it can be useful to use this, however be sure to remove it before deploying your code."'),(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"}))),(0,a.kt)("p",null,"Phil\u2019s answer suggests using urlArgs ","*",(0,a.kt)("strong",{parentName:"p"},"both"),"*"," for Production and for Development in 2 different ways. Using what amounts to a random number in the Development environment (as in the official docs) for cache-busting. For the Production environment he suggests using a specific version number which allows for client-side caching between different build versions."),(0,a.kt)("p",null,"Full disclosure, this is not the approach favoured by James Burke (author of RequireJS). He doesn\u2019t go into why in the RequireJS docs but has ",(0,a.kt)("a",o({parentName:"p"},{href:"https://groups.google.com/forum/#!msg/requirejs/3E9dP_BSQoY/36ut2Gtko7cJ"}),"elsewhere expounded on this"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("em",{parentName:"p"},"For deployed assets, I prefer to put the version or hash for the whole build as a build directory, then just modify the baseUrl config used for the project to use that versioned directory as the baseUrl. Then no other files change, and it helps avoid some proxy issues where they may not cache an URL with a query string on it. "))),(0,a.kt)("p",null,"I\u2019m not so worried about the proxy caching issue. My users tend to be people who use the application repeatedly and so the caching I most care about is their local machine caching. From what I understand urlArgs will work fine in this scenario. Yes the downside of this approach is that some proxy servers may not cache these assets. That\u2019s a shame but it\u2019s not a dealbreaker for me. As I said, I still have client side caching."),(0,a.kt)("p",null,"If you want to go a little deeper I recommend reading ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.stevesouders.com/blog/2008/08/23/revving-filenames-dont-use-querystring/"}),"Steve Souders post")," on the topic (in case you\u2019re not aware Steve is Google\u2019s Mr Performance). Interestingly, looking at the comments on the post it sounds like the lack of support for proxy caching with querystrings may that may be starting to change."),(0,a.kt)("p",null,"But either way, I\u2019m happy with this approach. As I always say, if it\u2019s good enough for Stack Overflow then it\u2019s good enough for me."),(0,a.kt)("h2",o({},{id:"implementation"}),"Implementation"),(0,a.kt)("p",null,"I\u2019m going to start off using the demo from ",(0,a.kt)("a",o({parentName:"p"},{href:"/typescript-and-requirejs-keep-it-simple"}),"my last blog post")," as a basis. Let\u2019s take that and evolve it. As a result my solution is going to work with TypeScript and RequireJS (since the previous demo was about that) but the implementation I\u2019m going to come up with would work as well with vanilla JS as it would with TypeScript compiled JS."),(0,a.kt)("p",null,"Let\u2019s take a look at our index.html. First we\u2019ll drop our usage of ",(0,a.kt)("inlineCode",{parentName:"p"},"main.ts")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"main.js"),' (our bootstrapper file that defines config and kicks off the "app"). We\u2019ll pull out the use of ',(0,a.kt)("inlineCode",{parentName:"p"},"data-main")," and instead, just after the reference to require we\u2019ll add the contents of ",(0,a.kt)("inlineCode",{parentName:"p"},"main.js")," much in ",(0,a.kt)("a",o({parentName:"p"},{href:"http://requirejs.org/docs/api.html#config"}),"the style of the RequireJS docs"),". We\u2019ll also include a urlArgs that as a cache-buster that uses the approach outlined ",(0,a.kt)("a",o({parentName:"p"},{href:"http://requirejs.org/docs/api.html#config-urlArgs"}),"in the RequireJS docs"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),"<script src=\"/scripts/require.js\"><\/script>\n<script>\n  require.config({\n    baseUrl: '/scripts',\n    paths: {\n      jquery: 'jquery-2.1.0',\n    },\n    urlArgs: 'v=' + new Date().getTime(),\n  });\n\n  require(['alerter'], function (alerter) {\n    alerter.showMessage();\n  });\n<\/script>\n")),(0,a.kt)("p",null,"Spinning up the site all runs as you would expect. The question is: does this work as a cache-buster? Let\u2019s tweak ",(0,a.kt)("inlineCode",{parentName:"p"},"alerter.ts")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"alerter.js"),"."),(0,a.kt)("p",null,"Oh yeah! We\u2019re cache-busting like gangbusters!"),(0,a.kt)("p",null,"So now let\u2019s comment out our existing urlArgs (which represents the Development solution from Phil\u2019s answer) and replace it with a fixed value like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"//urlArgs: \"v=\" +  (new Date()).getTime()\nurlArgs: 'v=1';\n")),(0,a.kt)("p",null,"This represents the Production solution from Phil\u2019s answer. Now let\u2019s run, refresh a couple of times and ensure that our fixed querystring value results in a 304 status code (indicating \u201cNot Modified\u201d and cached item used)."),(0,a.kt)("p",null,"It does! Now let\u2019s increment the value:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"urlArgs: 'v=2';\n")),(0,a.kt)("p",null,"When we refresh the browser this should result in 200 status codes (indicating the cached version has not been used and the client has picked up a new version from the server)."),(0,a.kt)("p",null,"Success! That\u2019s our premise tested \u2013 both Development and Production scenarios. Now we want to turn this into a slightly more sophisticated reusable solution like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),"<script src=\"/scripts/require.js\"><\/script>\n<script>\n  var inDevelopment = true,\n    version = '1';\n\n  require.config({\n    baseUrl: '/scripts',\n    paths: {\n      jquery: 'jquery-2.1.0',\n    },\n    urlArgs: 'v=' + (inDevelopment ? new Date().getTime() : version),\n  });\n\n  require(['alerter'], function (alerter) {\n    alerter.showMessage();\n  });\n<\/script>\n")),(0,a.kt)("p",null,"In the tweaked script above 2 variables are defined. The first is ",(0,a.kt)("inlineCode",{parentName:"p"},"inDevelopment")," which models whether you are in the Development scenario (true) or the Production scenario (false). The second is ",(0,a.kt)("inlineCode",{parentName:"p"},"version")," which represents the application version number. With this in place I can simply flip between the Development and Production scenario by changing the value of ",(0,a.kt)("inlineCode",{parentName:"p"},"inDevelopment"),". And when a new version ships I can change the version number to force a cache refresh on the users."),(0,a.kt)("p",null,"What drives the values of ",(0,a.kt)("inlineCode",{parentName:"p"},"inDevelopment")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"version")," is down to you. You could load the ",(0,a.kt)("inlineCode",{parentName:"p"},"inDevelopment")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"version")," values from some application endpoint. You could hardcode them in your screen. The choices are yours. I\u2019m going to finish off with a simple approach that I've found useful."),(0,a.kt)("h2",o({},{id:"lets-get-the-server-involved"}),"Let\u2019s get the server involved!"),(0,a.kt)("p",null,"I want the server to drive my urlArgs value. Why? Well this project happens to be an ASP.NET project which handily has the concept of Development / Production scenarios nicely modelled by the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/s10awwz0(v=vs.85).aspx"}),"web.config\u2019s compilation debug flag"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<configuration>\n  <system.web>\n    <compilation debug="true" targetFramework="4.5" />\n    <httpRuntime targetFramework="4.5" />\n  </system.web>\n</configuration>\n')),(0,a.kt)("p",null,"If debug is ",(0,a.kt)("inlineCode",{parentName:"p"},"true")," then that reflects the Development scenario. If debug is ",(0,a.kt)("inlineCode",{parentName:"p"},"false")," then that reflects the Production scenario."),(0,a.kt)("p",null,"So bearing that in mind I want to use the value of debug to drive my ",(0,a.kt)("inlineCode",{parentName:"p"},"urlArgs"),". If I have my debug flag set to ",(0,a.kt)("inlineCode",{parentName:"p"},"true")," I want to cache-bust all the way. Likewise, if debug is set to ",(0,a.kt)("inlineCode",{parentName:"p"},"false")," then I want to serve up the version number so that caching is used until the version number changes. Time to break out the C#:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'namespace RequireJSandCaching\n{\n    public static class RequireJSHelpers\n    {\n        private static readonly bool _inDebug;\n        private static readonly string _version;\n\n        static RequireJSHelpers()\n        {\n            _inDebug = System.Web.HttpContext.Current.IsDebuggingEnabled;\n            _version = (_inDebug)\n                ? "InDebug"\n                : System.Reflection.Assembly.GetExecutingAssembly().GetName().Version.ToString();\n        }\n\n        public static string Version\n        {\n            get\n            {\n                return (_inDebug)\n                    ? System.DateTime.Now.Ticks.ToString()\n                    : _version;\n            }\n        }\n    }\n}\n')),(0,a.kt)("p",null,"This is a static helper class called ",(0,a.kt)("inlineCode",{parentName:"p"},"RequireJSHelpers"),". It has a static constructor which initialises 2 fields. ",(0,a.kt)("inlineCode",{parentName:"p"},"_inDebug")," is taken from ",(0,a.kt)("inlineCode",{parentName:"p"},"System.Web.HttpContext.Current.IsDebuggingEnabled")," which exposes the compilation debug value. ",(0,a.kt)("inlineCode",{parentName:"p"},"_version")," is initialised, when debug is ",(0,a.kt)("inlineCode",{parentName:"p"},"false"),", to the version number of the dll (driven by this ",(0,a.kt)("inlineCode",{parentName:"p"},'AssemblyInfo.cs [assembly: AssemblyVersion("1.0.*")]')," attribute)"),(0,a.kt)("p",null,"There\u2019s 1 property on this helper class called version. Depending on whether the app is in debug mode or not this attribute either exposes the application version or effectively the C# equivalent to JavaScript\u2019s ",(0,a.kt)("inlineCode",{parentName:"p"},"(new Date()).getTime()"),". (Well strictly speaking they have a different starting point in history but that\u2019s by-the-by... Both are of equal value as cache-busters.)"),(0,a.kt)("p",null,"You probably see where this is all going."),(0,a.kt)("p",null,"Let\u2019s clone our ",(0,a.kt)("inlineCode",{parentName:"p"},"index.html")," page and call it ",(0,a.kt)("inlineCode",{parentName:"p"},"serverUrlArgs.cshtml")," (note the suffix). Let\u2019s replace the script section with this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),"<script>\n  require.config({\n    baseUrl: '/scripts',\n    paths: {\n      jquery: 'jquery-2.1.0',\n    },\n    urlArgs: 'v=@RequireJSandCaching.RequireJSHelpers.Version',\n  });\n\n  require(['alerter'], function (alerter) {\n    alerter.showMessage();\n  });\n<\/script>\n")),(0,a.kt)("p",null,"Which drives ",(0,a.kt)("inlineCode",{parentName:"p"},"urlArgs")," from the ",(0,a.kt)("inlineCode",{parentName:"p"},"RequireJSHelpers.Version")," property. If we fire it up now (with debug set to true in our web.config) then we see requests like this:"),(0,a.kt)("p",null,"And if we set debug to false in our web.config then (after the initial requests have been cached) we see requests like this:"),(0,a.kt)("p",null,"This leaves us with a simple mechanism to drive our RequireJS caching. If debug is set to ",(0,a.kt)("inlineCode",{parentName:"p"},"true")," in our ",(0,a.kt)("inlineCode",{parentName:"p"},"web.config")," then Require will perform cache-busting. If debug is set to ",(0,a.kt)("inlineCode",{parentName:"p"},"false")," then RequireJS will perform only version-changing cache-busting and will, whilst the version remains constant, support client-side caching."),(0,a.kt)("p",null,"Finished. In case it helps I\u2019ve put the code for this ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/RequireJSandCaching"}),"up on GitHub"),"."))}d.isMDXComponent=!0},25578:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"knockout-globalize-valuenumber-binding",title:"Knockout + Globalize = valueNumber Binding Handler",authors:"johnnyreilly",tags:["Globalize","Knockout"],hide_table_of_contents:!1},s=void 0,l={permalink:"/knockout-globalize-valuenumber-binding",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-03-11-knockout-globalize-valuenumber-binding/index.md",source:"@site/blog/2014-03-11-knockout-globalize-valuenumber-binding/index.md",title:"Knockout + Globalize = valueNumber Binding Handler",description:"I\u2019ve long used Globalize for my JavaScript number formatting / parsing needs. In a current project I\u2019m using Knockout for the UI. When it came to data-binding numeric values none of the default binding handlers seemed appropriate. What I wanted was a binding handler that:",date:"2014-03-11T00:00:00.000Z",formattedDate:"March 11, 2014",tags:[{label:"Globalize",permalink:"/tags/globalize"},{label:"Knockout",permalink:"/tags/knockout"}],readingTime:3.885,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"knockout-globalize-valuenumber-binding",title:"Knockout + Globalize = valueNumber Binding Handler",authors:"johnnyreilly",tags:["Globalize","Knockout"],hide_table_of_contents:!1},prevItem:{title:"The Surprisingly Happy Tale of Visual Studio Online, Continous Integration and Chutzpah",permalink:"/the-surprisingly-happy-tale-of-visual"},nextItem:{title:"Caching and cache-busting with RequireJS",permalink:"/caching-and-cache-busting-with-requirejs"}},p={authorsImageUrls:[void 0]},u=[{value:"PS Globalize is a-changing",id:"ps-globalize-is-a-changing",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I\u2019ve long used ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jquery/globalize/"}),"Globalize")," for my JavaScript number formatting / parsing needs. In a current project I\u2019m using Knockout for the UI. When it came to data-binding numeric values none of the default binding handlers seemed appropriate. What I wanted was a binding handler that:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Was specifically purposed for dealing with numeric values"),(0,a.kt)("li",{parentName:"ol"},"Handled the parsing / formatting for the current locale (and I naturally intended to use Globalize for this purpose)")),(0,a.kt)("p",null,"Like so much development we start by standing on the shoulders of giants. In this case it\u2019s the fantastic ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/RPNiemeyer"}),"Ryan Niemeyer")," who put up a ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/12647270/761388"}),"post on StackOverflow")," that got me on the right track."),(0,a.kt)("p",null,"Essentially his approach provides an \u201cinterceptor\u201d mechanism that allows you to validate numeric data entry on input and format numeric data going out as well. Very nice. Into this I plugged Globalize to handle the parsing and formatting. I ended up with the \u201cvalueNumber\u201d binding handler:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"ko.bindingHandlers.valueNumber = {\n  init: function (\n    element,\n    valueAccessor,\n    allBindingsAccessor,\n    viewModel,\n    bindingContext\n  ) {\n    /**\n     * Adapted from the KO hasfocus handleElementFocusChange function\n     */\n    function elementIsFocused() {\n      var isFocused = false,\n        ownerDoc = element.ownerDocument;\n      if ('activeElement' in ownerDoc) {\n        var active;\n        try {\n          active = ownerDoc.activeElement;\n        } catch (e) {\n          // IE9 throws if you access activeElement during page load\n          active = ownerDoc.body;\n        }\n        isFocused = active === element;\n      }\n\n      return isFocused;\n    }\n\n    /**\n     * Adapted from the KO hasfocus handleElementFocusChange function\n     *\n     * @param {boolean} isFocused whether the current element has focus\n     */\n    function handleElementFocusChange(isFocused) {\n      elementHasFocus(isFocused);\n    }\n\n    var observable = valueAccessor(),\n      properties = allBindingsAccessor(),\n      elementHasFocus = ko.observable(elementIsFocused()),\n      handleElementFocusIn = handleElementFocusChange.bind(null, true),\n      handleElementFocusOut = handleElementFocusChange.bind(null, false);\n\n    var interceptor = ko.computed({\n      read: function () {\n        var currentValue = ko.utils.unwrapObservable(observable);\n        if (elementHasFocus()) {\n          return !isNaN(currentValue) &&\n            currentValue !== null &&\n            currentValue !== undefined\n            ? currentValue\n                .toString()\n                .replace('.', Globalize.findClosestCulture().numberFormat['.']) // Displays correct decimal separator for the current culture (so de-DE would format 1.234 as \"1,234\")\n            : null;\n        } else {\n          var format = properties.numberFormat || 'n2',\n            formattedNumber = Globalize.format(currentValue, format);\n\n          return formattedNumber;\n        }\n      },\n      write: function (newValue) {\n        var currentValue = ko.utils.unwrapObservable(observable),\n          numberValue = Globalize.parseFloat(newValue);\n\n        if (!isNaN(numberValue)) {\n          if (numberValue !== currentValue) {\n            // The value has changed so update the observable\n            observable(numberValue);\n          }\n        } else if (newValue.length === 0) {\n          if (properties.isNullable) {\n            // If newValue is a blank string and the isNullable property has been set then nullify the observable\n            observable(null);\n          } else {\n            // If newValue is a blank string and the isNullable property has not been set then set the observable to 0\n            observable(0);\n          }\n        }\n      },\n    });\n\n    ko.utils.registerEventHandler(element, 'focus', handleElementFocusIn);\n    ko.utils.registerEventHandler(element, 'focusin', handleElementFocusIn); // For IE\n    ko.utils.registerEventHandler(element, 'blur', handleElementFocusOut);\n    ko.utils.registerEventHandler(element, 'focusout', handleElementFocusOut); // For IE\n\n    if (element.tagName.toLowerCase() === 'input') {\n      ko.applyBindingsToNode(element, { value: interceptor });\n    } else {\n      ko.applyBindingsToNode(element, { text: interceptor });\n    }\n  },\n};\n")),(0,a.kt)("p",null,"Using this binding handler you just need to drop in a ",(0,a.kt)("inlineCode",{parentName:"p"},"valueNumber")," into your ",(0,a.kt)("inlineCode",{parentName:"p"},"data-bind")," statement where you might previously have used a ",(0,a.kt)("inlineCode",{parentName:"p"},"value")," binding. The binding also has a couple of nice hooks in place which you might find useful:"),(0,a.kt)("dl",null,(0,a.kt)("dt",null,'numberFormat (defaults to "n2")'),(0,a.kt)("dd",null,'allows you to specify a format to display your number with. Eg, "c2" would display your number as a currency to 2 decimal places, "p1" would display your number as a percentage to 1 decimal place etc'),(0,a.kt)("dt",null,"isNullable (defaults to false)"),(0,a.kt)("dd",null,"specifies whether your number should be treated as nullable. If it's not then clearing the elements value will set the underlying observable to 0.")),(0,a.kt)("p",null,'Finally when the element gains focus / becomes active the full underlying value is displayed. (Kind of like Excel - like many an app, the one I\'m working on started life as Excel and the users want to keep some of the nice aspects of Excel\'s UI.) To take a scenario, let\'s imagine we have an input element which is applying the "n1" format. The underlying value backing this is 1.234. The valueNumber binding displays this as "1.2" when the input does not have focus and when the element gains focus the full "1.234" is displayed. Credit where it\u2019s due, this is thanks to ',(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/users/1105996/robert-westerlund"}),"Robert Westerlund")," who was kind enough to respond to a ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/22313546/761388"}),"question of mine on StackOverflow"),"."),(0,a.kt)("p",null,'Finally, here\u2019s a demo using the "de-DE" locale:'),(0,a.kt)("iframe",{width:"100%",height:"400",src:"https://jsfiddle.net/johnny_reilly/jRt3k/embedded/result,js,html",allowFullScreen:"allowFullScreen",frameBorder:"0"}),(0,a.kt)("h2",o({},{id:"ps-globalize-is-a-changing"}),"PS Globalize is a-changing"),(0,a.kt)("p",null,"The version of Globalize used in the binding handler is Globalize v0.1.1. This has been available in various forms for quite some time but as I write this the Globalize plugin is in the process of being ported to the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://cldr.unicode.org/"}),"CLDR"),". As part of that work it looks like the Globalize API will change. When that gets finalized I\u2019ll try and come back and update this."))}d.isMDXComponent=!0},26235:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"the-surprisingly-happy-tale-of-visual",title:"The Surprisingly Happy Tale of Visual Studio Online, Continous Integration and Chutzpah",authors:"johnnyreilly",tags:["Jasmine","TFS","unit testing","javascript","Continuous Integration"],hide_table_of_contents:!1},s=void 0,l={permalink:"/the-surprisingly-happy-tale-of-visual",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-03-17-the-surprisingly-happy-tale-of-visual/index.md",source:"@site/blog/2014-03-17-the-surprisingly-happy-tale-of-visual/index.md",title:"The Surprisingly Happy Tale of Visual Studio Online, Continous Integration and Chutzpah",description:"Going off piste",date:"2014-03-17T00:00:00.000Z",formattedDate:"March 17, 2014",tags:[{label:"Jasmine",permalink:"/tags/jasmine"},{label:"TFS",permalink:"/tags/tfs"},{label:"unit testing",permalink:"/tags/unit-testing"},{label:"javascript",permalink:"/tags/javascript"},{label:"Continuous Integration",permalink:"/tags/continuous-integration"}],readingTime:5.87,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"the-surprisingly-happy-tale-of-visual",title:"The Surprisingly Happy Tale of Visual Studio Online, Continous Integration and Chutzpah",authors:"johnnyreilly",tags:["Jasmine","TFS","unit testing","javascript","Continuous Integration"],hide_table_of_contents:!1},prevItem:{title:"TypeScript this is what I want! (the unfortunate neglect of Instance Methods / callback functions)",permalink:"/typescript-instance-methods"},nextItem:{title:"Knockout + Globalize = valueNumber Binding Handler",permalink:"/knockout-globalize-valuenumber-binding"}},p={authorsImageUrls:[void 0]},u=[{value:"Going off piste",id:"going-off-piste",level:2},{value:"...Try, try, try again...",id:"try-try-try-again",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"going-off-piste"}),"Going off piste"),(0,a.kt)("p",null,"The post that follows is a slightly rambly affair which is pretty much my journal of the first steps of getting up and running with JavaScript unit testing. I will not claim that much of this blog is down to me. In fact in large part is me working my way through ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.com/b/visualstudioalm/archive/2012/07/09/javascript-unit-tests-on-team-foundation-service-with-chutzpah.aspx"}),"Mathew Aniyan's excellent blog post on integrating Chutzpah with TFS"),". But a few deviations from this post have made me think it worth keeping hold of this record for my benefit (if no-one else's)."),(0,a.kt)("p",null,"That's the disclaimers out of the way now..."),(0,a.kt)("h2",o({},{id:"try-try-try-again"}),"...Try, try, try again..."),(0,a.kt)("p",null,"Getting started with JavaScript unit testing has not been the breeze I\u2019d expected. Frankly I\u2019ve found the docs out there not particularly helpful. But if at first you don't succeed then try, try, try again."),(0,a.kt)("p",null,"So after a number of failed attempts I\u2019m going to give it another go. ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.hanselminutes.com/412/getting-started-with-javascript-unit-testing-with-jasmine-and-rushaine-mcbean"}),"Rushaine McBean")," says Jasmine is easiest so I'm going to follow her lead and give it a go."),(0,a.kt)("p",null,"Let\u2019s new up a new (empty) ASP.NET project. Yes, I know ASP.NET has nothing to do with JavaScript unit testing but my end goal is to be able to run JS unit tests in Visual Studio and as part of Continuous Integration. Further to that, I'm anticipating a future where I have a solution that contains JavaScript unit tests and C# unit tests as well. It is indeed a bold and visionary Brave New World. We'll see how far we get."),(0,a.kt)("p",null,"First up, download Jasmine from ",(0,a.kt)("a",o({parentName:"p"},{href:"http://jasmine.github.io/"}),"GitHub")," ","-"," I'll use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/pivotal/jasmine/blob/master/dist/jasmine-standalone-2.0.0.zip"}),"v2.0"),". Unzip it and fire up SpecRunner.html and whaddya know... It works!"),(0,a.kt)("p",null,"As well it might. I\u2019d be worried if it didn\u2019t. So I\u2019ll move the contents of the release package into my empty project. Now let\u2019s see if we can get those tests running inside Visual Studio. I\u2019d heard of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://chutzpah.codeplex.com/"}),"Chutzpah")," which describes itself thusly:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("em",{parentName:"p"},"\u201cChutzpah is an open source JavaScript test runner which enables you to run unit tests using QUnit, Jasmine, Mocha, CoffeeScript and TypeScript.\u201d "))),(0,a.kt)("p",null,"What I\u2019m after is the Chutzpah test adapter for Visual Studio 2012/2013 which can be found ",(0,a.kt)("a",o({parentName:"p"},{href:"http://visualstudiogallery.msdn.microsoft.com/f8741f04-bae4-4900-81c7-7c9bfb9ed1fe"}),"here"),". I download the VSIX and install. Pretty painless. Once I restart Visual Studio I can see my unit tests in the test explorer. Nice! Run them and..."),(0,a.kt)("p",null,"All fail. This makes me sad. All the errors say \u201cCan\u2019t find variable: Player in file\u201d. Hmmm. Why? Dammit I\u2019m actually going to have to read the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://chutzpah.codeplex.com/wikipage?title=Chutzpah%20File%20References&referringTitle=Documentation"}),"documentation"),"... It turns out the issue can be happily resolved by adding these 3 references to the top of PlayerSpec.js:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),'/// <reference path="../src/Player.js" />\n/// <reference path="../src/Song.js" />\n/// <reference path="SpecHelper.js" />\n')),(0,a.kt)("p",null,"Now the tests pass."),(0,a.kt)("p",null,"The question is: can we get this working with Visual Studio Online?"),(0,a.kt)("p",null,"Fortunately another has gone before me. Mathew Aniyan has written a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.com/b/visualstudioalm/archive/2012/07/09/javascript-unit-tests-on-team-foundation-service-with-chutzpah.aspx"}),'superb blog post called "Javascript Unit Tests on Team Foundation Service with Chutzpah"'),". Using this post as a guide (it was written 18 months ago which is frankly aeons in the world of the web) I'm hoping that I'll be able to, without too many tweaks, get Javascript unit tests running on Team Foundation Service / Visual Studio Online ( / insert this weeks rebranding here)."),(0,a.kt)("p",null,'First of all in Visual Studio Online I\u2019ll create a new project called "GettingStartedWithJavaScriptUnitTesting" (using all the default options). Apparently ',(0,a.kt)("em",{parentName:"p"},"\u201cYour project is created and your team is going to absolutely love this.\u201d")," Hmmmm... I think I\u2019ll be judge of that."),(0,a.kt)("p",null,"Let's navigate to the project. I'll fire up Visual Studio by clicking on the \u201cOpen in Visual Studio\u201d link. Once fired up and all the workspace mapping is sorted I\u2019ll move my project into the GettingStartedWithJavaScriptUnitTesting folder that now exists on my machine and add this to source control."),(0,a.kt)("p",null,"Back to Mathew's blog. It suggests renaming Chutzpah.VS2012.vsix to Chutzpah.VS2012.zip and checking certain files into TFS. I think Chutzpah has changed a certain amount since this was written. To be on the safe side I\u2019ll create a new folder in the root of my project called Chutzpah.VS2012 and put the contents of Chutzpah.VS2012.zip in there and add it to TFS (being careful to ensure that no dll\u2019s are excluded)."),(0,a.kt)("p",null,"Then I'll follow steps 3 and 4 from the blog post:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"*","3","."," In Visual Studio, Open Team Explorer & connect to Team Foundation Service. Bring up the Manage Build Controllers dialog. ","[Build \u2013> Manage Build Controllers]"," Select Hosted Build Controller Click on Properties button to bring up the Build Controller Properties dialog."),(0,a.kt)("p",{parentName:"blockquote"},"4","."," Change Version Control Path to custom Assemblies to refer to the folder where you checked in the binaries in step 2."),(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"}))),(0,a.kt)("p",null,"In step 5 the blog tells me to edit my build definition. Well I don\u2019t have one in this new project so let\u2019s click on \u201cNew Build Definition\u201d, create one and then follow step 5:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"*","5","."," In Team Explorer, go to the Builds section and Edit your Build Definition which will run the javascript tests. Click on the Process tab Select the row named Automated Tests. Click on \u2026 button next to the value."),(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"}))),(0,a.kt)("p",null,'Rather than following step 6 (which essentially nukes the running of any .NET tests you might have) I chose to add another row by clicking "Add". In the dialog presented I changed the Test assembly specification to ',"*","*","\\","*",'.js and checked the "Fail build on test failure" checkbox.'),(0,a.kt)("p",null,"Step 7 says:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"*","7","."," Create your Web application in Visual Studio and add your Qunit or Jasmine unit tests to them. ",(0,a.kt)("u",null,"Make sure that the js files (that contain the tests) are getting copied to the build output directory.")),(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"}))),(0,a.kt)("p",null,"The picture below step 7 suggests that you should be setting your test / spec files to have a ",(0,a.kt)("inlineCode",{parentName:"p"},"Copy to Output Directory")," setting of ",(0,a.kt)("inlineCode",{parentName:"p"},"Copy always"),". ",(0,a.kt)("strong",{parentName:"p"},"This did not work for me!!!")," Instead, setting a ",(0,a.kt)("inlineCode",{parentName:"p"},"Build Action")," of ",(0,a.kt)("inlineCode",{parentName:"p"},"Content")," and a ",(0,a.kt)("inlineCode",{parentName:"p"},"Copy to Output Directory")," setting of ",(0,a.kt)("inlineCode",{parentName:"p"},"Do not copy")," did work."),(0,a.kt)("p",null,"Finally I checked everything into source control and queued a build. I honestly did not expect this to work. It couldn\u2019t be this easy could it? And..."),(0,a.kt)("p",null,"Wow! It did! Here\u2019s me cynically expecting some kind of \u201cpermission denied\u201d error and it actually works! Brilliant! Look up in the cloud it says the same thing!"),(0,a.kt)("p",null,"Fantastic!"),(0,a.kt)("p",null,"I realise that I haven\u2019t yet written a single JavaScript unit test of my own and so I\u2019ve still a way to go. What I have done is quietened those voices in my head that said \u201cthere\u2019s not too much point having a unit test suite that isn\u2019t plugged into continuous integration\u201d. Although it's not documented here I'm happy to be able to report that I have been able to follow the self-same instructions for Team Foundation Service / Visual Studio Online and get CI working with TFS 2012 on our build server as well."),(0,a.kt)("p",null,"Having got up and running off the back of other peoples hard work I best try and write some of my own tests now...."))}d.isMDXComponent=!0},83943:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-instance-methods",title:"TypeScript this is what I want! (the unfortunate neglect of Instance Methods / callback functions)",authors:"johnnyreilly",tags:["typescript"],hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-instance-methods",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-04-01-typescript-instance-methods/index.md",source:"@site/blog/2014-04-01-typescript-instance-methods/index.md",title:"TypeScript this is what I want! (the unfortunate neglect of Instance Methods / callback functions)",description:"I was recently reading Jeff Walker's blog post \"Why TypeScript Isn't the Answer\". This is part of series in which Jeff goes through various compile-to-JavaScript technologies including TypeScript, CoffeeScript and Dart and explains his view of why he feels they don't quite hit the mark.",date:"2014-04-01T00:00:00.000Z",formattedDate:"April 1, 2014",tags:[{label:"typescript",permalink:"/tags/typescript"}],readingTime:4.97,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-instance-methods",title:"TypeScript this is what I want! (the unfortunate neglect of Instance Methods / callback functions)",authors:"johnnyreilly",tags:["typescript"],hide_table_of_contents:!1},prevItem:{title:"TypeScript, JSDoc and Intellisense",permalink:"/typescript-jsdoc-and-intellisense"},nextItem:{title:"The Surprisingly Happy Tale of Visual Studio Online, Continous Integration and Chutzpah",permalink:"/the-surprisingly-happy-tale-of-visual"}},p={authorsImageUrls:[void 0]},u=[{value:"Instance Methods to the Rescue!",id:"instance-methods-to-the-rescue",level:2},{value:"<code>Greeter</code> with Instance Methods",id:"greeter-with-instance-methods",level:2},{value:"Updated 02/04/2014 - mixing and matching <code>prototype</code> and Instance Methods",id:"updated-02042014---mixing-and-matching-prototype-and-instance-methods",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I was recently reading ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.walkercoderanger.com/blog/2014/02/typescript-isnt-the-answer/"}),"Jeff Walker's blog post \"Why TypeScript Isn't the Answer\""),". This is part of series in which Jeff goes through various compile-to-JavaScript technologies including TypeScript, CoffeeScript and Dart and explains his view of why he feels they don't quite hit the mark."),(0,a.kt)("p",null,"As a user (and big fan) of TypeScript I read the post with interest and picked up on one particular issue that Jeff mentions:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Classes make the unchanged behaviour of the ",(0,a.kt)("inlineCode",{parentName:"p"},"this")," keyword more confusing. For example, in a class like ",(0,a.kt)("inlineCode",{parentName:"p"},"Greeter")," from the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.typescriptlang.org/Playground"}),"TypeScript playground"),", the use of ",(0,a.kt)("inlineCode",{parentName:"p"},"this")," is confusing:"),(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"class Greeter {\n  greeting: string;\n  constructor(message: string) {\n    this.greeting = message;\n  }\n  greet() {\n    return 'Hello, ' + this.greeting;\n  }\n}\n")),(0,a.kt)("p",{parentName:"blockquote"},"One can\u2019t help but feel the ",(0,a.kt)("inlineCode",{parentName:"p"},"this")," keyword in the methods of ",(0,a.kt)("inlineCode",{parentName:"p"},"Greeter")," should always reference a ",(0,a.kt)("inlineCode",{parentName:"p"},"Greeter")," instance. However, the semantics of this are unchanged from JavaScript:"),(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var greeter = new Greeter('world');\nvar unbound = greeter.greet;\nalert(unbound());\n")),(0,a.kt)("p",{parentName:"blockquote"},"The above code displays \u201cHello, undefined\u201d instead of the naively expected \u201cHello, world\u201d.")),(0,a.kt)("p",null,"Now Jeff is quite correct in everything he says above. However, he's also missing a trick. Or rather, he's missing out on a very useful feature of TypeScript."),(0,a.kt)("h2",o({},{id:"instance-methods-to-the-rescue"}),"Instance Methods to the Rescue!"),(0,a.kt)("p",null,"Still in the early days of TypeScript, the issue Jeff raises had already been identified. (And for what it's worth, this issue wasn't there by mistake - remember TypeScript is quite deliberately a \"superset of JavaScript\".) Happily with the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.com/b/typescript/archive/2013/08/06/announcing-0-9-1.aspx"}),"release of TypeScript 0.9.1"),' a nice remedy was included in the language in the form of "Instance Methods".'),(0,a.kt)("p",null,"Instance Methods are lexically scoped; bound to a specific instance of a JavaScript object. i.e. These methods are ","*",(0,a.kt)("strong",{parentName:"p"},"not"),"*"," vulnerable to the \u201cHello, undefined\u201d issue Jeff raises. To quote the blog post:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"We've relaxed the restrictions on field initializers to now allow ",(0,a.kt)("inlineCode",{parentName:"p"},"'this'"),". This means that classes can now contain both methods on the prototype, and ",(0,a.kt)("strong",{parentName:"p"},"callback functions on the instance"),". The latter are particularly useful when you want to use a member on the class as a callback function, as in the code above. This lets you mix-n-match between \u2018closure\u2019 style and \u2018prototype\u2019 style class member patterns easily.")),(0,a.kt)("h2",o({},{id:"greeter-with-instance-methods"}),(0,a.kt)("inlineCode",{parentName:"h2"},"Greeter")," with Instance Methods"),(0,a.kt)("p",null,"So, if we take the ",(0,a.kt)("inlineCode",{parentName:"p"},"Greeter")," example, how do we apply Instance Methods to it? Well, like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"class Greeter {\n  greeting: string;\n  constructor(message: string) {\n    this.greeting = message;\n  }\n  greet = () => {\n    return 'Hello, ' + this.greeting;\n  };\n}\n")),(0,a.kt)("p",null,"Can you tell the difference? It's subtle. That's right; the mere swapping out of ",(0,a.kt)("inlineCode",{parentName:"p"},"()")," with ",(0,a.kt)("inlineCode",{parentName:"p"},"= () =&gt;")," on the ",(0,a.kt)("inlineCode",{parentName:"p"},"greet")," method takes us from a ",(0,a.kt)("inlineCode",{parentName:"p"},"prototype")," method to an Instance Method."),(0,a.kt)("p",null,"Observant readers will have noticed that we are using TypeScript / ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/arrow_functions"}),"ES6's Arrow Function syntax"),". In fact with that in mind I could actually have gone super-terse if I was so inclined:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"class Greeter {\n  greeting: string;\n  constructor(message: string) {\n    this.greeting = message;\n  }\n  greet = () => 'Hello, ' + this.greeting;\n}\n")),(0,a.kt)("p",null,"But either way, both of the above class declarations compile down to the following JavaScript:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var Greeter = (function () {\n  function Greeter(message) {\n    var _this = this;\n    this.greet = function () {\n      return 'Hello, ' + _this.greeting;\n    };\n    this.greeting = message;\n  }\n  return Greeter;\n})();\n")),(0,a.kt)("p",null,"Which differs from the pre-Instance Methods generated JavaScript:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var Greeter = (function () {\n  function Greeter(message) {\n    this.greeting = message;\n  }\n  Greeter.prototype.greet = function () {\n    return 'Hello, ' + this.greeting;\n  };\n  return Greeter;\n})();\n")),(0,a.kt)("p",null,"As you can see the Instance Methods approach does ","*",(0,a.kt)("strong",{parentName:"p"},"not"),"*"," make use of the ",(0,a.kt)("inlineCode",{parentName:"p"},"prototype")," on ",(0,a.kt)("inlineCode",{parentName:"p"},"Greeter")," to add the method. (As the pre-Instance Methods ",(0,a.kt)("inlineCode",{parentName:"p"},"greet()")," declaration did.) Instead it creates a function directly on the created object and internally uses the ",(0,a.kt)("inlineCode",{parentName:"p"},"_this")," variable inside the Instance Methods. (",(0,a.kt)("inlineCode",{parentName:"p"},"_this")," being a previously captured instance of ",(0,a.kt)("inlineCode",{parentName:"p"},"this"),".)"),(0,a.kt)("p",null,"So with Instance Methods we can repeat Jeff's experiment from earlier:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var greeter = new Greeter('world');\nvar bound = greeter.greet;\nalert(bound());\n")),(0,a.kt)("p",null,"But this time round the code displays \u201cHello, world\u201d and no longer \u201cHello, undefined\u201d."),(0,a.kt)("h2",o({},{id:"updated-02042014---mixing-and-matching-prototype-and-instance-methods"}),"Updated 02/04/2014 - mixing and matching ",(0,a.kt)("inlineCode",{parentName:"h2"},"prototype")," and Instance Methods"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/bgever"}),"Bart Verkoeijen")," made an excellent comment concerning the extra memory that Instance Methods require as opposed to ",(0,a.kt)("inlineCode",{parentName:"p"},"prototype")," methods. Not everyone reads the comments and so I thought I'd add a little suffix to my post."),(0,a.kt)("p",null,"What I\u2019ve come to realise is that it comes down to problem that you\u2019re trying to solve. Instance methods are bulletproof in terms of relying on a specific instance of ",(0,a.kt)("inlineCode",{parentName:"p"},"this")," regardless of how a method is invoked. But for many of my use cases that\u2019s overkill. Let\u2019s take the original (",(0,a.kt)("inlineCode",{parentName:"p"},"prototype")," methods) ",(0,a.kt)("inlineCode",{parentName:"p"},"Greeter")," example:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var Greeter = (function () {\n  function Greeter(message) {\n    this.greeting = message;\n  }\n  Greeter.prototype.greet = function () {\n    return 'Hello, ' + this.greeting;\n  };\n  return Greeter;\n})();\n\nvar greeter = new Greeter('world');\nvar greeter2 = new Greeter('universe');\n\nconsole.log(greeter.greet()); // Logs \"Hello, world\"\nconsole.log(greeter2.greet()); // Logs \"Hello, universe\"\n")),(0,a.kt)("p",null,"As you can see above, provided I invoke my ",(0,a.kt)("inlineCode",{parentName:"p"},"greet")," method in the context of my created object then I can rely on ",(0,a.kt)("inlineCode",{parentName:"p"},"this")," being what I would hope."),(0,a.kt)("p",null,"That being the case my general practice has not been to use exclusively Instance methods ","*",(0,a.kt)("strong",{parentName:"p"},"or"),"*"," ",(0,a.kt)("inlineCode",{parentName:"p"},"prototype")," methods. What I tend to do is start out only with ",(0,a.kt)("inlineCode",{parentName:"p"},"prototype")," methods on my classes and switch them over to be an Instance method if there is an actual need to ensure context. So my TypeScript classes tend to be a combination of ",(0,a.kt)("inlineCode",{parentName:"p"},"prototype")," methods and Instance methods."),(0,a.kt)("p",null,"More often than not the ",(0,a.kt)("inlineCode",{parentName:"p"},"prototype")," methods are just fine. It tends to be where an object is interacting with some kind of presentation framework (Knockout / Angular etc) or being invoked as part of a callback (eg AJAX scenarios) where I need Instance methods."))}d.isMDXComponent=!0},26289:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-jsdoc-and-intellisense",title:"TypeScript, JSDoc and Intellisense",authors:"johnnyreilly",tags:["jquery","JSDoc","typescript"],hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-jsdoc-and-intellisense",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-05-05-typescript-jsdoc-and-intellisense/index.md",source:"@site/blog/2014-05-05-typescript-jsdoc-and-intellisense/index.md",title:"TypeScript, JSDoc and Intellisense",description:"Days of Yore",date:"2014-05-05T00:00:00.000Z",formattedDate:"May 5, 2014",tags:[{label:"jquery",permalink:"/tags/jquery"},{label:"JSDoc",permalink:"/tags/js-doc"},{label:"typescript",permalink:"/tags/typescript"}],readingTime:14.355,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-jsdoc-and-intellisense",title:"TypeScript, JSDoc and Intellisense",authors:"johnnyreilly",tags:["jquery","JSDoc","typescript"],hide_table_of_contents:!1},prevItem:{title:"Team Foundation Server, Continuous Integration and separate projects for JavaScript unit tests",permalink:"/team-foundation-server-continuous-integration-and-javascript-unit-tests-in-unit-test-project"},nextItem:{title:"TypeScript this is what I want! (the unfortunate neglect of Instance Methods / callback functions)",permalink:"/typescript-instance-methods"}},p={authorsImageUrls:[void 0]},u=[{value:"Days of Yore",id:"days-of-yore",level:2},{value:"Definitely Intellisensed",id:"definitely-intellisensed",level:2},{value:"Why <code>jquery.d.ts</code>?",id:"why-jquerydts",level:2},{value:"Turning API documentation into JSDoc",id:"turning-api-documentation-into-jsdoc",level:2},{value:"1. You have 20 seconds to comply (with the API)",id:"1-you-have-20-seconds-to-comply-with-the-api",level:2},{value:"2. <code>String</code> and <code>Array of String</code> setters",id:"2-string-and-array-of-string-setters",level:2},{value:"3. Getter",id:"3-getter",level:2},{value:"4. The <code>Function</code> setter",id:"4-the-function-setter",level:2},{value:"It could be you...",id:"it-could-be-you",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"days-of-yore"}),"Days of Yore"),(0,a.kt)("p",null,'It was my first job. The web was alive and well at this point but still very much in it\'s infancy. Newspapers had only recently moved on from calling it "the information superhighway". No-one was doing ',(0,a.kt)("em",{parentName:"p"},"real")," programming for the web - the desktop was where it was at."),(0,a.kt)("p",null,"As for me, I was writing call centre software. It was all very exciting. Here was the idea: the phone on your desk would start ringing and through the magic of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Telephony_Application_Programming_Interface"}),"TAPI"),' our app would be presented with the telephone number of the dialer. It would then look up that telephone number in the appropriate CRM application and pop the callers details on the screen. You\'d pick up the phone and bellow "why hello Mr Jones!" and either impress the caller with your incredible fore-knowledge of who had rung you or perhaps terrify them with our ',(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Nineteen_Eighty-Four"}),"Brave New Orwellian World"),"."),(0,a.kt)("p",null,"My job was to work out how to call into the APIs of the various CRM applications / databases being used and extract the relevant information. So it goes without saying that I have spent a lot of time with badly documented APIs. Or in fact ",(0,a.kt)("em",{parentName:"p"},"undocumented")," APIs. I know pain my friend..."),(0,a.kt)("p",null,"Hours and days were spent debugging and walking APIs just to find out what they could do and what information they exposed. This, I need hardly say, was dull and tedious work. Having spent longer than I care to remember with no more information on an API than method names has left its mark on me. I am consequently keener than your average dev on documentation and intellisense. When you've stared at the coalface of the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/IBM_Notes"}),"Lotus Notes")," API for 2 weeks with only Dephi 3 as your constant companion you'd feel the same way too. (This was ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/AltaVista"}),"before the days of Google")," and actually being able to find stuff on the internet.)"),(0,a.kt)("p",null,"If you can convey information about the API that you're building then I'd say you're duty-bound to do so. Or at least that it's good manners."),(0,a.kt)("h2",o({},{id:"definitely-intellisensed"}),"Definitely Intellisensed"),(0,a.kt)("p",null,"When I started getting involved with the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped"}),"Definitely Typed project"),' my focus was on giving good Intellisense. Where there was documentation for an API I wanted to get that popping in front of users when they hit the "." key:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"screenshot of intellisense in visual studio",src:n(51718).Z,width:"486",height:"314"})),(0,a.kt)("p",null,"As the above screenshot demonstrates ",(0,a.kt)("a",o({parentName:"p"},{href:"https://devblogs.microsoft.com/typescript/announcing-typescript-0-8-2/"}),"TypeScript supports Intellisense")," through a slightly tweaked implementation of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/JSDoc"}),"JSDoc"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"With 0.8.2, the TypeScript compiler and tools now support JSDoc comments."),(0,a.kt)("p",{parentName:"blockquote"},"In the TypeScript implementation, because types are already part of the system, we allow the JSDoc type annotation to be elided, as in the example above."),(0,a.kt)("p",{parentName:"blockquote"},"You can now document a variety of language constructs (including classes, modules, interfaces, and functions) with comments that become part of the information displayed to the user. We\u2019ve also started extending lib.d.ts, the default JS and DOM API library, with JSDoc comments.")),(0,a.kt)("p",null,"Partly as an exercise in getting better acquainted with TypeScript and partly responding to my instinctive need to have nicely documented APIs I decided to start adding JSDoc comments to the world's most popular typings file ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped/blob/master/jquery/jquery.d.ts"}),(0,a.kt)("inlineCode",{parentName:"a"},"jquery.d.ts")),"."),(0,a.kt)("h2",o({},{id:"why-jquerydts"}),"Why ",(0,a.kt)("inlineCode",{parentName:"h2"},"jquery.d.ts"),"?"),(0,a.kt)("p",null,"Well a number of reasons:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"I used ",(0,a.kt)("inlineCode",{parentName:"li"},"jquery.d.ts")," already myself and I'm a firm believer in ",(0,a.kt)("a",o({parentName:"li"},{href:"https://en.wikipedia.org/wiki/Eating_your_own_dog_food"}),"eating your own dogfood")),(0,a.kt)("li",{parentName:"ol"},"jQuery is well documented. I needed a source of information to power my JSDoc and ",(0,a.kt)("a",{href:"//api.jquery.com"},"api.jquery.com")," had my back."),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"jquery.d.ts")," was widely used. Given how ubiquitous jQuery has become this typing file was unsurprisingly the most popular in the world. That was key for me as I wanted feedback - if I was making a mess of the typings I wanted someone to pitch in and tell me.")),(0,a.kt)("p",null,"Just to digress once more, points #2 and #3 turned out to be of particular note."),(0,a.kt)("p",null,"Concerning point #2, I did find the occasional ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped/pull/1471#issuecomment-31204115"}),"error")," or ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped/pull/1835#issuecomment-37533088"}),"inconsistency")," in the jQuery API documentation. These were definitely the exception rather than the rule though. And thanks to the very helpful ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dmethvin"}),"Dave Methvin")," these actually lead to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jquery/api.jquery.com/pull/460"}),"minor improvements to the jQuery API documentation"),"."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Tweet by @basarat at 8:47 PM on Dec 26, 2013 reading &quot;#TypeScript definitions pointing out errors in JavaScript docs of a project #Jquery : https://github.com/borisyankov/DefinitelyTyped/pull/1471#issuecomment-31204115 caught by @johnny_reilly&quot; original tweet here: https://twitter.com/basarat/status/416309213430689792",src:n(55224).Z,width:"1172",height:"402"})),(0,a.kt)("p",null,"Concerning point #3 I did indeed get feedback. As well as enriching ",(0,a.kt)("inlineCode",{parentName:"p"},"jquery.d.ts")," with JSDoc goodness I also found myself fixing slight errors in the typings. Here and there I would find examples where ",(0,a.kt)("inlineCode",{parentName:"p"},"jquery.d.ts")," was out of line the with API documentation. Where this was the case I would amend the typings to bring them into line - trying to make ",(0,a.kt)("inlineCode",{parentName:"p"},"jquery.d.ts")," entirely API-compliant. This was ",(0,a.kt)("a",{href:"https://github.com/borisyankov/DefinitelyTyped/issues/1499"},"not always popular"),". But despite the heat it generated I think it ended up leading to a better typing file. I'm again grateful for Dave Methvin's thoughtful contributions."),(0,a.kt)("h2",o({},{id:"turning-api-documentation-into-jsdoc"}),"Turning API documentation into JSDoc"),(0,a.kt)("p",null,"I wanted to take an example of API documentation and demonstrate how that can be applied to a typing file with particular focus on how JSDoc comments can be created to drive Intellisense. So let's take everyone's favourite jQuery method: ",(0,a.kt)("inlineCode",{parentName:"p"},"val"),". The documentation of ",(0,a.kt)("inlineCode",{parentName:"p"},"val")," can be found here: ",(0,a.kt)("a",o({parentName:"p"},{href:"http://api.jquery.com/val"}),"api.jquery.com/val")),(0,a.kt)("p",null,"By the way, check out the ","*",(0,a.kt)("em",{parentName:"p"},"entirely"),"*"," intuitive URL. Now you've clocked just how straightforward that is you've probably a fair idea how you could find pretty much any jQuery documentation you might need without recourse to Google. Brilliant!"),(0,a.kt)("p",null,"Let's take a look at what ",(0,a.kt)("inlineCode",{parentName:"p"},"val")," looked like ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped/blob/c98eebb13724b5156f12318b68fc2d875ca6e4a3/jquery/jquery.d.ts#L364-L368"}),"before JSDoc")," in the first version of the typing available on GitHub. (By the way, remember the original ",(0,a.kt)("inlineCode",{parentName:"p"},"jquery.d.ts"),(0,a.kt)("a",o({parentName:"p"},{href:"https://typescript.codeplex.com/sourcecontrol/latest#samples/jquery/jquery.d.ts"})," came out of the TypeScript team"),"):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"val(): any;\nval(value: string[]): JQuery;\nval(value: string): JQuery;\nval(value: number): JQuery;\nval(func: (index: any, value: any) => any): JQuery;\n")),(0,a.kt)("p",null,"And now let's look at ",(0,a.kt)("inlineCode",{parentName:"p"},"jquery.d.ts"),(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped/blob/c259dba094121a389b41c573d5000dda7bdf2092/jquery/jquery.d.ts#L1494-L1545"}),"after JSDoc"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"/**\n * Get the current value of the first element in the set of matched elements.\n */\nval(): any;\n/**\n * Set the value of each element in the set of matched elements.\n *\n * @param value A string of text or an array of strings corresponding to the value of each matched element to set as selected/checked.\n */\nval(value: string): JQuery;\n/**\n * Set the value of each element in the set of matched elements.\n *\n * @param value A string of text or an array of strings corresponding to the value of each matched element to set as selected/checked.\n */\nval(value: string[]): JQuery;\n/**\n * Set the value of each element in the set of matched elements.\n *\n * @param func A function returning the value to set. this is the current element. Receives the index position of the element in the set and the old value as arguments.\n */\nval(func: (index: number, value: string) => string): JQuery;\n/**\n * Set the value of each element in the set of matched elements.\n *\n * @param func A function returning the value to set. this is the current element. Receives the index position of the element in the set and the old value as arguments.\n */\nval(func: (index: number, value: string[]) => string): JQuery;\n/**\n * Set the value of each element in the set of matched elements.\n *\n * @param func A function returning the value to set. this is the current element. Receives the index position of the element in the set and the old value as arguments.\n */\nval(func: (index: number, value: number) => string): JQuery;\n/**\n * Set the value of each element in the set of matched elements.\n *\n * @param func A function returning the value to set. this is the current element. Receives the index position of the element in the set and the old value as arguments.\n */\nval(func: (index: number, value: string) => string[]): JQuery;\n/**\n * Set the value of each element in the set of matched elements.\n *\n * @param func A function returning the value to set. this is the current element. Receives the index position of the element in the set and the old value as arguments.\n */\nval(func: (index: number, value: string[]) => string[]): JQuery;\n/**\n * Set the value of each element in the set of matched elements.\n *\n * @param func A function returning the value to set. this is the current element. Receives the index position of the element in the set and the old value as arguments.\n */\nval(func: (index: number, value: number) => string[]): JQuery;\n")),(0,a.kt)("p",null,"Many changes yes? Let's break it down a little."),(0,a.kt)("h2",o({},{id:"1-you-have-20-seconds-to-comply-with-the-api"}),"1. You have 20 seconds to comply (with the API)"),(0,a.kt)("p",null,"The first thing to note is the ",(0,a.kt)("inlineCode",{parentName:"p"},"number")," setter method:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"val(value: number): JQuery;\n")),(0,a.kt)("p",null,"Let's have a look at the jQuery documentation for the simple setter:"),(0,a.kt)("blockquote",null,(0,a.kt)("h2",o({parentName:"blockquote"},{id:"val-value-"}),(0,a.kt)("a",o({parentName:"h2"},{href:"http://api.jquery.com/val/#val-value"}),(0,a.kt)("inlineCode",{parentName:"a"},".val( value )"))),(0,a.kt)("div",null,(0,a.kt)("strong",null,"value")),(0,a.kt)("div",null,"Type: ",(0,a.kt)("a",{href:"http://api.jquery.com/Types/#String"},"String")," or ",(0,a.kt)("a",{href:"http://api.jquery.com/Types/#Array"},"Array")),(0,a.kt)("div",null,"A string of text or an array of strings corresponding to the value of each matched element to set as selected/checked.")),(0,a.kt)("p",null,"See the problem? There is ","*",(0,a.kt)("em",{parentName:"p"},"no"),"*"," ",(0,a.kt)("inlineCode",{parentName:"p"},"number")," setter. The typings are wrong. So let's remedy this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"<strike>val(value: number): JQuery;</strike>\n")),(0,a.kt)("h2",o({},{id:"2-string-and-array-of-string-setters"}),"2. ",(0,a.kt)("inlineCode",{parentName:"h2"},"String")," and ",(0,a.kt)("inlineCode",{parentName:"h2"},"Array of String")," setters"),(0,a.kt)("p",null,"The documentation states that we have setters which accept ",(0,a.kt)("inlineCode",{parentName:"p"},"String")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"Array of String"),". These are already modeled in the existing typings by the ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"string[]")," overloads:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"val(value: string[]): JQuery;\n    val(value: string): JQuery;\n")),(0,a.kt)("p",null,"So let's enrich these typings with some JSDoc:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"/**\n * Set the value of each element in the set of matched elements.\n *\n * @param value A string of text or an array of strings corresponding to the value of each matched element to set as selected/checked.\n */\nval(value: string): JQuery;\n/**\n * Set the value of each element in the set of matched elements.\n *\n * @param value A string of text or an array of strings corresponding to the value of each matched element to set as selected/checked.\n */\nval(value: string[]): JQuery;\n")),(0,a.kt)("p",null,"If you look you can see we've added a related JSDoc style comment block prior to each overload. The first part of the comment (",(0,a.kt)("em",{parentName:"p"},'"Set the value of..."'),") is the overarching Intellisense that is displayed. Each of the ",(0,a.kt)("inlineCode",{parentName:"p"},"@param")," statements represents each of the parameters and it's associated comment. By comparing the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://api.jquery.com/val/#val-value"}),"API documentation")," to the JSDoc it's pretty clear how the API has been transformed into useful JSDoc."),(0,a.kt)("p",null,"It's worth noting that I could have taken the choice to customise the ",(0,a.kt)("inlineCode",{parentName:"p"},"@param value")," comments based on the overload I was JSDoc-ing. Arguably it would have been more useful to have something like this instead:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"/**\n     * Set the value of each element in the set of matched elements.\n     *\n     * @param value A string of text <strike>or an array of strings</strike> corresponding to the value of each matched element to set as selected/checked.\n     */\n    val(value: string): JQuery;\n    /**\n     * Set the value of each element in the set of matched elements.\n     *\n     * @param value <strike>A string of text or</strike> an array of strings corresponding to the value of each matched element to set as selected/checked.\n     */\n    val(value: string[]): JQuery;\n")),(0,a.kt)("p",null,"After some pondering I decided not to take this approach, just to maintain that close relationship between ",(0,a.kt)("inlineCode",{parentName:"p"},"jquery.d.ts")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"http://api.jquery.com/"}),"api.jquery.com"),". It's open to debate how useful that relationship actually is so I thought I'd just highlight this as a choice I made."),(0,a.kt)("h2",o({},{id:"3-getter"}),"3. Getter"),(0,a.kt)("p",null,"The jQuery documentation for the getter looks like this:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("a",o({parentName:"p"},{href:"http://api.jquery.com/val/#val"}),(0,a.kt)("inlineCode",{parentName:"a"},".val()"))),(0,a.kt)("p",{parentName:"blockquote"},"Returns: ",(0,a.kt)("a",{href:"http://api.jquery.com/Types/#String"},"String")," or ",(0,a.kt)("a",{href:"http://api.jquery.com/Types/#Number"},"Number")," or ",(0,a.kt)("a",{href:"http://api.jquery.com/Types/#Array"},"Array")),(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("strong",{parentName:"p"},"Description: "),"Get the current value of the first element in the set of matched elements.")),(0,a.kt)("p",null,"So the ",(0,a.kt)("inlineCode",{parentName:"p"},"val()")," overload can return a ",(0,a.kt)("inlineCode",{parentName:"p"},"string"),", a ",(0,a.kt)("inlineCode",{parentName:"p"},"number")," or a ",(0,a.kt)("inlineCode",{parentName:"p"},"string[]"),". Unfortunately there is no real way to model that in TypeScript at present due to the absence of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://typescript.codeplex.com/workitem/1364"}),'"union types"'),". Union types are being ",(0,a.kt)("a",o({parentName:"p"},{href:"https://typescript.codeplex.com/discussions/543598#PostDetailsCell_1239340"}),"discussed at present")," but in TypeScript v1.0 world the only viable approach is returning the ",(0,a.kt)("inlineCode",{parentName:"p"},"any")," type. This implies ",(0,a.kt)("inlineCode",{parentName:"p"},"val()")," returns any possible JavaScript value from ",(0,a.kt)("inlineCode",{parentName:"p"},"boolean")," to ",(0,a.kt)("inlineCode",{parentName:"p"},"Function")," and straight on 'til morning. So clearly this isn't accurate but importantly it also allows for the possibility of ",(0,a.kt)("inlineCode",{parentName:"p"},"val()")," returning ",(0,a.kt)("inlineCode",{parentName:"p"},"string"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"number")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"string[]"),"."),(0,a.kt)("p",null,"The final getter typing with JSDoc applied ends up looking like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"/**\n     * Get the current value of the first element in the set of matched elements.\n     */\n    val(): any;\n")),(0,a.kt)("p",null,"As you can see the ",(0,a.kt)("em",{parentName:"p"},'"Get the current value..."')," from the API docs has been used as the overarching Intellisense that is displayed for the getter."),(0,a.kt)("h2",o({},{id:"4-the-function-setter"}),"4. The ",(0,a.kt)("inlineCode",{parentName:"h2"},"Function")," setter"),(0,a.kt)("p",null,"Finally we're going to take a look at the ",(0,a.kt)("inlineCode",{parentName:"p"},"Function")," setter which is documented as follows:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("a",o({parentName:"p"},{href:"http://api.jquery.com/val/#val-functionindex--value"}),(0,a.kt)("inlineCode",{parentName:"a"},".val( function(index, value) )"))),(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("inlineCode",{parentName:"p"},"function(index, value)")),(0,a.kt)("div",null,"Type: ",(0,a.kt)("a",{href:"http://api.jquery.com/Types/#Function"},"Function"),"()"),(0,a.kt)("div",null,"A function returning the value to set. ",(0,a.kt)("code",null,"this")," is the current element. Receives the index position of the element in the set and the old value as arguments.")),(0,a.kt)("p",null,"If you cast your eyes back to the original typings for the ",(0,a.kt)("inlineCode",{parentName:"p"},"Function")," setter you'll see they look like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"val(func: (index: any, value: any) => any): JQuery;\n")),(0,a.kt)("p",null,"This is a good start but it's less accurate than it could be in a number of ways:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"index")," is a ",(0,a.kt)("inlineCode",{parentName:"li"},"number")," ","-"," we needn't keep it as an ",(0,a.kt)("inlineCode",{parentName:"li"},"any")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"value")," is the old value - we know from our getter that this can be a ",(0,a.kt)("inlineCode",{parentName:"li"},"string"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"number")," or ",(0,a.kt)("inlineCode",{parentName:"li"},"string[]"),". So we can lose the ",(0,a.kt)("inlineCode",{parentName:"li"},"any")," in favour of overloads which specify different types for ",(0,a.kt)("inlineCode",{parentName:"li"},"value")," in each."),(0,a.kt)("li",{parentName:"ol"},"The return value of the function is the value that should be set. We know from our other setters that the possible types allowed here are ",(0,a.kt)("inlineCode",{parentName:"li"},"string")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"string[]"),". (And yes I'm as puzzled as you are that the getter can return a ",(0,a.kt)("inlineCode",{parentName:"li"},"number")," but the setter can't set one.) That being the case it makes sense for us to have overloads with functions that return both ",(0,a.kt)("inlineCode",{parentName:"li"},"string")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"string[]"))),(0,a.kt)("p",null,"So, we've got a little tidy up to do for #1 and extra overloads to add for #2 and #3. We're going to replace the single ",(0,a.kt)("inlineCode",{parentName:"p"},"Function")," setter with 3 overloads to cater for #2. Then for #3 we're going to take each of the 3 overloads we've just created and make 2 overloads place of each to handle the different return types. This will lead us with the grand total of 6 overloads to model our ",(0,a.kt)("inlineCode",{parentName:"p"},"Function")," setter!"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"/**\n     * Set the value of each element in the set of matched elements.\n     *\n     * @param func A function returning the value to set. this is the current element. Receives the index position of the element in the set and the old value as arguments.\n     */\n    val(func: (index: number, value: string) => string): JQuery;\n    /**\n     * Set the value of each element in the set of matched elements.\n     *\n     * @param func A function returning the value to set. this is the current element. Receives the index position of the element in the set and the old value as arguments.\n     */\n    val(func: (index: number, value: string[]) => string): JQuery;\n    /**\n     * Set the value of each element in the set of matched elements.\n     *\n     * @param func A function returning the value to set. this is the current element. Receives the index position of the element in the set and the old value as arguments.\n     */\n    val(func: (index: number, value: number) => string): JQuery;\n    /**\n     * Set the value of each element in the set of matched elements.\n     *\n     * @param func A function returning the value to set. this is the current element. Receives the index position of the element in the set and the old value as arguments.\n     */\n    val(func: (index: number, value: string) => string[]): JQuery;\n    /**\n     * Set the value of each element in the set of matched elements.\n     *\n     * @param func A function returning the value to set. this is the current element. Receives the index position of the element in the set and the old value as arguments.\n     */\n    val(func: (index: number, value: string[]) => string[]): JQuery;\n    /**\n     * Set the value of each element in the set of matched elements.\n     *\n     * @param func A function returning the value to set. this is the current element. Receives the index position of the element in the set and the old value as arguments.\n     */\n    val(func: (index: number, value: number) => string[]): JQuery;\n")),(0,a.kt)("p",null,"A cursory glance shows that each of the overloads above shares the same JSDoc. Each has the ",(0,a.kt)("em",{parentName:"p"},'"Set the value..."')," from the API docs as the overarching Intellisense that is displayed for the ",(0,a.kt)("inlineCode",{parentName:"p"},"Function")," setter. And each has the same ",(0,a.kt)("inlineCode",{parentName:"p"},"@param func")," comment as well."),(0,a.kt)("h2",o({},{id:"it-could-be-you"}),"It could be you..."),(0,a.kt)("p",null,"This post is much longer than I ever intended it to be. But I wanted to show how easy it is to create typings with JSDoc to drive Intellisense. For no obvious reason people generally don't make a great deal of use of JSDoc when creating typings. Perhaps the creators have no good source of documentation (a common problem). Or perhaps people are not even aware it's a possibility - they don't know about the TypeScript support of JSDoc. In case it's the latter I think this post was worth writing."))}d.isMDXComponent=!0},88723:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"team-foundation-server-continuous-integration-and-javascript-unit-tests-in-unit-test-project",title:"Team Foundation Server, Continuous Integration and separate projects for JavaScript unit tests",authors:"johnnyreilly",tags:["Jasmine","Visual Studio","Continuous Integration","Team Foundation Server","Chutzpah"],hide_table_of_contents:!1},s=void 0,l={permalink:"/team-foundation-server-continuous-integration-and-javascript-unit-tests-in-unit-test-project",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-05-15-team-foundation-server-continuous-integration-and-javascript-unit-tests-in-unit-test-project/index.md",source:"@site/blog/2014-05-15-team-foundation-server-continuous-integration-and-javascript-unit-tests-in-unit-test-project/index.md",title:"Team Foundation Server, Continuous Integration and separate projects for JavaScript unit tests",description:"Do you like to separate out your unit tests from the project you are testing? I imagine so. My own practice when creating a new project in Visual Studio is to create a separate unit test project alongside whose responsibility is to house unit tests for that new project.",date:"2014-05-15T00:00:00.000Z",formattedDate:"May 15, 2014",tags:[{label:"Jasmine",permalink:"/tags/jasmine"},{label:"Visual Studio",permalink:"/tags/visual-studio"},{label:"Continuous Integration",permalink:"/tags/continuous-integration"},{label:"Team Foundation Server",permalink:"/tags/team-foundation-server"},{label:"Chutzpah",permalink:"/tags/chutzpah"}],readingTime:2.65,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"team-foundation-server-continuous-integration-and-javascript-unit-tests-in-unit-test-project",title:"Team Foundation Server, Continuous Integration and separate projects for JavaScript unit tests",authors:"johnnyreilly",tags:["Jasmine","Visual Studio","Continuous Integration","Team Foundation Server","Chutzpah"],hide_table_of_contents:!1},prevItem:{title:"Migrating from AngularJS to AngularTS - a walkthrough",permalink:"/migrating-from-angularjs-to-angularts"},nextItem:{title:"TypeScript, JSDoc and Intellisense",permalink:"/typescript-jsdoc-and-intellisense"}},p={authorsImageUrls:[void 0]},u=[{value:"Points #1 and #2 in short order",id:"points-1-and-2-in-short-order",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Do you like to separate out your unit tests from the project you are testing? I imagine so. My own practice when creating a new project in Visual Studio is to create a separate unit test project alongside whose responsibility is to house unit tests for that new project."),(0,a.kt)("p",null,"When I check in code for that project I expect the continuous integration build to kick off and, as part of that, the unit tests to be run. When it comes to running .NET tests then Team Foundation Server (and it's cloud counterpart Visual Studio Online) has your back. When it comes to running JavaScript tests then... not so much."),(0,a.kt)("p",null,"This post will set out:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"How to get JavaScript tests to run on TFS / VSO in a continuous integration scenario."),(0,a.kt)("li",{parentName:"ol"},"How to achieve this ","*",(0,a.kt)("strong",{parentName:"li"},"without"),"*"," having to include your tests as part of web project.")),(0,a.kt)("p",null,'To do this I will lean heavily (that\'s fancy language for "rip off entirely") on an ',(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.com/b/visualstudioalm/archive/2012/07/09/javascript-unit-tests-on-team-foundation-service-with-chutzpah.aspx"}),"excellent blog post by Mathew Aniyan")," which covers point #1. My contribution is point #2."),(0,a.kt)("h2",o({},{id:"points-1-and-2-in-short-order"}),"Points #1 and #2 in short order"),(0,a.kt)("p",null,"First of all, install Chutzpah on TFS / VSO. You can do this by following ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.com/b/visualstudioalm/archive/2012/07/09/javascript-unit-tests-on-team-foundation-service-with-chutzpah.aspx"}),"Steps 1 - 6 from Mathew Aniyan's post"),". Instead of following steps 7 and 8 create a new unit test project in your solution."),(0,a.kt)("aside",null,"This unit test project will effectively be a C# project that hosts no real C# code at all. Instead we're going to use it to house JavaScript tests. If there is another way to have a separate project which TFS / VSO can pick up on and run tests in then please let me know. As far as I'm aware though, this is the only game in town."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Edit 29/05/2014:")," Matthew Manela (creator of Chutzpah) has confirmed that this is the correct approach - thanks chap!"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/johnny_reilly"}),"@johnny_reilly")," Nope that is pretty much what you need to do."),(0,a.kt)("p",{parentName:"blockquote"},"\u2014 Matthew Manela (@mmanela) ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/mmanela/statuses/466962743400996864"}),"May 15, 2014"))),(0,a.kt)("script",{async:"",src:"//platform.twitter.com/widgets.js",charSet:"utf-8"}),(0,a.kt)("p",null,'To our unit test project add your JavaScript unit tests. These should be marked in Visual Studio with a Build Action of "Content" and a Copy to Output Directory of "Do not copy". You should be able to run these tests locally using the Visual Studio Chutzpah extension - or indeed in some other JavaScript test runner. Then, and this is the important part, edit the csproj file of your unit test project and add this ',(0,a.kt)("inlineCode",{parentName:"p"},"Import Project")," statement:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),"<Import Project=\"$(VSToolsPath)\\WebApplications\\Microsoft.WebApplication.targets\" Condition=\"'$(VSToolsPath)' != ''\" />\n")),(0,a.kt)("p",null,"Ordering is important in this case. It matters that this new statement sits after the other ",(0,a.kt)("inlineCode",{parentName:"p"},"Import Project")," statements. So you should end up with a csproj file that looks in part like this: (comments added by me for clarity)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'\x3c!-- Pre-existing Import Project statements start --\x3e\n  <Import Project="$(VSToolsPath)\\TeamTest\\Microsoft.TestTools.targets" Condition="Exists(\'$(VSToolsPath)\\TeamTest\\Microsoft.TestTools.targets\')" />\n  <Import Project="$(MSBuildToolsPath)\\Microsoft.CSharp.targets" />\n  \x3c!-- Pre-existing Import Project statements end --\x3e\n\n  \x3c!-- New addition start --\x3e\n  <Import Project="$(VSToolsPath)\\WebApplications\\Microsoft.WebApplication.targets" Condition="\'$(VSToolsPath)\' != \'\'" />\n  \x3c!-- New addition end --\x3e\n')),(0,a.kt)("p",null,"Check in your amended csproj and the unit tests to TFS / VSO. You should see the JavaScript unit tests being run as part of the build."))}d.isMDXComponent=!0},26466:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"migrating-from-angularjs-to-angularts",title:"Migrating from AngularJS to AngularTS - a walkthrough",authors:"johnnyreilly",tags:["Jasmine","typescript","Unit tests","AngularJS"],hide_table_of_contents:!1},s=void 0,l={permalink:"/migrating-from-angularjs-to-angularts",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-06-01-migrating-from-angularjs-to-angularts/index.md",source:"@site/blog/2014-06-01-migrating-from-angularjs-to-angularts/index.md",title:"Migrating from AngularJS to AngularTS - a walkthrough",description:"It started with nuns. Don't all good stories start that way? One of my (many) aunts is a Poor Clare nun. At some point in the distant past I was cajoled into putting together a simple website for her convent. This post is a walkthrough of how to migrate from AngularJS using JavaScript to AngularJS using TypeScript. It just so happens that the AngularJS app in question is the one that belongs to my mother's sister's convent.",date:"2014-06-01T00:00:00.000Z",formattedDate:"June 1, 2014",tags:[{label:"Jasmine",permalink:"/tags/jasmine"},{label:"typescript",permalink:"/tags/typescript"},{label:"Unit tests",permalink:"/tags/unit-tests"},{label:"AngularJS",permalink:"/tags/angular-js"}],readingTime:12.55,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"migrating-from-angularjs-to-angularts",title:"Migrating from AngularJS to AngularTS - a walkthrough",authors:"johnnyreilly",tags:["Jasmine","typescript","Unit tests","AngularJS"],hide_table_of_contents:!1},prevItem:{title:"A folk story wherein we shall find dates, DataAnnotations & data impedance mismatch",permalink:"/dates-DataAnnotations-and-data-impedance-mismatch"},nextItem:{title:"Team Foundation Server, Continuous Integration and separate projects for JavaScript unit tests",permalink:"/team-foundation-server-continuous-integration-and-javascript-unit-tests-in-unit-test-project"}},p={authorsImageUrls:[void 0]},u=[{value:"TL;DR - grab what you need",id:"tldr---grab-what-you-need",level:2},{value:"Background",id:"background",level:2},{value:"Typings",id:"typings",level:2},{value:"Changing JS files to TS files",id:"changing-js-files-to-ts-files",level:2},{value:"Recap",id:"recap",level:2},{value:"TypeScriptify <code>app.ts</code>",id:"typescriptify-appts",level:2},{value:"TypeScriptify <code>siteSectionService.ts</code>",id:"typescriptify-sitesectionservicets",level:2},{value:"TypeScriptify <code>prayerRequestService.ts</code>",id:"typescriptify-prayerrequestservicets",level:2},{value:"TypeScriptify <code>prayerRequestController.ts</code>",id:"typescriptify-prayerrequestcontrollerts",level:2},{value:"TypeScriptify <code>navController.ts</code>",id:"typescriptify-navcontrollerts",level:2},{value:"TypeScriptify <code>mainController.ts</code>",id:"typescriptify-maincontrollerts",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"It started with nuns. Don't all good stories start that way? One of my (many) aunts is a Poor Clare nun. At some point in the distant past I was cajoled into putting together a simple website for her convent. This post is a walkthrough of how to migrate from AngularJS using JavaScript to AngularJS using TypeScript. It just so happens that the AngularJS app in question is the one that belongs to my mother's sister's convent."),(0,a.kt)("h2",o({},{id:"tldr---grab-what-you-need"}),"TL;DR - grab what you need"),(0,a.kt)("p",null,'For reference the complete "before" and "after" projects can be found on GitHub ',(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/AngularJS2AngularTS"}),"here"),". This is available so people can see clearly what changes have been made in the migration."),(0,a.kt)("p",null,"The content of the site is available for ",(0,a.kt)("u",null,"reference only")),(0,a.kt)("p",null,'. (Not that I can really imagine people creating their own "Poor Clares" site and hawking it to convents around the globe but I thought I\'d make the point.)'),(0,a.kt)("h2",o({},{id:"background"}),"Background"),(0,a.kt)("p",null,"I've been quietly maintaining this website / app for quite a while now. It's a very simple site; 95% of it is static content about the convent. The one piece of actual functionality is a page which allows the user of the website to send a prayer request to the nuns at the convent."),(0,a.kt)("p",null,"Behind the scenes this sends 2 emails:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"The first back to the person who submitted the prayer request assuring them that they will be prayed for."),(0,a.kt)("li",{parentName:"ul"},"The second to the convent telling them the details of what the person would like prayer for.")),(0,a.kt)("aside",null,(0,a.kt)("em",null,"It's not accidental that I am not sharing the location of my aunt's website in this post. Given the inherent mischievousness of most developers (I should know, I am one) I harbour a fear that readers of this post might go away and submit many an insincere prayer request (or worse) to the convent. If that's you I don't intend to help you. You're clever, you'll find the site if you are so minded. But please know that the nuns who read any of your prayer requests are wonderful people (nuns get a bad rep) and that they love you. They *",(0,a.kt)("strong",null,"will"),"* pray for you. They're good like that. I appeal to your better nature on this.")),(0,a.kt)("p",null,"Right now you are probably thinking this is an unusual post. Perhaps it is, but bear with me."),(0,a.kt)("p",null,"Over time the website has had many incarnations. It's been table-based layout, it's used Kendo UI, it's used Bootstrap. It's been static HTML, it's been ASP.Net WebForms, it's been ASP.Net MVC and it's currently built using ",(0,a.kt)("strong",{parentName:"p"},"AngularJS")," with ",(0,a.kt)("strong",{parentName:"p"},"MVC")," on the back-end to handle bundling / minification and dispatching of emails."),(0,a.kt)("p",null,"I decided to migrate this AngularJS app to use TypeScript. As I did that I thought I'd document the process for anyone else who might be considering doing something similar. As it happens this is a particularly good candidate for migration as there's a full unit test suite for the app (written with Jasmine). Once I've finished the migration these unit tests should pass, just as they do currently."),(0,a.kt)("p",null,'You are probably thinking to yourself "but TypeScript is just about adding compile-time annotations right? How could the unit tests not pass after migration?" Fair point, well made. Well that is generally true but I have something slightly different planned when we get to the controllers - you\'ll see what I mean...'),(0,a.kt)("p",null,"It's also a good candidate for documenting a walkthrough as it's a particularly small and simple Angular app. It consists of just ",(0,a.kt)("strong",{parentName:"p"},"3 controllers"),", ",(0,a.kt)("strong",{parentName:"p"},"2 services")," and ",(0,a.kt)("strong",{parentName:"p"},"1 app"),"."),(0,a.kt)("p",null,"Before I kick off I thought I'd list a couple of guidelines / caveats on this post:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"I don't intend to say much about the architecture of this application - I want to focus on the migration from JavaScript to TypeScript."),(0,a.kt)("li",{parentName:"ul"},'The choices that I make for the migration path do not necessarily reflect the "one true way". Rather, they are pragmatic choices that I am making - there may be alternatives approaches here and there that could be used instead.'),(0,a.kt)("li",{parentName:"ul"},"I love Visual Studio - it's my IDE of choice and the one I am using as I perform the migration. Some of the points that I will make are Visual Studio specific - I will try and highlight that when appropriate.")),(0,a.kt)("h2",o({},{id:"typings"}),"Typings"),(0,a.kt)("p",null,"The first thing we're going to need to get going are the Angular typing files which can be found on Definitely Typed ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped/tree/master/angularjs"}),"here"),". Since these typings are made available over ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.nuget.org/packages/angularjs.TypeScript.DefinitelyTyped/"}),"NuGet")," I'm going to pull them in with a wave of my magic ",(0,a.kt)("inlineCode",{parentName:"p"},"Install-Package angularjs.TypeScript.DefinitelyTyped"),"."),(0,a.kt)("p",null,"As well as pulling in the typing files Visual Studio 2013 has also made some tweaks to my ",(0,a.kt)("inlineCode",{parentName:"p"},"PoorClaresAngular.csproj")," file which it tells me about."),(0,a.kt)("p",null,"And these are the TypeScript specific additions that Visual Studio has made to ",(0,a.kt)("inlineCode",{parentName:"p"},"PoorClaresAngular.csproj"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<Import\n   Project="$(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion)\\TypeScript\\Microsoft.TypeScript.Default.props"\n   Condition="Exists(\'$(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion)\\TypeScript\\Microsoft.TypeScript.Default.props\')" />\n\n  <TypeScriptToolsVersion>1.0</TypeScriptToolsVersion>\n\n  <Import\n   Project="$(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion)\\TypeScript\\Microsoft.TypeScript.targets"\n   Condition="Exists(\'$(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion)\\TypeScript\\Microsoft.TypeScript.targets\')" />\n')),(0,a.kt)("p",null,"I'm going to add one extra of my own:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),"<TypeScriptNoImplicitAny>True</TypeScriptNoImplicitAny>\n")),(0,a.kt)("p",null,"This prevents you having variables of type ",(0,a.kt)("inlineCode",{parentName:"p"},"any")," in your TypeScript codebase without you implicitly specifying the type. You can live without this but I've found it's useful to catch where you're missing out on the benefit of static typing. Further to that, this option can be particularly useful when performing a migration. It will become obvious why this is the case as we go on."),(0,a.kt)("p",null,"I decline the kind opportunity to further search NuGet as I'm already on my way typing-wise. So let's review what has happened. Below you can see the typing files that have been pulled in and that the project and packages files were amended."),(0,a.kt)("h2",o({},{id:"changing-js-files-to-ts-files"}),"Changing JS files to TS files"),(0,a.kt)("p",null,"This really should be as simple as changing all the JavaScript files underneath the ",(0,a.kt)("inlineCode",{parentName:"p"},"js")," directory to have the suffix ",(0,a.kt)("inlineCode",{parentName:"p"},"ts"),"."),(0,a.kt)("p",null,"And if you're not using Visual Studio it is. But if you are using Visual Studio there's a certain amount of fiddling required to include the generated ",(0,a.kt)("inlineCode",{parentName:"p"},".js")," and ",(0,a.kt)("inlineCode",{parentName:"p"},".js.map")," files associated with each ",(0,a.kt)("inlineCode",{parentName:"p"},".ts")," file. The easiest (hah!) thing to do is to crack open the project and wherever you find a ",(0,a.kt)("inlineCode",{parentName:"p"},'&lt;TypeScriptCompile Include="js\\somePath.ts" /&gt;')," to add in 2 ",(0,a.kt)("inlineCode",{parentName:"p"},"Content")," statements, one for each generated file which states the dependency on the TypeScript file. For example:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<TypeScriptCompile Include="js\\services\\siteSectionService.ts" />\n    <Content Include="js\\services\\siteSectionService.js">\n      <DependentUpon>siteSectionService.ts</DependentUpon>\n    </Content>\n    <Content Include="js\\services\\siteSectionService.js.map">\n      <DependentUpon>siteSectionService.ts</DependentUpon>\n    </Content>\n')),(0,a.kt)("p",null,"It's a bit of a pain to have to do this at the moment. Hopefully the Visual Studio tooling will catch up so this sort of tweaking becomes unnecessary."),(0,a.kt)("h2",o({},{id:"recap"}),"Recap"),(0,a.kt)("p",null,"So, where are we? Well, we've got our project ready for TypeScript, we've pulled in the Angular typings from Definitely Typed and we've turned all our JavaScript files in the ",(0,a.kt)("inlineCode",{parentName:"p"},"js")," directory into TypeScript files."),(0,a.kt)("p",null,"Now we can actually start working through our TypeScript files and ensuring we're all typed correctly. Please note that because I'm working in Visual Studio I get the benefit of implicit referencing; I don't have to explicitly state the typing files each TypeScript file relies on at the head of the file (eg ",(0,a.kt)("inlineCode",{parentName:"p"},'/// &lt;reference path="angularjs/angular.d.ts" /&gt;'),"). If you aren't working in Visual Studio then you'd need to add these yourself."),(0,a.kt)("h2",o({},{id:"typescriptify-appts"}),"TypeScriptify ",(0,a.kt)("inlineCode",{parentName:"h2"},"app.ts")),(0,a.kt)("p",null,"Opening up ",(0,a.kt)("inlineCode",{parentName:"p"},"app.ts")," we're presented with a few red squigglies."),(0,a.kt)("p",null,"These red squigglies are the direct result of my earlier opting in to ",(0,a.kt)("inlineCode",{parentName:"p"},"NoImplicitAny"),". So in my view it's already paid for itself as it's telling me where I could start using typings. So to get things working nicely I'll give ",(0,a.kt)("inlineCode",{parentName:"p"},"$routeProvider")," the type of ",(0,a.kt)("inlineCode",{parentName:"p"},"ng.route.IRouteProvider")," and I'll explicitly specify the type of ",(0,a.kt)("inlineCode",{parentName:"p"},"any")," for the 2 ",(0,a.kt)("inlineCode",{parentName:"p"},"params")," parameters:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),'// ...\n    function ($routeProvider: ng.route.IRouteProvider) {\n\n        function getTheConventTemplateUrl(params: any) {\n            var view = params.view || "home";\n            return "partials/theConvent/" + view + ".html";\n        }\n\n        function getMainTemplateUrl(params: any) {\n            var view = params.view || "home";\n            return "partials/main/" + view + ".html";\n        }\n\n        // ...\n    }\n    // ...\n')),(0,a.kt)("h2",o({},{id:"typescriptify-sitesectionservicets"}),"TypeScriptify ",(0,a.kt)("inlineCode",{parentName:"h2"},"siteSectionService.ts")),(0,a.kt)("p",null,"Opening up ",(0,a.kt)("inlineCode",{parentName:"p"},"siteSectionService.ts")," we're only presented with a single squiggly, and for the same reason as last time."),(0,a.kt)("p",null,"This error is easily remedied by giving ",(0,a.kt)("inlineCode",{parentName:"p"},"path")," the type of ",(0,a.kt)("inlineCode",{parentName:"p"},"string"),"."),(0,a.kt)("p",null,"What's more interesting / challenging is thinking about how we want to enforce the definition of ",(0,a.kt)("inlineCode",{parentName:"p"},"siteSectionService"),". Remember, this is a service and as such it will be re-used elsewhere in the application (in both ",(0,a.kt)("inlineCode",{parentName:"p"},"navController")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"mainController"),"). What we need is an interface that describes what our (revealing module pattern) service exposes:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"'use strict';\n\ninterface ISiteSectionService {\n  getSiteSection: () => string;\n  determineSiteSection: (path: string) => void;\n}\n\nangular.module('poorClaresApp.services').factory(\n  'siteSectionService',\n\n  [\n    // No dependencies at present\n    function (): ISiteSectionService {\n      var siteSection = 'home';\n\n      function getSiteSection() {\n        return siteSection;\n      }\n\n      function determineSiteSection(path: string) {\n        var newSiteSection = 'home';\n\n        if (path.indexOf('/theConvent/') !== -1) {\n          newSiteSection = 'theConvent';\n        } else if (path !== '/') {\n          newSiteSection = 'main';\n        }\n\n        siteSection = newSiteSection;\n      }\n\n      return {\n        getSiteSection: getSiteSection,\n        determineSiteSection: determineSiteSection,\n      };\n    },\n  ]\n);\n")),(0,a.kt)("p",null,"As you can see the ",(0,a.kt)("inlineCode",{parentName:"p"},"ISiteSectionService ")," interface is marked as the return type of the function. This ensures that what we return from the function satisfies that definition. Also, it allows us to re-use that interface elsewhere (as we will do later)."),(0,a.kt)("h2",o({},{id:"typescriptify-prayerrequestservicets"}),"TypeScriptify ",(0,a.kt)("inlineCode",{parentName:"h2"},"prayerRequestService.ts")),(0,a.kt)("p",null,"Opening up ",(0,a.kt)("inlineCode",{parentName:"p"},"prayerRequestService.ts")," we're again in ",(0,a.kt)("inlineCode",{parentName:"p"},"NoImplicitAny")," country."),(0,a.kt)("p",null,"This is fixed up by defining ",(0,a.kt)("inlineCode",{parentName:"p"},"$http")," as ",(0,a.kt)("inlineCode",{parentName:"p"},"ng.IHttpService")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"email")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"prayFor")," as ",(0,a.kt)("inlineCode",{parentName:"p"},"string"),"."),(0,a.kt)("p",null,"As with ",(0,a.kt)("inlineCode",{parentName:"p"},"siteSectionService")," we need to create an interface to define what ",(0,a.kt)("inlineCode",{parentName:"p"},"prayerRequestService")," exposes. This leaves us with this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"'use strict';\n\ninterface IPrayerRequestService {\n  sendPrayerRequest: (\n    email: string,\n    prayFor: string\n  ) => ng.IPromise<{\n    success: boolean;\n    text: string;\n  }>;\n}\n\nangular.module('poorClaresApp.services').factory(\n  'prayerRequestService',\n\n  [\n    '$http',\n    function ($http: ng.IHttpService): IPrayerRequestService {\n      var url = '/PrayerRequest';\n\n      function sendPrayerRequest(email: string, prayFor: string) {\n        var params = { email: email, prayFor: prayFor };\n\n        return $http.post(url, params).then(function (response) {\n          return {\n            success: response.data.success,\n            text: response.data.text,\n          };\n        });\n      }\n\n      return {\n        sendPrayerRequest: sendPrayerRequest,\n      };\n    },\n  ]\n);\n")),(0,a.kt)("h2",o({},{id:"typescriptify-prayerrequestcontrollerts"}),"TypeScriptify ",(0,a.kt)("inlineCode",{parentName:"h2"},"prayerRequestController.ts")),(0,a.kt)("p",null,"Opening up ",(0,a.kt)("inlineCode",{parentName:"p"},"prayerRequestController.ts")," leads me to the conclusion that I have ",(0,a.kt)("strong",{parentName:"p"},"no interesting way left")," of telling you that we once more need to supply types for our parameters. Let's take it as read that the same will happen on all remaining files as well eh? Hopefully by now it's fairly clear that this option is useful, even if only for a migration. I say this because using it forces you to think about what typings should be applied to your code."),(0,a.kt)("p",null,"We'll define ",(0,a.kt)("inlineCode",{parentName:"p"},"$scope")," as ",(0,a.kt)("inlineCode",{parentName:"p"},"ng.IScope"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"prayerRequestService")," as ",(0,a.kt)("inlineCode",{parentName:"p"},"IPrayerRequestService")," (which we created just now) and ",(0,a.kt)("inlineCode",{parentName:"p"},"prayerRequest")," as ",(0,a.kt)("inlineCode",{parentName:"p"},"{ email: string; prayFor: string }"),". Which leaves me with this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"'use strict';\n\nangular.module('poorClaresApp.controllers').controller(\n  'PrayerRequestController',\n\n  [\n    '$scope',\n    'prayerRequestService',\n    function ($scope: ng.IScope, prayerRequestService: IPrayerRequestService) {\n      var vm = this;\n\n      vm.send = function (prayerRequest: { email: string; prayFor: string }) {\n        vm.message = {\n          success: true,\n          text: 'Sending...',\n        };\n\n        prayerRequestService\n          .sendPrayerRequest(prayerRequest.email, prayerRequest.prayFor)\n          .then(function (response) {\n            vm.message = {\n              success: response.success,\n              text: response.text,\n            };\n          })\n          .then(null, function (error) {\n            // IE 8 friendly alias for catch\n            vm.message = {\n              success: false,\n              text: 'Sorry your email was not sent',\n            };\n          });\n      };\n    },\n  ]\n);\n")),(0,a.kt)("p",null,"I could move on but let's go for bonus points (and now you'll see why the unit test suite is so handy). To quote the Angular documentation:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"In Angular, a Controller is a JavaScript constructor function that is used to augment the Angular Scope.")),(0,a.kt)("p",null,"So let's see if we can swap over our vanilla contructor function for a TypeScript class. This will (in my view) better express the intention of the code. To do this I am essentially following the example laid down by my Definitely Typed colleague ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/basarat"}),"Basarat"),". I highly recommend his ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.youtube.com/watch?v=WdtVn_8K17E"}),"screencast on the topic"),". Also kudos to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/andrewdavey"}),"Andrew Davey")," whose ",(0,a.kt)("a",o({parentName:"p"},{href:"http://aboutcode.net/2013/10/20/typescript-angularjs-controller-classes.html"}),"post on the topic")," also fed into this."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"'use strict';\n\nmodule poorClaresApp.controllers {\n  class PrayerRequestController {\n    static $inject = ['$scope', 'prayerRequestService'];\n    constructor(\n      private $scope: ng.IScope,\n      private prayerRequestService: IPrayerRequestService\n    ) {}\n\n    message: { success: boolean; text: string };\n\n    send(prayerRequest: { email: string; prayFor: string }) {\n      this.message = {\n        success: true,\n        text: 'Sending...',\n      };\n\n      this.prayerRequestService\n        .sendPrayerRequest(prayerRequest.email, prayerRequest.prayFor)\n        .then((response) => {\n          this.message = {\n            success: response.success,\n            text: response.text,\n          };\n        })\n        .then(null, (error) => {\n          // IE 8 friendly alias for catch\n          this.message = {\n            success: false,\n            text: 'Sorry your email was not sent',\n          };\n        });\n    }\n  }\n\n  angular\n    .module('poorClaresApp.controllers')\n    .controller('PrayerRequestController', PrayerRequestController);\n}\n")),(0,a.kt)("p",null,"My only reservation with this approach is that we have to declare the TypeScript class outside the ",(0,a.kt)("inlineCode",{parentName:"p"},"angular.module...")," statement. To avoid cluttering up global scope I've placed our class in a module called ",(0,a.kt)("inlineCode",{parentName:"p"},"poorClaresApp.controllers")," which maps nicely to our Angular module name. It would be nice if I could place the class definition in an ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Immediately-invoked_function_expression"}),"IIFE")," to completely keep this completely isolated but TypeScript doesn't allow for that syntax (for reasons I'm unclear about - the output would be legal JavaScript)."),(0,a.kt)("p",null,"For a small class this seems to add a little noise but as classes grow in complexity I think this approach will quickly start to pay dividends. There are a few things worth noting about the above approach:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"The required injectable parameters have moved into the class definition in the form of the ",(0,a.kt)("inlineCode",{parentName:"li"},"static $inject")," statement. I personally like that this no longer sits outside the code it relates to."),(0,a.kt)("li",{parentName:"ul"},'Because we\'re using TypeScript arrow functions (which preserve the outer "this" context) we are now free to dispose of the ',(0,a.kt)("inlineCode",{parentName:"li"},"var vm = this;")," mechanism we're were previously using for the same purpose. Much more intuitive code to my mind."),(0,a.kt)("li",{parentName:"ul"},"We are not actually using ",(0,a.kt)("inlineCode",{parentName:"li"},"$scope")," at all in this controller - maybe it should be removed entirely in the long run.")),(0,a.kt)("h2",o({},{id:"typescriptify-navcontrollerts"}),"TypeScriptify ",(0,a.kt)("inlineCode",{parentName:"h2"},"navController.ts")),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"navController")," can be simply converted like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"'use strict';\n\ninterface INavControllerScope extends ng.IScope {\n  isCollapsed: boolean;\n  siteSection: string;\n}\n\nangular.module('poorClaresApp.controllers').controller(\n  'NavController',\n\n  [\n    '$scope',\n    'siteSectionService',\n    function (\n      $scope: INavControllerScope,\n      siteSectionService: ISiteSectionService\n    ) {\n      $scope.isCollapsed = true;\n      $scope.siteSection = siteSectionService.getSiteSection();\n\n      $scope.$watch(\n        siteSectionService.getSiteSection,\n        function (newValue, oldValue) {\n          $scope.siteSection = newValue;\n        }\n      );\n    },\n  ]\n);\n")),(0,a.kt)("p",null,"I'd draw your attention to the creation of a the ",(0,a.kt)("inlineCode",{parentName:"p"},"INavControllerScope")," interface that extends the default Angular $scope of ",(0,a.kt)("inlineCode",{parentName:"p"},"ng.IScope")," with 2 extra properties."),(0,a.kt)("p",null,"Let's also switch this over to the class based approach (there is less of a reason to on this occasion just looking at the size of the codebase but I'm all about consistency of approach):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"'use strict';\n\nmodule poorClaresApp.controllers {\n  interface INavControllerScope extends ng.IScope {\n    isCollapsed: boolean;\n    siteSection: string;\n  }\n\n  class NavController {\n    static $inject = ['$scope', 'siteSectionService'];\n    constructor(\n      private $scope: INavControllerScope,\n      private siteSectionService: ISiteSectionService\n    ) {\n      $scope.isCollapsed = true;\n      $scope.siteSection = siteSectionService.getSiteSection();\n\n      $scope.$watch(\n        siteSectionService.getSiteSection,\n        function (newValue, oldValue) {\n          $scope.siteSection = newValue;\n        }\n      );\n    }\n  }\n\n  angular\n    .module('poorClaresApp.controllers')\n    .controller('NavController', NavController);\n}\n")),(0,a.kt)("h2",o({},{id:"typescriptify-maincontrollerts"}),"TypeScriptify ",(0,a.kt)("inlineCode",{parentName:"h2"},"mainController.ts")),(0,a.kt)("p",null,"Finally, ",(0,a.kt)("inlineCode",{parentName:"p"},"mainController")," can be converted as follows:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"'use strict';\n\nangular.module('poorClaresApp.controllers').controller(\n  'MainController',\n\n  [\n    '$location',\n    'siteSectionService',\n    function (\n      $location: ng.ILocationService,\n      siteSectionService: ISiteSectionService\n    ) {\n      siteSectionService.determineSiteSection($location.path());\n    },\n  ]\n);\n")),(0,a.kt)("p",null,"Again it's just a case of assigning the undeclared types. For completeness lets also switch this over to the class based approach:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"'use strict';\n\nmodule poorClaresApp.controllers {\n  class MainController {\n    static $inject = ['$location', 'siteSectionService'];\n    constructor(\n      private $location: ng.ILocationService,\n      private siteSectionService: ISiteSectionService\n    ) {\n      siteSectionService.determineSiteSection($location.path());\n    }\n  }\n\n  angular\n    .module('poorClaresApp.controllers')\n    .controller('MainController', MainController);\n}\n")))}d.isMDXComponent=!0},90805:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"dates-DataAnnotations-and-data-impedance-mismatch",title:"A folk story wherein we shall find dates, DataAnnotations & data impedance mismatch",authors:"johnnyreilly",tags:["Date"],hide_table_of_contents:!1},s=void 0,l={permalink:"/dates-DataAnnotations-and-data-impedance-mismatch",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-06-20-dates-DataAnnotations-and-data-impedance-mismatch/index.md",source:"@site/blog/2014-06-20-dates-DataAnnotations-and-data-impedance-mismatch/index.md",title:"A folk story wherein we shall find dates, DataAnnotations & data impedance mismatch",description:"If you ever take a step back from what you're doing it can sometimes seem pretty abstract. Here's an example. I was looking at an issue in an app that I was supporting. The problem concerned a field which was to store a date value. Let's call it, for the sake of argument, valuation_date. (Clearly in reality the field name was entirely different... Probably.) This field was supposed to represent a specific date, like June 15th 2012 or 19th August 2014. To be clear, a date and \\*not\\* in any way, a time.",date:"2014-06-20T00:00:00.000Z",formattedDate:"June 20, 2014",tags:[{label:"Date",permalink:"/tags/date"}],readingTime:4.04,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"dates-DataAnnotations-and-data-impedance-mismatch",title:"A folk story wherein we shall find dates, DataAnnotations & data impedance mismatch",authors:"johnnyreilly",tags:["Date"],hide_table_of_contents:!1},prevItem:{title:"HotTowel-Angular meet TypeScript",permalink:"/hottowel-angular-meet-typescript"},nextItem:{title:"Migrating from AngularJS to AngularTS - a walkthrough",permalink:"/migrating-from-angularjs-to-angularts"}},p={authorsImageUrls:[void 0]},u=[{value:"A Primitive Problem",id:"a-primitive-problem",level:2},{value:"An Attribute Solution",id:"an-attribute-solution",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"If you ever take a step back from what you're doing it can sometimes seem pretty abstract. Here's an example. I was looking at an issue in an app that I was supporting. The problem concerned a field which was to store a date value. Let's call it, for the sake of argument, ",(0,a.kt)("inlineCode",{parentName:"p"},"valuation_date"),". (Clearly in reality the field name was entirely different... Probably.) This field was supposed to represent a specific date, like June 15th 2012 or 19th August 2014. To be clear, a date and ","*",(0,a.kt)("strong",{parentName:"p"},"not"),"*"," in any way, a time."),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"valuation_date")," was stored in a SQL database as a ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-gb/library/ms187819.aspx"}),(0,a.kt)("inlineCode",{parentName:"a"},"datetime")),". That's right a date with a time portion. I've encountered this sort of scenario many times on systems I've inherited. Although there is a ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-gb/library/bb630352.aspx"}),(0,a.kt)("inlineCode",{parentName:"a"},"date"))," type in SQL it's pretty rarely used. I think it only shipped in SQL Server with 2008 which may go some way to explaining this. Anyway, I digress..."),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"valuation_date")," was read into a field in a C# application called ",(0,a.kt)("inlineCode",{parentName:"p"},"ValuationDate")," which was of type ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-us/library/system.datetime.aspx"}),(0,a.kt)("inlineCode",{parentName:"a"},"DateTime")),". As the name suggests this is also a date with a time portion. After a travelling through various layers of application this ended up being serialized as JSON and sent across the wire where it became a JavaScript variable by the name of ",(0,a.kt)("inlineCode",{parentName:"p"},"valuationDate")," which had the type ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date"}),(0,a.kt)("inlineCode",{parentName:"a"},"Date")),". Despite the deceptive name this is also, you guessed it, a date with a time portion. (Fine naming work there JavaScript!)"),(0,a.kt)("p",null,"You can probably guess where I'm going with this... Despite our (cough) rock solid naming convention, the situation had arisen where actual datetimes had snuck in. That's right, in the wilds of production, records with ",(0,a.kt)("inlineCode",{parentName:"p"},"valuation_date"),"s with time components had been spotted. My mission was to hunt them, kill them and stop them reproducing..."),(0,a.kt)("h2",o({},{id:"a-primitive-problem"}),"A Primitive Problem"),(0,a.kt)("p",null,"Dates is a sticky topic in many languages. As I mentioned, SQL Server has a ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-gb/library/bb630352.aspx"}),(0,a.kt)("inlineCode",{parentName:"a"},"date"))," data type. C# has ",(0,a.kt)("a",o({parentName:"p"},{href:"http://msdn.microsoft.com/en-gb/library/system.datetime.aspx"}),(0,a.kt)("inlineCode",{parentName:"a"},"DateTime")),". If you want to operate on Dates alone then you're best off talking looking at Jon Skeet's ",(0,a.kt)("a",o({parentName:"p"},{href:"http://nodatime.org/"}),"NodaTime")," ","-"," though most people start with ",(0,a.kt)("inlineCode",{parentName:"p"},"DateTime")," and stick with it. (After all, it's native.) As to JavaScript, well primitive-wise there's no alternative to ",(0,a.kt)("inlineCode",{parentName:"p"},"Date")," ","-"," but ",(0,a.kt)("a",o({parentName:"p"},{href:"http://momentjs.com/"}),(0,a.kt)("inlineCode",{parentName:"a"},"Moment.js"))," may help."),(0,a.kt)("p",null,"My point is that it is a long standing issue in the development world. We represent data in types that aren't entirely meant for the purpose that they are used. It's not just restricted to dates, numbers have a comparable story around the issue of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://csharpindepth.com/Articles/General/Decimal.aspx"}),"decimals and doubles"),". As a result of data type issues, developers experience problems. Like the one I was facing."),(0,a.kt)("h2",o({},{id:"an-attribute-solution"}),"An Attribute Solution"),(0,a.kt)("p",null,"The source of the problem turned out to be the string JavaScript ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date"}),(0,a.kt)("inlineCode",{parentName:"a"},"Date constructor"))," in an earlier version of Internet Explorer. The fix was switching away from using the JavaScript Date constructor in favour of using Moment.js's more dependable ability to parse strings into dates. Happy days we're working once more! Some quick work to put together a SQL script to fix up the data and we have ourselves our patch!"),(0,a.kt)("p",null,"But we didn't want to get bitten again. We wanted ourselves a little ",(0,a.kt)("a",o({parentName:"p"},{href:"http://dictionary.cambridge.org/dictionary/british/belt-and-braces"}),"belts and braces"),". What do do? Hang on a minute, lads \u2013 I've got a great idea... It's ",(0,a.kt)("inlineCode",{parentName:"p"},'<a href="http://msdn.microsoft.com/en-us/library/system.componentmodel.dataannotations.validationattribute(v=vs.110).aspx">ValidationAttribute</a>')," time!"),(0,a.kt)("p",null,"We whipped ourselves up an attribute that looked like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.ComponentModel.DataAnnotations;\nusing System.Globalization;\n\nnamespace My.Attributes\n{\n    [AttributeUsage(AttributeTargets.Property | AttributeTargets.Field, Inherited = false, AllowMultiple = false)]\n    public class DateOnlyAttribute: ValidationAttribute\n    {\n        protected override ValidationResult IsValid(object value, ValidationContext validationContext)\n        {\n            if (value != null)\n            {\n                if (value is DateTime)\n                {\n                    // Date but not Time check\n                    var date = (DateTime) value;\n                    if (date.TimeOfDay != TimeSpan.Zero)\n                    {\n                        return new ValidationResult(date.ToString("O", CultureInfo.InvariantCulture) + " is not a date - it is a date with a time", new[] { validationContext.MemberName });\n                    }\n                }\n                else\n                {\n                    return new ValidationResult("DateOnlyAttribute can only be used on DateTime? and DateTime", new[] { validationContext.MemberName });\n                }\n            }\n\n            return ValidationResult.Success;\n        }\n    }\n}\n')),(0,a.kt)("p",null,"This attribute does 2 things:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Most importantly it fails validation for any ",(0,a.kt)("inlineCode",{parentName:"li"},"DateTime")," or ",(0,a.kt)("inlineCode",{parentName:"li"},"DateTime?")," that includes a time portion. It only allows through DateTimes where the clock strikes midnight. It's optimised for Cinderella."),(0,a.kt)("li",{parentName:"ol"},"It fails validation if the attribute is applied to any property which is not a ",(0,a.kt)("inlineCode",{parentName:"li"},"DateTime")," or ",(0,a.kt)("inlineCode",{parentName:"li"},"DateTime?"),".")),(0,a.kt)("p",null,"You can decorate ",(0,a.kt)("inlineCode",{parentName:"p"},"DateTime")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"DateTime?")," properties on your model with this attribute like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"namespace My.Models\n{\n    public class ImAModelYouKnowWhatIMean\n    {\n        public int Id { get; set; }\n\n        [DateOnlyAttribute]\n        public DateTime ValuationDate { get; set; }\n\n        // Other properties...\n    }\n}\n")),(0,a.kt)("p",null,"And if you're using MVC (or anything that makes use of the validation data annotations) then you'll now find that you are nicely protected from DateTimes masquerading as dates. Should they show up you'll find that ",(0,a.kt)("inlineCode",{parentName:"p"},"ModelState.IsValid")," is false and you can kick them to the curb with alacrity!"))}d.isMDXComponent=!0},68552:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"hottowel-angular-meet-typescript",title:"HotTowel-Angular meet TypeScript",authors:"johnnyreilly",tags:["typescript","AngularJS"],hide_table_of_contents:!1},s=void 0,l={permalink:"/hottowel-angular-meet-typescript",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-07-03-hottowel-angular-meet-typescript/index.md",source:"@site/blog/2014-07-03-hottowel-angular-meet-typescript/index.md",title:"HotTowel-Angular meet TypeScript",description:"I've recently ported John Papa's popular Hot Towel Angular SPA Template to TypeScript. Why? Because it was there.",date:"2014-07-03T00:00:00.000Z",formattedDate:"July 3, 2014",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"AngularJS",permalink:"/tags/angular-js"}],readingTime:2.72,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"hottowel-angular-meet-typescript",title:"HotTowel-Angular meet TypeScript",authors:"johnnyreilly",tags:["typescript","AngularJS"],hide_table_of_contents:!1},prevItem:{title:"AngularJS meet ASP.Net Server Validation",permalink:"/angularjs-meet-aspnet-server-validation"},nextItem:{title:"A folk story wherein we shall find dates, DataAnnotations & data impedance mismatch",permalink:"/dates-DataAnnotations-and-data-impedance-mismatch"}},p={authorsImageUrls:[void 0]},u=[{value:"What is this port you speak of?",id:"what-is-this-port-you-speak-of",level:2},{value:"What&#39;s in the repo?",id:"whats-in-the-repo",level:2},{value:"1. sidebar.js&#39;s <code>getNavRoutes</code>",id:"1-sidebarjss-getnavroutes",level:3},{value:"2. common.js&#39;s <code>$broadcast</code>",id:"2-commonjss-broadcast",level:3},{value:"If you want to use this",id:"if-you-want-to-use-this",level:2},{value:"Thanks",id:"thanks",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I've recently ported John Papa's popular ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnpapa/HotTowel-Angular"}),"Hot Towel Angular SPA Template")," to TypeScript. Why? ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/George_Mallory"}),"Because it was there.")),(0,a.kt)("p",null,"If you'd like to read more about HotTowel-Angular then have a read of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.johnpapa.net/hot-towel-angular/"}),"John Papa's post"),". You can find my port on GitHub ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/HotTowel-Angular-TypeScript"}),"here"),"."),(0,a.kt)("h2",o({},{id:"what-is-this-port-you-speak-of"}),"What is this port you speak of?"),(0,a.kt)("p",null,"It is ",(0,a.kt)("strong",{parentName:"p"},"intentionally")," a \"bare bones\" port of the HotTowel-Angular JavaScript code across to TypeScript. It's essentially the same code as John's - just with added type annotations (and yes it is ",(0,a.kt)("inlineCode",{parentName:"p"},"noImplicitAny")," compliant)."),(0,a.kt)("p",null,"You could, if you wanted to, go much further. You could start using a whole host of TypeScripts functionality: modules / classes / arrow functions... the whole shebang. But my port is deliberately not that; I didn't want to scare your horses... I wanted you to see how easy it is to move from JS to TS. And I'm standing on the shoulders of that great giant ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/john_papa"}),"John Papa")," for that purpose."),(0,a.kt)("p",null,"If you wanted an example of how you might go further in an Angular port to TypeScript then you could take a look at my ",(0,a.kt)("a",o({parentName:"p"},{href:"/migrating-from-angularjs-to-angularts"}),"previous post")," on the topic."),(0,a.kt)("h2",o({},{id:"whats-in-the-repo"}),"What's in the repo?"),(0,a.kt)("p",null,"The repo contains the contents of HotTowel-Angular's app folder, with each JavaScript file converted over to TypeScript. The compiled JavaScript files are also included so that you can compare just how similar the compiled JavaScript is to John's original code."),(0,a.kt)("p",null,"In fact there are only 2 differences in the end:"),(0,a.kt)("h3",o({},{id:"1-sidebarjss-getnavroutes"}),"1","."," sidebar.js's ",(0,a.kt)("inlineCode",{parentName:"h3"},"getNavRoutes")),(0,a.kt)("p",null,"...had the filtering changed from this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"return r.config.settings && r.config.settings.nav;\n")),(0,a.kt)("p",null,"to this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"return r.config.settings && r.config.settings.nav ? true : false;\n")),(0,a.kt)("p",null,"This was necessary as TypeScript insists that the array ",(0,a.kt)("inlineCode",{parentName:"p"},"filter")," predicate returns a ",(0,a.kt)("inlineCode",{parentName:"p"},"boolean"),". John's original method returns a number (",(0,a.kt)("inlineCode",{parentName:"p"},"nav"),"'s value to be clear) which actually seems to work fine. My assumption is that JavaScript's filter method is happy with a truth-y / false-y test which John's implementation would satisfy."),(0,a.kt)("h3",o({},{id:"2-commonjss-broadcast"}),"2","."," common.js's ",(0,a.kt)("inlineCode",{parentName:"h3"},"$broadcast")),(0,a.kt)("p",null,"...had to be given a rest parameter to satisfy the TS compiler. John's original method exposed no parameters as it just forwards on whatever arguments are passed to it. This means that ",(0,a.kt)("inlineCode",{parentName:"p"},"$broadcast")," has a bit of unused code in the head of the generated method:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var args = [];\nfor (var _i = 0; _i < arguments.length - 0; _i++) {\n  args[_i] = arguments[_i + 0];\n}\n")),(0,a.kt)("h2",o({},{id:"if-you-want-to-use-this"}),"If you want to use this"),(0,a.kt)("p",null,"Then simply follow the instructions for installing ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnpapa/HotTowel-Angular"}),"HotTowel-Angular")," and then drop this repo's app folder over the one just created when HotTowel-Angular was installed. If you're using Visual Studio then make sure that you include the new TS files into your project and give them the ",(0,a.kt)("inlineCode",{parentName:"p"},"BuildAction")," of ",(0,a.kt)("inlineCode",{parentName:"p"},"TypeScriptCompile"),"."),(0,a.kt)("p",null,"You'll need the following NuGet packages for the relevant DefinitelyTyped Typings:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),"Install-Package angularjs.TypeScript.DefinitelyTyped\n    Install-Package angular-ui-bootstrap.TypeScript.DefinitelyTyped\n    Install-Package jquery.TypeScript.DefinitelyTyped\n    Install-Package spin.TypeScript.DefinitelyTyped\n    Install-Package toastr.TypeScript.DefinitelyTyped\n")),(0,a.kt)("p",null,"And you're good to go. If you're not using Visual Studio then you may need to add in some ",(0,a.kt)("inlineCode",{parentName:"p"},'&lt;reference path="angular.d.ts" /&gt;')," etc. statements to the TypeScript files as well."),(0,a.kt)("p",null,"If you're interested in the specific versions of the typings that I used then you can find them in the ",(0,a.kt)("inlineCode",{parentName:"p"},"packages.config")," of the repo."),(0,a.kt)("h2",o({},{id:"thanks"}),"Thanks"),(0,a.kt)("p",null,"To John Papa for creating HotTowel-Angular. Much love."),(0,a.kt)("p",null,"And my mum too... Just because."))}d.isMDXComponent=!0},84848:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"angularjs-meet-aspnet-server-validation",title:"AngularJS meet ASP.Net Server Validation",authors:"johnnyreilly",tags:["asp.net","typescript","AngularJS"],hide_table_of_contents:!1},s=void 0,l={permalink:"/angularjs-meet-aspnet-server-validation",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-08-01-angularjs-meet-aspnet-server-validation/index.md",source:"@site/blog/2014-08-01-angularjs-meet-aspnet-server-validation/index.md",title:"AngularJS meet ASP.Net Server Validation",description:"So. You're using AngularJS to build your front end with ASP.Net running on the server side. You're a trustworthy dev - you know that validation on the client will only get you so far. You need to validate on the server.",date:"2014-08-01T00:00:00.000Z",formattedDate:"August 1, 2014",tags:[{label:"asp.net",permalink:"/tags/asp-net"},{label:"typescript",permalink:"/tags/typescript"},{label:"AngularJS",permalink:"/tags/angular-js"}],readingTime:10.405,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"angularjs-meet-aspnet-server-validation",title:"AngularJS meet ASP.Net Server Validation",authors:"johnnyreilly",tags:["asp.net","typescript","AngularJS"],hide_table_of_contents:!1},prevItem:{title:"Getting more RESTful with Web API and IHttpActionResult",permalink:"/getting-more-RESTful-with-Web-API"},nextItem:{title:"HotTowel-Angular meet TypeScript",permalink:"/hottowel-angular-meet-typescript"}},p={authorsImageUrls:[void 0]},u=[{value:"What do we need client side?",id:"what-do-we-need-client-side",level:2},{value:"TypeScript",id:"typescript",level:3},{value:"JavaScript",id:"javascript",level:3},{value:"TypeScript",id:"typescript-1",level:3},{value:"JavaScript",id:"javascript-1",level:3},{value:"TypeScript",id:"typescript-2",level:3},{value:"JavaScript",id:"javascript-2",level:3},{value:"How can I get ASP.Net to send me this information?",id:"how-can-i-get-aspnet-to-send-me-this-information",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"So. You're using AngularJS to build your front end with ASP.Net running on the server side. You're a trustworthy dev - you know that validation on the client will only get you so far. You need to validate on the server."),(0,a.kt)("p",null,"My particular scenario is where you have a form which you are saving. Angular serves you well when it comes to hooking in your own client side validation. But it doesn't really ship with anything that supports ",(0,a.kt)("strong",{parentName:"p"},"nicely")," presenting server side validation on the client. Invariably when you look around you find people duplicating their server side validation on the client and presenting all their server side validation in a ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;div&gt;")," at the top of the screen."),(0,a.kt)("p",null,"This works but it's not as helpful to the user as it might be. It groups together all the validation from the server into one place. What I want is field level validation from the server that's presented on a field level basis on the screen."),(0,a.kt)("p",null,"Let us travel together to this promised land..."),(0,a.kt)("h2",o({},{id:"what-do-we-need-client-side"}),"What do we need client side?"),(0,a.kt)("p",null,"Well, let's start with a directive which I'll call ",(0,a.kt)("inlineCode",{parentName:"p"},"serverError"),". This plants a validation message just ",(0,a.kt)("em",{parentName:"p"},"after")," the element being validated which is displayed when that element is declared invalid by the server. (That is to say when the ",(0,a.kt)("inlineCode",{parentName:"p"},"ngModel")," has a ",(0,a.kt)("inlineCode",{parentName:"p"},"$error.server")," set.) When the element is changed then the ",(0,a.kt)("inlineCode",{parentName:"p"},"$error.server")," is unset in order that validation can be hidden and the form can be revalidated against the server."),(0,a.kt)("p",null,"I'm using TypeScript with Angular so for my JavaScript examples I'll give you both the TypeScript which I originally wrote and the generated JavaScript as well."),(0,a.kt)("h3",o({},{id:"typescript"}),"TypeScript"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),'interface serverErrorScope extends ng.IScope {\n    name: string;\n    serverError: { [field: string]: string };\n}\n\napp.directive("serverError", [function () {\n\n  // Usage:\n  // <input class="col-xs-12 col-sm-9"\n  //        name="sage.name" ng-model="vm.sage.name" server-error="vm.errors" />\n  var directive = {\n    link: link,\n    restrict: "A",\n    require: "ngModel", // supply the ngModel controller as the 4th parameter in the link function\n    scope: { // Pass in name and serverError to the scope\n      name: "@",\n      serverError: "="\n    }\n  };\n  return directive;\n\n  function link(scope: serverErrorScope, element: ng.IAugmentedJQuery, attrs: ng.IAttributes, ngModelController: ng.INgModelController) {\n\n    // Bootstrap alert template for error\n    var template = \'<div class="alert alert-danger" role="alert">\' +\n                               \'<i class="glyphicon glyphicon-warning-sign"></i> \' +\n                               \'%error%</div>\';\n\n    // Create an element to hold the validation message\n    var decorator = angular.element(\'<div></div>\');\n    element.after(decorator);\n\n    // Watch ngModelController.$error.server & show/hide validation accordingly\n    scope.$watch(safeWatch(() => ngModelController.$error.server), showHideValidation);\n\n    function showHideValidation(serverError: boolean) {\n\n      // Display an error if serverError is true otherwise clear the element\n      var errorHtml = "";\n      if (serverError) {\n        // Aliasing serverError and name to make it more obvious what their purpose is\n        var errorDictionary = scope.serverError;\n        var errorKey = scope.name;\n        errorHtml = template.replace(/%error%/, errorDictionary[errorKey] || "Unknown error occurred...");\n      }\n      decorator.html(errorHtml);\n    }\n\n    // wipe the server error message upon keyup or change events so can revalidate with server\n    element.on("keyup change", (event) => {\n      scope.$apply(() => { ngModelController.$setValidity("server", true); });\n    });\n  }\n}]);\n\n// Thanks @Basarat! http://stackoverflow.com/a/24863256/761388\nfunction safeWatch<t extends="" function="">(expression: T) {\n  return () => {\n    try {\n      return expression();\n    }\n    catch (e) {\n      return null;\n    }\n  };\n}\n</t>\n')),(0,a.kt)("h3",o({},{id:"javascript"}),"JavaScript"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"app.directive('serverError', [\n  function () {\n    // Usage:\n    // <input class=\"col-xs-12 col-sm-9\"\n    //        name=\"sage.name\" ng-model=\"vm.sage.name\" server-error=\"vm.errors\" />\n    var directive = {\n      link: link,\n      restrict: 'A',\n      require: 'ngModel',\n      scope: {\n        name: '@',\n        serverError: '=',\n      },\n    };\n    return directive;\n\n    function link(scope, element, attrs, ngModelController) {\n      // Bootstrap alert template for error\n      var template =\n        '<div class=\"alert alert-danger\" role=\"alert\">' +\n        '<i class=\"glyphicon glyphicon-warning-sign\"></i> ' +\n        '%error%</div>';\n\n      // Create an element to hold the validation message\n      var decorator = angular.element('<div></div>');\n      element.after(decorator);\n\n      // Watch ngModelController.$error.server & show/hide validation accordingly\n      scope.$watch(\n        safeWatch(function () {\n          return ngModelController.$error.server;\n        }),\n        showHideValidation\n      );\n\n      function showHideValidation(serverError) {\n        // Display an error if serverError is true otherwise clear the element\n        var errorHtml = '';\n        if (serverError) {\n          // Aliasing serverError and name to make it more obvious what their purpose is\n          var errorDictionary = scope.serverError;\n          var errorKey = scope.name;\n          errorHtml = template.replace(\n            /%error%/,\n            errorDictionary[errorKey] || 'Unknown error occurred...'\n          );\n        }\n        decorator.html(errorHtml);\n      }\n\n      // wipe the server error message upon keyup or change events so can revalidate with server\n      element.on('keyup change', function (event) {\n        scope.$apply(function () {\n          ngModelController.$setValidity('server', true);\n        });\n      });\n    }\n  },\n]);\n\n// Thanks @Basarat! http://stackoverflow.com/a/24863256/761388\nfunction safeWatch(expression) {\n  return function () {\n    try {\n      return expression();\n    } catch (e) {\n      return null;\n    }\n  };\n}\n")),(0,a.kt)("p",null,"If you look closely at this directive you'll see it is restricted to be used as an attribute and it depends on 2 things:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"The value that the ",(0,a.kt)("inlineCode",{parentName:"li"},"server-error")," attribute is set to should be an object which will contain key / values where the keys represent fields that are being validated."),(0,a.kt)("li",{parentName:"ol"},"The element being validated must have a name property (which will be used to look up the validation message in the ",(0,a.kt)("inlineCode",{parentName:"li"},"server-error"),' error "dictionary".')),(0,a.kt)("p",null,'Totally not clear, right? Let\'s have an example. Here is my "sageEdit" screen which you saw the screenshot of earlier:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<section class="mainbar" ng-controller="sageEdit as vm">\n  <section class="matter">\n    <div class="container-fluid">\n      <form name="form" novalidate role="form">\n        <div>\n          <button\n            class="btn btn-info"\n            ng-click="vm.save()"\n            ng-disabled="!vm.canSave"\n          >\n            <i class="glyphicon glyphicon-save"></i>Save\n          </button>\n          <span ng-show="vm.hasChanges" class="dissolve-animation ng-hide">\n            <i class="glyphicon glyphicon-asterisk orange"></i>\n          </span>\n        </div>\n        <div class="widget wblue">\n          <div data-cc-widget-header title="{{vm.title}}"></div>\n          <div class="widget-content form-horizontal">\n            <div class="form-group">\n              <label class="col-xs-12 col-sm-2">Name</label>\n              <input\n                class="col-xs-12 col-sm-9"\n                name="sage.name"\n                ng-model="vm.sage.name"\n                server-error="vm.errors"\n              />\n            </div>\n            <div class="form-group">\n              <label class="col-xs-12 col-sm-2">Username</label>\n              <input\n                class="col-xs-12 col-sm-9"\n                name="sage.userName"\n                ng-model="vm.sage.userName"\n                server-error="vm.errors"\n              />\n            </div>\n            <div class="form-group">\n              <label class="col-xs-12 col-sm-2">Email</label>\n              <input\n                class="col-xs-12 col-sm-9"\n                type="email"\n                name="sage.email"\n                ng-model="vm.sage.email"\n                server-error="vm.errors"\n              />\n            </div>\n          </div>\n        </div>\n      </form>\n    </div>\n  </section>\n</section>\n')),(0,a.kt)("p",null,"If you look closely at where ",(0,a.kt)("inlineCode",{parentName:"p"},"server-error"),' is used we have a name attribute set (eg "sage.email") and we\'re passing in something called ',(0,a.kt)("inlineCode",{parentName:"p"},"<em>vm.</em>errors")," as the ",(0,a.kt)("inlineCode",{parentName:"p"},"server-error")," attribute value. That's because we're using the \"controller as\" syntax and our controller is called ",(0,a.kt)("inlineCode",{parentName:"p"},"vm"),"."),(0,a.kt)("p",null,"On that controller we're going to have a dictionary style object called ",(0,a.kt)("inlineCode",{parentName:"p"},"errors"),'. If you wanted to you could put that object on the scope instead and omit the "vm." prefix. You could call it ',(0,a.kt)("inlineCode",{parentName:"p"},"wrongThingsWhatISpottedWithYourModel")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"barry")," ","-"," whatever floats your boat really. You get my point; it's flexible."),(0,a.kt)("p",null,"Let's take a look at our sageEdit Angular controller:"),(0,a.kt)("h3",o({},{id:"typescript-1"}),"TypeScript"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"module controllers {\n  'use strict';\n\n  interface sageEditRouteParams extends ng.route.IRouteParamsService {\n    id: number;\n  }\n\n  interface sageEditScope extends ng.IScope {\n    form: ng.IFormController;\n  }\n\n  class SageEdit {\n    errors: { [field: string]: string };\n    log: loggerFunction;\n    logError: loggerFunction;\n    logSuccess: loggerFunction;\n    sage: sage;\n    title: string;\n\n    private _isSaving: boolean;\n\n    static $inject = [\n      '$location',\n      '$routeParams',\n      '$scope',\n      'common',\n      'datacontext',\n    ];\n    constructor(\n      private $location: ng.ILocationService,\n      private $routeParams: sageEditRouteParams,\n      private $scope: sageEditScope,\n      private common: common,\n      private datacontext: datacontext\n    ) {\n      this.errors = {};\n      this.log = common.logger.getLogFn(controllerId);\n      this.logError = common.logger.getLogFn(controllerId, 'error');\n      this.logSuccess = common.logger.getLogFn(controllerId, 'success');\n      this.sage = undefined;\n      this.title = 'Sage Edit';\n\n      this._isSaving = false;\n\n      this.activate();\n    }\n\n    // Prototype methods\n\n    activate() {\n      var id = this.$routeParams.id;\n      var dataPromises: ng.IPromise<any>[] = [this.getSage(id)];\n\n      this.common\n        .activateController(dataPromises, controllerId, this.title)\n        .then(() => {\n          this.log('Activated Sage Edit View');\n          this.title = 'Sage Edit: ' + this.sage.name;\n        });\n    }\n\n    getSage(id: number) {\n      return this.datacontext.sage.getById(id).then((sage) => {\n        this.sage = sage;\n      });\n    }\n\n    save() {\n      this.errors = {}; //Wipe server errors\n      this._isSaving = true;\n      this.datacontext.sage.save(this.sage).then((response) => {\n        if (response.success) {\n          this.sage = response.entity;\n          this.logSuccess(\n            'Saved ' + this.sage.name + ' [' + this.sage.id + ']'\n          );\n          this.$location.path('/sages/detail/' + this.sage.id);\n        } else {\n          this.logError('Failed to save', response.errors);\n\n          angular.forEach(response.errors, (errors, field) => {\n            (<ng.INgModelController>this.$scope.form[field]).$setValidity(\n              'server',\n              false\n            );\n            this.errors[field] = errors.join(',');\n          });\n        }\n\n        this._isSaving = false;\n      });\n    }\n\n    // Properties\n\n    get hasChanges(): boolean {\n      return this.$scope.form.$dirty;\n    }\n\n    get canSave(): boolean {\n      return this.hasChanges && !this._isSaving && this.$scope.form.$valid;\n    }\n  }\n\n  var controllerId = 'sageEdit';\n  angular.module('app').controller(controllerId, SageEdit);\n}\n")),(0,a.kt)("h3",o({},{id:"javascript-1"}),"JavaScript"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var controllers;\n(function (controllers) {\n  'use strict';\n\n  var SageEdit = (function () {\n    function SageEdit($location, $routeParams, $scope, common, datacontext) {\n      this.$location = $location;\n      this.$routeParams = $routeParams;\n      this.$scope = $scope;\n      this.common = common;\n      this.datacontext = datacontext;\n      this.errors = {};\n      this.log = common.logger.getLogFn(controllerId);\n      this.logError = common.logger.getLogFn(controllerId, 'error');\n      this.logSuccess = common.logger.getLogFn(controllerId, 'success');\n      this.sage = undefined;\n      this.title = 'Sage Edit';\n\n      this._isSaving = false;\n\n      this.activate();\n    }\n    // Prototype methods\n    SageEdit.prototype.activate = function () {\n      var _this = this;\n      var id = this.$routeParams.id;\n      var dataPromises = [this.getSage(id)];\n\n      this.common\n        .activateController(dataPromises, controllerId, this.title)\n        .then(function () {\n          _this.log('Activated Sage Edit View');\n          _this.title = 'Sage Edit: ' + _this.sage.name;\n        });\n    };\n\n    SageEdit.prototype.getSage = function (id) {\n      var _this = this;\n      return this.datacontext.sage.getById(id).then(function (sage) {\n        _this.sage = sage;\n      });\n    };\n\n    SageEdit.prototype.save = function () {\n      var _this = this;\n      this.errors = {}; //Wipe server errors\n      this._isSaving = true;\n      this.datacontext.sage.save(this.sage).then(function (response) {\n        if (response.success) {\n          _this.sage = response.entity;\n          _this.logSuccess(\n            'Saved ' + _this.sage.name + ' [' + _this.sage.id + ']'\n          );\n\n          _this.$location.path('/sages/detail/' + _this.sage.id);\n        } else {\n          _this.logError('Failed to save', response.errors);\n\n          angular.forEach(response.errors, function (errors, field) {\n            _this.$scope.form[field].$setValidity('server', false);\n            _this.errors[field] = errors.join(',');\n          });\n        }\n\n        _this._isSaving = false;\n      });\n    };\n\n    Object.defineProperty(SageEdit.prototype, 'hasChanges', {\n      // Properties\n      get: function () {\n        return this.$scope.form.$dirty;\n      },\n      enumerable: true,\n      configurable: true,\n    });\n\n    Object.defineProperty(SageEdit.prototype, 'canSave', {\n      get: function () {\n        return this.hasChanges && !this._isSaving && this.$scope.form.$valid;\n      },\n      enumerable: true,\n      configurable: true,\n    });\n    SageEdit.$inject = [\n      '$location',\n      '$routeParams',\n      '$scope',\n      'common',\n      'datacontext',\n    ];\n    return SageEdit;\n  })();\n\n  var controllerId = 'sageEdit';\n  angular.module('app').controller(controllerId, SageEdit);\n})(controllers || (controllers = {}));\n")),(0,a.kt)("p",null,"Okay - this is a shedload of code and most of it isn't relevant to you. I share it as I like to see things in context. Let's focus in on the important bits that you should take away. Firstly, our controller has a property called ",(0,a.kt)("inlineCode",{parentName:"p"},"errors"),"."),(0,a.kt)("p",null,"Secondly, when we attempt to save our server sends back a JSON payload which, given a validation failure, looks something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "success": false,\n  "errors": {\n    "sage.name": ["The Name field is required."],\n    "sage.userName": [\n      "The UserName field is required.",\n      "The field UserName must be a string with a minimum length of 3 and a maximum length of 30."\n    ],\n    "sage.email": ["The Email field is not a valid e-mail address."]\n  }\n}\n')),(0,a.kt)("p",null,"So let's pare back our ",(0,a.kt)("inlineCode",{parentName:"p"},"save")," function to the bare necessities (those simple bare necessities, forget about your worries and your strife...):"),(0,a.kt)("h3",o({},{id:"typescript-2"}),"TypeScript"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),'save() {\n\n      this.errors = {}; //Wipe server errors\n\n      this.datacontext.sage.save(this.sage).then(response => {\n\n        if (response.success) {\n          this.sage = response.entity;\n        }\n        else {\n          angular.forEach(response.errors, (errors, field) => {\n            (<ng.INgModelController>this.$scope.form[field]).$setValidity("server", false);\n            this.errors[field] = errors.join(",");\n          });\n        }\n      });\n    }\n')),(0,a.kt)("h3",o({},{id:"javascript-2"}),"JavaScript"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"SageEdit.prototype.save = function () {\n  var _this = this;\n  this.errors = {}; //Wipe server errors\n  this.datacontext.sage.save(this.sage).then(function (response) {\n    if (response.success) {\n      _this.sage = response.entity;\n    } else {\n      angular.forEach(response.errors, function (errors, field) {\n        _this.$scope.form[field].$setValidity('server', false);\n        _this.errors[field] = errors.join(',');\n      });\n    }\n  });\n};\n")),(0,a.kt)("p",null,"At the point of save we wipe any server error messages that might be stored on the client. Then, if we receive back a payload with errors we store those errors and set the validity of the relevant form element to false. This will trigger the display of the message by our directive."),(0,a.kt)("p",null,"That's us done for the client side. You're no doubt now asking yourself this question:"),(0,a.kt)("h2",o({},{id:"how-can-i-get-aspnet-to-send-me-this-information"}),"How can I get ASP.Net to send me this information?"),(0,a.kt)("p",null,"So glad you asked. We've a simple model that looks like this which has a number of data annotations:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public class Sage\n{\n  public int Id { get; set; }\n\n  [Required]\n  public string Name { get; set; }\n\n  [Required]\n  [StringLength(30, MinimumLength = 3)]\n  public string UserName { get; set; }\n\n  [EmailAddress]\n  public string Email { get; set; }\n}\n")),(0,a.kt)("p",null,"When we save we post back to a Web API controller that looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public class SageController : ApiController\n{\n  // ...\n\n  public IHttpActionResult Post(User sage)\n  {\n    if (!ModelState.IsValid) {\n\n      return Ok(new\n      {\n        Success = false,\n        Errors = ModelState.ToErrorDictionary()\n      });\n    }\n\n    sage = _userService.Save(sage);\n\n    return Ok(new\n    {\n      Success = true,\n      Entity = sage\n    });\n  }\n\n  // ...\n}\n")),(0,a.kt)("p",null,"As you can see, when ",(0,a.kt)("inlineCode",{parentName:"p"},"ModelState")," is not valid we send back a dictionary of the ",(0,a.kt)("inlineCode",{parentName:"p"},"ModelState")," error messages keyed by property name. We generate this with an extension method I wrote called ",(0,a.kt)("inlineCode",{parentName:"p"},"ToErrorDictionary"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public static class ModelStateExtensions\n{\n  public static Dictionary<string, IEnumerable<string>> ToErrorDictionary(\n    this System.Web.Http.ModelBinding.ModelStateDictionary modelState, bool camelCaseKeyName = true)\n  {\n    var errors = modelState\n      .Where(x => x.Value.Errors.Any())\n      .ToDictionary(\n        kvp => CamelCasePropNames(kvp.Key),\n        kvp => kvp.Value.Errors.Select(e => e.ErrorMessage)\n      );\n\n    return errors;\n  }\n\n  private static string CamelCasePropNames(string propName)\n  {\n    var array = propName.Split('.');\n    var camelCaseList = new string[array.Length];\n    for (var i = 0; i < array.Length; i++)\n    {\n      var prop = array[i];\n      camelCaseList[i] = prop.Substring(0, 1).ToLower() + prop.Substring(1, prop.Length - 1);\n    }\n    return string.Join(\".\", camelCaseList);\n  }\n}\n")),(0,a.kt)("p",null,"That's it - your solution front to back. It would be quite easy to hook other types of validation in server-side (database level checks etc). I hope you find this useful."))}d.isMDXComponent=!0},61608:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"getting-more-RESTful-with-Web-API",title:"Getting more RESTful with Web API and IHttpActionResult",authors:"johnnyreilly",tags:["ASP.NET"],hide_table_of_contents:!1},s=void 0,l={permalink:"/getting-more-RESTful-with-Web-API",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-08-08-getting-more-RESTful-with-Web-API/index.md",source:"@site/blog/2014-08-08-getting-more-RESTful-with-Web-API/index.md",title:"Getting more RESTful with Web API and IHttpActionResult",description:"Up until, well yesterday really, I tended to have my Web API action methods all returning 200's no matter what. Successful request? 200 for you sir! Some validation error in the model? 200 for you too ma'am - but I'll wrap up the validation errors and send them back too. Database error? 200 and and an error message.",date:"2014-08-08T00:00:00.000Z",formattedDate:"August 8, 2014",tags:[{label:"ASP.NET",permalink:"/tags/asp-net"}],readingTime:2.685,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"getting-more-RESTful-with-Web-API",title:"Getting more RESTful with Web API and IHttpActionResult",authors:"johnnyreilly",tags:["ASP.NET"],hide_table_of_contents:!1},prevItem:{title:"My Unrequited Love for Isolate Scope",permalink:"/my-unrequited-love-for-isolate-scope"},nextItem:{title:"AngularJS meet ASP.Net Server Validation",permalink:"/angularjs-meet-aspnet-server-validation"}},p={authorsImageUrls:[void 0]},u=[{value:"Web API 2 - Bad Job on on the BadRequest Helper",id:"web-api-2---bad-job-on-on-the-badrequest-helper",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Up until, well yesterday really, I tended to have my Web API action methods all returning ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/HTTP_200#2xx_Success"}),"200"),"'s no matter what. Successful request? 200 for you sir! Some validation error in the model? 200 for you too ma'am - but I'll wrap up the validation errors and send them back too. Database error? 200 and and an error message."),(0,a.kt)("p",null,"It kind of looked like this (this example taken from a ",(0,a.kt)("a",o({parentName:"p"},{href:"/angularjs-meet-aspnet-server-validation"}),"previous post"),"):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public class SageController : ApiController\n{\n  // ...\n\n  public IHttpActionResult Post(User sage)\n  {\n    if (!ModelState.IsValid) {\n\n      return Ok(new {\n        Success = false,\n        Errors = ModelState.ToErrorDictionary()\n      });\n    }\n\n    sage = _userService.Save(sage);\n\n    return Ok(new {\n      Success = true,\n      Entity = sage\n    });\n  }\n\n  // ...\n}\n")),(0,a.kt)("p",null,"Well I'm no RESTafarian but this felt a little... wrong. Like I wasn't fully embracing the web. I didn't want to have to include my own ",(0,a.kt)("inlineCode",{parentName:"p"},"Success")," flag to indicate whether the request was good or not. I decided that I'd rather have it at least a little more webby. To that end, I decided I'd like to have 2xx success status codes for genuine success only and 4xx client error status codes for failures."),(0,a.kt)("p",null,"Lose the wrapper - embrace the web. This post is about doing just that."),(0,a.kt)("h2",o({},{id:"web-api-2---bad-job-on-on-the-badrequest-helper"}),"Web API 2 - Bad Job on on the BadRequest Helper"),(0,a.kt)("p",null,"Web API 2 ships with a whole host of API helper methods. Things like ",(0,a.kt)("inlineCode",{parentName:"p"},"Ok")," (which you can see me using above) and ",(0,a.kt)("inlineCode",{parentName:"p"},"BadRequest"),". ",(0,a.kt)("inlineCode",{parentName:"p"},"BadRequest")," was what I had in mind to use in place of ",(0,a.kt)("inlineCode",{parentName:"p"},"Ok")," where I had some kind of error I wanted to report to the client like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public class SageController : ApiController\n{\n  // ...\n\n  public IHttpActionResult Post(User sage)\n  {\n    if (!ModelState.IsValid) {\n\n      return BadRequest(new  {\n        Errors = ModelState.ToErrorDictionary()\n      });\n    }\n\n    sage = _userService.Save(sage);\n\n    return Ok(new {\n      Entity = sage\n    });\n  }\n\n  // ...\n}\n")),(0,a.kt)("p",null,"Looks good right? No more need for my ",(0,a.kt)("inlineCode",{parentName:"p"},"Success")," flag. Terser. Less code is better code. Unfortunately the built in ",(0,a.kt)("inlineCode",{parentName:"p"},"BadRequest")," helper method doesn't have the flexibility of the ",(0,a.kt)("inlineCode",{parentName:"p"},"Ok")," helper method - it doesn't allow you to send anything back you want. Fortunately this is easily remedied with a short extension method for ",(0,a.kt)("inlineCode",{parentName:"p"},"ApiController"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using System.Net;\nusing System.Web.Http;\nusing System.Web.Http.Results;\n\nnamespace System.Web.Http\n{\n    public static class ControllerExtensions\n    {\n        public static IHttpActionResult BadRequest<T>(this ApiController controller, T obj)\n        {\n            return new NegotiatedContentResult<T>(HttpStatusCode.BadRequest, obj, controller);\n        }\n    }\n}\n")),(0,a.kt)("p",null,"With this in place I can then tweak my implementation to hook into the extension method:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public class SageController : ApiController\n{\n  // ...\n\n  public IHttpActionResult Post(User sage)\n  {\n    if (!ModelState.IsValid) {\n      // See how we have "this." before BadRequest so the Extension method is invoked\n      return this.BadRequest(new  {\n        Errors = ModelState.ToErrorDictionary()\n      });\n    }\n\n    sage = _userService.Save(sage);\n\n    return Ok(new {\n      Entity = sage\n    });\n  }\n\n  // ...\n}\n')),(0,a.kt)("p",null,"And now we have have an endpoint that serves up 2xx status codes or 4xx status codes just as I'd hoped. Obviously this change in the way my action methods are returning will have implications for the consuming client (in my case an app built using AngularJS and $q). Essentially I can now use my ",(0,a.kt)("inlineCode",{parentName:"p"},"then")," to handle the successes and my ",(0,a.kt)("inlineCode",{parentName:"p"},"catch")," to handle the errors."))}d.isMDXComponent=!0},11644:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"my-unrequited-love-for-isolate-scope",title:"My Unrequited Love for Isolate Scope",authors:"johnnyreilly",tags:["typescript","javascript","Bootstrap","AngularJS"],hide_table_of_contents:!1},s=void 0,l={permalink:"/my-unrequited-love-for-isolate-scope",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-08-12-my-unrequited-love-for-isolate-scope/index.md",source:"@site/blog/2014-08-12-my-unrequited-love-for-isolate-scope/index.md",title:"My Unrequited Love for Isolate Scope",description:"I wrote a little while ago about creating a directive to present server errors on the screen in an Angular application. In my own (not so humble opinion), it was really quite nice. I was particularly proud of my usage of isolate scope. However, pride comes before a fall.",date:"2014-08-12T00:00:00.000Z",formattedDate:"August 12, 2014",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"javascript",permalink:"/tags/javascript"},{label:"Bootstrap",permalink:"/tags/bootstrap"},{label:"AngularJS",permalink:"/tags/angular-js"}],readingTime:4.515,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"my-unrequited-love-for-isolate-scope",title:"My Unrequited Love for Isolate Scope",authors:"johnnyreilly",tags:["typescript","javascript","Bootstrap","AngularJS"],hide_table_of_contents:!1},prevItem:{title:"Running JavaScript Unit Tests in AppVeyor",permalink:"/running-javascript-unit-tests-in-appveyor"},nextItem:{title:"Getting more RESTful with Web API and IHttpActionResult",permalink:"/getting-more-RESTful-with-Web-API"}},p={authorsImageUrls:[void 0]},u=[{value:"A New Hope",id:"a-new-hope",level:2},{value:"serverError.ts",id:"servererrorts",level:3},{value:"serverError.js",id:"servererrorjs",level:3},{value:"My Plea",id:"my-plea",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"/angularjs-meet-aspnet-server-validation"}),"I wrote a little while ago about creating a directive to present server errors on the screen in an Angular application"),". In my own (not so humble opinion), it was really quite nice. I was particularly proud of my usage of isolate scope. However, pride comes before a fall."),(0,a.kt)("p",null,"It turns out that using isolate scope in a directive is not always wise. Or rather \u2013 not always possible. And this is why:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'Error: [$compile:multidir] Multiple directives [datepickerPopup, serverError] asking for new/isolated scope on: <input name="sage.dateOfBirth" class="col-xs-12 col-sm-9" type="text" value="" ng-click="vm.dateOfBirthDatePickerOpen()" server-error="vm.errors" ng-model="vm.sage.dateOfBirth" is-open="vm.dateOfBirthDatePickerIsOpen" datepicker-popup="dd MMM yyyy">\n')),(0,a.kt)("p",null,"Ug. What happened here? Well, I had a date field that I was using my serverError directive on. Nothing too controversial there. The problem came when I tried to plug in ",(0,a.kt)("a",o({parentName:"p"},{href:"http://angular-ui.github.io/bootstrap/"}),"UI Bootstrap\u2019s datepicker")," as well. That\u2019s right the directives are fighting. Sad face."),(0,a.kt)("p",null,"To be more precise, it turns out that only one directive on an element is allowed to create an isolated scope. So if I want to use UI Bootstrap\u2019s datepicker (and I do) \u2013 well my serverError directive is toast."),(0,a.kt)("h2",o({},{id:"a-new-hope"}),"A New Hope"),(0,a.kt)("p",null,"So ladies and gentlemen, let me present serverError 2.0 \u2013 this time without isolated scope:"),(0,a.kt)("h3",o({},{id:"servererrorts"}),"serverError.ts"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"(function () {\n  'use strict';\n\n  var app = angular.module('app');\n\n  // Plant a validation message to the right of the element when it is declared invalid by the server\n  app.directive('serverError', [\n    function () {\n      // Usage:\n      // <input class=\"col-xs-12 col-sm-9\"\n      //        name=\"sage.name\" ng-model=\"vm.sage.name\" server-error=\"vm.errors\" />\n\n      var directive = {\n        link: link,\n        restrict: 'A',\n        require: 'ngModel', // supply the ngModel controller as the 4th parameter in the link function\n      };\n      return directive;\n\n      function link(\n        scope: ng.IScope,\n        element: ng.IAugmentedJQuery,\n        attrs: ng.IAttributes,\n        ngModelController: ng.INgModelController\n      ) {\n        // Extract values from attributes (deliberately not using isolated scope)\n        var errorKey: string = attrs['name']; // eg \"sage.name\"\n        var errorDictionaryExpression: string = attrs['serverError']; // eg \"vm.errors\"\n\n        // Bootstrap alert template for error\n        var template =\n          '<div class=\"alert alert-danger col-xs-9 col-xs-offset-2\" role=\"alert\"><i class=\"glyphicon glyphicon-warning-sign larger\"></i> %error%</div>';\n\n        // Create an element to hold the validation message\n        var decorator = angular.element('<div></div>');\n        element.after(decorator);\n\n        // Watch ngModelController.$error.server & show/hide validation accordingly\n        scope.$watch(\n          safeWatch(() => ngModelController.$error.server),\n          showHideValidation\n        );\n\n        function showHideValidation(serverError: boolean) {\n          // Display an error if serverError is true otherwise clear the element\n          var errorHtml = '';\n          if (serverError) {\n            var errorDictionary: { [field: string]: string } = scope.$eval(\n              errorDictionaryExpression\n            );\n            errorHtml = template.replace(\n              /%error%/,\n              errorDictionary[errorKey] || 'Unknown error occurred...'\n            );\n          }\n          decorator.html(errorHtml);\n        }\n\n        // wipe the server error message upon keyup or change events so can revalidate with server\n        element.on('keyup change', (event) => {\n          scope.$apply(() => {\n            ngModelController.$setValidity('server', true);\n          });\n        });\n      }\n    },\n  ]);\n\n  // Thanks @Basarat! http://stackoverflow.com/a/24863256/761388\n  function safeWatch<T extends Function>(expression: T) {\n    return () => {\n      try {\n        return expression();\n      } catch (e) {\n        return null;\n      }\n    };\n  }\n})();\n")),(0,a.kt)("h3",o({},{id:"servererrorjs"}),"serverError.js"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"(function () {\n  'use strict';\n\n  var app = angular.module('app');\n\n  // Plant a validation message to the right of the element when it is declared invalid by the server\n  app.directive('serverError', [\n    function () {\n      // Usage:\n      // <input class=\"col-xs-12 col-sm-9\"\n      //        name=\"sage.name\" ng-model=\"vm.sage.name\" server-error=\"vm.errors\" />\n      var directive = {\n        link: link,\n        restrict: 'A',\n        require: 'ngModel',\n      };\n      return directive;\n\n      function link(scope, element, attrs, ngModelController) {\n        // Extract values from attributes (deliberately not using isolated scope)\n        var errorKey = attrs['name'];\n        var errorDictionaryExpression = attrs['serverError'];\n\n        // Bootstrap alert template for error\n        var template =\n          '<div class=\"alert alert-danger col-xs-9 col-xs-offset-2\" role=\"alert\"><i class=\"glyphicon glyphicon-warning-sign larger\"></i> %error%</div>';\n\n        // Create an element to hold the validation message\n        var decorator = angular.element('<div></div>');\n        element.after(decorator);\n\n        // Watch ngModelController.$error.server & show/hide validation accordingly\n        scope.$watch(\n          safeWatch(function () {\n            return ngModelController.$error.server;\n          }),\n          showHideValidation\n        );\n\n        function showHideValidation(serverError) {\n          // Display an error if serverError is true otherwise clear the element\n          var errorHtml = '';\n          if (serverError) {\n            var errorDictionary = scope.$eval(errorDictionaryExpression);\n            errorHtml = template.replace(\n              /%error%/,\n              errorDictionary[errorKey] || 'Unknown error occurred...'\n            );\n          }\n          decorator.html(errorHtml);\n        }\n\n        // wipe the server error message upon keyup or change events so can revalidate with server\n        element.on('keyup change', function (event) {\n          scope.$apply(function () {\n            ngModelController.$setValidity('server', true);\n          });\n        });\n      }\n    },\n  ]);\n\n  // Thanks @Basarat! http://stackoverflow.com/a/24863256/761388\n  function safeWatch(expression) {\n    return function () {\n      try {\n        return expression();\n      } catch (e) {\n        return null;\n      }\n    };\n  }\n})();\n")),(0,a.kt)("p",null,"This version of the serverError directive is from a users perspective identical to the previous version. But it doesn\u2019t use isolated scope \u2013 this means it can be used in concert with other directives which do."),(0,a.kt)("p",null,"It works by pulling the ",(0,a.kt)("inlineCode",{parentName:"p"},"name")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"serverError")," values off the attrs parameter. ",(0,a.kt)("inlineCode",{parentName:"p"},"name")," is just a string - the value of which never changes so it can be used as is. ",(0,a.kt)("inlineCode",{parentName:"p"},"serverError")," is an expression that represents the error dictionary that is used to store the server error messages. This is accessed through use of ",(0,a.kt)("inlineCode",{parentName:"p"},"scope.$eval")," as an when it needs to."),(0,a.kt)("h2",o({},{id:"my-plea"}),"My Plea"),(0,a.kt)("p",null,"What I\u2019ve outlined here works. I\u2019ll admit that usage of ",(0,a.kt)("inlineCode",{parentName:"p"},"$eval")," makes me feel a little bit dirty (I\u2019ve got ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.jslint.com/lint.html#evil"}),"\u201ceval is evil\u201d")," running through my head). Whilst it works, I\u2019m not sure what I\u2019ve done is necessarily best practice. After all ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.angularjs.org/guide/directive"}),"the Angular docs themselves say"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("strong",{parentName:"p"},"*","Best Practice:")," Use the scope option to create isolate scopes when making components that you want to reuse throughout your app. ","*")),(0,a.kt)("p",null,"But as we\u2019ve seen this isn\u2019t always an option. I\u2019ve written this post to document my own particular struggle and ask the question \u201cis there a better way?\u201d If you know then please tell me!"))}d.isMDXComponent=!0},86247:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"running-javascript-unit-tests-in-appveyor",title:"Running JavaScript Unit Tests in AppVeyor",authors:"johnnyreilly",tags:["Jasmine","javascript","Unit tests","Continuous Integration","AppVeyor","Chutzpah"],hide_table_of_contents:!1},s=void 0,l={permalink:"/running-javascript-unit-tests-in-appveyor",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-09-06-running-javascript-unit-tests-in-appveyor/index.md",source:"@site/blog/2014-09-06-running-javascript-unit-tests-in-appveyor/index.md",title:"Running JavaScript Unit Tests in AppVeyor",description:"With a little help from Chutzpah...",date:"2014-09-06T00:00:00.000Z",formattedDate:"September 6, 2014",tags:[{label:"Jasmine",permalink:"/tags/jasmine"},{label:"javascript",permalink:"/tags/javascript"},{label:"Unit tests",permalink:"/tags/unit-tests"},{label:"Continuous Integration",permalink:"/tags/continuous-integration"},{label:"AppVeyor",permalink:"/tags/app-veyor"},{label:"Chutzpah",permalink:"/tags/chutzpah"}],readingTime:2.96,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"running-javascript-unit-tests-in-appveyor",title:"Running JavaScript Unit Tests in AppVeyor",authors:"johnnyreilly",tags:["Jasmine","javascript","Unit tests","Continuous Integration","AppVeyor","Chutzpah"],hide_table_of_contents:!1},prevItem:{title:"Unit Testing an Angular Controller with Jasmine",permalink:"/unit-testing-angular-controller-with"},nextItem:{title:"My Unrequited Love for Isolate Scope",permalink:"/my-unrequited-love-for-isolate-scope"}},p={authorsImageUrls:[void 0]},u=[{value:"With a little help from Chutzpah...",id:"with-a-little-help-from-chutzpah",level:2},{value:"NuGet me?",id:"nuget-me",level:2},{value:"Now to use Chutzpah",id:"now-to-use-chutzpah",level:2},{value:"Thanks to...",id:"thanks-to",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"with-a-little-help-from-chutzpah"}),"With a little help from Chutzpah..."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"http://www.appveyor.com"}),"AppVeyor")," (if you're not aware of it) is a Continuous Integration provider. If you like, it's plug-and-play CI for .NET developers. It's lovely. And what's more it's ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.appveyor.com/pricing"}),'"free for open-source projects with public repositories hosted on GitHub and BitBucket"'),". Boom! I recently hooked up 2 of my GitHub projects with AppVeyor. It took me all of... 10 minutes. If that? It really is ","*",(0,a.kt)("strong",{parentName:"p"},"that"),"*"," good."),(0,a.kt)("p",null,"But.... There had to be a \"but\" otherwise I wouldn't have been writing the post you're reading. For a little side project of mine called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/Proverb"}),"Proverb")," there were C# unit tests and there were JavaScript unit tests. And the JavaScript unit tests weren't being run... No fair!!!"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://chutzpah.codeplex.com/"}),"Chutzpah")," is a JavaScript test runner which at this point runs QUnit, Jasmine and Mocha JavaScript tests. I use the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://visualstudiogallery.msdn.microsoft.com/f8741f04-bae4-4900-81c7-7c9bfb9ed1fe"}),"Visual Studio extension")," to run Jasmine tests on my machine during development. I've also been able to use ",(0,a.kt)("a",o({parentName:"p"},{href:"/the-surprisingly-happy-tale-of-visual"}),"Chutzpah for CI purposes with Visual Studio Online / Team Foundation Server"),". So what say we try and do the triple and make it work with AppVeyor too?"),(0,a.kt)("h2",o({},{id:"nuget-me"}),"NuGet me?"),(0,a.kt)("p",null,"In order that I could run Chutzpah I needed Chutzpah to be installed on the build machine. So I had 2 choices:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Add Chutzpah direct to the repo"),(0,a.kt)("li",{parentName:"ol"},"Add the ",(0,a.kt)("a",o({parentName:"li"},{href:"http://www.nuget.org/packages/chutzpah"}),"Chutzpah Nuget package")," to the solution")),(0,a.kt)("p",null,"Unsurprisingly I chose #2 - much cleaner."),(0,a.kt)("h2",o({},{id:"now-to-use-chutzpah"}),"Now to use Chutzpah"),(0,a.kt)("p",null,'Time to dust down the PowerShell. I created myself a "before tests script" and added it to my build. It looked a little something like this:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),'# Locate Chutzpah\n\n$ChutzpahDir = get-childitem chutzpah.console.exe -recurse | select-object -first 1 | select -expand Directory\n\n# Run tests using Chutzpah and export results as JUnit format to chutzpah-results.xml\n\n$ChutzpahCmd = "$($ChutzpahDir)\\chutzpah.console.exe $($env:APPVEYOR_BUILD_FOLDER)\\AngularTypeScript\\Proverb.Web.Tests.JavaScript /junit .\\chutzpah-results.xml"\nWrite-Host $ChutzpahCmd\nInvoke-Expression $ChutzpahCmd\n\n# Upload results to AppVeyor one by one\n\n$testsuites = [xml](get-content .\\chutzpah-results.xml)\n\n$anyFailures = $FALSE\nforeach ($testsuite in $testsuites.testsuites.testsuite) {\n    write-host " $($testsuite.name)"\n    foreach ($testcase in $testsuite.testcase){\n        $failed = $testcase.failure\n        $time = $testsuite.time\n        if ($testcase.time) { $time = $testcase.time }\n        if ($failed) {\n            write-host "Failed   $($testcase.name) $($testcase.failure.message)"\n            Add-AppveyorTest $testcase.name -Outcome Failed -FileName $testsuite.name -ErrorMessage $testcase.failure.message -Duration $time\n            $anyFailures = $TRUE\n        }\n        else {\n            write-host "Passed   $($testcase.name)"\n            Add-AppveyorTest $testcase.name -Outcome Passed -FileName $testsuite.name -Duration $time\n        }\n\n    }\n}\n\nif ($anyFailures -eq $TRUE){\n    write-host "Failing build as there are broken tests"\n    $host.SetShouldExit(1)\n}\n')),(0,a.kt)("p",null,"What this does is:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Run Chutzpah from the installed NuGet package location, passing in the location of my Jasmine unit tests. In the case of my project there is a ",(0,a.kt)("inlineCode",{parentName:"li"},"chutzpah.json")," file in the project which dictates how Chutzpah should run the tests. Also, ",(0,a.kt)("a",o({parentName:"li"},{href:"https://chutzpah.codeplex.com/wikipage?title=Command%20Line%20Options&referringTitle=Documentation"}),"the JUnit flag is also passed")," in order that Chutzpah creates a ",(0,a.kt)("inlineCode",{parentName:"li"},"chutzpah-results.xml")," file of test results in the JUnit format."),(0,a.kt)("li",{parentName:"ol"},"We iterate through test results and tell AppVeyor about the the test passes and failures using the ",(0,a.kt)("a",o({parentName:"li"},{href:"http://www.appveyor.com/docs/build-worker-api"}),"Build Worker API"),"."),(0,a.kt)("li",{parentName:"ol"},"If there have been any failed tests then we fail the build. If you look ",(0,a.kt)("a",o({parentName:"li"},{href:"https://ci.appveyor.com/project/JohnReilly/proverb/build/1.0.17"}),"here")," you can see a deliberately failed build which demo's that this works as it should.")),(0,a.kt)("p",null,"That's a wrap - We now have CI which includes our JavaScript tests! That's right we get to see beautiful screens like these:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(85541).Z,width:"640",height:"578"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(4477).Z,width:"579",height:"640"})),(0,a.kt)("h2",o({},{id:"thanks-to"}),"Thanks to..."),(0,a.kt)("p",null,"Thanks to Dan Jones, whose comments on ",(0,a.kt)("a",o({parentName:"p"},{href:"http://help.appveyor.com/discussions/questions/390-running-jasmine-on-appveyor#comment_34433599"}),"this discussion")," provided a number of useful pointers which moved me in the right direction. And thanks to Feador Fitzner who has generously ",(0,a.kt)("a",o({parentName:"p"},{href:"http://help.appveyor.com/discussions/questions/495-integrating-chutzpah-into-appveyor#comment_34447202"}),"said AppVeyor will support JUnit in the future")," which may simplify use of Chutzpah with AppVeyor even further."))}d.isMDXComponent=!0},31301:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"unit-testing-angular-controller-with",title:"Unit Testing an Angular Controller with Jasmine",authors:"johnnyreilly",tags:["Jasmine","unit tests","AngularJS"],hide_table_of_contents:!1},s=void 0,l={permalink:"/unit-testing-angular-controller-with",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-09-10-unit-testing-angular-controller-with/index.md",source:"@site/blog/2014-09-10-unit-testing-angular-controller-with/index.md",title:"Unit Testing an Angular Controller with Jasmine",description:"Anyone who reads my blog will know that I have been long in the habit of writing unit tests for my C# code. I'm cool like that. However, it took me a while to get up and running writing unit tests for my JavaScript code. I finally got there using a combination of Jasmine 2.0 and Chutzpah. (Jasmine being my test framework and Chutzpah being my test runner.)",date:"2014-09-10T00:00:00.000Z",formattedDate:"September 10, 2014",tags:[{label:"Jasmine",permalink:"/tags/jasmine"},{label:"unit tests",permalink:"/tags/unit-tests"},{label:"AngularJS",permalink:"/tags/angular-js"}],readingTime:7.71,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"unit-testing-angular-controller-with",title:"Unit Testing an Angular Controller with Jasmine",authors:"johnnyreilly",tags:["Jasmine","unit tests","AngularJS"],hide_table_of_contents:!1},prevItem:{title:"Journalling the Migration of Jasmine Tests to TypeScript",permalink:"/migrating-jasmine-tests-to-typescript"},nextItem:{title:"Running JavaScript Unit Tests in AppVeyor",permalink:"/running-javascript-unit-tests-in-appveyor"}},p={authorsImageUrls:[void 0]},u=[{value:"What I&#39;m Testing",id:"what-im-testing",level:2},{value:"sagesDetail.ts",id:"sagesdetailts",level:3},{value:"sageDetail.js",id:"sagedetailjs",level:3},{value:"Now for the Tests",id:"now-for-the-tests",level:2},{value:"Jasmine tests for sageDetail.js",id:"jasmine-tests-for-sagedetailjs",level:3}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Anyone who reads my blog will know that I have been long in the habit of writing unit tests for my C# code. I'm cool like that. However, it took me a while to get up and running writing unit tests for my JavaScript code. I finally ",(0,a.kt)("a",o({parentName:"p"},{href:"/the-surprisingly-happy-tale-of-visual"}),"got there")," using a combination of Jasmine 2.0 and Chutzpah. (Jasmine being my test framework and Chutzpah being my test runner.)"),(0,a.kt)("p",null,"I'm getting properly into the habit of testing my JavaScript. I won't pretend it's been particularly fun but I firmly believe it will end up being useful... That's what I tell myself during the long dark tea-times of the soul anyway."),(0,a.kt)("p",null,"I have a side project called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/Proverb"}),"Proverb"),". It doesn't do anything in particular - for the most part it's a simple application that displays the collected wise sayings of a team that I used to be part of. There's not much to it - a bit of CRUD, a dashboard. Not much more. Because of the project's simplicity it's ideal to use Proverb's underlying idea when trying out new technologies / frameworks. ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Paul_Halmos"}),"The best way to learn is to do"),'. So if I want to learn "X", then building Proverb using "X" is a good way to go.'),(0,a.kt)("p",null,"I digress already. I had a version of Proverb built using a combination of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/Proverb/tree/master/AngularTypeScript"}),"AngularJS and TypeScript"),". I had written the Angular side of Proverb without any tests. Now I was able to write JavaScript tests for my Angular code that's just what I set out to do. It should prove something of a of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Kata_(programming)"}),"Code Kata")," too."),(0,a.kt)("p",null,"Whilst I'm at it I thought it might prove helpful if I wrote up how I approached writing unit tests for a single Angular controller. So here goes."),(0,a.kt)("h2",o({},{id:"what-im-testing"}),"What I'm Testing"),(0,a.kt)("p",null,"I have an Angular controller called ",(0,a.kt)("inlineCode",{parentName:"p"},"sagesDetail"),". It powers this screen:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(12521).Z,width:"640",height:"319"})),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"sagesDetail")," is a very simple controller. It does these things:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},'Load the "sage" (think of it as just a "user") and make it available on the controller so it can be bound to the view.'),(0,a.kt)("li",{parentName:"ol"},"Set the view title."),(0,a.kt)("li",{parentName:"ol"},"Log view activation."),(0,a.kt)("li",{parentName:"ol"},"Expose a ",(0,a.kt)("inlineCode",{parentName:"li"},"gotoEdit")," method which, when called, redirects the user to the edit screen.")),(0,a.kt)("p",null,"The controller is written in TypeScript and looks like this:"),(0,a.kt)("h3",o({},{id:"sagesdetailts"}),"sagesDetail.ts"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"module controllers {\n  'use strict';\n\n  var controllerId = 'sageDetail';\n\n  interface sageDetailRouteParams extends ng.route.IRouteParamsService {\n    id: string;\n  }\n\n  class SageDetail {\n    log: loggerFunction;\n    sage: sage;\n    title: string;\n\n    static $inject = ['$location', '$routeParams', 'common', 'datacontext'];\n    constructor(\n      private $location: ng.ILocationService,\n      private $routeParams: sageDetailRouteParams,\n      private common: common,\n      private datacontext: datacontext\n    ) {\n      this.sage = undefined;\n      this.title = 'Sage Details';\n\n      this.log = common.logger.getLogFn(controllerId);\n\n      this.activate();\n    }\n\n    // Prototype methods\n\n    activate() {\n      var id = parseInt(this.$routeParams.id, 10);\n      var dataPromises: ng.IPromise<any>[] = [\n        this.datacontext.sage\n          .getById(id, true)\n          .then((data) => (this.sage = data)),\n      ];\n\n      this.common\n        .activateController(dataPromises, controllerId, this.title)\n        .then(() => {\n          this.log('Activated Sage Details View');\n          this.title = 'Sage Details: ' + this.sage.name;\n        });\n    }\n\n    gotoEdit() {\n      this.$location.path('/sages/edit/' + this.sage.id);\n    }\n  }\n\n  angular.module('app').controller(controllerId, SageDetail);\n}\n")),(0,a.kt)("p",null,"When compiled to JavaScript it looks like this:"),(0,a.kt)("h3",o({},{id:"sagedetailjs"}),"sageDetail.js"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var controllers;\n(function (controllers) {\n  'use strict';\n\n  var controllerId = 'sageDetail';\n\n  var SageDetail = (function () {\n    function SageDetail($location, $routeParams, common, datacontext) {\n      this.$location = $location;\n      this.$routeParams = $routeParams;\n      this.common = common;\n      this.datacontext = datacontext;\n      this.sage = undefined;\n      this.title = 'Sage Details';\n\n      this.log = common.logger.getLogFn(controllerId);\n\n      this.activate();\n    }\n    // Prototype methods\n    SageDetail.prototype.activate = function () {\n      var _this = this;\n      var id = parseInt(this.$routeParams.id, 10);\n      var dataPromises = [\n        this.datacontext.sage.getById(id, true).then(function (data) {\n          return (_this.sage = data);\n        }),\n      ];\n\n      this.common\n        .activateController(dataPromises, controllerId, this.title)\n        .then(function () {\n          _this.log('Activated Sage Details View');\n          _this.title = 'Sage Details: ' + _this.sage.name;\n        });\n    };\n\n    SageDetail.prototype.gotoEdit = function () {\n      this.$location.path('/sages/edit/' + this.sage.id);\n    };\n    SageDetail.$inject = ['$location', '$routeParams', 'common', 'datacontext'];\n    return SageDetail;\n  })();\n\n  angular.module('app').controller(controllerId, SageDetail);\n})(controllers || (controllers = {}));\n//# sourceMappingURL=sageDetail.js.map\n")),(0,a.kt)("h2",o({},{id:"now-for-the-tests"}),"Now for the Tests"),(0,a.kt)("p",null,"I haven't yet made the move of switching over my Jasmine tests from JavaScript to TypeScript. (It's on my list but there's only so many things you can do at once...) For that reason the tests you'll see here are straight JavaScript. Below you will see the tests for the ",(0,a.kt)("inlineCode",{parentName:"p"},"sageDetail")," controller."),(0,a.kt)("p",null,"I have put very comments in the test code to make clear the intent to you, dear reader. Annotated the life out of them. Naturally I wouldn't expect a test to be so heavily annotated in a typical test suite - and you can be sure mine normally aren't!"),(0,a.kt)("h3",o({},{id:"jasmine-tests-for-sagedetailjs"}),"Jasmine tests for sageDetail.js"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"describe('Proverb.Web -> app-> controllers ->', function () {\n  // Before each test runs we're going to need ourselves an Angular App to test - go fetch!\n  beforeEach(function () {\n    module('app'); // module is an alias for <a href=\"https://docs.angularjs.org/api/ngMock/function/angular.mock.module\">angular.mock.module</a>\n  });\n\n  // Tests for the sageDetail controller\n  describe('sageDetail ->', function () {\n    // Declare describe-scoped variables\n    var $rootScope,\n      getById_deferred, // deferred used for promises\n      $location,\n      $routeParams_stub,\n      common,\n      datacontext, // controller dependencies\n      sageDetailController; // the controller\n\n    // Before each test runs set up the controller using inject - an alias for <a href=\"https://docs.angularjs.org/api/ngMock/function/angular.mock.inject\">angular.mock.inject</a>\n    beforeEach(inject(function (\n      _$controller_,\n      _$rootScope_,\n      _$q_,\n      _$location_,\n      _common_,\n      _datacontext_\n    ) {\n      // Note how each parameter is prefixed and suffixed with \"_\" - this an Angular nicety\n      // which allows you to have variables in your tests with the original reference name.\n      // So here we assign the injected parameters to the describe-scoped variables:\n      $rootScope = _$rootScope_;\n      $q = _$q_;\n      $location = _$location_;\n      common = _common_;\n      datacontext = _datacontext_;\n\n      // Our controller has a dependency on an \"id\" property passed on the $routeParams\n      // We're going to stub this out with a JavaScript object literal\n      $routeParams_stub = { id: '10' };\n\n      // Our controller depends on a promise returned from this function: datacontext.sage.getById\n      // Well strictly speaking it also uses a promise for activateController but since the activateController\n      // promise just wraps the getById promise it will be resolved when the getById promise is.\n      // Here we create a deferred representing the getById promise which we can resolve as we need to\n      getById_deferred = $q.defer();\n\n      // set up a spy on datacontext.sage.getById and set it to return the promise of getById_deferred\n      // this allows us to #1 detect that getById has been called\n      // and #2 resolve / reject our promise as our test requires using getById_deferred\n      spyOn(datacontext.sage, 'getById').and.returnValue(\n        getById_deferred.promise\n      );\n\n      // set up a spy on common.activateController and set it to call through\n      // this allows us to detect that activateController has been called whilst\n      // maintaining existing controller functionality\n      spyOn(common, 'activateController').and.callThrough();\n\n      // set up spys on common.logger.getLogFn and $location.path so we can detect they have been called\n      spyOn(common.logger, 'getLogFn').and.returnValue(\n        jasmine.createSpy('log')\n      );\n      spyOn($location, 'path').and.returnValue(jasmine.createSpy('path'));\n\n      // create a sageDetail controller and inject the dependencies we have set up\n      sageDetailController = _$controller_('sageDetail', {\n        $location: $location,\n        $routeParams: $routeParams_stub,\n        common: common,\n        datacontext: datacontext,\n      });\n    }));\n\n    // Tests for the controller state at the point of the sageDetail controller's creation\n    // ie before the getById / activateController promises have been resolved\n    // So this tests the constructor (function) and the activate function up to the point\n    // of the promise calls\n    describe('on creation ->', function () {\n      it(\"controller should have a title of 'Sage Details'\", function () {\n        // tests this code has executed:\n        // this.title = \"Sage Details\";\n        expect(sageDetailController.title).toBe('Sage Details');\n      });\n\n      it('controller should have no sage', function () {\n        // tests this code has executed:\n        // this.sage = undefined;\n        expect(sageDetailController.sage).toBeUndefined();\n      });\n\n      it('datacontext.sage.getById should be called', function () {\n        // tests this code has executed:\n        // this.datacontext.sage.getById(id, true)\n        expect(datacontext.sage.getById).toHaveBeenCalledWith(10, true);\n      });\n    });\n\n    // Tests for the controller state at the point of the resolution of the getById promise\n    // ie after the getById / activateController promises have been resolved\n    // So this tests the constructor (function) and the activate function after the point\n    // of the promise calls\n    describe('activateController ->', function () {\n      var sage_stub;\n      beforeEach(function () {\n        // Create a sage stub which will be used when resolving the getById promise\n        sage_stub = { name: 'John' };\n      });\n\n      it('should set sages to be the resolved promise values', function () {\n        // Resolve the getById promise with the sage stub\n        getById_deferred.resolve(sage_stub);\n        $rootScope.$digest(); // So Angular processes the resolved promise\n\n        // tests this code has executed:\n        // this.sage = data\n        expect(sageDetailController.sage).toBe(sage_stub);\n      });\n\n      it(\"should log 'Activated Sage Details View' and set title with name\", function () {\n        // Resolve the getById promise with the sage stub\n        getById_deferred.resolve(sage_stub);\n        $rootScope.$digest(); // So Angular processes the resolved promise\n\n        // tests this code has executed:\n        // this.log(\"Activated Sage Details View\");\n        // this.title = \"Sage Details: \" + this.sage.name;\n        expect(sageDetailController.log).toHaveBeenCalledWith(\n          'Activated Sage Details View'\n        );\n        expect(sageDetailController.title).toBe(\n          'Sage Details: ' + sage_stub.name\n        );\n      });\n    });\n\n    // Tests for the gotoEdit function on the controller\n    // Note that this will only be called *after* a controller has been created\n    // and it depends upon a sage having first been loaded\n    describe('gotoEdit ->', function () {\n      var sage_stub;\n      beforeEach(function () {\n        // Create a sage stub which will be used when resolving the getById promise\n        sage_stub = { id: 20 };\n      });\n\n      it('should set $location.path to edit URL', function () {\n        // Resolve the getById promise with the sage stub\n        getById_deferred.resolve(sage_stub);\n        $rootScope.$digest(); // So Angular processes the resolved promise\n\n        sageDetailController.gotoEdit();\n\n        // tests this code has executed:\n        // this.$location.path(\"/sages/edit/\" + this.sage.id);\n        expect($location.path).toHaveBeenCalledWith(\n          '/sages/edit/' + sage_stub.id\n        );\n      });\n    });\n  });\n});\n")))}d.isMDXComponent=!0},94437:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"migrating-jasmine-tests-to-typescript",title:"Journalling the Migration of Jasmine Tests to TypeScript",authors:"johnnyreilly",tags:["Jasmine","typescript","javascript"],hide_table_of_contents:!1},s=void 0,l={permalink:"/migrating-jasmine-tests-to-typescript",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-09-13-migrating-jasmine-tests-to-typescript/index.md",source:"@site/blog/2014-09-13-migrating-jasmine-tests-to-typescript/index.md",title:"Journalling the Migration of Jasmine Tests to TypeScript",description:"I previously attempted to migrate my Jasmine tests from JavaScript to TypeScript. The last time I tried it didn't go so well and I bailed. Thank the Lord for source control. But feeling I shouldn't be deterred I decided to have another crack at it.",date:"2014-09-13T00:00:00.000Z",formattedDate:"September 13, 2014",tags:[{label:"Jasmine",permalink:"/tags/jasmine"},{label:"typescript",permalink:"/tags/typescript"},{label:"javascript",permalink:"/tags/javascript"}],readingTime:9.5,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"migrating-jasmine-tests-to-typescript",title:"Journalling the Migration of Jasmine Tests to TypeScript",authors:"johnnyreilly",tags:["Jasmine","typescript","javascript"],hide_table_of_contents:!1},prevItem:{title:"He tasks me; he heaps me.... I will wreak that MOQ upon him.",permalink:"/he-tasks-me-he-heaps-me-i-will-wreak"},nextItem:{title:"Unit Testing an Angular Controller with Jasmine",permalink:"/unit-testing-angular-controller-with"}},p={authorsImageUrls:[void 0]},u=[{value:"What to Migrate?",id:"what-to-migrate",level:2},{value:"Off we go",id:"off-we-go",level:2},{value:"Could not find symbol &#39;$q&#39;",id:"could-not-find-symbol-q",level:2},{value:"Typings? Where we&#39;re going, we need typings...",id:"typings-where-were-going-we-need-typings",level:2},{value:"So That&#39;s All Good...",id:"so-thats-all-good",level:2},{value:"Who Killed the TypeScript Language Service?",id:"who-killed-the-typescript-language-service",level:2},{value:"Solutions....",id:"solutions",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I previously attempted to migrate my Jasmine tests from JavaScript to TypeScript. The last time I tried it didn't go so well and I bailed. Thank the Lord for source control. But feeling I shouldn't be deterred I decided to have another crack at it."),(0,a.kt)("p",null,'I did manage it this time... Sort of. Unfortunately there was a problem which I discovered right at the end. An issue with the TypeScript / Visual Studio tooling. So, just to be clear, this is not a blog post of "do this and it will work perfectly". On this occasion there will be some rough edges. This post exists, as much as anything else, as a record of the problems I experienced - I hope it will prove useful. Here we go:'),(0,a.kt)("h2",o({},{id:"what-to-migrate"}),"What to Migrate?"),(0,a.kt)("p",null,"I'm going to use one of the test files in my my side project ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/Proverb"}),"Proverb"),". It's the tests for an AngularJS controller called ",(0,a.kt)("inlineCode",{parentName:"p"},"sageDetail")," ","-"," I've written about it ",(0,a.kt)("a",o({parentName:"p"},{href:"/unit-testing-angular-controller-with"}),"before"),". Here it is in all it's JavaScript-y glory:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"describe('Proverb.Web -> app-> controllers ->', function () {\n  beforeEach(function () {\n    module('app');\n  });\n\n  describe('sageDetail ->', function () {\n    var $rootScope,\n      getById_deferred, // deferred used for promises\n      $location,\n      $routeParams_stub,\n      common,\n      datacontext, // controller dependencies\n      sageDetailController; // the controller\n\n    beforeEach(inject(function (\n      _$controller_,\n      _$rootScope_,\n      _$q_,\n      _$location_,\n      _common_,\n      _datacontext_\n    ) {\n      $rootScope = _$rootScope_;\n      $q = _$q_;\n\n      $location = _$location_;\n      common = _common_;\n      datacontext = _datacontext_;\n\n      $routeParams_stub = { id: '10' };\n      getById_deferred = $q.defer();\n\n      spyOn(datacontext.sage, 'getById').and.returnValue(\n        getById_deferred.promise\n      );\n      spyOn(common, 'activateController').and.callThrough();\n      spyOn(common.logger, 'getLogFn').and.returnValue(\n        jasmine.createSpy('log')\n      );\n      spyOn($location, 'path').and.returnValue(jasmine.createSpy('path'));\n\n      sageDetailController = _$controller_('sageDetail', {\n        $location: $location,\n        $routeParams: $routeParams_stub,\n        common: common,\n        datacontext: datacontext,\n      });\n    }));\n\n    describe('on creation ->', function () {\n      it(\"controller should have a title of 'Sage Details'\", function () {\n        expect(sageDetailController.title).toBe('Sage Details');\n      });\n\n      it('controller should have no sage', function () {\n        expect(sageDetailController.sage).toBeUndefined();\n      });\n\n      it('datacontext.sage.getById should be called', function () {\n        expect(datacontext.sage.getById).toHaveBeenCalledWith(10, true);\n      });\n    });\n\n    describe('activateController ->', function () {\n      var sage_stub;\n      beforeEach(function () {\n        sage_stub = { name: 'John' };\n      });\n\n      it('should set sages to be the resolved promise values', function () {\n        getById_deferred.resolve(sage_stub);\n        $rootScope.$digest(); // So Angular processes the resolved promise\n\n        expect(sageDetailController.sage).toBe(sage_stub);\n      });\n\n      it(\"should log 'Activated Sage Details View' and set title with name\", function () {\n        getById_deferred.resolve(sage_stub);\n        $rootScope.$digest(); // So Angular processes the resolved promise\n\n        expect(sageDetailController.log).toHaveBeenCalledWith(\n          'Activated Sage Details View'\n        );\n        expect(sageDetailController.title).toBe(\n          'Sage Details: ' + sage_stub.name\n        );\n      });\n    });\n\n    describe('gotoEdit ->', function () {\n      var sage_stub;\n      beforeEach(function () {\n        sage_stub = { id: 20 };\n      });\n\n      it('should set $location.path to edit URL', function () {\n        getById_deferred.resolve(sage_stub);\n        $rootScope.$digest(); // So Angular processes the resolved promise\n\n        sageDetailController.gotoEdit();\n\n        expect($location.path).toHaveBeenCalledWith(\n          '/sages/edit/' + sage_stub.id\n        );\n      });\n    });\n  });\n});\n")),(0,a.kt)("h2",o({},{id:"off-we-go"}),"Off we go"),(0,a.kt)("p",null,"Righteo. Let's flip the switch. ",(0,a.kt)("inlineCode",{parentName:"p"},"sageDetail.js")," you shall go to the ball! One wave of my magic wand and ",(0,a.kt)("inlineCode",{parentName:"p"},"sageDetail.js")," becomes ",(0,a.kt)("inlineCode",{parentName:"p"},"sageDetail.ts"),"... Alakazam!! Of course we've got to do the fiddling with the ",(0,a.kt)("inlineCode",{parentName:"p"},"csproj")," file to include the dependent JavaScript files. (I'll be very pleased when ASP.Net vNext ships and I don't have to do this anymore....) So find this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<TypeScriptCompile Include="app\\sages\\sageDetail.ts" />\n')),(0,a.kt)("p",null,"And add this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<Content Include="app\\sages\\sageDetail.js">\n  <DependentUpon>sageDetail.ts</DependentUpon>\n</Content>\n<Content Include="app\\sages\\sageDetail.js.map">\n  <DependentUpon>sageDetail.ts</DependentUpon>\n</Content>\n')),(0,a.kt)("p",null,"What next? I've a million red squigglies in my code. It's \"could not find symbol\" city. Why? Typings! We need typings! So let's begin - I'm needing the Jasmine typings for starters. So let's hit NuGet and it looks like we need ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.nuget.org/packages/jasmine.TypeScript.DefinitelyTyped/"}),"this"),":"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"Install-Package jasmine.TypeScript.DefinitelyTyped"),"That did no good at all. Still red squigglies. I'm going to hazard a guess that this is something to do with the fact my JavaScript Unit Test project doesn't contain the various TypeScript artefacts that Visual Studio kindly puts into the web csproj for you. This is because I'm keeping my JavaScript tests in a separate project from the code being tested. Also, the Visual Studio TypeScript tooling seems to work on the assumption that TypeScript will only be used within a web project; not a test project. Well I won't let that hold me back... Time to port the TypeScript artefacts in the web csproj over by hand. I'll take this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<Import Project="$(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion)\\TypeScript\\Microsoft.TypeScript.Default.props" Condition="Exists(\'$(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion)\\TypeScript\\Microsoft.TypeScript.Default.props\')" />\n')),(0,a.kt)("p",null,"And I'll also take this"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),"<PropertyGroup Condition=\"'$(Configuration)' == 'Debug'\">\n  <TypeScriptNoImplicitAny>True</TypeScriptNoImplicitAny>\n</PropertyGroup>\n<Import Project=\"$(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion)\\TypeScript\\Microsoft.TypeScript.targets\" Condition=\"Exists('$(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion)\\TypeScript\\Microsoft.TypeScript.targets')\" />\n")),(0,a.kt)("p",null,"Bingo bango - a difference. I no longer have red squigglies under the Jasmine statements (",(0,a.kt)("inlineCode",{parentName:"p"},"describe"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"it")," etc). But alas, I do everywhere else. One in particular draws my eye..."),(0,a.kt)("h2",o({},{id:"could-not-find-symbol-q"}),"Could not find symbol '$q'"),(0,a.kt)("p",null,"Once again TypeScript picks up the hidden bugs in my JavaScript:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"$q = _$q_;\n")),(0,a.kt)("p",null,"That's right it's an implicit global. Quickly fixed:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"var $q = _$q_;\n")),(0,a.kt)("h2",o({},{id:"typings-where-were-going-we-need-typings"}),"Typings? Where we're going, we need typings..."),(0,a.kt)("p",null,"We need more types. We're going to need the types created by our application; our controllers / services / directives etc. As well that we need the types used in the creation of the app. So the Angular typings etc. Since we're going to need to use ",(0,a.kt)("inlineCode",{parentName:"p"},"reference")," statements to pull in the types created by our application I might as well use them to pull in the required definition files as well (eg ",(0,a.kt)("inlineCode",{parentName:"p"},"angular.d.ts"),"):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'/// <reference path="../../../proverb.web/scripts/typings/angularjs/angular.d.ts" />\n/// <reference path="../../../proverb.web/scripts/typings/angularjs/angular-mocks.d.ts" />\n/// <reference path="../../../proverb.web/app/sages/sagedetail.ts" />\n/// <reference path="../../../proverb.web/app/common/common.ts" />\n/// <reference path="../../../proverb.web/app/services/datacontext.ts" />\n/// <reference path="../../../proverb.web/app/services/repository.sage.ts" />\n')),(0,a.kt)("p",null,"Now we need to work our way through the \"variable 'x' implicitly has an 'any' type\" messages. One thing we need to do is to amend our original sageDetails.ts file so that the ",(0,a.kt)("inlineCode",{parentName:"p"},"sageDetailRouteParams")," interface and ",(0,a.kt)("inlineCode",{parentName:"p"},"SageDetail")," class are exported from the controllers module. We can't use the types otherwise. Now we can add typings to our file - once finished it looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"/// <reference path=\"../../../proverb.web/scripts/typings/angularjs/angular.d.ts\" />\n/// <reference path=\"../../../proverb.web/scripts/typings/angularjs/angular-mocks.d.ts\" />\n/// <reference path=\"../../../proverb.web/app/sages/sagedetail.ts\" />\n/// <reference path=\"../../../proverb.web/app/common/common.ts\" />\n/// <reference path=\"../../../proverb.web/app/services/datacontext.ts\" />\n/// <reference path=\"../../../proverb.web/app/services/repository.sage.ts\" />\ndescribe('Proverb.Web -> app-> controllers ->', function () {\n  beforeEach(function () {\n    module('app');\n  });\n\n  describe('sageDetail ->', function () {\n    var $rootScope: ng.IRootScopeService,\n      // deferred used for promises\n      getById_deferred: ng.IDeferred<sage>,\n      // controller dependencies\n      $location: ng.ILocationService,\n      $routeParams_stub: controllers.sageDetailRouteParams,\n      common: common,\n      datacontext: datacontext,\n      sageDetailController: controllers.SageDetail; // the controller\n\n    beforeEach(inject(function (\n      _$controller_: any,\n      _$rootScope_: ng.IRootScopeService,\n      _$q_: ng.IQService,\n      _$location_: ng.ILocationService,\n      _common_: common,\n      _datacontext_: datacontext\n    ) {\n      $rootScope = _$rootScope_;\n      var $q = _$q_;\n\n      $location = _$location_;\n      common = _common_;\n      datacontext = _datacontext_;\n\n      $routeParams_stub = { id: '10' };\n      getById_deferred = $q.defer();\n\n      spyOn(datacontext.sage, 'getById').and.returnValue(\n        getById_deferred.promise\n      );\n      spyOn(common, 'activateController').and.callThrough();\n      spyOn(common.logger, 'getLogFn').and.returnValue(\n        jasmine.createSpy('log')\n      );\n      spyOn($location, 'path').and.returnValue(jasmine.createSpy('path'));\n\n      sageDetailController = _$controller_('sageDetail', {\n        $location: $location,\n        $routeParams: $routeParams_stub,\n        common: common,\n        datacontext: datacontext,\n      });\n    }));\n\n    describe('on creation ->', function () {\n      it(\"controller should have a title of 'Sage Details'\", function () {\n        expect(sageDetailController.title).toBe('Sage Details');\n      });\n\n      it('controller should have no sage', function () {\n        expect(sageDetailController.sage).toBeUndefined();\n      });\n\n      it('datacontext.sage.getById should be called', function () {\n        expect(datacontext.sage.getById).toHaveBeenCalledWith(10, true);\n      });\n    });\n\n    describe('activateController ->', function () {\n      var sage_stub: sage;\n      beforeEach(function () {\n        sage_stub = {\n          name: 'John',\n          id: 10,\n          username: 'John',\n          email: 'john@',\n          dateOfBirth: new Date(),\n        };\n      });\n\n      it('should set sages to be the resolved promise values', function () {\n        getById_deferred.resolve(sage_stub);\n        $rootScope.$digest(); // So Angular processes the resolved promise\n\n        expect(sageDetailController.sage).toBe(sage_stub);\n      });\n\n      it(\"should log 'Activated Sage Details View' and set title with name\", function () {\n        getById_deferred.resolve(sage_stub);\n        $rootScope.$digest(); // So Angular processes the resolved promise\n\n        expect(sageDetailController.log).toHaveBeenCalledWith(\n          'Activated Sage Details View'\n        );\n        expect(sageDetailController.title).toBe(\n          'Sage Details: ' + sage_stub.name\n        );\n      });\n    });\n\n    describe('gotoEdit ->', function () {\n      var sage_stub: sage;\n      beforeEach(function () {\n        sage_stub = {\n          name: 'John',\n          id: 20,\n          username: 'John',\n          email: 'john@',\n          dateOfBirth: new Date(),\n        };\n      });\n\n      it('should set $location.path to edit URL', function () {\n        getById_deferred.resolve(sage_stub);\n        $rootScope.$digest(); // So Angular processes the resolved promise\n\n        sageDetailController.gotoEdit();\n\n        expect($location.path).toHaveBeenCalledWith(\n          '/sages/edit/' + sage_stub.id\n        );\n      });\n    });\n  });\n});\n")),(0,a.kt)("h2",o({},{id:"so-thats-all-good"}),"So That's All Good..."),(0,a.kt)("p",null,"Except it's not. When I run the tests using Chutzpah my ",(0,a.kt)("inlineCode",{parentName:"p"},"sageDetail")," controller tests aren't found. My spider sense is tingling. This is something to do with the ",(0,a.kt)("inlineCode",{parentName:"p"},"reference")," statements. They're throwing Chutzpah off. No bother, I can fix that with a quick tweak of the project file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),"<PropertyGroup Condition=\"'$(Configuration)' == 'Debug'\">\n    <TypeScriptNoImplicitAny>True</TypeScriptNoImplicitAny>\n    <TypeScriptRemoveComments>True</TypeScriptRemoveComments>\n  </PropertyGroup>\n")),(0,a.kt)("p",null,"The TypeScript compiler will now strip comments; which includes the ",(0,a.kt)("inlineCode",{parentName:"p"},"reference")," statements. Now my tests are detected ","*",(0,a.kt)("strong",{parentName:"p"},"and"),"*"," they run. Yay!"),(0,a.kt)("h2",o({},{id:"who-killed-the-typescript-language-service"}),"Who Killed the TypeScript Language Service?"),(0,a.kt)("p",null,"Yup it's dead. Whilst the compilation itself has no issues, take a look at the errors being presented for just one of the files back in the original web project:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(84438).Z,width:"640",height:"454"})),(0,a.kt)("p",null,"It looks like having one TypeScript project in a solution which uses ",(0,a.kt)("inlineCode",{parentName:"p"},"reference")," comments somehow breaks the implicit referencing behaviour built into Visual Studio for other TypeScript projects in the solution. I can say this with some confidence as if I pull out the ",(0,a.kt)("inlineCode",{parentName:"p"},"reference")," comments from the top of the test file that we've converted then it's business as usual - the TypeScript Language Service lives once more. I'm sure you can see the problem here though: the TypeScript test file doesn't compile. All rather unsatisfactory."),(0,a.kt)("p",null,"I suspect that if I added ",(0,a.kt)("inlineCode",{parentName:"p"},"reference")," comments throughout the web project the TypeScript Language Service would be just fine. But I rather like the implicit referencing functionality so I'm not inclined to do that. After reaching something of a brick wall and thinking I had encountered a bug in the TypeScript Language service I ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/issues/673"}),"raised an issue on GitHub"),"."),(0,a.kt)("h2",o({},{id:"solutions"}),"Solutions...."),(0,a.kt)("p",null,"Thanks to the help of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/mhegazy"}),"Mohamed Hegazy")," it emerged that the problem was down to missing ",(0,a.kt)("inlineCode",{parentName:"p"},"reference")," comments in my ",(0,a.kt)("inlineCode",{parentName:"p"},"sageDetail")," controller tests. One thing I had not considered was the 2 different ways each of my TypeScript projects were working:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Proverb.Web uses the Visual Studio implicit referencing functionality. This means that I do not need to use ",(0,a.kt)("inlineCode",{parentName:"li"},"reference")," comments in the TypeScript files in Proverb.Web."),(0,a.kt)("li",{parentName:"ul"},"Proverb.Web.JavaScript does ","*",(0,a.kt)("strong",{parentName:"li"},"not"),"*"," uses the implicit referencing functionality. It needs ",(0,a.kt)("inlineCode",{parentName:"li"},"reference")," comments to resolve references.")),(0,a.kt)("p",null,"The important thing to take away from this (and the thing I had overlooked) was that Proverb.Web.JavaScript uses ",(0,a.kt)("inlineCode",{parentName:"p"},"reference")," comments to pull in Proverb.Web TypeScript files. Those files have dependencies which are ","*",(0,a.kt)("strong",{parentName:"p"},"not"),"*"," stated using ",(0,a.kt)("inlineCode",{parentName:"p"},"reference")," comments. So the compiler trips up when it tries to walk the dependency tree - there are no ",(0,a.kt)("inlineCode",{parentName:"p"},"reference")," comments to be followed! So for example, ",(0,a.kt)("inlineCode",{parentName:"p"},"common.ts")," has a dependency upon ",(0,a.kt)("inlineCode",{parentName:"p"},"logger.ts"),". Fixing the TypeScript Language Service involves ensuring that the full dependency list is included in the ",(0,a.kt)("inlineCode",{parentName:"p"},"sageDetail")," controller tests file, like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),'/// <reference path="../../../proverb.web/scripts/typings/angularjs/angular.d.ts" />\n/// <reference path="../../../proverb.web/scripts/typings/angularjs/angular-mocks.d.ts" />\n/// <reference path="../../../proverb.web/scripts/typings/angularjs/angular-route.d.ts" />\n/// <reference path="../../../proverb.web/scripts/typings/toastr/toastr.d.ts" />\n/// <reference path="../../../proverb.web/scripts/typings/underscore/underscore.d.ts" />\n/// <reference path="../../../proverb.web/app/sages/sagedetail.ts" />\n/// <reference path="../../../proverb.web/app/common/logger.ts" />\n/// <reference path="../../../proverb.web/app/common/common.ts" />\n/// <reference path="../../../proverb.web/app/services/datacontext.ts" />\n/// <reference path="../../../proverb.web/app/services/repositories.ts" />\n/// <reference path="../../../proverb.web/app/services/repository.sage.ts" />\n/// <reference path="../../../proverb.web/app/services/repository.saying.ts" />\n/// <reference path="../../../proverb.web/app/app.ts" />\n/// <reference path="../../../proverb.web/app/config.route.ts" />\n')),(0,a.kt)("p",null,"With this in place you have a working solution, albeit one that is a little flaky. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/issues/673#issuecomment-56024348"}),"An alternative solution was suggested by Noel Abrahams")," which I quote here:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Why not do the following?"),(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"},"Compile Proverb.Web with --declarations and the option for combining output into a single file. This should create a Proverb.Web.d.ts in your output directory."),(0,a.kt)("li",{parentName:"ul"},"In Proverb.Web.Tests.JavaScript add a reference to this file."),(0,a.kt)("li",{parentName:"ul"},'Right-click Proverb.Web.Tests.JavaScript select "Build Dependencies" > "Project Dependencies" and add a reference to Proverb.Web.')),(0,a.kt)("p",{parentName:"blockquote"},"I don't think directly referencing TypeScript source files is a good idea, because it causes the file to be rebuilt every time the dependant project is compiled.")),(0,a.kt)("p",null,"Mohamed rather liked this solution. It looks like some more work is due to be done on the TypeScript tooling to make this less headache-y in future."))}d.isMDXComponent=!0},15430:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"he-tasks-me-he-heaps-me-i-will-wreak",title:"He tasks me; he heaps me.... I will wreak that MOQ upon him.",authors:"johnnyreilly",tags:["unit testing","MOQ"],hide_table_of_contents:!1},s=void 0,l={permalink:"/he-tasks-me-he-heaps-me-i-will-wreak",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-10-03-he-tasks-me-he-heaps-me-i-will-wreak/index.md",source:"@site/blog/2014-10-03-he-tasks-me-he-heaps-me-i-will-wreak/index.md",title:"He tasks me; he heaps me.... I will wreak that MOQ upon him.",description:"Enough with the horrific misquotes - this is about Moq and async (that's my slight justification for robbing Herman Melville).",date:"2014-10-03T00:00:00.000Z",formattedDate:"October 3, 2014",tags:[{label:"unit testing",permalink:"/tags/unit-testing"},{label:"MOQ",permalink:"/tags/moq"}],readingTime:3.045,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"he-tasks-me-he-heaps-me-i-will-wreak",title:"He tasks me; he heaps me.... I will wreak that MOQ upon him.",authors:"johnnyreilly",tags:["unit testing","MOQ"],hide_table_of_contents:!1},prevItem:{title:"Caching and Cache-Busting in AngularJS with HTTP interceptors",permalink:"/caching-and-cache-busting-in-angularjs-with-http-interceptors"},nextItem:{title:"Journalling the Migration of Jasmine Tests to TypeScript",permalink:"/migrating-jasmine-tests-to-typescript"}},p={authorsImageUrls:[void 0]},u=[{value:"But wait.... What if there&#39;s like... Nothing?",id:"but-wait-what-if-theres-like-nothing",level:2},{value:"Here&#39;s one I made earlier...",id:"heres-one-i-made-earlier",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Enough with the horrific misquotes - this is about Moq and async (that's my slight justification for robbing Herman Melville)."),(0,a.kt)("p",null,"It's pretty straightforward to use Moq to do async testing thanks to it's marvellous ",(0,a.kt)("inlineCode",{parentName:"p"},"ReturnsAsync")," method. That means it's really easy to test a class that consumes an async API. Below is an example of a class that does just that: (it so happens that this class is a Web API controller but that's pretty irrelevant to be honest)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"namespace Proverb.Web.Controllers\n{\n    // ISageService included inline for ease of explanation\n    public interface ISageService\n    {\n        Task<int> DeleteAsync(int id);\n    }\n\n    public class SageController : ApiController\n    {\n        ISageService _sageService;\n\n        public SageController(ISageService userService)\n        {\n            _sageService = userService;\n        }\n\n        public async Task<IHttpActionResult> Delete(int id)\n        {\n            int deleteCount = await _sageService.DeleteAsync(id);\n\n            if (deleteCount == 0)\n                return NotFound();\n            else\n                return Ok();\n        }\n   }\n}\n")),(0,a.kt)("p",null,"To mock the ",(0,a.kt)("inlineCode",{parentName:"p"},"_sageService.DeleteAsync")," method it's as easy as this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"namespace Proverb.Web.Tests.ASPNet.Controllers\n{\n    [TestClass]\n    public class SageControllerTests\n    {\n        private Mock<ISageService> _sageServiceMock;\n        private SageController _controller;\n\n        [TestInitialize]\n        public void Initialise()\n        {\n            _sageServiceMock = new Mock<ISageService>();\n\n            _controller = new SageController(_sageServiceMock.Object);\n        }\n\n        [TestMethod]\n        public async Task Delete_returns_a_NotFound()\n        {\n            _sageServiceMock\n                .Setup(x => x.DeleteAsync(_sage.Id))\n                .ReturnsAsync(0); // This makes me *so* happy...\n\n            IHttpActionResult result = await _controller.Delete(_sage.Id);\n\n            var notFound = result as NotFoundResult;\n            Assert.IsNotNull(notFound);\n            _sageServiceMock.Verify(x => x.DeleteAsync(_sage.Id));\n        }\n\n        [TestMethod]\n        public async Task Delete_returns_an_Ok()\n        {\n            _sageServiceMock\n                .Setup(x => x.DeleteAsync(_sage.Id))\n                .ReturnsAsync(1); // I'm still excited now!\n\n            IHttpActionResult result = await _controller.Delete(_sage.Id);\n\n            var ok = result as OkResult;\n            Assert.IsNotNull(ok);\n            _sageServiceMock.Verify(x => x.DeleteAsync(_sage.Id));\n        }\n    }\n}\n")),(0,a.kt)("h2",o({},{id:"but-wait-what-if-theres-like-nothing"}),"But wait.... What if there's like... Nothing?"),(0,a.kt)("p",null,"Nope, I'm not getting into metaphysics. Something more simple. What if the ",(0,a.kt)("inlineCode",{parentName:"p"},"async")," API you're consuming returns just a ",(0,a.kt)("inlineCode",{parentName:"p"},"Task"),"? Not a ",(0,a.kt)("inlineCode",{parentName:"p"},"Task")," of ",(0,a.kt)("inlineCode",{parentName:"p"},"int")," but a simple old humble ",(0,a.kt)("inlineCode",{parentName:"p"},"Task"),"."),(0,a.kt)("p",null,"So to take our example we're going from this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public interface ISageService\n    {\n        Task<int> DeleteAsync(int id);\n    }\n")),(0,a.kt)("p",null,"To this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"public interface ISageService\n    {\n        Task DeleteAsync(int id);\n    }\n")),(0,a.kt)("p",null,"Your initial thought might be \"well that's okay, I'll just lop off the ",(0,a.kt)("inlineCode",{parentName:"p"},"ReturnsAsync")," statements and I'm home free\". That's what I thought anyway.... And I was ","*",(0,a.kt)("strong",{parentName:"p"},"WRONG"),"*","! A moments thought and you realise that there's still a return type - it's just ",(0,a.kt)("inlineCode",{parentName:"p"},"Task")," now. What you want to do is something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"_sageServiceMock\n                .Setup(x => x.DeleteAsync(_sage.Id))\n                .ReturnsAsync(void); // This'll definitely work... Probably\n")),(0,a.kt)("p",null,"No it won't - ",(0,a.kt)("inlineCode",{parentName:"p"},"void")," is not a real type and much as you might like it to, this is not going to work."),(0,a.kt)("p",null,"So right now you're thinking, well Moq probably has my back - it'll have something like ",(0,a.kt)("inlineCode",{parentName:"p"},"ReturnsTask"),", right? Wrong! It's intentional it turns out - there's a discussion on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Moq/moq4/issues/117"}),"GitHub about the issue"),". And in that discussion there's just what we need. We can use ",(0,a.kt)("inlineCode",{parentName:"p"},"Task.Delay")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"Task.FromResult")," alongside Moq's good old ",(0,a.kt)("inlineCode",{parentName:"p"},"Returns")," method and we're home free!"),(0,a.kt)("h2",o({},{id:"heres-one-i-made-earlier"}),"Here's one I made earlier..."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"namespace Proverb.Web.Controllers\n{\n    // ISageService again included inline for ease of explanation\n    public interface ISageService\n    {\n        Task DeleteAsync(int id);\n    }\n\n    public class SageController : ApiController\n    {\n        ISageService _sageService;\n\n        public SageController(ISageService userService)\n        {\n            _sageService = userService;\n        }\n\n        public async Task<IHttpActionResult> Delete(int id)\n        {\n            await _sageService.DeleteAsync(id);\n\n            return Ok();\n        }\n   }\n}\n")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"namespace Proverb.Web.Tests.ASPNet.Controllers\n{\n    [TestClass]\n    public class SageControllerTests\n    {\n        private Mock<ISageService> _sageServiceMock;\n        private SageController _controller;\n\n        readonly Task TaskOfNowt = Task.Delay(0);\n        // Or you could use this equally valid but slightly more verbose approach:\n        //readonly Task TaskOfNowt = Task.FromResult<object>(null);\n\n        [TestInitialize]\n        public void Initialise()\n        {\n            _sageServiceMock = new Mock<ISageService>();\n\n            _controller = new SageController(_sageServiceMock.Object);\n        }\n\n        [TestMethod]\n        public async Task Delete_returns_an_Ok()\n        {\n            _sageServiceMock\n                .Setup(x => x.DeleteAsync(_sage.Id))\n                .Returns(TaskOfNowt); // Feels good doesn't it?\n\n            IHttpActionResult result = await _controller.Delete(_sage.Id);\n\n            var ok = result as OkResult;\n            Assert.IsNotNull(ok);\n            _sageServiceMock.Verify(x => x.DeleteAsync(_sage.Id));\n        }\n    }\n}\n")))}d.isMDXComponent=!0},63623:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"caching-and-cache-busting-in-angularjs-with-http-interceptors",title:"Caching and Cache-Busting in AngularJS with HTTP interceptors",authors:"johnnyreilly",tags:["typescript","AngularJS"],hide_table_of_contents:!1},s=void 0,l={permalink:"/caching-and-cache-busting-in-angularjs-with-http-interceptors",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-10-06-caching-and-cache-busting-in-angularjs-with-http-interceptors/index.md",source:"@site/blog/2014-10-06-caching-and-cache-busting-in-angularjs-with-http-interceptors/index.md",title:"Caching and Cache-Busting in AngularJS with HTTP interceptors",description:"Loading On-Demand and Caching",date:"2014-10-06T00:00:00.000Z",formattedDate:"October 6, 2014",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"AngularJS",permalink:"/tags/angular-js"}],readingTime:4.075,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"caching-and-cache-busting-in-angularjs-with-http-interceptors",title:"Caching and Cache-Busting in AngularJS with HTTP interceptors",authors:"johnnyreilly",tags:["typescript","AngularJS"],hide_table_of_contents:!1},prevItem:{title:"Using Gulp in Visual Studio instead of Web Optimization",permalink:"/using-gulp-in-visual-studio-instead-of-web-optimization"},nextItem:{title:"He tasks me; he heaps me.... I will wreak that MOQ upon him.",permalink:"/he-tasks-me-he-heaps-me-i-will-wreak"}},p={authorsImageUrls:[void 0]},u=[{value:"Loading On-Demand and Caching",id:"loading-on-demand-and-caching",level:2},{value:"Loading Views in AngularJS Using this Approach",id:"loading-views-in-angularjs-using-this-approach",level:2},{value:"Interesting technique.... How do I apply it?",id:"interesting-technique-how-do-i-apply-it",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"loading-on-demand-and-caching"}),"Loading On-Demand and Caching"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"/caching-and-cache-busting-with-requirejs"}),"I've written before about my own needs for caching and cache-busting when using RequireJS.")," Long story short, when I'm loading ",(0,a.kt)("em",{parentName:"p"},"static")," resources (scripts / views etc) on demand from the server I want to do a little URL fiddling along the way. I want to do that to cater for these 2 scenarios:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("em",{parentName:"li"},"In Development")," ","-",' I want my URLs for static resources to have a unique querystring with each request to ensure that resources are loaded afresh each time. (eg so a GET request URL might look like this: "/app/layout/sidebar.html?v=IAmRandomYesRandomRandomIsWhatIAm58965782")'),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("em",{parentName:"li"},"In Production")," ","-",' I want my URLs for static resources to have a querystring with that is driven by the application version number. This means that static resources can potentially be cached with a given querystring - subsequent requests should result in a 304 status code (indicating \u201cNot Modified\u201d) and local cache should be used. But when a new version of the app is rolled out and the app version is incremented then the querystring will change and resources will be loaded anew. (eg a GET request URL might look like this: "/app/layout/sidebar.html?v=1.0.5389.16180")')),(0,a.kt)("h2",o({},{id:"loading-views-in-angularjs-using-this-approach"}),"Loading Views in AngularJS Using this Approach"),(0,a.kt)("p",null,"I have exactly the same use cases when I'm using AngularJS for views. Out of the box with AngularJS 1.x views are loaded lazily (unlike controllers, services etc). For that reason I want to use the same approach I've outlined above to load my views. Also, I want to prepend my URLs with the root of my application - this allows me to cater for my app being deployed in a virtual folder."),(0,a.kt)("p",null,"It turns out that's pretty easy thanks to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.angularjs.org/api/ng/service/$http#interceptors"}),"HTTP interceptors"),". They allow you to step into the pipeline and access and modify requests and responses made by your application. When AngularJS loads a view it's the HTTP service doing the heavy lifting. So to deal with my own use case, I just need to add in an HTTP interceptor that amends the get request. This is handled in the example that follows in the ",(0,a.kt)("inlineCode",{parentName:"p"},"configureHttpProvider")," function: (The example that follows is TypeScript - though if you just chopped out the interface and the type declarations you'd find this is pretty much idiomatic JavaScript)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"interface config {\n  appRoot: string; // eg \"/\"\n  inDebug: boolean; // eg true or false\n  urlCacheBusterSuffix: string; // if in debug this might look like this: \"v=1412608547047\",\n  // if not in debug this might look like this: \"v=1.0.5389.16180\"\n}\n\nfunction configureHttpProvider() {\n  // This is the name of our HTTP interceptor\n  var serviceId = 'urlInterceptor';\n\n  // We're going to create a service factory which will be our HTTP interceptor\n  // It will be injected with a config object which is represented by the config interface above\n  app.factory(serviceId, [\n    '$templateCache',\n    'config',\n    function ($templateCache: ng.ITemplateCacheService, config: config) {\n      // We're returning an object literal with a single function; the \"request\" function\n      var service = {\n        request: request,\n      };\n\n      return service;\n\n      // Request will be called with a request config object which includes the URL which we will amend\n      function request(requestConfig: ng.IRequestConfig) {\n        // For the loading of HTML templates we want the appRoot to be prefixed to the path\n        // and we want a suffix to either allow caching or prevent caching\n        // (depending on whether in debug mode or not)\n        if (\n          requestConfig.method === 'GET' &&\n          endsWith(requestConfig.url, '.html')\n        ) {\n          // If this has already been placed into a primed template cache then we should leave the URL as is\n          // so that the version in templateCache is served.  If we tweak the URL then it will not be found\n          var cachedAlready = $templateCache.get(requestConfig.url);\n          if (!cachedAlready) {\n            // THIS IS THE MAGIC!!!!!!!!!!!!!!!\n\n            requestConfig.url =\n              config.appRoot + requestConfig.url + config.urlCacheBusterSuffix;\n\n            // WE NOW HAVE A URL WHICH IS CACHE-FRIENDLY FOR OUR PURPOSES - REJOICE!!!!!!!!!!!\n          }\n        }\n\n        return requestConfig;\n      }\n\n      // <a href=\"http://stackoverflow.com/a/2548133/761388\">a simple JavaScript string \"endswith\" implementation</a>\n      function endsWith(str: string, suffix: string) {\n        return str.indexOf(suffix, str.length - suffix.length) !== -1;\n      }\n    },\n  ]);\n\n  // This adds our service factory interceptor into the pipeline\n  app.config([\n    '$httpProvider',\n    function ($httpProvider: ng.IHttpProvider) {\n      $httpProvider.interceptors.push(serviceId);\n    },\n  ]);\n}\n")),(0,a.kt)("p",null,"This interceptor steps in and amends each ajax request when all the following conditions hold true:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"It's a GET request."),(0,a.kt)("li",{parentName:"ol"},'It\'s requesting a file that ends ".html" - a template basically.'),(0,a.kt)("li",{parentName:"ol"},"The template cache does not already contain the template. I left this out at first and got bitten when I found that the contents of the template cache were being ignored for pre-primed templates. Ugly.")),(0,a.kt)("h2",o({},{id:"interesting-technique-how-do-i-apply-it"}),"Interesting technique.... How do I apply it?"),(0,a.kt)("p",null,"Isn't it always much more helpful when you can see an example of code in the context of which it is actually used? Course it is! If you want that then take a look at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/Proverb/blob/master/Proverb.Web/app/app.ts"}),(0,a.kt)("inlineCode",{parentName:"a"},"app.ts"))," on GitHub. And if you'd like the naked JavaScript well ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/Proverb/blob/master/Proverb.Web/app/app.js"}),"that's there too"),"."))}d.isMDXComponent=!0},10212:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"using-gulp-in-visual-studio-instead-of-web-optimization",title:"Using Gulp in Visual Studio instead of Web Optimization",authors:"johnnyreilly",tags:["Task Runner Explorer","Visual Studio","typescript","javascript","gulpjs"],hide_table_of_contents:!1},s=void 0,l={permalink:"/using-gulp-in-visual-studio-instead-of-web-optimization",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-11-04-using-gulp-in-visual-studio-instead-of-web-optimization/index.md",source:"@site/blog/2014-11-04-using-gulp-in-visual-studio-instead-of-web-optimization/index.md",title:"Using Gulp in Visual Studio instead of Web Optimization",description:"Updated 17/02/2015: I've taken the approach discussed in this post a little further - you can see here",date:"2014-11-04T00:00:00.000Z",formattedDate:"November 4, 2014",tags:[{label:"Task Runner Explorer",permalink:"/tags/task-runner-explorer"},{label:"Visual Studio",permalink:"/tags/visual-studio"},{label:"typescript",permalink:"/tags/typescript"},{label:"javascript",permalink:"/tags/javascript"},{label:"gulpjs",permalink:"/tags/gulpjs"}],readingTime:15.435,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"using-gulp-in-visual-studio-instead-of-web-optimization",title:"Using Gulp in Visual Studio instead of Web Optimization",authors:"johnnyreilly",tags:["Task Runner Explorer","Visual Studio","typescript","javascript","gulpjs"],hide_table_of_contents:!1},prevItem:{title:"Pretending to be someone you're not and the dark pit of despair",permalink:"/Coded-UI-IE-11-and-the-runas-problem"},nextItem:{title:"Caching and Cache-Busting in AngularJS with HTTP interceptors",permalink:"/caching-and-cache-busting-in-angularjs-with-http-interceptors"}},p={authorsImageUrls:[void 0]},u=[{value:"Updated 17/02/2015: I&#39;ve taken the approach discussed in this post a little further - you can see here",id:"updated-17022015-ive-taken-the-approach-discussed-in-this-post-a-little-further---you-can-see-here",level:3},{value:"Bub bye Web Optimization",id:"bub-bye-web-optimization",level:2},{value:"Installing Gulp (and Associates)",id:"installing-gulp-and-associates",level:2},{value:"Making <code>gulpfile.js</code>",id:"making-gulpfilejs",level:2},{value:"What <code>gulpfile.js</code> does",id:"what-gulpfilejs-does",level:2},{value:"Task Runner Explorer gets in on the action",id:"task-runner-explorer-gets-in-on-the-action",level:2},{value:"How do I use this in my HTML?",id:"how-do-i-use-this-in-my-html",level:2},{value:"I want to publish, how do I include my assets?",id:"i-want-to-publish-how-do-i-include-my-assets",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h3",o({},{id:"updated-17022015-ive-taken-the-approach-discussed-in-this-post-a-little-further---you-can-see-here"}),"Updated 17/02/2015: I've taken the approach discussed in this post a little further - you can see ",(0,a.kt)("a",o({parentName:"h3"},{href:"/using-web-optimization-with-mvc-3"}),"here")),(0,a.kt)("p",null,"I've used a number of tools to package up JavaScript and CSS in my web apps. ",(0,a.kt)("a",o({parentName:"p"},{href:"http://getcassette.net/"}),"Andrew Davey's tremendous Cassette")," has been really useful. Also good (although less powerful/magical) has been Microsoft's very own ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.nuget.org/packages/Microsoft.AspNet.Web.Optimization/"}),"Microsoft.AspNet.Web.Optimization")," that ships with MVC."),(0,a.kt)("p",null,"I was watching the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://youtu.be/NgbA2BxNweE?list=PL0M0zPgJ3HSftTAAHttA3JQU4vOjXFquF"}),"ASP.NET Community Standup from October 7th, 2014")," and learned that the ASP.Net team is not planning to migrate ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.nuget.org/packages/Microsoft.AspNet.Web.Optimization/"}),"Microsoft.AspNet.Web.Optimization")," to the next version of ASP.Net. Instead they're looking to make use of JavaScript task runners like ",(0,a.kt)("a",o({parentName:"p"},{href:"http://gruntjs.com/"}),"Grunt")," and maybe ",(0,a.kt)("a",o({parentName:"p"},{href:"http://gulpjs.com/"}),"Gulp"),". Perhaps you're even dimly aware that they've been taking steps to make these runners more of a first class citizen in Visual Studio, hence the recent release of the new and groovy ",(0,a.kt)("a",o({parentName:"p"},{href:"http://visualstudiogallery.msdn.microsoft.com/8e1b4368-4afb-467a-bc13-9650572db708"}),"Task Runner Explorer"),"."),(0,a.kt)("p",null,'Gulp has been on my radar for a while now as has Grunt. By "on my radar" what I really mean is "Hmmmm, I really need to learn this..... perhaps I could wait until the ',(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Videotape_format_war"}),"Betamax vs VHS battles"),' are done? Oh never mind, here we go...".'),(0,a.kt)("p",null,"My understanding is that Grunt and Gulp essentially do the same thing (run tasks in JavaScript) but have different approaches. Grunt is more about configuration, Gulp is more about code. At present Gulp also has a performance advantage as it does less IO than Grunt - though I understand that's due to change in the future. But generally my preference is code over configuration. On that basis I decided that I was going to give Gulp first crack."),(0,a.kt)("h2",o({},{id:"bub-bye-web-optimization"}),"Bub bye Web Optimization"),(0,a.kt)("p",null,"I already had a project that used ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/Proverb"}),"Web Optimization")," to bundle JavaScript and CSS files. When debugging on my own machine Web Optimization served up the full JavaScript and CSS files. Thanks to the magic of source maps I was able to debug the TypeScript that created the JavaScript files too. Which was nice. When I deployed to production, Web Optimization minified and concatenated the JavaScript and CSS files. This meant I had a single HTTP request for JavaScript and a single HTTP request for CSS. This was also... nooice!"),(0,a.kt)("p",null,"I took a copy of my existing project and created a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/Proverb-gulp"}),"new repo for it on GitHub"),". It was very simple in terms of bundling. It had a ",(0,a.kt)("inlineCode",{parentName:"p"},"BundleConfig")," that created 2 bundles; 1 for JavaScript and 1 for CSS:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System.Web;\nusing System.Web.Optimization;\n\nnamespace Proverb.Web\n{\n    public class BundleConfig\n    {\n        // For more information on bundling, visit http://go.microsoft.com/fwlink/?LinkId=301862\n        public static void RegisterBundles(BundleCollection bundles)\n        {\n            var angularApp = new ScriptBundle("~/angularApp").Include(\n\n                // Vendor Scripts\n                "~/scripts/jquery-{version}.js",\n                "~/scripts/angular.js",\n                "~/scripts/angular-animate.js",\n                "~/scripts/angular-route.js",\n                "~/scripts/angular-sanitize.js",\n                "~/scripts/angular-ui/ui-bootstrap-tpls.js",\n\n                "~/scripts/toastr.js",\n                "~/scripts/moment.js",\n                "~/scripts/spin.js",\n                "~/scripts/underscore.js",\n\n                // Bootstrapping\n                "~/app/app.js",\n                "~/app/config.route.js",\n\n                // common Modules\n                "~/app/common/common.js",\n                "~/app/common/logger.js",\n                "~/app/common/spinner.js",\n\n                // common.bootstrap Modules\n                "~/app/common/bootstrap/bootstrap.dialog.js"\n                );\n\n            // directives\n            angularApp.IncludeDirectory("~/app/directives", "*.js", true);\n\n            // services\n            angularApp.IncludeDirectory("~/app/services", "*.js", true);\n\n            // controllers\n            angularApp.IncludeDirectory("~/app/admin", "*.js", true);\n            angularApp.IncludeDirectory("~/app/about", "*.js", true);\n            angularApp.IncludeDirectory("~/app/dashboard", "*.js", true);\n            angularApp.IncludeDirectory("~/app/layout", "*.js", true);\n            angularApp.IncludeDirectory("~/app/sayings", "*.js", true);\n            angularApp.IncludeDirectory("~/app/sages", "*.js", true);\n\n            bundles.Add(angularApp);\n\n            bundles.Add(new StyleBundle("~/Content/css").Include(\n                "~/content/ie10mobile.css",\n                "~/content/bootstrap.css",\n                "~/content/font-awesome.css",\n                "~/content/toastr.css",\n                "~/content/styles.css"\n            ));\n        }\n    }\n}\n')),(0,a.kt)("p",null,"I set myself a task. I wanted to be able to work in ","*",(0,a.kt)("strong",{parentName:"p"},"exactly"),"*"," the way I was working now. But using Gulp instead of Web Optimization. I wanted to lose the BundleConfig above and remove Web Optimization from my application, secure in the knowledge that I had lost nothing. Could it be done? Read on!"),(0,a.kt)("h2",o({},{id:"installing-gulp-and-associates"}),"Installing Gulp (and Associates)"),(0,a.kt)("p",null,"I fired up Visual Studio and looked for an excuse to use the Task Runner Explorer. The first thing I needed was Gulp. My machine already had Node and NPM installed so I went to the command line to install Gulp globally:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),"npm install gulp -g\n")),(0,a.kt)("p",null,"Now to start to plug Gulp into my web project. It was time to make the introductions: Visual Studio meet NPM. At the root of the web project I created a ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," file by executing the following command and accepting all the defaults:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),"npm init\n")),(0,a.kt)("p",null,'I wanted to add Gulp as a development dependency of my project: ("Development" because I only need to run tasks at development time. My app has no dependency on Gulp at runtime - at that point it\'s just about serving up static files.)'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),"npm install gulp --save-dev\n")),(0,a.kt)("p",null,'This installs gulp local to the project as a development dependency. As a result we now have a "node_modules" folder sat in our root which contains our node packages. Currently, as our ',(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," reveals, this is only gulp:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"devDependencies": {\n    "gulp": "^3.8.8"\n  }\n')),(0,a.kt)("p",null,"It's time to go to town. Let's install all the packages we're going to need to bundle and minify JavaScript and CSS:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-sh"}),"npm install gulp-concat gulp-uglify gulp-rev del path gulp-ignore gulp-asset-manifest gulp-minify-css --save-dev\n")),(0,a.kt)("p",null,"This installs the packages as dev dependencies (as you've probably guessed) and leaves us with a list of dev dependencies like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"devDependencies": {\n    "del": "^0.1.3",\n    "gulp": "^3.8.8",\n    "gulp-asset-manifest": "0.0.5",\n    "gulp-concat": "^2.4.1",\n    "gulp-ignore": "^1.2.1",\n    "gulp-minify-css": "^0.3.10",\n    "gulp-rev": "^1.1.0",\n    "gulp-uglify": "^1.0.1",\n    "path": "^0.4.9"\n  }\n')),(0,a.kt)("h2",o({},{id:"making-gulpfilejs"}),"Making ",(0,a.kt)("inlineCode",{parentName:"h2"},"gulpfile.js")),(0,a.kt)("p",null,"So now I was ready. I had everything I needed to replace my ",(0,a.kt)("inlineCode",{parentName:"p"},"BundleConfig.cs"),". I created a new file called ",(0,a.kt)("inlineCode",{parentName:"p"},"gulpfile.js")," in the root of my web project that looked like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"/// <vs AfterBuild='default' />\nvar gulp = require('gulp');\n\n// Include Our Plugins\nvar concat = require('gulp-concat');\nvar ignore = require('gulp-ignore');\nvar manifest = require('gulp-asset-manifest');\nvar minifyCss = require('gulp-minify-css');\nvar uglify = require('gulp-uglify');\nvar rev = require('gulp-rev');\nvar del = require('del');\nvar path = require('path');\n\nvar tsjsmapjsSuffix = '.{ts,js.map,js}';\nvar excludetsjsmap = '**/*.{ts,js.map}';\n\nvar bundleNames = { scripts: 'scripts', styles: 'styles' };\n\nvar filesAndFolders = {\n  base: '.',\n  buildBaseFolder: './build/',\n  debug: 'debug',\n  release: 'release',\n  css: 'css',\n\n  // The fonts we want Gulp to process\n  fonts: ['./fonts/*.*'],\n\n  // The scripts we want Gulp to process - adapted from BundleConfig\n  scripts: [\n    // Vendor Scripts\n    './scripts/angular.js',\n    './scripts/angular-animate.js',\n    './scripts/angular-route.js',\n    './scripts/angular-sanitize.js',\n    './scripts/angular-ui/ui-bootstrap-tpls.js',\n\n    './scripts/toastr.js',\n    './scripts/moment.js',\n    './scripts/spin.js',\n    './scripts/underscore.js',\n\n    // Bootstrapping\n    './app/app' + tsjsmapjsSuffix,\n    './app/config.route' + tsjsmapjsSuffix,\n\n    // common Modules\n    './app/common/common' + tsjsmapjsSuffix,\n    './app/common/logger' + tsjsmapjsSuffix,\n    './app/common/spinner' + tsjsmapjsSuffix,\n\n    // common.bootstrap Modules\n    './app/common/bootstrap/bootstrap.dialog' + tsjsmapjsSuffix,\n\n    // directives\n    './app/directives/**/*' + tsjsmapjsSuffix,\n\n    // services\n    './app/services/**/*' + tsjsmapjsSuffix,\n\n    // controllers\n    './app/about/**/*' + tsjsmapjsSuffix,\n    './app/admin/**/*' + tsjsmapjsSuffix,\n    './app/dashboard/**/*' + tsjsmapjsSuffix,\n    './app/layout/**/*' + tsjsmapjsSuffix,\n    './app/sages/**/*' + tsjsmapjsSuffix,\n    './app/sayings/**/*' + tsjsmapjsSuffix,\n  ],\n\n  // The styles we want Gulp to process - adapted from BundleConfig\n  styles: [\n    './content/ie10mobile.css',\n    './content/bootstrap.css',\n    './content/font-awesome.css',\n    './content/toastr.css',\n    './content/styles.css',\n  ],\n};\n\nfilesAndFolders.debugFolder =\n  filesAndFolders.buildBaseFolder + '/' + filesAndFolders.debug + '/';\nfilesAndFolders.releaseFolder =\n  filesAndFolders.buildBaseFolder + '/' + filesAndFolders.release + '/';\n\n/**\n * Create a manifest depending upon the supplied arguments\n *\n * @param {string} manifestName\n * @param {string} bundleName\n * @param {boolean} includeRelativePath\n * @param {string} pathPrepend\n */\nfunction getManifest(\n  manifestName,\n  bundleName,\n  includeRelativePath,\n  pathPrepend\n) {\n  // Determine filename (\"./build/manifest-debug.json\" or \"./build/manifest-release.json\"\n  var manifestFile =\n    filesAndFolders.buildBaseFolder + 'manifest-' + manifestName + '.json';\n\n  return manifest({\n    bundleName: bundleName,\n    includeRelativePath: includeRelativePath,\n    manifestFile: manifestFile,\n    log: true,\n    pathPrepend: pathPrepend,\n    pathSeparator: '/',\n  });\n}\n\n// Delete the build folder\ngulp.task('clean', function (cb) {\n  del([filesAndFolders.buildBaseFolder], cb);\n});\n\n// Copy across all files in filesAndFolders.scripts to build/debug\ngulp.task('scripts-debug', ['clean'], function () {\n  return gulp\n    .src(filesAndFolders.scripts, { base: filesAndFolders.base })\n    .pipe(gulp.dest(filesAndFolders.debugFolder));\n});\n\n// Create a manifest.json for the debug build - this should have lots of script files in\ngulp.task('manifest-scripts-debug', ['scripts-debug'], function () {\n  return gulp\n    .src(filesAndFolders.scripts, { base: filesAndFolders.base })\n    .pipe(ignore.exclude('**/*.{ts,js.map}')) // Exclude ts and js.map files from the manifest (as they won't become script tags)\n    .pipe(getManifest(filesAndFolders.debug, bundleNames.scripts, true));\n});\n\n// Copy across all files in filesAndFolders.styles to build/debug\ngulp.task('styles-debug', ['clean'], function () {\n  return gulp\n    .src(filesAndFolders.styles, { base: filesAndFolders.base })\n    .pipe(gulp.dest(filesAndFolders.debugFolder));\n});\n\n// Create a manifest.json for the debug build - this should have lots of style files in\ngulp.task(\n  'manifest-styles-debug',\n  ['styles-debug', 'manifest-scripts-debug'],\n  function () {\n    return (\n      gulp\n        .src(filesAndFolders.styles, { base: filesAndFolders.base })\n        //.pipe(ignore.exclude(\"**/*.{ts,js.map}\")) // Exclude ts and js.map files from the manifest (as they won't become script tags)\n        .pipe(getManifest(filesAndFolders.debug, bundleNames.styles, true))\n    );\n  }\n);\n\n// Concatenate & Minify JS for release into a single file\ngulp.task('scripts-release', ['clean'], function () {\n  return (\n    gulp\n      .src(filesAndFolders.scripts)\n      .pipe(ignore.exclude('**/*.{ts,js.map}')) // Exclude ts and js.map files - not needed in release mode\n\n      .pipe(concat('app.js')) // Make a single file - if you want to see the contents then include the line below\n      //.pipe(gulp.dest(releaseFolder))\n\n      .pipe(uglify()) // Make the file titchy tiny small\n      .pipe(rev()) // Suffix a version number to it\n      .pipe(gulp.dest(filesAndFolders.releaseFolder))\n  ); // Write single versioned file to build/release folder\n});\n\n// Create a manifest.json for the release build - this should just have a single file for scripts\ngulp.task('manifest-scripts-release', ['scripts-release'], function () {\n  return gulp\n    .src(filesAndFolders.buildBaseFolder + filesAndFolders.release + '/*.js')\n    .pipe(getManifest(filesAndFolders.release, bundleNames.scripts, false));\n});\n\n// Copy across all files in filesAndFolders.styles to build/debug\ngulp.task('styles-release', ['clean'], function () {\n  return (\n    gulp\n      .src(filesAndFolders.styles)\n      .pipe(concat('app.css')) // Make a single file - if you want to see the contents then include the line below\n      //.pipe(gulp.dest(releaseFolder))\n\n      .pipe(minifyCss()) // Make the file titchy tiny small\n      .pipe(rev()) // Suffix a version number to it\n      .pipe(\n        gulp.dest(filesAndFolders.releaseFolder + '/' + filesAndFolders.css)\n      )\n  ); // Write single versioned file to build/release folder\n});\n\n// Create a manifest.json for the debug build - this should have a single style files in\ngulp.task(\n  'manifest-styles-release',\n  ['styles-release', 'manifest-scripts-release'],\n  function () {\n    return gulp\n      .src(filesAndFolders.releaseFolder + '**/*.css')\n      .pipe(\n        getManifest(\n          filesAndFolders.release,\n          bundleNames.styles,\n          false,\n          filesAndFolders.css + '/'\n        )\n      );\n  }\n);\n\n// Copy across all fonts in filesAndFolders.fonts to both release and debug locations\ngulp.task('fonts', ['clean'], function () {\n  return gulp\n    .src(filesAndFolders.fonts, { base: filesAndFolders.base })\n    .pipe(gulp.dest(filesAndFolders.debugFolder))\n    .pipe(gulp.dest(filesAndFolders.releaseFolder));\n});\n\n// Default Task\ngulp.task('default', [\n  'scripts-debug',\n  'manifest-scripts-debug',\n  'styles-debug',\n  'manifest-styles-debug',\n  'scripts-release',\n  'manifest-scripts-release',\n  'styles-release',\n  'manifest-styles-release',\n  'fonts',\n]);\n")),(0,a.kt)("h2",o({},{id:"what-gulpfilejs-does"}),"What ",(0,a.kt)("inlineCode",{parentName:"h2"},"gulpfile.js")," does"),(0,a.kt)("p",null,"This file does a number of things each time it is run. First of all it deletes any ",(0,a.kt)("inlineCode",{parentName:"p"},"build")," folder in the root of the web project so we're ready to build anew. Then it packages up files both for debug and for release mode. For debug it does the following:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"It copies the ",(0,a.kt)("inlineCode",{parentName:"li"},"ts"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"js.map")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"js")," files declared in ",(0,a.kt)("inlineCode",{parentName:"li"},"filesAndFolders.scripts")," to the ",(0,a.kt)("inlineCode",{parentName:"li"},"build/debug")," folder preserving their original folder structure. (So, for example, ",(0,a.kt)("inlineCode",{parentName:"li"},"app/app.ts"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"app/app.js.map")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"app/app.js")," will all end up at ",(0,a.kt)("inlineCode",{parentName:"li"},"build/debug/app/app.ts"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"build/debug/app/app.js.map")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"build/debug/app/app.js")," respectively.) This is done to allow the continued debugging of the original TypeScript files when running in debug mode."),(0,a.kt)("li",{parentName:"ol"},"It copies the ",(0,a.kt)("inlineCode",{parentName:"li"},"css")," files declared in ",(0,a.kt)("inlineCode",{parentName:"li"},"filesAndFolders.styles")," to the ",(0,a.kt)("inlineCode",{parentName:"li"},"build/debug")," folder preserving their original folder structure. (So ",(0,a.kt)("inlineCode",{parentName:"li"},"content/bootstrap.css")," will end up at ",(0,a.kt)("inlineCode",{parentName:"li"},"build/debug/content/bootstrap.css"),".)"),(0,a.kt)("li",{parentName:"ol"},"It creates a ",(0,a.kt)("inlineCode",{parentName:"li"},"build/manifest-debug.json")," file which contains details of all the script and style files that have been packaged up:")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "scripts": [\n    "scripts/angular.js",\n    "scripts/angular-animate.js",\n    "scripts/angular-route.js",\n    "scripts/angular-sanitize.js",\n    "scripts/angular-ui/ui-bootstrap-tpls.js",\n    "scripts/toastr.js",\n    "scripts/moment.js",\n    "scripts/spin.js",\n    "scripts/underscore.js",\n    "app/app.js",\n    "app/config.route.js",\n    "app/common/common.js",\n    "app/common/logger.js",\n    "app/common/spinner.js",\n    "app/common/bootstrap/bootstrap.dialog.js",\n    "app/directives/imgPerson.js",\n    "app/directives/serverError.js",\n    "app/directives/sidebar.js",\n    "app/directives/spinner.js",\n    "app/directives/waiter.js",\n    "app/directives/widgetClose.js",\n    "app/directives/widgetHeader.js",\n    "app/directives/widgetMinimize.js",\n    "app/services/datacontext.js",\n    "app/services/repositories.js",\n    "app/services/repository.sage.js",\n    "app/services/repository.saying.js",\n    "app/about/about.js",\n    "app/admin/admin.js",\n    "app/dashboard/dashboard.js",\n    "app/layout/shell.js",\n    "app/layout/sidebar.js",\n    "app/layout/topnav.js",\n    "app/sages/sageDetail.js",\n    "app/sages/sageEdit.js",\n    "app/sages/sages.js",\n    "app/sayings/sayingEdit.js",\n    "app/sayings/sayings.js"\n  ],\n  "styles": [\n    "content/ie10mobile.css",\n    "content/bootstrap.css",\n    "content/font-awesome.css",\n    "content/toastr.css",\n    "content/styles.css"\n  ]\n}\n')),(0,a.kt)("p",null,"For release our gulpfile works with the same resources but has a different aim. Namely to minimise the the number of HTTP requests, obfuscate the code and version the files produced to prevent caching issues. To achieve those lofty aims it does the following:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"It concatenates together all the ",(0,a.kt)("inlineCode",{parentName:"li"},"js")," files declared in ",(0,a.kt)("inlineCode",{parentName:"li"},"filesAndFolders.scripts"),", minifies them and writes them to a single ",(0,a.kt)("inlineCode",{parentName:"li"},"build/release/app-{xxxxx}.js")," file (where ",(0,a.kt)("inlineCode",{parentName:"li"},"-{xxxxx}")," represents a version created by gulp-rev)."),(0,a.kt)("li",{parentName:"ol"},"It concatenates together all the ",(0,a.kt)("inlineCode",{parentName:"li"},"css")," files declared in ",(0,a.kt)("inlineCode",{parentName:"li"},"filesAndFolders.styles"),", minifies them and writes them to a single ",(0,a.kt)("inlineCode",{parentName:"li"},"build/release/css/app-{xxxxx}.css")," file. The file is placed in a css subfolder because of relative paths specified in the CSS file."),(0,a.kt)("li",{parentName:"ol"},"It creates a ",(0,a.kt)("inlineCode",{parentName:"li"},"build/manifest-release.json")," file which contains details of all the script and style files that have been packaged up:")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "scripts": ["app-95d1e06d.js"],\n  "styles": ["css/app-1a6256ea.css"]\n}\n')),(0,a.kt)("p",null,"As you can see, the number of files included are reduced down to 2; 1 for JavaScript and 1 for CSS."),(0,a.kt)("p",null,"Finally, for both the debug and release packages the contents of the ",(0,a.kt)("inlineCode",{parentName:"p"},"fonts")," folder is copied across wholesale, preserving the original folder structure. This is because the CSS files contain relative references that point to the font files. If I had image files which were referenced by my CSS I'd similarly need to include these in the build process."),(0,a.kt)("h2",o({},{id:"task-runner-explorer-gets-in-on-the-action"}),"Task Runner Explorer gets in on the action"),(0,a.kt)("p",null,"The eagle eyed amongst you will also have noticed a peculiar first line to our ",(0,a.kt)("inlineCode",{parentName:"p"},"gulpfile.js"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"/// <vs AfterBuild='default' />\n")),(0,a.kt)("p",null,"This mysterious comment is actually how the Task Runner Explorer hooks our ",(0,a.kt)("inlineCode",{parentName:"p"},"gulpfile.js"),' into the Visual Studio build process. Our "magic comment" ensures that on the ',(0,a.kt)("inlineCode",{parentName:"p"},"AfterBuild")," event, Task Runner Explorer runs the ",(0,a.kt)("inlineCode",{parentName:"p"},"default")," task in our ",(0,a.kt)("inlineCode",{parentName:"p"},"gulpfile.js"),". The reason we're using the ",(0,a.kt)("inlineCode",{parentName:"p"},"AfterBuild")," event rather than the ",(0,a.kt)("inlineCode",{parentName:"p"},"BeforeBuild")," event is because our project contains TypeScript and we need the transpiled JavaScript to be created before we can usefully run our package tasks. If we were using JavaScript alone then that wouldn't be an issue and either build event would do."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(54758).Z,width:"640",height:"553"})),(0,a.kt)("h2",o({},{id:"how-do-i-use-this-in-my-html"}),"How do I use this in my HTML?"),(0,a.kt)("p",null,"Well this is magnificent - we have a gulpfile that builds our debug and release packages. The question now is, how do we use it?"),(0,a.kt)("p",null,"Web Optimization made our lives really easy. Up in my head I had a ",(0,a.kt)("inlineCode",{parentName:"p"},'@Styles.Render("~/Content/css")')," which pushed out my CSS and down at the foot of the body tag I had a ",(0,a.kt)("inlineCode",{parentName:"p"},'@Scripts.Render("~/angularApp")')," which pushed out my script tags. ",(0,a.kt)("inlineCode",{parentName:"p"},"Styles")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"Scripts")," are server-side utilities. It would be very easy to write equivalent utility classes that, depending on whether we were in debug or not, read the appropriate ",(0,a.kt)("inlineCode",{parentName:"p"},"build/manifest-xxxxxx.json")," file and served up either debug or release ",(0,a.kt)("inlineCode",{parentName:"p"},"style")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"script")," tags."),(0,a.kt)("p",null,"That would be pretty simple - and for what it's worth ","*","*","simple is ",(0,a.kt)("u",null,"good")),(0,a.kt)("p",null,"*","*",". But today I felt like a challenge. What say server side rendering had been outlawed? A draconian ruling had been passed and all you had to play with was HTML / JavaScript and a server API that served up JSON? What would you do then? (All fantasy I know... But go with me on this - it's a journey.) Or more sensibly, what if you just want to remove some of the work your app is doing server-side to bundle and minify. Just serve up static assets instead. Spend less money in Azure why not?"),(0,a.kt)("p",null,"Before I make all the changes let's review where we were. I had a single MVC view which, in terms of bundles, CSS and JavaScript pretty much looked like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<!DOCTYPE html>\n<html>\n  <head>\n    \x3c!-- ... --\x3e\n    @Styles.Render("~/Content/css")\n  </head>\n  <body>\n    \x3c!-- ... --\x3e\n\n    @Scripts.Render("~/angularApp")\n    <script>\n      (function () {\n        $.getJSON(\'@Url.Content("~/Home/StartApp")\').done(function (\n          startUpData\n        ) {\n          var appConfig = $.extend({}, startUpData, {\n            appRoot: \'@Url.Content("~/")\',\n            remoteServiceRoot: \'@Url.Content("~/api/")\',\n          });\n\n          angularApp.start({\n            thirdPartyLibs: {\n              moment: window.moment,\n              toastr: window.toastr,\n              underscore: window._,\n            },\n            appConfig: appConfig,\n          });\n        });\n      })();\n    <\/script>\n  </body>\n</html>\n')),(0,a.kt)("p",null,"This is already more a complicated example than most peoples use cases. Essentially what's happening here is both bundles are written out as part of the HTML and then, once the scripts have loaded the Angular app is bootstrapped with some configuration loaded from the server by a good old jQuery AJAX call."),(0,a.kt)("p",null,"After reading ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.html5rocks.com/en/tutorials/speed/script-loading/"}),"an article about script loading by the magnificently funny Jake Archibald")," I felt ready. I cast my MVC view to the four winds and created myself a straight HTML file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),"<!DOCTYPE html>\n<html>\n  <head>\n    \x3c!-- ... --\x3e\n  </head>\n  <body>\n    \x3c!-- ... --\x3e\n\n    <script src=\"Scripts/jquery-2.1.1.min.js\"><\/script>\n    <script>\n      (function () {\n        var appConfig = {};\n        var scriptsToLoad;\n\n        /**\n         * Handler which fires as each script loads\n         */\n        function onScriptLoad(event) {\n          scriptsToLoad -= 1;\n\n          // Now all the scripts are present start the app\n          if (scriptsToLoad === 0) {\n            angularApp.start({\n              thirdPartyLibs: {\n                moment: window.moment,\n                toastr: window.toastr,\n                underscore: window._,\n              },\n              appConfig: appConfig,\n            });\n          }\n        }\n\n        // Load startup data from the server\n        $.getJSON('api/Startup').done(function (startUpData) {\n          appConfig = startUpData;\n\n          // Determine the assets folder depending upon whether in debug mode or not\n          var buildFolder = appConfig.appRoot + 'build/';\n          var debugOrRelease = appConfig.inDebug ? 'debug' : 'release';\n          var manifestFile =\n            buildFolder + 'manifest-' + debugOrRelease + '.json';\n          var outputFolder = buildFolder + debugOrRelease + '/';\n\n          // Load JavaScript and CSS listed in manifest file\n          $.getJSON(manifestFile).done(function (manifest) {\n            manifest.styles.forEach(function (href) {\n              var link = document.createElement('link');\n\n              link.rel = 'stylesheet';\n              link.media = 'all';\n              link.href = outputFolder + href;\n\n              document.head.appendChild(link);\n            });\n\n            scriptsToLoad = manifest.scripts.length;\n            manifest.scripts.forEach(function (src) {\n              var script = document.createElement('script');\n\n              script.onload = onScriptLoad;\n              script.src = outputFolder + src;\n              script.async = false;\n\n              document.head.appendChild(script);\n            });\n          });\n        });\n      })();\n    <\/script>\n  </body>\n</html>\n")),(0,a.kt)("p",null,"If you very carefully compare the HTML above the MVC view that it replaces you can see the commonalities. They are doing pretty much the same thing - the only real difference is the bootstrapping API. Previously it was an MVC endpoint at ",(0,a.kt)("inlineCode",{parentName:"p"},"/Home/StartApp"),". Now it's a Web API endpoint at ",(0,a.kt)("inlineCode",{parentName:"p"},"api/Startup"),". Here's how it works:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"A jQuery AJAX call kicks off a call to load the bootstrapping / app config data. Importantly this data includes whether the app is running in debug or not."),(0,a.kt)("li",{parentName:"ol"},"Depending on the ",(0,a.kt)("inlineCode",{parentName:"li"},"isDebug")," flag the app either loads the ",(0,a.kt)("inlineCode",{parentName:"li"},"build/manifest-debug.json")," or ",(0,a.kt)("inlineCode",{parentName:"li"},"build/manifest-release.json")," manifest."),(0,a.kt)("li",{parentName:"ol"},"For each CSS file in the styles bundle a ",(0,a.kt)("inlineCode",{parentName:"li"},"link")," element is created and added to the page."),(0,a.kt)("li",{parentName:"ol"},"For each JavaScript file in the scripts bundle a ",(0,a.kt)("inlineCode",{parentName:"li"},"script")," element is created and added to the page.")),(0,a.kt)("p",null,"It's worth pointing out that this also has a performance edge over Web Optimization as the assets are loaded asynchronously! (Yes I know it says ",(0,a.kt)("inlineCode",{parentName:"p"},"script.async = false")," but that's not what you think it is... Go read Jake's article!)"),(0,a.kt)("p",null,"To finish off I had to make a few tweaks to my ",(0,a.kt)("inlineCode",{parentName:"p"},"web.config"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'\x3c!-- Allow ASP.Net to serve up JSON files --\x3e\n    <system.webServer>\n        <staticContent>\n            <mimeMap fileExtension=".json" mimeType="application/json"/>\n        </staticContent>\n    </system.webServer>\n\n    \x3c!-- The build folder (and it\'s child folder "debug") will not be cached.\n         When people are debugging they don\'t want to cache --\x3e\n    <location path="build">\n        <system.webServer>\n            <staticContent>\n                <clientCache cacheControlMode="DisableCache"/>\n            </staticContent>\n        </system.webServer>\n    </location>\n\n    \x3c!-- The release folder will be cached for a loooooong time\n         When you\'re in Production caching is your friend --\x3e\n    <location path="build/release">\n        <system.webServer>\n            <staticContent>\n                <clientCache cacheControlMode="UseMaxAge"/>\n            </staticContent>\n        </system.webServer>\n    </location>\n')),(0,a.kt)("h2",o({},{id:"i-want-to-publish-how-do-i-include-my-assets"}),"I want to publish, how do I include my assets?"),(0,a.kt)("p",null,"It's time for some ",(0,a.kt)("inlineCode",{parentName:"p"},"csproj")," trickery. I must say I think I'll be glad to see the back of project files when ASP.Net vNext ships. This is what you need:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<Target Name="AfterBuild">\n    <ItemGroup>\n      \x3c!-- what ever is in the build folder should be included in the project --\x3e\n      <Content Include="build\\**\\*.*" />\n    </ItemGroup>\n  </Target>\n')),(0,a.kt)("p",null,"What's happening here is that ","*",(0,a.kt)("em",{parentName:"p"},"after"),"*"," a build Visual Studio considers the complete contents of the build folder to part of the project. It's after the build because the folder will be deleted and reconstructed as part of the build."))}d.isMDXComponent=!0},58276:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"Coded-UI-IE-11-and-the-runas-problem",title:"Pretending to be someone you're not and the dark pit of despair",authors:"johnnyreilly",tags:["Coded UI","internet explorer"],hide_table_of_contents:!1},s=void 0,l={permalink:"/Coded-UI-IE-11-and-the-runas-problem",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-11-26-Coded-UI-IE-11-and-the-runas-problem/index.md",source:"@site/blog/2014-11-26-Coded-UI-IE-11-and-the-runas-problem/index.md",title:"Pretending to be someone you're not and the dark pit of despair",description:'Coded UI, IE 11 and the "runas" problem',date:"2014-11-26T00:00:00.000Z",formattedDate:"November 26, 2014",tags:[{label:"Coded UI",permalink:"/tags/coded-ui"},{label:"internet explorer",permalink:"/tags/internet-explorer"}],readingTime:10.43,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"Coded-UI-IE-11-and-the-runas-problem",title:"Pretending to be someone you're not and the dark pit of despair",authors:"johnnyreilly",tags:["Coded UI","internet explorer"],hide_table_of_contents:!1},prevItem:{title:"What's in a (Domain) Name?",permalink:"/whats-in-a-name"},nextItem:{title:"Using Gulp in Visual Studio instead of Web Optimization",permalink:"/using-gulp-in-visual-studio-instead-of-web-optimization"}},p={authorsImageUrls:[void 0]},u=[{value:"Coded UI, IE 11 and the &quot;runas&quot; problem",id:"coded-ui-ie-11-and-the-runas-problem",level:2},{value:"Sounds brilliant right? How could someone not love this?",id:"sounds-brilliant-right-how-could-someone-not-love-this",level:2},{value:"And yet, and yet...",id:"and-yet-and-yet",level:2},{value:"The &quot;runas&quot; Problem",id:"the-runas-problem",level:2},{value:"The <strike>hack</strike>",id:"the-hack",level:2},{value:"What do I think of the workaround?",id:"what-do-i-think-of-the-workaround",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"coded-ui-ie-11-and-the-runas-problem"}),'Coded UI, IE 11 and the "runas" problem'),(0,a.kt)("p",null,"\"I'm not angry, I'm just disappointed.\""),(0,a.kt)("p",null,"That's kind of how I feel about Coded UI tests. It may well be that you've never heard of them - in my experience very few people seem to be aware of them. What are they? Well, I've never used ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.seleniumhq.org/"}),"Selenium")," but as best I understand Coded UI is Microsoft's own version of that. Namely it's a way to automate testing, in my case browser-based testing. You can write a suite of tests that will spin up your application and test it out, going from screen to screen, URL to URL and asserting all is as you would expect."),(0,a.kt)("p",null,"The project that I'm currently working on has a pretty comprehensive set of tests covering the use of the application. Each night as the clock strikes midnight a lonely computer in the West End of London whirrs into life and runs the full suite. It takes about 8 hours and at the end a report slips into your inbox letting you know of any failures."),(0,a.kt)("h2",o({},{id:"sounds-brilliant-right-how-could-someone-not-love-this"}),"Sounds brilliant right? How could someone not love this?"),(0,a.kt)("p",null,"Well a number of reasons. First of all, ",(0,a.kt)("em",{parentName:"p"},"it takes 8 hours"),"!!!! That's a long time; I'd rather learn what I broke today rather than tomorrow."),(0,a.kt)("p",null,"Also, and this is probably more significant, Coded UI tests are pretty flaky. Let me qualify that. For a test to be particularly useful it has to be quick, repeatable and reliable. As I've said, Coded UI tests are not quick."),(0,a.kt)("p",null,"By their very nature integration tests (of which Coded UI tests are a type) can never be entirely reliably repeatable. They test your app in it's entirety. So, for example, if a 3rd party service goes down for 5 minutes then you will get failed tests. You'll burn time investigating these false positives."),(0,a.kt)("p",null,"Further to that, Coded UI tests are repeatable, except when they're not. I've seen colleagues reduced to near tears by incredible sensitivity of Coded UI tests. Out of the box Coded UI tests appear to ship with the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://blog.codinghorror.com/the-works-on-my-machine-certification-program/"}),'"Works on my machine"')," guarantee. It requires far more effort that you'd expect to come up with tests that can be reliably expected to pass. They will fail for surprising reasons. For instance, did you know that using the 2.x branch of jQuery won't work with Coded UI? ",(0,a.kt)("a",o({parentName:"p"},{href:"https://connect.microsoft.com/VisualStudio/Feedback/Details/794841"}),"Neither did I.")," I've lost track of the time that has been wasted running the same test in multiple different environments trying to identify what exactly is upsetting Coded UI about the environment this time."),(0,a.kt)("p",null,"It is sad but true that with Coded UI tests you can spend an ",(0,a.kt)("em",{parentName:"p"},"enormous")," amount of time maintaining the test pack on a day to day basis. As infrastructure and project dependencies are upgraded you will sadly discover Coded UI has once again gone into the foetal position and has to tempted back to normal functioning by whispering sweet nothings in it's ear. (",(0,a.kt)("em",{parentName:"p"},'"It\'s not true that they\'ve ended support for Windows XP" / "IE 6 will live forever"')," and so on)"),(0,a.kt)("p",null,"Coded UI also appears to be badly supported by Microsoft. Documentation is pretty sparse and, as we'll come back to in a minute, Coded UI is sometimes broken or damaged by other products shipped by Microsoft. This makes it hard to have faith in Coded UI. Indeed, if you're thinking of automating your QA testing my advice would be \"look into Selenium\". Not because I've used it (I haven't) but those I've met who have used Selenium and Coded UI say Selenium wins hands down."),(0,a.kt)("h2",o({},{id:"and-yet-and-yet"}),"And yet, and yet..."),(0,a.kt)("p",null,"All of the above said, if you have a Coded UI test suite it can still pay dividends. Significant dividends. As I mentioned, my current project has a significant coverage of Coded UI tests. We've crawled over a lot of broken glass to put these together. But now they're there it is undeniably useful."),(0,a.kt)("p",null,"Every now and then we'll do a significant refactor of part of the application. For instance, we've entirely changed our persistence strategy in the app but been able to check the code in with a high degree of confidence gleaned from running our test suite using the refactored codebase."),(0,a.kt)("p",null,"Let me be clear: Coded UI tests can be useful."),(0,a.kt)("h2",o({},{id:"the-runas-problem"}),'The "runas" Problem'),(0,a.kt)("p",null,'Long preamble over, this post is about how to work around the latest issue Coded UI has thrown in our direction. I call it the "runas" problem. Our application is a Knockout / ASP.Net MVC web app built to be used in an intranet environment. By that I mean that identity is handled by Active Directory / ',(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Integrated_Windows_Authentication"}),"Windows Authentication"),". When someone logs into our app we know who they are without them having to directly supply us with a username and password. No, by logging into their computer they have announced just who they are and Internet Explorer (for it is he) will pass along the credentials. (The app can be used with pretty much any browser but we're only mandated to support IE 9+.)"),(0,a.kt)("p",null,"In order that we can test the app we have a number of test accounts set up in Active Directory. These test accounts have been assigned various roles (viewer / editor / administrator etc). Our tests are designed to run using these accounts in order that all scenarios can be adequately tested."),(0,a.kt)("p",null,"To achieve this lofty goal the following code (or something very like it) is executed as the first step in any Coded UI test:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'string browserLocation = "C:\\\\Program Files\\\\Internet Explorer\\\\iexplore.exe";\nstring url = "http://localhost:12345/";\nstring username = "test.editor";\nstring domain = "theDomain";\nvar password = new SecureString();\nforeach (char c in "test.editor.password")\n{\n    password.AppendChar(c);\n}\n\nApplicationUnderTest.Launch(browserLocation, null, url, username, password, domain);\n')),(0,a.kt)("p",null,'What this does is fire up Internet Explorer as the supplied user of theDomain\\test.editor, and navigate to the home page. With that as our starting place we could dependably then run a test as this test user. This was a solution not without quirks (on occasion Coded UI tests would "stutter" - repeating each keypress 3 times with calamitous effects). But generally, this worked.'),(0,a.kt)("p",null,"Until that is either Visual Studio 2013 Update 3 or Internet Explorer 11 was installed. One of these (and it appears to be hotly contested) broke the ability to run the above code successfully. After these were installed running the above code resulted in the following error message:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},'"The application cannot be started. This could be due to one of the following reasons:'),(0,a.kt)("ol",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ol"},"Another instance of the application is already running and only one instance can be running at a time."),(0,a.kt)("li",{parentName:"ol"},"The application started another process and has now stopped. You may need to launch the process directly."),(0,a.kt)("li",{parentName:"ol"},'You do not have sufficient privileges for this application." File: C:\\Program Files\\Internet Explorer\\iexplore.exe."'))),(0,a.kt)("p",null,"Lamentably, this was pretty much unresolvable and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://connect.microsoft.com/VisualStudio/feedbackdetail/view/949049/coded-ui-cannot-run-as-a-different-user-with-visual-studio-2013-update-3"}),"logging it with Microsoft yielded nothing helpful"),". This is what I mean about Coded UI being badly supported by Microsoft. Despite my best efforts to report this issue both to Connect and ",(0,a.kt)("a",o({parentName:"p"},{href:"http://social.msdn.microsoft.com/Forums/vstudio/en-US/f48665e4-569a-4b67-9bdb-5522b2adffb2/cannot-run-coded-ui-tests-as-different-user-on-windows-81?forum=vsmantest#28c9decb-b579-4848-a7a9-f41c57584d59"}),"elsewhere")," and in the end nothing useful happened."),(0,a.kt)("p",null,"So what to do? I still have Coded UI tests, I still need to be able to run them. And crucially I need to be able to run them impersonating a different user. What to do indeed...."),(0,a.kt)("h2",o({},{id:"the-hack"}),"The ",(0,a.kt)("strike",null,"hack")),(0,a.kt)("p",null,"workaround"),(0,a.kt)("p",null,"After IE 11 / Visual Studio Update 3 / whatev's was installed I was left with a setup that allowed me to run Coded UI tests, ",(0,a.kt)("u",null,"but only")),(0,a.kt)("p",null,"as the current user. On that basis I started looking into a little MVC jiggery pokery. All my controllers inherit from a single base controller. Inside there I placed the following extra override:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public abstract class BaseController : System.Web.Mvc.Controller\n{\n  //...\n\n  protected override void OnAuthorization(AuthorizationContext filterContext)\n  {\n#if DEBUG\n    if (filterContext.HttpContext.IsDebuggingEnabled)// Is compilation debug="true" set in the web.config?\n    {\n      var userToImpersonate = Session["UserToImpersonate"] as string;\n      if (!string.IsNullOrEmpty(userToImpersonate))\n      {\n        // userToImpersonate example: "test.editor@theDomain.com"\n        filterContext.HttpContext.User = new RolePrincipal(new WindowsIdentity(userToImpersonate));\n      }\n    }\n#endif\n      base.OnAuthorization(filterContext);\n  }\n\n  //...\n}\n')),(0,a.kt)("p",null,"Each request will trigger this method as one of the first steps in the MVC pipeline. What it does is checks the ",(0,a.kt)("inlineCode",{parentName:"p"},"Session")," for a user to impersonate. (Yes I'm as wary of Session as the next chap - but in this case it's the right tool for the job.) If a user has been specified then it replaces the current user with the ",(0,a.kt)("inlineCode",{parentName:"p"},"Session")," user. From this point forwards the app is effectively running as that user. That's great!"),(0,a.kt)("p",null,'In order that Coded UI can make use of this mechanism we need to introduce a "hook". This is going to look a bit hacky - bear with me. Inside ',(0,a.kt)("inlineCode",{parentName:"p"},"Global.asax.cs")," we're going to add a ",(0,a.kt)("inlineCode",{parentName:"p"},"Session_Start")," method:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'protected void Session_Start(object sender, EventArgs eventArgs)\n{\n#if DEBUG\n    // If a user to impersonate has been supplied then add this user to the session\n    // Impersonation will happen in the OnAuthorization method of our base MVC controller\n    // Note, this is only allowed in debug mode - not in release mode\n    // This exists purely to support coded ui tests\n    if (Context.IsDebuggingEnabled)  // Is compilation debug="true" set in the web.config?\n    {\n        var userToImpersonate = Request.QueryString["UserToImpersonate"] as string;\n        if (!string.IsNullOrEmpty(userToImpersonate))\n        {\n            Session.Add("UserToImpersonate", userToImpersonate);\n        }\n    }\n#endif\n}\n')),(0,a.kt)("p",null,"For the first Request in a Session this checks the ",(0,a.kt)("inlineCode",{parentName:"p"},"QueryString")," for a parameter called ",(0,a.kt)("inlineCode",{parentName:"p"},"UserToImpersonate"),". If it's found then it's placed into ",(0,a.kt)("inlineCode",{parentName:"p"},"Session"),". With this hook exposed we can now amend the first step that all our Coded UI tests follow:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'// Various lines commented out as doesn\'t work with IE 11 - left as an example of how it could be done in the past\n//string browserLocation = "C:\\\\Program Files\\\\Internet Explorer\\\\iexplore.exe";\nstring url = "http://localhost:12345/";\nstring username = "test.editor";\nstring domain = "theDomain.com";\n//var password = new SecureString();\n//foreach (char c in "test.editor.password")\n//{\n//    password.AppendChar(c);\n//}\n\n//ApplicationUnderTest.Launch(browserLocation, null, url, username, password, domain);\n\n// Suffixing url with UrlToImpersonate which will be picked up in Session_Start and used to impersonate\n// in OnAuthorization in BaseController.  Also no longer using ApplicationUnderTest.Launch; switched to\n// BrowserWindow.Launch\n// No longer used parameters: browserLocation, password\nvar userToImpersonate = username + "@" + domain; // eg "test.editor@theDomain.com"\nvar urlWithUser = url + "?UserToImpersonate=" + HttpUtility.UrlEncode(userToImpersonate);\nvar browser = BrowserWindow.Launch(urlWithUser, "-nomerge"); // "-nomerge" flag forces a new session\n')),(0,a.kt)("p",null,"As you can see we actually need less when we're using this approach. We no longer need to directly specify the password or the browser location. And the user to impersonate is now passed in as the part of the initial URL used to launch the test."),(0,a.kt)("p",null,'Pay careful attention to the "-nomerge" flag that is passed in. This ensures that when another browser instance is opened a new session will be started. This is essential for "multi-user" tests that run tests for ',(0,a.kt)("em",{parentName:"p"},"different"),' users as part of the same test. It ensures that "test.editor" and "test.different.editor" can co-exist happily.'),(0,a.kt)("h2",o({},{id:"what-do-i-think-of-the-workaround"}),"What do I think of the workaround?"),(0,a.kt)("p",null,"This approach works reliably and dependably. More so than the original approach which on occasion wouldn't work or would \"stutter\" keypresses. That's the good news."),(0,a.kt)("p",null,"The not so good news is that this approach is, in my view, a bit of hack. I want you to know that this isn't my ideal."),(0,a.kt)("p",null,"I ",(0,a.kt)("em",{parentName:"p"},"really"),' don\'t like having to change the actual system code to facilitate the impersonation requirement. Naturally we only ship the release and not the debug builds to Production so the "back door" that this approach provides will not exist in our Production builds. It will only be accessible in our development environments and on our Coded UI test server. But it feels oh so wrong that there is an effective potential back door in the system now. Well, only if the stars were to align in a really terrible (and admittedly rather unlikely) way. But still, you take my point. Caveat emptor and all that. This is something of a cutdown example to illustrate the point. If anyone else intends to use this then I\'d suggest doing more to safeguard your approach. Implementing impersonation allowlists so "any" user cannot be impersonated would be a sensible precaution to start with.'),(0,a.kt)("p",null,"Perhaps this is just one more reason that I'm not that enamoured of Coded UI. Once again it is useful but I've had to compromise more than I'd like to keep it's use. If anyone out there has a better solution I would ",(0,a.kt)("em",{parentName:"p"},"love")," to hear from you."))}d.isMDXComponent=!0},73536:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"whats-in-a-name",title:"What's in a (Domain) Name?",authors:"johnnyreilly",hide_table_of_contents:!1},s=void 0,l={permalink:"/whats-in-a-name",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-12-05-whats-in-a-name/index.md",source:"@site/blog/2014-12-05-whats-in-a-name/index.md",title:"What's in a (Domain) Name?",description:'The observant amongst you may have noticed that this blog has a brand new and shiny domain name! That\'s right, after happily trading under "icanmakethiswork.blogspot.com" for the longest time it\'s now "blog.icanmakethiswork.io". Trumpets and fanfare!',date:"2014-12-05T00:00:00.000Z",formattedDate:"December 5, 2014",tags:[],readingTime:2.61,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"whats-in-a-name",title:"What's in a (Domain) Name?",authors:"johnnyreilly",hide_table_of_contents:!1},prevItem:{title:"Gulp, npm, long paths and Visual Studio.... Fight!",permalink:"/gulp-npm-long-paths-and-visual-studio-fight"},nextItem:{title:"Pretending to be someone you're not and the dark pit of despair",permalink:"/Coded-UI-IE-11-and-the-runas-problem"}},p={authorsImageUrls:[void 0]},u=[{value:"Why do things have to change at all?",id:"why-do-things-have-to-change-at-all",level:2},{value:"Why blog.icanmakethiswork.io?",id:"why-blogicanmakethisworkio",level:2},{value:"Is anything else going to change?",id:"is-anything-else-going-to-change",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'The observant amongst you may have noticed that this blog has a brand new and shiny domain name! That\'s right, after happily trading under "icanmakethiswork.blogspot.com" for the longest time it\'s now "blog.icanmakethiswork.io". Trumpets and fanfare!'),(0,a.kt)("p",null,"Why the change? Well let's break that question down a little. First of all, why change at all? Secondly, why change to blog.icanmakethiswork.io?"),(0,a.kt)("h2",o({},{id:"why-do-things-have-to-change-at-all"}),"Why do things have to change at all?"),(0,a.kt)("p",null,"I mean, weren't we happy? Wasn't it all good? Well quite. For the record, I have no complaints of Blogger who have hosted my blog since it began. They've provided good tools and a good service and I'm happy with them."),(0,a.kt)("p",null,"That said, I've been toying with the idea for a while now of trying out a few other blogging solutions - possibly even hosting it myself. Whilst my plans are far from definite at the moment I'm aware that I don't own icanmakethiswork.blogspot.com - I can't take it with me. So if I want to make a move to change my blogging solution a first step is establishing my own domain name for my blog. I've done that now. If and when I up sticks, people will hopefully come with me as the URL for my blog should not change."),(0,a.kt)("p",null,"Also, in the back of my mind I'm aware that Google owns Blogger. Given their recent spate of closing services it's certainly possible that the Google reaper could one day call for Blogger. So it makes sense to be ready to move my blog elsewhere should that day come."),(0,a.kt)("h2",o({},{id:"why-blogicanmakethisworkio"}),"Why blog.icanmakethiswork.io?"),(0,a.kt)("p",null,'Why indeed? And why the ".io" suffix? Doesn\'t that just make you a desperate follower of fashion?'),(0,a.kt)("p",null,'Good questions all, and "no, I hope not". My original plans were to use the domain name "icanmakethiswork.com". icanmakethiswork was the name of the blog and it made sense to keep it in the URL. So off I went to register the domain name when to my surprise I discovered this:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(35455).Z,width:"640",height:"623"})),(0,a.kt)("p",null,"My domain is being ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Cybersquatting"}),"cybersquatted"),"! I mean.... What??!!!!"),(0,a.kt)("p",null,'I started to wonder "is there another icanmakethiswork out there"? Am I not the ',(0,a.kt)("a",o({parentName:"p"},{href:"http://youtu.be/z8f2mW1GFSI"}),"one and only"),'? So I checked with DuckDuckGo ("The search engine that doesn\'t track you.") and look what I found:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(30064).Z,width:"624",height:"640"})),(0,a.kt)("p",null,"A whole screen of me. Just me."),(0,a.kt)("p",null,"As of June 3rd 2014 someone has been sitting on my blog name. I was actually rather outraged by this. I became even more so as I discovered that there was a mechanism (not free) by which I could try and buy it off the squatter. I could instead be like my life idol Madonna and go to court to get it back. But frankly in this sense I'm more like Rachel Green in Friends; not litigous."),(0,a.kt)("p",null,"So that's why I went for icanmakethiswork.io instead. Path of least resistance and all that. I'd still like icanmakethiswork.com to be mine but I'm not going to court and I'm not paying the squatter. Maybe one day I'll get it. Who knows?"),(0,a.kt)("p",null,"Either way, from now on this is blog.icanmakethiswork.io - please stick around!"),(0,a.kt)("h2",o({},{id:"is-anything-else-going-to-change"}),"Is anything else going to change?"),(0,a.kt)("p",null,"Not for now, no."))}d.isMDXComponent=!0},46648:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"gulp-npm-long-paths-and-visual-studio-fight",title:"Gulp, npm, long paths and Visual Studio.... Fight!",authors:"johnnyreilly",tags:["npm","Visual Studio"],hide_table_of_contents:!1},s=void 0,l={permalink:"/gulp-npm-long-paths-and-visual-studio-fight",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-12-12-gulp-npm-long-paths-and-visual-studio-fight/index.md",source:"@site/blog/2014-12-12-gulp-npm-long-paths-and-visual-studio-fight/index.md",title:"Gulp, npm, long paths and Visual Studio.... Fight!",description:"How I managed to gulp-angular-templatecache working inside Visual Studio",date:"2014-12-12T00:00:00.000Z",formattedDate:"December 12, 2014",tags:[{label:"npm",permalink:"/tags/npm"},{label:"Visual Studio",permalink:"/tags/visual-studio"}],readingTime:2.715,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"gulp-npm-long-paths-and-visual-studio-fight",title:"Gulp, npm, long paths and Visual Studio.... Fight!",authors:"johnnyreilly",tags:["npm","Visual Studio"],hide_table_of_contents:!1},prevItem:{title:"Deploying from ASP.Net MVC to GitHub Pages using AppVeyor part 1",permalink:"/deploying-aspnet-mvc-to-github-pages-with-appveyor-part-1"},nextItem:{title:"What's in a (Domain) Name?",permalink:"/whats-in-a-name"}},p={authorsImageUrls:[void 0]},u=[{value:"<sub>How I managed to gulp-angular-templatecache working inside Visual Studio</sub>",id:"how-i-managed-to-gulp-angular-templatecache-working-inside-visual-studio",level:2},{value:"It&#39;s Workaround Time!",id:"its-workaround-time",level:2},{value:"The Future",id:"the-future",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"how-i-managed-to-gulp-angular-templatecache-working-inside-visual-studio"}),(0,a.kt)("sub",null,"How I managed to gulp-angular-templatecache working inside Visual Studio")),(0,a.kt)("p",null,"Every now and then something bites you unexpectedly. After a certain amount of pain, the answer comes to you and you know you want to save others from falling into the same deathtrap."),(0,a.kt)("p",null,"There I was minding my own business and having a play with a Gulp plugin called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/gulp-angular-templatecache"}),"gulp-angular-templatecache"),'. If you\'re not aware of it, it "Concatenates and registers AngularJS templates in the $templateCache". I was planning to use it so that all the views in an ',(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/proverb-offline"}),"Angular app of mine"),' were loaded up-front rather than on demand. (It\'s a first step in making an "offline-first" version of that particular app.)'),(0,a.kt)("p",null,"I digress already. No sooner had I tapped in:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),"npm install gulp-angular-templatecache --saveDev\n")),(0,a.kt)("p",null,"Then I noticed my Visual Studio project was no longer compiling. It was dying a death on build with this error:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),"ASPNETCOMPILER : error ASPRUNTIME: The specified path, file name, or both are too long. The fully qualified file name must be less than 260 characters, and the directory name must be less than 248 characters.\n")),(0,a.kt)("p",null,"I was dimly aware that there were issues with the nested ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/joyent/node/issues/6960"}),"node_modules")," leading to Windows-killing paths. This sounded just like that.... And it was! ",(0,a.kt)("inlineCode",{parentName:"p"},"gulp-angular-templatecache")," had a dependency on ",(0,a.kt)("inlineCode",{parentName:"p"},"gulp-footer")," which had a dependency on ",(0,a.kt)("inlineCode",{parentName:"p"},"lodash.assign")," which had a dependency on ",(0,a.kt)("inlineCode",{parentName:"p"},"lodash._basecreatecallback")," which had.... You see where I'm going? It seems that the lovely lodash has created the path from hell."),(0,a.kt)("p",null,"For reasons that aren't particularly clear this kills Visual Studio's build process. This is slightly surprising given that our rogue path is sat in the ",(0,a.kt)("inlineCode",{parentName:"p"},"node_modules")," directory which isn't part of the project in Visual Studio. That being the case you'd imagine that you could do what you liked there. But no, it seems VS is a delicate flower and we must be careful not to offend. Strange."),(0,a.kt)("h2",o({},{id:"its-workaround-time"}),"It's Workaround Time!"),(0,a.kt)("p",null,"After a ",(0,a.kt)("em",{parentName:"p"},"great deal")," of digging I found the answer nestled in the middle of an ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/24144479/761388"}),"answer on Stack Overflow"),". To quote:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"If you will add \"lodash.bind\" module to your project's package.json as dependency it will be installed in one level with gulp and not as gulp's dependency")),(0,a.kt)("p",null,"That's right, I just needed to tap enter this at the root of my project:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),"npm install lodash.bind --saveDev\n")),(0,a.kt)("p",null,"And all was sweetness and light once more - no more complaints from VS."),(0,a.kt)("h2",o({},{id:"the-future"}),"The Future"),(0,a.kt)("p",null,"It looks like lodash are ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/lodash/lodash-cli/issues/23"}),"on course to address this issue"),". So one day this this workaround won't be necessary anymore which is good."),(0,a.kt)("p",null,"However, the general long path issue concerning node / npm hasn't vanished for Windows users. Given VS 2015 is planning to make Gulp and Grunt 1st class citizens of Visual Studio I'm going to guess that sort of issue is likely to arise again and again for other packages. I'm hoping that means that someone will actually fix the underlying path issues that upset Windows with npm."),(0,a.kt)("p",null,"It sounds like npm are planning to take ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/joyent/node/issues/6960#issuecomment-46704998"}),"some steps")," which is great. But I can't be alone in having a slightly nagging feeling that Windows isn't quite a first class citizen for node / io / npm yet. I really hope it will become one."))}d.isMDXComponent=!0},23085:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"deploying-aspnet-mvc-to-github-pages-with-appveyor-part-1",title:"Deploying from ASP.Net MVC to GitHub Pages using AppVeyor part 1",authors:"johnnyreilly",tags:["powershell","github pages","AppVeyor"],hide_table_of_contents:!1},s=void 0,l={permalink:"/deploying-aspnet-mvc-to-github-pages-with-appveyor-part-1",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2014-12-29-deploying-aspnet-mvc-to-github-pages-with-appveyor-part-1/index.md",source:"@site/blog/2014-12-29-deploying-aspnet-mvc-to-github-pages-with-appveyor-part-1/index.md",title:"Deploying from ASP.Net MVC to GitHub Pages using AppVeyor part 1",description:"There's a small open source project I'm responsible for called jQuery Validation Unobtrusive Native. (A catchy name is a must for any good open source project. Alas I'm not quite meeting my own exacting standards on this particular point... I should have gone with my gut and called it \"Livingstone\" instead. Too late now...)",date:"2014-12-29T00:00:00.000Z",formattedDate:"December 29, 2014",tags:[{label:"powershell",permalink:"/tags/powershell"},{label:"github pages",permalink:"/tags/github-pages"},{label:"AppVeyor",permalink:"/tags/app-veyor"}],readingTime:5.805,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"deploying-aspnet-mvc-to-github-pages-with-appveyor-part-1",title:"Deploying from ASP.Net MVC to GitHub Pages using AppVeyor part 1",authors:"johnnyreilly",tags:["powershell","github pages","AppVeyor"],hide_table_of_contents:!1},prevItem:{title:"Deploying from ASP.Net MVC to GitHub Pages using AppVeyor part 2",permalink:"/deploying-aspnet-mvc-to-github-pages-with-appveyor-part-2"},nextItem:{title:"Gulp, npm, long paths and Visual Studio.... Fight!",permalink:"/gulp-npm-long-paths-and-visual-studio-fight"}},p={authorsImageUrls:[void 0]},u=[{value:"I&#39;m quite cheap",id:"im-quite-cheap",level:2},{value:"You Wget me?",id:"you-wget-me",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"There's a small open source project I'm responsible for called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/jQuery.Validation.Unobtrusive.Native"}),"jQuery Validation Unobtrusive Native"),'. (A catchy name is a must for any good open source project. Alas I\'m not quite meeting my own exacting standards on this particular point... I should have gone with my gut and called it "Livingstone" instead. Too late now...)'),(0,a.kt)("p",null,"The project itself is fairly simple in purpose. It's essentially a bridge between ASP.Net MVC's inbuilt support for driving validation from data attributes and jQuery Validation's native support for the same. It is, in the end, a collection of ASP.Net MVC HTML helper extensions. It is not massively complicated."),(0,a.kt)("p",null,'I believe it was Tony Blair that said "documentation, documentation, documentation" were his priorities for open source projects. Or maybe it was someone else... Anyway, the point stands. Documentation is supremely important if you want your project to be in any way useful to anyone other than yourself. A project, no matter how fantastic, which lacks decent documentation is a missed opportunity.'),(0,a.kt)("p",null,"Anyway I'm happy to say that jQuery Validation Unobtrusive Native ",(0,a.kt)("em",{parentName:"p"},"has")," documentation! And pretty good documentation at that. The documentation takes the form of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/jQuery.Validation.Unobtrusive.Native/tree/master/jVUNDemo"}),"jVUNDemo")," project which is part of the jQuery Validation Unobtrusive Native repo. jVUNDemo is an ASP.Net MVC web application which is built on top of the jQuery Validation Unobtrusive Native helpers. It demonstrates the helpers in action and documents how you might go about using them. It looks a bit like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(30014).Z,width:"640",height:"525"})),(0,a.kt)("p",null,"When I first put jVUNDemo together I hosted it on Azure so the world could see it in all it's finery. And that worked just fine. However, there's something you ought to know about me:"),(0,a.kt)("h2",o({},{id:"im-quite-cheap"}),"I'm quite cheap"),(0,a.kt)("p",null,'No really, I am. My attention was grabbed by the essentially "free" nature of ',(0,a.kt)("a",o({parentName:"p"},{href:"https://pages.github.com/"}),"GitHub Pages"),". I was immediately seized by the desire to somehow deploy jVUNDemo to GitHub Pages and roll around joyfully in all that lovely free hosting."),(0,a.kt)("p",null,'"But", I hear you cry, "you can\'t deploy an ASP.Net MVC application to Git Hub Pages... It only hosts static sites!" Quite right. Sort of. This is where I get to pull my ace of spades: jVUNDemo is not really an "app" so much as a static site. Yup, once the HTML that makes up each page is generated there isn\'t any app like business to do. It\'s just a collection of text and 1 screen demo\'s really.'),(0,a.kt)("p",null,"That being the case, there's no reason why I shouldn't be able to make use of GitHub Pages. So that's what I decided to do. Whilst I was at it I also wanted to automate the deployment process. When I tweak jVUNDemo I don't want to have to manually push out a new version of jVUNDemo to wherever it's being hosted. No, I'm a developer so I'll automate it."),(0,a.kt)("p",null,"I've broken this up into 2 posts. This first one will cover how you generate a static site from an ASP.Net MVC site. The second will be about how to use ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.appveyor.com/"}),"AppVeyor")," to ensure that on each build your documentation is getting republished."),(0,a.kt)("h2",o({},{id:"you-wget-me"}),"You Wget me?"),(0,a.kt)("p",null,"So, static site generation. There's a well known Unix utility called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Wget"}),"Wget"),' which covers exactly that ground and so we\'re going to use it. It downloads and saves HTML, it recursively walks the links inside the site and grabs those pages too and it converts our routes so they are locally browsable ("Demo/Required" becomes "Demo/Required.html").'),(0,a.kt)("p",null,"You can use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://chocolatey.org/packages/Wget"}),"Chocolatey")," to get a copy of Wget. We're also going to need IIS Express to host jVUNDemo whilst Wget converts it. Once jVUNDemo has been built successfully you should be be able to kick off the process like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),"cd C:\\projects\\jquery-validation-unobtrusive-native\n.\\makeStatic.ps1 $pwd.path\n")),(0,a.kt)("p",null,"This invokes the ",(0,a.kt)("inlineCode",{parentName:"p"},"makeStatic")," Powershell script in the root of the jQuery Validation Unobtrusive Native repo:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),'param([string]$buildFolder)\n\n$jVUNDemo = "$($buildFolder)\\jVUNDemo"\n$staticSiteParentPath = (get-item $buildFolder).Parent.FullName\n$staticSite = "static-site"\n$staticSitePath = "$($staticSiteParentPath)\\$($staticSite)"\n$wgetLogPath = "$($staticSiteParentPath)\\wget.log"\n$port = 57612\n$servedAt = "http://localhost:$($port)/"\nwrite-host "jVUNDemo location: $jVUNDemo"\nwrite-host "static site parent location: $staticSiteParentPath"\nwrite-host "static site location: $staticSitePath"\nwrite-host "wget log path: $wgetLogPath"\n\nwrite-host "Spin up jVUNDemo site at $($servedAt)"\n$process = Start-Process \'C:\\Program Files (x86)\\IIS Express\\iisexpress.exe\' -NoNewWindow -ArgumentList "/path:$($jVUNDemo) /port:$($port)"\n\nwrite-host "Wait a moment for IIS to startup"\nStart-sleep -s 15\n\nif (Test-Path $staticSitePath) {\n    write-host "Removing $($staticSitePath)..."\n    Remove-Item -path $staticSitePath -Recurse -Force\n}\n\nwrite-host "Create static version of demo site here: $($staticSitePath)"\nPush-Location $staticSiteParentPath\n# 2>&1 used to combine stderr and stdout\nwget.exe --recursive --convert-links -E --directory-prefix=$staticSite --no-host-directories $servedAt > $wgetLogPath 2>&1\nwrite-host "lastExitCode: $($lastExitCode)"\ncat $wgetLogPath\nPop-Location\n\nwrite-host "Shut down jVUNDemo site"\nstop-process -Name iisexpress\n\nif (Test-Path $staticSitePath) {\n    write-host "Contents of $($staticSitePath)"\n    ls $staticSitePath\n}\n')),(0,a.kt)("p",null,"The above Powershell does the following:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Starts up IIS Express serving jVUNDemo on http://localhost:57612/"),(0,a.kt)("li",{parentName:"ol"},"Waits 15 seconds for IIS Express to get itself together (probably a shorter wait time would be sufficient)"),(0,a.kt)("li",{parentName:"ol"},'Points Wget at jVUNDemo and bellows "go!!!!"'),(0,a.kt)("li",{parentName:"ol"},'Wget downloads and saves the static version of jVUNDemo to a directory called "static-site"'),(0,a.kt)("li",{parentName:"ol"},"Stops IIS Express"),(0,a.kt)("li",{parentName:"ol"},'Prints out the contents of the "static-site" directory')),(0,a.kt)("p",null,"When run, it pumps something like this out:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"jVUNDemo location: C:\\projects\\jquery-validation-unobtrusive-native\\jVUNDemo\nstatic site parent location: C:\\projects\nstatic site location: C:\\projects\\static-site\nwget log path: C:\\projects\\wget.log\nSpin up jVUNDemo site at http://localhost:57612/\nWait a moment for IIS to startup\nCreate static version of demo site here: C:\\projects\\static-site\nwget.exe : --2014-12-29 07:49:56--  http://localhost:57612/\nResolving localhost...\n127.0.0.1\nConnecting to localhost|127.0.0.1|:57612... connected.\nHTTP request sent, awaiting response...\n200 OK\n\n..... lots of HTTP requests.....\n\nDownloaded: 30 files, 1.0M in 0.09s (10.8 MB/s)\nConverting static-site/Demo/CreditCard.html... 34-0\nConverting static-site/Demo/Number.html... 34-0\nConverting static-site/Demo/Range.html... 34-0\nConverting static-site/Demo/Email.html... 34-0\nConverting static-site/AdvancedDemo/CustomValidation.html... 35-0\nConverting static-site/Demo/Date.html... 36-0\nConverting static-site/Home/License.html... 27-0\nConverting static-site/index.html... 29-0\nConverting static-site/AdvancedDemo/Dynamic.html... 35-0\nConverting static-site/Demo/MaxLengthMinLength.html... 34-0\nConverting static-site/Demo/Required.html... 34-0\nConverting static-site/AdvancedDemo.html... 32-0\nConverting static-site/Demo/Remote.html... 35-0\nConverting static-site/Demo/EqualTo.html... 34-0\nConverting static-site/AdvancedDemo/Globalize.html... 38-0\nConverting static-site/Demo/Url.html... 34-0\nConverting static-site/Demo.html... 37-0\nConverting static-site/Home/GettingStarted.html... 29-0\nConverting static-site/Home/Download.html... 27-0\nConverting static-site/AdvancedDemo/Tooltip.html... 34-0\nConverted 20 files in 0.03 seconds.\n\nShut down jVUNDemo site\nContents of C:\\projects\\static-site\n\n\n    Directory: C:\\projects\\static-site\n\n\nMode                LastWriteTime     Length Name\n----                -------------     ------ ----\nd----        12/29/2014   7:50 AM            AdvancedDemo\nd----        12/29/2014   7:50 AM            Content\nd----        12/29/2014   7:50 AM            Demo\nd----        12/29/2014   7:50 AM            Home\nd----        12/29/2014   7:50 AM            Scripts\n-a---        12/29/2014   7:50 AM       5967 AdvancedDemo.html\n-a---        12/29/2014   7:50 AM       6802 Demo.html\n-a---        12/29/2014   7:47 AM      12862 favicon.ico\n-a---        12/29/2014   7:50 AM       8069 index.html\n")),(0,a.kt)("p",null,"And that's it for part 1 my friends! You now have a static version of the ASP.Net MVC site to dazzle the world with. I should say for the purposes of full disclosure that there are 2 pages in the site which are not entirely \"static\" friendly. For these 2 pages I've put messages in that are displayed when the page is served up in a static format explaining the limitations. Their full glory can still be experienced by cloning the project and running locally."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"/deploying-aspnet-mvc-to-github-pages-with-appveyor-part-2"}),"Next time")," we'll take the mechanism detailed above and plug it into AppVeyor for some Continuous Integration happiness."))}d.isMDXComponent=!0},93670:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"deploying-aspnet-mvc-to-github-pages-with-appveyor-part-2",title:"Deploying from ASP.Net MVC to GitHub Pages using AppVeyor part 2",authors:"johnnyreilly",tags:["GitHub Personal Access Token","Continuous Integration","powershell","github pages","AppVeyor"],hide_table_of_contents:!1},s=void 0,l={permalink:"/deploying-aspnet-mvc-to-github-pages-with-appveyor-part-2",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-01-07-deploying-aspnet-mvc-to-github-pages-with-appveyor-part-2/index.md",source:"@site/blog/2015-01-07-deploying-aspnet-mvc-to-github-pages-with-appveyor-part-2/index.md",title:"Deploying from ASP.Net MVC to GitHub Pages using AppVeyor part 2",description:'"Automation, automation, automation." Those were and are Tony Blair\'s priorities for keeping open source projects well maintained.',date:"2015-01-07T00:00:00.000Z",formattedDate:"January 7, 2015",tags:[{label:"GitHub Personal Access Token",permalink:"/tags/git-hub-personal-access-token"},{label:"Continuous Integration",permalink:"/tags/continuous-integration"},{label:"powershell",permalink:"/tags/powershell"},{label:"github pages",permalink:"/tags/github-pages"},{label:"AppVeyor",permalink:"/tags/app-veyor"}],readingTime:4.78,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"deploying-aspnet-mvc-to-github-pages-with-appveyor-part-2",title:"Deploying from ASP.Net MVC to GitHub Pages using AppVeyor part 2",authors:"johnnyreilly",tags:["GitHub Personal Access Token","Continuous Integration","powershell","github pages","AppVeyor"],hide_table_of_contents:!1},prevItem:{title:"TypeScript: In Praise of Union Types",permalink:"/typescript-using-functions-with-union-types"},nextItem:{title:"Deploying from ASP.Net MVC to GitHub Pages using AppVeyor part 1",permalink:"/deploying-aspnet-mvc-to-github-pages-with-appveyor-part-1"}},p={authorsImageUrls:[void 0]},u=[{value:"GitHub Personal Access Token",id:"github-personal-access-token",level:2},{value:"<code>appveyor.yml</code>",id:"appveyoryml",level:2},{value:"<code>pushStatic.ps1</code>",id:"pushstaticps1",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'"Automation, automation, automation." Those were and are Tony Blair\'s priorities for keeping open source projects well maintained.'),(0,a.kt)("p",null,"OK, that's not quite true... But what is certainly true is that maintaining an open source project takes time. And there's only so much free time that anyone has. For that reason, wherever you can it makes sense to ",(0,a.kt)("em",{parentName:"p"},"AUTOMATE"),"!"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"/deploying-aspnet-mvc-to-github-pages-with-appveyor-part-1"}),"Last time")," we looked at how you can take an essentially static ASP.Net MVC site (in this case my jVUNDemo documentation site) and generate an entirely static version using Wget. This static site has been pushed to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://pages.github.com/"}),"GitHub Pages")," and is serving as the documentation for ",(0,a.kt)("a",o({parentName:"p"},{href:"http://johnnyreilly.github.io/jQuery.Validation.Unobtrusive.Native/"}),"jQuery Validation Unobtrusive Native")," (and for bonus points is costing me no money at all)."),(0,a.kt)("p",null,"So what next? Well, automation clearly! If I make a change to jQuery Validation Unobtrusive Native then AppVeyor already bounds in and performs a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://ci.appveyor.com/project/JohnReilly/jquery-validation-unobtrusive-native"}),"continuous integration build")," for me. It picks up the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/jQuery.Validation.Unobtrusive.Native"}),"latest source")," from GitHub, pulls in my dependencies, performs a build and runs my tests. Lovely."),(0,a.kt)("p",null,"So the obvious thing to do is to take this process and plug in the generation of my static site and the publication thereof to GitHub pages. The minute a change is made to my project the documentation should be updated without me having to break sweat. That's the goal."),(0,a.kt)("h2",o({},{id:"github-personal-access-token"}),"GitHub Personal Access Token"),(0,a.kt)("p",null,"In order to complete our chosen mission we're going to need a GitHub Personal Access Token. We're going to use it when we clone, update and push our GitHub Pages branch. To get one we biff over to Settings / Applications in GitHub and click the \"Generate New Token\" button."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(58035).Z,width:"640",height:"435"})),(0,a.kt)("p",null,"The token I'm using for my project has the following scopes selected:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(42715).Z,width:"640",height:"435"})),(0,a.kt)("h2",o({},{id:"appveyoryml"}),(0,a.kt)("inlineCode",{parentName:"h2"},"appveyor.yml")),(0,a.kt)("p",null,"With our token in hand we turn our attention to AppVeyor build configuration. This is possible using a file called ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.appveyor.com/docs/build-configuration"}),(0,a.kt)("inlineCode",{parentName:"a"},"appveyor.yml"))," stored in the root of your repo. You can also use the AppVeyor web UI to do this. However, for the purposes of ease of demonstration I'm using the file approach. The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/jQuery.Validation.Unobtrusive.Native/blob/master/appveyor.yml"}),"jQuery Validation Unobtrusive Native ",(0,a.kt)("inlineCode",{parentName:"a"},"appveyor.yml"))," looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"---\n#---------------------------------#\n#      general configuration      #\n#---------------------------------#\n\n# version format\nversion: 1.0.{build}\n\n#---------------------------------#\n#    environment configuration    #\n#---------------------------------#\n\n# environment variables\nenvironment:\n  GithubEmail: johnny_reilly@hotmail.com\n  GithubUsername: johnnyreilly\n  GithubPersonalAccessToken:\n    secure: T4M/N+e/baksVoeWoYKPWIpfahOsiSFw/+Zc81VuThZmWEqmrRtgEHUyin0vCWhl\n\nbranches:\n  only:\n    - master\n\ninstall:\n  - ps: choco install wget\n\nbuild:\n  verbosity: minimal\n\nafter_test:\n  - ps: ./makeStatic.ps1 $env:APPVEYOR_BUILD_FOLDER\n  - ps: ./pushStatic.ps1 $env:APPVEYOR_BUILD_FOLDER $env:GithubEmail $env:GithubUsername $env:GithubPersonalAccessToken\n")),(0,a.kt)("p",null,"There's a number of things you should notice from the yml file:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"We create 3 environment variables: GithubEmail, GithubUsername and GithubPersonalAccessToken (more on this in a moment)."),(0,a.kt)("li",{parentName:"ul"},"We only build the master branch."),(0,a.kt)("li",{parentName:"ul"},"We use ",(0,a.kt)("a",o({parentName:"li"},{href:"https://chocolatey.org/packages/Wget"}),"Chocolatey")," to install Wget which is used by the ",(0,a.kt)("inlineCode",{parentName:"li"},"makeStatic.ps1")," Powershell script."),(0,a.kt)("li",{parentName:"ul"},"After the tests have completed we run 2 Powershell scripts. First ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/johnnyreilly/jQuery.Validation.Unobtrusive.Native/blob/master/makeStatic.ps1"}),(0,a.kt)("inlineCode",{parentName:"a"},"makeStatic.ps1"))," which builds the static version of our site. This is the exact same script we discussed in the previous post - we're just passing it the build folder this time (one of AppVeyor's environment variables). Second, we run ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/johnnyreilly/jQuery.Validation.Unobtrusive.Native/blob/master/pushStatic.ps1"}),(0,a.kt)("inlineCode",{parentName:"a"},"pushStatic.ps1"))," which publishes the static site to GitHub Pages.")),(0,a.kt)("p",null,"We pass 4 arguments to ",(0,a.kt)("inlineCode",{parentName:"p"},"pushStatic.ps1"),": the build folder, my email address, my username and my personal access token. For the sake of security the GithubPersonalAccessToken has been encrypted as indicated by the ",(0,a.kt)("inlineCode",{parentName:"p"},"secure")," keyword. This is a capability available in AppVeyor ",(0,a.kt)("a",o({parentName:"p"},{href:"https://ci.appveyor.com/tools/encrypt"}),"here"),"."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(60422).Z,width:"640",height:"369"})),(0,a.kt)("p",null,"This allows me to mask my personal access token rather than have it available as free text for anyone to grab."),(0,a.kt)("h2",o({},{id:"pushstaticps1"}),(0,a.kt)("inlineCode",{parentName:"h2"},"pushStatic.ps1")),(0,a.kt)("p",null,"Finally we can turn our attention to how our Powershell script ",(0,a.kt)("inlineCode",{parentName:"p"},"pushStatic.ps1")," goes about pushing our changes up to GitHub Pages:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),'param([string]$buildFolder, [string]$email, [string]$username, [string]$personalAccessToken)\n\nWrite-Host "- Set config settings...."\ngit config --global user.email $email\ngit config --global user.name $username\ngit config --global push.default matching\n\nWrite-Host "- Clone gh-pages branch...."\ncd "$($buildFolder)\\..\\"\nmkdir gh-pages\ngit clone --quiet --branch=gh-pages https://$($username):$($personalAccessToken)@github.com/johnnyreilly/jQuery.Validation.Unobtrusive.Native.git .\\gh-pages\\\ncd gh-pages\ngit status\n\nWrite-Host "- Clean gh-pages folder...."\nGet-ChildItem -Attributes !r | Remove-Item -Recurse -Force\n\nWrite-Host "- Copy contents of static-site folder into gh-pages folder...."\ncopy-item -path ..\\static-site\\* -Destination $pwd.Path -Recurse\n\ngit status\n$thereAreChanges = git status | select-string -pattern "Changes not staged for commit:","Untracked files:" -simplematch\nif ($thereAreChanges -ne $null) {\n    Write-host "- Committing changes to documentation..."\n    git add --all\n    git status\n    git commit -m "skip ci - static site regeneration"\n    git status\n    Write-Host "- Push it...."\n    git push --quiet\n    Write-Host "- Pushed it good!"\n}\nelse {\n    write-host "- No changes to documentation to commit"\n}\n')),(0,a.kt)("p",null,"So what's happening here? Let's break it down:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Git is configured with the passed in username and email address."),(0,a.kt)("li",{parentName:"ul"},'A folder is created that sits alongside the build folder called "gh-pages".'),(0,a.kt)("li",{parentName:"ul"},'We clone the "gh-pages" branch of jQuery Validation Unobtrusive Native into our "gh-pages" directory. You\'ll notice that we are using our GitHub personal access token in the clone URL itself.'),(0,a.kt)("li",{parentName:"ul"},'We delete the contents of the "gh-pages" directory leaving it empty.'),(0,a.kt)("li",{parentName:"ul"},'We copy across the contents of the "static-site" folder (created by ',(0,a.kt)("inlineCode",{parentName:"li"},"makeStatic.ps1"),') into the "gh-pages".'),(0,a.kt)("li",{parentName:"ul"},"We use ",(0,a.kt)("inlineCode",{parentName:"li"},"git status")," to check if there are any changes. (This method is completely effective but a little crude to my mind - there's probably better approaches to this.... shout me in the comments if you have a suggestion.)"),(0,a.kt)("li",{parentName:"ul"},"If we have no changes then we do nothing."),(0,a.kt)("li",{parentName:"ul"},"If we have changes then we stage them, commit them and push them to GitHub Pages. Then we sign off with an allusion to ",(0,a.kt)("a",o({parentName:"li"},{href:"https://en.wikipedia.org/wiki/Push_It_(Salt-n-Pepa_song)"}),"80's East Coast hip-hop"),"... 'Cos that's how we roll.")),(0,a.kt)("p",null,'With this in place, any changes to the docs will be automatically published out to our "gh-pages" branch. Our documentation will always be up to date thanks to the goodness of AppVeyor\'s Continuous Integration service.'))}d.isMDXComponent=!0},23132:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-using-functions-with-union-types",title:"TypeScript: In Praise of Union Types",authors:"johnnyreilly",tags:["typescript","Union Types"],hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-using-functions-with-union-types",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-01-20-typescript-using-functions-with-union-types/index.md",source:"@site/blog/2015-01-20-typescript-using-functions-with-union-types/index.md",title:"TypeScript: In Praise of Union Types",description:"(& How to Express Functions in UTs)",date:"2015-01-20T00:00:00.000Z",formattedDate:"January 20, 2015",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"Union Types",permalink:"/tags/union-types"}],readingTime:6.295,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-using-functions-with-union-types",title:"TypeScript: In Praise of Union Types",authors:"johnnyreilly",tags:["typescript","Union Types"],hide_table_of_contents:!1},prevItem:{title:"The Convent with Continuous Delivery",permalink:"/the-convent-with-continuous-delivery"},nextItem:{title:"Deploying from ASP.Net MVC to GitHub Pages using AppVeyor part 2",permalink:"/deploying-aspnet-mvc-to-github-pages-with-appveyor-part-2"}},p={authorsImageUrls:[void 0]},u=[{value:"(&amp; How to Express Functions in UTs)",id:"-how-to-express-functions-in-uts",level:2},{value:"A little history",id:"a-little-history",level:2},{value:"That&#39;s right - the days before Union Types are now &quot;history&quot; :-)",id:"thats-right---the-days-before-union-types-are-now-history--",level:3},{value:"A new dawn",id:"a-new-dawn",level:2},{value:"State of the Union",id:"state-of-the-union",level:2},{value:"Bonfire of the Overloads",id:"bonfire-of-the-overloads",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"-how-to-express-functions-in-uts"}),"(& How to Express Functions in UTs)"),(0,a.kt)("p",null,"Have you heard the good news my friend? I refer, of course, to the shipping of TypeScript 1.4 and my ",(0,a.kt)("em",{parentName:"p"},"favourite")," language feature since generics.... Union Types."),(0,a.kt)("p",null,"In the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.com/b/typescript/archive/2015/01/16/announcing-typescript-1-4.aspx"}),"1",".","4 announcement")," Jonathan Turner described Union Types thusly:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"JavaScript functions may take a number of possible argument types. Up to now, we\u2019ve supported this using function overloads. Starting with TypeScript 1.4, we\u2019ve generalized this capability and now allow you to specify that that a value is one of a number of different types using a union type:"),(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"function f(x: number | number[]) {\n  if (typeof x === 'number') {\n    return x + 10;\n  } else {\n    // return sum of numbers\n  }\n}\n")),(0,a.kt)("p",{parentName:"blockquote"},"Once you have a value of a union type, you can use a typeof and instanceof checks to use the value in a type-safe way. You'll notice we use this in the above example and can treat x as a number type inside of the if-block."),(0,a.kt)("p",{parentName:"blockquote"},"Union types are a new kind of type and work any place you specify a type.")),(0,a.kt)("p",null,"Lovely right? But what's missing? Well, to my mind, the most helpful aspect of Union Types. Definition file creation."),(0,a.kt)("h2",o({},{id:"a-little-history"}),"A little history"),(0,a.kt)("h3",o({},{id:"thats-right---the-days-before-union-types-are-now-history--"}),'That\'s right - the days before Union Types are now "history" :-)'),(0,a.kt)("p",null,"When creating definition files (",(0,a.kt)("inlineCode",{parentName:"p"},"*.d.ts"),') in the past there was a problem with TypeScript. A limitation. JavaScript often relies on "option bags" to pass configuration into a method. An "option bag" is essentially a JavaScript object literal which contains properties which are used to perform configuration. A good example of this is the ',(0,a.kt)("inlineCode",{parentName:"p"},"route")," parameter passed into Angular's ngRoute ",(0,a.kt)("inlineCode",{parentName:"p"},'<a href="https://docs.angularjs.org/api/ngRoute/provider/$routeProvider#when">when</a>')," method."),(0,a.kt)("p",null,"I'd like to draw your attention to 2 of the properties that can be passed in (quoted from the documentation):"),(0,a.kt)("blockquote",null,(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"controller \u2013 ",(0,a.kt)("inlineCode",{parentName:"p"},"{(string|function()=}")," \u2013 Controller fn that should be associated with newly created scope or the name of a registered controller if passed as a string.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"template \u2013 ",(0,a.kt)("inlineCode",{parentName:"p"},"{string=|function()=}")," \u2013 html template as a string or a function that returns an html template as a string which should be used by ngView or ngInclude directives. This property takes precedence over templateUrl."),(0,a.kt)("p",{parentName:"li"},"If template is a function, it will be called with the following parameters:"),(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"{Array.&lt;Object&gt;}")," ","-"," route parameters extracted from the current $location.path() by applying the current route")))),(0,a.kt)("p",null,"Both of these properties can be of more than 1 type."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"controller")," can be a ",(0,a.kt)("inlineCode",{parentName:"li"},"string"),(0,a.kt)("em",{parentName:"li"},"or")," a ",(0,a.kt)("inlineCode",{parentName:"li"},"function"),"."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"template")," can be a ",(0,a.kt)("inlineCode",{parentName:"li"},"string"),(0,a.kt)("em",{parentName:"li"},"or")," a ",(0,a.kt)("inlineCode",{parentName:"li"},"function")," that returns a ",(0,a.kt)("inlineCode",{parentName:"li"},"string")," and has ",(0,a.kt)("inlineCode",{parentName:"li"},"$routeParams")," as a parameter.")),(0,a.kt)("p",null,"There's the rub. Whilst it was possible to overload functions in TypeScript pre 1.4, it was ",(0,a.kt)("u",null,"not")),(0,a.kt)("p",null,"possible to overload interface members. This meant the only way to model these sorts of properties was by seeking out a best common type which would fit all scenarios. This invariably meant using the ",(0,a.kt)("inlineCode",{parentName:"p"},"any")," type. Whilst that worked it didn't lend any consuming code a great deal of type safety. Let's look at a truncated version of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped/blob/c71628e0765eb8e240d8eabd2225f64ea2e2fdb8/angularjs/angular-route.d.ts"}),(0,a.kt)("inlineCode",{parentName:"a"},"angular-route.d.ts"))," for these properties prior to union types:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"declare module ng.route {\n  // ...\n\n  interface IRoute {\n    /**\n     * {(string|function()=}\n     * Controller fn that should be associated with newly created scope or\n     * the name of a registered controller if passed as a string.\n     */\n    controller?: any;\n\n    /**\n     * {string=|function()=}\n     * Html template as a string or a function that returns an html template\n     * as a string which should be used by ngView or ngInclude directives. This\n     * property takes precedence over templateUrl.\n     *\n     * If template is a function, it will be called with the following parameters:\n     *\n     * {Array.<Object>} - route parameters extracted from the current\n     * $location.path() by applying the current route\n     */\n    template?: any;\n\n    // ...\n  }\n\n  // ...\n}\n")),(0,a.kt)("p",null,"It's ",(0,a.kt)("inlineCode",{parentName:"p"},"any")," city... Kind of sticks in the craw doesn't it?"),(0,a.kt)("h2",o({},{id:"a-new-dawn"}),"A new dawn"),(0,a.kt)("p",null,"TypeScript 1.4 has shipped and Union Types are with us. We can do better than ",(0,a.kt)("inlineCode",{parentName:"p"},"any"),". So what does ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped/blob/30ce45e0e706322f34608ab6fa5de141bba59c90/angularjs/angular-route.d.ts"}),(0,a.kt)("inlineCode",{parentName:"a"},"angular-route.d.ts"))," look like now we have Union Types?"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"declare module ng.route {\n  // ...\n\n  interface IRoute {\n    /**\n     * {(string|function()=}\n     * Controller fn that should be associated with newly created scope or\n     * the name of a registered controller if passed as a string.\n     */\n    controller?: string | Function;\n\n    /**\n     * {string=|function()=}\n     * Html template as a string or a function that returns an html template\n     * as a string which should be used by ngView or ngInclude directives. This\n     * property takes precedence over templateUrl.\n     *\n     * If template is a function, it will be called with the following parameters:\n     *\n     * {Array.<Object>} - route parameters extracted from the current\n     * $location.path() by applying the current route\n     */\n    template?:\n      | string\n      | { ($routeParams?: ng.route.IRouteParamsService): string };\n\n    // ...\n  }\n\n  // ...\n}\n")),(0,a.kt)("p",null,"With these changes in place we are now accurately modelling the ",(0,a.kt)("inlineCode",{parentName:"p"},"route")," option bags in TypeScript. Hoorah!!!"),(0,a.kt)("p",null,"Let's dig in a little. If you look at the ",(0,a.kt)("inlineCode",{parentName:"p"},"controller")," definition it's pretty straightforward. ",(0,a.kt)("inlineCode",{parentName:"p"},"string|Function")," ","-"," clearly the ",(0,a.kt)("inlineCode",{parentName:"p"},"controller")," can be a ",(0,a.kt)("inlineCode",{parentName:"p"},"string"),(0,a.kt)("em",{parentName:"p"},"or")," a ",(0,a.kt)("inlineCode",{parentName:"p"},"Function"),". Simple."),(0,a.kt)("p",null,"Now let's look at the ",(0,a.kt)("inlineCode",{parentName:"p"},"template")," definition by itself:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"template?: string | { ($routeParams?: ng.route.IRouteParamsService) : string; }\n")),(0,a.kt)("p",null,"As with the ",(0,a.kt)("inlineCode",{parentName:"p"},"controller")," the ",(0,a.kt)("inlineCode",{parentName:"p"},"template")," can be a string - that is pretty clear. But what's that hovering on the other side of the \"","|",'"? What could ',(0,a.kt)("inlineCode",{parentName:"p"},"{ ($routeParams?: ng.route.IRouteParamsService) : string; }")," be exactly?"),(0,a.kt)("p",null,"Well, in a word, it's a ",(0,a.kt)("inlineCode",{parentName:"p"},"Function"),". The ",(0,a.kt)("inlineCode",{parentName:"p"},"controller")," would allow any kind of function at all. However the ",(0,a.kt)("inlineCode",{parentName:"p"},"template")," definition is deliberately more restrictive. This defines a function which must return a ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," and which receives an optional parameter of ",(0,a.kt)("inlineCode",{parentName:"p"},"$routeParams")," of type ",(0,a.kt)("inlineCode",{parentName:"p"},"ng.route.IRouteParamsService"),"."),(0,a.kt)("h2",o({},{id:"state-of-the-union"}),"State of the Union"),(0,a.kt)("p",null,"Hopefully you can now see just how useful Union Types are and how you can express specific sorts of function definitions as part of a Union Type."),(0,a.kt)("p",null,"The thing that prompted me first to write this post was seeing that there don't appear to be any examples out there of how to express functions inside Union Types. I only landed on the syntax myself after a little experimentation in Visual Studio after I'd installed TS 1.4. I've started work on bringing Union Types to the typings inside ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped"}),"DefinitelyTyped")," and so you'll start to see them appearing more and more. But since it's rather \"hidden knowledge\" at present I wanted to do my bit to make it a little better known."),(0,a.kt)("p",null,"As ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/Rickenhacker"}),"Daniel")," helpfully points out in the comments there is an alternate syntax - lambda style. So instead of this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"template?: string | { ($routeParams?: ng.route.IRouteParamsService) : string; }\n")),(0,a.kt)("p",null,"You could write this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"template?: string | (($routeParams?: ng.route.IRouteParamsService) => string);\n")),(0,a.kt)("p",null,"Just remember to place parentheses around the lambda to clearly delineate it."),(0,a.kt)("h2",o({},{id:"bonfire-of-the-overloads"}),"Bonfire of the Overloads"),(0,a.kt)("p",null,'Before I sign off I should mention the ability Union Types give you to define a much terser definition file. Basically the "',"|",'" operator makes for a bonfire of the overloads. Where you previously may have had 6 overloads for the same method (each with identical JSDoc) you now only need 1. Which is beautiful (and DRY).'),(0,a.kt)("p",null,"It's surprising just what a difference it makes. This is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped/blob/9bd7fe69d98337db56144c3da131d413f5b7e895/jquery/jquery.d.ts"}),(0,a.kt)("inlineCode",{parentName:"a"},"jQuery.d.ts"))," last week (pre TypeScript 1.4). This is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/borisyankov/DefinitelyTyped/blob/9f64372a065541fe2b8f6c5c5cd9b55a1d631f19/jquery/jquery.d.ts"}),(0,a.kt)("inlineCode",{parentName:"a"},"jQuery.d.ts"))," now - with Union Types aplenty. Last week it was ","~","4000 lines of code. This week it's ","~","3200 lines of code. With the same functionality. Union Types are ",(0,a.kt)("em",{parentName:"p"},"FANTASTIC"),"!"))}d.isMDXComponent=!0},35243:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"the-convent-with-continuous-delivery",title:"The Convent with Continuous Delivery",authors:"johnnyreilly",tags:["Continuous Delivery","AppVeyor"],hide_table_of_contents:!1},s=void 0,l={permalink:"/the-convent-with-continuous-delivery",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-02-11-the-convent-with-continuous-delivery/index.md",source:"@site/blog/2015-02-11-the-convent-with-continuous-delivery/index.md",title:"The Convent with Continuous Delivery",description:"I've done it. I've open sourced the website that I maintain for my aunt what is a nun. Because I think we can all agree that nuns need open source and continuous integration about as much as anyone else.",date:"2015-02-11T00:00:00.000Z",formattedDate:"February 11, 2015",tags:[{label:"Continuous Delivery",permalink:"/tags/continuous-delivery"},{label:"AppVeyor",permalink:"/tags/app-veyor"}],readingTime:3.535,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"the-convent-with-continuous-delivery",title:"The Convent with Continuous Delivery",authors:"johnnyreilly",tags:["Continuous Delivery","AppVeyor"],hide_table_of_contents:!1},prevItem:{title:"Using Gulp to inject scripts and styles tags directly into your HTML",permalink:"/using-gulp-in-asp-net-instead-of-web-optimization"},nextItem:{title:"TypeScript: In Praise of Union Types",permalink:"/typescript-using-functions-with-union-types"}},p={authorsImageUrls:[void 0]},u=[{value:"Why on earth did you bother?",id:"why-on-earth-did-you-bother",level:2},{value:"How did you go about it?",id:"how-did-you-go-about-it",level:2},{value:"Where is it?",id:"where-is-it",level:2},{value:"Will you take pull requests?",id:"will-you-take-pull-requests",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I've done it. I've open sourced the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.poorclaresarundel.org/"}),"website that I maintain for my aunt what is a nun"),". Because I think we can all agree that nuns need open source and continuous integration about as much as anyone else."),(0,a.kt)("p",null,"For a long time now I've been maintaining a website for one of my (many) aunts that is a Poor Clare. (",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Subtyping"}),'That\'s a subtype of "nun" you OO enthusiasts.'),") It's not a terribly exciting site - it's mostly static content. It's built with a combination of AngularJS / TypeScript / Bootstrap and ASP.Net MVC. It's hosted on ",(0,a.kt)("a",o({parentName:"p"},{href:"http://azure.microsoft.com/en-us/documentation/services/websites/"}),"Azure Websites"),". In fact I have written about it (slightly more cagily) before ",(0,a.kt)("a",o({parentName:"p"},{href:"/migrating-from-angularjs-to-angularts"}),"here"),"."),(0,a.kt)("p",null,"I'll say up front: presentation-wise the site is not a work of art. However the nuns seem pretty happy with it. (Or perhaps secretly they're forgiving me the shonkiness and sparing my feelings - who can say?) If I put my mind to it the site could look much more lovely. But there's only so much time I can spare - and that's actually one of the reasons I've set up Continuous Delivery."),(0,a.kt)("h2",o({},{id:"why-on-earth-did-you-bother"}),"Why on earth did you bother?"),(0,a.kt)("p",null,"Well, you'd be surprised how often tweaks can be requested. Sometimes it appears to be forgotten for months at a time, and then all of a sudden my inbox is daily filled with a list of minor alterations. You know, slight text changes and the like."),(0,a.kt)("p",null,'So what I was generally doing was getting home of an evening, waiting until the children were in bed, chomping down some food and then firing up Visual Studio to make the changes and hit "Publish". Yes that\'s right; I was essentially using Visual Studio to edit text files and push a website out to Azure. The very definition of using a sledgehammer to crack a nut I think we can all agree.'),(0,a.kt)("p",null,"It occurred to me that if I had Continuous Delivery set up then I could make these tweaks and not have to worry about the site being published. Which would be nice. I wouldn't need Visual Studio anymore - any text editor would do. Also nice. Finally, if the source control was accessible online then I could probably get away with doing most tweaks on my mobile phone whilst I was travelling home. Timesaver!"),(0,a.kt)("h2",o({},{id:"how-did-you-go-about-it"}),"How did you go about it?"),(0,a.kt)("p",null,"Since ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.visualstudioonline.com"}),'Visual Studio Online (then "Team Foundation Service")')," was released I have been using it to host the source code. So the obvious solution was to use the tools offered there to do the deployment. However, this wasn't the smooth experience you might have hoped for. I had quite a frustrating afternoon trying things out before deciding it was becoming more trouble than it was worth. VSO appeared to make it supremely hard to customise builds."),(0,a.kt)("p",null,"Just recently though I have been having the most wonderful experience with ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.appveyor.com/"}),"AppVeyor"),". AppVeyor market themselves as ",(0,a.kt)("em",{parentName:"p"},'"#1 Continuous Delivery service for Windows"')," ","-"," I think they're right. Their build process is entirely flexible and customisable. It is, in short, a joy to use. (The support is fantastic too - very helpful indeed. Go ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/FeodorFitsner"}),"Feodor"),"!)"),(0,a.kt)("p",null,"If you look just below the header you'll read a very important sentence: ",(0,a.kt)("em",{parentName:"p"},'"Free for open-source projects"'),". You hear that? By the time I'd finished reading that sentence I'd decided that the Poor Clares website was about to become an open source project."),(0,a.kt)("p",null,"And now it is."),(0,a.kt)("h2",o({},{id:"where-is-it"}),"Where is it?"),(0,a.kt)("p",null,"The source on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/poorclaresarundel"}),"GitHub"),". The builds and deployment are taken care of by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://ci.appveyor.com/project/JohnReilly/poorclaresarundel"}),"AppVeyor"),"."),(0,a.kt)("h2",o({},{id:"will-you-take-pull-requests"}),"Will you take pull requests?"),(0,a.kt)("p",null,"If they're serious, then yes, certainly! My long term plan is to try and get the nuns set up as collaborators in GitHub. That way they can make their own minor tweaks without me getting involved."),(0,a.kt)("p",null,"On another front, I do wonder if open-sourcing Poor Clares, Arundel might have other hidden benefits. There's a number of things I'm not too keen on in the code. Up until now I think my attitude was possibly \"it works so that's good enough\". It was only me aware of the shortcomings. Now it's public I'll probably have more of an incentive to tidy up the rough edges. That's the theory anyway - Embarrassment Driven Development anyone? :-)"))}d.isMDXComponent=!0},38305:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"using-gulp-in-asp-net-instead-of-web-optimization",title:"Using Gulp to inject scripts and styles tags directly into your HTML",authors:"johnnyreilly",tags:["asp.net","Web Optimization","gulpjs"],hide_table_of_contents:!1},s=void 0,l={permalink:"/using-gulp-in-asp-net-instead-of-web-optimization",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-02-17-using-gulp-in-asp-net-instead-of-web-optimization/index.md",source:"@site/blog/2015-02-17-using-gulp-in-asp-net-instead-of-web-optimization/index.md",title:"Using Gulp to inject scripts and styles tags directly into your HTML",description:"This is very probably the dullest title for a blog post I've ever come up with. Read on though folks - it's definitely going to pick up...",date:"2015-02-17T00:00:00.000Z",formattedDate:"February 17, 2015",tags:[{label:"asp.net",permalink:"/tags/asp-net"},{label:"Web Optimization",permalink:"/tags/web-optimization"},{label:"gulpjs",permalink:"/tags/gulpjs"}],readingTime:10.47,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"using-gulp-in-asp-net-instead-of-web-optimization",title:"Using Gulp to inject scripts and styles tags directly into your HTML",authors:"johnnyreilly",tags:["asp.net","Web Optimization","gulpjs"],hide_table_of_contents:!1},prevItem:{title:"Hey tsconfig.json, where have you been all my life?",permalink:"/hey-tsconfigjson-where-have-you-been"},nextItem:{title:"The Convent with Continuous Delivery",permalink:"/the-convent-with-continuous-delivery"}},p={authorsImageUrls:[void 0]},u=[{value:"Death to dynamic loading",id:"death-to-dynamic-loading",level:2},{value:"clean",id:"clean",level:3},{value:"boot-dependencies",id:"boot-dependencies",level:3},{value:"inject-debug and inject-release",id:"inject-debug-and-inject-release",level:3},{value:"scripts-debug and scripts-release",id:"scripts-debug-and-scripts-release",level:3},{value:"styles-debug and styles-release",id:"styles-debug-and-styles-release",level:3},{value:"fonts-debug and fonts-release",id:"fonts-debug-and-fonts-release",level:3},{value:"build-debug, build-release and default",id:"build-debug-build-release-and-default",level:3}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This is very probably the dullest title for a blog post I've ever come up with. Read on though folks - it's definitely going to pick up..."),(0,a.kt)("p",null,"I ",(0,a.kt)("a",o({parentName:"p"},{href:"/using-gulp-in-visual-studio-instead-of-web-optimization"}),"wrote last year")," about my first usage of Gulp in an ASP.Net project. I used Gulp to replace the Web Optimization functionality that is due to disappear when ASP.Net v5 ships. What I came up with was an approach that provided pretty much the same functionality; raw source in debug mode, bundling + minification in release mode."),(0,a.kt)("p",null,"It worked by having a launch page which was straight HTML. Embedded within this page was JavaScript that would, at runtime, load the required JavaScript / CSS and inject it dynamically into the document. This approach worked but it had a number of downsides:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Each time you fired up the app the following sequence of events would happen: - jQuery would load (purely there to simplify the making of various startup AJAX calls)")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"the page would make an AJAX call to the server to load various startup data, including whether the app is running in debug or release mode"),(0,a.kt)("li",{parentName:"ul"},"Depending on the result of the startup data either the debug or release package manifest would be loaded."),(0,a.kt)("li",{parentName:"ul"},"For each entry in the package manifest ",(0,a.kt)("inlineCode",{parentName:"li"},"script")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"link")," tags would be created and added to the document. These would generate further requests to the server to load the resources.")),(0,a.kt)("p",null,'Quite a lot going on here isn\'t there? Accordingly, initial startup time was slower than you might hope. 2. The "F" word: ',(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Flash_of_unstyled_content"}),"FOUC"),". Flash Of Unstyled Content - whilst all the hard work of the page load was going on (before the CSS had been loaded) the page would look rather ... bare. Not a terrible thing but none too slick either. 3. The gulpfile built both the debug and the release package each time it was run. This meant the gulp task generally did double the work that it needed to do."),(0,a.kt)("p",null,"I wanted to see if I could tackle these issues. I've recently been watching ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/John_Papa"}),"John Papa"),"'s excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.pluralsight.com/courses/javascript-build-automation-gulpjs"}),"Pluralsight course on Gulp")," and picked up a number of useful tips. With that in hand let's see what we can come up with..."),(0,a.kt)("h2",o({},{id:"death-to-dynamic-loading"}),"Death to dynamic loading"),(0,a.kt)("p",null,"The main issue with the approach I've been using is the dynamic loading. It makes the app slower and more complicated. So the obvious solution is to have my gulpfile inject scripts and css into the template. To that end it's ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/wiredep"}),"wiredep")," & ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/gulp-inject"}),"gulp-inject")," to the rescue!"),(0,a.kt)("p",null,"gulp-inject (as the name suggests) is used to inject ",(0,a.kt)("inlineCode",{parentName:"p"},"script")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"link")," tags into source code. I'm using ",(0,a.kt)("a",o({parentName:"p"},{href:"http://bower.io/"}),"Bower")," as my client side package manager and so I'm going to use wiredep to determine the vendor scripts I need. It will determine what packages my app is using from looking at my ",(0,a.kt)("inlineCode",{parentName:"p"},"bower.json"),", and give me a list of file paths in ",(0,a.kt)("em",{parentName:"p"},"dependency order")," (which I can then pass on to gulp-inject in combination with my own app script files). This means I don't have to think about ordering bower dependencies myself and I no longer need to separately maintain a list of these files within my gulpfile."),(0,a.kt)("p",null,"So, let's get the launch page (",(0,a.kt)("inlineCode",{parentName:"p"},"index.html"),") ready for gulp-inject:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<!DOCTYPE html>\n<html>\n  <head>\n    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />\n    <style>\n      .ng-hide {\n        display: none !important;\n      }\n    </style>\n    <title ng-bind="title">Proverb</title>\n    <meta charset="utf-8" />\n    <meta\n      name="viewport"\n      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"\n    />\n\n    \x3c!-- inject:css --\x3e\n    \x3c!-- endinject --\x3e\n\n    <link rel="icon" type="image/png" href="content/images/icon.png" />\n  </head>\n  <body>\n    <div>\n      <div ng-include="\'app/layout/shell.html\'"></div>\n      <div id="splash-page" ng-show="false" class="dissolve-animation">\n        <div class="page-splash">\n          <div class="page-splash-message">Proverb</div>\n\n          <div class="progress">\n            <div\n              class="progress-bar progress-bar-striped active"\n              role="progressbar"\n              style="width: 20%;"\n            >\n              <span class="sr-only">loading...</span>\n            </div>\n          </div>\n        </div>\n      </div>\n    </div>\n\n    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"><\/script>\n    <script>\n      window.jQuery ||\n        document.write(\'<script src="/build/jquery.min.js">\\x3C/script>\');\n    <\/script>\n\n    \x3c!-- inject:js --\x3e\n    \x3c!-- endinject --\x3e\n\n    <script>\n      (function () {\n        // Load startup data from the server\n        $.getJSON(\'api/Startup\').done(function (startUpData) {\n          angularApp.start({\n            thirdPartyLibs: {\n              moment: window.moment,\n              toastr: window.toastr,\n              underscore: window._,\n            },\n            appConfig: startUpData,\n          });\n        });\n      })();\n    <\/script>\n  </body>\n</html>\n')),(0,a.kt)("p",null,"The important thing to notice here are the ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;!-- inject:css --&gt;")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;!-- inject:js --&gt;")," injection placeholders. It's here that our script and style tags will be injected into the template. You'll notice that jQuery is ",(0,a.kt)("em",{parentName:"p"},"not")," being injected - and that's because I've opted to use a CDN for jQuery and then only fallback to serving jQuery myself if the CDN fails."),(0,a.kt)("p",null,"The other thing to notice here is that our launch page has become oh so much simpler in comparison with the dynamic loading approach. Which is fab."),(0,a.kt)("p",null,"Now before we start looking at our gulpfile I want to split out the configuration into a standalone file called gulpfile.config.js:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var tsjsmapjsSuffix = '.{ts,js.map,js}';\n\nvar bower = 'bower_components/';\nvar app = 'app/';\n\nvar config = {\n  base: '.',\n  buildDir: './build/',\n  debug: 'debug',\n  release: 'release',\n  css: 'css',\n\n  bootFile: app + 'index.html',\n  bootjQuery: bower + 'jquery/dist/jquery.min.js',\n\n  // The fonts we want Gulp to process\n  fonts: [bower + 'fontawesome/fonts/*.*'],\n\n  images: 'images/**/*.{gif,jpg,png}',\n\n  // The scripts we want Gulp to process\n  scripts: [\n    // Bootstrapping\n    app + 'app' + tsjsmapjsSuffix,\n    app + 'config.route' + tsjsmapjsSuffix,\n\n    // common Modules\n    app + 'common/common' + tsjsmapjsSuffix,\n    app + 'common/logger' + tsjsmapjsSuffix,\n    app + 'common/spinner' + tsjsmapjsSuffix,\n\n    // common.bootstrap Modules\n    app + 'common/bootstrap/bootstrap.dialog' + tsjsmapjsSuffix,\n\n    // directives\n    app + 'directives/**/*' + tsjsmapjsSuffix,\n\n    // services\n    app + 'services/**/*' + tsjsmapjsSuffix,\n\n    // controllers\n    app + 'about/**/*' + tsjsmapjsSuffix,\n    app + 'admin/**/*' + tsjsmapjsSuffix,\n    app + 'dashboard/**/*' + tsjsmapjsSuffix,\n    app + 'layout/**/*' + tsjsmapjsSuffix,\n    app + 'sages/**/*' + tsjsmapjsSuffix,\n    app + 'sayings/**/*' + tsjsmapjsSuffix,\n  ],\n\n  // The styles we want Gulp to process\n  styles: ['content/styles.css'],\n\n  wiredepOptions: {\n    exclude: [/jquery/],\n    ignorePath: '..',\n  },\n};\n\nconfig.debugFolder = config.buildDir + config.debug + '/';\nconfig.releaseFolder = config.buildDir + config.release + '/';\n\nconfig.templateFiles = [\n  app + '**/*.html',\n  '!' + config.bootFile, // Exclude the launch page\n];\n\nmodule.exports = config;\n")),(0,a.kt)("p",null,"Now to the meat of the matter - let me present the gulpfile:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"/// <vs AfterBuild='default' />\nvar gulp = require('gulp');\n\n// Include Our Plugins\nvar concat = require('gulp-concat');\nvar ignore = require('gulp-ignore');\nvar minifyCss = require('gulp-minify-css');\nvar uglify = require('gulp-uglify');\nvar rev = require('gulp-rev');\nvar del = require('del');\nvar path = require('path');\nvar templateCache = require('gulp-angular-templatecache');\nvar eventStream = require('event-stream');\nvar order = require('gulp-order');\nvar gulpUtil = require('gulp-util');\nvar wiredep = require('wiredep');\nvar inject = require('gulp-inject');\n\n// Get our config\nvar config = require('./gulpfile.config.js');\n\n/**\n * Get the scripts or styles the app requires by combining bower dependencies and app dependencies\n *\n * @param {string} jsOrCss Should be \"js\" or \"css\"\n */\nfunction getScriptsOrStyles(jsOrCss) {\n  var bowerScriptsAbsolute = wiredep(config.wiredepOptions)[jsOrCss];\n\n  var bowerScriptsRelative = bowerScriptsAbsolute.map(\n    function makePathRelativeToCwd(file) {\n      return path.relative('', file);\n    }\n  );\n\n  var appScripts = bowerScriptsRelative.concat(\n    jsOrCss === 'js' ? config.scripts : config.styles\n  );\n\n  return appScripts;\n}\n\n/**\n * Get the scripts the app requires\n */\nfunction getScripts() {\n  return getScriptsOrStyles('js');\n}\n\n/**\n * Get the styles the app requires\n */\nfunction getStyles() {\n  return getScriptsOrStyles('css');\n}\n\n/**\n * Get the scripts and the templates combined streams\n *\n * @param {boolean} isDebug\n */\nfunction getScriptsAndTemplates(isDebug) {\n  var options = isDebug ? { base: config.base } : undefined;\n  var appScripts = gulp.src(getScripts(), options);\n\n  //Get the view templates for $templateCache\n  var templates = gulp\n    .src(config.templateFiles)\n    .pipe(templateCache({ module: 'app', root: 'app/' }));\n\n  var combined = eventStream.merge(appScripts, templates);\n\n  return combined;\n}\n\ngulp.task('clean', function (cb) {\n  gulpUtil.log('Delete the build folder');\n\n  return del([config.buildDir], cb);\n});\n\ngulp.task('boot-dependencies', ['clean'], function () {\n  gulpUtil.log('Get dependencies needed for boot (jQuery and images)');\n\n  var jQuery = gulp.src(config.bootjQuery);\n  var images = gulp.src(config.images, { base: config.base });\n\n  var combined = eventStream\n    .merge(jQuery, images)\n    .pipe(gulp.dest(config.buildDir));\n\n  return combined;\n});\n\ngulp.task('inject-debug', ['styles-debug', 'scripts-debug'], function () {\n  gulpUtil.log('Inject debug links and script tags into ' + config.bootFile);\n\n  var scriptsAndStyles = [].concat(getScripts(), getStyles());\n\n  return gulp\n    .src(config.bootFile)\n    .pipe(\n      inject(\n        gulp\n          .src(\n            [\n              config.debugFolder + '**/*.{js,css}',\n              '!build\\\\debug\\\\bower_components\\\\spin.js', // Exclude weird spin js path\n            ],\n            { read: false }\n          )\n          .pipe(order(scriptsAndStyles))\n      )\n    )\n    .pipe(gulp.dest(config.buildDir));\n});\n\ngulp.task('inject-release', ['styles-release', 'scripts-release'], function () {\n  gulpUtil.log('Inject release links and script tags into ' + config.bootFile);\n\n  return gulp\n    .src(config.bootFile)\n    .pipe(\n      inject(gulp.src(config.releaseFolder + '**/*.{js,css}', { read: false }))\n    )\n    .pipe(gulp.dest(config.buildDir));\n});\n\ngulp.task('scripts-debug', ['clean'], function () {\n  gulpUtil.log('Copy across all JavaScript files to build/debug');\n\n  return getScriptsAndTemplates(true).pipe(gulp.dest(config.debugFolder));\n});\n\ngulp.task('scripts-release', ['clean'], function () {\n  gulpUtil.log('Concatenate & Minify JS for release into a single file');\n\n  return getScriptsAndTemplates(false)\n    .pipe(ignore.exclude('**/*.{ts,js.map}')) // Exclude ts and js.map files - not needed in release mode\n    .pipe(concat('app.js')) // Make a single file\n    .pipe(uglify()) // Make the file titchy tiny small\n    .pipe(rev()) // Suffix a version number to it\n    .pipe(gulp.dest(config.releaseFolder)); // Write single versioned file to build/release folder\n});\n\ngulp.task('styles-debug', ['clean'], function () {\n  gulpUtil.log('Copy across all CSS files to build/debug');\n\n  return gulp\n    .src(getStyles(), { base: config.base })\n    .pipe(gulp.dest(config.debugFolder));\n});\n\ngulp.task('styles-release', ['clean'], function () {\n  gulpUtil.log('Copy across all files in config.styles to build/debug');\n\n  return gulp\n    .src(getStyles())\n    .pipe(concat('app.css')) // Make a single file\n    .pipe(minifyCss()) // Make the file titchy tiny small\n    .pipe(rev()) // Suffix a version number to it\n    .pipe(gulp.dest(config.releaseFolder + '/' + config.css)); // Write single versioned file to build/release folder\n});\n\ngulp.task('fonts-debug', ['clean'], function () {\n  gulpUtil.log('Copy across all fonts in config.fonts to debug location');\n\n  return gulp\n    .src(config.fonts, { base: config.base })\n    .pipe(gulp.dest(config.debugFolder));\n});\n\ngulp.task('fonts-release', ['clean'], function () {\n  gulpUtil.log('Copy across all fonts in config.fonts to release location');\n\n  return gulp\n    .src(config.fonts)\n    .pipe(gulp.dest(config.releaseFolder + '/fonts'));\n});\n\ngulp.task('build-debug', ['boot-dependencies', 'inject-debug', 'fonts-debug']);\n\ngulp.task('build-release', [\n  'boot-dependencies',\n  'inject-release',\n  'fonts-release',\n]);\n\n// Use the web.config to determine whether the default task should create a debug or a release build\n// If the web.config contains this: '<compilation debug=\"true\"' then we do a default build, otherwise\n// we do a release build.  It's a little hacky but generally works\nvar fs = require('fs');\nvar data = fs.readFileSync(__dirname + '/web.config', 'UTF-8');\nvar inDebug = !!data.match(/<compilation debug=\"true\"/);\n\ngulp.task('default', [inDebug ? 'build-debug' : 'build-release']);\n")),(0,a.kt)("p",null,"That's a big old lump of code. So let's go through this a task by task..."),(0,a.kt)("h3",o({},{id:"clean"}),"clean"),(0,a.kt)("p",null,"Deletes the ",(0,a.kt)("inlineCode",{parentName:"p"},"build")," folder so we have a clean slate to build into."),(0,a.kt)("h3",o({},{id:"boot-dependencies"}),"boot-dependencies"),(0,a.kt)("p",null,'Copy across all files that are needed to allow the page to "boot" / startup. At present this is only jQuery and images.'),(0,a.kt)("h3",o({},{id:"inject-debug-and-inject-release"}),"inject-debug and inject-release"),(0,a.kt)("p",null,"This is the magic. This picks up the launch page (",(0,a.kt)("inlineCode",{parentName:"p"},"index.html"),"), takes the JavaScript and CSS and injects the corresponding ",(0,a.kt)("inlineCode",{parentName:"p"},"script")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"link")," tags into the page and writing it to the ",(0,a.kt)("inlineCode",{parentName:"p"},"build")," folder. Either the original source code or the bundled / minified equivalent will be used depending on whether it's debug or release."),(0,a.kt)("h3",o({},{id:"scripts-debug-and-scripts-release"}),"scripts-debug and scripts-release"),(0,a.kt)("p",null,"Here we collect up the following:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"the Bower specified JavaScript files"),(0,a.kt)("li",{parentName:"ul"},"the TypeScript + associated JavaScript files"),(0,a.kt)("li",{parentName:"ul"},"and we use our template files to construct a ",(0,a.kt)("inlineCode",{parentName:"li"},"templates.js")," file to prime the Angular template cache")),(0,a.kt)("p",null,"If it's the scripts-debug task we copy all these files into the ",(0,a.kt)("inlineCode",{parentName:"p"},"build/debug")," folder. If it's the scripts-release task we also bundle, minify and strip the TypeScript out too and copy into the ",(0,a.kt)("inlineCode",{parentName:"p"},"build/release")," folder."),(0,a.kt)("h3",o({},{id:"styles-debug-and-styles-release"}),"styles-debug and styles-release"),(0,a.kt)("p",null,"Here we collect up the following:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"the Bower specified CSS files"),(0,a.kt)("li",{parentName:"ul"},"our own app CSS")),(0,a.kt)("p",null,"If it's the styles-debug task we copy all these files into the ",(0,a.kt)("inlineCode",{parentName:"p"},"build/debug")," folder. If it's the styles-release task we also bundle and minify and copy into the ",(0,a.kt)("inlineCode",{parentName:"p"},"build/release")," folder."),(0,a.kt)("h3",o({},{id:"fonts-debug-and-fonts-release"}),"fonts-debug and fonts-release"),(0,a.kt)("p",null,"Whether it's the debug or the release build we copy across the font-awesome assets and place them in a location which works for the associated CSS (as the CSS will depend upon font-awesome)."),(0,a.kt)("h3",o({},{id:"build-debug-build-release-and-default"}),"build-debug, build-release and default"),(0,a.kt)("p",null,'build-debug and build-release (as their name suggests) either perform a build for release or a build for debug. If you remember, the web optimization library in ASP.Net serves up the raw code ("debug" code) if the ',(0,a.kt)("inlineCode",{parentName:"p"},"compilation debug")," flag in the ",(0,a.kt)("inlineCode",{parentName:"p"},"web.config")," is set to ",(0,a.kt)("inlineCode",{parentName:"p"},"true"),". If it is set to ",(0,a.kt)("inlineCode",{parentName:"p"},"false"),' then we get the bundled and minified code ("release" code) instead. Our default task tries its best to emulate this behaviour by doing a very blunt regex against the ',(0,a.kt)("inlineCode",{parentName:"p"},"web.config"),". Simply, if it can match ",(0,a.kt)("inlineCode",{parentName:"p"},'&lt;compilation debug="true"')," then it runs the debug build. Otherwise, the release build. It could be more elegant but there's a dearth of XML readers on npm that support synchronous parsing (which you kinda need for this scenario)."),(0,a.kt)("p",null,"What I intend to do soon is switch from using the web.config to drive the gulp build to using the approach outlined ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.codecadwallader.com/2015/03/15/integrating-gulp-into-your-tfs-builds-and-web-deploy/"}),"here"),". Namely plugging the build directly into Visual Studio's build process and using the type of build there."),(0,a.kt)("p",null,"Hopefully what I've written here makes it fairly clear how to use Gulp to directly inject scripts and styles directly into your HTML. If you want to look directly at the source then check out the Proverb.Web folder in ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/proverb-offline"}),"this repo"),"."))}d.isMDXComponent=!0},67917:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>m,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"hey-tsconfigjson-where-have-you-been",title:"Hey tsconfig.json, where have you been all my life?",authors:"johnnyreilly",tags:["tsconfig.json","typescript"],hide_table_of_contents:!1},s=void 0,l={permalink:"/hey-tsconfigjson-where-have-you-been",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-02-27-hey-tsconfigjson-where-have-you-been/index.md",source:"@site/blog/2015-02-27-hey-tsconfigjson-where-have-you-been/index.md",title:"Hey tsconfig.json, where have you been all my life?",description:"Sometimes, you just miss things. Something seismic happens and you had no idea. So it was with tsconfig.json.",date:"2015-02-27T00:00:00.000Z",formattedDate:"February 27, 2015",tags:[{label:"tsconfig.json",permalink:"/tags/tsconfig-json"},{label:"typescript",permalink:"/tags/typescript"}],readingTime:4.375,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"hey-tsconfigjson-where-have-you-been",title:"Hey tsconfig.json, where have you been all my life?",authors:"johnnyreilly",tags:["tsconfig.json","typescript"],hide_table_of_contents:!1},prevItem:{title:"PartialView.ToString()",permalink:"/partialview-tostring"},nextItem:{title:"Using Gulp to inject scripts and styles tags directly into your HTML",permalink:"/using-gulp-in-asp-net-instead-of-web-optimization"}},p={authorsImageUrls:[void 0]},u=[{value:"Implicit Referencing",id:"implicit-referencing",level:2},{value:"Cross-IDE TypeScript projects",id:"cross-ide-typescript-projects",level:2},{value:"<code>tsconfig.json</code>",id:"tsconfigjson",level:2}],c=(d="TypeScriptEnabled",function(e){return console.warn("Component "+d+" was not imported, exported, or provided by MDXProvider as global scope"),(0,a.kt)("div",o({},e))});var d;const h={toc:u};function m(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},h,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Sometimes, you just miss things. Something seismic happens and you had no idea. So it was with ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json"),"."),(0,a.kt)("p",null,'This blog post started life with the name "TypeScript: Some IDEs are more equal than others". I\'d intended to use it summarise a discussion on the ',(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/issues/1066"}),"TypeScript GitHub repo")," about implicit referencing including a fist shaken at the sky at the injustice of it all. But whilst I was writing it I dicovered things had changed without my knowledge. That's a rather wonderful thing."),(0,a.kt)("h2",o({},{id:"implicit-referencing"}),"Implicit Referencing"),(0,a.kt)("p",null,"Implicit referencing, if you're not aware, is the thing that separates Visual Studio from all other IDEs / text editors. Implicit referencing means that in Visual Studio you don't need to make use of comments at the head of each TypeScript file in order to tell the compiler where it can find the related TypeScript files."),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"reference")," comments aren't necessary when using Visual Studio because the VS project file is used to drive the files passed to the TypeScript compiler (tsc)."),(0,a.kt)("p",null,"The upshot of this is that, at time of writing, you can generally look at a TypeScript codebase and tell whether it was written using Visual Studio by opening it up a file at random and eyeballing for something like this at the top:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),'/// <reference path="other-file.ts" />\n')),(0,a.kt)("p",null,(0,a.kt)("em",{parentName:"p"},'"A-ha! They\'re using "reference" comments Watson. From this I deduce that the individuals in question are using the internal module approach and using Visual Studio as their IDE. Elementary, my dear fellow, quite elementary."')),(0,a.kt)("p",null,"This has important implications. Important I tell you, yes important! Well, important if you want to reduce the barriers between Visual Studio and everyone else. And I do. Whilst I love Visual Studio - it's been my daily workhorse for many years - I also love stepping away from it and using something more stripped down. I also like working with other people without mandating that they need to use Visual Studio as well. In the words of Rodney King, \"can't we all get along?\"."),(0,a.kt)("h2",o({},{id:"cross-ide-typescript-projects"}),"Cross-IDE TypeScript projects"),(0,a.kt)("p",null,"I feel I should be clear - you can already set up TypeScript projects to work regardless of IDE. But there's friction. It's not clear cut. You can see a full on discussion around this ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/issues/1066"}),"here")," but in the end it comes down to making a choice between these 3 options:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Set ",(0,a.kt)(c,{mdxType:"TypeScriptEnabled"},"false")," in a project file. ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/Microsoft/TypeScript/issues/1066#issuecomment-63727612"}),"This flag effectively deactivates implicit referencing.")," This approach requires that all developers (regardless of IDE) use ",(0,a.kt)("inlineCode",{parentName:"li"},"/// &lt;reference"),"s to build context. Compiler options in VS can be controlled using the project file as is."),(0,a.kt)("li",{parentName:"ol"},"Using Visual Studio without any csproj tweaks. This approach requires that all files will need ",(0,a.kt)("inlineCode",{parentName:"li"},"/// &lt;reference"),"s at their heads in order to build compilation context ",(0,a.kt)("em",{parentName:"li"},"outside")," of Visual Studio. It's possible that ",(0,a.kt)("inlineCode",{parentName:"li"},"/// &lt;reference"),"s and the csproj could get out of line - care is required to avoid this. Compiler options in VS can be controlled using the project file as is."),(0,a.kt)("li",{parentName:"ol"},"Using just files in Visual Studio with ",(0,a.kt)("inlineCode",{parentName:"li"},"/// &lt;reference"),"s to build compilation context. This scenario also requires that all developers (regardless of IDE) use ",(0,a.kt)("inlineCode",{parentName:"li"},"/// &lt;reference"),"s to build context. In Visual Studio there will be no control over compiler options.")),(0,a.kt)("p",null,"As you can see - this is sub-optimal. But don't worry - there's a new sheriff in town...."),(0,a.kt)("h2",o({},{id:"tsconfigjson"}),(0,a.kt)("inlineCode",{parentName:"h2"},"tsconfig.json")),(0,a.kt)("p",null,"I'd decided to give ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/atom-typescript"}),"Atom TypeScript plugin")," a go as I heard much enthusiastic noise about it. I fired it up and pointed it at a a TypeScript AngularJS project built in Visual Studio. I was mentally preparing myself for the job of adding all the /// references in when I suddenly noticed a file blinking at me:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(37769).Z,width:"640",height:"485"})),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json"),"? What's that? Time to read ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/atom-typescript#project-support"}),"the docs"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Supported via tsconfig.json (",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/atom-typescript/blob/master/docs/tsconfig/index.md"}),"read more"),") which is going to be the defacto Project file format for the next versions of TypeScript.")),(0,a.kt)("p",null,'"read more"? Oh yes indeedy - I think I will "read more"!'),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"A unified project format for TypeScript (",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/pull/1692"}),"see merged PR on Microsoft/TypeScript"),"). The TypeScript compiler (1.4 and above) only cares about compilerOptions and files. We add additional features to this ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/issues/1955"}),"with the typescript team's approval to extend the file as long as we don't conflict:")),(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/TypeStrong/atom-typescript/blob/e2fa67c4715189b71430f766ed9a92d9fb3255f9/lib/main/tsconfig/tsconfig.ts#L8-L35"}),"compilerOptions")," similar to what you would pass on the commandline to tsc."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/TypeStrong/atom-typescript/blob/master/docs/tsconfig/index.md#filesglob"}),"filesGlob"),": To make it easier for you to just add / remove files in your project we add filesGlob which accepts an array of glob / minimatch / RegExp patterns (similar to grunt)to specify source files."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/TypeStrong/atom-typescript/blob/master/docs/tsconfig/index.md#format"}),"format"),": Code formatting options"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/TypeStrong/atom-typescript/blob/master/docs/tsconfig/index.md#version"}),"version"),": The TypeScript version"))),(0,a.kt)("p",null,"That's right folks, we don't need ",(0,a.kt)("inlineCode",{parentName:"p"},"/// &lt;reference"),"s comments anymore. In a blinding flash of light it all changes. We're going from the dark end of the street, to the bright side of the road. ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," is here to ease away the pain and make it all better. Let's enjoy it while we can."),(0,a.kt)("p",null,"This change should ship with TypeScript 1.5 (hopefully) for those using Visual Studio. For those using Atom TypeScript (and as of today that's includes me) the carnival celebrations can begin now!"),(0,a.kt)("p",null,"Thanks to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/basarat"}),"@basarat")," who have quoted at length and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://smellegantcode.wordpress.com/"}),"Daniel Earwicker")," who is the reason that I came to discover ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json"),"."))}m.isMDXComponent=!0},44262:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"partialview-tostring",title:"PartialView.ToString()",authors:"johnnyreilly",tags:["asp.net mvc"],hide_table_of_contents:!1},s=void 0,l={permalink:"/partialview-tostring",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-03-20-partialview-tostring/index.md",source:"@site/blog/2015-03-20-partialview-tostring/index.md",title:"PartialView.ToString()",description:"In the name of DRY I found myself puzzling how one could take a PartialViewResult and render it as a string. Simple, right?",date:"2015-03-20T00:00:00.000Z",formattedDate:"March 20, 2015",tags:[{label:"asp.net mvc",permalink:"/tags/asp-net-mvc"}],readingTime:3.71,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"partialview-tostring",title:"PartialView.ToString()",authors:"johnnyreilly",tags:["asp.net mvc"],hide_table_of_contents:!1},prevItem:{title:"How to activate your emoji keyboard on Android 5.0 (Lollipop)",permalink:"/how-to-activate-your-emoji-keyboard-on-android"},nextItem:{title:"Hey tsconfig.json, where have you been all my life?",permalink:"/hey-tsconfigjson-where-have-you-been"}},p={authorsImageUrls:[void 0]},u=[{value:"What are we trying to do?",id:"what-are-we-trying-to-do",level:2},{value:"Inheritance (it&#39;s so yesterday darling)",id:"inheritance-its-so-yesterday-darling",level:2},{value:"Extension method (sexier syntax)",id:"extension-method-sexier-syntax",level:2},{value:"Favouring Composition over Inheritance (testable)",id:"favouring-composition-over-inheritance-testable",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"In the name of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Don%27t_repeat_yourself"}),"DRY")," I found myself puzzling how one could take a ",(0,a.kt)("inlineCode",{parentName:"p"},"PartialViewResult")," and render it as a ",(0,a.kt)("inlineCode",{parentName:"p"},"string"),". Simple, right?"),(0,a.kt)("p",null,"In fact, in my head this was already a solved problem. I mean I've written about this ",(0,a.kt)("a",o({parentName:"p"},{href:"/rendering-partial-view-to-string"}),"before")," already! Except I haven't. Not really - what I did back then was link to what someone else had written and say \"yay! well done chap - like he said!\". It turns out that was a bad move. That blog appears to be gone and so I'm back to where I was. Ug. Lesson learned."),(0,a.kt)("h2",o({},{id:"what-are-we-trying-to-do"}),"What are we trying to do?"),(0,a.kt)("p",null,"So, for the second time of asking, here is how to take a ",(0,a.kt)("inlineCode",{parentName:"p"},"PartialViewResult")," and turn it into a ",(0,a.kt)("inlineCode",{parentName:"p"},"string"),". It's an invaluable technique to deal with certain scenarios."),(0,a.kt)("p",null,"In my own case I have a toolbar in my application that is first pushed into the UI in my ",(0,a.kt)("inlineCode",{parentName:"p"},"_Layout.cshtml")," by means of a trusty ",(0,a.kt)("inlineCode",{parentName:"p"},'@Html.Action("Toolbar")'),". I wanted to be able to re-use the ",(0,a.kt)("inlineCode",{parentName:"p"},"PartialViewResult")," returned by ",(0,a.kt)("inlineCode",{parentName:"p"},"Toolbar")," on my controller inside a ",(0,a.kt)("inlineCode",{parentName:"p"},"JSON")," payload. And despite the title of this post, ",(0,a.kt)("inlineCode",{parentName:"p"},"PartialView.ToString()"),(0,a.kt)("em",{parentName:"p"},"doesn't")," quite cut the mustard. Obvious really, if it did then why would I be writing this and you be reading this?"),(0,a.kt)("p",null,"The solution is actually fairly simple. And, purely for swank, I'm going to offer it you 3 ways. Whatever's your poison."),(0,a.kt)("h2",o({},{id:"inheritance-its-so-yesterday-darling"}),"Inheritance (it's so yesterday darling)"),(0,a.kt)("p",null,"Yes there was a time when everything was inheritance based. You were rewarded handsomely for making sure that was the case. However, times have changed and (with good reason) people tend to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Composition_over_inheritance"}),"favour composition over inheritance"),". So, perhaps just for the memories, let first offer you the inheritance based approach:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"protected string ConvertPartialViewToString(PartialViewResult partialView)\n{\n  using (var sw = new StringWriter())\n  {\n    partialView.View = ViewEngines.Engines\n      .FindPartialView(ControllerContext, partialView.ViewName).View;\n\n    var vc = new ViewContext(\n      ControllerContext, partialView.View, partialView.ViewData, partialView.TempData, sw);\n    partialView.View.Render(vc, sw);\n\n    var partialViewString = sw.GetStringBuilder().ToString();\n\n    return partialViewString;\n  }\n}\n")),(0,a.kt)("p",null,"The idea being that the above method is placed onto a base controller which your controllers subclass. Thus using this method inside one of the controllers is as simple as:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"var toolbarHtml = ConvertPartialViewToString(partialViewResult);\n")),(0,a.kt)("h2",o({},{id:"extension-method-sexier-syntax"}),"Extension method (sexier syntax)"),(0,a.kt)("p",null,"So the next choice is implementing this as an extension method. Here's my static class which adds ",(0,a.kt)("inlineCode",{parentName:"p"},"ConvertToString")," onto ",(0,a.kt)("inlineCode",{parentName:"p"},"PartialViewResult"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using System.IO;\nusing System.Web.Mvc;\n\nnamespace My.Utilities.Extensions\n{\n  public static class PartialViewResultExtensions\n  {\n    public static string ConvertToString(this PartialViewResult partialView,\n                                              ControllerContext controllerContext)\n    {\n      using (var sw = new StringWriter())\n      {\n        partialView.View = ViewEngines.Engines\n          .FindPartialView(controllerContext, partialView.ViewName).View;\n\n        var vc = new ViewContext(\n          controllerContext, partialView.View, partialView.ViewData, partialView.TempData, sw);\n        partialView.View.Render(vc, sw);\n\n        var partialViewString = sw.GetStringBuilder().ToString();\n\n        return partialViewString;\n      }\n    }\n  }\n}\n")),(0,a.kt)("p",null,"I don't know about you but I do love an extension method - it often makes for much more readable code. In this case we can use:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"var toolbarHtml = partialViewResult.ConvertToString(ControllerContext);\n")),(0,a.kt)("p",null,"Which I think we can all agree is really rather lovely. Perhaps it would be more lovely if I didn't have to pass ",(0,a.kt)("inlineCode",{parentName:"p"},"ControllerContext")," ","-"," but hey! Still quite nice."),(0,a.kt)("h2",o({},{id:"favouring-composition-over-inheritance-testable"}),"Favouring Composition over Inheritance (testable)"),(0,a.kt)("p",null,'Although ASP.Net MVC was designed to be testable there are times when you think "really? Can it be that hard?". In fact for a well thought through discussion on the topic I advise you read ',(0,a.kt)("a",o({parentName:"p"},{href:"http://volaresystems.com/blog/post/2010/08/19/Dont-mock-HttpContext"}),"this"),". (I'm aware of the irony implicit in linking to another blog post in a blog post that I only wrote because I first linked to another blog which vanished.... Infinite recursion anybody?)"),(0,a.kt)("p",null,"The conclusion of the linked blog post is twofold"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Don't mock HTTPContext"),(0,a.kt)("li",{parentName:"ol"},"Use the ",(0,a.kt)("a",o({parentName:"li"},{href:"https://en.wikipedia.org/wiki/Facade_pattern"}),"facade pattern")," instead")),(0,a.kt)("p",null,"Having testable code is not a optional bauble in my view - it's a necessity. So with my final approach that's exactly what I'll do."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using System.Web.Mvc;\n\nnamespace My.Interfaces\n{\n  public interface IMvcInternals\n  {\n    string ConvertPartialViewToString(PartialViewResult partialView, ControllerContext controllerContext);\n  }\n}\n\n// ....\n\nusing System.IO;\nusing System.Web.Mvc;\nusing My.Interfaces;\n\nnamespace My.Utilities\n{\n  public class MvcInternals : IMvcInternals\n  {\n    public string ConvertPartialViewToString(PartialViewResult partialView,\n                                             ControllerContext controllerContext)\n    {\n      using (var sw = new StringWriter())\n      {\n        partialView.View = ViewEngines.Engines\n          .FindPartialView(controllerContext, partialView.ViewName).View;\n\n        var vc = new ViewContext(\n          controllerContext, partialView.View, partialView.ViewData, partialView.TempData, sw);\n        partialView.View.Render(vc, sw);\n\n        var partialViewString = sw.GetStringBuilder().ToString();\n\n        return partialViewString;\n      }\n    }\n  }\n}\n")),(0,a.kt)("p",null,"So here I have a simple interface with a ",(0,a.kt)("inlineCode",{parentName:"p"},"ConvertPartialViewToString")," method on it. This interface can be passed into a controller and then used like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"var toolbarHtml = _mvcInternals.ConvertPartialViewToString(partialViewResult, ControllerContext);\n")),(0,a.kt)("p",null,"Ah... that's the sweet mellifluous sound of easily testable code."))}d.isMDXComponent=!0},21673:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"how-to-activate-your-emoji-keyboard-on-android",title:"How to activate your emoji keyboard on Android 5.0 (Lollipop)",authors:"johnnyreilly",tags:["android"],hide_table_of_contents:!1},s=void 0,l={permalink:"/how-to-activate-your-emoji-keyboard-on-android",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-04-17-how-to-activate-your-emoji-keyboard-on-android/index.md",source:"@site/blog/2015-04-17-how-to-activate-your-emoji-keyboard-on-android/index.md",title:"How to activate your emoji keyboard on Android 5.0 (Lollipop)",description:"A departure from from my normal content - I need to tell you about emoji! You'll probably already know about them - just imagine a emoticon but about 300,000 times better. They really add spice to to textual content. Oh and they're Japanese - which is also way cool.",date:"2015-04-17T00:00:00.000Z",formattedDate:"April 17, 2015",tags:[{label:"android",permalink:"/tags/android"}],readingTime:.895,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"how-to-activate-your-emoji-keyboard-on-android",title:"How to activate your emoji keyboard on Android 5.0 (Lollipop)",authors:"johnnyreilly",tags:["android"],hide_table_of_contents:!1},prevItem:{title:"Tonight I'll Start an Open Source Project...",permalink:"/tonight-ill-start-open-source-project"},nextItem:{title:"PartialView.ToString()",permalink:"/partialview-tostring"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"A departure from from my normal content - I need to tell you about ",(0,a.kt)("a",o({parentName:"p"},{href:"http://en.wikipedia.org/wiki/Emoji"}),"emoji"),"! You'll probably already know about them - just imagine a emoticon but about 300,000 times better. They really add spice to to textual content. Oh and they're Japanese - which is also way cool."),(0,a.kt)("p",null,"Since I've discovered emoji I've felt a pressing need to have them on my (Android) phone. This is harder than you might imagine. But totally do-able.... Here's how you get the emoji love on your Android Lollipop phone:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"goto settings (the cog)"),(0,a.kt)("li",{parentName:"ul"},'select "Language and Input"'),(0,a.kt)("li",{parentName:"ul"},'select your "Current keyboard" and then select the "Choose keyboards" option'),(0,a.kt)("li",{parentName:"ul"},'look for a keyboard that says "iWnn IME Japanese". Select it'),(0,a.kt)("li",{parentName:"ul"},'drop back to the "Language and Input" menu where you will see "iWnn IME Japanese" is now there.'),(0,a.kt)("li",{parentName:"ul"},'select it and deactivate "Japanese" and activate "Emoji" like this:')),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"screenshot of input languages in android",src:n(27644).Z,width:"900",height:"1600"})),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"now you should find your keyboard contains a little globe icon. When you select it.... Emoji!!!!")),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of emoji keyboard",src:n(82183).Z,width:"1080",height:"1031"})))}d.isMDXComponent=!0},89101:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"tonight-ill-start-open-source-project",title:"Tonight I'll Start an Open Source Project...",authors:"johnnyreilly",tags:["asp.net mvc","validation","AngularJS"],hide_table_of_contents:!1},s=void 0,l={permalink:"/tonight-ill-start-open-source-project",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-04-24-tonight-ill-start-open-source-project/index.md",source:"@site/blog/2015-04-24-tonight-ill-start-open-source-project/index.md",title:"Tonight I'll Start an Open Source Project...",description:"Further posts on this topic",date:"2015-04-24T00:00:00.000Z",formattedDate:"April 24, 2015",tags:[{label:"asp.net mvc",permalink:"/tags/asp-net-mvc"},{label:"validation",permalink:"/tags/validation"},{label:"AngularJS",permalink:"/tags/angular-js"}],readingTime:5.075,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"tonight-ill-start-open-source-project",title:"Tonight I'll Start an Open Source Project...",authors:"johnnyreilly",tags:["asp.net mvc","validation","AngularJS"],hide_table_of_contents:!1},prevItem:{title:"A tale of Angular, html5mode, ASP.Net MVC and ASP.Net Web API",permalink:"/a-tale-of-angular-html5mode-aspnet-mvc"},nextItem:{title:"How to activate your emoji keyboard on Android 5.0 (Lollipop)",permalink:"/how-to-activate-your-emoji-keyboard-on-android"}},p={authorsImageUrls:[void 0]},u=[{value:"Further posts on this topic",id:"further-posts-on-this-topic",level:3},{value:"The Idea",id:"the-idea",level:2},{value:"The Aim",id:"the-aim",level:2},{value:"The Approach",id:"the-approach",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h3",o({},{id:"further-posts-on-this-topic"}),"Further posts on this topic"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"/ngvalidationfor-baby-steps"}),"NgValidationFor Baby Steps"))),(0,a.kt)("p",null,"I'm excited. Are you? I'm babysitting for a friend, I've my laptop, time to kill and (crucially) an idea..."),(0,a.kt)("h2",o({},{id:"the-idea"}),"The Idea"),(0,a.kt)("p",null,"You're likely aware of the various form element directives that AngularJS offers. For instance the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.angularjs.org/api/ng/directive/input"}),"input directive"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"HTML input element control. When used together with ngModel, it provides data-binding, input state control, and ",(0,a.kt)("em",{parentName:"p"},"validation"),".")),(0,a.kt)("p",null,"You'll notice that I emphasised the word \"validation\" there. That's important - that's my idea. I'm using AngularJS to build SPA's and for the server side I'm using ASP.Net MVC / Web API. Crucially, my templates are actually ASP.Net MVC Partial Views. That's key."),(0,a.kt)("p",null,"When I send data back from my SPA back to the server it gets unmarshalled / deserialized into a C# class (view model) of some kind. When data goes the other way it's flowing back from a JSON'd view model and being used by my Angular code."),(0,a.kt)("p",null,"Now historically if I was building a fairly vanilla MVC app then I'd be making use of all the ",(0,a.kt)("inlineCode",{parentName:"p"},"TextboxFor")," extension methods etc to generate my input elements. For example, with a view model like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using System.ComponentModel.DataAnnotations;\n\nnamespace App.ViewModels\n{\n public class RequiredModel\n {\n  [Required]\n  public string RequiredField{ get; set; }\n }\n}\n")),(0,a.kt)("p",null,"I'd have a view like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'@model App.ViewModels.RequiredModel @using (Html.BeginForm()) {\n<div class="row">\n  @Html.LabelFor(x => x.TextBox, "Something must be entered:")\n  @Html.TextBoxFor(x => x.TextBox, true)\n</div>\n}\n')),(0,a.kt)("p",null,"And that would generate HTML like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<form action="/Demo/Required" method="post">\n  <div class="row">\n    <label for="TextBox">Something must be entered:</label>\n    <input\n      data-msg-required="The TextBox field is required."\n      data-rule-required="true"\n      id="TextBox"\n      name="TextBox"\n      type="text"\n      value=""\n    />\n  </div>\n</form>\n')),(0,a.kt)("p",null,"If you look at the HTML you'll see that the ",(0,a.kt)("inlineCode",{parentName:"p"},"Required")," data annotations have been propogated into the HTML in the HTML in the form of ",(0,a.kt)("inlineCode",{parentName:"p"},"data-rule-*")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"data-msg-*")," attributes. The code above is built using my ",(0,a.kt)("a",o({parentName:"p"},{href:"http://johnnyreilly.github.io/jQuery.Validation.Unobtrusive.Native/"}),"jQuery.Validation.Unobtrusive.Native project")," which in turn was inspired by / based upon the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://bradwilson.typepad.com/blog/2010/10/mvc3-unobtrusive-validation.html"}),"Unobtrusive Client Validation in ASP.NET MVC"),". That's right - I've done this before - or at least something quite like it."),(0,a.kt)("p",null,"There's clearly a strong crossover between AngularJS's input directive parameters and unobtrusive client validation. I'm planning to take the principles (and maybe some of the code) that I used on that project and see if I can't make something useful with it here. ",(0,a.kt)("a",o({parentName:"p"},{href:"/angularjs-meet-aspnet-server-validation"}),"Server side validation is jolly important")," but I can probably save a few compute cycles on the server by making use of client side validation as well. If I'm right then I should able to come up with a mechanism that saves me from manually duplicating my server validation on the client."),(0,a.kt)("h2",o({},{id:"the-aim"}),"The Aim"),(0,a.kt)("p",null,"I want to be able to use HTML Helpers to propogate validation metadata from the server view models into angular form validation directive attributes. Quite a mouthful I know. What does that actually mean? Well I've got 2 ideas. Possibly I want to be able to code something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'@model App.ViewModels.RequiredModel @using (Html.BeginForm()) {\n<div class="row">\n  @Html.LabelFor(x => x.TextBox, "Something must be entered:")\n  @Html.NgTextBoxFor(x => x.TextBox)\n</div>\n}\n')),(0,a.kt)("p",null,"And have HTML like this generated:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<form action="/Demo/Required" method="post">\n  <div class="row">\n    <label for="TextBox">Something must be entered:</label>\n    <input\n      ng-required="true"\n      id="TextBox"\n      name="TextBox"\n      type="text"\n      value=""\n    />\n  </div>\n</form>\n')),(0,a.kt)("p",null,"The reservation I have about this approach is that it rather takes you away from the HTML. Yes it works (and to your seasoned MVC-er it will feel quite natural in some ways) but it feels rather heavy handed. But I'd like what I'm building to be easy for users to plug into existing code without a ton of rework. So, the other idea I'm toying with is having HTML helpers that just return a string of attributes. So if I had an angular form that looked like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<div ng-controller="ExampleController">\n  <form>\n    <div class="row">\n      <label\n        >Something must be entered:\n        <input name="RequiredField" type="text" value="" />\n      </label>\n    </div>\n  </form>\n</div>\n')),(0,a.kt)("p",null,"I could tweak it to push in the validation directive attributes like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'@model App.ViewModels.RequiredModel\n<div ng-controller="ExampleController">\n  <form>\n    <div class="row">\n      <label\n        >Something must be entered: <input name="RequiredField" type="text"\n        value="" @Html.NgValidationFor(x => x.RequiredField) />\n      </label>\n    </div>\n  </form>\n</div>\n')),(0,a.kt)("p",null,"And end up with HTML like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<div ng-controller="ExampleController">\n  <form>\n    <div class="row">\n      <label\n        >Something must be entered:\n        <input name="RequiredField" type="text" value="" ng-required="true" />\n      </label>\n    </div>\n  </form>\n</div>\n')),(0,a.kt)("p",null,"This is a simplified example of course - it's likely that any number of validation directive attributes might be returned from ",(0,a.kt)("inlineCode",{parentName:"p"},"NgValidationFor"),". And crucially if these attributes were changed on the server view model then the validation changes would automatically end up in the client HTML with this approach."),(0,a.kt)("h2",o({},{id:"the-approach"}),"The Approach"),(0,a.kt)("p",null,"At least to start off with I'm going to aim at creating the second of my approaches. I may come back and implement the first at some point but I think the second is a better place to start."),(0,a.kt)("p",null,"I'm kind of surprised no-one else has built this already actually - but I'm not aware of anything. I've had a little duckduckgo around and found no takers. The closest I've come is the excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.breezejs.com/sites/all/apidocs/classes/Validator.html"}),"BreezeJS"),". BreezeJS does way more than I want it to - I'm planning to restrict the scope of this project to simply turning data annotations on my ASP.Net MVC server models into ",(0,a.kt)("inlineCode",{parentName:"p"},"ng-*")," directive attributes in HTML. That's it."),(0,a.kt)("p",null,"So, general housekeeping.... I'm going to host this project on ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.github.com"}),"GitHub"),", I'm going to have Continuous Integration with ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.appveyor.com/"}),"AppVeyor")," and I'm planning to publish this via ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.nuget.org/"}),"NuGet")," (when and if I've created something useful)."),(0,a.kt)("p",null,"I just need a name and I'll begin. What shall I call it? Some options:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Angular ASP.Net MVC Extensions"),(0,a.kt)("li",{parentName:"ul"},"angular-aspnet-mvc-extensions"),(0,a.kt)("li",{parentName:"ul"},"Angular MVC Element Extensions"),(0,a.kt)("li",{parentName:"ul"},"Angular Validation Html Helpers"),(0,a.kt)("li",{parentName:"ul"},"NgValidationFor (the name of the HTML helper I made up)")),(0,a.kt)("p",null,"Hmmmm.... None of them is particularly lighting my fire. The first four are all a bit ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Ronseal"}),"RonSeal")," ","-"," which is fine.... Ug. The last one... It's a bit more pithy. Okay - I'll go with \"NgValidationFor\" at least for now. If something better occurs I can always change my mind."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/NgValidationFor"}),"And we're off!")))}d.isMDXComponent=!0},93282:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"a-tale-of-angular-html5mode-aspnet-mvc",title:"A tale of Angular, html5mode, ASP.Net MVC and ASP.Net Web API",authors:"johnnyreilly",tags:["asp.net","AngularJS"],hide_table_of_contents:!1},s=void 0,l={permalink:"/a-tale-of-angular-html5mode-aspnet-mvc",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-05-05-a-tale-of-angular-html5mode-aspnet-mvc/index.md",source:"@site/blog/2015-05-05-a-tale-of-angular-html5mode-aspnet-mvc/index.md",title:"A tale of Angular, html5mode, ASP.Net MVC and ASP.Net Web API",description:"So. You want to kick hash based routing to the kerb. You want real URLs. You've read the HTML5 mode section of the Angular $location docs and you're good to go. It's just a matter of dropping $locationProvider.html5Mode(true) into your app initialisation right?",date:"2015-05-05T00:00:00.000Z",formattedDate:"May 5, 2015",tags:[{label:"asp.net",permalink:"/tags/asp-net"},{label:"AngularJS",permalink:"/tags/angular-js"}],readingTime:2.95,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"a-tale-of-angular-html5mode-aspnet-mvc",title:"A tale of Angular, html5mode, ASP.Net MVC and ASP.Net Web API",authors:"johnnyreilly",tags:["asp.net","AngularJS"],hide_table_of_contents:!1},prevItem:{title:"NgValidationFor Baby Steps",permalink:"/ngvalidationfor-baby-steps"},nextItem:{title:"Tonight I'll Start an Open Source Project...",permalink:"/tonight-ill-start-open-source-project"}},p={authorsImageUrls:[void 0]},u=[{value:"ASP.Net MVC",id:"aspnet-mvc",level:2},{value:"ASP.Net Web API",id:"aspnet-web-api",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"So. You want to kick hash based routing to the kerb. You want ",(0,a.kt)("em",{parentName:"p"},"real")," URLs. You've read the HTML5 mode section of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.angularjs.org/guide/$location"}),"Angular $location docs")," and you're good to go. It's just a matter of dropping ",(0,a.kt)("inlineCode",{parentName:"p"},"$locationProvider.html5Mode(true)")," into your app initialisation right?"),(0,a.kt)("p",null,"Wrong."),(0,a.kt)("p",null,"You want your URLs to be shareable. If, when you copy the URL out of your browser and send it someone else, they do not get taken to the same position in the application as you do then I've got news for you: THAT'S NOT REALLY A URL. And just using ",(0,a.kt)("inlineCode",{parentName:"p"},"$locationProvider.html5Mode(true)")," has done nothing useful for you. You want to ensure that, if the URL entered in the browser does not relate to a specific server-side end-point, the self-same HTML root page is ",(0,a.kt)("em",{parentName:"p"},"always")," served up. Then Angular can load the correct resources for the URL you have entered and get you to the required state."),(0,a.kt)("p",null,"There are tips to be found in Angular UI's ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/angular-ui/ui-router/wiki/Frequently-Asked-Questions#how-to-configure-your-server-to-work-with-html5mode"}),"How to: Configure your server to work with html5Mode")," doc. However they required a little extra fiddling to get my ASP.Net back end working quite as I wanted. To save you pain, here are my cultural learnings."),(0,a.kt)("h2",o({},{id:"aspnet-mvc"}),"ASP.Net MVC"),(0,a.kt)("p",null,"I had an ASP.Net MVC app which I wanted to use ",(0,a.kt)("inlineCode",{parentName:"p"},"html5mode")," with. To do this is simply a matter of tweaking your ",(0,a.kt)("inlineCode",{parentName:"p"},"RouteConfig.cs")," like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public class RouteConfig\n    {\n        public static void RegisterRoutes(RouteCollection routes)\n        {\n            routes.IgnoreRoute("{resource}.axd/{*pathInfo}");\n\n            // Here go the routes that you still want to be able to hit\n            routes.MapRoute(\n                name: "IAmARouteThatYouStillWantToHit",\n                url: "ThatsWhyIAmRegisteredFirst",\n                defaults: new { controller = "Hittable", action = "Index" }\n            );\n\n            // Everything else will hit Home/Index which serves up the root angular app page\n            routes.MapRoute(\n                name: "Default",\n                url: "{*anything}", // THIS IS THE MAGIC!!!!\n                defaults: new { controller = "Home", action = "Index" }\n            );\n        }\n')),(0,a.kt)("p",null,"With this in place my existing routes work just as I would hope. Any route that doesn't fit that registered can be assumed to be ",(0,a.kt)("inlineCode",{parentName:"p"},"html5mode")," related and will serve up the root angular app page as I'd hope."),(0,a.kt)("h2",o({},{id:"aspnet-web-api"}),"ASP.Net Web API"),(0,a.kt)("p",null,'Later I realised that the app in question was mostly static content. Certainly the root angular app page was and so it seemed wasteful to require an ASP.Net MVC controller to serve up that static content. So I stripped out MVC from the app entirely, choosing to serve raw HTML instead. For the dynamic parts I switched to using Web API. This was "hittable" as long as I had my ',(0,a.kt)("inlineCode",{parentName:"p"},"WebApiConfig.cs")," and my ",(0,a.kt)("inlineCode",{parentName:"p"},"system.webServer")," section in my ",(0,a.kt)("inlineCode",{parentName:"p"},"web.config")," lined up correctly, viz:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public static class WebApiConfig\n    {\n        public static void Register(HttpConfiguration config)\n        {\n            // Web API routes\n            config.MapHttpAttributeRoutes();\n\n            config.Routes.MapHttpRoute(\n                name: "DefaultApi",\n                routeTemplate: "api/{controller}/{id}",\n                defaults: new { id = RouteParameter.Optional }\n            );\n\n            // other stuff\n        }\n    }\n')),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<configuration>\n\n    <system.webServer>\n\n        <defaultDocument>\n            <files>\n                <clear />\n                <add value="build/index.html" /> \x3c!-- This is the root document for the Angular app --\x3e\n            </files>\n        </defaultDocument>\n\n        <rewrite>\n            <rules>\n                <rule name="Main Rule" stopProcessing="true">\n                    <match url=".*" />\n                    <conditions logicalGrouping="MatchAll">\n                        \x3c!-- Allows "api/" prefixed URLs to still hit Web API controllers\n                             as defined in WebApiConfig --\x3e\n                        <add input="{REQUEST_URI}" pattern="api/" ignoreCase="true" negate="true" />\n\n                        \x3c!-- Static files and directories can be served so partials etc can be loaded --\x3e\n                        <add input="{REQUEST_FILENAME}" matchType="IsFile" negate="true" />\n                        <add input="{REQUEST_FILENAME}" matchType="IsDirectory" negate="true" />\n                    </conditions>\n                    <action type="Rewrite" url="/" />\n                </rule>\n            </rules>\n        </rewrite>\n\n    </system.webServer>\n\n</configuration>\n')),(0,a.kt)("p",null,'With this in place I can happily hit "api" prefixed URLs and still land on my Web API controllers whilst other URLs will serve up the root angular app page. Lovely.'))}d.isMDXComponent=!0},11743:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"ngvalidationfor-baby-steps",title:"NgValidationFor Baby Steps",authors:"johnnyreilly",tags:["asp.net mvc","AngularJS"],hide_table_of_contents:!1},s=void 0,l={permalink:"/ngvalidationfor-baby-steps",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-05-11-ngvalidationfor-baby-steps/index.md",source:"@site/blog/2015-05-11-ngvalidationfor-baby-steps/index.md",title:"NgValidationFor Baby Steps",description:"I thought as I start the NgValidationFor project I'd journal my progress. I'm writing this with someone particular in mind welcome!",date:"2015-05-11T00:00:00.000Z",formattedDate:"May 11, 2015",tags:[{label:"asp.net mvc",permalink:"/tags/asp-net-mvc"},{label:"AngularJS",permalink:"/tags/angular-js"}],readingTime:3.385,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"ngvalidationfor-baby-steps",title:"NgValidationFor Baby Steps",authors:"johnnyreilly",tags:["asp.net mvc","AngularJS"],hide_table_of_contents:!1},prevItem:{title:"Angular UI Bootstrap Datepicker Weirdness",permalink:"/angular-ui-bootstrap-datepicker-weirdness"},nextItem:{title:"A tale of Angular, html5mode, ASP.Net MVC and ASP.Net Web API",permalink:"/a-tale-of-angular-html5mode-aspnet-mvc"}},p={authorsImageUrls:[void 0]},u=[{value:"Getting up and running",id:"getting-up-and-running",level:2},{value:"So what have we got?",id:"so-what-have-we-got",level:2},{value:"So what now?",id:"so-what-now",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I thought as I start the ",(0,a.kt)("a",o({parentName:"p"},{href:"/tonight-ill-start-open-source-project"}),"NgValidationFor project")," I'd journal my progress. I'm writing this with someone particular in mind: me. Specifically, me in 2 years who will no doubt wonder why I made some of the choices I did. Everyone else, move along now - nothing to see. Unless the inner workings of someone else's mind are interesting to you... In which case: welcome!"),(0,a.kt)("h2",o({},{id:"getting-up-and-running"}),"Getting up and running"),(0,a.kt)("p",null,"I've got a project on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/NgValidationFor"}),"GitHub")," and I'm starting to think about implementations. One thing that bit me on ",(0,a.kt)("a",o({parentName:"p"},{href:"http://johnnyreilly.github.io/jQuery.Validation.Unobtrusive.Native/"}),"jVUN")," was being tied to a specific version of ASP.Net MVC. For each major release of ASP.Net MVC I needed separate builds / NuGet packages and the like. A pain. Particularly when it came to bug fixes for prior versions - the breaking changes with each version of MVC meant far more work was required when it came to shipping fixes for MVC 4 / MVC 3."),(0,a.kt)("p",null,"So with that in mind I'm going to try and limit my dependencies. I'm not saying I will never depend upon ASP.Net MVC - I may if I think it becomes useful to give the users a nicer API or if there's another compelling reason. But to start with I'm just going to focus on the translation of data annotations to Angular validation directive attributes."),(0,a.kt)("p",null,"To that end I'm going to begin with just a class library and an associated test project. I'm going to try and minimise the dependencies that NgValidationFor has. At least initially I may even see if I can sensibly avoid depending on ",(0,a.kt)("inlineCode",{parentName:"p"},"System.Web")," (mindful of the upcoming ASP.Net 5 changes). Let's see."),(0,a.kt)("p",null,"A little time passes......."),(0,a.kt)("h2",o({},{id:"so-what-have-we-got"}),"So what have we got?"),(0,a.kt)("p",null,"My first efforts have resulted in the implementation of the ",(0,a.kt)("inlineCode",{parentName:"p"},'<a href="https://msdn.microsoft.com/en-us/library/system.componentmodel.dataannotations.requiredattribute(v=vs.110).aspx">RequiredAttribute</a>'),". This is the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/NgValidationFor/tree/6cf862a7638d3ed933cd0e075a1807b1414847da"}),"code right now"),". It's made up of:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"NgValidationFor.Core - the core part of the project which converts data annotations into AngularJS 1.x validation directive attributes."),(0,a.kt)("li",{parentName:"ol"},"NgValidationFor.Core.UnitTests - the unit tests for the core"),(0,a.kt)("li",{parentName:"ol"},"NgValidationFor.Documentation - this is an ASP.Net MVC project which will become a documentation site for NgValidationFor. It also doubles as a way for me to try out NgValidationFor."),(0,a.kt)("li",{parentName:"ol"},"NgValidationFor.Documentation.UnitTests - unit tests for the documentation (there's none yet as I'm still spiking - but when I'm a little clearer, they will be)")),(0,a.kt)("p",null,"How can it be used? Well fairly easily. Take this simple model:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using System.ComponentModel.DataAnnotations;\n\nnamespace NgValidationFor.Documentation.Models\n{\n    public class RequiredDemoModel\n    {\n        [Required]\n        public string RequiredField { get; set; }\n    }\n}\n")),(0,a.kt)("p",null,"When used in an MVC View for which ",(0,a.kt)("inlineCode",{parentName:"p"},"RequiredDemoModel")," is the Model, NgValiditionFor can be used thusly:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'@using NgValidationFor.Core @using NgValidationFor.Documentation.Models @model\nRequiredDemoModel <input type="text" name="userName" ng-model="user.name"\n@Html.Raw(Model.GetAttributes(x => Model.RequiredField)) >\n')),(0,a.kt)("p",null,"Which results in this HTML:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<input type="text" name="userName" ng-model="user.name" required="required" />\n')),(0,a.kt)("p",null,"Tada!!!! It works."),(0,a.kt)("h2",o({},{id:"so-what-now"}),"So what now?"),(0,a.kt)("p",null,"Yes it works, but I'm not going to pretend it's pretty. I don't like having to wrap the usage of NgValidationFor with ",(0,a.kt)("inlineCode",{parentName:"p"},"Html.Raw(...)"),". I'm having to do that because ",(0,a.kt)("inlineCode",{parentName:"p"},"GetAttributes")," returns a ",(0,a.kt)("inlineCode",{parentName:"p"},"string"),". This string is then HTML encoded by MVC. To avoid my quotation marks turning into ",(0,a.kt)("inlineCode",{parentName:"p"},"&amp;quot;")," I need to actually be exposing an ",(0,a.kt)("inlineCode",{parentName:"p"},'<a href="https://msdn.microsoft.com/en-us/library/system.web.ihtmlstring(v=vs.110).aspx">IHtmlString</a>'),". So I'm going to need to depend upon ",(0,a.kt)("inlineCode",{parentName:"p"},"System.Web"),". That's not so bad - at least I'm not tied to a specific MVC version."),(0,a.kt)("p",null,"I'm not too keen on the implementation I've come up with for NgValidationFor either. It's a single static method at the minute which does everything. It breaks the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Single_responsibility_principle"}),"Single Responsibility Priniciple")," and the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Open/closed_principle"}),"Open/Closed Principle"),". I need to take a look at that - I want people to be able to extend this and I need to think about a good and simple way to achieve that."),(0,a.kt)("p",null,"Finally, usage. ",(0,a.kt)("inlineCode",{parentName:"p"},"Model.GetAttributes(x =&gt; Model.RequiredField)")," feels wrong to me. I think I'm happy with having this used as an extension method but it needs to be clearer what's happening. Perhaps ",(0,a.kt)("inlineCode",{parentName:"p"},"Model.NgValidationFor(x =&gt; Model.RequiredField)")," would be better. I need to try a few things out and come up with a nicer way to use NgValidationFor."))}d.isMDXComponent=!0},97079:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"angular-ui-bootstrap-datepicker-weirdness",title:"Angular UI Bootstrap Datepicker Weirdness",authors:"johnnyreilly",tags:["Bootstrap","AngularJS"],hide_table_of_contents:!1},s=void 0,l={permalink:"/angular-ui-bootstrap-datepicker-weirdness",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-05-23-angular-ui-bootstrap-datepicker-weirdness/index.md",source:"@site/blog/2015-05-23-angular-ui-bootstrap-datepicker-weirdness/index.md",title:"Angular UI Bootstrap Datepicker Weirdness",description:"The Angular UI Bootstrap Datepicker is fan-dabby-dozy. But it has a ... pecularity. You can use the picker like this:",date:"2015-05-23T00:00:00.000Z",formattedDate:"May 23, 2015",tags:[{label:"Bootstrap",permalink:"/tags/bootstrap"},{label:"AngularJS",permalink:"/tags/angular-js"}],readingTime:2.485,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"angular-ui-bootstrap-datepicker-weirdness",title:"Angular UI Bootstrap Datepicker Weirdness",authors:"johnnyreilly",tags:["Bootstrap","AngularJS"],hide_table_of_contents:!1},prevItem:{title:"Back to the Future with Code First Migrations",permalink:"/Back-to-the-Future-with-Code-First-Migrations"},nextItem:{title:"NgValidationFor Baby Steps",permalink:"/ngvalidationfor-baby-steps"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://angular-ui.github.io/bootstrap/#/datepicker"}),"Angular UI Bootstrap Datepicker")," is fan-dabby-dozy. But it has a ... pecularity. You can use the picker like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<div ng-app="peskyDatepicker">\n  <div ng-controller="DatepickerDemoCtrl as vm">\n    <input\n      type="text"\n      class="form-control"\n      datepicker-popup="mediumDate"\n      is-open="vm.valuationDatePickerIsOpen"\n      ng-click="vm.valuationDatePickerOpen()"\n      ng-model="vm.valuationDate"\n    />\n  </div>\n</div>\n')),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"angular\n  .module('peskyDatepicker', ['ui.bootstrap'])\n  .controller('DatepickerDemoCtrl', [\n    function () {\n      var vm = this;\n\n      vm.valuationDate = new Date();\n      vm.valuationDatePickerIsOpen = false;\n\n      vm.valuationDatePickerOpen = function () {\n        this.valuationDatePickerIsOpen = true;\n      };\n    },\n  ]);\n")),(0,a.kt)("p",null,"The above code produces a textbox which, when clicked upon, renders the datepicker popup (which vanishes upon date selection). This works because the ",(0,a.kt)("inlineCode",{parentName:"p"},"ng-click")," directive calls the ",(0,a.kt)("inlineCode",{parentName:"p"},"valuationDatePickerOpen")," function on the controller which sets the ",(0,a.kt)("inlineCode",{parentName:"p"},"valuationDatePickerIsOpen")," property to be ",(0,a.kt)("inlineCode",{parentName:"p"},"true")," and that property happens to be bound to the ",(0,a.kt)("inlineCode",{parentName:"p"},"is-open")," attribute. Your knee bone connected to your thigh bone, Your thigh bone connected to your hip bone... This makes sense. This works. Great."),(0,a.kt)("p",null,"But I want something a little prettier - I want to use the lovely calendar glyph to trigger the datepicker popup like in the docs. That should be really easy right? I just tweak the HTML to add a calendar button and the associated ",(0,a.kt)("inlineCode",{parentName:"p"},'ng-click="vm.valuationDatePickerOpen()"'),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<div ng-app="peskyDatepicker">\n  <div ng-controller="DatepickerDemoCtrl as vm">\n    <p class="input-group">\n      <input\n        type="text"\n        class="form-control"\n        datepicker-popup="mediumDate"\n        is-open="vm.valuationDatePickerIsOpen"\n        ng-click="vm.valuationDatePickerOpen()"\n        ng-model="vm.valuationDate"\n      />\n      <span class="input-group-btn">\n        <button\n          type="button"\n          class="btn btn-default"\n          ng-click="vm.valuationDatePickerOpen()"\n        >\n          <i class="glyphicon glyphicon-calendar"></i>\n        </button>\n      </span>\n    </p>\n  </div>\n</div>\n')),(0,a.kt)("p",null,"Miraculously, this ",(0,a.kt)("em",{parentName:"p"},"doesn't")," work. Which is strange - I mean it ought to... The same ",(0,a.kt)("inlineCode",{parentName:"p"},"ng-click")," directive is sat on our new calendar button as is in place on the datepicker itself. So what's happening? Well let's do some investigation. If you take a look at the docs you'll see that their example with the calendar glyph is subtly different to our own. Namely, when the opener function is invoked, the official docs pass along ",(0,a.kt)("inlineCode",{parentName:"p"},"$event"),". To what end? Well, the docs opener function does something that our own does not. This:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"$scope.open = function ($event) {\n  $event.preventDefault();\n  $event.stopPropagation();\n\n  $scope.opened = true;\n};\n")),(0,a.kt)("p",null,"Ignore all the ",(0,a.kt)("inlineCode",{parentName:"p"},"$scope")," malarkey - I want you to pay attention to what is happening with ",(0,a.kt)("inlineCode",{parentName:"p"},"$event"),". ",(0,a.kt)("inlineCode",{parentName:"p"},"preventDefault")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"stopPropogation")," are being called. This is probably relevant."),(0,a.kt)("p",null,"I decided to do a little experimentation. I created a Plunk which demonstrates the datepicker and uses ",(0,a.kt)("inlineCode",{parentName:"p"},"$watch")," to track what happens to ",(0,a.kt)("inlineCode",{parentName:"p"},"valuationDatePickerIsOpen"),". The Plunk featured 2 calendar glyphs - the left one doesn't pass along ",(0,a.kt)("inlineCode",{parentName:"p"},"$event")," to ",(0,a.kt)("inlineCode",{parentName:"p"},"valuationDatePickerOpen")," when it is clicked and the right one does. When ",(0,a.kt)("inlineCode",{parentName:"p"},"$event")," is passed we call ",(0,a.kt)("inlineCode",{parentName:"p"},"preventDefault")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"stopPropogation"),"."),(0,a.kt)("iframe",{src:"https://embed.plnkr.co/dJyF531w0QRGiAScRf15/preview",width:"100%",height:"450"}),(0,a.kt)("p",null,"After a little experimentation of my own I discovered that calling ",(0,a.kt)("inlineCode",{parentName:"p"},"$event.stopPropogation()")," is the magic bullet. Without that in place ",(0,a.kt)("inlineCode",{parentName:"p"},"valuationDatePickerIsOpen")," gets set to ",(0,a.kt)("inlineCode",{parentName:"p"},"true")," and then immediately back to ",(0,a.kt)("inlineCode",{parentName:"p"},"false")," again. I do not know why. There may be an entirely sane reason for this - if so then please do post a comment and let me know. It wouldn't hurt for the Angular UI Bootstrap Datepicker docs to mention this. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/angular-ui/bootstrap/issues/3705"}),"Perhaps it's time to submit a PR....")))}d.isMDXComponent=!0},22832:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"Back-to-the-Future-with-Code-First-Migrations",title:"Back to the Future with Code First Migrations",authors:"johnnyreilly",tags:["Entity Framework"],hide_table_of_contents:!1},s=void 0,l={permalink:"/Back-to-the-Future-with-Code-First-Migrations",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-06-19-Back-to-the-Future-with-Code-First-Migrations/index.md",source:"@site/blog/2015-06-19-Back-to-the-Future-with-Code-First-Migrations/index.md",title:"Back to the Future with Code First Migrations",description:"Code First Migrations. They look a little like this in Visual Studio:",date:"2015-06-19T00:00:00.000Z",formattedDate:"June 19, 2015",tags:[{label:"Entity Framework",permalink:"/tags/entity-framework"}],readingTime:2.26,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"Back-to-the-Future-with-Code-First-Migrations",title:"Back to the Future with Code First Migrations",authors:"johnnyreilly",tags:["Entity Framework"],hide_table_of_contents:!1},prevItem:{title:"npm please stop hurting Visual Studio",permalink:"/npm-please-stop-hurting-visual-studio"},nextItem:{title:"Angular UI Bootstrap Datepicker Weirdness",permalink:"/angular-ui-bootstrap-datepicker-weirdness"}},p={authorsImageUrls:[void 0]},u=[{value:"Great Scott! It&#39;s clearly filename driven",id:"great-scott-its-clearly-filename-driven",level:2},{value:"Whoa, this is heavy! Gimme the project file",id:"whoa-this-is-heavy-gimme-the-project-file",level:2},{value:"Designer.cs... Your kids are gonna love it",id:"designercs-your-kids-are-gonna-love-it",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Code First Migrations. They look a little like this in Visual Studio:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(69682).Z,width:"333",height:"221"})),(0,a.kt)("p",null,"The thing I want you to notice about the image above is not the pithily named migrations. It isn't the natty opacity on everything but the migration files (which I can assure you took me to the very limits of my ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.gimp.org/"}),"GIMP")," expertise). No, whilst exciting in themselves what I want you to think about is ",(0,a.kt)("em",{parentName:"p"},"the order in which migrations are applied"),". Essentially how the ",(0,a.kt)("inlineCode",{parentName:"p"},"__MigrationHistory")," table in SQL Server ends up being populated in this manner:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(62879).Z,width:"640",height:"207"})),(0,a.kt)("p",null,"Because, myself, I didn't really think about this until it came time for me to try and change the ordering of some migrations manually. Do you know how migrations end up the order they do? I bet you don't. But either way, let's watch and see what happens to the pre-enlightenment me as I attempt to take a migration which appears ",(0,a.kt)("em",{parentName:"p"},"before")," a migration I have created locally and move it to ",(0,a.kt)("em",{parentName:"p"},"after")," that same migration."),(0,a.kt)("h2",o({},{id:"great-scott-its-clearly-filename-driven"}),"Great Scott! It's clearly filename driven"),(0,a.kt)("p",null,"That's right - it's blindingly obvious to me. All I need do is take the migration I want to move forwards in time and rename it in Visual Studio. So take our old migration (\"2014 is so pass\xe9 darling\"):"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(35300).Z,width:"302",height:"115"})),(0,a.kt)("p",null,'And rename it to make it new and shiny ("2015! Gorgeous - I love it sweetie!"):'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(38526).Z,width:"359",height:"170"})),(0,a.kt)("p",null,"Perfection right? Wrong! What you've done makes not the slightest jot of difference."),(0,a.kt)("h2",o({},{id:"whoa-this-is-heavy-gimme-the-project-file"}),"Whoa, this is heavy! Gimme the project file"),(0,a.kt)("p",null,"How could I be so dim? I mean it makes perfect sense - before the days of ",(0,a.kt)("a",o({parentName:"p"},{href:"/hey-tsconfigjson-where-have-you-been"}),"TypeScript's ",(0,a.kt)("inlineCode",{parentName:"a"},"tsconfig.json"))," the default ordering of ",(0,a.kt)("inlineCode",{parentName:"p"},"*.ts")," files being passed to the TypeScript compiler was determined by the ordering of the ",(0,a.kt)("inlineCode",{parentName:"p"},"*.ts")," files in the ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj")," file. It must be the same for Code First Migrations."),(0,a.kt)("p",null,"So, simply spin up ",(0,a.kt)("a",o({parentName:"p"},{href:"https://notepad-plus-plus.org/"}),"Notepad++")," and let's play hack the XML until each file is referenced in the required order."),(0,a.kt)("p",null,"Well, I'm glad we sorted that out. A quick test to reassure myself of my astuteness. Drum roll.... Fail!! Things are just as they were. Shame on you John Reilly, shame on you."),(0,a.kt)("h2",o({},{id:"designercs-your-kids-are-gonna-love-it"}),"Designer.cs... Your kids are gonna love it"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(22780).Z,width:"640",height:"398"})),(0,a.kt)("p",null,"I want you to look very carefully at this and tell me what you see. We're looking at the mysterious ",(0,a.kt)("inlineCode",{parentName:"p"},"201508121401253_AddSagacityToSage.Designer.cs")," file that sits underneath the main ",(0,a.kt)("inlineCode",{parentName:"p"},"201508121401253_AddSagacityToSage.cs")," file. What could it be.... Give in?"),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"IMigrationMetadata.Id")," property is returning ",(0,a.kt)("inlineCode",{parentName:"p"},"<u>201408121401253</u>_AddSagacityToSage"),". That is the ",(0,a.kt)("em",{parentName:"p"},"old")," date! Remember? The pass\xe9 one. If you change that property to line up with the file name change you're done. It works."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(66102).Z,width:"1368",height:"764"})),(0,a.kt)("p",null,"Let's say it together: \"Automatic Migrations? Where we're going, we don't need Automatic Migrations.\""))}d.isMDXComponent=!0},64715:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"npm-please-stop-hurting-visual-studio",title:"npm please stop hurting Visual Studio",authors:"johnnyreilly",tags:["npm","Windows"],hide_table_of_contents:!1},s=void 0,l={permalink:"/npm-please-stop-hurting-visual-studio",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-06-29-npm-please-stop-hurting-visual-studio/index.md",source:"@site/blog/2015-06-29-npm-please-stop-hurting-visual-studio/index.md",title:"npm please stop hurting Visual Studio",description:"I don't know about you but I personally feel that the following sentence may well be the saddest in the English language:",date:"2015-06-29T00:00:00.000Z",formattedDate:"June 29, 2015",tags:[{label:"npm",permalink:"/tags/npm"},{label:"Windows",permalink:"/tags/windows"}],readingTime:4.49,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"npm-please-stop-hurting-visual-studio",title:"npm please stop hurting Visual Studio",authors:"johnnyreilly",tags:["npm","Windows"],hide_table_of_contents:!1},prevItem:{title:"Upgrading to Globalize 1.x for Dummies",permalink:"/upgrading-to-globalize-1x-for-dummies"},nextItem:{title:"Back to the Future with Code First Migrations",permalink:"/Back-to-the-Future-with-Code-First-Migrations"}},p={authorsImageUrls:[void 0]},u=[{value:"The Latest Infraction",id:"the-latest-infraction",level:2},{value:"rimraf to the Rescue",id:"rimraf-to-the-rescue",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I don't know about you but I personally feel that the following sentence may well be the saddest in the English language:"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"2&gt;ASPNETCOMPILER : error ASPRUNTIME: The specified path, file name, or both are too long. The fully qualified file name must be less than 260 characters, and the directory name must be less than 248 characters.")),(0,a.kt)("p",null,"The message above would suggest there is some kind of ASP.Net issue going on. There isn't - the problem actually lies with Windows. It's ",(0,a.kt)("a",o({parentName:"p"},{href:"/gulp-npm-long-paths-and-visual-studio-fight"}),"not the first time it's come up")," but for those of you not aware there is something you need to know about Windows: ",(0,a.kt)("em",{parentName:"p"},"It handles long paths badly.")),(0,a.kt)("p",null,"There's a number of caveats which people may attach the above sentence. But essentially what I have said is true. And it becomes brutally apparent to you the moment you start using a few node / npm powered tools in your workflow. You will likely see that horrible message and you won't be able to get much further forward. Sigh. I thought this was the future..."),(0,a.kt)("p",null,"This post is about how to deal with the long path issue when using npm with Visual Studio. This should very much be a short term workaround as ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/npm/npm/releases/tag/v3.0.0"}),"npm 3.0")," is planned to make long paths with npm a thing of the past. But until that golden dawn...."),(0,a.kt)("h2",o({},{id:"the-latest-infraction"}),"The Latest Infraction"),(0,a.kt)("p",null,"I'm a big fan of Gulp and Bower. They rock. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/codecadwallader"}),"Steve Cadwallader")," wrote an excellent blog post about ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.codecadwallader.com/2015/03/15/integrating-gulp-into-your-tfs-builds-and-web-deploy/"}),"integrating Gulp into your Visual Studio build"),". Essentially the Gist of his post is this: forget using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://visualstudiogallery.msdn.microsoft.com/8e1b4368-4afb-467a-bc13-9650572db708"}),"Task Runner Explorer")," to trigger your Gulp / Grunt jobs. No, actually plug it into the build process by tweaking your ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj")," file. The first time I used this approach it was a dream come true. It just worked and I was a very happy man."),(0,a.kt)("p",null,"Since this approach was so marvellous I took a look at the demo / docs part of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/jQuery.Validation.Unobtrusive.Native"}),"jQuery Validation Unobtrusive Native")," with a view to applying it there. I originally wrote this back in 2013 and at the time used NuGet for both server and client side package management. I decided to migrate it to use Bower for the client side packages (which I planned to combine with a Gulp script which was going to pull out the required JS / CSS etc as needed). However it wasn't the plain sailing I'd imagined. The actual switchover from NuGet to Bower was simple. Just a case of removing NuGet packages and adding their associated Bower counterpart. The problem came when the migration was done and I hit \"compile\". That's when I got to see ",(0,a.kt)("inlineCode",{parentName:"p"},"2&gt;ASPNETCOMPILER : error ASPRUNTIME: The specified path, file name, or both are too long...")," etc"),(0,a.kt)("p",null,"For reasons that I don't fully understand, Visual Studio is really upset by the presence in the project structure of one almighty long path. Oddly enough, not a path that's actually part of the Visual Studio project in question at all. Rather one that has come along as a result of our Gulp / Bower / npm shenanigans. Quick as a flash, I whipped out Daniel Schroeder's ",(0,a.kt)("a",o({parentName:"p"},{href:"https://pathlengthchecker.codeplex.com/"}),"Path Length Checker")," to see where the problem lay:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(79304).Z,width:"640",height:"497"})),(0,a.kt)("p",null,"And lo, the fault lay with Bower. Poor show, Bower, poor show."),(0,a.kt)("h2",o({},{id:"rimraf-to-the-rescue"}),"rimraf to the Rescue"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/isaacs/rimraf"}),"rimraf"),' is "the ',(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Rm_(Unix)"}),"UNIX command"),(0,a.kt)("inlineCode",{parentName:"p"},"rm -rf"),' for node". (By the way, what is it with node and the pathological hatred of capital letters?)'),(0,a.kt)("p",null,"What this means is: rimraf can delete. Properly. So let's get it: ",(0,a.kt)("inlineCode",{parentName:"p"},"npm install -g rimraf"),". Then at any time at the command line we can dispose of a long path in 2 shakes of lamb's tail."),(0,a.kt)("p",null,"In my current situation the contents of the ",(0,a.kt)("inlineCode",{parentName:"p"},"node_modules")," folder is causing me heartache. But with rimraf in play I can get rid of it with the magic words: ",(0,a.kt)("inlineCode",{parentName:"p"},"rimraf ./node_modules"),". Alakazam! So let's poke this command into the extra commands that I've already shoplifted from Steve's blog post. I'll end up with the following section of XML at the end of my ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<PropertyGroup>\n    <CompileDependsOn>\n      $(CompileDependsOn);\n      GulpBuild;\n    </CompileDependsOn>\n    <CleanDependsOn>\n      $(CleanDependsOn);\n      GulpClean\n    </CleanDependsOn>\n    <CopyAllFilesToSingleFolderForPackageDependsOn>\n      CollectGulpOutput;\n      $(CopyAllFilesToSingleFolderForPackageDependsOn);\n    </CopyAllFilesToSingleFolderForPackageDependsOn>\n    <CopyAllFilesToSingleFolderForMsdeployDependsOn>\n      CollectGulpOutput;\n      $(CopyAllFilesToSingleFolderForPackageDependsOn);\n    </CopyAllFilesToSingleFolderForMsdeployDependsOn>\n  </PropertyGroup>\n  <Target Name="GulpBuild">\n    <Exec Command="npm install" />\n    <Exec Command="bower install" />\n    <Exec Command="gulp" />\n    <Exec Command="rimraf ./node_modules" />\n  </Target>\n  <Target Name="GulpClean">\n    <Exec Command="npm install" />\n    <Exec Command="gulp clean" />\n    <Exec Command="rimraf ./node_modules" />\n  </Target>\n  <Target Name="CollectGulpOutput">\n    <ItemGroup>\n      <_CustomFiles Include="build\\**\\*" />\n      <FilesForPackagingFromProject Include="%(_CustomFiles.Identity)">\n        <DestinationRelativePath>build\\%(RecursiveDir)%(Filename)%(Extension)</DestinationRelativePath>\n      </FilesForPackagingFromProject>\n    </ItemGroup>\n    <Message Text="CollectGulpOutput list: %(_CustomFiles.Identity)" />\n  </Target>\n')),(0,a.kt)("p",null,"So let's focus on the important bits in the ",(0,a.kt)("inlineCode",{parentName:"p"},"GulpBuild")," target:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},'&lt;Exec Command="npm install" /&gt;')," ","-"," install the node packages our project uses as specified in ",(0,a.kt)("inlineCode",{parentName:"li"},"package.json"),". This will include Gulp and Bower. The latter package is going to contain super-long, Windows wrecking paths."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},'&lt;Exec Command="bower install" /&gt;')," ","-"," install the bower packages specified in ",(0,a.kt)("inlineCode",{parentName:"li"},"bower.json")," using Bower (which was installed by npm just now)."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},'&lt;Exec Command="gulp" /&gt;')," ","-"," do a little dance, make a little love, copy a few files, get down tonight."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},'&lt;Exec Command="rimraf ./node_modules" /&gt;')," ","-"," remove the ",(0,a.kt)("inlineCode",{parentName:"li"},"node_modules")," folder populated by the ",(0,a.kt)("inlineCode",{parentName:"li"},"npm install")," command.")),(0,a.kt)("p",null,"With that addition of ",(0,a.kt)("inlineCode",{parentName:"p"},"rimraf ./node_modules")," to the build phase the problem goes away. During each build a big, big Windows path is being constructed but then it's wiped again before it has chance to upset anyone. I've also added the same to the ",(0,a.kt)("inlineCode",{parentName:"p"},"GulpClean")," target."),(0,a.kt)("p",null,"You are very welcome."))}d.isMDXComponent=!0},68428:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"upgrading-to-globalize-1x-for-dummies",title:"Upgrading to Globalize 1.x for Dummies",authors:"johnnyreilly",tags:["Globalize"],hide_table_of_contents:!1},s=void 0,l={permalink:"/upgrading-to-globalize-1x-for-dummies",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-07-30-upgrading-to-globalize-1x-for-dummies/index.md",source:"@site/blog/2015-07-30-upgrading-to-globalize-1x-for-dummies/index.md",title:"Upgrading to Globalize 1.x for Dummies",description:"Globalize has hit 1.0. Anyone who reads my blog will likely be aware that I'm a long time user of Globalize 0.1.x. I've been a little daunted by the leap that the move from 0.1.x to 1.x represents. It appears to be the very definition of \"breaking changes\". :-) But hey, this is Semantic Versioning being used correctly so how could I complain? Either way, I've decided to write up the migration here as I'm not expecting this to be easy.",date:"2015-07-30T00:00:00.000Z",formattedDate:"July 30, 2015",tags:[{label:"Globalize",permalink:"/tags/globalize"}],readingTime:9.415,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"upgrading-to-globalize-1x-for-dummies",title:"Upgrading to Globalize 1.x for Dummies",authors:"johnnyreilly",tags:["Globalize"],hide_table_of_contents:!1},prevItem:{title:"(Top One, Nice One) Get Sorted",permalink:"/top-one-nice-one-get-sorted"},nextItem:{title:"npm please stop hurting Visual Studio",permalink:"/npm-please-stop-hurting-visual-studio"}},p={authorsImageUrls:[void 0]},u=[{value:"Updated our Bower dependencies",id:"updated-our-bower-dependencies",level:2},{value:"We need fuel",id:"we-need-fuel",level:2},{value:"Some bitching and moaning.",id:"some-bitching-and-moaning",level:2},{value:"Take the modules and run",id:"take-the-modules-and-run",level:2},{value:"Updated 30/08/2015: Globalize \xb7 So What&#39;cha Want",id:"updated-30082015-globalize--so-whatcha-want",level:3},{value:"The Actual Migration",id:"the-actual-migration",level:2},{value:"Observations",id:"observations",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Globalize has hit 1.0. Anyone who reads my blog will likely be aware that I'm a long time user of ",(0,a.kt)("a",o({parentName:"p"},{href:"/globalizejs-number-and-date"}),"Globalize 0.1.x"),". I've been a little daunted by the leap that the move from 0.1.x to 1.x represents. It appears to be the very definition of \"breaking changes\". :-) But hey, this is Semantic Versioning being used correctly so how could I complain? Either way, I've decided to write up the migration here as I'm not expecting this to be easy."),(0,a.kt)("p",null,"To kick things off I've set up a very ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/globalize-migration/tree/v0.1.x"}),"simple repo")," that consists of a single page that depends upon Globalize 0.1.x to render a number and a date in German. It looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<html>\n  <head>\n    <title>Globalize demo</title>\n    <link\n      href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css"\n      rel="stylesheet"\n    />\n  </head>\n  <body>\n    <div class="container-fluid">\n      <h4>Globalize demo for the <em id="locale"></em> culture / locale</h4>\n      <p>\n        This is a the number <strong id="number"></strong> formatted by\n        Globalize: <strong id="numberFormatted"></strong>\n      </p>\n      <p>\n        This is a the number <strong id="date"></strong> formatted by Globalize:\n        <strong id="dateFormatted"></strong>\n      </p>\n    </div>\n\n    <script src="bower_components/globalize/lib/globalize.js"><\/script>\n    <script src="bower_components/globalize/lib/cultures/globalize.culture.de-DE.js"><\/script>\n    <script>\n      var locale = \'de-DE\';\n      var number = 12345.67;\n      var date = new Date(2012, 5, 15);\n\n      Globalize.culture(locale);\n      document.querySelector(\'#locale\').innerText = locale;\n      document.querySelector(\'#number\').innerText = number;\n      document.querySelector(\'#date\').innerText = date;\n      document.querySelector(\'#numberFormatted\').innerText = Globalize.format(\n        number,\n        \'n2\'\n      );\n      document.querySelector(\'#dateFormatted\').innerText = Globalize.format(\n        date,\n        \'d\'\n      );\n    <\/script>\n  </body>\n</html>\n')),(0,a.kt)("p",null,"When it's run it looks like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(26740).Z,width:"640",height:"162"})),(0,a.kt)("p",null,"Let's see how we go about migrating this super simple example."),(0,a.kt)("h2",o({},{id:"updated-our-bower-dependencies"}),"Updated our Bower dependencies"),(0,a.kt)("p",null,"First things first, we want to move Globalize from 0.1.x to 1.x using Bower. To do that we update our ",(0,a.kt)("inlineCode",{parentName:"p"},"bower.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),'"dependencies": {\n    "globalize": "^1.0.0"\n  }\n')),(0,a.kt)("p",null,"Now we enter: ",(0,a.kt)("inlineCode",{parentName:"p"},"bower update"),". And we're off!"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-sh"}),"bower globalize#^1.0.0          cached git://github.com/jquery/globalize.git#1.0.0\nbower globalize#^1.0.0        validate 1.0.0 against git://github.com/jquery/globalize.git#^1.0.0\nbower cldr-data#>=25            cached git://github.com/rxaviers/cldr-data-bower.git#27.0.3\nbower cldr-data#>=25          validate 27.0.3 against git://github.com/rxaviers/cldr-data-bower.git#>=25\nbower cldrjs#0.4.1              cached git://github.com/rxaviers/cldrjs.git#0.4.1\nbower cldrjs#0.4.1            validate 0.4.1 against git://github.com/rxaviers/cldrjs.git#0.4.1\nbower globalize#^1.0.0         install globalize#1.0.0\nbower cldr-data#>=25           install cldr-data#27.0.3\nbower cldrjs#0.4.1             install cldrjs#0.4.1\n\nglobalize#1.0.0 bower_components\\globalize\n\u251c\u2500\u2500 cldr-data#27.0.3\n\u2514\u2500\u2500 cldrjs#0.4.1\n\ncldr-data#27.0.3 bower_components\\cldr-data\n\ncldrjs#0.4.1 bower_components\\cldrjs\n\u2514\u2500\u2500 cldr-data#27.0.3\n")),(0,a.kt)("p",null,"This all looks happy enough. Except it's actually not."),(0,a.kt)("h2",o({},{id:"we-need-fuel"}),"We need fuel"),(0,a.kt)("p",null,'Or as I like to call it cldr-data. We just pulled down Globalize 1.x but we didn\'t pull down the data that Globalize 1.x relies upon. This is one of the differences between Globalize 0.1.x and 1.x. Globalize 1.x does not include the "culture" data. By which I mean all the ',(0,a.kt)("inlineCode",{parentName:"p"},"globalize.culture.de-DE.js")," type files. Instead Globalize 1.x relies upon ",(0,a.kt)("a",o({parentName:"p"},{href:"http://cldr.unicode.org/"}),"CLDR - Unicode Common Locale Data Repository"),". It does this in the form of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/unicode-cldr/cldr-json"}),"cldr-json"),"."),(0,a.kt)("p",null,"Now before you start to worry, you shouldn't actually need to go and get this by yourself, the lovely ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/rxaviers"}),"Rafael Xavier de Souza")," has saved you a job by putting together ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/rxaviers/cldr-data-bower"}),"Bower")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/rxaviers/cldr-data-npm"}),"npm")," modules to do the hard work for you."),(0,a.kt)("p",null,"I'm using Bower for my client side package management and so I'll use that. Looking at the Bower dependencies downloaded when I upgraded my package I can see there is a ",(0,a.kt)("inlineCode",{parentName:"p"},"cldr-data")," package. Yay! However it appears to be missing the associated json files. Boo!"),(0,a.kt)("p",null,"To the documentation Batman. It says you need a ",(0,a.kt)("inlineCode",{parentName:"p"},".bowerrc")," file in your repo which contains this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),'{\n  "scripts": {\n    "preinstall": "npm install cldr-data-downloader@0.2.x",\n    "postinstall": "node ./node_modules/cldr-data-downloader/bin/download.js -i bower_components/cldr-data/index.json -o bower_components/cldr-data/"\n  }\n}\n')),(0,a.kt)("p",null,"Unfortunately, because I've already upgraded to v1 adding this file alone doesn't do anything for me. To get round that I delete my ",(0,a.kt)("inlineCode",{parentName:"p"},"bower_components")," folder and enter ",(0,a.kt)("inlineCode",{parentName:"p"},"bower install"),". Boom!"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"bower globalize#^1.0.0          cached git://github.com/jquery/globalize.git#1.0.0\nbower globalize#^1.0.0        validate 1.0.0 against git://github.com/jquery/globalize.git#^1.0.0\nbower cldrjs#0.4.1                        cached git://github.com/rxaviers/cldrjs.git#0.4.1\nbower cldrjs#0.4.1                      validate 0.4.1 against git://github.com/rxaviers/cldrjs.git#0.4.1\nbower cldr-data#>=25                      cached git://github.com/rxaviers/cldr-data-bower.git#27.0.3\nbower cldr-data#>=25                    validate 27.0.3 against git://github.com/rxaviers/cldr-data-bower.git#>=25\nbower                                 preinstall npm install cldr-data-downloader@0.2.x\nbower                                 preinstall cldr-data-downloader@0.2.3 node_modules\\cldr-data-downloader\nbower                                 preinstall \u251c\u2500\u2500 progress@1.1.8\nbower                                 preinstall \u251c\u2500\u2500 q@1.0.1\nbower                                 preinstall \u251c\u2500\u2500 request-progress@0.3.1 (throttleit@0.0.2)\nbower                                 preinstall \u251c\u2500\u2500 nopt@3.0.3 (abbrev@1.0.7)\nbower                                 preinstall \u251c\u2500\u2500 mkdirp@0.5.0 (minimist@0.0.8)\nbower                                 preinstall \u251c\u2500\u2500 adm-zip@0.4.4\nbower                                 preinstall \u251c\u2500\u2500 npmconf@2.0.9 (uid-number@0.0.5, ini@1.3.4, inherits@2.0.1, once@1.3.2, osenv@0.1.3, config-chain@1.1.9, semver@4.3.6)\nbower                                 preinstall \u2514\u2500\u2500 request@2.53.0 (caseless@0.9.0, forever-agent@0.5.2, aws-sign2@0.5.0, stringstream@0.0.4, tunnel-agent@0.4.1, oauth-sign@0.6.0, isstream@0.1.2, json-stringify-safe@5.0.1, qs@2.3.3, node-uuid@1.4.3, combined-stream@0.0.7, mime-types@2.0.14, form-data@0.2.0, tough-cookie@2.0.0, bl@0.9.4, http-signature@0.10.1, hawk@2.3.1)\nbower globalize#^1.0.0                   install globalize#1.0.0\nbower cldrjs#0.4.1                       install cldrjs#0.4.1\nbower cldr-data#>=25                     install cldr-data#27.0.3\nbower                                postinstall node ./node_modules/cldr-data-downloader/bin/download.js -i bower_components/cldr-data/index.json -o bower_components/cldr-data/\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-core/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-dates-modern/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-cal-buddhist-modern/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-cal-chinese-modern/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-cal-coptic-modern/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-cal-dangi-modern/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-cal-ethiopic-modern/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-cal-hebrew-modern/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-cal-indian-modern/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-cal-islamic-modern/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-cal-japanese-modern/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-cal-persian-modern/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-cal-roc-modern/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-localenames-modern/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-misc-modern/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-numbers-modern/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-segments-modern/archive/27.0.3.zip`\nbower                                postinstall GET `https://github.com/unicode-cldr/cldr-units-modern/archive/27.0.3.zip`\nbower                                postinstall Received 28728K total.\nbower                                postinstall Received 28753K total.\nbower                                postinstall Unpacking it into `./bower_components\\cldr-data`\n\nglobalize#1.0.0 bower_components\\globalize\n\u251c\u2500\u2500 cldr-data#27.0.3\n\u2514\u2500\u2500 cldrjs#0.4.1\n\ncldrjs#0.4.1 bower_components\\cldrjs\n\u2514\u2500\u2500 cldr-data#27.0.3\n\ncldr-data#27.0.3 bower_components\\cldr-data\n")),(0,a.kt)("p",null,"That's right - I'm golden. And if I didn't want to do that I could have gone straight to the command line and entered this: (look familiar?)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"npm install cldr-data-downloader@0.2.x\nnode ./node_modules/cldr-data-downloader/bin/download.js -i bower_components/cldr-data/index.json -o bower_components/cldr-data/\n")),(0,a.kt)("h2",o({},{id:"some-bitching-and-moaning"}),"Some bitching and moaning."),(0,a.kt)("p",null,"If, like me, you were a regular user of Globalize 0.1.x then you know that you needed very little to get going. As you can see from our example you just serve up ",(0,a.kt)("inlineCode",{parentName:"p"},"Globalize.js")," and the culture files you are interested in (eg ",(0,a.kt)("inlineCode",{parentName:"p"},"globalize.culture.de-DE.js"),"). That's it - you have all you need; job's a good'un. This is all very convenient and entirely lovely."),(0,a.kt)("p",null,"Globalize 1.x has a different approach and one that (I have to be honest) I'm not entirely on board with. The thing that you need to know about the new Globalize is that ",(0,a.kt)("em",{parentName:"p"},"nothing comes for free"),". It's been completely modularised and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jquery/globalize#pick-the-modules-you-need"}),"you have to include extra libraries depending on the functionality you require.")," On top of that you then have to work out the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jquery/globalize#2-cldr-content"}),"portions of the cldr data that you require for those modules")," and supply them. This means that getting up and running with Globalize 1.x is much harder. Frankly I think it's a little painful."),(0,a.kt)("p",null,"I realise this is a little ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Who_Moved_My_Cheese%3F"}),'"Who moved my cheese"'),". I'll get over it. I do actually see the logic of this. It is certainly good that the culture date is not frozen in aspic but will evolve as the world does. But it's undeniable that in our brave new world Globalize is no longer a doddle to pick up. Or at least right now."),(0,a.kt)("h2",o({},{id:"take-the-modules-and-run"}),"Take the modules and run"),(0,a.kt)("p",null,"So. What do we actually need? Well I've consulted the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jquery/globalize#pick-the-modules-you-need"}),"documentation")," and I think I'm clear. Our simple demo cares about dates and numbers. So I'm going to guess that means I need:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/jquery/globalize#core-module"}),(0,a.kt)("inlineCode",{parentName:"a"},"globalize.js"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/jquery/globalize#date-module"}),(0,a.kt)("inlineCode",{parentName:"a"},"globalize/date.js"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/jquery/globalize#number-module"}),(0,a.kt)("inlineCode",{parentName:"a"},"globalize/number.js")))),(0,a.kt)("p",null,"On top of that I'm also going to need the various cldr dependencies too. That's not all. Given that I've decided which modules I will use I now need to acquire the associated cldr data. According to the docs ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jquery/globalize#2-cldr-content"}),"here")," we're going to need:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"cldr/supplemental/likelySubtags.json")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"cldr/main/<i>locale</i>/ca-gregorian.json")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"cldr/main/<i>locale</i>/timeZoneNames.json")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"cldr/supplemental/timeData.json")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"cldr/supplemental/weekData.json")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"cldr/main/locale/numbers.json")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"cldr/supplemental/numberingSystems.json"))),(0,a.kt)("p",null,"Figuring that all out felt like really hard work. But I think that now we're ready to do the actual migration."),(0,a.kt)("h3",o({},{id:"updated-30082015-globalize--so-whatcha-want"}),"Updated 30/08/2015: Globalize \xb7 So What'cha Want"),(0,a.kt)("p",null,"To make working out what you need when using Globalize I've built ",(0,a.kt)("a",o({parentName:"p"},{href:"http://johnnyreilly.github.io/globalize-so-what-cha-want/"}),"Globalize \xb7 So What'cha Want"),". You're so very welcome."),(0,a.kt)("h2",o({},{id:"the-actual-migration"}),"The Actual Migration"),(0,a.kt)("p",null,"To do this I'm going to lean heavily upon ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jquery/globalize/blob/master/examples/plain-javascript/index.html"}),"an example put together by Rafael"),". The migrated code looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),"<html>\n  <head>\n    <title>Globalize demo</title>\n    <link\n      href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css\"\n      rel=\"stylesheet\"\n    />\n  </head>\n  <body>\n    <div class=\"container-fluid\">\n      <h4>Globalize demo for the <em id=\"locale\"></em> culture / locale</h4>\n      <p>\n        This is a the number <strong id=\"number\"></strong> formatted by\n        Globalize: <strong id=\"numberFormatted\"></strong>\n      </p>\n      <p>\n        This is a the number <strong id=\"date\"></strong> formatted by Globalize:\n        <strong id=\"dateFormatted\"></strong>\n      </p>\n    </div>\n\n    \x3c!-- First, we load Globalize's dependencies (`cldrjs` and its supplemental module). --\x3e\n    <script src=\"bower_components/cldrjs/dist/cldr.js\"><\/script>\n    <script src=\"bower_components/cldrjs/dist/cldr/event.js\"><\/script>\n    <script src=\"bower_components/cldrjs/dist/cldr/supplemental.js\"><\/script>\n\n    \x3c!-- Next, we load Globalize and its modules. --\x3e\n    <script src=\"bower_components/globalize/dist/globalize.js\"><\/script>\n    <script src=\"bower_components/globalize/dist/globalize/number.js\"><\/script>\n\n    \x3c!-- Load after globalize/number.js --\x3e\n    <script src=\"bower_components/globalize/dist/globalize/date.js\"><\/script>\n\n    <script>\n      var locale = 'de';\n\n      Promise.all([\n        // Core\n        fetch('bower_components/cldr-data/supplemental/likelySubtags.json'),\n\n        // Date\n        fetch(\n          'bower_components/cldr-data/main/' + locale + '/ca-gregorian.json'\n        ),\n        fetch(\n          'bower_components/cldr-data/main/' + locale + '/timeZoneNames.json'\n        ),\n        fetch('bower_components/cldr-data/supplemental/timeData.json'),\n        fetch('bower_components/cldr-data/supplemental/weekData.json'),\n\n        // Number\n        fetch('bower_components/cldr-data/main/' + locale + '/numbers.json'),\n        fetch('bower_components/cldr-data/supplemental/numberingSystems.json'),\n      ])\n        .then(function (responses) {\n          return Promise.all(\n            responses.map(function (response) {\n              return response.json();\n            })\n          );\n        })\n        .then(Globalize.load)\n        .then(function () {\n          var number = 12345.67;\n          var date = new Date(2012, 5, 15);\n\n          var globalize = Globalize(locale);\n          document.querySelector('#locale').innerText = locale;\n          document.querySelector('#number').innerText = number;\n          document.querySelector('#date').innerText = date;\n          document.querySelector('#numberFormatted').innerText =\n            globalize.formatNumber(number, {\n              minimumFractionDigits: 2,\n              useGrouping: true,\n            });\n          document.querySelector('#dateFormatted').innerText =\n            globalize.formatDate(date, {\n              date: 'medium',\n            });\n        });\n    <\/script>\n  </body>\n</html>\n")),(0,a.kt)("p",null,"By the way, I'm using ",(0,a.kt)("a",o({parentName:"p"},{href:"http://jakearchibald.com/2015/thats-so-fetch/"}),"fetch")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.html5rocks.com/en/tutorials/es6/promises/"}),"promises")," to load the cldr-data. This isn't mandatory - I use it because Chrome lets me. (I'm so bleeding edge.) Some standard jQuery ajax calls would do just as well. There's an example of that approach ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jquery/globalize/blob/master/doc/cldr/index.md#how-do-i-load-cldr-data-into-globalize"}),"here"),"."),(0,a.kt)("h2",o({},{id:"observations"}),"Observations"),(0,a.kt)("p",null,"We've gone from not a lot of code to... well, more than a little. A medium amount. Almost all of that extra code relates to getting Globalize 1.x to spin up so it's ready to work. We've also gone from 2 HTTP requests to 13 which is unlucky for you. 6 of them took place via ajax after the page had loaded. It's worth noting that we're not even loading all of Globalize either. On top of that there's the old order-of-loading shenanigans to deal with. All of these can be mitigated by introducing a custom build step of your own to concatenate and minify the associated cldr / Globalize files."),(0,a.kt)("p",null,"Loading the data via ajax isn't mandatory by the way. If you wanted to you could create your own style of ",(0,a.kt)("inlineCode",{parentName:"p"},"globalize.culture.de.js")," files which would allow you load the page without recourse to post-page load HTTP requests. Something like this Gulp task I've knocked up would do the trick:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"gulp.task('make-globalize-culture-de-js', function () {\n  var locale = 'de';\n  var jsonWeNeed = [\n    require('./bower_components/cldr-data/supplemental/likelySubtags.json'),\n    require('./bower_components/cldr-data/main/' +\n      locale +\n      '/ca-gregorian.json'),\n    require('./bower_components/cldr-data/main/' +\n      locale +\n      '/timeZoneNames.json'),\n    require('./bower_components/cldr-data/supplemental/timeData.json'),\n    require('./bower_components/cldr-data/supplemental/weekData.json'),\n    require('./bower_components/cldr-data/main/' + locale + '/numbers.json'),\n    require('./bower_components/cldr-data/supplemental/numberingSystems.json'),\n  ];\n\n  var jsonStringWithLoad =\n    'Globalize.load(' +\n    jsonWeNeed\n      .map(function (json) {\n        return JSON.stringify(json);\n      })\n      .join(', ') +\n    ');';\n\n  var fs = require('fs');\n  fs.writeFile(\n    './globalize.culture.' + locale + '.js',\n    jsonStringWithLoad,\n    function (err) {\n      if (err) {\n        console.log(err);\n      } else {\n        console.log('The file was created!');\n      }\n    }\n  );\n});\n")),(0,a.kt)("p",null,"The above is standard node/io type code by the way; just take the contents of the function and run in node and you should be fine. If you do use this approach then you're very much back to the simplicity of Globalize 0.1.x's approach."),(0,a.kt)("p",null,"And here is the page in all its post migration glory:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(69599).Z,width:"640",height:"154"})),(0,a.kt)("p",null,"It looks exactly the same except 'de-DE' has become simply 'de' (since that's how the cldr rolls)."),(0,a.kt)("p",null,"The migrated code is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/globalize-migration"}),"there for the taking"),". Make sure you remember to ",(0,a.kt)("inlineCode",{parentName:"p"},"bower install")," ","-"," and you'll need to host the demo on a simple server since it makes ajax calls."),(0,a.kt)("p",null,"Before I finish off I wanted to say \"well done!\" to all the people who have worked on Globalize. It's an important project and I do apologise for my being a little critical of it here. I should say that I think it's just the getting started that's hard. Once you get over that hurdle you'll be fine. Hopefully this post will help people do just that. Pip, pip!"))}d.isMDXComponent=!0},24570:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"top-one-nice-one-get-sorted",title:"(Top One, Nice One) Get Sorted",authors:"johnnyreilly",tags:["javascript","LINQ"],hide_table_of_contents:!1},s=void 0,l={permalink:"/top-one-nice-one-get-sorted",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-08-13-top-one-nice-one-get-sorted/index.md",source:"@site/blog/2015-08-13-top-one-nice-one-get-sorted/index.md",title:"(Top One, Nice One) Get Sorted",description:"I was recently reading a post by Jaime Gonz\xe1lez Garc\xeda which featured the following mind-bending proposition:",date:"2015-08-13T00:00:00.000Z",formattedDate:"August 13, 2015",tags:[{label:"javascript",permalink:"/tags/javascript"},{label:"LINQ",permalink:"/tags/linq"}],readingTime:8.575,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"top-one-nice-one-get-sorted",title:"(Top One, Nice One) Get Sorted",authors:"johnnyreilly",tags:["javascript","LINQ"],hide_table_of_contents:!1},prevItem:{title:"Things Done Changed",permalink:"/things-done-changed"},nextItem:{title:"Upgrading to Globalize 1.x for Dummies",permalink:"/upgrading-to-globalize-1x-for-dummies"}},p={authorsImageUrls:[void 0]},u=[{value:"Sort",id:"sort",level:2},{value:"String Comparer",id:"string-comparer",level:2},{value:"Number Comparer",id:"number-comparer",level:2},{value:"Descending Into the Pit of Success",id:"descending-into-the-pit-of-success",level:2},{value:"<code>ThenBy</code>",id:"thenby",level:2},{value:"<code>composeComparers</code>: The Sequel",id:"composecomparers-the-sequel",level:2},{value:"<code>composeComparers</code>: The Ultimate",id:"composecomparers-the-ultimate",level:2},{value:"Updated 08/10/2018: Now TypeScript",id:"updated-08102018-now-typescript",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I was recently reading ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.barbarianmeetscoding.com/blog/2015/07/09/mastering-the-arcane-art-of-javascript-mancy-for-c-sharp-developers-chapter-7-using-linq-in-javascript/"}),"a post by Jaime Gonz\xe1lez Garc\xeda")," which featured the following mind-bending proposition:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"What if I told you that JavaScript has ",(0,a.kt)("a",o({parentName:"p"},{href:"https://msdn.microsoft.com/en-us/library/bb397926.aspx"}),"LINQ"),"??")),(0,a.kt)("p",null,"It got me thinking about one of favourite features of LINQ: ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.dotnetperls.com/orderby-extension"}),"ordering using OrderBy, ThenBy...")," The ability to simply expose a collection of objects in a given order with a relatively terse and descriptive syntax. It is fantastically convenient, expressive and something I've been missing in JavaScript. But if Jaime is right... Well, let's see what we can do."),(0,a.kt)("h2",o({},{id:"sort"}),"Sort"),(0,a.kt)("p",null,"JavaScript arrays have a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/sort"}),"sort")," method. To quote MDN:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("inlineCode",{parentName:"p"},"arr.sort([compareFunction])"),"### ",(0,a.kt)("inlineCode",{parentName:"p"},"compareFunction")),(0,a.kt)("p",{parentName:"blockquote"},"Optional. Specifies a function that defines the sort order. If omitted, the array is sorted according to each character's Unicode code point value, according to the string conversion of each element.")),(0,a.kt)("p",null,"We want to use the ",(0,a.kt)("inlineCode",{parentName:"p"},"sort")," function to introduce some LINQ-ish ordering goodness. Sort of. See what I did there?"),(0,a.kt)("p",null,"Before we get going it's worth saying that LINQ's ",(0,a.kt)("inlineCode",{parentName:"p"},"OrderBy")," and JavaScript's ",(0,a.kt)("inlineCode",{parentName:"p"},"sort")," are not the same thing. ",(0,a.kt)("inlineCode",{parentName:"p"},"sort")," actually changes the order of the array. However, ",(0,a.kt)("inlineCode",{parentName:"p"},"OrderBy")," returns an ",(0,a.kt)("inlineCode",{parentName:"p"},"IOrderedEnumerable")," which when iterated returns the items of the collection in a particular order. An important difference. If preserving the original order of my array was important to me (spoiler: mostly it isn't) then I could make a call to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/slice"}),(0,a.kt)("inlineCode",{parentName:"a"},"slice"))," prior to calling ",(0,a.kt)("inlineCode",{parentName:"p"},"sort"),"."),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"sort")," also returns the array to the caller which is nice for chaining and means we can use it in a similar fashion to the way we use ",(0,a.kt)("inlineCode",{parentName:"p"},"OrderBy"),". With that in mind, we're going to create comparer functions which will take a lambda / arrow function (ES6 alert!) and return a function which will compare based on the supplied lambda."),(0,a.kt)("h2",o({},{id:"string-comparer"}),"String Comparer"),(0,a.kt)("p",null,"Let's start with ordering by string properties:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"function stringComparer(propLambda) {\n  return (obj1, obj2) => {\n    const obj1Val = propLambda(obj1) || '';\n    const obj2Val = propLambda(obj2) || '';\n    return obj1Val.localeCompare(obj2Val);\n  };\n}\n")),(0,a.kt)("p",null,"We need some example data to sort: (I can only apologise for my lack of inspiration here)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const foodInTheHouse = [\n  { what: 'cake', daysSincePurchase: 2 },\n  { what: 'apple', daysSincePurchase: 8 },\n  { what: 'orange', daysSincePurchase: 6 },\n  { what: 'apple', daysSincePurchase: 2 },\n];\n")),(0,a.kt)("p",null,"If we were doing a sort by strings in LINQ we wouldn't need to implement our own comparer. And the code we'd write would look something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var foodInTheHouseSorted = foodInTheHouse.OrderBy((x) => x.what);\n")),(0,a.kt)("p",null,"With that in mind, here's how it would look to use our shiny and new ",(0,a.kt)("inlineCode",{parentName:"p"},"stringComparer"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const foodInTheHouseSorted = foodInTheHouse.sort(stringComparer((x) => x.what));\n\n// foodInTheHouseSorted: [\n//   { what: 'apple',  daysSincePurchase: 8 },\n//   { what: 'apple',  daysSincePurchase: 2 },\n//   { what: 'cake',   daysSincePurchase: 2 },\n//   { what: 'orange', daysSincePurchase: 6 }\n// ]\n\n// PS Don't forget, for our JavaScript: foodInTheHouse === foodInTheHouseSorted\n//    But for the LINQ:                 foodInTheHouse !=  foodInTheHouseSorted\n//\n//    However, if I'd done this:\n\nconst foodInTheHouseSlicedAndSorted = foodInTheHouse\n  .slice()\n  .sort(stringComparer((x) => x.what));\n\n//    then:                             foodInTheHouse !== foodInTheHouseSlicedAndSorted\n//\n//    I shan't mention this again.\n")),(0,a.kt)("h2",o({},{id:"number-comparer"}),"Number Comparer"),(0,a.kt)("p",null,"Well that's strings sorted (quite literally). Now, what about numbers?"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"function numberComparer(propLambda) {\n  return (obj1, obj2) => {\n    const obj1Val = propLambda(obj1);\n    const obj2Val = propLambda(obj2);\n    if (obj1Val > obj2Val) {\n      return 1;\n    } else if (obj1Val < obj2Val) {\n      return -1;\n    }\n    return 0;\n  };\n}\n")),(0,a.kt)("p",null,"If we use the ",(0,a.kt)("inlineCode",{parentName:"p"},"numberComparer")," on our original array it looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const foodInTheHouseSorted = foodInTheHouse.sort(\n  numberComparer((x) => x.daysSincePurchase)\n);\n\n// foodInTheHouseSorted: [\n//   { what: 'cake',   daysSincePurchase: 2 },\n//   { what: 'apple',  daysSincePurchase: 2 },\n//   { what: 'orange', daysSincePurchase: 6 },\n//   { what: 'apple',  daysSincePurchase: 8 }\n// ]\n")),(0,a.kt)("h2",o({},{id:"descending-into-the-pit-of-success"}),"Descending Into the Pit of Success"),(0,a.kt)("p",null,"Well this is all kinds of fabulous. But something's probably nagging at you... What about ",(0,a.kt)("inlineCode",{parentName:"p"},"OrderByDescending"),"? What about when I want to sort in the reverse order? May I present the ",(0,a.kt)("inlineCode",{parentName:"p"},"reverse")," function:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"function reverse(comparer) {\n  return (obj1, obj2) => comparer(obj1, obj2) * -1;\n}\n")),(0,a.kt)("p",null,"As the name suggests, this function takes a given comparer that's handed to it and returns a function that inverts the results of executing that comparer. Clear as mud? A comparer can return 3 types of return values:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"0 - implies equality for ",(0,a.kt)("inlineCode",{parentName:"li"},"obj1")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"obj2")),(0,a.kt)("li",{parentName:"ul"},"positive - implies ",(0,a.kt)("inlineCode",{parentName:"li"},"obj1")," is greater than ",(0,a.kt)("inlineCode",{parentName:"li"},"obj2")," by the ordering criterion"),(0,a.kt)("li",{parentName:"ul"},"negative - implies ",(0,a.kt)("inlineCode",{parentName:"li"},"obj1")," is less than ",(0,a.kt)("inlineCode",{parentName:"li"},"obj2")," by the ordering criterion")),(0,a.kt)("p",null,"Our ",(0,a.kt)("inlineCode",{parentName:"p"},"reverse")," function takes the comparer it is given and returns a new comparer that will return a positive value where the old one would have returned a negative and vica versa. (Equality is unaffected.) An alternative implementation would have been this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"function reverse(comparer) {\n  return (obj1, obj2) => comparer(obj2, obj1);\n}\n")),(0,a.kt)("p",null,"Which is more optimal and even simpler as it just swaps the values supplied to the comparer. Whatever tickles your fancy. Either way, when used it looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const foodInTheHouseSorted = foodInTheHouse.sort(\n  reverse(stringComparer((x) => x.what))\n);\n\n// foodInTheHouseSorted: [\n//   { what: 'orange', daysSincePurchase: 6 },\n//   { what: 'cake',   daysSincePurchase: 2 },\n//   { what: 'apple',  daysSincePurchase: 8 },\n//   { what: 'apple',  daysSincePurchase: 2 }\n// ]\n")),(0,a.kt)("p",null,"If you'd rather not have a function wrapping a function inline then you could create ",(0,a.kt)("inlineCode",{parentName:"p"},"stringComparerDescending"),", a ",(0,a.kt)("inlineCode",{parentName:"p"},"numberComparerDescending")," etc implementations. Arguably it might make for a nicer API. I'm not unhappy with the present approach myself and so I'll leave it as is. But it's an option."),(0,a.kt)("h2",o({},{id:"thenby"}),(0,a.kt)("inlineCode",{parentName:"h2"},"ThenBy")),(0,a.kt)("p",null,"So far we can sort arrays by strings, we can sort arrays by numbers and we can do either in descending order. It's time to take it to the next level people. That's right ",(0,a.kt)("inlineCode",{parentName:"p"},"ThenBy"),"; I want to be able to sort by one criteria and then by a subcriteria. So perhaps I want to eat the food in the house in alphabetical order, but if I have multiple apples I want to eat the ones I bought most recently first (because the other ones look old, brown and yukky). This may also be a sign I haven't thought my life through, but it's a choice that people make. People that I know. People I may have married."),(0,a.kt)("p",null,"It's time to compose our comparers together. May I present... drum roll.... the ",(0,a.kt)("inlineCode",{parentName:"p"},"composeComparers")," function:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"function composeComparers(...comparers) {\n  return (obj1, obj2) => {\n    const comparer = comparers.find((c) => c(obj1, obj2) !== 0);\n    return comparer ? comparer(obj1, obj2) : 0;\n  };\n}\n")),(0,a.kt)("p",null,"This fine function takes any number of comparers that have been supplied to it. It then returns a comparer function which, when called, iterates through each of the original comparers and executes them until it finds one that returns a value that is not 0 (ie represents that the 2 items are not equal). It then sends that non-zero value back or if all was equal then sends back 0."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const foodInTheHouseSorted = foodInTheHouse.sort(\n  composeComparers(\n    stringComparer((x) => x.what),\n    numberComparer((x) => x.daysSincePurchase)\n  )\n);\n\n// foodInTheHouseSorted: [\n//   { what: 'apple',  daysSincePurchase: 2 },\n//   { what: 'apple',  daysSincePurchase: 8 },\n//   { what: 'cake',   daysSincePurchase: 2 },\n//   { what: 'orange', daysSincePurchase: 6 }\n// ]\n")),(0,a.kt)("h2",o({},{id:"composecomparers-the-sequel"}),(0,a.kt)("inlineCode",{parentName:"h2"},"composeComparers"),": The Sequel"),(0,a.kt)("p",null,"I'm not gonna lie - I was feeling quite pleased with this approach. I shared it with my friend (and repeated colleague) ",(0,a.kt)("a",o({parentName:"p"},{href:"http://blog.peterfoldi.com/"}),"Peter Foldi"),". The next day I found this in my inbox:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"function composeComparers(...comparers) {\n  return (obj1, obj2) =>\n    comparers.reduce((prev, curr) => prev || curr(obj1, obj2), 0);\n}\n")),(0,a.kt)("p",null,"Dammit he's improved it. It's down to 1 line of code, it doesn't execute a non-zero returning comparer twice and it doesn't rely on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/find"}),(0,a.kt)("inlineCode",{parentName:"a"},"find"))," which only arrives with ES6. So if you wanted to backport to ES5 then this is a better choice."),(0,a.kt)("p",null,"The only criticism I can make of it is that it iterates through each of the comparers even when it doesn't need to execute them. But that's just carping really."),(0,a.kt)("h2",o({},{id:"composecomparers-the-ultimate"}),(0,a.kt)("inlineCode",{parentName:"h2"},"composeComparers"),": The Ultimate"),(0,a.kt)("p",null,"So naturally I thought I was done. Showing Peter's improvements to the estimable Matthew Horsley I learned that this was not so. Because he reached for the keyboard and entered this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),'function composeComparers(...comparers) {\n  // README: <a href="https://wiki.haskell.org/Function_composition">https://wiki.haskell.org/Function_composition</a>\n  return comparers.reduce((prev, curr) => (a, b) => prev(a, b) || curr(a, b));\n}\n')),(0,a.kt)("p",null,"That's right, he's created a function which takes a number of comparers and reduced them up front into a single comparer function. This means that when the sort takes place there is no longer a need to iterate through the comparers, just execute them."),(0,a.kt)("p",null,"I know."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"animated gif with the heading &quot;mind-equals-blown&quot;",src:n(57950).Z,width:"500",height:"299"})),(0,a.kt)("p",null,"I'll get my coat..."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"function composeComparers(...comparers) {\n  return comparers.reduce((prev, curr) => (a, b) => prev(a, b) || curr(a, b));\n}\n\nfunction stringComparer(propLambda) {\n  return (obj1, obj2) => {\n    const obj1Val = propLambda(obj1) || '';\n    const obj2Val = propLambda(obj2) || '';\n    return obj1Val.localeCompare(obj2Val);\n  };\n}\n\nfunction numberComparer(propLambda) {\n  return (obj1, obj2) => {\n    const obj1Val = propLambda(obj1);\n    const obj2Val = propLambda(obj2);\n    if (obj1Val > obj2Val) {\n      return 1;\n    } else if (obj1Val < obj2Val) {\n      return -1;\n    }\n    return 0;\n  };\n}\n\nfunction reverse(comparer) {\n  return (obj1, obj2) => comparer(obj2, obj1);\n}\n\n/* - Example usage\nconst foodInTheHouse = [\n  { what: 'cake',   daysSincePurchase: 2 },\n  { what: 'apple',  daysSincePurchase: 8 },\n  { what: 'orange', daysSincePurchase: 6 },\n  { what: 'apple',  daysSincePurchase: 2 },\n];\nconst foodInTheHouseSorted = foodInTheHouse.sort(composeComparers(\n    stringComparer(x => x.what),\n    reverse(numberComparer(x => x.daysSincePurchase))\n));\nconsole.log(foodInTheHouseSorted);\n*/\n")),(0,a.kt)("h2",o({},{id:"updated-08102018-now-typescript"}),"Updated 08/10/2018: Now TypeScript"),(0,a.kt)("p",null,"You want to do this with TypeScript? Use this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"type Comparer<TObject> = (obj1: TObject, obj2: TObject) => number;\n\nexport function stringComparer<TObject>(\n  propLambda: (obj: TObject) => string\n): Comparer<TObject> {\n  return (obj1: TObject, obj2: TObject) => {\n    const obj1Val = propLambda(obj1) || '';\n    const obj2Val = propLambda(obj2) || '';\n    return obj1Val.localeCompare(obj2Val);\n  };\n}\n\nexport function numberComparer<TObject>(\n  propLambda: (obj: TObject) => number\n): Comparer<TObject> {\n  return (obj1: TObject, obj2: TObject) => {\n    const obj1Val = propLambda(obj1);\n    const obj2Val = propLambda(obj2);\n    if (obj1Val > obj2Val) {\n      return 1;\n    } else if (obj1Val < obj2Val) {\n      return -1;\n    }\n    return 0;\n  };\n}\n\nexport function reverse<TObject>(comparer: Comparer<TObject>) {\n  return (obj1: TObject, obj2: TObject) => comparer(obj2, obj1);\n}\n\nexport function composeComparers<TObject>(...comparers: Comparer<TObject>[]) {\n  return comparers.reduce((prev, curr) => (a, b) => prev(a, b) || curr(a, b));\n}\n")))}d.isMDXComponent=!0},50045:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"things-done-changed",title:"Things Done Changed",authors:"johnnyreilly",tags:["ES6","Atom","Babel","React","WebSockets"],hide_table_of_contents:!1},s=void 0,l={permalink:"/things-done-changed",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-09-10-things-done-changed/index.md",source:"@site/blog/2015-09-10-things-done-changed/index.md",title:"Things Done Changed",description:"Some people fear change. Most people actually. I'm not immune to that myself, but not in the key area of technology. Any developer that fears change when it comes to the tools and languages that he / she is using is in the wrong business. Because what you're using to cut code today will not last. The language will evolve, the tools and frameworks that you love will die out and be replaced by new ones that are different and strange. In time, the language you feel you write as a native will fall out of favour, replaced by a new upstart.",date:"2015-09-10T00:00:00.000Z",formattedDate:"September 10, 2015",tags:[{label:"ES6",permalink:"/tags/es-6"},{label:"Atom",permalink:"/tags/atom"},{label:"Babel",permalink:"/tags/babel"},{label:"React",permalink:"/tags/react"},{label:"WebSockets",permalink:"/tags/web-sockets"}],readingTime:10.13,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"things-done-changed",title:"Things Done Changed",authors:"johnnyreilly",tags:["ES6","Atom","Babel","React","WebSockets"],hide_table_of_contents:!1},prevItem:{title:"Definitely Typed Shouldn't Exist",permalink:"/authoring-npm-modules-with-typescript"},nextItem:{title:"(Top One, Nice One) Get Sorted",permalink:"/top-one-nice-one-get-sorted"}},p={authorsImageUrls:[void 0]},u=[{value:"The Shock of the New (Toys)",id:"the-shock-of-the-new-toys",level:2},{value:"How Does it Feel to be on Your Own?",id:"how-does-it-feel-to-be-on-your-own",level:2},{value:"Someone to watch over me",id:"someone-to-watch-over-me",level:2},{value:"Karma, Karma, Karma, Chameleon",id:"karma-karma-karma-chameleon",level:2},{value:"I cry Babel, Babel, look at me now",id:"i-cry-babel-babel-look-at-me-now",level:2},{value:"Browserify (there are no song lyrics that can be crowbarred in)",id:"browserify-there-are-no-song-lyrics-that-can-be-crowbarred-in",level:2},{value:"WebSockets / Protocol Buffers",id:"websockets--protocol-buffers",level:2},{value:"React / Flux",id:"react--flux",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Some people fear change. Most people actually. I'm not immune to that myself, but not in the key area of technology. Any developer that fears change when it comes to the tools and languages that he / she is using is in the ",(0,a.kt)("em",{parentName:"p"},"wrong")," business. Because what you're using to cut code today will not last. The language will evolve, the tools and frameworks that you love will die out and be replaced by new ones that are different and strange. In time, the language you feel you write as a native will fall out of favour, replaced by a new upstart."),(0,a.kt)("p",null,"My first gig was writing telecoms software using Delphi. I haven't touched Delphi (or telecoms for that matter) for over 10 years now. Believe me, I grok that things change."),(0,a.kt)("p",null,"That is the developer's lot. If you're able to accept that then you'll be just fine. For my part I've always rather relished the new and so I embrace it. However, I've met a surprising number of devs that are outraged when they realise that the language and tools they have used since their first job are not going to last. They do not go gentle into that good dawn. They rage, rage against the death of WebForms. My apologies to Dylan Thomas."),(0,a.kt)("p",null,"I recently started a new contract. This always brings a certain amount of change. This is part of the fun of contracting. However, the change was more significant in this case. As a result, the tools that I've been using for the last couple of months have been rather different to those that I'm used to. I've been outside my comfort zone. I've loved it. And now I want to reflect upon it. Because, in the words of Socrates, \"the unexamined life is not worth living\"."),(0,a.kt)("h2",o({},{id:"the-shock-of-the-new-toys"}),"The Shock of the New (Toys)"),(0,a.kt)("p",null,"I'd been brought in to work on a full stack ASP.Net project. However, I've initially been working on a separate project which is ",(0,a.kt)("em",{parentName:"p"},"entirely")," different. A web client app which has nothing to do with ASP.Net at all. It's a greenfield app which is built using the following:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",o({parentName:"li"},{href:"https://facebook.github.io/react/"}),"React")," / ",(0,a.kt)("a",o({parentName:"li"},{href:"https://facebook.github.io/flux/docs/overview.html"}),"Flux")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",o({parentName:"li"},{href:"https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API"}),"WebSockets")," / ",(0,a.kt)("a",o({parentName:"li"},{href:"https://developers.google.com/protocol-buffers/"}),"Protocol Buffers")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",o({parentName:"li"},{href:"http://browserify.org/"}),"Browserify")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",o({parentName:"li"},{href:"http://babeljs.io/"}),"ES6 with Babel")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",o({parentName:"li"},{href:"https://karma-runner.github.io"}),"Karma")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",o({parentName:"li"},{href:"http://gulpjs.com/"}),"Gulp")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",o({parentName:"li"},{href:"https://atom.io/"}),"Atom"))),(0,a.kt)("p",null,"Where to begin? Perhaps at the end - Atom."),(0,a.kt)("h2",o({},{id:"how-does-it-feel-to-be-on-your-own"}),"How Does it Feel to be on Your Own?"),(0,a.kt)("p",null,"When all around you, as far as the eye can see, are monitors displaying Visual Studio in all its grey glory whilst I was hammering away on Atom. It felt pretty good actually."),(0,a.kt)("p",null,"The app I was working on was a React / Flux app. You know what that means? JSX! At the time the project began Visual Studio did not have good editor support for JSX (something that the shipping of VS 2015 may have remedied but I haven't checked). So, rather than endure a life dominated with red squigglies I jumped ship and moved over to using GitHub's Atom to edit code."),(0,a.kt)("p",null,"I rather like it. Whilst VS is a full blown IDE, Atom is a text editor. A very pretty one. And crucially, one that can be extended by plugins of which there is a rich ecosystem. You want JSX support? ",(0,a.kt)("a",o({parentName:"p"},{href:"https://atom.io/packages/jshint"}),"There's a plugin for that"),". You want something that formats JSON nicely for you? ",(0,a.kt)("a",o({parentName:"p"},{href:"https://atom.io/packages/pretty-json"}),"There's a plugin for that too"),"."),(0,a.kt)("p",null,"My only criticism of Atom really is that it doesn't handle large files well and it crashes a lot. I'm quite surprised by both of these characteristics given that in contrast to VS it is so small. You'd think the basics would be better covered. Go figure. It still rocks though. It looks so sexy - how could I not like it?"),(0,a.kt)("h2",o({},{id:"someone-to-watch-over-me"}),"Someone to watch over me"),(0,a.kt)("p",null,"I've been using Gulp for a while now. It's a great JavaScript task runner and incredibly powerful. Previously though, I've used it as part of a manual build step (even plumbing it into my csproj). With the current project I've moved over to using the watch functionality of gulp. So I'm scrapping triggering gulp tasks manually. Instead we have gulp configured to gaze lovingly at the source files and, when they change, re-run the build steps."),(0,a.kt)("p",null,"This is nice for a couple of reasons:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"When I want to test out the app the build is already done - I don't have to wait for it to happen."),(0,a.kt)("li",{parentName:"ul"},"When I do bad things I find out faster. So I've got JSHint being triggered by my watch. If I write code that makes JSHint sad (and I haven't noticed the warnings from the ",(0,a.kt)("a",o({parentName:"li"},{href:"https://atom.io/packages/jshint"}),"atom plugin"),") then they'll appear in the console. Likewise, my unit tests are continuously running in response to file changes (in an ",(0,a.kt)("a",o({parentName:"li"},{href:"http://www.ncrunch.net/"}),"ncrunch"),"-","y sorta style) and so I know straight away if I'm breaking tests. Rather invaluable in the dynamic world of JavaScript.")),(0,a.kt)("h2",o({},{id:"karma-karma-karma-chameleon"}),"Karma, Karma, Karma, Chameleon"),(0,a.kt)("p",null,"In the past, when using Visual Studio, it made sense to use the mighty ",(0,a.kt)("a",o({parentName:"p"},{href:"http://mmanela.github.io/chutzpah/"}),"Chutzpah")," which allows you to run JS unit tests from within VS itself. I needed a new way to run my Jasmine unit tests. The obvious choice was Karma (built by the Angular team I think?). It's really flexible."),(0,a.kt)("p",null,"You're using Browserify? ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/karma-browserify"}),"No bother"),". You're writing ES6 and transpiling with Babel? Not a problem. You want code coverage? ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/karma-coverage"}),"That we can do"),". You want an integration for TeamCity? ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/karma-teamcity-reporter"}),"That too is sorted"),"...."),(0,a.kt)("p",null,"Karma is fantastic. Fun fact: originally it was called Testacular. I kind of get why they changed the name but the world is all the duller for it. A side effect of the name change is that due to invalid search results I know a lot more about Buddhism than I used to."),(0,a.kt)("h2",o({},{id:"i-cry-babel-babel-look-at-me-now"}),"I cry Babel, Babel, look at me now"),(0,a.kt)("p",null,"Can you not wait for the future? Me neither. Even though it's 2015 and Back to the Future II takes place in ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.october212015.com/"}),"only a month's time"),". So I'm not waiting for a million and one browsers to implement ES6 and IE 8 to finally die dammit. Nope, I have a plan and it's ",(0,a.kt)("a",o({parentName:"p"},{href:"http://babeljs.io/"}),"Babel"),". Transpile the tears away, write ES6 and have Babel spit out EStoday."),(0,a.kt)("p",null,"I've found this pretty addictive. Once you've started using ES6 features it's hard to go back. Take ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment"}),"destructuring")," ","-"," I can't get enough of it."),(0,a.kt)("p",null,"Whilst I love Babel, it has caused me some sadness as well. My beloved TypeScript is currently not in the mix, Babel is instead sat squarely where I want TS to be. I'm without static types and rather bereft. You can certainly live without them but having done so for a while I'm pretty clear now that static typing is a massive productivity win. You don't have to hold the data structures that you're working on in your head so much, code completion gives you what you need there, you can focus more on the problem that you're trying to solve. You also burn less time on silly mistakes. If you accidentally change the return type of a function you're likely to know straight away. Refactoring is so much harder without static types. I could go on."),(0,a.kt)("p",null,"All this goes to say: I want my static typing back. It wasn't really an option to use TypeScript in the beginning because we were using JSX and TS didn't support it. However! TypeScript is due to add support for JSX in ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.com/b/typescript/archive/2015/09/02/announcing-typescript-1-6-beta-react-jsx-better-error-checking-and-more.aspx"}),"TS 1.6 (currently in beta)"),". I've plans to see if I can get TypeScript to emit ES6 and then keep using Babel to do the transpilation. Whether this will work, I don't know yet. But it seems likely. So I'm hoping for a bright future."),(0,a.kt)("h2",o({},{id:"browserify-there-are-no-song-lyrics-that-can-be-crowbarred-in"}),"Browserify (there are no song lyrics that can be crowbarred in)"),(0,a.kt)("p",null,"Emitting scripts in the required order has been a perpetual pain for everyone in the web world for the longest time. I've taken about 5 different approaches to solving this problem over the years. None felt particularly good. So Browserify."),(0,a.kt)("p",null,"Browserify solves the problem of script ordering for you by allowing you to define an entry point to your application and getting you to write ",(0,a.kt)("inlineCode",{parentName:"p"},"require")," (npm style) or ",(0,a.kt)("inlineCode",{parentName:"p"},"import")," (",(0,a.kt)("a",o({parentName:"p"},{href:"http://exploringjs.com/es6/ch_modules.html"}),"ES6 modules"),") to bring in the modules that you need. This allows Browserify (which we're using with Babel thanks to the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/babel/babelify"}),"babelify transform"),") to create a ginormous js file that contains the scripts served as needed. Thanks to the magic of source maps it also allows us to debug our original code (yup, the original ES6!) Browserify has the added bonus of allowing us free reign to pull in npm packages to use in our app without a great deal of ceremony."),(0,a.kt)("p",null,"Browserify is pretty fab - my only real reservation is that if you step outside the normal use cases you can quickly find yourself in deep water. Take for instance web workers. We were briefly looking into using them as an optimisation (breaking IO onto a separate process from the UI). A prime reason for backing away from this is that ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/substack/webworkify/issues/14"}),"Web Workers don't play particularly well with Browserify"),". And when you've got Babel (or ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/babel/babelify"}),"Babelify"),") in the mix the problems just multiply. That apart, I really dig Browserify. I think I'd like to give WebPack a go as well as I understand it fulfills a similar purpose."),(0,a.kt)("h2",o({},{id:"websockets--protocol-buffers"}),"WebSockets / Protocol Buffers"),(0,a.kt)("p",null,"The application I'm working on is plugging into an existing system which uses WebSockets for communication. Since WebSockets are native to the web we've been able to plumb these straight into our app. We're also using Protocol Buffers as another optimisation; a way to save a few extra bytes from going down the wire. I don't have much to say about either, just some observations really:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"WebSockets is a slightly different way of working - permanently open connections as opposed to the request / response paradigm of classic HTTP"),(0,a.kt)("li",{parentName:"ol"},"WebSockets are wicked fast (due in part to those permanent connections). So performance is ",(0,a.kt)("em",{parentName:"li"},"amazing"),". Fast like native, type amazing. In our case performance is pretty important and so this has been really great.")),(0,a.kt)("h2",o({},{id:"react--flux"}),"React / Flux"),(0,a.kt)("p",null,'Finally, React and Flux. I was completely new to these when I came onto the project and I quickly came to love them. There was a prejudice for me to overcome and that was JSX. When I first saw it I felt a little sick. "Have we learned ',(0,a.kt)("em",{parentName:"p"},"NOTHING"),'???" I wailed. "Don\'t we know that embedding strings in our controllers is a ',(0,a.kt)("em",{parentName:"p"},"BAD")," thing?\" I was wrong. I had an epiphany. I discovered that JSX is not, as I first imagined, embedded HTML strings. Actually it's syntactic sugar for object creation. A simple example:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-jsx"}),"var App;\n\n// Some JSX:\nvar app = <App version=\"1.0.0\" />;\n\n// What that JSX transpiles into:\nvar app = React.createElement(App, { version: '1.0.0' });\n")),(0,a.kt)("p",null,"Now that I'm well used to JSX and React I've really got to like it. I keep my views / components as dumb as possible and do all the complex logic in the stores. The stores are just standard JavaScript and so, pretty testable (simple Jasmine gives you all you need - I haven't felt the need for ",(0,a.kt)("a",o({parentName:"p"},{href:"https://facebook.github.io/jest/"}),"Jest"),"). The components / views are also completely testable. I'd advise anyone coming to React afresh to make use of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://facebook.github.io/react/docs/test-utils.html#shallow-rendering"}),(0,a.kt)("inlineCode",{parentName:"a"},"ReactShallowRenderer"))," for these purposes. This means you can test without a DOM - much better all round."),(0,a.kt)("p",null,"I don't have a great deal to say about Flux; I think my views on it aren't fully formed yet. I do really like predictability that unidirectional data flow gives you. However, I'm mindful that the app that I've been writing is very much about displaying data and doesn't require much user input. I know that I'm living without 2-way data binding and I do wonder if I would come to miss it. Time will tell."),(0,a.kt)("p",null,"I really want to get back to static typing. That either means TypeScript (which I know and love) or Facebook's Flow. (",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/flow/issues/6"}),"A Windows version of Flow is in the works"),".) I'll be very happy if I get either into the mix... Watch this space."))}d.isMDXComponent=!0},30259:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"authoring-npm-modules-with-typescript",title:"Definitely Typed Shouldn't Exist",authors:"johnnyreilly",tags:["npm","DefinitelyTyped","typescript"],hide_table_of_contents:!1},s=void 0,l={permalink:"/authoring-npm-modules-with-typescript",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-09-23-authoring-npm-modules-with-typescript/index.md",source:"@site/blog/2015-09-23-authoring-npm-modules-with-typescript/index.md",title:"Definitely Typed Shouldn't Exist",description:"OK - the title's total clickbait but stay with me; there's a point here.",date:"2015-09-23T00:00:00.000Z",formattedDate:"September 23, 2015",tags:[{label:"npm",permalink:"/tags/npm"},{label:"DefinitelyTyped",permalink:"/tags/definitely-typed"},{label:"typescript",permalink:"/tags/typescript"}],readingTime:10.86,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"authoring-npm-modules-with-typescript",title:"Definitely Typed Shouldn't Exist",authors:"johnnyreilly",tags:["npm","DefinitelyTyped","typescript"],hide_table_of_contents:!1},prevItem:{title:"jQuery Validation Globalize hits 1.0",permalink:"/jquery-validation-globalize-hits-10"},nextItem:{title:"Things Done Changed",permalink:"/things-done-changed"}},p={authorsImageUrls:[void 0]},u=[{value:"Wrong!",id:"wrong",level:2},{value:"Authoring npm modules with TypeScript",id:"authoring-npm-modules-with-typescript",level:2},{value:"Port, port, port!!!",id:"port-port-port",level:2},{value:"PS I&#39;m not the only one",id:"ps-im-not-the-only-one",level:2},{value:"PPS Update 23/09/2015 09:51",id:"pps-update-23092015-0951",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"OK - the title's total clickbait but stay with me; there's a point here."),(0,a.kt)("p",null,"I'm a member of the Definitely Typed team - and hopefully I won't be kicked out for writing this. My point is this: ",(0,a.kt)("inlineCode",{parentName:"p"},".d.ts")," files should live with the package they provide typing information for, in npm / GitHub etc. Not separately. TypeScript 1.6 has just been released. Yay! In the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.com/b/typescript/archive/2015/09/16/announcing-typescript-1-6.aspx"}),"release blog post")," it says this:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"We\u2019ve changed module resolution when doing CommonJS output to work more closely to how Node does module resolution. If a module name is non-relative, we now follow these steps to find the associated typings:"),(0,a.kt)("ol",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ol"},"Check in ",(0,a.kt)("inlineCode",{parentName:"li"},"node_modules")," for ",(0,a.kt)("inlineCode",{parentName:"li"},"&lt;module name&gt;.d.ts")),(0,a.kt)("li",{parentName:"ol"},"Search ",(0,a.kt)("inlineCode",{parentName:"li"},"node_modules\\&lt;module name&gt;\\package.json")," for a ",(0,a.kt)("inlineCode",{parentName:"li"},"typings")," field"),(0,a.kt)("li",{parentName:"ol"},"Look for ",(0,a.kt)("inlineCode",{parentName:"li"},"node_modules\\&lt;module name&gt;\\index.d.ts")),(0,a.kt)("li",{parentName:"ol"},"Then we go one level higher and repeat the process")),(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("strong",{parentName:"p"},"Please note:")," when we search through node_modules, we assume these are the packaged node modules which have type information and a corresponding ",(0,a.kt)("inlineCode",{parentName:"p"},".js")," file. As such, we resolve only ",(0,a.kt)("inlineCode",{parentName:"p"},".d.ts")," files (not ",(0,a.kt)("inlineCode",{parentName:"p"},".ts")," file) for non-relative names."),(0,a.kt)("p",{parentName:"blockquote"},"Previously, we treated all module names as relative paths, and therefore we would never properly look in node_modules... We will continue to improve module resolution, including improvements to AMD, in upcoming releases.")),(0,a.kt)("p",null,"The TL;DR is this: consuming npm packages which come with definition files should JUST WORK\u2122... npm is now a first class citizen in TypeScriptLand. So everyone who has a package on npm should now feel duty bound to include a ",(0,a.kt)("inlineCode",{parentName:"p"},".d.ts")," when they publish and Definitely Typed can shut up shop. Simple right?"),(0,a.kt)("h2",o({},{id:"wrong"}),"Wrong!"),(0,a.kt)("p",null,"Yeah, it's never going to happen. Surprising as it is, there are many people who are quite happy without TypeScript in their lives (I know - mad right?). These poor unfortunates are unlikely to ever take the extra steps necessary to write definition files. For this reason, there will probably ",(0,a.kt)("em",{parentName:"p"},"always")," be a need for a provider of typings such as Definitely Typed. As well as that, the vast majority of people using TypeScript probably don't use npm to manage dependencies. There are, however, an increasing number of users who are using npm. Some (like me) may even be using tools like ",(0,a.kt)("a",o({parentName:"p"},{href:"http://browserify.org/"}),"Browserify")," (with the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/smrq/tsify"}),"TSIFY plugin"),") or ",(0,a.kt)("a",o({parentName:"p"},{href:"https://webpack.github.io/"}),"WebPack")," (with the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jbrantly/ts-loader"}),"TS loader"),") to bring it all together. My feeling is that, over time, using npm will become more common; particularly given the improvements being made to module resolution in the language."),(0,a.kt)("p",null,"An advantage of shipping typings with an npm package is this: those typings should accurately describe their accompanying package. In Definitely Typed we only aim to support the latest and greatest typings. So if you find yourself looking for the typings of an older version of a package you're going to have to pick your way back through the history of a ",(0,a.kt)("inlineCode",{parentName:"p"},".d.ts")," file and hope you happen upon the version you're looking for. Not a fantastic experience."),(0,a.kt)("p",null,"So I guess what I'm saying is this: if you're an npm package author then it would be fantastic to start shipping a package with typings in the box. If you're using npm to consume packages then using Definitely Typed ought to be the second step you might take after installing a package; the step you only need to take if the package doesn't come with typings. Using DT should be a fallback, not a default."),(0,a.kt)("h2",o({},{id:"authoring-npm-modules-with-typescript"}),"Authoring npm modules with TypeScript"),(0,a.kt)("p",null,"Yup - that's what this post is actually about. See how I lured you in with my mild trolling and pulled the old switcheroo? That's edutainment my friend. So, how do we write npm packages in TypeScript and publish them with their typings? Apparently Gandhi ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.nytimes.com/2011/08/30/opinion/falser-words-were-never-spoken.html?_r=0"}),"didn't actually say"),' "Be the change you wish to see in the world." Which is a shame. But anyway, I\'m going to try and embrace the sentiment here.'),(0,a.kt)("p",null,"Not so long ago I wrote a small npm module called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/globalize-so-what-cha-want"}),"globalize-so-what-cha-want"),". It is used to determine what parts of Globalize 1.x you need depending on the modules you're planning to use. It also, contains a little demo UI / online tool written in React which powers ",(0,a.kt)("a",o({parentName:"p"},{href:"http://johnnyreilly.github.io/globalize-so-what-cha-want/"}),"this"),"."),(0,a.kt)("p",null,"For this post, the purpose of the package is rather irrelevant. And even though I've just told you about it, I want you to pretend that the online tool doesn't exist. Pretend I never mentioned it."),(0,a.kt)("p",null,"What is relevant, and what I want you to think about, is this: I wrote globalize-so-what-cha-want in plain old, honest to goodness JavaScript. Old school."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://www.youtube.com/watch?v=V4YPFHyGWaY&feature=youtu.be&t=49s"}),"But, my love of static typing could be held in abeyance for only so long.")," Once the initial package was written, unit tested and published I got the itch. THIS SHOULD BE WRITTEN IN TYPESCRIPT!!! Well, it didn't have to be but I wanted it to be. Despite having used TypeScript since the early days I'd only been using it for front end work; not for writing npm packages. My mission was clear: port globalize-so-what-cha-want to TypeScript and re-publish to npm."),(0,a.kt)("h2",o({},{id:"port-port-port"}),"Port, port, port!!!"),(0,a.kt)("p",null,"At this point globalize-so-what-cha-want consisted of a single ",(0,a.kt)("inlineCode",{parentName:"p"},"index.js")," file in the root of the package. My end goal was to end up with that file still sat there, but now generated from TypeScript. Alongside it I wanted to see a ",(0,a.kt)("inlineCode",{parentName:"p"},"index.d.ts")," which was generated from the same TypeScript."),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"index.js"),(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/globalize-so-what-cha-want/tree/6cce84289134a555fe8462247b43eddb051303e3"}),"before")," looked like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"/* jshint varstmt: false, esnext: false */\nvar DEPENDENCY_TYPES = {\n  SHARED_JSON: 'Shared JSON (used by all locales)',\n  LOCALE_JSON: 'Locale specific JSON (supplied for each locale)',\n};\n\nvar moduleDependencies = {\n  core: {\n    dependsUpon: [],\n    cldrGlobalizeFiles: [\n      'cldr.js',\n      'cldr/event.js',\n      'cldr/supplemental.js',\n      'globalize.js',\n    ],\n    json: [\n      {\n        dependencyType: DEPENDENCY_TYPES.SHARED_JSON,\n        dependency: 'cldr/supplemental/likelySubtags.json',\n      },\n    ],\n  },\n\n  currency: {\n    dependsUpon: ['number', 'plural'],\n    cldrGlobalizeFiles: ['globalize/currency.js'],\n    json: [\n      {\n        dependencyType: DEPENDENCY_TYPES.LOCALE_JSON,\n        dependency: 'cldr/main/{locale}/currencies.json',\n      },\n      {\n        dependencyType: DEPENDENCY_TYPES.SHARED_JSON,\n        dependency: 'cldr/supplemental/currencyData.json',\n      },\n    ],\n  },\n\n  date: {\n    dependsUpon: ['number'],\n    cldrGlobalizeFiles: ['globalize/date.js'],\n    json: [\n      {\n        dependencyType: DEPENDENCY_TYPES.LOCALE_JSON,\n        dependency: 'cldr/main/{locale}/ca-gregorian.json',\n      },\n      {\n        dependencyType: DEPENDENCY_TYPES.LOCALE_JSON,\n        dependency: 'cldr/main/{locale}/timeZoneNames.json',\n      },\n      {\n        dependencyType: DEPENDENCY_TYPES.SHARED_JSON,\n        dependency: 'cldr/supplemental/timeData.json',\n      },\n      {\n        dependencyType: DEPENDENCY_TYPES.SHARED_JSON,\n        dependency: 'cldr/supplemental/weekData.json',\n      },\n    ],\n  },\n\n  message: {\n    dependsUpon: ['core'],\n    cldrGlobalizeFiles: ['globalize/message.js'],\n    json: [],\n  },\n\n  number: {\n    dependsUpon: ['core'],\n    cldrGlobalizeFiles: ['globalize/number.js'],\n    json: [\n      {\n        dependencyType: DEPENDENCY_TYPES.LOCALE_JSON,\n        dependency: 'cldr/main/{locale}/numbers.json',\n      },\n      {\n        dependencyType: DEPENDENCY_TYPES.SHARED_JSON,\n        dependency: 'cldr/supplemental/numberingSystems.json',\n      },\n    ],\n  },\n\n  plural: {\n    dependsUpon: ['core'],\n    cldrGlobalizeFiles: ['globalize/plural.js'],\n    json: [\n      {\n        dependencyType: DEPENDENCY_TYPES.SHARED_JSON,\n        dependency: 'cldr/supplemental/plurals.json',\n      },\n      {\n        dependencyType: DEPENDENCY_TYPES.SHARED_JSON,\n        dependency: 'cldr/supplemental/ordinals.json',\n      },\n    ],\n  },\n\n  relativeTime: {\n    dependsUpon: ['number', 'plural'],\n    cldrGlobalizeFiles: ['globalize/relative-time.js'],\n    json: [\n      {\n        dependencyType: DEPENDENCY_TYPES.LOCALE_JSON,\n        dependency: 'cldr/main/{locale}/dateFields.json',\n      },\n    ],\n  },\n};\n\nfunction determineRequiredCldrData(globalizeOptions) {\n  return determineRequired(\n    globalizeOptions,\n    _populateDependencyCurrier('json', function (json) {\n      return json.dependency;\n    })\n  );\n}\n\nfunction determineRequiredCldrGlobalizeFiles(globalizeOptions) {\n  return determineRequired(\n    globalizeOptions,\n    _populateDependencyCurrier(\n      'cldrGlobalizeFiles',\n      function (cldrGlobalizeFile) {\n        return cldrGlobalizeFile;\n      }\n    )\n  );\n}\n\nfunction determineRequired(globalizeOptions, populateDependencies) {\n  var modules = Object.keys(globalizeOptions);\n  modules.forEach(function (module) {\n    if (!moduleDependencies[module]) {\n      throw new TypeError(\"There is no '\" + module + \"' module\");\n    }\n  });\n\n  var requireds = [];\n  modules.forEach(function (module) {\n    if (globalizeOptions[module]) {\n      populateDependencies(module, requireds);\n    }\n  });\n\n  return requireds;\n}\n\nfunction _populateDependencyCurrier(requiredArray, requiredArrayGetter) {\n  var popDepFn = function (module, requireds) {\n    var dependencies = moduleDependencies[module];\n\n    dependencies.dependsUpon.forEach(function (requiredModule) {\n      popDepFn(requiredModule, requireds);\n    });\n\n    dependencies[requiredArray].forEach(function (required) {\n      var newRequired = requiredArrayGetter(required);\n      if (requireds.indexOf(newRequired) === -1) {\n        requireds.push(newRequired);\n      }\n    });\n\n    return requireds;\n  };\n\n  return popDepFn;\n}\n\nmodule.exports = {\n  determineRequiredCldrData: determineRequiredCldrData,\n  determineRequiredCldrGlobalizeFiles: determineRequiredCldrGlobalizeFiles,\n};\n")),(0,a.kt)("p",null,"You can even kind of tell that it was written in JavaScript thanks to the jshint rules at the top."),(0,a.kt)("p",null,"I fired up Atom and created a new folder ",(0,a.kt)("inlineCode",{parentName:"p"},"src/lib")," and inside there I created ",(0,a.kt)("inlineCode",{parentName:"p"},"index.ts")," (yes, ",(0,a.kt)("inlineCode",{parentName:"p"},"index.js")," renamed) and ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json"),". By the way, you'll notice I'm not leaving Atom - I'm making use of the magnificent ",(0,a.kt)("a",o({parentName:"p"},{href:"https://atom.io/packages/atom-typescript"}),"atom-typescript")," which you should totally be using too. It rocks."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(86686).Z,width:"640",height:"346"})),(0,a.kt)("p",null,"Now I'm not going to bore you with what I had to do to port the JS to TS (not much). If you're interested, the source is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/globalize-so-what-cha-want/blob/master/src/lib/index.ts"}),"here"),". What's more interesting is the ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," ","-"," as it's this that is going to lead the generation of the JS and TS that we need:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "compileOnSave": true,\n  "compilerOptions": {\n    "module": "commonjs",\n    "declaration": true,\n    "target": "es5",\n    "noImplicitAny": true,\n    "suppressImplicitAnyIndexErrors": true,\n    "removeComments": false,\n    "preserveConstEnums": true,\n    "sourceMap": false,\n    "outDir": "../../"\n  },\n  "files": ["index.ts"]\n}\n')),(0,a.kt)("p",null,"The things to notice are:"),(0,a.kt)("dl",null,(0,a.kt)("dt",null,"module"),(0,a.kt)("dd",null,"Publishing a commonjs module means it will play well with npm"),(0,a.kt)("dt",null,"declaration"),(0,a.kt)("dd",null,"This is what makes TypeScript generate ",(0,a.kt)("code",null,"index.d.ts")),(0,a.kt)("dt",null,"outDir"),(0,a.kt)("dd",null,"We want to regenerate the ",(0,a.kt)("code",null,"index.js")," in the root (2 directories above this)")),(0,a.kt)("p",null,"So now, what do we get when we build in Atom? Well, we're generating an ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/globalize-so-what-cha-want/blob/master/index.js"}),(0,a.kt)("inlineCode",{parentName:"a"},"index.js"))," file which looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var DEPENDENCY_TYPES = {\n  SHARED_JSON: 'Shared JSON (used by all locales)',\n  LOCALE_JSON: 'Locale specific JSON (supplied for each locale)',\n};\nvar moduleDependencies = {\n  core: {\n    dependsUpon: [],\n    cldrGlobalizeFiles: [\n      'cldr.js',\n      'cldr/event.js',\n      'cldr/supplemental.js',\n      'globalize.js',\n    ],\n    json: [\n      {\n        dependencyType: DEPENDENCY_TYPES.SHARED_JSON,\n        dependency: 'cldr/supplemental/likelySubtags.json',\n      },\n    ],\n  },\n  currency: {\n    dependsUpon: ['number', 'plural'],\n    cldrGlobalizeFiles: ['globalize/currency.js'],\n    json: [\n      {\n        dependencyType: DEPENDENCY_TYPES.LOCALE_JSON,\n        dependency: 'cldr/main/{locale}/currencies.json',\n      },\n      {\n        dependencyType: DEPENDENCY_TYPES.SHARED_JSON,\n        dependency: 'cldr/supplemental/currencyData.json',\n      },\n    ],\n  },\n  date: {\n    dependsUpon: ['number'],\n    cldrGlobalizeFiles: ['globalize/date.js'],\n    json: [\n      {\n        dependencyType: DEPENDENCY_TYPES.LOCALE_JSON,\n        dependency: 'cldr/main/{locale}/ca-gregorian.json',\n      },\n      {\n        dependencyType: DEPENDENCY_TYPES.LOCALE_JSON,\n        dependency: 'cldr/main/{locale}/timeZoneNames.json',\n      },\n      {\n        dependencyType: DEPENDENCY_TYPES.SHARED_JSON,\n        dependency: 'cldr/supplemental/timeData.json',\n      },\n      {\n        dependencyType: DEPENDENCY_TYPES.SHARED_JSON,\n        dependency: 'cldr/supplemental/weekData.json',\n      },\n    ],\n  },\n  message: {\n    dependsUpon: ['core'],\n    cldrGlobalizeFiles: ['globalize/message.js'],\n    json: [],\n  },\n  number: {\n    dependsUpon: ['core'],\n    cldrGlobalizeFiles: ['globalize/number.js'],\n    json: [\n      {\n        dependencyType: DEPENDENCY_TYPES.LOCALE_JSON,\n        dependency: 'cldr/main/{locale}/numbers.json',\n      },\n      {\n        dependencyType: DEPENDENCY_TYPES.SHARED_JSON,\n        dependency: 'cldr/supplemental/numberingSystems.json',\n      },\n    ],\n  },\n  plural: {\n    dependsUpon: ['core'],\n    cldrGlobalizeFiles: ['globalize/plural.js'],\n    json: [\n      {\n        dependencyType: DEPENDENCY_TYPES.SHARED_JSON,\n        dependency: 'cldr/supplemental/plurals.json',\n      },\n      {\n        dependencyType: DEPENDENCY_TYPES.SHARED_JSON,\n        dependency: 'cldr/supplemental/ordinals.json',\n      },\n    ],\n  },\n  relativeTime: {\n    dependsUpon: ['number', 'plural'],\n    cldrGlobalizeFiles: ['globalize/relative-time.js'],\n    json: [\n      {\n        dependencyType: DEPENDENCY_TYPES.LOCALE_JSON,\n        dependency: 'cldr/main/{locale}/dateFields.json',\n      },\n    ],\n  },\n};\nfunction determineRequired(globalizeOptions, populateDependencies) {\n  var modules = Object.keys(globalizeOptions);\n  modules.forEach(function (module) {\n    if (!moduleDependencies[module]) {\n      throw new TypeError(\"There is no '\" + module + \"' module\");\n    }\n  });\n  var requireds = [];\n  modules.forEach(function (module) {\n    if (globalizeOptions[module]) {\n      populateDependencies(module, requireds);\n    }\n  });\n  return requireds;\n}\nfunction _populateDependencyCurrier(requiredArray, requiredArrayGetter) {\n  var popDepFn = function (module, requireds) {\n    var dependencies = moduleDependencies[module];\n    dependencies.dependsUpon.forEach(function (requiredModule) {\n      popDepFn(requiredModule, requireds);\n    });\n    dependencies[requiredArray].forEach(function (required) {\n      var newRequired = requiredArrayGetter(required);\n      if (requireds.indexOf(newRequired) === -1) {\n        requireds.push(newRequired);\n      }\n    });\n    return requireds;\n  };\n  return popDepFn;\n}\n/**\n * The string array returned will contain a list of the required cldr json data you need. I don't believe ordering matters for the json but it is listed in the same dependency order as the cldr / globalize files are.\n *\n * @param options The globalize modules being used.\n */\nfunction determineRequiredCldrData(globalizeOptions) {\n  return determineRequired(\n    globalizeOptions,\n    _populateDependencyCurrier('json', function (json) {\n      return json.dependency;\n    })\n  );\n}\nexports.determineRequiredCldrData = determineRequiredCldrData;\n/**\n * The string array returned will contain a list of the required cldr / globalize files you need, listed in the order they are required.\n *\n * @param options The globalize modules being used.\n */\nfunction determineRequiredCldrGlobalizeFiles(globalizeOptions) {\n  return determineRequired(\n    globalizeOptions,\n    _populateDependencyCurrier(\n      'cldrGlobalizeFiles',\n      function (cldrGlobalizeFile) {\n        return cldrGlobalizeFile;\n      }\n    )\n  );\n}\nexports.determineRequiredCldrGlobalizeFiles =\n  determineRequiredCldrGlobalizeFiles;\n")),(0,a.kt)("p",null,"Aside from one method moving internally and me adding some JSDoc, the only really notable change is the end of the file. TypeScript, when generating commonjs, doesn't use the ",(0,a.kt)("inlineCode",{parentName:"p"},"module.exports = {}")," approach. Rather, it drops exported functions onto the ",(0,a.kt)("inlineCode",{parentName:"p"},"exports")," object as functions are exported. Functionally this is ",(0,a.kt)("em",{parentName:"p"},"identical"),"."),(0,a.kt)("p",null,"Now for our big finish: happily sat alongside is ",(0,a.kt)("inlineCode",{parentName:"p"},"index.js")," is the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/globalize-so-what-cha-want/blob/master/index.d.ts"}),(0,a.kt)("inlineCode",{parentName:"a"},"index.d.ts"))," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export interface Options {\n  currency?: boolean;\n  date?: boolean;\n  message?: boolean;\n  number?: boolean;\n  plural?: boolean;\n  relativeTime?: boolean;\n}\n/**\n * The string array returned will contain a list of the required cldr json data you need. I don't believe ordering matters for the json but it is listed in the same dependency order as the cldr / globalize files are.\n *\n * @param options The globalize modules being used.\n */\nexport declare function determineRequiredCldrData(\n  globalizeOptions: Options\n): string[];\n/**\n * The string array returned will contain a list of the required cldr / globalize files you need, listed in the order they are required.\n *\n * @param options The globalize modules being used.\n */\nexport declare function determineRequiredCldrGlobalizeFiles(\n  globalizeOptions: Options\n): string[];\n")),(0,a.kt)("p",null,"We're there, huzzah! This has been now published to npm - anyone consuming this package can use TypeScript straight out of the box. I really hope that publishing npm packages in this fashion becomes much more commonplace. Time will tell."),(0,a.kt)("h2",o({},{id:"ps-im-not-the-only-one"}),"PS I'm not the only one"),(0,a.kt)("p",null,'I was just about to hit "publish" when I happened upon ',(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/basarat"}),"Basarat"),"'s ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/basarat/ts-npm-module"}),"ts-npm-module")," which is a project on GitHub which demo's how to publish and consume TypeScript using npm. I'd say great minds think alike but I'm pretty sure Basarat's mind is far greater than mine! (Cough, atom-typescript, cough.) Either way, it's good to see validation for the approach I'm suggesting."),(0,a.kt)("h2",o({},{id:"pps-update-23092015-0951"}),"PPS Update 23/09/2015 09:51"),(0,a.kt)("p",null,"One of the useful things about writing a blog is that you get to learn. Since I published I've become aware of a few things somewhat relevant to this post. First of all, there is still work ongoing in TypeScript land around this topic. Essentially there are problems resolving dependency conflicts when different dependencies have different versions - you can take part in the ongoing discussion ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/issues/4665"}),"here"),". There's also some useful resources to look at:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/Microsoft/TypeScript/wiki/Typings-for-npm-packages"}),"https://github.com/Microsoft/TypeScript/wiki/Typings-for-npm-packages")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://basarat.gitbooks.io/typescript/content/docs/node/nodejs.html"}),"https://basarat.gitbooks.io/typescript/content/docs/node/nodejs.html"))))}d.isMDXComponent=!0},19551:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"jquery-validation-globalize-hits-10",title:"jQuery Validation Globalize hits 1.0",authors:"johnnyreilly",tags:["Globalize","jQuery Validation"],hide_table_of_contents:!1},s=void 0,l={permalink:"/jquery-validation-globalize-hits-10",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-10-05-jquery-validation-globalize-hits-10/index.md",source:"@site/blog/2015-10-05-jquery-validation-globalize-hits-10/index.md",title:"jQuery Validation Globalize hits 1.0",description:"This is just a quick post - the tl;dr is this: jQuery Validation Globalize has been ported to Globalize 1.x. Yay! In one of those twists of fate I'm not actually using this plugin in my day job anymore but I thought it might be useful to other people. So here you go. You can read more about this plugin in an older post and you can see a demo of it in action here.",date:"2015-10-05T00:00:00.000Z",formattedDate:"October 5, 2015",tags:[{label:"Globalize",permalink:"/tags/globalize"},{label:"jQuery Validation",permalink:"/tags/j-query-validation"}],readingTime:2.87,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"jquery-validation-globalize-hits-10",title:"jQuery Validation Globalize hits 1.0",authors:"johnnyreilly",tags:["Globalize","jQuery Validation"],hide_table_of_contents:!1},prevItem:{title:"The Names Have Been Changed...",permalink:"/the-names-have-been-changed"},nextItem:{title:"Definitely Typed Shouldn't Exist",permalink:"/authoring-npm-modules-with-typescript"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This is just a quick post - the tl;dr is this: jQuery Validation Globalize has been ported to Globalize 1.x. Yay! In one of those twists of fate I'm not actually using this plugin in my day job anymore but I thought it might be useful to other people. So here you go. You can read more about this plugin in an ",(0,a.kt)("a",o({parentName:"p"},{href:"/globalize-and-jquery-validate"}),"older post")," and you can see a demo of it in action ",(0,a.kt)("a",o({parentName:"p"},{href:"http://johnnyreilly.github.io/jQuery.Validation.Unobtrusive.Native/AdvancedDemo/Globalize.html"}),"here"),"."),(0,a.kt)("p",null,"The code did not change drastically - essentially it was just a question of swapping ",(0,a.kt)("inlineCode",{parentName:"p"},"parseFloat")," for ",(0,a.kt)("inlineCode",{parentName:"p"},"parseNumber")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"parseDate")," for a slightly different ",(0,a.kt)("inlineCode",{parentName:"p"},"parseDate"),". So, we went from this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"(function ($, Globalize) {\n  // Clone original methods we want to call into\n  var originalMethods = {\n    min: $.validator.methods.min,\n    max: $.validator.methods.max,\n    range: $.validator.methods.range,\n  };\n\n  // Tell the validator that we want numbers parsed using Globalize\n\n  $.validator.methods.number = function (value, element) {\n    var val = Globalize.parseFloat(value);\n    return this.optional(element) || $.isNumeric(val);\n  };\n\n  // Tell the validator that we want dates parsed using Globalize\n\n  $.validator.methods.date = function (value, element) {\n    var val = Globalize.parseDate(value);\n    return this.optional(element) || val instanceof Date;\n  };\n\n  // Tell the validator that we want numbers parsed using Globalize,\n  // then call into original implementation with parsed value\n\n  $.validator.methods.min = function (value, element, param) {\n    var val = Globalize.parseFloat(value);\n    return originalMethods.min.call(this, val, element, param);\n  };\n\n  $.validator.methods.max = function (value, element, param) {\n    var val = Globalize.parseFloat(value);\n    return originalMethods.max.call(this, val, element, param);\n  };\n\n  $.validator.methods.range = function (value, element, param) {\n    var val = Globalize.parseFloat(value);\n    return originalMethods.range.call(this, val, element, param);\n  };\n})(jQuery, Globalize);\n")),(0,a.kt)("p",null,"To this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"(function ($, Globalize) {\n  // Clone original methods we want to call into\n  var originalMethods = {\n    min: $.validator.methods.min,\n    max: $.validator.methods.max,\n    range: $.validator.methods.range,\n  };\n\n  // Globalize options - initially just the date format used for parsing\n  // Users can customise this to suit them\n  $.validator.methods.dateGlobalizeOptions = {\n    dateParseFormat: { skeleton: 'yMd' },\n  };\n\n  // Tell the validator that we want numbers parsed using Globalize\n  $.validator.methods.number = function (value, element) {\n    var val = Globalize.parseNumber(value);\n    return this.optional(element) || $.isNumeric(val);\n  };\n\n  // Tell the validator that we want dates parsed using Globalize\n  $.validator.methods.date = function (value, element) {\n    var val = Globalize.parseDate(\n      value,\n      $.validator.methods.dateGlobalizeOptions.dateParseFormat\n    );\n    return this.optional(element) || val instanceof Date;\n  };\n\n  // Tell the validator that we want numbers parsed using Globalize,\n  // then call into original implementation with parsed value\n\n  $.validator.methods.min = function (value, element, param) {\n    var val = Globalize.parseNumber(value);\n    return originalMethods.min.call(this, val, element, param);\n  };\n\n  $.validator.methods.max = function (value, element, param) {\n    var val = Globalize.parseNumber(value);\n    return originalMethods.max.call(this, val, element, param);\n  };\n\n  $.validator.methods.range = function (value, element, param) {\n    var val = Globalize.parseNumber(value);\n    return originalMethods.range.call(this, val, element, param);\n  };\n})(jQuery, Globalize);\n")),(0,a.kt)("p",null,"All of which is pretty self-explanatory. The only thing I'd like to draw out is that Globalize 0.1.x didn't force you to specify a date parsing format and, as I recall, would attempt various methods of parsing. For that reason jQuery Validation Globalize 1.0 exposes a ",(0,a.kt)("inlineCode",{parentName:"p"},"$.validator.methods.dateGlobalizeOptions")," which allows you to specify the data parsing format you want to use. This means, should you be using a different format than the out of the box one then you can tweak it like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"$.validator.methods.dateGlobalizeOptions.dateParseFormat = // your data parsing format goes here...\n")),(0,a.kt)("p",null,"Theoretically, this functionality could be tweaked to allow the user to specify multiple possible date parsing formats to attempt. I'm not certain if that's a good idea though, so it remains unimplemented for now."))}d.isMDXComponent=!0},25419:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"the-names-have-been-changed",title:"The Names Have Been Changed...",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},s=void 0,l={permalink:"/the-names-have-been-changed",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-10-23-the-names-have-been-changed/index.md",source:"@site/blog/2015-10-23-the-names-have-been-changed/index.md",title:"The Names Have Been Changed...",description:"...to protect my wallet.",date:"2015-10-23T00:00:00.000Z",formattedDate:"October 23, 2015",tags:[],readingTime:.75,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"the-names-have-been-changed",title:"The Names Have Been Changed...",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},prevItem:{title:"IQueryable... IEnumerable... Hmmm...",permalink:"/iqueryable-ienumerable-hmmm"},nextItem:{title:"jQuery Validation Globalize hits 1.0",permalink:"/jquery-validation-globalize-hits-10"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"...to protect my wallet."),(0,a.kt)("p",null,"Subsequent to this blog getting ",(0,a.kt)("a",o({parentName:"p"},{href:"/whats-in-a-name"}),"a proper domain name a year ago")," it's now got a new one. That's right, ",(0,a.kt)("inlineCode",{parentName:"p"},"blog.icanmakethiswork.io")," is dead! Long live ",(0,a.kt)("inlineCode",{parentName:"p"},"blog.johnnyreilly.com"),"!"),(0,a.kt)("p",null,"There's nothing particularly exciting about this, it's more that ",(0,a.kt)("inlineCode",{parentName:"p"},".io")," domain names are ",(0,a.kt)("em",{parentName:"p"},"wayyyyy")," expensive. And also I noticed that johnnyreilly.com was available. By an accident of history I've ended up either being johnny_reilly or johnnyreilly online. (\"",(0,a.kt)("a",o({parentName:"p"},{href:"mailto:johnreilly@hotmail.com"}),"johnreilly@hotmail.com"),'" was already taken back in 2000 and "johnny',"_",(0,a.kt)("a",o({parentName:"p"},{href:"mailto:reilly@hotmail.com"}),"reilly@hotmail.com"),"\" was available. I've subsequently become ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/johnny_reilly"}),"@johnny_reilly")," on Twitter, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly"}),"johnnyreilly")," on GitHub so I guess you could say it's stuck.)"),(0,a.kt)("p",null,"So I thought I'd kill 2 birds with one stone and make the switch. I've set up a redirect on ",(0,a.kt)("a",o({parentName:"p"},{href:"http://blog.icanmakethiswork.io"}),"blog.icanmakethiswork.io")," and so, anyone who goes to the old site should be 301'd over here. At least until my old domain name expires. Last time it'll change I promise. Well.... until next time anyway..."))}d.isMDXComponent=!0},54334:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"iqueryable-ienumerable-hmmm",title:"IQueryable... IEnumerable... Hmmm...",authors:"johnnyreilly",tags:["LINQ"],hide_table_of_contents:!1},s=void 0,l={permalink:"/iqueryable-ienumerable-hmmm",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-11-30-iqueryable-ienumerable-hmmm/index.md",source:"@site/blog/2015-11-30-iqueryable-ienumerable-hmmm/index.md",title:"IQueryable... IEnumerable... Hmmm...",description:"So there I was, tip-tapping away at my keyboard when I became aware of the slowly loudening noise of a debate. It wasn't about poverty, war, civil rights or anything like that. No; this was far more contentious. It was about the behaviour of IQueryable&lt;T&gt; when mixed with IEnumerable&lt;T&gt;. I know, right, how could I not get involved?",date:"2015-11-30T00:00:00.000Z",formattedDate:"November 30, 2015",tags:[{label:"LINQ",permalink:"/tags/linq"}],readingTime:4.365,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"iqueryable-ienumerable-hmmm",title:"IQueryable... IEnumerable... Hmmm...",authors:"johnnyreilly",tags:["LINQ"],hide_table_of_contents:!1},prevItem:{title:"ES6 + TypeScript + Babel + React + Flux + Karma: The Secret Recipe",permalink:"/es6-typescript-babel-react-flux-karma"},nextItem:{title:"The Names Have Been Changed...",permalink:"/the-names-have-been-changed"}},p={authorsImageUrls:[void 0]},u=[{value:"LINQ to Objects vs LINQ to ... ?",id:"linq-to-objects-vs-linq-to--",level:2},{value:"Fixing the Problem",id:"fixing-the-problem",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"So there I was, tip-tapping away at my keyboard when I became aware of the slowly loudening noise of a debate. It wasn't about poverty, war, civil rights or anything like that. No; this was far more contentious. It was about the behaviour of ",(0,a.kt)("inlineCode",{parentName:"p"},'<a href="https://msdn.microsoft.com/en-gb/library/bb351562(v=vs.100).aspx">IQueryable&lt;T&gt;</a>')," when mixed with ",(0,a.kt)("inlineCode",{parentName:"p"},'<a href="https://msdn.microsoft.com/en-gb/library/9eekhta0(v=vs.100).aspx">IEnumerable&lt;T&gt;</a>'),". I know, right, how could I not get involved?"),(0,a.kt)("p",null,"The code that was being debated was a database query that was being facilitated by Entity Framework. Now let me ask you a question: what is the problem with the methods below?"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"private IEnumerable<Sage> GetSagesWithSayings()\n{\n    IQueryable<Sage> sageWithSayings =\n        from s in DbContext.Sages.Include(x => x.Sayings)\n        select s;\n\n    return sageWithSayings;\n}\n\npublic IEnumerable<Sage> GetSagesWithSayingsBornWithinTheLast100Years()\n{\n    var aHundredYearsAgo = DateTime.Now.AddYears(-100);\n    var sageWithSayings = GetSagesWithSayings().Where(x => x.DateOfBirth > aHundredYearsAgo);\n\n    return sageWithSayings;\n}\n")),(0,a.kt)("p",null,"I've rather emphasised the problem by expressly declaring types in the ",(0,a.kt)("inlineCode",{parentName:"p"},"GetSagesWithSayings")," method. More typically the ",(0,a.kt)("inlineCode",{parentName:"p"},"IQueryable&lt;Sage&gt;")," would be hiding itself beneath a ",(0,a.kt)("inlineCode",{parentName:"p"},"var")," making the problem less obvious. But you get the point; it's something to do with an ",(0,a.kt)("inlineCode",{parentName:"p"},"IQueryable&lt;Sage&gt;")," being passed back as an ",(0,a.kt)("inlineCode",{parentName:"p"},"IEnumerable&lt;Sage&gt;"),"."),(0,a.kt)("p",null,'The debate was raging around what this piece of code (or one much like it) actually did. One side positing "it\'ll get every record from the database and then throw away what it doesn\'t need in C#-land..." The opposing view being "are you sure about that? Doesn\'t it just get the records from the last hundred years from the database?"'),(0,a.kt)("p",null,"So it comes down the SQL that ends up being generated. On the one hand it's going to get everything from the Sages table..."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-sql"}),"select ...\nfrom Sages ...\n")),(0,a.kt)("p",null,"Or does it include a filter clause as well?"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-sql"}),"select ...\nfrom Sages ...\nwhere DateOfBirth > '1915-11-30'\n")),(0,a.kt)("p",null,"You probably know the answer... It gets everything. Every record is brought back from the database and those that are older than 100 years are then casually thrown away. So kinda wasteful. That's the problem. But why? And what does that tell us?"),(0,a.kt)("h2",o({},{id:"linq-to-objects-vs-linq-to--"}),"LINQ to Objects vs LINQ to ... ?"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},'The term "LINQ to Objects" refers to the use of LINQ queries with any ',(0,a.kt)("inlineCode",{parentName:"p"},"IEnumerable")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"IEnumerable&lt;T&gt;")," collection directly, without the use of an intermediate LINQ provider or API such as LINQ to SQL or LINQ to XML.")),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"The ",(0,a.kt)("inlineCode",{parentName:"p"},'<a href="https://msdn.microsoft.com/en-gb/library/bb351562(v=vs.100).aspx">IQueryable&lt;T&gt;</a>')," interface is intended for implementation by query providers."),(0,a.kt)("p",{parentName:"blockquote"},"This interface inherits the ",(0,a.kt)("inlineCode",{parentName:"p"},'<a href="https://msdn.microsoft.com/en-gb/library/9eekhta0(v=vs.100).aspx">IEnumerable&lt;T&gt;</a>')," interface so that if it represents a query, the results of that query can be enumerated. Enumeration forces the expression tree associated with an ",(0,a.kt)("inlineCode",{parentName:"p"},'<a href="https://msdn.microsoft.com/en-gb/library/bb351562(v=vs.100).aspx">IQueryable&lt;T&gt;</a>')," object to be executed. Queries that do not return enumerable results are executed when the ",(0,a.kt)("inlineCode",{parentName:"p"},'<a href="https://msdn.microsoft.com/en-gb/library/bb549414(v=vs.100).aspx">Execute&lt;TResult&gt;(Expression)</a>')," method is called."),(0,a.kt)("p",{parentName:"blockquote"},'The definition of "executing an expression tree" is specific to a query provider. For example, it may involve translating the expression tree to a query language appropriate for an underlying data source.')),(0,a.kt)("p",null,'I know - check me out with my "quotes".'),(0,a.kt)("p",null,"Now, ",(0,a.kt)("inlineCode",{parentName:"p"},"IEnumerable")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"IQueryable"),' are similar; for instance they are both considered "lazy" as they offer deferred execution. But there is an important difference between ',(0,a.kt)("inlineCode",{parentName:"p"},"IEnumerable")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"IQueryable"),"; namely that ",(0,a.kt)("inlineCode",{parentName:"p"},"IQueryable")," hands off information about a query to another provider in order that they may decide how to do the necessary work. ",(0,a.kt)("inlineCode",{parentName:"p"},"IEnumerable")," does not; its work is done in memory by operating on the data it has."),(0,a.kt)("p",null,"So let's apply this to our issue. We have an ",(0,a.kt)("inlineCode",{parentName:"p"},"IQueryable&lt;Sage&gt;")," and we return it as an ",(0,a.kt)("inlineCode",{parentName:"p"},"IEnumerable&lt;Sage&gt;"),". By doing this we haven't changed the underlying type; it's still an ",(0,a.kt)("inlineCode",{parentName:"p"},"IQueryable&lt;Sage&gt;"),". But by upcasting to ",(0,a.kt)("inlineCode",{parentName:"p"},"IEnumerable&lt;Sage&gt;")," we have told the compiler that we don't have an ",(0,a.kt)("inlineCode",{parentName:"p"},"IQueryable&lt;Sage&gt;"),". We've lied. I trust you're feeling guilty."),(0,a.kt)("p",null,"No doubt whoever raised you told you not to tell lies. This was probably the very situation they had in mind. The implications of our dirty little fib come back to haunt us when we start to chain on subsequent filters. So when we perform our filter of ",(0,a.kt)("inlineCode",{parentName:"p"},".Where(x =&gt; x.DateOfBirth &gt; aHundredYearsAgo)")," the compiler isn't going to get LINQ to Entities's extension methods in on this. No, it's going to get the LINQ to object extension methods instead."),(0,a.kt)("p",null,"This is the cause of our problem. When it comes to execution we're not getting the database to do the heavy lifting because we've moved away from using ",(0,a.kt)("inlineCode",{parentName:"p"},"IQueryable"),"."),(0,a.kt)("h2",o({},{id:"fixing-the-problem"}),"Fixing the Problem"),(0,a.kt)("p",null,"There are 2 courses of action open to you. The obvious course of action (and 99% of the time what you'd look to do) is change the signature of the `` method to return an IQueryable like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"private IQueryable<Sage> GetSagesWithSayings()\n    var sageWithSayings = // I prefer 'var', don't you?\n        from s in DbContext.Sages.Include(x => x.Sayings)\n        select s;\n\n    return sageWithSayings;\n}\n")),(0,a.kt)("p",null,'The other alternative is what I like to think of as "the escape hatch": ',(0,a.kt)("inlineCode",{parentName:"p"},'<a href="https://msdn.microsoft.com/en-gb/library/bb353734(v=vs.100).aspx">AsQueryable</a>'),". This takes an ",(0,a.kt)("inlineCode",{parentName:"p"},"IEnumerable"),", checks if it's actually an ",(0,a.kt)("inlineCode",{parentName:"p"},"IQueryable")," slumming it and casts back to that if it is. You might use this in a situation where you didn't have control over the data access code. Using it looks like this: (and would work whether ",(0,a.kt)("inlineCode",{parentName:"p"},"GetSagesWithSayings")," was returning ",(0,a.kt)("inlineCode",{parentName:"p"},"IEnumerable"),(0,a.kt)("em",{parentName:"p"},"or"),(0,a.kt)("inlineCode",{parentName:"p"},"IQueryable"),")"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public IEnumerable<Sage> GetSagesWithSayingsBornWithinTheLast100Years()\n{\n    var aHundredYearsAgo = DateTime.Now.AddYears(-100);\n    var sageWithSayings =GetSagesWithSayings().AsQueryable().Where(x => x.DateOfBirth > aHundredYearsAgo);\n\n    return sageWithSayings;\n}\n")))}d.isMDXComponent=!0},46098:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"es6-typescript-babel-react-flux-karma",title:"ES6 + TypeScript + Babel + React + Flux + Karma: The Secret Recipe",authors:"johnnyreilly",tags:["ES6","Karma","React","ts-loader","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/es6-typescript-babel-react-flux-karma",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-12-16-es6-typescript-babel-react-flux-karma/index.md",source:"@site/blog/2015-12-16-es6-typescript-babel-react-flux-karma/index.md",title:"ES6 + TypeScript + Babel + React + Flux + Karma: The Secret Recipe",description:"I wrote a while ago about how I was using some different tools in a current project:",date:"2015-12-16T00:00:00.000Z",formattedDate:"December 16, 2015",tags:[{label:"ES6",permalink:"/tags/es-6"},{label:"Karma",permalink:"/tags/karma"},{label:"React",permalink:"/tags/react"},{label:"ts-loader",permalink:"/tags/ts-loader"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:13.65,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"es6-typescript-babel-react-flux-karma",title:"ES6 + TypeScript + Babel + React + Flux + Karma: The Secret Recipe",authors:"johnnyreilly",tags:["ES6","Karma","React","ts-loader","webpack"],hide_table_of_contents:!1},prevItem:{title:"Live Reload Considered Harmful",permalink:"/live-reload-considered-harmful"},nextItem:{title:"IQueryable... IEnumerable... Hmmm...",permalink:"/iqueryable-ienumerable-hmmm"}},p={authorsImageUrls:[void 0]},u=[{value:"What a Guy Wants",id:"what-a-guy-wants",level:2},{value:"gulpfile.js",id:"gulpfilejs",level:2},{value:"WebPack",id:"webpack",level:2},{value:"Inject",id:"inject",level:2},{value:"Static Files",id:"static-files",level:2},{value:"Karma",id:"karma",level:2},{value:"Babel 5 -&gt; Babel 6",id:"babel-5---babel-6",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I wrote ",(0,a.kt)("a",o({parentName:"p"},{href:"/things-done-changed"}),"a while ago")," about how I was using some different tools in a current project:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"React with JSX"),(0,a.kt)("li",{parentName:"ul"},"Flux"),(0,a.kt)("li",{parentName:"ul"},"ES6 with Babel"),(0,a.kt)("li",{parentName:"ul"},"Karma for unit testing")),(0,a.kt)("p",null,"I have fully come to love and appreciate all of the above. I really like working with them. However. There was still an ache in my soul and a thorn in my side. Whilst I love the syntax of ES6 and even though I've come to appreciate the clarity of JSX, I have been missing something. Perhaps you can guess? It's static typing."),(0,a.kt)("p",null,"It's actually been really good to have the chance to work without it because it's made me realise what a productivity boost having static typing actually is. The number of silly mistakes burning time that a compiler could have told me.... Sigh."),(0,a.kt)("p",null,"But the pain is over. The dark days are gone. It's possible to have strong typing, courtesy of TypeScript, plugged into this workflow. It's yours for the taking. Take it. Take it now!"),(0,a.kt)("h2",o({},{id:"what-a-guy-wants"}),"What a Guy Wants"),(0,a.kt)("p",null,"I decided a couple of months ago what I wanted to have in my setup:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"I want to be able to write React / JSX in TypeScript. Naturally I couldn't achieve that by myself but handily the TypeScript team decided to add support for JSX with ",(0,a.kt)("a",o({parentName:"li"},{href:"https://blogs.msdn.com/b/typescript/archive/2015/09/16/announcing-typescript-1-6.aspx"}),"TypeScript 1.6"),". Ooh yeah."),(0,a.kt)("li",{parentName:"ol"},"I wanted to be able to write ES6. When I realised ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/Microsoft/TypeScript/issues/3956"}),"the approach for writing ES6 and having the transpilation handled by TypeScript wasn't clear")," I had another idea. I thought ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/Microsoft/TypeScript/issues/4765"}),'"what if I write ES6 and hand off the transpilation to Babel?"')," i.e. Use TypeScript for type checking, not for transpilation. I realised that ",(0,a.kt)("a",o({parentName:"li"},{href:"http://www.jbrantly.com/es6-modules-with-typescript-and-webpack/#configuringwebpack"}),"James Brantly had my back")," here already. Enter ",(0,a.kt)("a",o({parentName:"li"},{href:"https://webpack.github.io/"}),"Webpack")," and ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/TypeStrong/ts-loader"}),"ts-loader"),"."),(0,a.kt)("li",{parentName:"ol"},"Debugging. Being able to debug my code is non-negotiable for me. If I can't debug it I'm less productive. (I'm also bitter and twisted inside.) I should say that I wanted to be able to debug my ",(0,a.kt)("em",{parentName:"li"},"original")," source code. Thanks to the magic of ",(0,a.kt)("a",o({parentName:"li"},{href:"https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit?usp=sharing"}),"sourcemaps"),", that mad thing is possible."),(0,a.kt)("li",{parentName:"ol"},"Karma for unit testing. I've become accustomed to writing my tests in ES6 and running them on a continual basis with ",(0,a.kt)("a",o({parentName:"li"},{href:"https://karma-runner.github.io/0.13/index.html"}),"Karma"),". This allows for a rather good debugging story as well. I didn't want to lose this when I moved to TypeScript. I didn't.")),(0,a.kt)("p",null,"So I've talked about what I want and I've alluded to some of the solutions that there are. The question now is how to bring them all together. This post is, for the most part, going to be about correctly orchestrating a number of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://gulpjs.com/"}),"gulp tasks")," to achieve the goals listed above. If you're after the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Blue_Peter"}),'Blue Peter "here\'s one I made earlier"')," moment then take a look at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScriptSamples/tree/master/es6-babel-react-flux-karma"}),"the es6-babel-react-flux-karma repo")," in the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScriptSamples"}),"Microsoft/TypeScriptSamples repo on Github"),"."),(0,a.kt)("h2",o({},{id:"gulpfilejs"}),"gulpfile.js"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"/* eslint-disable no-var, strict, prefer-arrow-callback */\n'use strict';\n\nvar gulp = require('gulp');\nvar gutil = require('gulp-util');\nvar connect = require('gulp-connect');\nvar eslint = require('gulp-eslint');\nvar webpack = require('./gulp/webpack');\nvar staticFiles = require('./gulp/staticFiles');\nvar tests = require('./gulp/tests');\nvar clean = require('./gulp/clean');\nvar inject = require('./gulp/inject');\n\nvar lintSrcs = ['./gulp/**/*.js'];\n\ngulp.task('delete-dist', function (done) {\n  clean.run(done);\n});\n\ngulp.task('build-process.env.NODE_ENV', function () {\n  process.env.NODE_ENV = 'production';\n});\n\ngulp.task(\n  'build-js',\n  ['delete-dist', 'build-process.env.NODE_ENV'],\n  function (done) {\n    webpack.build().then(function () {\n      done();\n    });\n  }\n);\n\ngulp.task(\n  'build-other',\n  ['delete-dist', 'build-process.env.NODE_ENV'],\n  function () {\n    staticFiles.build();\n  }\n);\n\ngulp.task('build', ['build-js', 'build-other', 'lint'], function () {\n  inject.build();\n});\n\ngulp.task('lint', function () {\n  return gulp.src(lintSrcs).pipe(eslint()).pipe(eslint.format());\n});\n\ngulp.task('watch', ['delete-dist'], function () {\n  process.env.NODE_ENV = 'development';\n  Promise.all([\n    webpack.watch(), //,\n    //less.watch()\n  ])\n    .then(function () {\n      gutil.log(\n        'Now that initial assets (js and css) are generated inject will start...'\n      );\n      inject.watch(postInjectCb);\n    })\n    .catch(function (error) {\n      gutil.log('Problem generating initial assets (js and css)', error);\n    });\n\n  gulp.watch(lintSrcs, ['lint']);\n  staticFiles.watch();\n  tests.watch();\n});\n\ngulp.task('watch-and-serve', ['watch'], function () {\n  postInjectCb = stopAndStartServer;\n});\n\nvar postInjectCb = null;\nvar serverStarted = false;\nfunction stopAndStartServer() {\n  if (serverStarted) {\n    gutil.log('Stopping server');\n    connect.serverClose();\n    serverStarted = false;\n  }\n  startServer();\n}\n\nfunction startServer() {\n  gutil.log('Starting server');\n  connect.server({\n    root: './dist',\n    port: 8080,\n  });\n  serverStarted = true;\n}\n")),(0,a.kt)("p",null,"Let's start picking this apart; what do we actually have here? Well, we have 2 gulp tasks that I want you to notice:"),(0,a.kt)("dl",null,(0,a.kt)("dt",null,"build"),(0,a.kt)("dd",null,(0,a.kt)("p",null,"This is likely the task you would use when deploying. It takes all of your source code, builds it, provides cache-busting filenames (eg ",(0,a.kt)("code",null,"main.dd2fa20cd9eac9d1fb2f.js"),"), injects your shell SPA page with references to the files and deploys everything to the ",(0,a.kt)("code",null,"./dist/")," directory. So that's TypeScript, static assets like images and CSS all made ready for Production."),(0,a.kt)("p",null,"The build task also implements ",(0,a.kt)("a",{href:"https://facebook.github.io/react/blog/2015/09/10/react-v0.14-rc1.html"},"this advice"),":"),(0,a.kt)("blockquote",{cite:"https://facebook.github.io/react/blog/2015/09/10/react-v0.14-rc1.html"},"When deploying your app, set the ",(0,a.kt)("code",null,"NODE_ENV")," environment variable to ",(0,a.kt)("code",null,"production")," to use the production build of React which does not include the development warnings and runs significantly faster. ")),(0,a.kt)("dt",null,"watch-and-serve"),(0,a.kt)("dd",null,(0,a.kt)("p",null,'This task represents "development mode" or "debug mode". It\'s what you\'ll likely be running as you develop your app. It does the same as the build task but with some important distinctions.'),(0,a.kt)("ul",null,(0,a.kt)("li",null,"As well as building your source it also runs your tests using Karma"),(0,a.kt)("li",null,"This task is not triggered on a once-only basis, rather your files are watched and each tweak of a file will result in a new build and a fresh run of your tests. Nice eh?"),(0,a.kt)("li",null,"It spins up a simple web server and serves up the contents of ",(0,a.kt)("code",null,"./dist")," (i.e. your built code) in order that you can easily test out your app."),(0,a.kt)("li",null,"In addition, whilst it builds your source it does ",(0,a.kt)("em",null,"not")," minify your code and it emits sourcemaps. For why? For debugging! You can go to ",(0,a.kt)("code",null,(0,a.kt)("a",{href:"http://localhost:8080/"},"http://localhost:8080/"))," in your browser of choice, fire up the dev tools and you're off to the races; debugging like gangbusters. It also doesn't bother to provide cache-busting filenames as Chrome dev tools are smart enough to not cache localhost."),(0,a.kt)("li",null,"Oh and Karma.... If you've got problems with a failing test then head to ",(0,a.kt)("code",null,(0,a.kt)("a",{href:"http://localhost:9876/"},"http://localhost:9876/"))," and you can debug the tests in your dev tools."),(0,a.kt)("li",null,'Finally, it runs ESLint in the console. Not all of my files are TypeScript; essentially the build process (aka "gulp-y") files are all vanilla JS. So they\'re easily breakable. ESLint is there to provide a little reassurance on that front.')))),(0,a.kt)("p",null,"Now let's dig into each of these in a little more detail"),(0,a.kt)("h2",o({},{id:"webpack"}),"WebPack"),(0,a.kt)("p",null,"Let's take a look at what's happening under the covers of ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.build()")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.watch()"),"."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/webpack"}),"WebPack")," with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader"}),"ts-loader")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/babel/babel-loader"}),"babel-loader")," is what we're using to compile our ES6 TypeScript. ts-loader uses the TypeScript compiler to, um, compile TypeScript and emit ES6 code. This is then passed on to the babel-loader which transpiles it from ES6 down to ES-old-school. It all gets brought together in 2 files; ",(0,a.kt)("inlineCode",{parentName:"p"},"main.js")," which contains the compiled result of the code written by us and ",(0,a.kt)("inlineCode",{parentName:"p"},"vendor.js")," which contains the compiled result of 3rd party / vendor files. The reason for this separation is that vendor files are likely to change fairly rarely whilst our own code will constantly be changing. This separation allows for quicker compile times upon file changes as, for the most part, the vendor files will not need to included in this process."),(0,a.kt)("p",null,"Our ",(0,a.kt)("inlineCode",{parentName:"p"},"gulpfile.js")," above uses the following task:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"'use strict';\n\nvar gulp = require('gulp');\nvar gutil = require('gulp-util');\nvar webpack = require('webpack');\nvar WebpackNotifierPlugin = require('webpack-notifier');\nvar webpackConfig = require('../webpack.config.js');\n\nfunction buildProduction(done) {\n  // modify some webpack config options\n  var myProdConfig = Object.create(webpackConfig);\n  myProdConfig.output.filename = '[name].[hash].js';\n\n  myProdConfig.plugins = myProdConfig.plugins.concat(\n    // make the vendor.js file with cachebusting filename\n    new webpack.optimize.CommonsChunkPlugin({\n      name: 'vendor',\n      filename: 'vendor.[hash].js',\n    }),\n    new webpack.optimize.DedupePlugin(),\n    new webpack.optimize.UglifyJsPlugin()\n  );\n\n  // run webpack\n  webpack(myProdConfig, function (err, stats) {\n    if (err) {\n      throw new gutil.PluginError('webpack:build', err);\n    }\n    gutil.log(\n      '[webpack:build]',\n      stats.toString({\n        colors: true,\n      })\n    );\n\n    if (done) {\n      done();\n    }\n  });\n}\n\nfunction createDevCompiler() {\n  // show me some sourcemap love people\n  var myDevConfig = Object.create(webpackConfig);\n  myDevConfig.devtool = 'inline-source-map';\n  myDevConfig.debug = true;\n\n  myDevConfig.plugins = myDevConfig.plugins.concat(\n    // Make the vendor.js file\n    new webpack.optimize.CommonsChunkPlugin({\n      name: 'vendor',\n      filename: 'vendor.js',\n    }),\n    new WebpackNotifierPlugin({ title: 'Webpack build', excludeWarnings: true })\n  );\n\n  // create a single instance of the compiler to allow caching\n  return webpack(myDevConfig);\n}\n\nfunction buildDevelopment(done, devCompiler) {\n  // run webpack\n  devCompiler.run(function (err, stats) {\n    if (err) {\n      throw new gutil.PluginError('webpack:build-dev', err);\n    }\n    gutil.log(\n      '[webpack:build-dev]',\n      stats.toString({\n        chunks: false, // dial down the output from webpack (it can be noisy)\n        colors: true,\n      })\n    );\n\n    if (done) {\n      done();\n    }\n  });\n}\n\nfunction bundle(options) {\n  var devCompiler;\n\n  function build(done) {\n    if (options.shouldWatch) {\n      buildDevelopment(done, devCompiler);\n    } else {\n      buildProduction(done);\n    }\n  }\n\n  if (options.shouldWatch) {\n    devCompiler = createDevCompiler();\n\n    gulp.watch('src/**/*', function () {\n      build();\n    });\n  }\n\n  return new Promise(function (resolve, reject) {\n    build(function (err) {\n      if (err) {\n        reject(err);\n      } else {\n        resolve('webpack built');\n      }\n    });\n  });\n}\n\nmodule.exports = {\n  build: function () {\n    return bundle({ shouldWatch: false });\n  },\n  watch: function () {\n    return bundle({ shouldWatch: true });\n  },\n};\n")),(0,a.kt)("p",null,"Hopefully this is fairly self-explanatory; essentially ",(0,a.kt)("inlineCode",{parentName:"p"},"buildDevelopment")," performs the development build (providing sourcemap support) and ",(0,a.kt)("inlineCode",{parentName:"p"},"buildProduction")," builds for Production (providing minification support). Both are driven by this ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"/* eslint-disable no-var, strict, prefer-arrow-callback */\n'use strict';\n\nvar path = require('path');\n\nmodule.exports = {\n  cache: true,\n  entry: {\n    // The entry point of our application; the script that imports all other scripts in our SPA\n    main: './src/main.tsx',\n\n    // The packages that are to be included in vendor.js\n    vendor: ['babel-polyfill', 'events', 'flux', 'react'],\n  },\n\n  // Where the output of our compilation ends up\n  output: {\n    path: path.resolve(__dirname, './dist/scripts'),\n    filename: '[name].js',\n    chunkFilename: '[chunkhash].js',\n  },\n\n  module: {\n    loaders: [\n      {\n        // The loader that handles ts and tsx files.  These are compiled\n        // with the ts-loader and the output is then passed through to the\n        // babel-loader.  The babel-loader uses the es2015 and react presets\n        // in order that jsx and es6 are processed.\n        test: /\\.ts(x?)$/,\n        exclude: /node_modules/,\n        loader: 'babel-loader?presets[]=es2015&presets[]=react!ts-loader',\n      },\n      {\n        // The loader that handles any js files presented alone.\n        // It passes these to the babel-loader which (again) uses the es2015\n        // and react presets.\n        test: /\\.js$/,\n        exclude: /node_modules/,\n        loader: 'babel',\n        query: {\n          presets: ['es2015', 'react'],\n        },\n      },\n    ],\n  },\n  plugins: [],\n  resolve: {\n    // Files with the following extensions are fair game for webpack to process\n    extensions: ['', '.webpack.js', '.web.js', '.ts', '.tsx', '.js'],\n  },\n};\n")),(0,a.kt)("h2",o({},{id:"inject"}),"Inject"),(0,a.kt)("p",null,"Your compiled output needs to be referenced from some kind of HTML page. So we've got this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<!DOCTYPE html>\n<html lang="en">\n  <head>\n    <meta charset="utf-8" />\n    <meta http-equiv="X-UA-Compatible" content="IE=edge" />\n    <meta name="viewport" content="width=device-width, initial-scale=1" />\n\n    <title>ES6 + Babel + React + Flux + Karma: The Secret Recipe</title>\n\n    \x3c!-- inject:css --\x3e\n    \x3c!-- endinject --\x3e\n    <link\n      rel="stylesheet"\n      href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css"\n    />\n  </head>\n  <body>\n    <div id="content"></div>\n    \x3c!-- inject:js --\x3e\n    \x3c!-- endinject --\x3e\n  </body>\n</html>\n')),(0,a.kt)("p",null,"Which is no more than a boilerplate HTML page with a couple of key features:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"a single ",(0,a.kt)("inlineCode",{parentName:"li"},"&lt;div /&gt;")," element in the ",(0,a.kt)("inlineCode",{parentName:"li"},"&lt;body /&gt;")," which is where our React app is going to be rendered."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"&lt;!-- inject:css --&gt;")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"&lt;!-- inject:js --&gt;")," placeholders where css and js is going to be injected by ",(0,a.kt)("inlineCode",{parentName:"li"},"gulp-inject"),"."),(0,a.kt)("li",{parentName:"ul"},"a single ",(0,a.kt)("inlineCode",{parentName:"li"},"&lt;link /&gt;")," to the Bootstrap CDN. This sample app doesn't actually serve up any css generated as part of the project. It could but it doesn't. When it comes to injection time no css will actually be injected. This has been left in place as, more typically, a project would have some styling served up.")),(0,a.kt)("p",null,"This is fed into our inject task in ",(0,a.kt)("inlineCode",{parentName:"p"},"inject.build()")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"inject.watch()"),". They take css and javascript and, using our shell template, create a new page which has the css and javascript dropped into their respective placeholders:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"'use strict';\n\nvar gulp = require('gulp');\nvar inject = require('gulp-inject');\nvar glob = require('glob');\n\nfunction injectIndex(options) {\n  var postInjectCb = options.postInjectCb;\n  var postInjectCbTriggerId = null;\n  function run() {\n    var target = gulp.src('./src/index.html');\n    var sources = gulp.src(\n      [\n        //'./dist/styles/main*.css',\n        './dist/scripts/vendor*.js',\n        './dist/scripts/main*.js',\n      ],\n      { read: false }\n    );\n\n    return target\n      .on('end', function () {\n        // invoke postInjectCb after 1s\n        if (postInjectCbTriggerId || !postInjectCb) {\n          return;\n        }\n\n        postInjectCbTriggerId = setTimeout(function () {\n          postInjectCb();\n          postInjectCbTriggerId = null;\n        }, 1000);\n      })\n      .pipe(\n        inject(sources, {\n          ignorePath: '/dist/',\n          addRootSlash: false,\n          removeTags: true,\n        })\n      )\n      .pipe(gulp.dest('./dist'));\n  }\n\n  var jsCssGlob = 'dist/**/*.{js,css}';\n\n  function checkForInitialFilesThenRun() {\n    glob(jsCssGlob, function (er, files) {\n      var filesWeNeed = [\n        'dist/scripts/main',\n        'dist/scripts/vendor' /*, 'dist/styles/main'*/,\n      ];\n\n      function fileIsPresent(fileWeNeed) {\n        return files.some(function (file) {\n          return file.indexOf(fileWeNeed) !== -1;\n        });\n      }\n\n      if (filesWeNeed.every(fileIsPresent)) {\n        run('initial build');\n      } else {\n        checkForInitialFilesThenRun();\n      }\n    });\n  }\n\n  checkForInitialFilesThenRun();\n\n  if (options.shouldWatch) {\n    gulp.watch(jsCssGlob, function (evt) {\n      if (evt.path && evt.type === 'changed') {\n        run(evt.path);\n      }\n    });\n  }\n}\n\nmodule.exports = {\n  build: function () {\n    return injectIndex({ shouldWatch: false });\n  },\n  watch: function (postInjectCb) {\n    return injectIndex({ shouldWatch: true, postInjectCb: postInjectCb });\n  },\n};\n")),(0,a.kt)("p",null,"This also triggers the server to serve up the new content."),(0,a.kt)("h2",o({},{id:"static-files"}),"Static Files"),(0,a.kt)("p",null,"Your app will likely rely on a number of static assets; images, fonts and whatnot. This script picks up the static assets you've defined and places them in the ",(0,a.kt)("inlineCode",{parentName:"p"},"dist")," folder ready for use:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"'use strict';\n\nvar gulp = require('gulp');\nvar cache = require('gulp-cached');\n\nvar targets = [\n  // In my own example I don't use any of the targets below, they\n  // are included to give you more of a feel of how you might use this\n  { description: 'FONTS', src: './fonts/*', dest: './dist/fonts' },\n  { description: 'STYLES', src: './styles/*', dest: './dist/styles' },\n  { description: 'FAVICON', src: './favicon.ico', dest: './dist' },\n  { description: 'IMAGES', src: './images/*', dest: './dist/images' },\n];\n\nfunction copy(options) {\n  // Copy files from their source to their destination\n  function run(target) {\n    gulp\n      .src(target.src)\n      .pipe(cache(target.description))\n      .pipe(gulp.dest(target.dest));\n  }\n\n  function watch(target) {\n    gulp.watch(target.src, function () {\n      run(target);\n    });\n  }\n\n  targets.forEach(run);\n\n  if (options.shouldWatch) {\n    targets.forEach(watch);\n  }\n}\n\nmodule.exports = {\n  build: function () {\n    return copy({ shouldWatch: false });\n  },\n  watch: function () {\n    return copy({ shouldWatch: true });\n  },\n};\n")),(0,a.kt)("h2",o({},{id:"karma"}),"Karma"),(0,a.kt)("p",null,"Finally, we're ready to get our tests set up to run continually with Karma. ",(0,a.kt)("inlineCode",{parentName:"p"},"tests.watch()")," triggers the following task:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"'use strict';\n\nvar Server = require('karma').Server;\nvar path = require('path');\nvar gutil = require('gulp-util');\n\nmodule.exports = {\n  watch: function () {\n    // Documentation: https://karma-runner.github.io/0.13/dev/public-api.html\n    var karmaConfig = {\n      configFile: path.join(__dirname, '../karma.conf.js'),\n      singleRun: false,\n\n      plugins: [\n        'karma-webpack',\n        'karma-jasmine',\n        'karma-mocha-reporter',\n        'karma-sourcemap-loader',\n        'karma-phantomjs-launcher',\n        'karma-phantomjs-shim',\n      ], // karma-phantomjs-shim only in place until PhantomJS hits 2.0 and has function.bind\n      reporters: ['mocha'],\n    };\n\n    new Server(karmaConfig, karmaCompleted).start();\n\n    function karmaCompleted(exitCode) {\n      gutil.log('Karma has exited with:', exitCode);\n      process.exit(exitCode);\n    }\n  },\n};\n")),(0,a.kt)("p",null,"When running in watch mode it's possible to debug the tests by going to: ",(0,a.kt)("inlineCode",{parentName:"p"},'<a href="http://localhost:9876/">http://localhost:9876/</a>'),". It's also possible to run the tests standalone with a simple ",(0,a.kt)("inlineCode",{parentName:"p"},"npm run test"),". Running them like this also outputs the results to an ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/q/442556/761388"}),"XML file in JUnit format"),"; this can be useful for integrating into CI solutions that don't natively pick up test results."),(0,a.kt)("p",null,"Whichever approach we use for running tests, we use the following ",(0,a.kt)("inlineCode",{parentName:"p"},"karma.conf.js")," file to configure Karma:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"/* eslint-disable no-var, strict */\n'use strict';\n\nvar webpackConfig = require('./webpack.config.js');\n\nmodule.exports = function (config) {\n  // Documentation: https://karma-runner.github.io/0.13/config/configuration-file.html\n  config.set({\n    browsers: ['PhantomJS'],\n\n    files: [\n      'test/import-babel-polyfill.js', // This ensures we have the es6 shims in place from babel\n      'test/**/*.tests.ts',\n      'test/**/*.tests.tsx',\n    ],\n\n    port: 9876,\n\n    frameworks: ['jasmine', 'phantomjs-shim'],\n\n    logLevel: config.LOG_INFO, //config.LOG_DEBUG\n\n    preprocessors: {\n      'test/import-babel-polyfill.js': ['webpack', 'sourcemap'],\n      'src/**/*.{ts,tsx}': ['webpack', 'sourcemap'],\n      'test/**/*.tests.{ts,tsx}': ['webpack', 'sourcemap'],\n    },\n\n    webpack: {\n      devtool: 'eval-source-map', //'inline-source-map', - inline-source-map doesn't work at present\n      debug: true,\n      module: webpackConfig.module,\n      resolve: webpackConfig.resolve,\n    },\n\n    webpackMiddleware: {\n      quiet: true,\n      stats: {\n        colors: true,\n      },\n    },\n\n    // reporter options\n    mochaReporter: {\n      colors: {\n        success: 'bgGreen',\n        info: 'cyan',\n        warning: 'bgBlue',\n        error: 'bgRed',\n      },\n    },\n\n    junitReporter: {\n      outputDir: 'test-results', // results will be saved as $outputDir/$browserName.xml\n      outputFile: undefined, // if included, results will be saved as $outputDir/$browserName/$outputFile\n      suite: '',\n    },\n  });\n};\n")),(0,a.kt)("p",null,"As you can see, we're still using our webpack configuration from earlier to configure much of how the transpilation takes place."),(0,a.kt)("p",null,"And that's it; we have a workflow for developing in TypeScript using React with tests running in an automated fashion. I appreciated this has been a rather long blog post but I hope I've clarified somewhat how this all plugs together and works. Do leave a comment if you think I've missed something."),(0,a.kt)("h2",o({},{id:"babel-5---babel-6"}),"Babel 5 -> Babel 6"),(0,a.kt)("p",null,'This post has actually been sat waiting to be published for some time. I\'d got this solution up and running with Babel 5. Then they shipped Babel 6 and (as is the way with "breaking changes") ',(0,a.kt)("a",o({parentName:"p"},{href:"https://phabricator.babeljs.io/T2864"}),"broke sourcemap support")," and thus torpedoed this workflow. Happily that's now ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/babel/babel/pull/3108"}),"been resolved"),". But if you should experience any wonkiness - it's worth checking that you're using the latest and greatest of Babel 6."))}d.isMDXComponent=!0},64180:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"live-reload-considered-harmful",title:"Live Reload Considered Harmful",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},s=void 0,l={permalink:"/live-reload-considered-harmful",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2015-12-20-live-reload-considered-harmful/index.md",source:"@site/blog/2015-12-20-live-reload-considered-harmful/index.md",title:"Live Reload Considered Harmful",description:"I've seen it go by many names; live reload, hot reload, browser sync... the list goes on. It's been the subject of a million demos. It's the focus of a thousand npm packages. Someone tweaks a file and... wait for it... doesn't have to refresh their browser to see the changes... The future is now!",date:"2015-12-20T00:00:00.000Z",formattedDate:"December 20, 2015",tags:[],readingTime:2.46,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"live-reload-considered-harmful",title:"Live Reload Considered Harmful",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},prevItem:{title:"UseStaticFiles for ASP.Net Framework",permalink:"/usestaticfiles-for-aspnet-vold"},nextItem:{title:"ES6 + TypeScript + Babel + React + Flux + Karma: The Secret Recipe",permalink:"/es6-typescript-babel-react-flux-karma"}},p={authorsImageUrls:[void 0]},u=[{value:"Why is Live Reload a Thing?",id:"why-is-live-reload-a-thing",level:2},{value:"Why is Live Reload a BAD Thing?",id:"why-is-live-reload-a-bad-thing",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I've seen it go by many names; ",(0,a.kt)("a",o({parentName:"p"},{href:"http://livereload.com/"}),"live reload"),", hot reload, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://browsersync.io/"}),"browser sync"),"... the list goes on. It's been the subject of a million demos. It's the focus of a thousand npm packages. Someone tweaks a file and... wait for it... ",(0,a.kt)("em",{parentName:"p"},"doesn't have to refresh their browser to see the changes"),"... The future is now!"),(0,a.kt)("p",null,"Forgive me the sarcasm, but I have come to the conclusion that whilst live reload is impressive... for my own purposes, it is not actually that useful. It certainly shouldn't be the default goto that it seems to have become."),(0,a.kt)("p",null,"Hear me out people, I may be the voice crying out in the wilderness but I'm right dammit."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(84583).Z,width:"245",height:"170"})),(0,a.kt)("h2",o({},{id:"why-is-live-reload-a-thing"}),"Why is Live Reload a Thing?"),(0,a.kt)("p",null,"What is live reload? Well having to hit F5 after you've made a change... That seems like such hard work right? To quote ",(0,a.kt)("a",o({parentName:"p"},{href:"http://haacked.com/archive/2011/12/13/better-git-with-powershell.aspx/"}),"Phil Haack"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"... we\u2019re software developers.... It\u2019s time to AWW TOE MATE!")),(0,a.kt)("p",null,"Yup, automation. Anything that a developer can theoretically automate.... will be automated. Usually this is a good thing but automation can be addictive. And on this occasion it's time for an intervention."),(0,a.kt)("p",null,"What else could be the attraction? Well, this is speculation but I would say that the implementation actually has something to do with it. Live reload is almost invariably powered by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/WebSocket"}),"WebSockets")," and they are certainly cool. Developers I know what you are like. You're attracted by the new shiny thing. You can't resist the allure of WS. And there with live reload idling away in the background you're all bleeding edge. I can say all this because this is exactly what I am like."),(0,a.kt)("h2",o({},{id:"why-is-live-reload-a-bad-thing"}),"Why is Live Reload a BAD Thing?"),(0,a.kt)("p",null,"Well the OCD part of me is instinctively repelled by the extra ",(0,a.kt)("inlineCode",{parentName:"p"},"script")," tag of alien code that live reload foists upon your app. How very dare that ",(0,a.kt)("inlineCode",{parentName:"p"},'&lt;script src="http://localhost:35729/livereload.js?snipver=1"&gt;&lt;/script&gt;')," push its way into my pristine DOM. It's an outrage."),(0,a.kt)("p",null,"Perhaps a more convincing rationale is how useful it is to have 2 different versions of your app up on screen at the same time. I like to try things out when I'm working. I get a screen working one way and then I tweak and play with my implementation. I have the app of 10 minutes ago sat side by side with the newly adjusted one. Assess, compare and and declare a winner. That's so useful and live reload does away with it. That's a problem."),(0,a.kt)("p",null,"Finally, I'm an obsessive 'Ctrl-S'-er. I've been burned by unsaved changes too many times. I'm saving every couple of keypresses. With live reload that usually means I have the noise of a dead application in the corner of my eye as LR obsessively forces the latest brokenness upon me. That sucks."),(0,a.kt)("p",null,"I've no doubt there are situations where live reload is useful. But for my money that's the exception rather than the rule. Let the madness end now. Just say \"no\", kids."))}d.isMDXComponent=!0},86946:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"usestaticfiles-for-aspnet-vold",title:"UseStaticFiles for ASP.Net Framework",authors:"johnnyreilly",tags:["ASP.NET"],hide_table_of_contents:!1},s=void 0,l={permalink:"/usestaticfiles-for-aspnet-vold",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-01-01-usestaticfiles-for-aspnet-vold/index.md",source:"@site/blog/2016-01-01-usestaticfiles-for-aspnet-vold/index.md",title:"UseStaticFiles for ASP.Net Framework",description:"This is a guide on how not to expose all your static files to the world at large when working with the ASP.Net Framework. How to move from a blocklisting approach to a allowlisting approach.",date:"2016-01-01T00:00:00.000Z",formattedDate:"January 1, 2016",tags:[{label:"ASP.NET",permalink:"/tags/asp-net"}],readingTime:6.075,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"usestaticfiles-for-aspnet-vold",title:"UseStaticFiles for ASP.Net Framework",authors:"johnnyreilly",tags:["ASP.NET"],hide_table_of_contents:!1},prevItem:{title:"Coded UI and the Curse of the Docking Station",permalink:"/coded-ui-and-curse-of-docking-station"},nextItem:{title:"Live Reload Considered Harmful",permalink:"/live-reload-considered-harmful"}},p={authorsImageUrls:[void 0]},u=[{value:"Support for HTML5 History API!",id:"support-for-html5-history-api",level:2},{value:"<code>UseStaticFiles</code>",id:"usestaticfiles",level:2},{value:"&quot;I am SPArtucus&quot;",id:"i-am-spartucus",level:2},{value:"Data! Data! Data!.. I can&#39;t make bricks without clay.",id:"data-data-data-i-cant-make-bricks-without-clay",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This is a guide on how ",(0,a.kt)("em",{parentName:"p"},"not")," to expose all your static files to the world at large when working with the ASP.Net Framework. How to move from a blocklisting approach to a allowlisting approach."),(0,a.kt)("p",null,"Not clear? Stick around; I'll get better. Oh and that's not all, we've also got.... drumroll:"),(0,a.kt)("h2",o({},{id:"support-for-html5-history-api"}),"Support for ",(0,a.kt)("a",o({parentName:"h2"},{href:"https://html.spec.whatwg.org/multipage/browsers.html#the-history-interface"}),"HTML5 History API"),"!"),(0,a.kt)("p",null,"What that means, in as close to English as I can get it, is real URLs for Single Page Applications. None of that hash-based routing malarkey. So, ",(0,a.kt)("inlineCode",{parentName:"p"},"https://i-am-your-domain.com/i-am-your-route")," rather than ",(0,a.kt)("inlineCode",{parentName:"p"},"https://i-am-your-domain.com/<em>#/</em>i-am-your-route"),". (For a more in depth look at the different sorts of routing SPA's can use then take a look at the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://rackt.org/history/stable/GettingStarted.html"}),"excellent docs")," by the folk behind ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/rackt/react-router"}),"React Router"),". These concepts are not React specific and can be applied to any SPA technology.)"),(0,a.kt)("h2",o({},{id:"usestaticfiles"}),(0,a.kt)("inlineCode",{parentName:"h2"},"UseStaticFiles")),(0,a.kt)("p",null,"You may be aware that historically ASP.Net has been somewhat unusual in its approach to serving static files. Essentially, all the files in a project are theoretically servable. Okay, that's not entirely true; things like the ",(0,a.kt)("inlineCode",{parentName:"p"},"web.config")," files etc are not going to be handed over to someone browsing your site. But other files that you might well want kept away from prying eyes may be. So your ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.typescriptlang.org/"}),"TypeScript")," files, your ",(0,a.kt)("a",o({parentName:"p"},{href:"http://lesscss.org/"}),"Less")," files are all up for grabs unless you take action to block access to them. This is, and has always been, bad."),(0,a.kt)("p",null,'The ASP.Net team know this and things are changing with ASP.Net 5. With the new stack you have to say "these are the static files we want people to access" in the form of an ',(0,a.kt)("inlineCode",{parentName:"p"},'<a href="https://msdn.microsoft.com/en-us/library/dn782589(v=vs.113).aspx">app.UseStaticFiles()</a>')," declaration. This is mighty similar to how you do things in other frameworks such as ",(0,a.kt)("a",o({parentName:"p"},{href:"http://expressjs.com/en/starter/static-files.html"}),"Express"),". To quote the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.asp.net/en/latest/fundamentals/static-files.html#serving-static-files"}),"docs"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"By default, static files are stored in the webroot of your project. The location of the webroot is defined in the project\u2019s ",(0,a.kt)("inlineCode",{parentName:"p"},"project.json")," file where the default is wwwroot."),(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"webroot": "wwwroot"\n')),(0,a.kt)("p",{parentName:"blockquote"},"Static files can be stored in any folder under the webroot and accessed with a relative path to that root. For example, when you create a default Web application project using Visual Studio, there are several folders created within the webroot folder - ",(0,a.kt)("inlineCode",{parentName:"p"},"css"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"images")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"js"),". In order to directly access an image in the images subfolder, the URL would look like the following:"),(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("inlineCode",{parentName:"p"},"http://&lt;yourApp&gt;/images/&lt;imageFileName&gt;"))),(0,a.kt)("p",null,"So how do we get this behaviour with ASP.Net vOld? Well, it's just a matter of ",(0,a.kt)("inlineCode",{parentName:"p"},"web.config")," URL rewrite twiddling:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<configuration>\n  \x3c!-- other config --\x3e\n\n  <system.webServer>\n    <rewrite>\n      <rules>\n        <rule name="Map empty URLs to the index.html">\n          <match url="^$" />\n          <action type="Rewrite" url="/index.html" />\n        </rule>\n        <rule name="Map all requests with a \'.\' in to the \'build\' directory" stopProcessing="true">\n          <match url="^(.*[.].*)$" />\n          <action type="Rewrite" url="/build/{R:1}" />\n        </rule>\n      </rules>\n    </rewrite>\n  </system.webServer>\n</configuration>\n')),(0,a.kt)("p",null,"My ",(0,a.kt)("inlineCode",{parentName:"p"},"webroot")," is named ",(0,a.kt)("inlineCode",{parentName:"p"},"build")," rather than ",(0,a.kt)("inlineCode",{parentName:"p"},"wwwroot"),". The 2 URL rewrite rules above do the following:"),(0,a.kt)("dl",null,(0,a.kt)("dt",null,"Map empty URLs to the index.html"),(0,a.kt)("dd",null,"Empty URLs (ie the URL for the root of your site) are mapped to ",(0,a.kt)("code",null,"index.html"),". The ",(0,a.kt)("code",null,"index.html")," in the ",(0,a.kt)("code",null,"build")," folder is the home page of this particular site and the next rule will make sure that we hit that. (Since we haven't set ",(0,a.kt)("code",null,"stopProcessing")," to ",(0,a.kt)("code",null,"true")," for this particular rule the next rule will be processed after this one.)"),(0,a.kt)("dt",null,"Map all requests with a '.' in to the 'build' directory"),(0,a.kt)("dd",null,'All URLs with a "." in the title (including ',(0,a.kt)("code",null,"index.html"),") are redirected to the ",(0,a.kt)("code",null,"build"),' folder. All static files have a "." in them because filenames have suffixes. This essentially means all requests for files are served from the ',(0,a.kt)("code",null,"build")," folder. In this case we have set ",(0,a.kt)("code",null,"stopProcessing")," to ",(0,a.kt)("code",null,"true")," which means that any URLs that matched this rule will be not be affected by any subsequent rules.")),(0,a.kt)("p",null,"So if anyone sneakily tries to sneakily browse to say, ",(0,a.kt)("inlineCode",{parentName:"p"},"http://&lt;yourApp&gt;/js/app.ts")," then they'll be nicely redirected to the non-existent ",(0,a.kt)("inlineCode",{parentName:"p"},"build/js/app.ts"),". 404 in your face!"),(0,a.kt)("h2",o({},{id:"i-am-spartucus"}),'"I am SPArtucus"'),(0,a.kt)("p",null,"When you have a Single Page Application you want the same web experience as a server side rendered web app. What I mean by this is: routing just works. You want people to be able to go to ",(0,a.kt)("inlineCode",{parentName:"p"},"https://i-am-your-domain.com/i-am-your-route")," and get your site at the specified route. Happily, whether you're using React Router, Angular UI Router or something else, the client side is covered. They can be configured to detect the route that you enter at and serve up the SPA in the relevant state. But you have to meet them halfway; the server needs to do its bit."),(0,a.kt)("p",null,"When a URL is requested that doesn't look like a request for a static file, let's make the (reasonable) assumption that this is a route URL and serve up the shell SPA page. So, for my own example of an Angular 1.x app I want the server to hand over ",(0,a.kt)("inlineCode",{parentName:"p"},"/build/index.html"),"."),(0,a.kt)("p",null,'This is the magic that makes real URLs and SPAs work. Provided the client hasn\'t requested a static file, every request to the server will be responded to with our very own "I am SPArtucus"; the shell SPA page. This is catered for by the addition of another new rule to our ',(0,a.kt)("inlineCode",{parentName:"p"},"web.config"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<configuration>\n  \x3c!-- other config --\x3e\n\n  <system.webServer>\n    <rewrite>\n      <rules>\n        <rule name="Map empty URLs to the index.html">\n          <match url="^$" />\n          <action type="Rewrite" url="/index.html" />\n        </rule>\n        <rule name="Map all requests with a \'.\' in to the \'build\' directory" stopProcessing="true">\n          <match url="^(.*[.].*)$" />\n          <action type="Rewrite" url="/build/{R:1}" />\n        </rule>\n        <rule name="Map all other URLs to the index.html - this to support our SPA routes">\n          <match url="^.*$" />\n          <action type="Rewrite" url="/build/index.html" />\n        </rule>\n      </rules>\n    </rewrite>\n  </system.webServer>\n</configuration>\n')),(0,a.kt)("dl",null,(0,a.kt)("dt",null,"Map all other URLs to the index.html - this to support our SPA routes"),(0,a.kt)("dd",null,"Our new rule says \"whatever URL turns up, if it hasn't been catered for by an existing rule, well it must be a SPA route, so we'll serve up the shell SPA page of ",(0,a.kt)("code",null,"build/index.html"),'".')),(0,a.kt)("h2",o({},{id:"data-data-data-i-cant-make-bricks-without-clay"}),"Data! Data! Data!.. I can't make bricks without clay."),(0,a.kt)("p",null,"Sherlock Holmes was onto something; most applications are nothing without data. What you've got at present is an application that carefully restricts access to static files and, for all other requests, serves up our shell SPA page. So let's relax our final rule a little to make data access a thing:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<configuration>\n  \x3c!-- other config --\x3e\n\n  <system.webServer>\n    <rewrite>\n      <rules>\n        <rule name="Map empty URLs to the index.html">\n          <match url="^$" />\n          <action type="Rewrite" url="/index.html" />\n        </rule>\n        <rule name="Map all requests with a \'.\' in to the \'build\' directory" stopProcessing="true">\n          <match url="^(.*[.].*)$" />\n          <action type="Rewrite" url="/build/{R:1}" />\n        </rule>\n        <rule name="Map non-api URLs to the index.html - this to support our SPA routes">\n          <match url="^(api/).*$" negate="true" ignoreCase="true" />\n          <action type="Rewrite" url="/build/index.html" />\n        </rule>\n      </rules>\n    </rewrite>\n  </system.webServer>\n</configuration>\n')),(0,a.kt)("dl",null,(0,a.kt)("dt",null,"Map non-api URLs to the index.html - this to support our SPA routes"),(0,a.kt)("dd",null,'This amended rule says "whatever URL turns up, ',(0,a.kt)("em",null,"unless it begins ",(0,a.kt)("code",null,'"api/"')),", if it hasn't been catered for by an existing rule, well it must be a SPA route, so we'll serve up the shell SPA page of ",(0,a.kt)("code",null,"build/index.html"),'".')),(0,a.kt)("p",null,"This allows us to perform data access by prefixing all the Web API routes with ",(0,a.kt)("inlineCode",{parentName:"p"},'"api/"'),". I've picked this because it is the default location for ASP.Net Web API routes. It is (like most things) entirely configurable. To see a working implementation of this complete approach then take a look at the PoorClaresAngular project ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/poorclaresarundel/tree/15e7d4ddc0f1c06fe326b44c3bdc71ceb554bf73"}),"here"),"."))}d.isMDXComponent=!0},78590:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"coded-ui-and-curse-of-docking-station",title:"Coded UI and the Curse of the Docking Station",authors:"johnnyreilly",tags:["Surface Pro 3","Coded UI"],hide_table_of_contents:!1},s=void 0,l={permalink:"/coded-ui-and-curse-of-docking-station",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-01-14-coded-ui-and-curse-of-docking-station/index.md",source:"@site/blog/2016-01-14-coded-ui-and-curse-of-docking-station/index.md",title:"Coded UI and the Curse of the Docking Station",description:"I\u2019ve a love / hate relationship with Coded UI. Well hate / hate might be more accurate. Hate perhaps married with a very grudging respect still underpinned by a wary bitterness. Yes, that\u2019s about the size of it. Why? Well, when Coded UI works, it\u2019s fab. But it\u2019s flaky as anything. Anybody who\u2019s used the technology is presently nodding sagely and holding back the tears. It\u2019s all a bit... tough.",date:"2016-01-14T00:00:00.000Z",formattedDate:"January 14, 2016",tags:[{label:"Surface Pro 3",permalink:"/tags/surface-pro-3"},{label:"Coded UI",permalink:"/tags/coded-ui"}],readingTime:2.425,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"coded-ui-and-curse-of-docking-station",title:"Coded UI and the Curse of the Docking Station",authors:"johnnyreilly",tags:["Surface Pro 3","Coded UI"],hide_table_of_contents:!1},prevItem:{title:"TFS 2012, .NET 4.5 and C# 6",permalink:"/tfs-2012-net-45-and-c-6"},nextItem:{title:"UseStaticFiles for ASP.Net Framework",permalink:"/usestaticfiles-for-aspnet-vold"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I\u2019ve a love / hate relationship with Coded UI. Well hate / hate might be more accurate. Hate perhaps married with a very grudging respect still underpinned by a wary bitterness. Yes, that\u2019s about the size of it. Why? Well, when Coded UI works, it\u2019s fab. But it\u2019s flaky as anything. Anybody who\u2019s used the technology is presently nodding sagely and holding back the tears. It\u2019s all a bit... tough."),(0,a.kt)("p",null,"I\u2019ve recently discovered another quirk to add to the list. Docking stations. I was back working on a project which had a Coded UI test suite. I\u2019d heard tell that there were problems with the tests and was just taking a look at them. The first hurdle I fell at was getting the tests to run locally. The tests had first been developed on a standard desktop build and, as much as this can ever be said of Coded UI tests, they worked. However, the future had happened. The company in question was no longer using the old school desktop towers. Nope, they\u2019d reached for the sky and equipped the whole office with Surface Pro 3\u2019s, hot desks, docking stations and big, big monitors. It looked terribly flash."),(0,a.kt)("p",null,"Coded UI was not happy."),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"Mouse.Click")," behaviour wasn\u2019t working. Most tests need the ability for users to click on buttons, dropdowns etc. That\u2019s part of a normal UI. And so it was with these tests. This is where they fell over. The reason they fell over at this point didn\u2019t become clear for a while. It wasn\u2019t until we tried tweaking our implementation of the tests that we realised what was happening. The tests normally found buttons / dropdowns etc on the screen and then attempted to perform a ",(0,a.kt)("inlineCode",{parentName:"p"},"Mouse.Click")," upon them. We changed the implementation to be subtly different. Instead of just clicking on the element we amended the test to move the mouse to the button and then perform the click."),(0,a.kt)("p",null,"Aha!"),(0,a.kt)("p",null,"Rather than steadily moving towards an element and clicking, the pointer was swerving like a drunk man crossing the road at 3am. It completely missed the element it was aiming for and clicked upon a seemingly random area of the screen. This is Coded UI doing \u201cpin the tail on the donkey\u201d."),(0,a.kt)("p",null,"After more time than I'd like to admit I happened upon the solution. I tended to dock my Surface and then tune my monitor resolution to the one most optimal for coding. (ie really high res.) This is what messes with Coded UI's head; the resolution change. If I wanted to be able to run tests successfully all I had to do was switch back to the resolution I initially booted with. Alternately I could restart my computer so it launched with the resolution I was presently using."),(0,a.kt)("p",null,"Once you do follow this guidance Coded UI has a moment of clarity, gets sober and starts ",(0,a.kt)("inlineCode",{parentName:"p"},"Mouse.Click"),"-","ing like a pro."))}d.isMDXComponent=!0},67782:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"tfs-2012-net-45-and-c-6",title:"TFS 2012, .NET 4.5 and C# 6",authors:"johnnyreilly",tags:["C#",".NET Framework","TFS"],hide_table_of_contents:!1},s=void 0,l={permalink:"/tfs-2012-net-45-and-c-6",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-02-01-tfs-2012-net-45-and-c-6/index.md",source:"@site/blog/2016-02-01-tfs-2012-net-45-and-c-6/index.md",title:"TFS 2012, .NET 4.5 and C# 6",description:"So, you want to use C# 6 language features and you\u2019re working on an older project that\u2019s still rocking .NET 4.5. Well, with some caveats, you can.",date:"2016-02-01T00:00:00.000Z",formattedDate:"February 1, 2016",tags:[{label:"C#",permalink:"/tags/c"},{label:".NET Framework",permalink:"/tags/net-framework"},{label:"TFS",permalink:"/tags/tfs"}],readingTime:.855,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"tfs-2012-net-45-and-c-6",title:"TFS 2012, .NET 4.5 and C# 6",authors:"johnnyreilly",tags:["C#",".NET Framework","TFS"],hide_table_of_contents:!1},prevItem:{title:"Visual Studio, tsconfig.json and external TypeScript compilation",permalink:"/visual-studio-tsconfigjson-and-external"},nextItem:{title:"Coded UI and the Curse of the Docking Station",permalink:"/coded-ui-and-curse-of-docking-station"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"So, you want to use C# 6 language features and you\u2019re working on an older project that\u2019s still rocking .NET 4.5. Well, with ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/28921749/761388"}),"some caveats"),", you can."),(0,a.kt)("p",null,"The new compiler will compile targeting older framework versions. Well that\u2019s all lovely; let\u2019s all go home."),(0,a.kt)("p",null,"Now. What say you\u2019ve got an old, old build server? It\u2019s TFS 2012 Update 2, creaking away, still glad to alive and kind of wondering why it hasn\u2019t been upgraded or retired. This is where you want to compile .NET 4.5 from C# 6. Well it can be done. Here\u2019s how it\u2019s done:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Install Visual Studio 2015 on the build server (I\u2019m told this can be achieved using ",(0,a.kt)("a",o({parentName:"li"},{href:"https://www.microsoft.com/en-us/download/details.aspx?id=48159"}),"Microsoft Build Tools 2015")," but I haven\u2019t tried it myelf so caveat emptor)"),(0,a.kt)("li",{parentName:"ol"},"set the ",(0,a.kt)("inlineCode",{parentName:"li"},"MSBuild Arguments")," in the build definition to ",(0,a.kt)("inlineCode",{parentName:"li"},"/p:VisualStudioVersion=14.0")," (i.e. Visual Studio 2015 mode)")),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(88583).Z,width:"640",height:"449"})),(0,a.kt)("ol",o({},{start:3}),(0,a.kt)("li",{parentName:"ol"},"in each project that uses C# 6 syntax, install the NuGet package ",(0,a.kt)("a",o({parentName:"li"},{href:"https://www.nuget.org/packages/Microsoft.Net.Compilers"}),"Microsoft.Net.Compilers")," with a quick ",(0,a.kt)("inlineCode",{parentName:"li"},"install-package Microsoft.Net.Compilers"))),(0,a.kt)("p",null,"That\u2019s it; huzzah! String interpolation here I come\u2026"))}d.isMDXComponent=!0},55122:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"visual-studio-tsconfigjson-and-external",title:"Visual Studio, tsconfig.json and external TypeScript compilation",authors:"johnnyreilly",tags:["TFS","Visual Studio","tsconfig.json","typescript","Webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/visual-studio-tsconfigjson-and-external",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-02-19-visual-studio-tsconfigjson-and-external/index.md",source:"@site/blog/2016-02-19-visual-studio-tsconfigjson-and-external/index.md",title:"Visual Studio, tsconfig.json and external TypeScript compilation",description:"TypeScript first gained support for tsconfig.json back with the 1\\.5 release. However, to my lasting regret and surprise Visual Studio will not be gaining meaningful support for it until TypeScript 1.8 ships. However, if you want it now, it's already available to use in beta.",date:"2016-02-19T00:00:00.000Z",formattedDate:"February 19, 2016",tags:[{label:"TFS",permalink:"/tags/tfs"},{label:"Visual Studio",permalink:"/tags/visual-studio"},{label:"tsconfig.json",permalink:"/tags/tsconfig-json"},{label:"typescript",permalink:"/tags/typescript"},{label:"Webpack",permalink:"/tags/webpack"}],readingTime:5.86,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"visual-studio-tsconfigjson-and-external",title:"Visual Studio, tsconfig.json and external TypeScript compilation",authors:"johnnyreilly",tags:["TFS","Visual Studio","tsconfig.json","typescript","Webpack"],hide_table_of_contents:!1},prevItem:{title:"Creating Angular UI Routes in the Controller",permalink:"/creating-angular-ui-routes-in-controller"},nextItem:{title:"TFS 2012, .NET 4.5 and C# 6",permalink:"/tfs-2012-net-45-and-c-6"}},p={authorsImageUrls:[void 0]},u=[{value:"External TypeScript Compilation and the VS build",id:"external-typescript-compilation-and-the-vs-build",level:2},{value:"Goodbye TypeScript Compilation in VS",id:"goodbye-typescript-compilation-in-vs",level:2},{value:"Hello TypeScript Compilation outside VS",id:"hello-typescript-compilation-outside-vs",level:2},{value:"The <code>WebClientBuild</code> Target",id:"the-webclientbuild-target",level:2},{value:"The <code>WebClientClean</code> Target",id:"the-webclientclean-target",level:2},{value:"The <code>CollectLegacyTypeScriptOutput</code> and <code>CollectGulpOutput</code> Targets",id:"the-collectlegacytypescriptoutput-and-collectgulpoutput-targets",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"TypeScript first gained support for ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/wiki/tsconfig.json"}),(0,a.kt)("inlineCode",{parentName:"a"},"tsconfig.json"))," back with the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.microsoft.com/typescript/2015/07/20/announcing-typescript-1-5/"}),"1",".","5 release"),". However, to my lasting regret and surprise Visual Studio will not be gaining meaningful support for it until ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/wiki/What%27s-new-in-TypeScript#improved-support-for-tsconfigjson-in-visual-studio-2015"}),"TypeScript 1.8")," ships. However, if you want it now, it's already available to use in ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.microsoft.com/typescript/2016/01/28/announcing-typescript-1-8-beta/"}),"beta"),"."),(0,a.kt)("p",null,"I've already leapt aboard. Whilst there's a number of bugs in the beta it's still totally usable. So use it."),(0,a.kt)("h2",o({},{id:"external-typescript-compilation-and-the-vs-build"}),"External TypeScript Compilation and the VS build"),(0,a.kt)("p",null,"Whilst ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," is useful and super cool it has limitations. It allows you to deactivate compilation upon file saving using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/issues/2326#issuecomment-178294169"}),(0,a.kt)("inlineCode",{parentName:"a"},"compileOnSave")),". ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/issues/7091"}),"What it doesn't allow is deactivation of the TypeScript compilation that happens as part of a Visual Studio build.")," That may not matter for the vanilla workflow of just dropping TypeScript files in a Visual Studio web project and having VS invoke the TypeScript compilation. However it comes to matter when your workflow deviates from the norm, as mine does. Using external compilation of TypeScript within Visual Studio is a little tricky. My own use case is somewhat atypical but perhaps not uncommon."),(0,a.kt)("p",null,"I'm working on a project which has been built using TypeScript since TS 0.9. Not surprisingly, this started off using the default Visual Studio / TypeScript workflow. Active development on the project ceased around 9 months ago. Now it's starting up again. It's a reasonable sized web app and the existing functionality is, in the main, fine. But the users want to add some new screens."),(0,a.kt)("p",null,"Like any developer, I want to build with the latest and greatest. In my case, this means I want to write modular ES6 using TypeScript. With this approach my code can be leaner and I have less script ordering drama in my life. (Yay import statements!) This can be done by bringing together webpack, TypeScript (",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader"}),"ts-loader"),") and ",(0,a.kt)("a",o({parentName:"p"},{href:"http://babeljs.io/"}),"Babel")," (",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/babel/babel-loader"}),"babel-loader"),"). There's an example of this approach ",(0,a.kt)("a",o({parentName:"p"},{href:"/es6-typescript-babel-react-flux-karma"}),"here"),". Given the size of the existing codebase I'd rather leave the legacy TypeScript as is and isolate my new approach to the screens I'm going to build. Obviously I'd like to have a common build process for all the codebase at some point but I've got a deadline to meet and so a half-old / half-new approach is called for (at least for the time being)."),(0,a.kt)("h2",o({},{id:"goodbye-typescript-compilation-in-vs"}),"Goodbye TypeScript Compilation in VS"),(0,a.kt)("p",null,"Writing modular ES6 TypeScript which is fully transpiled to old-school JS is ",(0,a.kt)("em",{parentName:"p"},"not possible")," using the Visual Studio tooling at present. For what it's worth I think that SystemJS compilation may make this more possible in the future but I don't really know enough about it to be sure. That's why I'm bringing webpack / Babel into the mix right now. I don't want Visual Studio to do anything for the ES6 code; I don't want it to compile. I want to deactivate my TypeScript compilation for the ES6 code. I can't do this from the ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," so I'm in a bit of a hole. What to do?"),(0,a.kt)("p",null,"Well, as of (I think) TypeScript 1.7 it's possible to deactivate TypeScript compilation in Visual Studio. To ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/issues/2294#issuecomment-129367578"}),"quote"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"there is an easier way to disable TypeScriptCompile:"),(0,a.kt)("p",{parentName:"blockquote"},"Just add ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;TypeScriptCompileBlocked&gt;true&lt;/TypeScriptCompileBlocked&gt;")," to the ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj"),", e.g. in the first ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;PropertyGroup&gt;"),".")),(0,a.kt)("p",null,"Awesomeness!"),(0,a.kt)("p",null,"But wait, this means that the legacy TypeScript isn't being compiled any longer. Bear in mind, I'm totally happy with the existing / legacy TypeScript compilation. Nooooooooooooooo!!!!!!!!!!!!!!!"),(0,a.kt)("h2",o({},{id:"hello-typescript-compilation-outside-vs"}),"Hello TypeScript Compilation outside VS"),(0,a.kt)("p",null,"Have no fear, I gotcha. What we're going to do is ensure that Visual Studio triggers 2 external TypeScript builds as part of its own build process:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"The modular ES6 TypeScript (new)"),(0,a.kt)("li",{parentName:"ul"},"The legacy TypeScript (old)")),(0,a.kt)("p",null,"How do we do this? Through the magic of build targets. We need to add this to our ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj"),": (I add it near the end; I'm not sure if location matters though)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<PropertyGroup>\n    <CompileDependsOn>\n      $(CompileDependsOn);\n      WebClientBuild;\n    </CompileDependsOn>\n    <CleanDependsOn>\n      $(CleanDependsOn);\n      WebClientClean\n    </CleanDependsOn>\n    <CopyAllFilesToSingleFolderForPackageDependsOn>\n      CollectGulpOutput;\n      CollectLegacyTypeScriptOutput;\n      $(CopyAllFilesToSingleFolderForPackageDependsOn);\n    </CopyAllFilesToSingleFolderForPackageDependsOn>\n    <CopyAllFilesToSingleFolderForMsdeployDependsOn>\n      CollectGulpOutput;\n      CollectLegacyTypeScriptOutput;\n      $(CopyAllFilesToSingleFolderForPackageDependsOn);\n    </CopyAllFilesToSingleFolderForMsdeployDependsOn>\n  </PropertyGroup>\n  <Target Name="WebClientBuild">\n    <Exec Command="npm install" />\n    <Exec Command="npm run build-legacy-typescript" />\n    <Exec Command="npm run build -- --mode $(ConfigurationName)" />\n  </Target>\n  <Target Name="WebClientClean">\n    <Exec Command="npm run clean" />\n  </Target>\n  <Target Name="CollectGulpOutput">\n    <ItemGroup>\n      <_CustomFiles Include="dist\\**\\*" />\n      <FilesForPackagingFromProject Include="%(_CustomFiles.Identity)">\n        <DestinationRelativePath>dist\\%(RecursiveDir)%(Filename)%(Extension)</DestinationRelativePath>\n      </FilesForPackagingFromProject>\n    </ItemGroup>\n    <Message Text="CollectGulpOutput list: %(_CustomFiles.Identity)" />\n  </Target>\n  <Target Name="CollectLegacyTypeScriptOutput">\n    <ItemGroup>\n      <_CustomFiles Include="Scripts\\**\\*.js" />\n      <FilesForPackagingFromProject Include="%(_CustomFiles.Identity)">\n        <DestinationRelativePath>Scripts\\%(RecursiveDir)%(Filename)%(Extension)</DestinationRelativePath>\n      </FilesForPackagingFromProject>\n    </ItemGroup>\n    <Message Text="CollectLegacyTypeScriptOutput list: %(_CustomFiles.Identity)" />\n  </Target>\n')),(0,a.kt)("p",null,"There's a few things going on here; let's take them one by one."),(0,a.kt)("h2",o({},{id:"the-webclientbuild-target"}),"The ",(0,a.kt)("inlineCode",{parentName:"h2"},"WebClientBuild")," Target"),(0,a.kt)("p",null,"This target triggers our external builds. One by one it runs the following commands:"),(0,a.kt)("dl",null,(0,a.kt)("dt",null,(0,a.kt)("code",null,"npm install")),(0,a.kt)("dd",null,"Installs the npm packages."),(0,a.kt)("dt",null,(0,a.kt)("code",null,"npm run build-legacy-typescript")),(0,a.kt)("dd",null,"Runs the ",(0,a.kt)("code",null,'"build-legacy-typescript"'),(0,a.kt)("code",null,"script")," in our ",(0,a.kt)("code",null,"package.json")),(0,a.kt)("dt",null,(0,a.kt)("code",null,"npm run build -- --mode $(ConfigurationName)")),(0,a.kt)("dd",null,"Runs the ",(0,a.kt)("code",null,'"build"'),(0,a.kt)("code",null,"script")," in our ",(0,a.kt)("code",null,"package.json")," and passes through a ",(0,a.kt)("code",null,"mode")," parameter of either ",(0,a.kt)("code",null,'"Debug"')," or ",(0,a.kt)("code",null,'"Release"')," from MSBuild - indicating whether we're creating a debug or a release build.")),(0,a.kt)("p",null,"As you've no doubt gathered, I'm following the convention of using the ",(0,a.kt)("inlineCode",{parentName:"p"},"scripts")," element of my ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," as repository for the various build tasks I might have for a web project. It looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  // ...\n  "scripts": {\n    "test": "karma start --reporters mocha,junit --single-run --browsers PhantomJS",\n    "build-legacy-typescript": "tsc -v&&tsc --project Scripts",\n    "clean": "gulp delete-dist-contents",\n    "watch": "gulp watch",\n    "build": "gulp build"\n  }\n  // ...\n}\n')),(0,a.kt)("p",null,"As you can see, ",(0,a.kt)("inlineCode",{parentName:"p"},'"build-legacy-typescript"')," invokes ",(0,a.kt)("inlineCode",{parentName:"p"},"tsc")," (which is registered as a ",(0,a.kt)("inlineCode",{parentName:"p"},"devDependency"),") to print out the version of the compiler. Then it invokes ",(0,a.kt)("inlineCode",{parentName:"p"},"tsc")," again using the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/wiki/Compiler-Options"}),(0,a.kt)("inlineCode",{parentName:"a"},"project"))," flag directly on the ",(0,a.kt)("inlineCode",{parentName:"p"},"Scripts")," directory. This is where the legacy TypeScript and its associated ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," resides. Et voil\xe1, the old / existing TypeScript is compiled just as it was previously by VS itself."),(0,a.kt)("p",null,"Next, the ",(0,a.kt)("inlineCode",{parentName:"p"},'"build"')," invokes a ",(0,a.kt)("inlineCode",{parentName:"p"},"gulp")," task called, descriptively, ",(0,a.kt)("inlineCode",{parentName:"p"},'"build"'),". This task caters for our brand new codebase of modular ES6 TypeScript. When run, this task will invoke webpack, copy static files, build less etc. Quick digression: you can see there's a ",(0,a.kt)("inlineCode",{parentName:"p"},'"watch"')," script that does the same thing on a file-watching basis; I use that during development."),(0,a.kt)("h2",o({},{id:"the-webclientclean-target"}),"The ",(0,a.kt)("inlineCode",{parentName:"h2"},"WebClientClean")," Target"),(0,a.kt)("p",null,"The task that runs to clean up artefacts created by ",(0,a.kt)("inlineCode",{parentName:"p"},"WebClientBuild"),"."),(0,a.kt)("h2",o({},{id:"the-collectlegacytypescriptoutput-and-collectgulpoutput-targets"}),"The ",(0,a.kt)("inlineCode",{parentName:"h2"},"CollectLegacyTypeScriptOutput")," and ",(0,a.kt)("inlineCode",{parentName:"h2"},"CollectGulpOutput")," Targets"),(0,a.kt)("p",null,"Since we're compiling our TypeScript outside of VS we need to tell MSBuild / MSDeploy about the externally compiled assets in order that they are included in the publish pipeline. Here I'm standing on the shoulders of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.codecadwallader.com/2015/03/15/integrating-gulp-into-your-tfs-builds-and-web-deploy/"}),"Steve Cadwallader's excellent post"),". Thanks Steve!"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"CollectLegacyTypeScriptOutput")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"CollectGulpOutput")," respectively include all the built files contained in the ",(0,a.kt)("inlineCode",{parentName:"p"},'"Scripts"')," and ",(0,a.kt)("inlineCode",{parentName:"p"},'"dist"')," folders when a publish takes place. You don't need this for when you're building on your own machine but if you're looking to publish (either from your machine or from TFS) then you will need exactly this. Believe me that last sentence was typed with a memory of ",(0,a.kt)("em",{parentName:"p"},"great")," pain and frustration."),(0,a.kt)("p",null,"So in the end, as far as TypeScript is concerned, I'm using Visual Studio solely as an editor. It's the hooks in the ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj")," that ensure that compilation happens. It seems a little quirky that we still need to have the original TypeScript targets in the ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj")," file as well; but it works. That's all that matters."))}d.isMDXComponent=!0},66874:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"creating-angular-ui-routes-in-controller",title:"Creating Angular UI Routes in the Controller",authors:"johnnyreilly",tags:["AngularJS"],hide_table_of_contents:!1},s=void 0,l={permalink:"/creating-angular-ui-routes-in-controller",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-02-29-creating-angular-ui-routes-in-controller/index.md",source:"@site/blog/2016-02-29-creating-angular-ui-routes-in-controller/index.md",title:"Creating Angular UI Routes in the Controller",description:"So you're creating a link with the Angular UI Router. You're passing more than a few parameters and it's getting kinda big. Something like this:",date:"2016-02-29T00:00:00.000Z",formattedDate:"February 29, 2016",tags:[{label:"AngularJS",permalink:"/tags/angular-js"}],readingTime:1.87,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"creating-angular-ui-routes-in-controller",title:"Creating Angular UI Routes in the Controller",authors:"johnnyreilly",tags:["AngularJS"],hide_table_of_contents:!1},prevItem:{title:"TFS 2012 meet PowerShell, Karma and BuildNumber",permalink:"/tfs-2012-meet-powershell-karma-and-buildnumber"},nextItem:{title:"Visual Studio, tsconfig.json and external TypeScript compilation",permalink:"/visual-studio-tsconfigjson-and-external"}},p={authorsImageUrls:[void 0]},u=[{value:"<code>ui-sref</code> in the Controller",id:"ui-sref-in-the-controller",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"So you're creating a link with the Angular UI Router. You're passing more than a few parameters and it's getting kinda big. Something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<a class="contains-icon"\n      ui-sref="Entity.Edit({ entityId: (vm.selectedEntityId ? vm.selectedEntityId: null), initialData: vm.initialData })">\n        <i class="fa fa-pencil"></i>Edit\n   </a>\n')),(0,a.kt)("p",null,"See? It's too long to fit on the screen without wrapping. It's clearly mad and bad."),(0,a.kt)("p",null,"Generally I try to keep the logic in a view to a minimum. It makes the view harder to read, it makes behaviour of the app harder to reason about. Also, it's not testable and (if you're using some kind of static typing like TypeScript) it is entirely out of the realms that a compiler can catch. So what to do? Move the URL generation to the controller. That's what I decided to do after I had a typo in my view which I didn't catch until post-commit."),(0,a.kt)("h2",o({},{id:"ui-sref-in-the-controller"}),(0,a.kt)("inlineCode",{parentName:"h2"},"ui-sref")," in the Controller"),(0,a.kt)("p",null,"Actually, that's not exactly what you want to do. If you look at the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://angular-ui.github.io/ui-router/site/#/api/ui.router.state.directive:ui-sref"}),"Angular UI Router docs")," you will see that ",(0,a.kt)("inlineCode",{parentName:"p"},"ui-sref")," is:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"...a directive that binds a link (",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;a&gt;")," tag) to a state. If the state has an associated URL, the directive will automatically generate & update the href attribute via the ",(0,a.kt)("a",o({parentName:"p"},{href:"http://angular-ui.github.io/ui-router/site/#/api/ui.router.state.$state#methods_href"}),(0,a.kt)("inlineCode",{parentName:"a"},"$state.href()"))," method.")),(0,a.kt)("p",null,"So what we actually want to do is use the ",(0,a.kt)("inlineCode",{parentName:"p"},"$state.href()")," method in our controller. To take our example above we'll create another method on our controller called ",(0,a.kt)("inlineCode",{parentName:"p"},"getEditUrl")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"export class EntityController {\n  $state: angular.ui.IStateService;\n\n  static $inject = ['$state'];\n  constructor($state: angular.ui.IStateService) {\n    this.$state = $state;\n  }\n\n  //... Other stuff\n\n  getEditUrl() {\n    return this.$state.href('Entity.Edit', {\n      selectedEntityId: this.selectedEntityId ? this.selectedEntityId : null,\n      initialData: this.initialData,\n    });\n  }\n}\n")),(0,a.kt)("p",null,"You can see I'm using TypeScript here; but feel free to strip out the type annotations and go with raw ES6 classes; that'll still give you testability if not static typing."),(0,a.kt)("p",null,"Now we've added the ",(0,a.kt)("inlineCode",{parentName:"p"},"getEditUrl")," method we just need to reference it in our view:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<a class="contains-icon" ng-href="{{vm.getEditUrl()}}"><i class="fa fa-pencil"></i>Edit</a>\n')),(0,a.kt)("p",null,"Note we've ditched usage of the ",(0,a.kt)("inlineCode",{parentName:"p"},"ui-sref")," directive and gone with Angular's native ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.angularjs.org/api/ng/directive/ngHref"}),(0,a.kt)("inlineCode",{parentName:"a"},"ng-href")),". Within that directive we execute our ",(0,a.kt)("inlineCode",{parentName:"p"},"getEditUrl")," as an expression which gives us our route. As a bonus, our view is much less cluttered and comprehensible as a result. How lovely."))}d.isMDXComponent=!0},21443:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"tfs-2012-meet-powershell-karma-and-buildnumber",title:"TFS 2012 meet PowerShell, Karma and BuildNumber",authors:"johnnyreilly",tags:["TFS"],hide_table_of_contents:!1},s=void 0,l={permalink:"/tfs-2012-meet-powershell-karma-and-buildnumber",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-03-04-tfs-2012-meet-powershell-karma-and-buildnumber/index.md",source:"@site/blog/2016-03-04-tfs-2012-meet-powershell-karma-and-buildnumber/index.md",title:"TFS 2012 meet PowerShell, Karma and BuildNumber",description:"To my lasting regret, TFS 2012 has no direct support for PowerShell. Such a shame as PowerShell scripts can do a lot of heavy lifting in a build process. Well, here we're going to brute force TFS 2012 into running PowerShell scripts. And along the way we'll also get Karma test results publishing into TFS 2012 as an example usage. Nice huh? Let's go!",date:"2016-03-04T00:00:00.000Z",formattedDate:"March 4, 2016",tags:[{label:"TFS",permalink:"/tags/tfs"}],readingTime:5.405,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"tfs-2012-meet-powershell-karma-and-buildnumber",title:"TFS 2012 meet PowerShell, Karma and BuildNumber",authors:"johnnyreilly",tags:["TFS"],hide_table_of_contents:!1},prevItem:{title:"Atom - Recovering from Corrupted Packages",permalink:"/atom-recovering-from-corrupted-packages"},nextItem:{title:"Creating Angular UI Routes in the Controller",permalink:"/creating-angular-ui-routes-in-controller"}},p={authorsImageUrls:[void 0]},u=[{value:"PowerShell via <code>csproj</code>",id:"powershell-via-csproj",level:2},{value:"Where&#39;s my <code>BuildNumber</code> and <code>BuildDefinitionName</code>?",id:"wheres-my-buildnumber-and-builddefinitionname",level:2},{value:"<code>AfterBuild.ps1</code>",id:"afterbuildps1",level:2},{value:"Bonus Karma: <code>test-results.trx</code>",id:"bonus-karma-test-resultstrx",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"To my lasting regret, TFS 2012 has no direct support for PowerShell. Such a shame as PowerShell scripts can do a lot of heavy lifting in a build process. Well, here we're going to brute force TFS 2012 into running PowerShell scripts. And along the way we'll also get Karma test results publishing into TFS 2012 as an example usage. Nice huh? Let's go!"),(0,a.kt)("h2",o({},{id:"powershell-via-csproj"}),"PowerShell via ",(0,a.kt)("inlineCode",{parentName:"h2"},"csproj")),(0,a.kt)("p",null,"It's time to hack the ",(0,a.kt)("inlineCode",{parentName:"p"},"csproj")," (or whatever project file you have) again. We're going to add an ",(0,a.kt)("inlineCode",{parentName:"p"},"AfterBuild")," target to the end of the file. This target will be triggered after the build completes (as the name suggests):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),"<Target Name=\"AfterBuild\">\n    <Message Importance=\"High\" Text=\"AfterBuild: PublishUrl = $(PublishUrl), BuildUri = $(BuildUri), Configuration = $(Configuration), ProjectDir = $(ProjectDir), TargetDir = $(TargetDir), TargetFileName = $(TargetFileName), BuildNumber = $(BuildNumber), BuildDefinitionName = $(BuildDefinitionName)\" />\n    <Exec Command=\"powershell.exe -NonInteractive -ExecutionPolicy RemoteSigned \"& '$(ProjectDir)AfterBuild.ps1' '$(Configuration)' '$(ProjectDir)' '$(TargetDir)' '$(PublishUrl)' '$(BuildNumber)' '$(BuildDefinitionName)'\"\" />\n  </Target>\n")),(0,a.kt)("p",null,"There's 2 things happening in this target:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"A message is printed out during compilation which contains details of the various compile time variables. This is nothing more than a ",(0,a.kt)("inlineCode",{parentName:"li"},"console.log")," statement really; it's useful for debugging and so I keep it around. You'll notice one of them is called ",(0,a.kt)("inlineCode",{parentName:"li"},"$(BuildNumber)"),"; more on that later."),(0,a.kt)("li",{parentName:"ol"},"A command is executed; PowerShell! This invokes PowerShell with the ",(0,a.kt)("inlineCode",{parentName:"li"},"-NonInteractive")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"-ExecutionPolicy RemoteSigned")," flags. It passes a script to be executed called ",(0,a.kt)("inlineCode",{parentName:"li"},"AfterBuild.ps1")," that lives in the root of the project directory. To that script a number of parameters are supplied; compile time variables that we may use in the script.")),(0,a.kt)("h2",o({},{id:"wheres-my-buildnumber-and-builddefinitionname"}),"Where's my ",(0,a.kt)("inlineCode",{parentName:"h2"},"BuildNumber")," and ",(0,a.kt)("inlineCode",{parentName:"h2"},"BuildDefinitionName"),"?"),(0,a.kt)("p",null,"So you've checked in your changes and kicked off a build on the server. You're picking over the log messages and you're thinking: \"Where's my ",(0,a.kt)("inlineCode",{parentName:"p"},"BuildNumber"),"?\". Well, TFS 2012 does not have that set as a variable at compile time by default. This stumped me for a while but thankfully I wasn't the only person wondering... As ever, ",(0,a.kt)("a",o({parentName:"p"},{href:"http://stackoverflow.com/a/7330453/761388"}),"Stack Overflow had the answer"),". So, deep breath, it's time to hack the TFS build template file."),(0,a.kt)("p",null,"Checkout the ",(0,a.kt)("inlineCode",{parentName:"p"},"DefaultTemplate.11.1.xaml")," file from TFS and open it in your text editor of choice. It's ",(0,a.kt)("em",{parentName:"p"},"find and replace")," time! (There are probably 2 instances that need replacement.) Perform a ",(0,a.kt)("em",{parentName:"p"},"find")," for the below"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"[String.Format(&quot;/p:SkipInvalidConfigurations=true {0}&quot;, MSBuildArguments)]\n")),(0,a.kt)("p",null,"And ",(0,a.kt)("em",{parentName:"p"},"replace")," it with this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"[\n  String.Format(\n    '/p:SkipInvalidConfigurations=true /p:BuildNumber={1} /p:BuildDefinitionName={2} {0}',\n    MSBuildArguments,\n    BuildDetail.BuildNumber,\n    BuildDetail.BuildDefinition.Name\n  ),\n];\n")),(0,a.kt)("p",null,"Pretty long line eh? Let's try breaking that up to make it more readable: (but remember in the XAML it needs to be a one liner)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),'[String.Format("/p:SkipInvalidConfigurations=true\n    /p:BuildNumber={1}\n    /p:BuildDefinitionName={2} {0}", MSBuildArguments, BuildDetail.BuildNumber, BuildDetail.BuildDefinition.Name)]\n')),(0,a.kt)("p",null,"We're just adding 2 extra parameters of ",(0,a.kt)("inlineCode",{parentName:"p"},"BuildNumber")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"BuildDefinitionName")," to the invocation of MSBuild. Once we've checked this back in, ",(0,a.kt)("inlineCode",{parentName:"p"},"BuildNumber")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"BuildDefinitionName")," will be available on future builds. Yay! ",(0,a.kt)("em",{parentName:"p"},"Important! You must have a build name that does not feature spaces; probably there's a way to pass spaces here but I'm not sure what it is.")),(0,a.kt)("h2",o({},{id:"afterbuildps1"}),(0,a.kt)("inlineCode",{parentName:"h2"},"AfterBuild.ps1")),(0,a.kt)("p",null,"You can use your ",(0,a.kt)("inlineCode",{parentName:"p"},"AfterBuild.ps1")," script to do any number of things. In my case I'm going to use MSTest to publish some test results which have been generated by Karma into TFS:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),'param ([string]$configuration, [string]$projectDir, [string]$targetDir, [string]$publishUrl, [string]$buildNumber, [string] $buildDefinitionName)\n\n$ErrorActionPreference = \'Stop\'\nClear\n\nfunction PublishTestResults([string]$resultsFile) {\n Write-Host \'PublishTests\'\n $mstest = \'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE\\MSTest.exe\'\n\n Write-Host "Using $mstest at $pwd"\n Write-Host "Publishing: $resultsFile"\n\n & $mstest /publishresultsfile:$resultsFile /publish:http://my-tfs-server:8080/tfs /teamproject:MyProject /publishbuild:$buildNumber /platform:\'Any CPU\' /flavor:Release\n}\n\nfunction FailBuildIfThereAreTestFailures([string]$resultsFile) {\n $results = [xml](GC $resultsFile)\n $outcome = $results.TestRun.ResultSummary.outcome\n $fgColor = if($outcome -eq "Failed") { "Red" } else { "Green" }\n $total = $results.TestRun.ResultSummary.Counters.total\n $passed = $results.TestRun.ResultSummary.Counters.passed\n $failed = $results.TestRun.ResultSummary.Counters.failed\n\n $failedTests = $results.TestRun.Results.UnitTestResult | Where-Object { $_.outcome -eq "Failed" }\n\n Write-Host Test Results: $outcome -ForegroundColor $fgColor -BackgroundColor "Black"\n Write-Host Total tests: $total\n Write-Host Passed: $passed\n Write-Host Failed: $failed\n Write-Host\n\n $failedTests | % { Write-Host Failed test: $_.testName\n  Write-Host $_.Output.ErrorInfo.Message\n  Write-Host $_.Output.ErrorInfo.StackTrace }\n\n Write-Host\n\n if($outcome -eq "Failed") {\n  Write-Host "Failing build as there are broken tests"\n  $host.SetShouldExit(1)\n }\n}\n\nfunction Run() {\n  Write-Host "Running AfterBuild.ps1 using Configuration: $configuration, projectDir: $projectDir, targetDir: $targetDir, publishUrl: $publishUrl, buildNumber: $buildNumber, buildDefinitionName: $buildDefinitionName"\n\n if($buildNumber) {\n  $resultsFile = "$projectDir\\test-results.trx"\n  PublishTestResults $resultsFile\n  FailBuildIfThereAreTestFailures $resultsFile\n }\n}\n\n# Off we go...\nRun\n')),(0,a.kt)("p",null,"Assuming we have a build number this script kicks off the ",(0,a.kt)("inlineCode",{parentName:"p"},"PublishTestResults")," function above. So we won't attempt to publish test results when compiling in Visual Studio on our dev machine. The script looks for ",(0,a.kt)("inlineCode",{parentName:"p"},"MSTest.exe")," in a certain location on disk (the default VS 2015 installation location in fact; it may be installed elsewhere on your build machine). MSTest is then invoked and passed a file called ",(0,a.kt)("inlineCode",{parentName:"p"},"test-results.trx")," which is is expected to live in the root of the project. All being well, the test results will be registered with the running build and will be visible when you look at test results in TFS."),(0,a.kt)("p",null,"Finally in ",(0,a.kt)("inlineCode",{parentName:"p"},"FailBuildIfThereAreTestFailures")," we parse the ",(0,a.kt)("inlineCode",{parentName:"p"},"test-results.trx")," file (and for this I'm totally in the debt of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://gist.github.com/davidroberts63/5655441"}),"David Robert's helpful Gist"),"). We write out the results to the host so it'll show up in the MSBuild logs. Also, and this is crucial, if there are any failures we fail the build by exiting PowerShell with a code of 1. We are deliberately swallowing any error that Karma raises earlier when it detects failed tests. We do this because we want to publish the failed test results to TFS ",(0,a.kt)("em",{parentName:"p"},"before")," we kill the build."),(0,a.kt)("h2",o({},{id:"bonus-karma-test-resultstrx"}),"Bonus Karma: ",(0,a.kt)("inlineCode",{parentName:"h2"},"test-results.trx")),(0,a.kt)("p",null,"If you've read a ",(0,a.kt)("a",o({parentName:"p"},{href:"/visual-studio-tsconfigjson-and-external"}),"previous post of mine")," you'll be aware that it's possible to get MSBuild to kick off npm build tasks. Specifically I have MSBuild kicking off an ",(0,a.kt)("inlineCode",{parentName:"p"},"npm run build"),". My ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"scripts": {\n    "test": "karma start --reporters mocha,trx --single-run --browsers PhantomJS",\n    "clean": "gulp delete-dist-contents",\n    "watch": "gulp watch",\n    "build": "gulp build",\n    "postbuild": "npm run test"\n  },\n')),(0,a.kt)("p",null,"You can see that the ",(0,a.kt)("inlineCode",{parentName:"p"},"postbuild")," hook kicks off the ",(0,a.kt)("inlineCode",{parentName:"p"},"test")," script in turn. And that ",(0,a.kt)("inlineCode",{parentName:"p"},"test")," script kicks off a single run of karma. I'm not going to go over setting up Karma at all here; there are other posts out there that cover that admirably. But I wanted to share news of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/karma-trx-reporter"}),"karma trx reporter"),". This reporter is the thing that produces our ",(0,a.kt)("inlineCode",{parentName:"p"},"test-results.trx")," file; trx being the format that TFS likes to deal with."),(0,a.kt)("p",null,"So now we've got a PowerShell hook into our build process (something very useful in itself) which we are using to publish Karma test results into TFS 2012. They said it couldn't be done. They were wrong. Huzzah!!!!!!!"))}d.isMDXComponent=!0},51351:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"atom-recovering-from-corrupted-packages",title:"Atom - Recovering from Corrupted Packages",authors:"johnnyreilly",tags:["Atom"],hide_table_of_contents:!1},s=void 0,l={permalink:"/atom-recovering-from-corrupted-packages",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-03-17-atom-recovering-from-corrupted-packages/index.md",source:"@site/blog/2016-03-17-atom-recovering-from-corrupted-packages/index.md",title:"Atom - Recovering from Corrupted Packages",description:"Every now and then when I try and update my packages in Atom I find this glaring back at me:",date:"2016-03-17T00:00:00.000Z",formattedDate:"March 17, 2016",tags:[{label:"Atom",permalink:"/tags/atom"}],readingTime:.71,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"atom-recovering-from-corrupted-packages",title:"Atom - Recovering from Corrupted Packages",authors:"johnnyreilly",tags:["Atom"],hide_table_of_contents:!1},prevItem:{title:"Concatting IEnumerables in C#",permalink:"/concatting-ienumerables-in-csharp"},nextItem:{title:"TFS 2012 meet PowerShell, Karma and BuildNumber",permalink:"/tfs-2012-meet-powershell-karma-and-buildnumber"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Every now and then when I try and update my packages in ",(0,a.kt)("a",o({parentName:"p"},{href:"https://atom.io/"}),"Atom")," I find this glaring back at me:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(7468).Z,width:"640",height:"346"})),(0,a.kt)("p",null,"Ug. The problem is that my atom packages have become corrupt. Quite how I couldn't say. But that's the problem. Atom, as I know from bitter experience, will not recover from this. It just sits there feeling sorry for itself. However, getting back to where you belong is simpler than you imagine:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Shutdown Atom"),(0,a.kt)("li",{parentName:"ol"},"In the file system go to ",(0,a.kt)("inlineCode",{parentName:"li"},"[Your name]/.atom")," (and bear in mind this is Windows; Macs / Linux may be different)")),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(66148).Z,width:"640",height:"250"})),(0,a.kt)("ol",o({},{start:3}),(0,a.kt)("li",{parentName:"ol"},"You'll see an ",(0,a.kt)("inlineCode",{parentName:"li"},".apm")," folder that contains all your packages. Delete this.")),(0,a.kt)("p",null,"When you next fire up Atom these packages will automagically come back but this time they shouldn't be corrupt. Instead you should see the happiness of normality restored:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(19888).Z,width:"640",height:"346"})))}d.isMDXComponent=!0},82941:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"concatting-ienumerables-in-csharp",title:"Concatting IEnumerables in C#",authors:"johnnyreilly",tags:["C#"],hide_table_of_contents:!1},s=void 0,l={permalink:"/concatting-ienumerables-in-csharp",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-03-22-concatting-ienumerables-in-csharp/index.md",source:"@site/blog/2016-03-22-concatting-ienumerables-in-csharp/index.md",title:"Concatting IEnumerables in C#",description:"I hate LINQ's Enumerable.Concat when bringing together IEnumerables. Not the behaviour (I love that!) but rather how code ends up looking when you use it. Consider this:",date:"2016-03-22T00:00:00.000Z",formattedDate:"March 22, 2016",tags:[{label:"C#",permalink:"/tags/c"}],readingTime:2.525,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"concatting-ienumerables-in-csharp",title:"Concatting IEnumerables in C#",authors:"johnnyreilly",tags:["C#"],hide_table_of_contents:!1},prevItem:{title:"Instant Stubs with JSON.Net (just add hot water)",permalink:"/instant-stubs-with-jsonnet"},nextItem:{title:"Atom - Recovering from Corrupted Packages",permalink:"/atom-recovering-from-corrupted-packages"}},p={authorsImageUrls:[void 0]},u=[{value:"Attempt #1: <code>ConcatMany</code>",id:"attempt-1-concatmany",level:2},{value:"Attempt #2: <code>EnumerableExtensions.Create</code>",id:"attempt-2-enumerableextensionscreate",level:2},{value:"What Gives Elvis?",id:"what-gives-elvis",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I hate LINQ's ",(0,a.kt)("a",o({parentName:"p"},{href:"https://msdn.microsoft.com/en-us/library/bb302894%28v=vs.110%29.aspx?f=255&MSPPError=-2147217396"}),(0,a.kt)("inlineCode",{parentName:"a"},"Enumerable.Concat"))," when bringing together ",(0,a.kt)("inlineCode",{parentName:"p"},"IEnumerable"),"s. Not the behaviour (I love that!) but rather how code ends up looking when you use it. Consider this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"var concatenated = myCollection?.Select(x => new ConcatObj(x)) ?? new ConcatObj[0].Concat(\n   myOtherCollection?.Select(x => new ConcatObj(x)) ?? new ConcatObj[0]\n);\n")),(0,a.kt)("p",null,"In this example I'm bringing together 2 collections, either of which may be null (more on that later). I think we can all agree this doesn't represent a world of readability. I've also had to create a custom class ",(0,a.kt)("inlineCode",{parentName:"p"},"ConcatObj")," because you can't create an empty array for an anonymous type in C#."),(0,a.kt)("h2",o({},{id:"attempt-1-concatmany"}),"Attempt #1: ",(0,a.kt)("inlineCode",{parentName:"h2"},"ConcatMany")),(0,a.kt)("p",null,"After toying around with a bunch of different ideas I created this extension method:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public static class FunctionalExtensions\n{\n    public static IEnumerable<T> ConcatMany<T>(\n        this IEnumerable<T> original,\n        params IEnumerable<T>[] enumerablesToConcat) => original.Concat(\n            enumerablesToConcat.Where(e => e != null).SelectMany(c => c)\n        );\n}\n")),(0,a.kt)("p",null,"Thanks to the joy of ",(0,a.kt)("inlineCode",{parentName:"p"},"params")," this extension allows me to bring together multiple IEnumerables into a single one but has the advantage of considerably cleaner calling code:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"var concatenated = Enumerable.Empty<ConcatObj>().ConcatMany(\n    myCollection?.Select(x => new ConcatObj(x)),\n    myOtherCollection?.Select(x => new ConcatObj(x))\n    );\n")),(0,a.kt)("p",null,"For my money this is more readable and intent is clearer. Particularly as the number of contributing IEnumerables goes up. The downside is that I can\u2019t use anonymous objects because you need to tell the compiler what the type is when using ",(0,a.kt)("inlineCode",{parentName:"p"},'<a href="https://msdn.microsoft.com/en-us/library/bb341042%28v=vs.110%29.aspx?f=255&amp;MSPPError=-2147217396">Enumerable.Empty</a>'),"."),(0,a.kt)("p",null,"Wouldn't it be nice to have both:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Readable code and"),(0,a.kt)("li",{parentName:"ol"},"Anonymous objects?")),(0,a.kt)("h2",o({},{id:"attempt-2-enumerableextensionscreate"}),"Attempt #2: ",(0,a.kt)("inlineCode",{parentName:"h2"},"EnumerableExtensions.Create")),(0,a.kt)("p",null,"After batting round a few ideas (thanks Matt) I settled on this implementation:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public static class EnumerableExtensions\n{\n    public static IEnumerable<TSource> Create<TSource>(params IEnumerable<TSource>[] enumerables)\n    {\n        return Concat(enumerables.Where(e => e != null));\n    }\n\n    private static IEnumerable<TSource> Concat<TSource>(IEnumerable<IEnumerable<TSource>> enumerables)\n    {\n        foreach (var enumerable in enumerables)\n        {\n            foreach (var item in enumerable)\n            {\n                yield return item;\n            }\n        }\n    }\n}\n")),(0,a.kt)("p",null,"Which allows for calling code like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"var concatenated = EnumerableExtensions.Create(\n    myCollection?.Select(x => new { Anonymous = x.Types }),\n    myOtherCollection?.Select(x => new { Anonymous = x.Types })\n);\n")),(0,a.kt)("p",null,"That's right; anonymous types are back! Strictly speaking the ",(0,a.kt)("inlineCode",{parentName:"p"},"Concat")," method above could be converted into a single ",(0,a.kt)("inlineCode",{parentName:"p"},"SelectMany")," (and boy does ReSharper like telling me) but I'm quite happy with it as is. And to be honest, I so rarely get to use ",(0,a.kt)("inlineCode",{parentName:"p"},"yield")," in my own code; I thought it might be nice to give it a whirl \ud83d\ude0a"),(0,a.kt)("h2",o({},{id:"what-gives-elvis"}),"What Gives Elvis?"),(0,a.kt)("p",null,"If you look closely at the implementation you'll notice that I purge all ",(0,a.kt)("inlineCode",{parentName:"p"},"null"),"s when I'm bringing together the ",(0,a.kt)("inlineCode",{parentName:"p"},"Enumerable"),'s. For why? Some may legitimately argue this is a bad idea. However, there is method in my "bad practice".'),(0,a.kt)("p",null,"I've chosen to treat ",(0,a.kt)("inlineCode",{parentName:"p"},"null"),' as "not important" for this use case. I\'m doing this because it emerges that ASP.NET MVC deserialises empty collections as nulls. (See ',(0,a.kt)("a",o({parentName:"p"},{href:"http://aspnetwebstack.codeplex.com/SourceControl/latest#src/System.Web.Mvc/ValueProviderResult.cs"}),"here")," and play spot the ",(0,a.kt)("inlineCode",{parentName:"p"},"return null;"),") Which is a pain. But thanks to the null purging behaviour of ",(0,a.kt)("inlineCode",{parentName:"p"},"EnumerableExtensions.Create")," I can trust in the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://csharp.today/c-6-features-null-conditional-and-and-null-coalescing-operators/"}),"null-conditional (Elvis)")," operator to not do me wrong."))}d.isMDXComponent=!0},8489:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"instant-stubs-with-jsonnet",title:"Instant Stubs with JSON.Net (just add hot water)",authors:"johnnyreilly",tags:["unit testing","json.net"],hide_table_of_contents:!1},s=void 0,l={permalink:"/instant-stubs-with-jsonnet",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-04-25-instant-stubs-with-jsonnet/index.md",source:"@site/blog/2016-04-25-instant-stubs-with-jsonnet/index.md",title:"Instant Stubs with JSON.Net (just add hot water)",description:"I'd like you to close your eyes and imagine a scenario. You're handed a prototype system. You're told it works. It has no documentation. It has 0 unit tests. The hope is that you can take it on, refactor it, make it better and (crucially) not break it. Oh, and you don't really understand what the code does or why it does it either; information on that front is, alas, sorely lacking.",date:"2016-04-25T00:00:00.000Z",formattedDate:"April 25, 2016",tags:[{label:"unit testing",permalink:"/tags/unit-testing"},{label:"json.net",permalink:"/tags/json-net"}],readingTime:4.05,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"instant-stubs-with-jsonnet",title:"Instant Stubs with JSON.Net (just add hot water)",authors:"johnnyreilly",tags:["unit testing","json.net"],hide_table_of_contents:!1},prevItem:{title:"Inlining Angular Templates with WebPack and TypeScript",permalink:"/inlining-angular-templates-with-webpack"},nextItem:{title:"Concatting IEnumerables in C#",permalink:"/concatting-ienumerables-in-csharp"}},p={authorsImageUrls:[void 0]},u=[{value:"Instant Stubs",id:"instant-stubs",level:2},{value:"Using your JSON",id:"using-your-json",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I'd like you to close your eyes and imagine a scenario. You're handed a prototype system. You're told it works. It has no documentation. It has 0 unit tests. The hope is that you can take it on, refactor it, make it better and (crucially) not break it. Oh, and you don't really understand what the code does or why it does it either; information on that front is, alas, sorely lacking."),(0,a.kt)("p",null,"This has happened to me; it's alas not that unusual. The common advice handed out in this situation is: \"add unit tests before you change it\". That's good advice. We need to take the implementation that embodies the correctness of the system and create unit tests that set that implementation in stone. However, what say the system that you're hoping to add tests to takes a number of large and complex inputs from some external source and produces a similarly large and complex output?"),(0,a.kt)("p",null,"You could start with integration tests. They're good but slow and crucially they depend upon the external inputs being available and unchanged (which is perhaps unlikely). What you could do (what I have done) is debug a working working system. At each point that an input is obtained I have painstakingly transcribed the data which allows me to subsequently hand code stub data. There comes a point when this is plainly untenable; it's just too much data to transcribe. At this point the temptation is to think \"it's okay; I can live without the tests. I'll just be super careful with my refactoring... It'll be fine It'll be fine It'll be fine It'll be fine\"."),(0,a.kt)("p",null,"Actually, it probably won't be fine. And even if it is (miracles do happen) you're going to be fairly stressed as you wonder if you've been careful enough. What if there was another way? A way that wasn't quite so hard but that allowed you to add tests without requiring 3 months hand coding...."),(0,a.kt)("h2",o({},{id:"instant-stubs"}),"Instant Stubs"),(0,a.kt)("p",null,"What I've come up with is a super simple utility class for creating stubs / fakes. (I'm aware the naming of such things ",(0,a.kt)("a",o({parentName:"p"},{href:"http://martinfowler.com/articles/mocksArentStubs.html"}),"can be a little contentious"),".)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using Newtonsoft.Json;\nusing System;\nusing System.IO;\n\nnamespace MakeFakeData.UnitTests\n{\n  public static class Stubs\n  {\n    private static JsonSerializer _serializer = new JsonSerializer { NullValueHandling = NullValueHandling.Ignore };\n\n    public static void Make<T>(string stubPath, T data)\n    {\n      try\n      {\n        if (string.IsNullOrEmpty(stubPath))\n          throw new ArgumentNullException(nameof(stubPath));\n        if (data == null)\n          throw new ArgumentNullException(nameof(data));\n\n        using (var sw = new StreamWriter(stubPath))\n        using (var writer = new JsonTextWriter(sw) {\n            Formatting = Formatting.Indented,\n            IndentChar = \' \',\n            Indentation = 2})\n        {\n          _serializer.Serialize(writer, data);\n        }\n      }\n      catch (Exception exc)\n      {\n        throw new Exception($"Failed to make {stubPath}", exc);\n      }\n    }\n\n    public static T Load<T>(string stubPath)\n    {\n      try\n      {\n        if (string.IsNullOrEmpty(stubPath))\n          throw new ArgumentNullException(nameof(stubPath));\n\n        using (var file = File.OpenText(stubPath))\n        using (var reader = new JsonTextReader(file))\n        {\n          return _serializer.Deserialize<T>(reader);\n        }\n      }\n      catch (Exception exc)\n      {\n        throw new Exception($"Failed to load {stubPath}", exc);\n      }\n    }\n  }\n}\n')),(0,a.kt)("p",null,"As you can see this class uses ",(0,a.kt)("a",o({parentName:"p"},{href:"http://www.newtonsoft.com/json"}),"JSON.Net")," and exposes 2 methods:"),(0,a.kt)("dl",null,(0,a.kt)("dt",null,"Make"),(0,a.kt)("dd",null,"Takes a given piece of data and uses JSON.Net to serialise it as JSON to a file. (nb I choose to format the JSON for readability and exclude null values; both totally optional)"),(0,a.kt)("dt",null,"Load"),(0,a.kt)("dd",null,"Takes the given path and loads the associated JSON file and deserialises it back into an object.")),(0,a.kt)("p",null,"The idea is this: we take our working implementation and, wherever it extracts data from an external source, we insert a temporary statement like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'var data = _dataService.GetComplexData();\n\n    // Just inserted so we can generate the stub data...\n    Stubs.Make($"{System.AppDomain.CurrentDomain.BaseDirectory}\\\\data.json", data);\n')),(0,a.kt)("p",null,"The next time you run the implementation you'll find the app generates a ",(0,a.kt)("inlineCode",{parentName:"p"},"data.json")," file containing the complex data serialized to JSON. Strip out your ",(0,a.kt)("inlineCode",{parentName:"p"},"Stubs.Make")," statements from the implementation and we're ready for the next stage."),(0,a.kt)("h2",o({},{id:"using-your-json"}),"Using your JSON"),(0,a.kt)("p",null,"What you need to do now is to take the new and shiny ",(0,a.kt)("inlineCode",{parentName:"p"},"data.json")," file and move it to your unit test project. It needs to be included within the unit test project. Also, for each JSON file you have, the ",(0,a.kt)("inlineCode",{parentName:"p"},"Build Action")," in VS needs to be set to ",(0,a.kt)("inlineCode",{parentName:"p"},"Content")," and the ",(0,a.kt)("inlineCode",{parentName:"p"},"Copy to Output Directory")," to ",(0,a.kt)("inlineCode",{parentName:"p"},"Copy if newer"),"."),(0,a.kt)("p",null,"Then within your unit tests you can write code like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"var dummyData = Stubs.Load<ComplexDataType>('Stubs/data.json');\n")),(0,a.kt)("p",null,"Which pulls in your data from the JSON file and deserialises it into the original types. With this in hand you can plug together a unit test based on an existing implementation which depends on external data much faster than the hand-cranked method of old."),(0,a.kt)("p",null,"Finally, before the wildebeest of TDD descend upon me howling and wailing, let me say again; I anticipate this being useful when you're trying to add tests to something that already exists but is untested. Clearly it would be better not to be in this situaion in the first place."))}d.isMDXComponent=!0},37665:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"inlining-angular-templates-with-webpack",title:"Inlining Angular Templates with WebPack and TypeScript",authors:"johnnyreilly",tags:["AngularJS","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/inlining-angular-templates-with-webpack",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-05-13-inlining-angular-templates-with-webpack/index.md",source:"@site/blog/2016-05-13-inlining-angular-templates-with-webpack/index.md",title:"Inlining Angular Templates with WebPack and TypeScript",description:"This technique actually applies to pretty much any web stack where you have to supply templates; it just so happens that I'm using Angular 1.x in this case. Also I have an extra technique which is useful to handle the ng-include scenario.",date:"2016-05-13T00:00:00.000Z",formattedDate:"May 13, 2016",tags:[{label:"AngularJS",permalink:"/tags/angular-js"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:2.9,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"inlining-angular-templates-with-webpack",title:"Inlining Angular Templates with WebPack and TypeScript",authors:"johnnyreilly",tags:["AngularJS","webpack"],hide_table_of_contents:!1},prevItem:{title:"The Mysterious Case of webpack, AngularJS and jQuery",permalink:"/the-mysterious-case-of-webpack-angular-and-jquery"},nextItem:{title:"Instant Stubs with JSON.Net (just add hot water)",permalink:"/instant-stubs-with-jsonnet"}},p={authorsImageUrls:[void 0]},u=[{value:"Preamble",id:"preamble",level:2},{value:"raw-loader!",id:"raw-loader",level:2},{value:"ng-include",id:"ng-include",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This technique actually applies to pretty much any web stack where you have to supply templates; it just so happens that I'm using Angular 1.x in this case. Also I have an extra technique which is useful to handle the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.angularjs.org/api/ng/directive/ngInclude"}),"ng-include")," scenario."),(0,a.kt)("h2",o({},{id:"preamble"}),"Preamble"),(0,a.kt)("p",null,"For some time I've been using webpack to bundle my front end. I write ES6 TypeScript; import statements and all. This is all sewn together using the glorious ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/ts-loader"}),"ts-loader")," to compile and emit ES6 code which is handed off to the wonderful ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/babel-loader"}),"babel-loader")," which transpiles it to ESold code. All with full source map support. It's wonderful."),(0,a.kt)("p",null,"However, up until now I've been leaving Angular to perform the relevant http requests at runtime when it needs to pull in templates. That works absolutely fine but my preference is to preload those templates. In fact I've ",(0,a.kt)("a",o({parentName:"p"},{href:"/using-gulp-in-asp-net-instead-of-web-optimization"}),"written before")," about using the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/gulp-angular-templatecache"}),"gulp angular template cache")," to achieve just that aim."),(0,a.kt)("p",null,"So I was wondering; in this modular world what would be the equivalent approach? Sure I could still use the gulp angular template cache approach but I would like something a little more deliberate and a little less magic. Also, I've discovered (to my cost) that when using the existing approach, it's possible to break the existing implementation without realising it; only finding out there's a problem in Production when unexpected http requests start happening. Finding these problems out at compile time rather than runtime is always to be strived for. So how?"),(0,a.kt)("h2",o({},{id:"raw-loader"}),(0,a.kt)("a",o({parentName:"h2"},{href:"https://www.npmjs.com/package/raw-loader"}),"raw-loader"),"!"),(0,a.kt)("p",null,"raw-loader allows you load file content using ",(0,a.kt)("inlineCode",{parentName:"p"},"require")," statements. This works well with the use case of inlining html. So I drop it into my ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js")," like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var path = require('path');\n\nmodule.exports = {\n  cache: true,\n  entry: {\n    main: './src/main.ts',\n\n    vendor: [\n      'babel-polyfill',\n      'angular',\n      'angular-animate',\n      'angular-sanitize',\n      'angular-ui-bootstrap',\n      'angular-ui-router',\n    ],\n  },\n  output: {\n    path: path.resolve(__dirname, './dist/scripts'),\n    filename: '[name].js',\n    chunkFilename: '[chunkhash].js',\n  },\n  module: {\n    loaders: [\n      {\n        test: /\\.ts(x?)$/,\n        exclude: /node_modules/,\n        loader: 'babel-loader?presets[]=es2015!ts-loader',\n      },\n      {\n        test: /\\.js$/,\n        exclude: /node_modules/,\n        loader: 'babel',\n        query: {\n          presets: ['es2015'],\n        },\n      },\n      {\n        // THIS IS THE MAGIC!\n        test: /\\.html$/,\n        exclude: /node_modules/,\n        loader: 'raw',\n      },\n    ], // THAT WAS THE MAGIC!\n  },\n  plugins: [\n    // ....\n  ],\n  resolve: {\n    extensions: ['', '.ts', '.tsx', '.js'],\n  },\n};\n")),(0,a.kt)("p",null,"With this in place, if someone requires a file with the ",(0,a.kt)("inlineCode",{parentName:"p"},"html")," suffix then raw-loader comes in. So now we can swap this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"$stateProvider.state('state1', {\n  url: '/state1',\n  templateUrl: 'partials/state1.html',\n});\n")),(0,a.kt)("p",null,"For this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"$stateProvider.state('state1', {\n  url: '/state1',\n  template: require('./partials/state1.html'),\n});\n")),(0,a.kt)("p",null,"Now initially TypeScript is going to complain about your ",(0,a.kt)("inlineCode",{parentName:"p"},"require")," statement. That's fair; outside of node-land it doesn't know what ",(0,a.kt)("inlineCode",{parentName:"p"},"require")," is. No bother, you just need to drop in a one line simple definition file to sort this out; let me present ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack-require.d.ts"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"declare var require: (filename: string) => any;\n")),(0,a.kt)("p",null,"You've now inlined your template. And for bonus points, if you were to make a mistake in your path then webpack would shout at you at compile time; which is a ",(0,a.kt)("em",{parentName:"p"},"good, good")," thing."),(0,a.kt)("h2",o({},{id:"ng-include"}),"ng-include"),(0,a.kt)("p",null,"The one use case that this doesn't cover is where your templates import other templates through use of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.angularjs.org/api/ng/directive/ngInclude"}),"ng-include")," directive. They will still trigger http requests as the templates are served. The simple way to prevent that is by priming the angular ",(0,a.kt)("inlineCode",{parentName:"p"},'<a href="https://docs.angularjs.org/api/ng/service/$templateCache">$templateCache</a>')," like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"app.run([\n  '$templateCache',\n  ($templateCache: ng.ITemplateCacheService) => {\n    $templateCache.put('justSome.html', require('./justSome.html'));\n    // Other templates go here...\n  },\n]);\n")),(0,a.kt)("p",null,"Now when the app spins up it already has everything it needs pre-cached."))}d.isMDXComponent=!0},81386:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"the-mysterious-case-of-webpack-angular-and-jquery",title:"The Mysterious Case of webpack, AngularJS and jQuery",authors:"johnnyreilly",tags:["jquery","AngularJS","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/the-mysterious-case-of-webpack-angular-and-jquery",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-05-24-the-mysterious-case-of-webpack-angular-and-jquery/index.md",source:"@site/blog/2016-05-24-the-mysterious-case-of-webpack-angular-and-jquery/index.md",title:"The Mysterious Case of webpack, AngularJS and jQuery",description:"You may know that Angular ships with a cutdown version of jQuery called jQLite. It's still possible to use the full-fat jQuery; to quote the docs:",date:"2016-05-24T00:00:00.000Z",formattedDate:"May 24, 2016",tags:[{label:"jquery",permalink:"/tags/jquery"},{label:"AngularJS",permalink:"/tags/angular-js"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:1.895,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"the-mysterious-case-of-webpack-angular-and-jquery",title:"The Mysterious Case of webpack, AngularJS and jQuery",authors:"johnnyreilly",tags:["jquery","AngularJS","webpack"],hide_table_of_contents:!1},prevItem:{title:"Creating an ES2015 Map from an Array in TypeScript",permalink:"/create-es2015-map-from-array-in-typescript"},nextItem:{title:"Inlining Angular Templates with WebPack and TypeScript",permalink:"/inlining-angular-templates-with-webpack"}},p={authorsImageUrls:[void 0]},u=[{value:"But wait! I&#39;m using webpack",id:"but-wait-im-using-webpack",level:2},{value:"You need the <code>ProvidePlugin</code>",id:"you-need-the-provideplugin",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"You may know that ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.angularjs.org/api/ng/function/angular.element"}),"Angular ships with a cutdown version of jQuery called jQLite"),". It's still possible to use the full-fat jQuery; to quote the docs:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"To use ",(0,a.kt)("inlineCode",{parentName:"p"},"jQuery"),", simply ensure it is loaded before the ",(0,a.kt)("inlineCode",{parentName:"p"},"angular.js")," file.")),(0,a.kt)("p",null,"Now the wording rather implies that you're not using any module loader / bundler. Rather that all files are being loaded via ",(0,a.kt)("inlineCode",{parentName:"p"},"script")," tags and relies on the global variables that result from that. True enough, if you take a look at the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/angular/angular.js/blob/eaa1119d4252bed08dfa42f984ef9502d0f02775/src/Angular.js#L1791"}),"Angular source")," you can see how this works:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"// bind to jQuery if present;\nvar jqName = jq();\njQuery = isUndefined(jqName)\n  ? window.jQuery // use jQuery (if present)\n  : !jqName\n  ? undefined // use jqLite\n  : window[jqName]; // use jQuery specified by `ngJq`\n")),(0,a.kt)("p",null,"Amongst other things it looks for a ",(0,a.kt)("inlineCode",{parentName:"p"},"jQuery")," variable which has been placed onto the ",(0,a.kt)("inlineCode",{parentName:"p"},"window")," object. If it is found then jQuery is used; if it is not then it's ",(0,a.kt)("inlineCode",{parentName:"p"},"jqLite")," all the way."),(0,a.kt)("h2",o({},{id:"but-wait-im-using-webpack"}),"But wait! I'm using webpack"),(0,a.kt)("p",null,"Me too! And one of the reasons is that we get to move away from reliance upon the global scope and towards proper modularisation. So how do we get Angular to use jQuery given the code we've seen above? Well, your first thought might be to ",(0,a.kt)("inlineCode",{parentName:"p"},"npm install")," yourself some ",(0,a.kt)("inlineCode",{parentName:"p"},"jQuery")," and then make sure you've got something like this in your entry file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import 'jquery'; // This'll fix it... Right?\nimport * as angular from 'angular';\n")),(0,a.kt)("p",null,"Wrong."),(0,a.kt)("h2",o({},{id:"you-need-the-provideplugin"}),"You need the ",(0,a.kt)("inlineCode",{parentName:"h2"},"ProvidePlugin")),(0,a.kt)("p",null,"In your ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js")," you need to add the following entry to your plugins:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),'new webpack.ProvidePlugin({\n          "window.jQuery": "jquery"\n      }),\n')),(0,a.kt)("p",null,"This uses the webpack ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/docs/wiki/list-of-plugins#provideplugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"ProvidePlugin"))," and, at the point of webpackification (\xa9 2016 John Reilly) all references in the code to ",(0,a.kt)("inlineCode",{parentName:"p"},"window.jQuery")," will be replaced with a reference to the webpack module that contains jQuery. So when you look at the bundled file you'll see that the code that checks the ",(0,a.kt)("inlineCode",{parentName:"p"},"window")," object for ",(0,a.kt)("inlineCode",{parentName:"p"},"jQuery")," has become this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"jQuery = isUndefined(jqName)\n  ? __webpack_provided_window_dot_jQuery // use jQuery (if present)\n  : !jqName\n  ? undefined // use jqLite\n  : window[jqName]; // use jQuery specified by `ngJq`\n")),(0,a.kt)("p",null,"That's right; webpack is providing Angular with jQuery whilst still ",(0,a.kt)("em",{parentName:"p"},"not")," placing a ",(0,a.kt)("inlineCode",{parentName:"p"},"jQuery")," variable onto the ",(0,a.kt)("inlineCode",{parentName:"p"},"window"),". Neat huh?"))}d.isMDXComponent=!0},81043:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"create-es2015-map-from-array-in-typescript",title:"Creating an ES2015 Map from an Array in TypeScript",authors:"johnnyreilly",tags:["typescript","ES6","ES2015"],hide_table_of_contents:!1},s=void 0,l={permalink:"/create-es2015-map-from-array-in-typescript",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-06-02-create-es2015-map-from-array-in-typescript/index.md",source:"@site/blog/2016-06-02-create-es2015-map-from-array-in-typescript/index.md",title:"Creating an ES2015 Map from an Array in TypeScript",description:"I'm a great lover of ES2015's Map. However, just recently I tumbled over something I find a touch inconvenient about how you initialise a new Map from the contents of an Array in TypeScript.",date:"2016-06-02T00:00:00.000Z",formattedDate:"June 2, 2016",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"ES6",permalink:"/tags/es-6"},{label:"ES2015",permalink:"/tags/es-2015"}],readingTime:2.105,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"create-es2015-map-from-array-in-typescript",title:"Creating an ES2015 Map from an Array in TypeScript",authors:"johnnyreilly",tags:["typescript","ES6","ES2015"],hide_table_of_contents:!1},prevItem:{title:"Understanding webpack's DefinePlugin (and using with TypeScript)",permalink:"/using-webpacks-defineplugin-with-typescript"},nextItem:{title:"The Mysterious Case of webpack, AngularJS and jQuery",permalink:"/the-mysterious-case-of-webpack-angular-and-jquery"}},p={authorsImageUrls:[void 0]},u=[{value:"This Doesn&#39;t Work",id:"this-doesnt-work",level:2},{value:"This Does",id:"this-does",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I'm a great lover of ES2015's ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map"}),(0,a.kt)("inlineCode",{parentName:"a"},"Map")),". However, just recently I tumbled over something I find a touch inconvenient about how you initialise a new ",(0,a.kt)("inlineCode",{parentName:"p"},"Map")," from the contents of an ",(0,a.kt)("inlineCode",{parentName:"p"},"Array")," in TypeScript."),(0,a.kt)("h2",o({},{id:"this-doesnt-work"}),"This Doesn't Work"),(0,a.kt)("p",null,"We're going try to something like this: (pilfered from the MDN docs)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"var kvArray = [\n  ['key1', 'value1'],\n  ['key2', 'value2'],\n];\n\n// Use the regular Map constructor to transform a 2D key-value Array into a map\nvar myMap = new Map(kvArray);\n")),(0,a.kt)("p",null,"Simple enough right? Well I'd rather assumed that I should be able to do something like this in TypeScript:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),'const iAmAnArray [\n  { value: "value1", text: "hello" }\n  { value: "value2", text: "map" }\n];\n\nconst iAmAMap = new Map<string, string>(\n  iAmAnArray.map(x => [x.value, x.text])\n);\n')),(0,a.kt)("p",null,"However, to my surprise this errored out with:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"[ts] Argument of type 'string[][]' is not assignable to parameter of type 'Iterable<[string, string]>'.\n  Types of property '[Symbol.iterator]' are incompatible.\n    Type '() => IterableIterator<string[]>' is not assignable to type '() => Iterator<[string, string]>'.\n      Type 'IterableIterator<string[]>' is not assignable to type 'Iterator<[string, string]>'.\n        Types of property 'next' are incompatible.\n          Type '(value?: any) => IteratorResult<string[]>' is not assignable to type '(value?: any) => IteratorResult<[string, string]>'.\n            Type 'IteratorResult<string[]>' is not assignable to type 'IteratorResult<[string, string]>'.\n              Type 'string[]' is not assignable to type '[string, string]'.\n                Property '0' is missing in type 'string[]'.\n")),(0,a.kt)("p",null,"Disappointing right? It's expecting ",(0,a.kt)("inlineCode",{parentName:"p"},"Iterable&lt;[string, string]&gt;")," and an ",(0,a.kt)("inlineCode",{parentName:"p"},"Array")," with 2 elements that are strings is ",(0,a.kt)("em",{parentName:"p"},"not")," inferred to be that."),(0,a.kt)("h2",o({},{id:"this-does"}),"This Does"),(0,a.kt)("p",null,"It emerges that there is a way to do this though; you just need to give the compiler a clue. You need to include a type assertion of ",(0,a.kt)("inlineCode",{parentName:"p"}," as [string, string]")," which tells the compiler that what you've just declared is a ",(0,a.kt)("inlineCode",{parentName:"p"},"Tuple")," of ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"string"),". (Please note that ",(0,a.kt)("inlineCode",{parentName:"p"},"[string, string]")," corresponds to the types of the ",(0,a.kt)("inlineCode",{parentName:"p"},"Key")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"Value")," of your ",(0,a.kt)("inlineCode",{parentName:"p"},"Map")," and should be set accordingly.)"),(0,a.kt)("p",null,"So a working version of the code looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),'const iAmAnArray [\n  { value: "value1", text: "hello" }\n  { value: "value2", text: "map" }\n];\n\nconst iAmAMap = new Map<string, string>(\n  iAmAnArray.map(x => [x.value, x.text] as [string, string])\n);\n')),(0,a.kt)("p",null,"Or, to be terser, this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),'const iAmAnArray [\n  { value: "value1", text: "hello" }\n  { value: "value2", text: "map" }\n];\n\nconst iAmAMap = new Map( // Look Ma!  No type annotations\n  iAmAnArray.map(x => [x.value, x.text] as [string, string])\n);\n')),(0,a.kt)("p",null,"I've raised this as an issue with the TypeScript team; you can find details ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/issues/8936"}),"here"),"."))}d.isMDXComponent=!0},82058:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"using-webpacks-defineplugin-with-typescript",title:"Understanding webpack's DefinePlugin (and using with TypeScript)",description:"webpack's DefinePlugin allows you to create global constants which can be configured at compile time; here's how to use it with TypeScript",authors:"johnnyreilly",tags:["typescript","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/using-webpacks-defineplugin-with-typescript",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-07-23-using-webpacks-defineplugin-with-typescript/index.md",source:"@site/blog/2016-07-23-using-webpacks-defineplugin-with-typescript/index.md",title:"Understanding webpack's DefinePlugin (and using with TypeScript)",description:"webpack's DefinePlugin allows you to create global constants which can be configured at compile time; here's how to use it with TypeScript",date:"2016-07-23T00:00:00.000Z",formattedDate:"July 23, 2016",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:2.6,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"using-webpacks-defineplugin-with-typescript",title:"Understanding webpack's DefinePlugin (and using with TypeScript)",description:"webpack's DefinePlugin allows you to create global constants which can be configured at compile time; here's how to use it with TypeScript",authors:"johnnyreilly",tags:["typescript","webpack"],hide_table_of_contents:!1},prevItem:{title:"The Ternary Operator <3 Destructuring",permalink:"/the-ternary-operator-meets-destructuring"},nextItem:{title:"Creating an ES2015 Map from an Array in TypeScript",permalink:"/create-es2015-map-from-array-in-typescript"}},p={authorsImageUrls:[void 0]},u=[{value:"What Globals?",id:"what-globals",level:2},{value:"Configuring our Globals",id:"configuring-our-globals",level:2},{value:"TypeScript and Define",id:"typescript-and-define",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I've been searching for a way to describe what the DefinePlugin actually does. The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/docs/wiki/list-of-plugins#defineplugin"}),"docs")," say:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Define free variables. Useful for having development builds with debug logging or adding global constants.")),(0,a.kt)("p",null,"I think I would describe it thusly: the DefinePlugin allows you to create global constants which can be ",(0,a.kt)("em",{parentName:"p"},"configured at compile time"),". I find this very useful for allowing different behaviour between development builds and release builds. This post will demonstrate usage of this approach, talk about what's actually happening and how to get this working nicely with TypeScript."),(0,a.kt)("p",null,"If you just want to see this in action then take a look at this ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/poorclaresarundel/"}),"repo")," and keep your eyes open for usage of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/poorclaresarundel/search?utf8=%E2%9C%93&q=__VERSION__"}),(0,a.kt)("inlineCode",{parentName:"a"},"__VERSION__"))," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/poorclaresarundel/search?utf8=%E2%9C%93&q=__IN_DEBUG__"}),(0,a.kt)("inlineCode",{parentName:"a"},"__IN_DEBUG__")),"."),(0,a.kt)("h2",o({},{id:"what-globals"}),"What Globals?"),(0,a.kt)("p",null,"For our example we want to define 2 global constants; a string called ",(0,a.kt)("inlineCode",{parentName:"p"},"__VERSION__")," and a boolean called ",(0,a.kt)("inlineCode",{parentName:"p"},"__IN_DEBUG__"),'. The names are deliberately wacky to draw attention to the fact that these are not your everyday, common-or-garden variables. Them\'s "special". These constants will be initialised with different values depending on whether we are in a debug build or a production build. Usage of these constants in our code might look like this:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"if (__IN_DEBUG__) {\n  console.log(`This app is version ${__VERSION__}`);\n}\n")),(0,a.kt)("p",null,"So, if ",(0,a.kt)("inlineCode",{parentName:"p"},"__IN_DEBUG__")," is set to ",(0,a.kt)("inlineCode",{parentName:"p"},"true")," this code would log out to the console the version of the app."),(0,a.kt)("h2",o({},{id:"configuring-our-globals"}),"Configuring our Globals"),(0,a.kt)("p",null,"To introduce these constants to webpack we're going to add this to our webpack configuration:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"var webpack = require('webpack');\n\n// ...\n\nplugins: [\n  new webpack.DefinePlugin({\n    __IN_DEBUG__: JSON.stringify(false),\n    __VERSION__: JSON.stringify('1.0.0.' + Date.now()),\n  }),\n  // ...\n];\n// ...\n")),(0,a.kt)("p",null,"What's going on here? Well, each key of the object literal above represents one of our global constants. When you look at the value, just imagine each outer ",(0,a.kt)("inlineCode",{parentName:"p"},"JSON.stringify( ... )")," is not there. It's just noise. Imagine instead that you're seeing this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"__IN_DEBUG__: false,\n          __VERSION__: '1.0.0.' + Date.now()\n")),(0,a.kt)("p",null,"A little clearer, right? ",(0,a.kt)("inlineCode",{parentName:"p"},"__IN_DEBUG__")," is given the boolean value ",(0,a.kt)("inlineCode",{parentName:"p"},"false")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"__VERSION__")," is given the string value of ",(0,a.kt)("inlineCode",{parentName:"p"},"1.0.0.")," plus the ticks off of ",(0,a.kt)("inlineCode",{parentName:"p"},"Date.now()"),". What's happening here is well explained in Pete Hunt's excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/petehunt/webpack-howto#6-feature-flags"}),"webpack howto"),': "definePlugin takes raw strings and inserts them". ',(0,a.kt)("inlineCode",{parentName:"p"},"JSON.stringify")," facilitates this; it produces a string representation of a value that can be inlined into code. When the inlining takes place the actual output would be something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"if (false) {\n  // Because at compile time, __IN_DEBUG__ === false\n  console.log(`This app is version ${'1.0.0.1469268116580'}`); // And __VERSION__ === \"1.0.0.1469268116580\"\n}\n")),(0,a.kt)("p",null,"And if you've got some ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/mishoo/UglifyJS"}),"UglifyJS")," or similar in the mix then, in the example above, this would actually strip out the statement above entirely since it's clearly a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/NOP"}),"NOOP"),". Yay the dead code removal! If ",(0,a.kt)("inlineCode",{parentName:"p"},"__IN_DEBUG__")," was ",(0,a.kt)("inlineCode",{parentName:"p"},"false")," then (perhaps obviously) this statement would be left in place as it wouldn't be dead code."),(0,a.kt)("h2",o({},{id:"typescript-and-define"}),"TypeScript and Define"),(0,a.kt)("p",null,"The final piece of the puzzle is making TypeScript happy. It doesn't know anything about our global constants. So we need to tell it:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"declare var __IN_DEBUG__: boolean;\ndeclare var __VERSION__: string;\n")),(0,a.kt)("p",null,"And that's it. Compile time constants are a go!"))}d.isMDXComponent=!0},16313:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"the-ternary-operator-meets-destructuring",title:"The Ternary Operator <3 Destructuring",authors:"johnnyreilly",tags:["typescript","ES2015"],hide_table_of_contents:!1},s=void 0,l={permalink:"/the-ternary-operator-meets-destructuring",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-08-19-the-ternary-operator-meets-destructuring/index.md",source:"@site/blog/2016-08-19-the-ternary-operator-meets-destructuring/index.md",title:"The Ternary Operator <3 Destructuring",description:"I'm addicted to the ternary operator. For reasons I can't explain, I cannot get enough of:",date:"2016-08-19T00:00:00.000Z",formattedDate:"August 19, 2016",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"ES2015",permalink:"/tags/es-2015"}],readingTime:2.21,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"the-ternary-operator-meets-destructuring",title:"The Ternary Operator <3 Destructuring",authors:"johnnyreilly",tags:["typescript","ES2015"],hide_table_of_contents:!1},prevItem:{title:"Integration Tests with SQL Server Database Snapshots",permalink:"/integration-tests-with-sql-server"},nextItem:{title:"Understanding webpack's DefinePlugin (and using with TypeScript)",permalink:"/using-webpacks-defineplugin-with-typescript"}},p={authorsImageUrls:[void 0]},u=[{value:"Crowdfund You A Tuple",id:"crowdfund-you-a-tuple",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I'm addicted to the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Conditional_Operator"}),"ternary operator"),". For reasons I can't explain, I cannot get enough of:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const thisOrThat = someCondition ? 'this' : 'or that';\n")),(0,a.kt)("p",null,"The occasion regularly arises where I need to turn my lovely terse code into an if statement in order to set 2 variables instead of 1. I've been heartbroken; I hate doing:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"let legWear: string, coat: boolean;\nif (weather === 'good') {\n  legWear = 'shorts';\n  coat = false;\n} else {\n  legWear = 'jeans';\n  coat = true;\n}\n")),(0,a.kt)("p",null,"Just going from setting one variable to setting two has been really traumatic:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"I've had do stop using ",(0,a.kt)("inlineCode",{parentName:"li"},"const")," and moved to ",(0,a.kt)("inlineCode",{parentName:"li"},"let"),'. This has made my code less "truthful" in the sense that I never intend to reassign these variables again; they are intended to be immutable.'),(0,a.kt)("li",{parentName:"ul"},"I've gone from 1 line of code to ",(0,a.kt)("em",{parentName:"li"},"9 lines of code"),". That's 9x the code for increasing the number of variables in play by 1. That's... heavy."),(0,a.kt)("li",{parentName:"ul"},"This third point only applies if you're using TypeScript (and I am): I have to specify the types of my variables up front if I want type safety.")),(0,a.kt)("p",null,"ES2015 gives us another option. We can move back to the ternary operator if we change the return type of each branch to be an object sharing the same signature. Then, using destructuring, we can pull out those object properties into ",(0,a.kt)("inlineCode",{parentName:"p"},"const"),"s:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const { legWear, coat } =\n  weather === 'good'\n    ? { legWear: 'shorts', coat: false }\n    : { legWear: 'jeans', coat: true };\n")),(0,a.kt)("p",null,"With this approach we're keeping usage of ",(0,a.kt)("inlineCode",{parentName:"p"},"const")," instead of ",(0,a.kt)("inlineCode",{parentName:"p"},"let")," and we're only marginally increasing the amount of code we're writing. If you're using TypeScript you're back to being able to rely on the compiler correctly inferring your types; you don't need to specify. Awesome."),(0,a.kt)("h2",o({},{id:"crowdfund-you-a-tuple"}),"Crowdfund You A Tuple"),(0,a.kt)("p",null,"I thought I was done and then I saw this:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/johnny_reilly"}),"@johnny_reilly")," even neater with tuples: const ","[str, num]"," = test ? ",'["yes", 100]'," : ",'["no", 50]',";"),(0,a.kt)("p",{parentName:"blockquote"},"\u2014 Illustrated Pamphlet (@Rickenhacker) ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/Rickenhacker/status/766913766323781632"}),"August 20, 2016"))),(0,a.kt)("script",{async:"",src:"//platform.twitter.com/widgets.js",charSet:"utf-8"}),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/Rickenhacker"}),"Daniel")," helpfully points out that there's an even terser syntax available to us:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const [legWear, coat] =\n  weather === 'good' ? ['shorts', false] : ['jeans', true];\n")),(0,a.kt)("p",null,"The above is ES2015 array destructuring. We get exactly the same effect but it's a little terser as we don't have to repeat the prop names as we do when using object destructuring. From a TypeScript perspective the assignment side of the above is a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/pull/428"}),"Tuple")," which allows our type inference to flow through in the manner we'd hope."),(0,a.kt)("p",null,"Lovely. Thanks!"))}d.isMDXComponent=!0},6454:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"integration-tests-with-sql-server",title:"Integration Tests with SQL Server Database Snapshots",authors:"johnnyreilly",tags:["Database Snapshots","Integration Testing","SQL Server"],hide_table_of_contents:!1},s=void 0,l={permalink:"/integration-tests-with-sql-server",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-09-12-integration-tests-with-sql-server/index.md",source:"@site/blog/2016-09-12-integration-tests-with-sql-server/index.md",title:"Integration Tests with SQL Server Database Snapshots",description:"Once More With Feeling",date:"2016-09-12T00:00:00.000Z",formattedDate:"September 12, 2016",tags:[{label:"Database Snapshots",permalink:"/tags/database-snapshots"},{label:"Integration Testing",permalink:"/tags/integration-testing"},{label:"SQL Server",permalink:"/tags/sql-server"}],readingTime:5.14,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"integration-tests-with-sql-server",title:"Integration Tests with SQL Server Database Snapshots",authors:"johnnyreilly",tags:["Database Snapshots","Integration Testing","SQL Server"],hide_table_of_contents:!1},prevItem:{title:"TypeScript 2.0, ES2016 and Babel",permalink:"/typescript-20-es2016-and-babel"},nextItem:{title:"The Ternary Operator <3 Destructuring",permalink:"/the-ternary-operator-meets-destructuring"}},p={authorsImageUrls:[void 0]},u=[{value:"Once More With Feeling",id:"once-more-with-feeling",level:2},{value:"What&#39;s the Scenario?",id:"whats-the-scenario",level:2},{value:"Talk is cheap, show me the code",id:"talk-is-cheap-show-me-the-code",level:2},{value:"DatabaseSnapshot.cs",id:"databasesnapshotcs",level:3},{value:"SetupAndTeardown.cs",id:"setupandteardowncs",level:3},{value:"TestBase.cs",id:"testbasecs",level:3}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"once-more-with-feeling"}),"Once More With Feeling"),(0,a.kt)("p",null,"This is a topic that I have written about ",(0,a.kt)("a",o({parentName:"p"},{href:"/integration-testing-with-entity"}),"before"),".... But not well. I recently had cause to dust down my notes on how to use snapshotting in your integration tests. To my dismay, referring back to my original blog post was less helpful than I'd hoped. Now I've cracked the enigma code that my original scribings turned out to be, it's time to turn my relearnings back into something genuinely useful."),(0,a.kt)("h2",o({},{id:"whats-the-scenario"}),"What's the Scenario?"),(0,a.kt)("p",null,"You have a test database. You want to write integration tests. So what's the problem? Well, these tests will add records, delete records, update records within the tables of the database. They will mutate the data. And that's exactly what they ought to do; they're testing that our code uses the database in the way we would hope and expect."),(0,a.kt)("p",null,"So how do we handle this? Well, we could handle this by writing code at the end of each test that is responsible for reverting the database back to the state that it was in at the start of the test. So if we had a test that added a record and tested it, we'd need the test to be responsible for removing that record before any subsequent tests run. Now that's a totally legitimate approach but it adds tax. Each test becomes more complicated and requires more code."),(0,a.kt)("p",null,"So what's another approach? Perhaps we could take a backup of our database before our first test runs. Then, at the end of each test, we could restore our backup to roll the database back to its initial state. Perfect, right? Less code to write, less scope for errors. So what's the downside? Backups are slowwwww. Restores likewise. We could be waiting minutes between each test that runs. That's not acceptable."),(0,a.kt)("p",null,"There is another way though: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://msdn.microsoft.com/en-us/library/ms175158.aspx"}),"database snapshots")," ","-"," a feature that's been nestling inside SQL Server for a goodly number of years. For our use case, to all intents and purposes, database snapshots offers the same functionality as backups and restores. You can backup a database (take a snapshot of a database at a point in time), you can restore a database (roll back the database to the point of the snapshot). More importantly, you can do either operation in ","*",(0,a.kt)("em",{parentName:"p"},"under a second"),"*",". As it happens, Microsoft advocate using this approach themselves:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"In a testing environment, it can be useful when repeatedly running a test protocol for the database to contain identical data at the start of each round of testing. Before running the first round, an application developer or tester can create a database snapshot on the test database. After each test run, the database can be quickly returned to its prior state by reverting the database snapshot.")),(0,a.kt)("p",null,"Sold!"),(0,a.kt)("h2",o({},{id:"talk-is-cheap-show-me-the-code"}),"Talk is cheap, show me the code"),(0,a.kt)("p",null,"In the end it comes down to 3 classes; ",(0,a.kt)("inlineCode",{parentName:"p"},"DatabaseSnapshot.cs")," which does the actual snapshotting work and 2 classes that make use of it."),(0,a.kt)("h3",o({},{id:"databasesnapshotcs"}),"DatabaseSnapshot.cs"),(0,a.kt)("p",null,"This is our ",(0,a.kt)("inlineCode",{parentName:"p"},"DatabaseSnapshot")," class. Isn't it pretty?"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System.Data;\nusing System.Data.SqlClient;\n\nnamespace Testing.Shared\n{\n    public class DatabaseSnapshot\n    {\n        private readonly string _dbName;\n        private readonly string _dbSnapShotPath;\n        private readonly string _dbSnapShotName;\n        private readonly string _dbConnectionString;\n\n        public DatabaseSnapshot(string dbName, string dbSnapshotPath, string dbSnapshotName, string dbConnectionString)\n        {\n            _dbName = dbName;\n            _dbSnapshotPath = dbSnapshotPath;\n            _dbSnapshotName = dbSnapshotName;\n            _dbConnectionString = dbConnectionString;\n        }\n\n        public void CreateSnapshot()\n        {\n            if (!System.IO.Directory.Exists(_dbSnapshotPath))\n                System.IO.Directory.CreateDirectory(_dbSnapshotPath);\n\n            var sql = $"CREATE DATABASE { _dbSnapshotName } ON (NAME=[{ _dbName }], FILENAME=\'{ _dbSnapshotPath }{ _dbSnapshotName }\') AS SNAPSHOT OF [{_dbName }]";\n\n            ExecuteSqlAgainstMaster(sql);\n        }\n\n        public void DeleteSnapshot()\n        {\n            var sql = $"DROP DATABASE { _dbSnapshotName }";\n\n            ExecuteSqlAgainstMaster(sql);\n        }\n\n        public void RestoreSnapshot()\n        {\n            var sql = "USE master;\\r\\n" +\n\n                $"ALTER DATABASE {_dbName} SET SINGLE_USER WITH ROLLBACK IMMEDIATE;\\r\\n" +\n\n                $"RESTORE DATABASE {_dbName}\\r\\n" +\n                $"FROM DATABASE_SNAPSHOT = \'{ _dbSnapshotName }\';\\r\\n" +\n\n                $"ALTER DATABASE {_dbName} SET MULTI_USER;\\r\\n";\n\n            ExecuteSqlAgainstMaster(sql);\n        }\n\n        private void ExecuteSqlAgainstMaster(string sql, params SqlParameter[] parameters)\n        {\n            using (var conn = new SqlConnection(_dbConnectionString))\n            {\n                conn.Open();\n                var cmd = new SqlCommand(sql, conn) { CommandType = CommandType.Text };\n                cmd.Parameters.AddRange(parameters);\n                cmd.ExecuteNonQuery();\n                conn.Close();\n            }\n        }\n    }\n}\n')),(0,a.kt)("p",null,"It exposes 3 methods:"),(0,a.kt)("dl",null,(0,a.kt)("dt",null,"CreateSnapshot"),(0,a.kt)("dd",null,"This method creates the snapshot of the database. We will run this right at the start, before any of our tests run."),(0,a.kt)("dt",null,"DeleteSnapshot"),(0,a.kt)("dd",null,"Deletes the snapshot we created. We will run this at the end, after all our tests have finished running."),(0,a.kt)("dt",null,"RestoreSnapshot"),(0,a.kt)("dd",null,"Restores the database back to the snapshot we took earlier. We run this after each test has completed. This method relies on a connection to the database (perhaps unsurprisingly). It switches the database in use away from the database that is being restored prior to actually running the restore. It happens to shift to the master database (I believe that's entirely incidental; although I haven't tested).")),(0,a.kt)("h3",o({},{id:"setupandteardowncs"}),"SetupAndTeardown.cs"),(0,a.kt)("p",null,"This class is responsible for setting up the snapshot we're going to use in our tests right before any of the tests have run (in the ",(0,a.kt)("inlineCode",{parentName:"p"},"FixtureSetup")," method). It's also responsible for deleting the snapshot once all the tests have finished running (in the ",(0,a.kt)("inlineCode",{parentName:"p"},"FixtureTearDown")," method). It should be noted that in this example I'm using NUnit and this class is written to depend on the hooks NUnit exposes for running code at the very beginning and end of the test cycle. All test frameworks have these hooks; if you're using something other than NUnit then it's just a case of swapping in the relevant attribute (everything tends to attribute driven in the test framework world)."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using NUnit.Framework;\n\nnamespace Testing.Shared\n{\n   [SetUpFixture]\n   public class SetupAndTeardown\n   {\n      public static DatabaseSnapshot DatabaseSnapshot;\n\n      [SetUp]\n      public void FixtureSetup()\n      {\n         DatabaseSnapshot = new DatabaseSnapshot("MyDbName", "C:\\\\", "MySnapshot", "Data Source=.;initial catalog=MyDbName;integrated security=True;");\n\n         try\n         {\n            // Try to delete the snapshot in case it was left over from aborted test runs\n            DatabaseSnapshot.DeleteSnapShot();\n         }\n         catch { /* this should fail with snapshot does not exist */ }\n\n         DatabaseSnapshot.CreateSnapShot();\n      }\n\n      [TearDown]\n      public void FixtureTearDown()\n      {\n         DatabaseSnapshot.DeleteSnapShot();\n      }\n   }\n}\n')),(0,a.kt)("h3",o({},{id:"testbasecs"}),"TestBase.cs"),(0,a.kt)("p",null,"All of our test classes are made to inherit from this class:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using NUnit.Framework;\n\nnamespace Testing.Shared\n{\n   public class TestBase\n   {\n      [TearDown]\n      public void TearDown()\n      {\n         SetupAndTeardown.DatabaseSnapshot.RestoreSnapShot();\n      }\n   }\n}\n")),(0,a.kt)("p",null,"Which restores the database back to the snapshot position at the end of each test. And that... Is that!"))}d.isMDXComponent=!0},11387:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-20-es2016-and-babel",title:"TypeScript 2.0, ES2016 and Babel",authors:"johnnyreilly",tags:["typescript","Babel","ES2016"],hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-20-es2016-and-babel",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-09-22-typescript-20-es2016-and-babel/index.md",source:"@site/blog/2016-09-22-typescript-20-es2016-and-babel/index.md",title:"TypeScript 2.0, ES2016 and Babel",description:"TypeScript 2.0 has shipped! Naturally I'm excited. For some time I've been using TypeScript to emit ES2015 code which I pass onto Babel to transpile to ES \"old school\". You can see how here.",date:"2016-09-22T00:00:00.000Z",formattedDate:"September 22, 2016",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"Babel",permalink:"/tags/babel"},{label:"ES2016",permalink:"/tags/es-2016"}],readingTime:2.32,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-20-es2016-and-babel",title:"TypeScript 2.0, ES2016 and Babel",authors:"johnnyreilly",tags:["typescript","Babel","ES2016"],hide_table_of_contents:!1},prevItem:{title:"React Component Curry",permalink:"/react-component-curry"},nextItem:{title:"Integration Tests with SQL Server Database Snapshots",permalink:"/integration-tests-with-sql-server"}},p={authorsImageUrls:[void 0]},u=[{value:"<code>tsconfig.json</code> changes",id:"tsconfigjson-changes",level:2},{value:"Babel changes",id:"babel-changes",level:2},{value:"Webpack changes",id:"webpack-changes",level:2},{value:"Wake Up and Smell the Jasmine",id:"wake-up-and-smell-the-jasmine",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.microsoft.com/typescript/2016/09/22/announcing-typescript-2-0/"}),"TypeScript 2.0 has shipped!")," Naturally I'm excited. For some time I've been using TypeScript to emit ES2015 code which I pass onto Babel to transpile to ES \"old school\". You can see how ",(0,a.kt)("a",o({parentName:"p"},{href:"/es6-typescript-babel-react-flux-karma"}),"here"),"."),(0,a.kt)("p",null,"Merely upgrading my ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," to use ",(0,a.kt)("inlineCode",{parentName:"p"},'"typescript": "^2.0.3"')," from ",(0,a.kt)("inlineCode",{parentName:"p"},'"typescript": "^1.8.10"')," was painless. TypeScript now supports ES2016 (the previous major release 1.8 supported ES2015). I wanted to move on from writing ES2015 to writing ES2016 using my chosen build process. Fortunately, it's supported. Phew. However, due to some advances in ecmascript feature modularisation within the TypeScript compiler the upgrade path is slightly different. I figured that I'd just be able to update the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/docs/handbook/compiler-options.html"}),(0,a.kt)("inlineCode",{parentName:"a"},"target"))," in my ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," to ",(0,a.kt)("inlineCode",{parentName:"p"},'"es2016"')," from ",(0,a.kt)("inlineCode",{parentName:"p"},'"es2015"'),", add in the ES2016 preset for Babel and jobs a good 'un. Not so. There were a few more steps to follow. Here's the recipe:"),(0,a.kt)("h2",o({},{id:"tsconfigjson-changes"}),(0,a.kt)("inlineCode",{parentName:"h2"},"tsconfig.json")," changes"),(0,a.kt)("p",null,"Well, there's no ",(0,a.kt)("inlineCode",{parentName:"p"},'"es2016"')," target for TypeScript. You carry on with a target of ",(0,a.kt)("inlineCode",{parentName:"p"},'"es2015"'),". What I need is a new entry: ",(0,a.kt)("inlineCode",{parentName:"p"},'"lib": ["dom", "es2015", "es2016"]'),". This tells the compiler that we're expecting to be emitting to an environment which supports a browser (",(0,a.kt)("inlineCode",{parentName:"p"},'"dom"'),'), and both ES2016 and ES2015. Our "environment" is Babel and it\'s going to pick up the baton from this point. My complete ',(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "compileOnSave": false,\n  "compilerOptions": {\n    "allowSyntheticDefaultImports": true,\n    "lib": ["dom", "es2015", "es2016"],\n    "jsx": "preserve",\n    "module": "es2015",\n    "moduleResolution": "node",\n    "noEmitOnError": false,\n    "noImplicitAny": true,\n    "preserveConstEnums": true,\n    "removeComments": false,\n    "suppressImplicitAnyIndexErrors": true,\n    "target": "es2015"\n  }\n}\n')),(0,a.kt)("h2",o({},{id:"babel-changes"}),"Babel changes"),(0,a.kt)("p",null,"I needed the Babel preset for ES2016; with a quick ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/babel-preset-es2016"}),(0,a.kt)("inlineCode",{parentName:"a"},"npm install --save-dev babel-preset-es2016"))," that was sorted. Now just to kick Webpack into gear..."),(0,a.kt)("h2",o({},{id:"webpack-changes"}),"Webpack changes"),(0,a.kt)("p",null,"My webpack config plugs together TypeScript and Babel with the help of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/ts-loader"}),"ts-loader")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/babel-loader"}),"babel-loader"),". It allows the transpilation of my (few) JavaScript files so I can write ES2015. However, mainly it allows the transpilation of my (many) TypeScript files so I can write ES2015-flavoured TypeScript. I'll now tweak the ",(0,a.kt)("inlineCode",{parentName:"p"},"loaders")," so they cater for ES2016 as well."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var webpack = require('webpack');\n\nmodule.exports = {\n  // ....\n\n  module: {\n    loaders: [\n      {\n        // Now transpiling ES2016 TS\n        test: /\\.ts(x?)$/,\n        exclude: /node_modules/,\n        loader:\n          'babel-loader?presets[]=es2016&presets[]=es2015&presets[]=react!ts-loader',\n      },\n      {\n        // Now transpiling ES2016 JS\n        test: /\\.js$/,\n        exclude: /node_modules/,\n        loader: 'babel',\n        query: {\n          presets: ['es2016', 'es2015', 'react'],\n        },\n      },\n    ],\n  },\n\n  // ....\n};\n")),(0,a.kt)("h2",o({},{id:"wake-up-and-smell-the-jasmine"}),"Wake Up and Smell the Jasmine"),(0,a.kt)("p",null,"And we're there; it works. How do I know? Well; here's the proof:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"it('Array.prototype.includes works', () => {\n  const result = [1, 2, 3].includes(2);\n  expect(result).toBe(true);\n});\n\nit('Exponentiation operator works', () => {\n  expect(1 ** 2 === Math.pow(1, 2)).toBe(true);\n});\n")),(0,a.kt)("p",null,"Much love to the TypeScript team for an awesome job; I can't wait to get stuck into some of the exciting new features of TypeScript 2.0. ",(0,a.kt)("inlineCode",{parentName:"p"},"strictNullChecks")," FTW!"))}d.isMDXComponent=!0},69958:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"react-component-curry",title:"React Component Curry",authors:"johnnyreilly",tags:["jsx","React","stateless functional components"],hide_table_of_contents:!1},s=void 0,l={permalink:"/react-component-curry",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-10-05-react-component-curry/index.md",source:"@site/blog/2016-10-05-react-component-curry/index.md",title:"React Component Curry",description:"Everyone loves curry don't they? I don't know about you but I'm going for one on Friday.",date:"2016-10-05T00:00:00.000Z",formattedDate:"October 5, 2016",tags:[{label:"jsx",permalink:"/tags/jsx"},{label:"React",permalink:"/tags/react"},{label:"stateless functional components",permalink:"/tags/stateless-functional-components"}],readingTime:1.395,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"react-component-curry",title:"React Component Curry",authors:"johnnyreilly",tags:["jsx","React","stateless functional components"],hide_table_of_contents:!1},prevItem:{title:"But you can't die... I love you!",permalink:"/but-you-cant-die-i-love-you-ts-loader"},nextItem:{title:"TypeScript 2.0, ES2016 and Babel",permalink:"/typescript-20-es2016-and-babel"}},p={authorsImageUrls:[void 0]},u=[{value:"Mine&#39;s a Balti",id:"mines-a-balti",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Everyone loves curry don't they? I don't know about you but I'm going for one on Friday."),(0,a.kt)("p",null,"When React 0.14 shipped, it came with a new way to write React components. Rather than as an ES2015 class or using ",(0,a.kt)("inlineCode",{parentName:"p"},"React.createClass")," there was now another way: stateless functional components."),(0,a.kt)("p",null,"These are components which have no state (the name gives it away) and a simple syntax; they are a function which takes your component props as a single parameter and they return JSX. Think of them as the render method of a standard component just with props as a parameter."),(0,a.kt)("p",null,"The advantage of these components is that they can reduce the amount of code you have to write for a component which requires no state. This is even more true if you're using ES2015 syntax as you have arrow functions and destructuring to help.Embrace the terseness!"),(0,a.kt)("h2",o({},{id:"mines-a-balti"}),"Mine's a Balti"),(0,a.kt)("p",null,"There is another advantage of this syntax. If you have a number of components which share similar implementation you can easily make component factories by currying:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-jsx"}),"function iconMaker(fontAwesomeClassName: string) {\n  return (props) => <i className={`fa ${fontAwesomeClassName}`} />;\n}\n\nconst ThumbsUpIcon = iconMaker('fa-thumbs-up');\nconst TrophyIcon = iconMaker('fa-trophy');\n\n// Somewhere in else inside a render function:\n\n<p>\n  This is totally <ThumbsUpIcon />\n  .... You should win a <TrophyIcon />\n</p>;\n")),(0,a.kt)("p",null,"So our ",(0,a.kt)("inlineCode",{parentName:"p"},"iconMaker")," is a function which, when called with a ",(0,a.kt)("a",o({parentName:"p"},{href:"http://fontawesome.io/"}),"Font Awesome")," class name produces a function which, when invoked, will return a the HTML required to render that icon. This is a super simple example, a bhaji if you will, but you can imagine how useful this technique can be when you've more of a banquet in mind."))}d.isMDXComponent=!0},84855:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"but-you-cant-die-i-love-you-ts-loader",title:"But you can't die... I love you!",authors:"johnnyreilly",tags:["open source","typescript","ts-loader"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/but-you-cant-die-i-love-you-ts-loader",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-11-01-but-you-cant-die-i-love-you-ts-loader/index.md",source:"@site/blog/2016-11-01-but-you-cant-die-i-love-you-ts-loader/index.md",title:"But you can't die... I love you!",description:"That's how I was feeling on the morning of October 6th 2016. I'd been feeling that way for some time. The target of my concern? ts-loader. ts-loader is a loader for webpack; the module bundler. ts-loader allows you use TypeScript with webpack. I'd been a merry user of it for at least a year or so. But, at that point, all was not well in the land of ts-loader. Come with me and I'll tell you a story...",date:"2016-11-01T00:00:00.000Z",formattedDate:"November 1, 2016",tags:[{label:"open source",permalink:"/tags/open-source"},{label:"typescript",permalink:"/tags/typescript"},{label:"ts-loader",permalink:"/tags/ts-loader"}],readingTime:4.86,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"but-you-cant-die-i-love-you-ts-loader",title:"But you can't die... I love you!",authors:"johnnyreilly",tags:["open source","typescript","ts-loader"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"My Subconscious is a Better Developer Than I Am",permalink:"/my-subconscious-is-better-developer"},nextItem:{title:"React Component Curry",permalink:"/react-component-curry"}},p={image:n(13106).Z,authorsImageUrls:[void 0]},u=[{value:"Going Red",id:"going-red",level:2},{value:"The Statement of Intent",id:"the-statement-of-intent",level:2},{value:"Caretaker, not BDFL",id:"caretaker-not-bdfl",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"That's how I was feeling on the morning of October 6th 2016. I'd been feeling that way for some time. The target of my concern? ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader"}),"ts-loader"),". ts-loader is a loader for ",(0,a.kt)("a",o({parentName:"p"},{href:"https://webpack.github.io/"}),"webpack; the module bundler"),". ts-loader allows you use TypeScript with webpack. I'd been a merry user of it for at least a year or so. But, at that point, all was not well in the land of ts-loader. Come with me and I'll tell you a story..."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"a poster that reads: &quot;But you can&#39;t die... I love you!&quot;",src:n(13106).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"going-red"}),"Going Red"),(0,a.kt)("p",null,"At some point, I became a member of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong"}),"TypeStrong")," organisation on GitHub. I'm honestly not entirely sure how. I think it may have been down to the very excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"https://youtube.com/basaratali"}),"Basarat")," (he of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://alm.tools/"}),"ALM")," / ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/atom-typescript"}),"atom-typescript")," / the list goes on fame) but I couldn't clearly say."),(0,a.kt)("p",null,"Either way, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jbrantly"}),"James Brantly"),"'s ts-loader was also one of TypeStrong's projects. Since I used it, I occasionally contributed. Not much to be honest; mostly it was documentation tweaks. I mean I never really looked at the main code at all. It worked (thanks to other people). I just plugged it into my projects and ploughed on my merry way. I liked it. It was well established; with friendly maintainers. It had a continuous integration test pack that ran against multiple versions of TypeScript on both Windows and Linux. I trusted it. Then one day the continuous integration tests went red. And stayed red."),(0,a.kt)("p",null,"This is where we came in. On the morning of October 6th I was mulling what to do about this. I knew there was another alternative out there (awesome-typescript-loader) but I was a little wary of it. My understanding of ATL was that it targeted webpack 2.0 which has long been in beta. Where I ply my trade (mostly developing software for the financial sector in the City of London) beta is not a word that people trust. They don't do beta. What's more I was quite happy with ts-loader; I didn't want to switch if I didn't have to. I also rather suspected (rightly) that there wasn't much wrong; ts-loader just needed a little bit of love. So I thought: I bet I can help here."),(0,a.kt)("h2",o({},{id:"the-statement-of-intent"}),"The Statement of Intent"),(0,a.kt)("p",null,"So that evening I raised ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/issues/296"}),"an issue against ts-loader"),'. Not a "sort it out chap" issue. No. That wouldn\'t be terribly helpful. I raised a "here\'s how I can help" issue. I present an abridged version below:'),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Okay here's the deal; I've been using ts-loader for a long time but my contributions up until now have mostly been documentation. Fixing of tests etc. As the commit history shows this is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jbrantly"}),"@jbrantly"),"'s baby and kudos to him."),(0,a.kt)("p",{parentName:"blockquote"},"He's not been able to contribute much of late and since he's the main person who's worked on ts-loader not much has happened for a while; the code is a bit stale. As I'm a member of TypeStrong I'm going to have a go at improving the state of the project. I'm going to do this as carefully as I can. This issue is intended as a meta issue to make it visible what I'm plannning to do / doing."),(0,a.kt)("p",{parentName:"blockquote"},"My immediate goal is to get a newer version of ts-loader built and shipped. Essentially all the bug fixes / tweaks since the last release should ship."),(0,a.kt)("p",{parentName:"blockquote"},"..."),(0,a.kt)("p",{parentName:"blockquote"},"I don't have npm publish rights for ts-loader. Fortunately both ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jbrantly"}),"@jbrantly")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/blakeembrey"}),"@blakeembrey")," do - and hopefully one of them will either be able to help out with a publish or let me have the requisite rights to do it."),(0,a.kt)("p",{parentName:"blockquote"},"I can't promise this is all going to work; I've got a limited amount of spare time I'm afraid. Whatever happens it's going to take me a little while. But I'm going to see where I can take this. Best foot forward! Please bear with me...")),(0,a.kt)("p",null,"I did wonder what would happen next. This happened next:"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/jbrantly/status/785931975064444928"}),(0,a.kt)("img",{loading:"lazy",alt:"tweet from James Brantly on October 11, 2016 that reads: &quot;My #opensourceguilt has been lifted thanks to @johnny_reilly stepping up to take over ts-loader. Thanks man!&quot;",src:n(64857).Z,width:"1199",height:"1183"}))),(0,a.kt)("h2",o({},{id:"caretaker-not-bdfl"}),"Caretaker, not ",(0,a.kt)("a",o({parentName:"h2"},{href:"https://en.wikipedia.org/wiki/Benevolent_dictator_for_life"}),"BDFL")),(0,a.kt)("p",null,"So that's how it came to pass that I became the present main caretaker of ts-loader. James very kindly gave me the rights to publish to npm and soon enough I did. I fixed up the existing integration test pack; made it less brittle. I wrote a new integration test pack (that performs a different sort of testing; execution rather than comparison). I merged pull requests, I closed issues. I introduced a regression (whoops!), a community member helped me fix it (thanks ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dopare"}),"Mike Mazmanyan"),"!). In the last month ts-loader has shipped 6 times."),(0,a.kt)("p",null,'The thing that matters most in the last paragraph are the phrases "I merged pull requests" and "a community member helped me fix it". I\'m wary of one man bands; you should be to. I want projects to be a thing communally built and maintained. If I go under a bus I want someone else to be able to carry on without me. So be part of this; I want you to help!'),(0,a.kt)("p",null,"I've got plans to do a lot more. I'm in the process of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/343"}),"refactoring ts-loader to make it more modular and hence easier for others to contribute"),". (Also it must be said, refactoring something is an excellent way to try and learn a codebase.) Version 1.0 of ts-loader should ship this week."),(0,a.kt)("p",null,"I'm working with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/HerringtonDarkholme"}),"Herrington Darkholme")," (awesome name BTW!) to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/issues/270"}),"add a hook-in point")," that will allow ts-loader to support ",(0,a.kt)("a",o({parentName:"p"},{href:"http://vuejs.org/"}),"vuejs"),". Stuff is happening and will continue to. But don't be shy; be part of this! ts-loader awaits your PRs and is happy to have as many caretakers as possible!"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"a poster that reads: &quot;keep calm, I&#39;m a caretaker&quot;",src:n(83440).Z,width:"400",height:"388"})))}d.isMDXComponent=!0},24107:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"my-subconscious-is-better-developer",title:"My Subconscious is a Better Developer Than I Am",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},s=void 0,l={permalink:"/my-subconscious-is-better-developer",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-11-12-my-subconscious-is-better-developer/index.md",source:"@site/blog/2016-11-12-my-subconscious-is-better-developer/index.md",title:"My Subconscious is a Better Developer Than I Am",description:"Occasionally I flatter myself that I'm alright at this development lark. Such egotistical talk is foolish. What makes me pause even more when I consider the proposition is this: my subconscious is a better developer than I am.",date:"2016-11-12T00:00:00.000Z",formattedDate:"November 12, 2016",tags:[],readingTime:1.84,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"my-subconscious-is-better-developer",title:"My Subconscious is a Better Developer Than I Am",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},prevItem:{title:"webpack: syncing the enhanced-resolve",permalink:"/webpack-syncing-enhanced-resolve"},nextItem:{title:"But you can't die... I love you!",permalink:"/but-you-cant-die-i-love-you-ts-loader"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Occasionally I flatter myself that I'm alright at this development lark. Such egotistical talk is foolish. What makes me pause even more when I consider the proposition is this: my subconscious is a better developer than I am."),(0,a.kt)("p",null,"What's this fellow talking about?"),(0,a.kt)("p",null,"There's two of me. Not identical twins; masquerading as a single man (spoiler: I am not a Christopher Nolan movie). No. There's me, the chap who's tapping away at his keyboard and solving a problem. And there's the other chap too."),(0,a.kt)("p",null,"I have days when I'm working away at something and I'll hit a brick wall. I produce solutions that work but are not elegant. I'm not proud of them. Or worse, I fail to come up with something that solves the problem I'm facing. So I go home. I see my family, I have some food, I do something else. I context switch. I go to sleep."),(0,a.kt)("p",null,"When I awake, sometimes (not always) I'll have waiting in my head a better solution. I can see the solution in my head. I can turn it over and compare it to what, if anything, I currently have and see the reasons the new approach is better. Great, right? Up to a point."),(0,a.kt)("p",null,"What concerns me is this: I didn't work this out from first principles. The idea arrived sight unseen in my head. It totally works but whose work actually is it? I feel like I'm taking credit for someone else's graft. This is probably why I'm so keen on the MIT License. Don't want to be caught out."),(0,a.kt)("p",null,"I think I'd like it better if I was a better developer than my subconscious. I'd come up with the gold and mock the half baked ideas he shows me in the morning. Alas it is not to be."),(0,a.kt)("p",null,"I draw some comfort from the knowledge that I'm not alone in my experience. I've chatted to other devs in the same boat. There's probably two of you as well. Amarite? There's probably three of Jon Skeet; each more brilliant than the last..."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"a poster from the film Being John Malkovich",src:n(15994).Z,width:"293",height:"320"})),(0,a.kt)("p",null,"PS I posted this to Hacker News and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://news.ycombinator.com/item?id=12942461"}),"the comments left by people are pretty fascinating"),"."))}d.isMDXComponent=!0},20284:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"webpack-syncing-enhanced-resolve",title:"webpack: syncing the enhanced-resolve",authors:"johnnyreilly",tags:["webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/webpack-syncing-enhanced-resolve",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-12-11-webpack-syncing-enhanced-resolve/index.md",source:"@site/blog/2016-12-11-webpack-syncing-enhanced-resolve/index.md",title:"webpack: syncing the enhanced-resolve",description:"Like Captain Ahab I resolve to sync the white whale that is webpack's enhanced-resolve... English you say? Let me start again:",date:"2016-12-11T00:00:00.000Z",formattedDate:"December 11, 2016",tags:[{label:"webpack",permalink:"/tags/webpack"}],readingTime:2.37,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"webpack-syncing-enhanced-resolve",title:"webpack: syncing the enhanced-resolve",authors:"johnnyreilly",tags:["webpack"],hide_table_of_contents:!1},prevItem:{title:"Using ts-loader with webpack 2",permalink:"/using-ts-loader-with-webpack-2"},nextItem:{title:"My Subconscious is a Better Developer Than I Am",permalink:"/my-subconscious-is-better-developer"}},p={authorsImageUrls:[void 0]},u=[{value:"Sync, for lack of a better word, is good",id:"sync-for-lack-of-a-better-word-is-good",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Like Captain Ahab I resolve to sync the white whale that is webpack's ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/enhanced-resolve"}),(0,a.kt)("inlineCode",{parentName:"a"},"enhanced-resolve")),"... English you say? Let me start again:"),(0,a.kt)("p",null,"So, you're working on a webpack loader. (In my case the typescript loader; ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader"}),(0,a.kt)("inlineCode",{parentName:"a"},"ts-loader")),") You have need of webpack's resolve capabilities. You dig around and you discover that that superpower is lodged in the very heart of the enhanced-resolve package. Fantastic. But wait, there's more: your needs are custom. You need a sync, not an async resolver. (Try saying that quickly.) You regard the description of ",(0,a.kt)("inlineCode",{parentName:"p"},"enhanced-resolve")," with some concern:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},'"Offers an async require.resolve function. It\'s highly configurable."')),(0,a.kt)("p",null,"Well that doesn't sound too promising. Let's have a look at the docs. Ah. Hmmm. You know how it goes with webpack. Why document anything clearly when people could just guess wildly until they near insanity and gibber? Right? It's well established that webpack's attitude to docs has been traditionally akin to Gordon Gecko's view on lunch."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(79080).Z,width:"584",height:"349"})),(0,a.kt)("p",null,"In all fairness, things are beginning to change on that front. In fact the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://webpack.js.org/"}),"new docs")," look very promising. But regrettably, the docs on the enhanced-resolve repo are old school. Which is to say: opaque. However, I'm here to tell you that if a sync resolver is your baby then, contrary to appearances, ",(0,a.kt)("inlineCode",{parentName:"p"},"enhanced-resolve")," has your back."),(0,a.kt)("h2",o({},{id:"sync-for-lack-of-a-better-word-is-good"}),"Sync, for lack of a better word, is good"),(0,a.kt)("p",null,"Nestled inside enhanced-resolve is the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/enhanced-resolve/blob/3f3f4cd1fcbafa1e98c3c6470fed1277817ed607/lib/ResolverFactory.js"}),(0,a.kt)("inlineCode",{parentName:"a"},"ResolverFactory.js"))," which can be used to make a resolver. However, you can supply it with a million options and that's just like giving someone a gun with a predilection for feet."),(0,a.kt)("p",null,"What you want is an example of how you could make a sync resolver. Well, surprise surprise it's right in front of your nose. Tucked away in ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/enhanced-resolve/blob/3f3f4cd1fcbafa1e98c3c6470fed1277817ed607/lib/node.js"}),(0,a.kt)("inlineCode",{parentName:"a"},"node.js"))," (I do ","*",(0,a.kt)("strong",{parentName:"p"},"not"),"*"," get the name) is exactly what you're after. It contains a number of factory functions which will construct a ready-made resolver for you; sync or async. Perfect! So here's how I'm rolling:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const node = require('enhanced-resolve/lib/node');\n\nfunction makeSyncResolver(options) {\n  return node.create.sync(options.resolve);\n}\n\nconst resolveSync = makeSyncResolver(loader.options);\n")),(0,a.kt)("p",null,"The loader options used above you'll be familiar with as the ",(0,a.kt)("inlineCode",{parentName:"p"},"resolve")," section of your ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js"),". You can read more about them ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/enhanced-resolve/blob/master/README/index.md"}),"here")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://webpack.js.org/configuration/resolve/"}),"here"),"."),(0,a.kt)("p",null,"What you're left with at this point is a function; a ",(0,a.kt)("inlineCode",{parentName:"p"},"resolveSync")," function if you will that takes 3 arguments:"),(0,a.kt)("dl",null,(0,a.kt)("dt",null,"context"),(0,a.kt)("dd",null,"I don't know what this is. So when using the function I just supply ",(0,a.kt)("code",null,"undefined"),"; and that seems to be OK. Weird, right?"),(0,a.kt)("dt",null,"path"),(0,a.kt)("dd",null,"This is the path to your code (I think). So, a valid value to supply - handily lifted from the ts-loader test pack - would be: ",(0,a.kt)("code",null,"C:\\source\\ts-loader\\.test\\babel-issue92")),(0,a.kt)("dt",null,"request"),(0,a.kt)("dd",null,"The actual module you're interested in; so using the same test the relevant value would be ",(0,a.kt)("code",null,"./submodule/submodule"))),(0,a.kt)("p",null,"Put it all together and what have you got?"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const resolvedFileName = resolveSync(\n  undefined,\n  'C:source\\ts-loader.test\\babel-issue92',\n  './submodule/submodule'\n);\n\n// resolvedFileName: C:\\source\\ts-loader\\.test\\babel-issue92\\submodule\\submodule.tsx\n")),(0,a.kt)("p",null,"Boom."))}d.isMDXComponent=!0},88210:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"using-ts-loader-with-webpack-2",title:"Using ts-loader with webpack 2",authors:"johnnyreilly",tags:["ts-loader","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/using-ts-loader-with-webpack-2",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2016-12-19-using-ts-loader-with-webpack-2/index.md",source:"@site/blog/2016-12-19-using-ts-loader-with-webpack-2/index.md",title:"Using ts-loader with webpack 2",description:"Hands up, despite being one of the maintainers of ts-loader (a TypeScript loader for webpack) I have not been tracking webpack v2. My reasons? Well, I'm keen on cutting edge but bleeding edge is often not a ton of fun as dealing with regularly breaking changes is frustrating. I'm generally happy to wait for things to settle down a bit before leaping aboard. However, webpack 2 RC'd last week and so it's time to take a look!",date:"2016-12-19T00:00:00.000Z",formattedDate:"December 19, 2016",tags:[{label:"ts-loader",permalink:"/tags/ts-loader"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:7.85,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"using-ts-loader-with-webpack-2",title:"Using ts-loader with webpack 2",authors:"johnnyreilly",tags:["ts-loader","webpack"],hide_table_of_contents:!1},prevItem:{title:"webpack: configuring a loader with query / options",permalink:"/webpack-configuring-loader-with-query"},nextItem:{title:"webpack: syncing the enhanced-resolve",permalink:"/webpack-syncing-enhanced-resolve"}},p={authorsImageUrls:[void 0]},u=[{value:"Porting our example",id:"porting-our-example",level:2},{value:"<code>webpack.config.js</code>",id:"webpackconfigjs",level:2},{value:"<code>plugins</code>",id:"plugins",level:2},{value:"<code>LoaderOptionsPlugin</code> we hardly new ya",id:"loaderoptionsplugin-we-hardly-new-ya",level:2},{value:"<code>karma.conf.js</code>",id:"karmaconfjs",level:2},{value:"Compare and contrast",id:"compare-and-contrast",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Hands up, despite being one of the maintainers of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader"}),"ts-loader")," (a TypeScript loader for webpack) I have not been tracking webpack v2. My reasons? Well, I'm keen on cutting edge but bleeding edge is often not a ton of fun as dealing with regularly breaking changes is frustrating. I'm generally happy to wait for things to settle down a bit before leaping aboard. However, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/webpack/releases/tag/v2.2.0-rc.0"}),"webpack 2 RC'd last week")," and so it's time to take a look!"),(0,a.kt)("h2",o({},{id:"porting-our-example"}),"Porting our example"),(0,a.kt)("p",null,"Let's take ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/tree/master/examples/webpack1-gulp-react-flux-babel-karma"}),"ts-loader's webpack 1 example")," and try and port it to webpack 2. Will it work? Probably; I'm aware of other people using ts-loader with webpack 2. It'll be a voyage of discovery. Like Darwin on the Beagle, I shall document our voyage for a couple of reasons:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"I'm probably going to get some stuff wrong. That's fine; one of the best ways to learn is to make mistakes. So do let me know where I go wrong."),(0,a.kt)("li",{parentName:"ul"},"I'm doing this based on what I've read in the new docs; they're very much a work in progress and the mistakes I make here may lead to those docs improving even more. That matters; ",(0,a.kt)("strong",{parentName:"li"},"documentation matters"),". I'll be leaning heavily on the ",(0,a.kt)("a",o({parentName:"li"},{href:"https://webpack.js.org/guides/migrating/"}),"Migrating from v1 to v2")," guide.")),(0,a.kt)("p",null,"So here we go. Our example is one which uses TypeScript for static typing and uses Babel to transpile from ES-super-modern (yes - it's a thing) to ES-older-than-that. Our example also uses React; but that's somewhat incidental. It only uses webpack for typescript / javascript and karma. It uses gulp to perform various other tasks; so if you're reliant on webpack for less / sass compilation etc then I have no idea whether that works."),(0,a.kt)("p",null,"First of all, let's install the latest RC of webpack:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"npm install webpack@2.2.0-rc.1 --save-dev\n")),(0,a.kt)("h2",o({},{id:"webpackconfigjs"}),(0,a.kt)("inlineCode",{parentName:"h2"},"webpack.config.js")),(0,a.kt)("p",null,"Let's look at our existing ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"'use strict';\n\nvar path = require('path');\n\nmodule.exports = {\n  cache: true,\n  entry: {\n    main: './src/main.tsx',\n    vendor: ['babel-polyfill', 'fbemitter', 'flux', 'react', 'react-dom'],\n  },\n  output: {\n    path: path.resolve(__dirname, './dist/scripts'),\n    filename: '[name].js',\n    chunkFilename: '[chunkhash].js',\n  },\n  module: {\n    loaders: [\n      {\n        test: /\\.ts(x?)$/,\n        exclude: /node_modules/,\n        loader:\n          'babel-loader?presets[]=es2016&presets[]=es2015&presets[]=react!ts-loader',\n      },\n      {\n        test: /\\.js$/,\n        exclude: /node_modules/,\n        loader: 'babel',\n        query: {\n          presets: ['es2016', 'es2015', 'react'],\n        },\n      },\n    ],\n  },\n  plugins: [],\n  resolve: {\n    extensions: ['', '.webpack.js', '.web.js', '.ts', '.tsx', '.js'],\n  },\n};\n")),(0,a.kt)("p",null,"There's a number of things we need to do here. First of all, we can get rid of the empty extension under resolve; I understand that's unnecessary now. Also, I'm going to get rid of ",(0,a.kt)("inlineCode",{parentName:"p"},"'.webpack.js'")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"'.web.js'"),"; I never used them anyway. Also, just having ",(0,a.kt)("inlineCode",{parentName:"p"},"'babel'")," as a loader won't fly anymore. We need that suffix as well."),(0,a.kt)("p",null,"Now I could start renaming ",(0,a.kt)("inlineCode",{parentName:"p"},"loaders")," to ",(0,a.kt)("inlineCode",{parentName:"p"},"rules")," as the terminology is changing. But I'd like to deal with that later since I know the old school names are still supported at present. More interestingly, I seem to remember hearing that one of the super exciting things about webpack is that it supports modules directly now. (I think that's supposed to be good for tree-shaking but I'm not totally certain.)"),(0,a.kt)("p",null,"Initially I thought I was supposed to switch to a custom babel preset called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/babel-preset-es2015-webpack"}),(0,a.kt)("inlineCode",{parentName:"a"},"babel-preset-es2015-webpack")),'. However it has a big "DEPRECATED" mark at the top and it says I should just use ',(0,a.kt)("inlineCode",{parentName:"p"},"babel-preset-es2015")," (which I already am) with the following option specified:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),'{\n    "presets": [\n        [\n            "es2015",\n            {\n                "modules": false\n            }\n        ]\n    ]\n}\n')),(0,a.kt)("p",null,"Looking at our existing config you'll note that for ",(0,a.kt)("inlineCode",{parentName:"p"},"js")," files we're using ",(0,a.kt)("inlineCode",{parentName:"p"},"query")," (",(0,a.kt)("inlineCode",{parentName:"p"},"options")," in the new world I understand) to configure babel usage. We're using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://webpack.github.io/docs/using-loaders.html#query-parameters"}),"query parameters")," for ",(0,a.kt)("inlineCode",{parentName:"p"},"ts")," files. I have ",(0,a.kt)("em",{parentName:"p"},"zero")," idea how to configure preset options using query parameters. Fiddling with ",(0,a.kt)("inlineCode",{parentName:"p"},"query")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"options")," didn't seem to work. So, I've decided to abandon using query entirely and drop in a ",(0,a.kt)("a",o({parentName:"p"},{href:"http://babeljs.io/docs/usage/babelrc/"}),(0,a.kt)("inlineCode",{parentName:"a"},".babelrc"))," file using our presets combined with the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://babeljs.io/docs/plugins/#plugin-preset-options"}),(0,a.kt)("inlineCode",{parentName:"a"},"modules"))," setting:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),'{\n   "presets": [\n      "react",\n      [\n         "es2015",\n         {\n            "modules": false\n         }\n      ],\n      "es2016"\n   ]\n}\n')),(0,a.kt)("p",null,"As an aside; apparently these are applied in reverse order. So ",(0,a.kt)("inlineCode",{parentName:"p"},"es2016")," is applied first, ",(0,a.kt)("inlineCode",{parentName:"p"},"es2015")," second and ",(0,a.kt)("inlineCode",{parentName:"p"},"react")," third. I'm not totally certain this is correct; the ",(0,a.kt)("inlineCode",{parentName:"p"},'<a href="http://babeljs.io/docs/usage/babelrc/">.babelrc</a> docs')," are a little unclear."),(0,a.kt)("p",null,"With our query options extracted we're down to a simpler ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"'use strict';\n\nvar path = require('path');\n\nmodule.exports = {\n  cache: true,\n  entry: {\n    main: './src/main.tsx',\n    vendor: ['babel-polyfill', 'fbemitter', 'flux', 'react', 'react-dom'],\n  },\n  output: {\n    path: path.resolve(__dirname, './dist/scripts'),\n    filename: '[name].js',\n    chunkFilename: '[chunkhash].js',\n  },\n  module: {\n    loaders: [\n      {\n        test: /\\.ts(x?)$/,\n        exclude: /node_modules/,\n        loader: 'babel-loader!ts-loader',\n      },\n      {\n        test: /\\.js$/,\n        exclude: /node_modules/,\n        loader: 'babel-loader',\n      },\n    ],\n  },\n  plugins: [],\n  resolve: {\n    extensions: ['.ts', '.tsx', '.js'],\n  },\n};\n")),(0,a.kt)("h2",o({},{id:"plugins"}),(0,a.kt)("inlineCode",{parentName:"h2"},"plugins")),(0,a.kt)("p",null,"In our example the ",(0,a.kt)("inlineCode",{parentName:"p"},"plugins")," section of our ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js")," is extended in a separate process. Whilst we're developing we also set the ",(0,a.kt)("inlineCode",{parentName:"p"},"debug")," flag to be ",(0,a.kt)("inlineCode",{parentName:"p"},"true"),". ",(0,a.kt)("a",o({parentName:"p"},{href:"https://webpack.js.org/guides/migrating/#debug"}),"It seems we need to introduce a ",(0,a.kt)("inlineCode",{parentName:"a"},"LoaderOptionsPlugin")," to do this for us.")),(0,a.kt)("p",null,"As we introduce our ",(0,a.kt)("inlineCode",{parentName:"p"},"LoaderOptionsPlugin")," we also need to make sure that we provide it with ",(0,a.kt)("inlineCode",{parentName:"p"},"options"),". How do I know this? Well ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/issues/283"}),"someone raised an issue against ts-loader"),". I don't think this is actually an issue with ts-loader; I think it's just a webpack 2 thing. I could be wrong; answers on a postcard please."),(0,a.kt)("p",null,"Either way, to get up and running we just need the ",(0,a.kt)("inlineCode",{parentName:"p"},"LoaderOptionsPlugin")," in play. Consequently, most of what follows in our ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.js")," file is unchanged:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"// .....\n\nvar webpackConfig = require('../webpack.config.js');\nvar packageJson = require('../package.json');\n\n// .....\n\nfunction buildProduction(done) {\n  // .....\n\n  myProdConfig.plugins = myProdConfig.plugins.concat(\n    // .....\n\n    // new webpack.optimize.DedupePlugin(), Not a thing anymore apparently\n    new webpack.optimize.UglifyJsPlugin(),\n\n    // I understand this here matters...\n    // but it doesn't seem to make any difference; perhaps I'm missing something?\n    new webpack.LoaderOptionsPlugin({\n      minimize: true,\n      debug: false,\n    }),\n\n    failPlugin\n  );\n\n  // .....\n}\n\nfunction createDevCompiler() {\n  var myDevConfig = webpackConfig;\n  myDevConfig.devtool = 'inline-source-map';\n  // myDevConfig.debug = true; - not allowed in webpack 2\n\n  myDevConfig.plugins = myDevConfig.plugins.concat(\n    new webpack.optimize.CommonsChunkPlugin({\n      name: 'vendor',\n      filename: 'vendor.js',\n    }),\n    new WebpackNotifierPlugin({\n      title: 'Webpack build',\n      excludeWarnings: true,\n    }),\n\n    // this is the Webpack 2 hotness!\n    new webpack.LoaderOptionsPlugin({\n      debug: true,\n      options: myDevConfig,\n    })\n    // it ends here - there wasn't much really....\n  );\n\n  // create a single instance of the compiler to allow caching\n  return webpack(myDevConfig);\n}\n\n// .....\n")),(0,a.kt)("h2",o({},{id:"loaderoptionsplugin-we-hardly-new-ya"}),(0,a.kt)("inlineCode",{parentName:"h2"},"LoaderOptionsPlugin")," we hardly new ya"),(0,a.kt)("p",null,"After a little more experimentation it seems that the ",(0,a.kt)("inlineCode",{parentName:"p"},"LoaderOptionsPlugin")," is not necessary at all for our own use case. In fact it's probably not best practice to get used to using it as it's only intended to live a short while whilst people move from webpack 1 to webpack 2. In that vein let's tweak our ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.js")," file once more:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"function buildProduction(done) {\n  // .....\n\n  myProdConfig.plugins = myProdConfig.plugins.concat(\n    // .....\n\n    new webpack.optimize.UglifyJsPlugin({\n      compress: {\n        warnings: true,\n      },\n    }),\n\n    failPlugin\n  );\n\n  // .....\n}\n\nfunction createDevCompiler() {\n  var myDevConfig = webpackConfig;\n  myDevConfig.devtool = 'inline-source-map';\n\n  myDevConfig.plugins = myDevConfig.plugins.concat(\n    new webpack.optimize.CommonsChunkPlugin({\n      name: 'vendor',\n      filename: 'vendor.js',\n    }),\n    new WebpackNotifierPlugin({ title: 'Webpack build', excludeWarnings: true })\n  );\n\n  // create a single instance of the compiler to allow caching\n  return webpack(myDevConfig);\n}\n\n// .....\n")),(0,a.kt)("h2",o({},{id:"karmaconfjs"}),(0,a.kt)("inlineCode",{parentName:"h2"},"karma.conf.js")),(0,a.kt)("p",null,"Finally Karma. Our ",(0,a.kt)("inlineCode",{parentName:"p"},"karma.conf.js")," with webpack 1 looked like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"/* eslint-disable no-var, strict */\n'use strict';\n\nvar webpackConfig = require('./webpack.config.js');\n\nmodule.exports = function (config) {\n  // Documentation: https://karma-runner.github.io/0.13/config/configuration-file.html\n  config.set({\n    browsers: ['PhantomJS'],\n\n    files: [\n      // This ensures we have the es6 shims in place and then loads all the tests\n      'test/main.js',\n    ],\n\n    port: 9876,\n\n    frameworks: ['jasmine'],\n\n    logLevel: config.LOG_INFO, //config.LOG_DEBUG\n\n    preprocessors: {\n      'test/main.js': ['webpack', 'sourcemap'],\n    },\n\n    webpack: {\n      devtool: 'inline-source-map',\n      debug: true,\n      module: webpackConfig.module,\n      resolve: webpackConfig.resolve,\n    },\n\n    webpackMiddleware: {\n      quiet: true,\n      stats: {\n        colors: true,\n      },\n    },\n\n    // reporter options\n    mochaReporter: {\n      colors: {\n        success: 'bgGreen',\n        info: 'cyan',\n        warning: 'bgBlue',\n        error: 'bgRed',\n      },\n    },\n  });\n};\n")),(0,a.kt)("p",null,"We just need to chop out the ",(0,a.kt)("inlineCode",{parentName:"p"},"debug")," statement from the ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack")," section like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"module.exports = function(config) {\n\n  // .....\n\n    webpack: {\n      devtool: 'inline-source-map',\n      module: webpackConfig.module,\n      resolve: webpackConfig.resolve\n    },\n\n  // .....\n\n  });\n};\n")),(0,a.kt)("h2",o({},{id:"compare-and-contrast"}),"Compare and contrast"),(0,a.kt)("p",null,"We now have a repo that works with webpack 2 rc 1. Yay! If you'd like to see it then take a look ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/tree/master/examples/webpack2-gulp-react-flux-babel-karma"}),"here"),"."),(0,a.kt)("p",null,"I thought I'd compare performance / output size of compiling with webpack 1 to webpack 2. First of all in debug / development mode:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"// webpack 1\n\nVersion: webpack 1.14.0\nTime: 5063ms\n    Asset     Size  Chunks             Chunk Names\n  main.js  37.2 kB       0  [emitted]  main\nvendor.js  2.65 MB       1  [emitted]  vendor\n\n// webpack 2\n\nVersion: webpack 2.2.0-rc.1\nTime: 5820ms\n    Asset     Size  Chunks                    Chunk Names\n  main.js  38.7 kB       0  [emitted]         main\nvendor.js  2.63 MB       1  [emitted]  [big]  vendor\n")),(0,a.kt)("p",null,"Size and compilation time is not massively different from webpack 1 to webpack 2. It's all about the same. I'm not sure if that's to be expected or not.... Though I've a feeling in production mode I'm supposed to feel the benefits of tree shaking so let's have a go:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"// webpack 1\n\nVersion: webpack 1.14.0\nTime: 5788ms\n                         Asset     Size  Chunks             Chunk Names\n  main.269c66e1bc13b7426cee.js  10.5 kB       0  [emitted]  main\nvendor.269c66e1bc13b7426cee.js   231 kB       1  [emitted]  vendor\n\n// webpack 2\n\nVersion: webpack 2.2.0-rc.1\nTime: 5659ms\n                         Asset     Size  Chunks             Chunk Names\n  main.33e0d70eeec29206e9b6.js  9.22 kB       0  [emitted]  main\nvendor.33e0d70eeec29206e9b6.js   233 kB       1  [emitted]  vendor\n")),(0,a.kt)("p",null,"To my surprise this looks pretty much unchanged before and after as well. This may be a sign I have missed something crucial out. Or maybe that's to be expected. Do give me a heads up if I've missed something..."))}d.isMDXComponent=!0},50313:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"webpack-configuring-loader-with-query",title:"webpack: configuring a loader with query / options",authors:"johnnyreilly",tags:["webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/webpack-configuring-loader-with-query",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-01-01-webpack-configuring-loader-with-query/index.md",source:"@site/blog/2017-01-01-webpack-configuring-loader-with-query/index.md",title:"webpack: configuring a loader with query / options",description:"webpack 2 is on it's way. As one of the maintainers of ts-loader I've been checking out that ts-loader works with webpack 2. It does: phew!",date:"2017-01-01T00:00:00.000Z",formattedDate:"January 1, 2017",tags:[{label:"webpack",permalink:"/tags/webpack"}],readingTime:2.805,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"webpack-configuring-loader-with-query",title:"webpack: configuring a loader with query / options",authors:"johnnyreilly",tags:["webpack"],hide_table_of_contents:!1},prevItem:{title:"webpack: resolveLoader / alias with query / options",permalink:"/webpack-resolveloader-alias-with-query"},nextItem:{title:"Using ts-loader with webpack 2",permalink:"/using-ts-loader-with-webpack-2"}},p={authorsImageUrls:[void 0]},u=[{value:"What exactly is <code>query</code> / <code>options</code>?",id:"what-exactly-is-query--options",level:2},{value:"webpack 2 is coming - look busy!",id:"webpack-2-is-coming---look-busy",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://medium.com/webpack/webpack-2-2-the-release-candidate-2e614d05d75f#.ntniu44u6"}),"webpack 2 is on it's way"),". As one of the maintainers of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/"}),"ts-loader")," I've been checking out that ts-loader works with webpack 2. It does: phew!"),(0,a.kt)("p",null,"ts-loader has a continuous integration build that runs against webpack 1. When webpack 2 ships we're planning to move to running CI against webpack 2. However, webpack 2 has some breaking changes. The one that's particularly of relevance to our test packs is that a strict schema is now enforced for ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js")," with webpack 2. This has been the case since webpack 2 hit beta 23. Check the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/webpack/pull/2974"}),"PR that added it"),". You can see some of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/webpack/issues/3018"}),"frankly tortured discussion that this generated as well"),"."),(0,a.kt)("p",null,"Let's all take a moment and realise that working on open source is sometimes a rather painful experience. Take a breath. Breathe out. Ready to carry on? Great."),(0,a.kt)("p",null,"There are 2 ways to configure loader options for ts-loader (and in fact this stands for most loaders). Loader options can be set either using a ",(0,a.kt)("inlineCode",{parentName:"p"},"query")," when specifying the loader or through the ",(0,a.kt)("inlineCode",{parentName:"p"},"ts")," (insert the name of alternative loaders here) property in the ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js"),"."),(0,a.kt)("p",null,"The implicatations of the breaking change are: with webpack 2 you can ",(0,a.kt)("strong",{parentName:"p"},"no longer")," configure ts-loader (or any other loader) with a ",(0,a.kt)("inlineCode",{parentName:"p"},"ts")," (insert the name of alternative loaders here) property in the ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js"),". It ",(0,a.kt)("strong",{parentName:"p"},"must")," be done through the ",(0,a.kt)("inlineCode",{parentName:"p"},"query")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"options"),". The following code is no longer valid with webpack 2:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"module.exports = {\n  ...\n  module: {\n    loaders: [{\n      test: /\\.tsx?$/,\n      loader: 'ts-loader'\n    }]\n  },\n  // specify option using `ts` property - **only do this if you are using webpack 1**\n  ts: {\n    transpileOnly: false\n  }\n}\n")),(0,a.kt)("p",null,"This change means that we have needed to adjust how our test pack works. We can no longer make use of ",(0,a.kt)("inlineCode",{parentName:"p"},"ts")," for configuration. Since I wasn't terribly aware of ",(0,a.kt)("inlineCode",{parentName:"p"},"query")," I thought it made sense to share my learnings."),(0,a.kt)("h2",o({},{id:"what-exactly-is-query--options"}),"What exactly is ",(0,a.kt)("inlineCode",{parentName:"h2"},"query")," / ",(0,a.kt)("inlineCode",{parentName:"h2"},"options"),"?"),(0,a.kt)("p",null,"Good question. Well, strictly speaking it's 2 possible things; both ways to configure a webpack loader. Classically ",(0,a.kt)("inlineCode",{parentName:"p"},"query")," was a string which could be appended to the name of the loader much like a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Query_string"}),(0,a.kt)("inlineCode",{parentName:"a"},"query string"))," but actually with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/loader-utils#parsequery"}),"greater powers"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"module.exports = {\n  ...\n  module: {\n    loaders: [{\n      test: /\\.tsx?$/,\n      loader: 'ts-loader?' + JSON.stringify({\n        transpileOnly: false\n      })\n    }]\n  }\n}\n")),(0,a.kt)("p",null,"But it can also be a separately specified object that's supplied alongside a loader (I understand this is relatively new behaviour):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"module.exports = {\n  ...\n  module: {\n    loaders: [{\n      test: /\\.tsx?$/,\n      loader: 'ts-loader'\n      query: {\n        transpileOnly: false\n      }\n    }]\n  }\n}\n")),(0,a.kt)("h2",o({},{id:"webpack-2-is-coming---look-busy"}),"webpack 2 is coming - look busy!"),(0,a.kt)("p",null,"So if you're planning to move to webpack 2, be aware of this breaking change. You can start moving to using configuration via query right now with webpack 1. You don't need to be using webpack 2 to make the jump. So jump!"),(0,a.kt)("p",null,"Finally, and by way of a PS, ",(0,a.kt)("inlineCode",{parentName:"p"},"query")," is renamed to ",(0,a.kt)("inlineCode",{parentName:"p"},"options")," in webpack 2; a much better name to my mind. There's actually a bunch of other renames on the way as well - check out the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://webpack.js.org/guides/migrating/#module-loaders-is-now-module-rules"}),"migration guide")," for more on this. The important thing to note is that ",(0,a.kt)("strong",{parentName:"p"},"the old names work in webpack 2"),". But you should plan to move to the new naming at some point as they'll likely disappear when webpack 3 ships."))}d.isMDXComponent=!0},40722:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"webpack-resolveloader-alias-with-query",title:"webpack: resolveLoader / alias with query / options",authors:"johnnyreilly",tags:["webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/webpack-resolveloader-alias-with-query",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-01-06-webpack-resolveloader-alias-with-query/index.md",source:"@site/blog/2017-01-06-webpack-resolveloader-alias-with-query/index.md",title:"webpack: resolveLoader / alias with query / options",description:'Sometimes you write a post for the ages. Sometimes you write one you hope is out of date before you hit "publish". This is one of those.',date:"2017-01-06T00:00:00.000Z",formattedDate:"January 6, 2017",tags:[{label:"webpack",permalink:"/tags/webpack"}],readingTime:1.38,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"webpack-resolveloader-alias-with-query",title:"webpack: resolveLoader / alias with query / options",authors:"johnnyreilly",tags:["webpack"],hide_table_of_contents:!1},prevItem:{title:"Hands-free HTTPS",permalink:"/hands-free-https"},nextItem:{title:"webpack: configuring a loader with query / options",permalink:"/webpack-configuring-loader-with-query"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'Sometimes you write a post for the ages. Sometimes you write one you hope is out of date before you hit "publish". This is one of those.'),(0,a.kt)("p",null,"There's a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/enhanced-resolve/issues/41"}),"bug")," in webpack's enhanced-resolve. It means that you cannot configure an aliased loader using the ",(0,a.kt)("inlineCode",{parentName:"p"},"query")," (or ",(0,a.kt)("inlineCode",{parentName:"p"},"options")," in the webpack 2 nomenclature). Let me illustrate; consider the following code:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"module.exports = {\n  // ...\n  module: {\n    loaders: [\n      {\n        test: /\\.ts$/,\n        loader: 'ts-loader',\n        query: {\n            entryFileIsJs: true\n        }\n      }\n    ]\n  }\n}\n\nmodule.exports.resolveLoader = { alias: { 'ts-loader': require('path').join(__dirname, \"../../index.js\")\n")),(0,a.kt)("p",null,"At the time of writing, if you alias a loader as above, then the ",(0,a.kt)("inlineCode",{parentName:"p"},"query")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"options")," will ","*",(0,a.kt)("em",{parentName:"p"},"not"),"*"," be passed along. This is bad, particularly given the requirement in webpack 2 that configuration is no longer possible through extending the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://webpack.js.org/guides/migrating/#loader-configuration-is-through-options"}),(0,a.kt)("inlineCode",{parentName:"a"},"webpack.config.js")),". So what to do? Well, when this was a problem previously the marvellous ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.twitter.com/jbrantly"}),"James Brantly")," had a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/webpack/issues/1289#issuecomment-125767499"}),"workaround"),". I've taken that and run with it:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var config = {\n  // ...\n  module: {\n    loaders: [\n      {\n        test: /\\.ts$/,\n        loader: 'ts-loader',\n        query: {\n          entryFileIsJs: true,\n        },\n      },\n    ],\n  },\n};\n\nmodule.exports = config;\n\nvar loaderAliasPath = require('path').join(__dirname, '../../../index.js');\nvar rules = config.module.loaders || config.module.rules;\nrules.forEach(function (rule) {\n  var options = rule.query || rule.options;\n  rule.loader = rule.loader.replace(\n    'ts-loader',\n    loaderAliasPath + (options ? '?' + JSON.stringify(options) : '')\n  );\n});\n")),(0,a.kt)("p",null,"This approach stringifies the ",(0,a.kt)("inlineCode",{parentName:"p"},"query")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"options")," and suffixes it to the aliased path. This works as long as the options you're passing are JSON-able (yes it's a word)."),(0,a.kt)("p",null,"As I said earlier; hopefully by the time you read this the workaround will no longer be necessary again. But just in case...."))}d.isMDXComponent=!0},77317:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"hands-free-https",title:"Hands-free HTTPS",authors:"johnnyreilly",tags:["TLS","HTTPS","cloudflare"],hide_table_of_contents:!1},s=void 0,l={permalink:"/hands-free-https",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-02-01-hands-free-https/index.md",source:"@site/blog/2017-02-01-hands-free-https/index.md",title:"Hands-free HTTPS",description:"I have had a \\*great\\* week. You? Take a look at this blog. Can you see what I can see? Here's a clue:",date:"2017-02-01T00:00:00.000Z",formattedDate:"February 1, 2017",tags:[{label:"TLS",permalink:"/tags/tls"},{label:"HTTPS",permalink:"/tags/https"},{label:"cloudflare",permalink:"/tags/cloudflare"}],readingTime:1.625,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"hands-free-https",title:"Hands-free HTTPS",authors:"johnnyreilly",tags:["TLS","HTTPS","cloudflare"],hide_table_of_contents:!1},prevItem:{title:"@types is rogue",permalink:"/typescript-types-and-repeatable-builds"},nextItem:{title:"webpack: resolveLoader / alias with query / options",permalink:"/webpack-resolveloader-alias-with-query"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I have had a ","*",(0,a.kt)("strong",{parentName:"p"},"great"),"*"," week. You? Take a look at this blog. Can you see what I can see? Here's a clue:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(50391).Z,width:"640",height:"428"})),(0,a.kt)("p",null,"Yup, look at the top left hand corner.... see that beautiful padlock? Yeah - that's what's thrilled me. You see I have a dream; that one day on the red hills of the internet, the sons of former certificates and the sons of former certificate authorities will be able to sit down together at the table of HTTPS. Peace, love and TLS for all."),(0,a.kt)("p",null,"The world is turning and slowly but surely HTTPS is becoming the default of the web. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://security.googleblog.com/2014/08/https-as-ranking-signal_6.html"}),"Search results get ranked higher if they're HTTPS."),(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/HTTP/2#Encryption"}),"HTTP/2 is, to all intents and purposes, a HTTPS-only game."),(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en/docs/Web/API/Service_Worker_API"}),"Service Workers are HTTPS-only.")),(0,a.kt)("p",null,"I care about all of these. So it's ",(0,a.kt)("em",{parentName:"p"},"essential")," that I have HTTPS. But. But. But... Certificates, the administration that goes with them. It's boring. I mean, it just is. I want to be building interesting apps, I don't want to be devoting my time to acquiring certificates and fighting my way through the (never simple) administration of them. I'm dimly aware that there's free certificates to be had thanks to the fine work of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://letsencrypt.org/"}),"LetsEncrypt"),". I believe that work is being done on reduce the onerous admin burden as well. And that's great. But I'm still avoiding it..."),(0,a.kt)("p",null,"What if I told you you could have HTTPS on your blog, on your Azure websites, on your anywhere.... ",(0,a.kt)("em",{parentName:"p"},"FOR FREE. IN FIVE MINUTES?"),". Well, you can thanks to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.cloudflare.com/"}),"CloudFlare"),". I did; you should too."),(0,a.kt)("p",null,"This is where I point you off to a number of resources to help you on your HTTPS way:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",o({parentName:"li"},{href:"https://www.troyhunt.com/how-to-get-your-ssl-for-free-on-shared/"}),'Read Troy Hunt\'s "How to get your SSL for free on a Shared Azure website with CloudFlare"')),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",o({parentName:"li"},{href:"https://www.pluralsight.com/courses/cloudflare-security-getting-started"}),'Watch Troy Hunt\'s Pluralsight course "Getting Started with CloudFlare\u2122 Security"')),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",o({parentName:"li"},{href:"https://www.cloudflare.com/"}),"Go to Cloudflare's website and sign up"))),(0,a.kt)("p",null,"It just works. And that makes me very happy indeed."))}d.isMDXComponent=!0},82510:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-types-and-repeatable-builds",title:"@types is rogue",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-types-and-repeatable-builds",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-02-14-typescript-types-and-repeatable-builds/index.md",source:"@site/blog/2017-02-14-typescript-types-and-repeatable-builds/index.md",title:"@types is rogue",description:'Or perhaps I should call this "@types and repeatable builds"....',date:"2017-02-14T00:00:00.000Z",formattedDate:"February 14, 2017",tags:[],readingTime:2.03,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-types-and-repeatable-builds",title:"@types is rogue",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},prevItem:{title:"Under the Duck: An Afternoon in Open Source",permalink:"/under-duck-afternoon-in-open-source"},nextItem:{title:"Hands-free HTTPS",permalink:"/hands-free-https"}},p={authorsImageUrls:[void 0]},u=[{value:"How do we respond to this?",id:"how-do-we-respond-to-this",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'Or perhaps I should call this "@types and repeatable builds"....'),(0,a.kt)("p",null,"The other day, on a React / TypeScript project I work on, the nightly CI build started failing. But nothing had changed in the project... What gives? After digging I discovered the reason; spome of the type definitions which my project depends upon had changed. Why did this break my build? Let\u2019s learn some more..."),(0,a.kt)("p",null,"We acquire type definitions via npm. Type definitions from Definitely Typed are published to npm by an ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/types-publisher"}),"automated process")," and they are all published under the @types namespace on npm. So, the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/react"}),"react type definition")," is published as the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/@types/react"}),"@types/react")," package, the node type definition is published as the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/@types/node"}),"@types/node")," package. The hip bone's connected to the thigh bone. You get the picture."),(0,a.kt)("p",null,"The npm ecosystem is essentially built on top of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://semver.org/"}),"semantic versioning")," and they ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.npmjs.com/getting-started/semantic-versioning"}),"take it seriously"),". Essentially, when a package is published it should be categorised as a major release (breaking changes), a minor release (extra functionality which is backwards compatible) or a patch release (backwards compatible bug fixes)."),(0,a.kt)("p",null,"Now we get to the meat of the matter: @types is rogue. You cannot trust the version numbers on @types packages to respect semantic versioning. They don't."),(0,a.kt)("p",null,"The main reason for this is that when it comes to versioning, the @types type definition essentially looks to mirror the version of the package they are seeking to type. ",(0,a.kt)("em",{parentName:"p"},"THIS MEANS THE TYPE DEFINITION CANNOT DO ITS OWN SEMANTIC VERSIONING.")," A simple change in a type definition can lead to breakages in consuming code. That's what happened to me. Let's say an exported interface name changes; all code that relies upon the old name will now break. You see? Pain."),(0,a.kt)("h2",o({},{id:"how-do-we-respond-to-this"}),"How do we respond to this?"),(0,a.kt)("p",null,"My own take has been to pin the version numbers of @types packages; fixing to specific definitions. No ",(0,a.kt)("inlineCode",{parentName:"p"},'"~"')," or ",(0,a.kt)("inlineCode",{parentName:"p"},'"^"')," for my ",(0,a.kt)("inlineCode",{parentName:"p"},"@types devDependencies"),"."),(0,a.kt)("p",null,"No respect semantic versioning? No problem. You can go much further with repeatable builds and made use of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://code.facebook.com/posts/1840075619545360"}),"facebook's new npm client yarn")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://yarnpkg.com/blog/2016/11/24/lockfiles-for-all/"}),"lockfiles")," (very popular BTW) but I haven't felt the need yet. This should be ample for now."),(0,a.kt)("p",null,"The other question that may be nagging at your subconscious is this: what\u2019s an easy way to know when new packages are available for my project dependencies? Well, the ",(0,a.kt)("inlineCode",{parentName:"p"},"Get-Package -Updates")," (nuget hat tip) for npm that I\u2019d recommend is this: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/npm-check-updates"}),"npm-check-updates"),". It does the job wonderfully."))}d.isMDXComponent=!0},38243:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"under-duck-afternoon-in-open-source",title:"Under the Duck: An Afternoon in Open Source",authors:"johnnyreilly",tags:["ts-loader","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/under-duck-afternoon-in-open-source",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-02-23-under-duck-afternoon-in-open-source/index.md",source:"@site/blog/2017-02-23-under-duck-afternoon-in-open-source/index.md",title:"Under the Duck: An Afternoon in Open Source",description:"Have you ever wondered what happens behind the scenes of open source projects? One that I'm involved with is ts-loader; a TypeScript loader for webpack. Yesterday was an interesting day in the life of ts-loader and webpack; things unexpectedly broke. Oh and don't worry, they're fixed now.",date:"2017-02-23T00:00:00.000Z",formattedDate:"February 23, 2017",tags:[{label:"ts-loader",permalink:"/tags/ts-loader"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:5.255,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"under-duck-afternoon-in-open-source",title:"Under the Duck: An Afternoon in Open Source",authors:"johnnyreilly",tags:["ts-loader","webpack"],hide_table_of_contents:!1},prevItem:{title:"Debugging ASP.Net Core in VS or Code",permalink:"/debugging-aspnet-core-in-vs-or-code"},nextItem:{title:"@types is rogue",permalink:"/typescript-types-and-repeatable-builds"}},p={authorsImageUrls:[void 0]},u=[{value:"3:55pm",id:"355pm",level:3},{value:"16:12",id:"1612",level:3},{value:"16:15",id:"1615",level:3},{value:"17:28",id:"1728",level:3},{value:"18:00",id:"1800",level:3},{value:"18:15",id:"1815",level:3},{value:"19:30",id:"1930",level:3},{value:"20:30",id:"2030",level:3}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Have you ever wondered what happens behind the scenes of open source projects? One that I'm involved with is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/typestrong/ts-loader"}),"ts-loader"),"; a TypeScript loader for webpack. Yesterday was an interesting day in the life of ts-loader and webpack; things unexpectedly broke. Oh and don't worry, they're fixed now."),(0,a.kt)("p",null,"How things panned out reflects well on the webpack community. I thought it might be instructive to take a look at the legs furiously paddling underneath the duck of open source. What follows is a minute by minute account of my life on the afternoon of Wednesday 22nd February 2017:"),(0,a.kt)("h3",o({},{id:"355pm"}),"3:55pm"),(0,a.kt)("p",null,"I'm sat at my desk in the City of London. I have to leave at 4pm to go to the dentist. I'm working away on a project which is built and bundled using ts-loader and webpack. However, having just npm installed and tried to spin up webpack in watch mode, I discover that everything is broken. Watch mode is not working - there's an error being thrown in ts-loader. It's to do with a webpack property called ",(0,a.kt)("inlineCode",{parentName:"p"},"mtimes"),". ts-loader depends upon it and it looks like it is no longer always passed through. Go figure. ### 4:01pm"),(0,a.kt)("p",null,"I've got to go. I'm 15 minutes from Bank station. So, I grab my bag and scarper out the door. On my phone I notice ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/issues/479"}),"an issue")," has been raised - other people are being affected by the problem too. As I trot down the various alleys that lead to the station I wonder whether I can work around this issue. Using GitHub to fork, edit code and submit a PR on a mobile phone is possible. Just. But it's certainly not easy..."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/481"}),"My PR is in"),", the various test packs are starting to execute somewhere out there in Travis and Appveyor-land. Then I notice ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/mredbishop"}),"Ed Bishop")," has submitted a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/480"}),"near identical PR"),". Yay Ed! I'm always keen to encourage people to contribute and so I intend to merge that PR rather than my own."),(0,a.kt)("h3",o({},{id:"1612"}),"16:12"),(0,a.kt)("p",null,"Rubbish. The Waterloo and City Line is out of action. I need to get across London to reach Waterloo or I'll miss my appointment. It's time to start running...."),(0,a.kt)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/4IBGernmtKA",frameBorder:"0",allowFullScreen:""}),(0,a.kt)("h3",o({},{id:"1615"}),"16:15"),(0,a.kt)("p",null,"It's rather nagging at me that behaviour has changed without warning. This has been reliably in place the entire time I've been involved with ts-loader / webpack. Why now? I don't see any obvious mentions on the webpack GitHub repo. So I head over to the webpack Slack channel and ask: (conversation slightly abridged)"),(0,a.kt)("blockquote",null,(0,a.kt)("h4",o({parentName:"blockquote"},{id:"johnny_reilly"}),"johnny_reilly"),(0,a.kt)("p",{parentName:"blockquote"},"Hey all, has something happened to ",(0,a.kt)("inlineCode",{parentName:"p"},"mtimes"),"? Behaviour seems to have changed - now undefined occasionally during watch mode. A PR has been raised against ts-loader to work around this ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/480#issuecomment-281714600"}),"https://github.com/TypeStrong/ts-loader/pull/480#issuecomment-281714600")),(0,a.kt)("p",{parentName:"blockquote"},"However I'm wondering if this should actually be merged given behaviour has changed unexpectedly"),(0,a.kt)("h4",o({parentName:"blockquote"},{id:"sokra"}),"sokra"),(0,a.kt)("p",{parentName:"blockquote"},"ah..."),(0,a.kt)("p",{parentName:"blockquote"},"i removed it. I thought it was unused."),(0,a.kt)("h4",o({parentName:"blockquote"},{id:"johnny_reilly-1"}),"johnny_reilly"),(0,a.kt)("p",{parentName:"blockquote"},"It's definitely not!"),(0,a.kt)("h4",o({parentName:"blockquote"},{id:"sokra-1"}),"sokra"),(0,a.kt)("p",{parentName:"blockquote"},"it's not in the public API^^"),(0,a.kt)("p",{parentName:"blockquote"},"Any reason why you are not using ",(0,a.kt)("inlineCode",{parentName:"p"},"getTimes()"),"?"),(0,a.kt)("p",{parentName:"blockquote"},"..."),(0,a.kt)("h4",o({parentName:"blockquote"},{id:"johnny_reilly-2"}),"johnny_reilly"),(0,a.kt)("p",{parentName:"blockquote"},"Okay, I'm on a train and won't be near a computer for a while. ts-loader is presently broken because it depends on mtimes. Would it be possible for you to add this back at least for now. I'm aware many people depend on ts-loader and are now broken. #### sokra"),(0,a.kt)("p",{parentName:"blockquote"},"sure, I readd it but deprecate it."),(0,a.kt)("p",{parentName:"blockquote"},"..."),(0,a.kt)("h4",o({parentName:"blockquote"},{id:"seanlarkin"}),"sean.larkin"),(0,a.kt)("p",{parentName:"blockquote"},"@sokra is this the change you just made for that watchpack bug fix? Or unlrelated, just wanted to track if I didn't already have the change/issue #### sokra"),(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/watchpack/pull/48"}),"https://github.com/webpack/watchpack/pull/48")),(0,a.kt)("h4",o({parentName:"blockquote"},{id:"johnny_reilly-3"}),"johnny_reilly"),(0,a.kt)("p",{parentName:"blockquote"},"This is what the present code does:"),(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const watcher =\n  watching.compiler.watchFileSystem.watcher ||\n  watching.compiler.watchFileSystem.wfs.watcher;\n")),(0,a.kt)("p",{parentName:"blockquote"},"And then ",(0,a.kt)("inlineCode",{parentName:"p"},".mtimes")),(0,a.kt)("p",{parentName:"blockquote"},"Should I be able to do ",(0,a.kt)("inlineCode",{parentName:"p"},".getTimes()")," instead?"),(0,a.kt)("h4",o({parentName:"blockquote"},{id:"sokra-2"}),"sokra"),(0,a.kt)("p",{parentName:"blockquote"},"actually you can't rely on ",(0,a.kt)("inlineCode",{parentName:"p"},"watchFileSystem")," being ",(0,a.kt)("inlineCode",{parentName:"p"},"NodeJsWatchFileSystem"),". But this is another topic"),(0,a.kt)("p",{parentName:"blockquote"},"..."),(0,a.kt)("p",{parentName:"blockquote"},"but yes"),(0,a.kt)("h4",o({parentName:"blockquote"},{id:"johnny_reilly-4"}),"johnny_reilly"),(0,a.kt)("p",{parentName:"blockquote"},"Thanks @sokra - when I get to a keyboard I'll swap ",(0,a.kt)("inlineCode",{parentName:"p"},"mtimes")," for ",(0,a.kt)("inlineCode",{parentName:"p"},"getTimes()")," and report back.")),(0,a.kt)("h3",o({},{id:"1728"}),"17:28"),(0,a.kt)("p",null,"Despite various trains being out of action / missing in action I've made it to the dentists; phew! I go in for my checkup and plan to take a look at the issue later that evening. In the meantime I've hoping that Tobias (",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/wsokra"}),"Sokra"),") will get chance to republish so that ts-loader users aren't too impacted."),(0,a.kt)("h3",o({},{id:"1800"}),"18:00"),(0,a.kt)("p",null,"Done at the dentist and I'm heading home. Whilst I've been opening wide and squinting at the ceiling, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.microsoft.com/typescript/2017/02/22/announcing-typescript-2-2/"}),"TypeScript 2.2 has shipped"),". Whilst this is super exciting, according to Greenkeeper, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/483"}),"the new version has broken the build"),". Arrrrghhhh..."),(0,a.kt)("p",null,"I start to look into this and realise we're not broken because of TypeScript 2.2; we were broken because of the ",(0,a.kt)("inlineCode",{parentName:"p"},"mtimes"),". Tobias has now re-added ",(0,a.kt)("inlineCode",{parentName:"p"},"mtimes")," and published. With that in place I requeue a build and.... drum roll.... we're green!"),(0,a.kt)("p",null,"The good news just keeps on coming as ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/bancek"}),"Luka Zakraj\u0161ek")," has submitted a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/482"}),"PR which uses ",(0,a.kt)("inlineCode",{parentName:"a"},"getTimes()")," in place of ",(0,a.kt)("inlineCode",{parentName:"a"},"mtimes")),". And the tests pass. Awesome! MERGE. I just need to cut a release and we're done."),(0,a.kt)("h3",o({},{id:"1815"}),"18:15"),(0,a.kt)("p",null,"I'm home. My youngest son has been suffering from chicken pox all week and as a result my wife has been in isolation, taking care of him. We chat whilst the boys watch Paw Patrol as the bath runs. I flick open the laptop and start doing the various housekeeping tasks around cutting a release. This is interrupted by various bathtime / bedtime activities and I abandon work for now."),(0,a.kt)("h3",o({},{id:"1930"}),"19:30"),(0,a.kt)("p",null,"The boys are down and I get on with the release; updating the changelog, bumping the version number and running the tests. For various reasons this takes longer than it normally does."),(0,a.kt)("h3",o({},{id:"2030"}),"20:30"),(0,a.kt)("p",null,"Finally we're there; ts-loader 2.0.1 ships: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/releases/tag/v2.0.1"}),"https://github.com/TypeStrong/ts-loader/releases/tag/v2.0.1"),"."),(0,a.kt)("p",null,"I'm tremendously grateful to everyone that helped out - thank you all!"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"ts-loader 2.0.1 has shipped; thanks ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/wSokra"}),"@wsokra"),(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/bancek"}),"@bancek")," and @mredbishop ",(0,a.kt)("a",o({parentName:"p"},{href:"https://t.co/I00c7sJyFo"}),"https://t.co/I00c7sJyFo"),(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/hashtag/typescript?src=hash"}),"#","typescript")),(0,a.kt)("p",{parentName:"blockquote"},"\u2014 John Reilly (@johnny_reilly) ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/johnny_reilly/status/834515296077627392"}),"February 22, 2017"))),(0,a.kt)("script",{async:"",src:"//platform.twitter.com/widgets.js",charSet:"utf-8"}))}d.isMDXComponent=!0},31785:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"debugging-aspnet-core-in-vs-or-code",title:"Debugging ASP.Net Core in VS or Code",authors:"johnnyreilly",tags:["VS Code","ASP.Net Core","Visual Studio"],hide_table_of_contents:!1},s=void 0,l={permalink:"/debugging-aspnet-core-in-vs-or-code",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-03-28-debugging-aspnet-core-in-vs-or-code/index.md",source:"@site/blog/2017-03-28-debugging-aspnet-core-in-vs-or-code/index.md",title:"Debugging ASP.Net Core in VS or Code",description:"I've been using Visual Studio for a long time. Very good it is too. However, it is heavyweight; it does far more than I need. What I really want when I'm working is a fast snappy editor, with intellisense and debugging. What I've basically described is VS Code. It rocks and has long become my go-to editor for TypeScript.",date:"2017-03-28T00:00:00.000Z",formattedDate:"March 28, 2017",tags:[{label:"VS Code",permalink:"/tags/vs-code"},{label:"ASP.Net Core",permalink:"/tags/asp-net-core"},{label:"Visual Studio",permalink:"/tags/visual-studio"}],readingTime:3.705,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"debugging-aspnet-core-in-vs-or-code",title:"Debugging ASP.Net Core in VS or Code",authors:"johnnyreilly",tags:["VS Code","ASP.Net Core","Visual Studio"],hide_table_of_contents:!1},prevItem:{title:"I'm looking for work!",permalink:"/im-looking-for-work"},nextItem:{title:"Under the Duck: An Afternoon in Open Source",permalink:"/under-duck-afternoon-in-open-source"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I've been using Visual Studio for a long time. Very good it is too. However, it is heavyweight; it does far more than I need. What I really want when I'm working is a fast snappy editor, with intellisense and debugging. What I've basically described is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://code.visualstudio.com/"}),"VS Code"),". It rocks and has long become my go-to editor for TypeScript."),(0,a.kt)("p",null,"Since I'm a big C# fan as well I was delighted that editing C# was also possible in Code. What I want now is to be able to debug ASP.Net Core in Visual Studio OR VS Code. Can it be done? Let's see...."),(0,a.kt)("p",null,"I fire up Visual Studio and ",(0,a.kt)("inlineCode",{parentName:"p"},"File -&gt; New Project")," (yes it's a verb now). Select .NET Core and then ASP.Net Core Web Application. OK. We'll go for a Web Application. Let's not bother with authentication. OK. Wait a couple of seconds and Visual Studio serves up a new project. Hit F5 and we're debugging in Visual Studio."),(0,a.kt)("p",null,"So far, so straightforward. What will VS Code make of this?"),(0,a.kt)("p",null,'I cd my way to the root of my new ASP.Net Core Web Application and type the magical phrase "code .". Up it fires. I feel lucky, let\'s hit "F5". Huh, a dropdown shows up saying ',(0,a.kt)("inlineCode",{parentName:"p"},'"Select Environment"')," and offering me the options of Chrome and Node. Neither do I want. It's about this time I remember this is a clean install of VS Code and doesn't yet have the C# extension installed. In fact, if I open a C# file it up it tells me and recommends that I install. Well that's nice. I take it up on the kind offer; install and reload."),(0,a.kt)("p",null,'When it comes back up I see the following entries in the "output" tab:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"Updating C# dependencies...\nPlatform: win32, x86_64 (win7-x64)\n\nDownloading package 'OmniSharp (.NET 4.6 / x64)' (20447 KB) .................... Done!\nDownloading package '.NET Core Debugger (Windows / x64)' (39685 KB) .................... Done!\n\nInstalling package 'OmniSharp (.NET 4.6 / x64)'\nInstalling package '.NET Core Debugger (Windows / x64)'\n\nFinished\n")),(0,a.kt)("p",null,'Note that mention of "debugger" there? Sounds super-promising. There\'s also some prompts: ',(0,a.kt)("inlineCode",{parentName:"p"},"\"There are unresolved dependencies from 'WebApplication1/WebApplication1.csproj'. Please execute the restore command to continue\"")),(0,a.kt)("p",null,"So it wants me to ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet restore"),". It's even offering to do that for me! Have at you; I let it."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"Welcome to .NET Core!\n---------------------\nLearn more about .NET Core @ https://aka.ms/dotnet-docs. Use dotnet --help to see available commands or go to https://aka.ms/dotnet-cli-docs.\n\nTelemetry\n--------------\nThe .NET Core tools collect usage data in order to improve your experience. The data is anonymous and does not include command-line arguments. The data is collected by Microsoft and shared with the community.\nYou can opt out of telemetry by setting a DOTNET_CLI_TELEMETRY_OPTOUT environment variable to 1 using your favorite shell.\nYou can read more about .NET Core tools telemetry @ https://aka.ms/dotnet-cli-telemetry.\n\nConfiguring...\n-------------------\nA command is running to initially populate your local package cache, to improve restore speed and enable offline access. This command will take up to a minute to complete and will only happen once.\nDecompressing Decompressing 100% 4026 ms\nExpanding 100% 34814 ms\n  Restoring packages for c:\\Source\\Debugging\\WebApplication1\\WebApplication1\\WebApplication1.csproj...\n  Restoring packages for c:\\Source\\Debugging\\WebApplication1\\WebApplication1\\WebApplication1.csproj...\n  Restore completed in 734.05 ms for c:\\Source\\Debugging\\WebApplication1\\WebApplication1\\WebApplication1.csproj.\n  Generating MSBuild file c:\\Source\\Debugging\\WebApplication1\\WebApplication1\\obj\\WebApplication1.csproj.nuget.g.props.\n  Writing lock file to disk. Path: c:\\Source\\Debugging\\WebApplication1\\WebApplication1\\obj\\project.assets.json\n  Restore completed in 1.26 sec for c:\\Source\\Debugging\\WebApplication1\\WebApplication1\\WebApplication1.csproj.\n\n  NuGet Config files used:\n      C:\\Users\\johnr\\AppData\\Roaming\\NuGet\\NuGet.Config\n      C:\\Program Files (x86)\\NuGet\\Config\\Microsoft.VisualStudio.Offline.config\n\n  Feeds used:\n      https://api.nuget.org/v3/index.json\n      C:\\Program Files (x86)\\Microsoft SDKs\\NuGetPackages\\\nDone: 0.\n")),(0,a.kt)("p",null,"The other prompt says ",(0,a.kt)("inlineCode",{parentName:"p"},"\"Required assets to build and debug are missing from 'WebApplication1'. Add them?\""),". This also sounds very promising and I give it the nod. This creates a ",(0,a.kt)("inlineCode",{parentName:"p"},".vscode")," directory and 2 enclosed files; ",(0,a.kt)("inlineCode",{parentName:"p"},"launch.json")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"tasks.json"),"."),(0,a.kt)("p",null,"So lets try that F5 thing again... http://localhost:5000/ is now serving the same app. That looks pretty good. So lets add a breakpoint to the ",(0,a.kt)("inlineCode",{parentName:"p"},"HomeController")," and see if we can hit it:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(69904).Z,width:"640",height:"347"})),(0,a.kt)("p",null,"Well I can certainly add a breakpoint but all those red squigglies are unnerving me. Let's clean the slate. If you want to simply do that in VS Code hold down ",(0,a.kt)("inlineCode",{parentName:"p"},"CTRL+SHIFT+P"),' and then type "reload". Pick "Reload window". A couple of seconds later we\'re back in and Code is looking much happier. Can we hit our breakpoint?'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(12313).Z,width:"640",height:"347"})),(0,a.kt)("p",null,"Yes we can! So you're free to develop in either Code or VS; the choice is yours. I think that's pretty awesome - and well done to all the peeople behind Code who've made this a pretty seamless experience!"))}d.isMDXComponent=!0},59134:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"im-looking-for-work",title:"I'm looking for work!",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},s=void 0,l={permalink:"/im-looking-for-work",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-03-30-im-looking-for-work/index.md",source:"@site/blog/2017-03-30-im-looking-for-work/index.md",title:"I'm looking for work!",description:"My name is John Reilly. I'm a full stack developer based in London, UK. I'm just coming to the end of a contract (due to finish in April 2017) and I'm starting to look for my next role.",date:"2017-03-30T00:00:00.000Z",formattedDate:"March 30, 2017",tags:[],readingTime:2.505,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"im-looking-for-work",title:"I'm looking for work!",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},prevItem:{title:"Setting Build Version Using AppVeyor and ASP.Net Core",permalink:"/setting-build-version-using-appveyor"},nextItem:{title:"Debugging ASP.Net Core in VS or Code",permalink:"/debugging-aspnet-core-in-vs-or-code"}},p={authorsImageUrls:[void 0]},u=[{value:"Updated 25/04/2016: Position Filled",id:"updated-25042016-position-filled",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"My name is John Reilly. I'm a full stack developer based in London, UK. I'm just coming to the end of a contract (due to finish in April 2017) and I'm starting to look for my next role."),(0,a.kt)("p",null,"I have more than 15 years experience developing software commercially. I've worked in a number of industries including telecoms, advertising, technology (I worked at Microsoft for a time) and, of course, finance. The bulk of my experience is in the finance sector. I've provided consultancy services, building and maintaining applications for both large and small companies; from enterprise to startup."),(0,a.kt)("p",null,"My most recent work has been full stack web work; using React on the front end and SignalR (ASP.Net) on the back end. I'm pragmatic about the tools that I use to deliver software solutions and not tied to any particular technology. That said, I've gravitated towards the handiwork of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Anders_Hejlsberg"}),"Anders Hejlsberg"),"; starting out with Delphi and being both an early C# and TypeScript adopter. I've built everything from high volume trade feeds with no UI beyond a log file, WinForms apps for call centres, to fully fledged rich web applications with a heavy emphasis on UX."),(0,a.kt)("p",null,"I enjoy the challenges of understanding problems and coming up with useful solutions to them. I'm thrilled when something I've built makes someone's life easier. I love to learn and to share my knowledge; both in person and also through writing this blog. (This is the first time I've used a post to seek work.)"),(0,a.kt)("p",null,"In my spare time I'm involved with various open source projects including ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/typestrong/ts-loader"}),"ts-loader")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped"}),"DefinitelyTyped")," (",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/orgs/DefinitelyTyped/people"}),"member of the core team"),"). Get in contact with me if you're interested in learning more about me. Mail me at ",(0,a.kt)("a",o({parentName:"p"},{href:"mailto:johnny_reilly@hotmail.com"}),"johnny_reilly@hotmail.com")," and I can provide you with a CV. You can also find me on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly"}),"GitHub"),"."),(0,a.kt)("h2",o({},{id:"updated-25042016-position-filled"}),"Updated 25/04/2016: Position Filled"),(0,a.kt)("p",null,"I'm happy to say that I've lined up work for the next 6 months or so. Once again I'll be working in the financial services industry with one interesting twist. ",(0,a.kt)("a",o({parentName:"p"},{href:"/wpf-and-mystic-meg-or-playing"}),"In a blog post ages ago I bet that native apps would start to be replaced with SPAs.")," This has started to happen. I've started to see companies taking a \"web-first-and-only\" approach to building apps. In that vein, that's exactly what I'm off to build."),(0,a.kt)("p",null,"As a result of publishing this blog post I've had some interesting conversations with companies and got to think hard about the direction the industry is taking. I remain excited by JavaScript / TypeScript and React. I'm hopeful of the possibilities offered by the container world of Docker etc. I'm enjoying .NET Core and have very high hopes for it. I remain curious about Web Assembly."),(0,a.kt)("p",null,"Before I sign off, I know at some point I'll be looking for work once again. If there's a system you'd like built, if there's some mentoring and training you'd like done or if you'd just like to have a conversation I'm always available to talk. Drop me a line at ",(0,a.kt)("a",o({parentName:"p"},{href:"mailto:johnny_reilly@hotmail.com"}),"johnny_reilly@hotmail.com"),"."))}d.isMDXComponent=!0},54029:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"setting-build-version-using-appveyor",title:"Setting Build Version Using AppVeyor and ASP.Net Core",authors:"johnnyreilly",tags:["powershell","Version","dot net core","AppVeyor"],hide_table_of_contents:!1},s=void 0,l={permalink:"/setting-build-version-using-appveyor",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-04-25-setting-build-version-using-appveyor/index.md",source:"@site/blog/2017-04-25-setting-build-version-using-appveyor/index.md",title:"Setting Build Version Using AppVeyor and ASP.Net Core",description:"AppVeyor has support for setting the version of a binary during a build. However - this deals with the classic ASP.Net world of AssemblyInfo. I didn't find any reference to support for doing the same with dot net core. Remember, dot net core relies upon a &lt;Version&gt; or a &lt;VersionPrefix&gt; setting in the .csproj file. Personally, &lt;Version&gt; is my jam.",date:"2017-04-25T00:00:00.000Z",formattedDate:"April 25, 2017",tags:[{label:"powershell",permalink:"/tags/powershell"},{label:"Version",permalink:"/tags/version"},{label:"dot net core",permalink:"/tags/dot-net-core"},{label:"AppVeyor",permalink:"/tags/app-veyor"}],readingTime:1.03,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"setting-build-version-using-appveyor",title:"Setting Build Version Using AppVeyor and ASP.Net Core",authors:"johnnyreilly",tags:["powershell","Version","dot net core","AppVeyor"],hide_table_of_contents:!1},prevItem:{title:"TypeScript: Spare the Rod, Spoil the Code",permalink:"/typescript-spare-rod-spoil-code"},nextItem:{title:"I'm looking for work!",permalink:"/im-looking-for-work"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"AppVeyor has ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.appveyor.com/docs/build-configuration/#assemblyinfo-patching"}),"support for setting the version of a binary during a build"),". However - this deals with the classic ASP.Net world of ",(0,a.kt)("inlineCode",{parentName:"p"},"AssemblyInfo"),". I didn't find any reference to support for doing the same with dot net core. Remember, dot net core ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/articles/core/tools/project-json-to-csproj#version"}),"relies upon a ",(0,a.kt)("inlineCode",{parentName:"a"},"&lt;Version&gt;")," or a ",(0,a.kt)("inlineCode",{parentName:"a"},"&lt;VersionPrefix&gt;")," setting in the ",(0,a.kt)("inlineCode",{parentName:"a"},".csproj")," file"),". Personally, ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;Version&gt;")," is my jam."),(0,a.kt)("p",null,"However, coming up with your own bit of powershell that stamps the version during the build is a doddle; here we go:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),'Param($projectFile, $buildNum)\n\n$content = [IO.File]::ReadAllText($projectFile)\n\n$regex = new-object System.Text.RegularExpressions.Regex (\'(<version>)([\\d]+.[\\d]+.[\\d]+)(.[\\d]+)(<\\/Version>)\',\n         [System.Text.RegularExpressions.RegexOptions]::MultiLine)\n\n$version = $null\n$match = $regex.Match($content)\nif($match.Success) {\n    # from "<version>1.0.0.0</version>" this will extract "1.0.0"\n    $version = $match.groups[2].value\n}\n\n# suffix build number onto $version. eg "1.0.0.15"\n$version = "$version.$buildNum"\n\n# update "<version>1.0.0.0</version>" to "<version>$version</version>"\n$content = $regex.Replace($content, \'${1}\' + $version + \'${4}\')\n\n# update csproj file\n[IO.File]::WriteAllText($projectFile, $content)\n\n# update AppVeyor build\nUpdate-AppveyorBuild -Version $version\n</version>\n')),(0,a.kt)("p",null,"You can invoke this script as part of the build process in AppVeyor by adding something like this to your ",(0,a.kt)("inlineCode",{parentName:"p"},"appveyor.yml"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"before_build:\n  - ps: .\\ModifyVersion.ps1 $env:APPVEYOR_BUILD_FOLDER\\src\\Proverb.Web\\Proverb.Web.csproj $env:APPVEYOR_BUILD_NUMBER\n")),(0,a.kt)("p",null,"It will keep the first 3 parts of the version in your ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj"),' (eg "1.0.0") and suffix on the build number supplied by AppVeyor.'))}d.isMDXComponent=!0},2860:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-spare-rod-spoil-code",title:"TypeScript: Spare the Rod, Spoil the Code",authors:"johnnyreilly",tags:["tsconfig.json","typescript"],hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-spare-rod-spoil-code",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-05-20-typescript-spare-rod-spoil-code/index.md",source:"@site/blog/2017-05-20-typescript-spare-rod-spoil-code/index.md",title:"TypeScript: Spare the Rod, Spoil the Code",description:"I've recently started a new role. Perhaps unsurprisingly, part of the technology stack is TypeScript. A couple of days into the new codebase I found a bug. Well, I say I found a bug, TypeScript and VS Code found the bug - I just let everyone else know.",date:"2017-05-20T00:00:00.000Z",formattedDate:"May 20, 2017",tags:[{label:"tsconfig.json",permalink:"/tags/tsconfig-json"},{label:"typescript",permalink:"/tags/typescript"}],readingTime:2.08,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-spare-rod-spoil-code",title:"TypeScript: Spare the Rod, Spoil the Code",authors:"johnnyreilly",tags:["tsconfig.json","typescript"],hide_table_of_contents:!1},prevItem:{title:"Windows Defender Step Away From npm",permalink:"/windows-defender-step-away-from-npm"},nextItem:{title:"Setting Build Version Using AppVeyor and ASP.Net Core",permalink:"/setting-build-version-using-appveyor"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I've recently started a new role. Perhaps unsurprisingly, part of the technology stack is TypeScript. A couple of days into the new codebase I found a bug. Well, I say I found a bug, TypeScript and VS Code found the bug - I just let everyone else know."),(0,a.kt)("p",null,'The flexibility that TypeScript offers in terms of compiler settings is second to none. You can turn up the dial of strictness to your hearts content. Or down. I\'m an "up" man myself.'),(0,a.kt)("p",null,"The project that I am working on has the dial set fairly low; it's pretty much using the default compiler values which are (sensibly) not too strict. I have to say this makes sense for helping people get on board with using TypeScript. Start from a point of low strictness and turn it up when you're ready. As you might have guessed, I cranked the dial up on day one on my own machine. I should say that as I did this, I didn't foist this on the project at large - I kept it just to my build... I'm not ","*",(0,a.kt)("strong",{parentName:"p"},"that"),"*"," guy!"),(0,a.kt)("p",null,"I made the below changes to the ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," file. Details of what each of these settings does can be found in the documentation ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/docs/handbook/compiler-options.html"}),"here"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"noImplicitAny": true,\n    "noImplicitThis": true,\n    "noUnusedLocals": true,\n    "noImplicitReturns": true,\n    "noUnusedParameters": true,\n')),(0,a.kt)("p",null,"I said I found a bug. The nature of the bug was an unused variable; a variable was created in a function but then not used. Here's a super simple example:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"function sayHi(name: string) {\n  const greeting = `Hi ${name}`;\n  return name;\n}\n")),(0,a.kt)("p",null,"It's an easy mistake to make. I've made this mistake before myself. But with the ",(0,a.kt)("inlineCode",{parentName:"p"},"noUnusedLocals")," compiler setting in place it's now an easy mistake to catch; VS Code lets you know loud and clear:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(85941).Z,width:"400",height:"196"})),(0,a.kt)("p",null,"The other compiler settings will similarly highlight simple mistakes it's possible to make and I'd recommend using them. I should say I've written this from the perspective of a VS Code user, but this really applies generally to TypeScript usage. So whether you're an ",(0,a.kt)("a",o({parentName:"p"},{href:"http://alm.tools/"}),"alm.tools")," guy, a WebStorm gal or something else entirely then this too can be yours!"),(0,a.kt)("p",null,"I'd also say that the ",(0,a.kt)("inlineCode",{parentName:"p"},"strictNullChecks")," compiler setting is worth looking into. However, switching an already established project to using that can involve fairly extensive code changes and will also require a certain amount of education of, and buy in from, your team. So whilst I'd recommend it too, I'd save that one until last."))}d.isMDXComponent=!0},9136:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"windows-defender-step-away-from-npm",title:"Windows Defender Step Away From npm",authors:"johnnyreilly",tags:["VS Code","Windows","npm"],hide_table_of_contents:!1},s=void 0,l={permalink:"/windows-defender-step-away-from-npm",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-06-11-windows-defender-step-away-from-npm/index.md",source:"@site/blog/2017-06-11-windows-defender-step-away-from-npm/index.md",title:"Windows Defender Step Away From npm",description:"Updated 18/06/2017",date:"2017-06-11T00:00:00.000Z",formattedDate:"June 11, 2017",tags:[{label:"VS Code",permalink:"/tags/vs-code"},{label:"Windows",permalink:"/tags/windows"},{label:"npm",permalink:"/tags/npm"}],readingTime:1.685,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"windows-defender-step-away-from-npm",title:"Windows Defender Step Away From npm",authors:"johnnyreilly",tags:["VS Code","Windows","npm"],hide_table_of_contents:!1},prevItem:{title:"Dynamic import: I've been awaiting you...",permalink:"/dynamic-import-ive-been-await-ing-you"},nextItem:{title:"TypeScript: Spare the Rod, Spoil the Code",permalink:"/typescript-spare-rod-spoil-code"}},p={authorsImageUrls:[void 0]},u=[{value:"Updated 18/06/2017",id:"updated-18062017",level:2},{value:"Updated 12/07/2017",id:"updated-12072017",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"updated-18062017"}),"Updated 18/06/2017"),(0,a.kt)("p",null,"Whilst things did improve by fiddling with Windows Defender it wasn't a 100% fix which makes me wary. Interestingly, VS Code was always open when I did experience the issue and I haven't experienced it when it's been closed. So it may be the cause. I've opened ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/vscode/issues/28593"}),"an issue for this against the VS Code repo")," ","-"," it sounds like other people may be affected as I was. Perhaps this is VS Code and not Windows Defender. Watch that space..."),(0,a.kt)("h2",o({},{id:"updated-12072017"}),"Updated 12/07/2017"),(0,a.kt)("p",null,"The issue was VS Code. The bug has now been fixed and shipped last night with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://code.visualstudio.com/updates/v1_14"}),"VS Code 1.14.0"),". Yay!"),(0,a.kt)("hr",null),(0,a.kt)("p",null,"I've recently experienced many of my ",(0,a.kt)("inlineCode",{parentName:"p"},"npm install"),"s failing for no consistent reason. The error message would generally be something along the lines of:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-sh"}),"npm ERR! Error: EPERM: operation not permitted, rename 'C:\\dev\\training\\drrug\\node_modules\\.staging\\@exponent\\ngrok-fc327f2a' -> 'C:\\dev\\training\\drrug\\node_modules\\@exponent\\ngrok'\n")),(0,a.kt)("p",null,"I spent a good deal of time changing the versions of node and npm I was running; all seemingly to no avail. Regular flakiness which I ascribed to node / npm. I was starting to give up when I read of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/react-community/create-react-native-app/issues/191#issuecomment-304073970"}),"other people experiencing similar issues"),". Encouragingly ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/fmeira"}),"Fernando Meira")," suggested a solution:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"I got the same problem just doing an npm install. Run with antivirus disabled (if you use Windows Defender, turn off Real-Time protection and Cloud-based protection). That worked for me!")),(0,a.kt)("p",null,"I didn't really expect this to work - Windows Defender has been running in the background of my Windows 10 laptop since I've had it. There's been no problems with npm installs up until a week or so ago. But given the experience I and others have had I thought I should put it out there: it looks like Windows Defender has it in for npm. Go figure."),(0,a.kt)("p",null,"Alas Windows Defender doesn't stay dead for long; it's like a zombie that rises from the grave no matter how many times you kill it. So you might want to try configuring it to ignore node.exe:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(85968).Z,width:"445",height:"640"})),(0,a.kt)("p",null,"Or switching to Linux..."))}d.isMDXComponent=!0},31949:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"dynamic-import-ive-been-await-ing-you",title:"Dynamic import: I've been awaiting you...",authors:"johnnyreilly",tags:["typescript","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/dynamic-import-ive-been-await-ing-you",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-07-02-dynamic-import-ive-been-await-ing-you/index.md",source:"@site/blog/2017-07-02-dynamic-import-ive-been-await-ing-you/index.md",title:"Dynamic import: I've been awaiting you...",description:"One of the most exciting features to ship with TypeScript 2.4 was support for the dynamic import expression. To quote the release blog post:",date:"2017-07-02T00:00:00.000Z",formattedDate:"July 2, 2017",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:5.075,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"dynamic-import-ive-been-await-ing-you",title:"Dynamic import: I've been awaiting you...",authors:"johnnyreilly",tags:["typescript","webpack"],hide_table_of_contents:!1},prevItem:{title:"A Haiku on the Problem with SemVer: Us",permalink:"/a-haiku-on-problem-with-semver-us"},nextItem:{title:"Windows Defender Step Away From npm",permalink:"/windows-defender-step-away-from-npm"}},p={authorsImageUrls:[void 0]},u=[{value:"TypeScript Setup",id:"typescript-setup",level:2},{value:"Babel Setup",id:"babel-setup",level:2},{value:"webpack",id:"webpack",level:2},{value:"ts-loader example",id:"ts-loader-example",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"One of the most exciting features to ship with TypeScript 2.4 was support for the dynamic import expression. To quote the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.microsoft.com/typescript/2017/06/27/announcing-typescript-2-4/#dynamic-import-expressions"}),"release blog post"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Dynamic ",(0,a.kt)("inlineCode",{parentName:"p"},"import")," expressions are a new feature in ECMAScript that allows you to asynchronously request a module at any arbitrary point in your program. These modules come back as ",(0,a.kt)("inlineCode",{parentName:"p"},"Promise"),"s of the module itself, and can be ",(0,a.kt)("inlineCode",{parentName:"p"},"await"),"-","ed in an async function, or can be given a callback with ",(0,a.kt)("inlineCode",{parentName:"p"},".then"),"."),(0,a.kt)("p",{parentName:"blockquote"},"..."),(0,a.kt)("p",{parentName:"blockquote"},"Many bundlers have support for automatically splitting output bundles (a.k.a. \u201ccode splitting\u201d) based on these ",(0,a.kt)("inlineCode",{parentName:"p"},"import()")," expressions, so consider using this new feature with the ",(0,a.kt)("inlineCode",{parentName:"p"},"esnext")," module target. Note that this feature won\u2019t work with the ",(0,a.kt)("inlineCode",{parentName:"p"},"es2015")," module target, since the feature is anticipated for ES2018 or later.")),(0,a.kt)("p",null,"As the post makes clear, this adds support for a very bleeding edge ECMAScript feature. This is not fully standardised yet; it's currently at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/tc39/proposals"}),"stage 3")," on the TC39 proposals list. That means it's at the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://tc39.github.io/process-document/"}),"Candidate")," stage and is unlikely to change further. If you'd like to read more about it then take a look at the official proposal ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/tc39/proposal-dynamic-import"}),"here"),"."),(0,a.kt)("p",null,"Whilst this is super-new, we are still able to use this feature. We just have to jump through a few hoops first."),(0,a.kt)("h2",o({},{id:"typescript-setup"}),"TypeScript Setup"),(0,a.kt)("p",null,"First of all, you need to install TypeScript 2.4. With that in place you need to make some adjustments to your ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," in order that the relevant compiler switches are flipped. What do you need? First of all you need to be targeting ECMAScript 2015 as a minimum. That's important specifically because ES2015 contained ",(0,a.kt)("inlineCode",{parentName:"p"},"Promise"),"s which is what dynamic ",(0,a.kt)("inlineCode",{parentName:"p"},"import"),"s produce. The second thing you need is to target the module type of ",(0,a.kt)("inlineCode",{parentName:"p"},"esnext"),". You're likely targeting ",(0,a.kt)("inlineCode",{parentName:"p"},"es2015")," now, ",(0,a.kt)("inlineCode",{parentName:"p"},"esnext")," is that ",(0,a.kt)("strong",{parentName:"p"},"plus")," dynamic ",(0,a.kt)("inlineCode",{parentName:"p"},"import"),"s."),(0,a.kt)("p",null,"Here's a ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," I made earlier which has the relevant settings set:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "compilerOptions": {\n    "allowSyntheticDefaultImports": true,\n    "lib": ["dom", "es2015"],\n    "target": "es2015",\n    "module": "esnext",\n    "moduleResolution": "node",\n    "noImplicitAny": true,\n    "noUnusedLocals": true,\n    "noUnusedParameters": true,\n    "removeComments": false,\n    "preserveConstEnums": true,\n    "sourceMap": true,\n    "skipLibCheck": true\n  }\n}\n')),(0,a.kt)("h2",o({},{id:"babel-setup"}),"Babel Setup"),(0,a.kt)("p",null,"At the time of writing, browser support for dynamic ",(0,a.kt)("inlineCode",{parentName:"p"},"import")," is non-existent. This will likely be the case for some time but it needn't hold us back. Babel can step in here and compile our super-new JS into JS that will run in our browsers today."),(0,a.kt)("p",null,"You'll need to decide for yourself how much you want Babel to do for you. In my case I'm targeting old school browsers which don't yet support ES2015. You may not need to. However, the one thing that you'll certainly need is the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://babeljs.io/docs/plugins/syntax-dynamic-import/"}),"Syntax Dynamic Import")," plugin. It's this that allows Babel to process dynamic ",(0,a.kt)("inlineCode",{parentName:"p"},"import")," statements."),(0,a.kt)("p",null,"These are the options I'm passing to Babel:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var babelOptions = {\n  plugins: ['syntax-dynamic-import'],\n  presets: [\n    [\n      'es2015',\n      {\n        modules: false,\n      },\n    ],\n  ],\n};\n")),(0,a.kt)("p",null,"You're also going to need something that actually execute the ",(0,a.kt)("inlineCode",{parentName:"p"},"import"),"s. In my case I'm using webpack..."),(0,a.kt)("h2",o({},{id:"webpack"}),"webpack"),(0,a.kt)("p",null,"webpack 2 supports ",(0,a.kt)("a",o({parentName:"p"},{href:"https://webpack.js.org/api/module-methods/#import-"}),(0,a.kt)("inlineCode",{parentName:"a"},"import()")),". So if you webpack set up with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader"}),"ts-loader")," (or awesome-typescript-loader etc), chaining into ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/babel/babel-loader"}),"babel-loader")," you should find you have a setup that supports dynamic ",(0,a.kt)("inlineCode",{parentName:"p"},"import"),". That means a ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js")," that looks something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var path = require('path');\nvar webpack = require('webpack');\n\nvar babelOptions = {\n  plugins: ['syntax-dynamic-import'],\n  presets: [\n    [\n      'es2015',\n      {\n        modules: false,\n      },\n    ],\n  ],\n};\n\nmodule.exports = {\n  entry: './app.ts',\n  output: {\n    filename: 'bundle.js',\n  },\n  module: {\n    rules: [\n      {\n        test: /\\.ts(x?)$/,\n        exclude: /node_modules/,\n        use: [\n          {\n            loader: 'babel-loader',\n            options: babelOptions,\n          },\n          {\n            loader: 'ts-loader',\n          },\n        ],\n      },\n      {\n        test: /\\.js$/,\n        exclude: /node_modules/,\n        use: [\n          {\n            loader: 'babel-loader',\n            options: babelOptions,\n          },\n        ],\n      },\n    ],\n  },\n  resolve: {\n    extensions: ['.ts', '.tsx', '.js'],\n  },\n};\n")),(0,a.kt)("h2",o({},{id:"ts-loader-example"}),"ts-loader example"),(0,a.kt)("p",null,"I'm one of the maintainers of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader"}),"ts-loader")," which is a TypeScript loader for webpack. When support for dynamic ",(0,a.kt)("inlineCode",{parentName:"p"},"import"),"s landed I wanted to add a test to cover usage of the new syntax with ts-loader."),(0,a.kt)("p",null,'We have 2 test packs for ts-loader, one of which is our "execution" test pack. It is so named because it works by spinning up webpack with ts-loader and then using ',(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/karma-runner/karma"}),"karma"),' to execute a set of tests. Each "test" in our execution test pack is actually a mini-project with its own test suite (generally ',(0,a.kt)("a",o({parentName:"p"},{href:"https://jasmine.github.io/"}),"jasmine")," but that's entirely configurabe). Each complete with its own ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"karma.conf.js")," and either a ",(0,a.kt)("inlineCode",{parentName:"p"},"typings.json")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," for bringing in dependencies. So it's a full test of whether code slung with ts-loader and webpack actually executes when the output is plugged into a browser."),(0,a.kt)("p",null,"This is the test pack for dynamic ",(0,a.kt)("inlineCode",{parentName:"p"},"import"),"s:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),'import a from "../src/a";\nimport b from "../src/b";\n\ndescribe("app", () => {\n  it("a to be \'a\' and b to be \'b\' (classic)", () => {\n    expect(a).toBe("a");\n    expect(b).toBe("b");\n  });\n\n  it("import results in a module with a default export", done => {\n    import("../src/c").then(c => {\n      // .default is the default export\n      expect(c.default).toBe("c");\n\n      done();\n    }\n  });\n\n  it("import results in a module with an export", done => {\n    import("../src/d").then(d => {\n      // .default is the default export\n      expect(d.d).toBe("d");\n\n      done();\n    }\n  });\n\n  it("await import results in a module with a default export", async done => {\n    const c = await import("../src/c");\n\n    // .default is the default export\n    expect(c.default).toBe("c");\n\n    done();\n  });\n\n  it("await import results in a module with an export", async done => {\n    const d = await import("../src/d");\n\n    expect(d.d).toBe("d");\n\n    done();\n  });\n});\n')),(0,a.kt)("p",null,"As you can see, it's possible to use the dynamic ",(0,a.kt)("inlineCode",{parentName:"p"},"import")," as a ",(0,a.kt)("inlineCode",{parentName:"p"},"Promise")," directly. Alternatively, it's possible to consume the imported module using TypeScripts support for ",(0,a.kt)("inlineCode",{parentName:"p"},"async")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"await"),". For my money the latter option makes for much clearer code."),(0,a.kt)("p",null,"If you're looking for a complete example of how to use the new syntax then you could do worse than taking the existing test pack and tweaking it to your own ends. The only change you'd need to make is to strip out the ",(0,a.kt)("inlineCode",{parentName:"p"},"resolveLoader")," statements in ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"karma.conf.js"),". (They exist to lock the test in case to the freshly built ts-loader stored locally. You'll not need this.)"),(0,a.kt)("p",null,"You can find the test in question ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/tree/master/test/execution-tests/2.4.1_babel-importCodeSplitting"}),"here"),". Happy code splitting!"))}d.isMDXComponent=!0},85962:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"a-haiku-on-problem-with-semver-us",title:"A Haiku on the Problem with SemVer: Us",authors:"johnnyreilly",tags:["semantic versioning"],hide_table_of_contents:!1},s=void 0,l={permalink:"/a-haiku-on-problem-with-semver-us",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-07-29-a-haiku-on-problem-with-semver-us/index.md",source:"@site/blog/2017-07-29-a-haiku-on-problem-with-semver-us/index.md",title:"A Haiku on the Problem with SemVer: Us",description:"Version numbers wrong",date:"2017-07-29T00:00:00.000Z",formattedDate:"July 29, 2017",tags:[{label:"semantic versioning",permalink:"/tags/semantic-versioning"}],readingTime:.06,hasTruncateMarker:!1,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"a-haiku-on-problem-with-semver-us",title:"A Haiku on the Problem with SemVer: Us",authors:"johnnyreilly",tags:["semantic versioning"],hide_table_of_contents:!1},prevItem:{title:"Karma: From PhantomJS to Headless Chrome",permalink:"/karma-from-phantomjs-to-headless-chrome"},nextItem:{title:"Dynamic import: I've been awaiting you...",permalink:"/dynamic-import-ive-been-await-ing-you"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Version numbers wrong\nWe release breaking changes\nWe don't know we do"))}d.isMDXComponent=!0},32512:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"karma-from-phantomjs-to-headless-chrome",title:"Karma: From PhantomJS to Headless Chrome",authors:"johnnyreilly",tags:["Chrome","Karma","PhantomJS"],hide_table_of_contents:!1},s=void 0,l={permalink:"/karma-from-phantomjs-to-headless-chrome",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-08-27-karma-from-phantomjs-to-headless-chrome/index.md",source:"@site/blog/2017-08-27-karma-from-phantomjs-to-headless-chrome/index.md",title:"Karma: From PhantomJS to Headless Chrome",description:"Like pretty much everyone else I've been using PhantomJS to run my JavaScript (or compiled-to-JS) unit tests. It's been great. So when I heard the news that PhantomJS was dead I was genuinely sad. However, the King is dead.... Long live the King! For there is a new hope; it's called Chrome Headless . It's not a separate version of Chrome; rather the ability to run Chrome without a UI is now baked into Google's favourite browser as of v59. (For those history buffs I might as well be clear: the main reason PhantomJS died is because Chrome Headless was in the works.)",date:"2017-08-27T00:00:00.000Z",formattedDate:"August 27, 2017",tags:[{label:"Chrome",permalink:"/tags/chrome"},{label:"Karma",permalink:"/tags/karma"},{label:"PhantomJS",permalink:"/tags/phantom-js"}],readingTime:1.91,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"karma-from-phantomjs-to-headless-chrome",title:"Karma: From PhantomJS to Headless Chrome",authors:"johnnyreilly",tags:["Chrome","Karma","PhantomJS"],hide_table_of_contents:!1},prevItem:{title:"Oh the Glamour of Open Source",permalink:"/oh-glamour-of-open-source"},nextItem:{title:"A Haiku on the Problem with SemVer: Us",permalink:"/a-haiku-on-problem-with-semver-us"}},p={authorsImageUrls:[void 0]},u=[{value:"Making the Switch",id:"making-the-switch",level:2},{value:"<code>package.json</code>",id:"packagejson",level:2},{value:"<code>karma.conf.js</code>",id:"karmaconfjs",level:2},{value:"Continuous Integration",id:"continuous-integration",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Like pretty much everyone else I've been using PhantomJS to run my JavaScript (or compiled-to-JS) unit tests. It's been great. So when I heard the news that ",(0,a.kt)("a",o({parentName:"p"},{href:"https://news.ycombinator.com/item?id=14105489"}),"PhantomJS was dead")," I was genuinely sad. However, the King is dead.... Long live the King! For there is a new hope; it's called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/web/updates/2017/04/headless-chrome"}),"Chrome Headless "),". It's not a separate version of Chrome; rather the ability to run Chrome without a UI is now baked into Google's favourite browser as of v59. (For those history buffs I might as well be clear: the main reason PhantomJS died is because Chrome Headless was in the works.)"),(0,a.kt)("h2",o({},{id:"making-the-switch"}),"Making the Switch"),(0,a.kt)("p",null,"As long as you're running Chrome v59 or greater then you can switch. I've just made ts-loader's execution test pack run with Chrome Headless instead of PhantomJS and I've rarely been happier. Honest. Some context: the execution test pack runs Jasmine unit tests via the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://karma-runner.github.io/1.0/index.html"}),"Karma test runner"),". The move was surprisingly easy and you can see just how minimal it was in the PR ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/611/files"}),"here"),". If you want to migrate a test that runs tests via Karma then this will take you through what you need to do."),(0,a.kt)("h2",o({},{id:"packagejson"}),(0,a.kt)("inlineCode",{parentName:"h2"},"package.json")),(0,a.kt)("p",null,"You no longer need ",(0,a.kt)("inlineCode",{parentName:"p"},"phantomjs-prebuilt")," as a dev dependency of your project. That's the PhantomJS browser disappearing in the rear view mirror. Next we need to replace ",(0,a.kt)("inlineCode",{parentName:"p"},"karma-phantomjs-launcher")," with ",(0,a.kt)("inlineCode",{parentName:"p"},"karma-chrome-launcher"),". These packages are responsible for firing up the browser that the tests are run in and we no longer want to invoke PhantomJS; we're Chrome all the way baby."),(0,a.kt)("h2",o({},{id:"karmaconfjs"}),(0,a.kt)("inlineCode",{parentName:"h2"},"karma.conf.js")),(0,a.kt)("p",null,"You need to tell Karma to use Chrome Headless instead of PhantomJS. You do that by replacing"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"browsers: [ 'PhantomJS' ],\n")),(0,a.kt)("p",null,"with"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"browsers: [ 'ChromeHeadless' ],\n")),(0,a.kt)("p",null,"That's it; job done!"),(0,a.kt)("h2",o({},{id:"continuous-integration"}),"Continuous Integration"),(0,a.kt)("p",null,"There's always one more thing isn't there? Yup, ts-loader has CI builds that run on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://ci.appveyor.com/project/JohnReilly/ts-loader/branch/master"}),"Windows with AppVeyor")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://travis-ci.org/TypeStrong/ts-loader"}),"Linux with Travis"),". The AppVeyor build went green on the first run; that's because Chrome is installed by default in the AppVeyor build environment. (yay!)"),(0,a.kt)("p",null,"Travis went red. (boooo!) Travis doesn't have Chrome installed by default. But it's no biggie; you just need to tweak your ",(0,a.kt)("inlineCode",{parentName:"p"},".travis.yml")," like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"dist: trusty\naddons:\n  chrome: stable\n")),(0,a.kt)("p",null,"This includes Chrome in the Travis build environment. Green. Boom!"))}d.isMDXComponent=!0},54314:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"oh-glamour-of-open-source",title:"Oh the Glamour of Open Source",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},s=void 0,l={permalink:"/oh-glamour-of-open-source",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-08-30-oh-glamour-of-open-source/index.md",source:"@site/blog/2017-08-30-oh-glamour-of-open-source/index.md",title:"Oh the Glamour of Open Source",description:"Here's how my life panned out in the early hours of Wednesday 30th September 2017:",date:"2017-08-30T00:00:00.000Z",formattedDate:"August 30, 2017",tags:[],readingTime:1.21,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"oh-glamour-of-open-source",title:"Oh the Glamour of Open Source",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},prevItem:{title:"TypeScript + Webpack: Super Pursuit Mode",permalink:"/typescript-webpack-super-pursuit-mode"},nextItem:{title:"Karma: From PhantomJS to Headless Chrome",permalink:"/karma-from-phantomjs-to-headless-chrome"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Here's how my life panned out in the early hours of Wednesday 30th September 2017:"),(0,a.kt)("dl",null,(0,a.kt)("dt",null,"2 am"),(0,a.kt)("dd",null,"awoken by Lisette having a nightmare"),(0,a.kt)("dt",null,"3 am"),(0,a.kt)("dd",null,"gave up hope of getting back to sleep upstairs and headed for the sofa"),(0,a.kt)("dt",null,"4 am"),(0,a.kt)("dd",null,"still not asleep and discovered a serious gap in an open source project I help out with"),(0,a.kt)("dt",null,"4:30 am"),(0,a.kt)("dd",null," come up with idea for a fix"),(0,a.kt)("dt",null,"4:45 am"),(0,a.kt)("dd",null," accidentally delete a repo that I and many others care about from GitHub"),(0,a.kt)("dt",null,"4:50 am"),(0,a.kt)("dd",null," recover said repo from backups (sweet mercy how could I be so stupid?)"),(0,a.kt)("dt",null,"4:55 am"),(0,a.kt)("dd",null," actually succeed in cloning the repo I want to hack on "),(0,a.kt)("dt",null,"5:30 am"),(0,a.kt)("dd",null," implement fix and ",(0,a.kt)("a",{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin/pull/43"},"send PR")),(0,a.kt)("dt",null,"5:35 am"),(0,a.kt)("dd",null," go for a walk round the river"),(0,a.kt)("dt",null,"6:30 am"),(0,a.kt)("dd",null," realise I didn't submit a test for the changed functionality"),(0,a.kt)("dt",null,"6:35 am"),(0,a.kt)("dd",null," write test only to discover I can't run the test pack on Windows"),(0,a.kt)("dt",null,"6:40 am"),(0,a.kt)("dd",null," add test to PR anyway so I can see test results when Travis runs on each commit."),(0,a.kt)("dt",null,"7 am"),(0,a.kt)("dd",null,"despair at the duration of my feedback loop, totally fail to get my tests to pass"),(0,a.kt)("dt",null,"7:10 am"),(0,a.kt)("dd",null," stub my toe really badly on a train set Benjamin has been busily assembling beneath my feet"),(0,a.kt)("dt",null,"7:11 am"),(0,a.kt)("dd",null," give in and literally beg the project owner in Paris to fix the tests for me. He takes pity on me and agrees. Possibly because I gave him emoji tulips \ud83c\udf37"),(0,a.kt)("dt",null,"7:12 am"),(0,a.kt)("dd",null," feel like a slight failure and profoundly tired.")),(0,a.kt)("p",null,"Oh the glamour of open source."))}d.isMDXComponent=!0},23082:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-webpack-super-pursuit-mode",title:"TypeScript + Webpack: Super Pursuit Mode",authors:"johnnyreilly",tags:["typescript","fork-ts-checker-webpack-plugin","Webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-webpack-super-pursuit-mode",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-09-07-typescript-webpack-super-pursuit-mode/index.md",source:"@site/blog/2017-09-07-typescript-webpack-super-pursuit-mode/index.md",title:"TypeScript + Webpack: Super Pursuit Mode",description:"This post also featured as a webpack Medium publication.",date:"2017-09-07T00:00:00.000Z",formattedDate:"September 7, 2017",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"fork-ts-checker-webpack-plugin",permalink:"/tags/fork-ts-checker-webpack-plugin"},{label:"Webpack",permalink:"/tags/webpack"}],readingTime:6.665,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-webpack-super-pursuit-mode",title:"TypeScript + Webpack: Super Pursuit Mode",authors:"johnnyreilly",tags:["typescript","fork-ts-checker-webpack-plugin","Webpack"],hide_table_of_contents:!1},prevItem:{title:"fork-ts-checker-webpack-plugin code clickability",permalink:"/fork-ts-checker-webpack-plugin-code"},nextItem:{title:"Oh the Glamour of Open Source",permalink:"/oh-glamour-of-open-source"}},p={authorsImageUrls:[void 0]},u=[{value:"fork-ts-checker-webpack-plugin",id:"fork-ts-checker-webpack-plugin",level:2},{value:"HappyPack",id:"happypack",level:2},{value:"<code>thread-loader</code> + <code>cache-loader</code>",id:"thread-loader--cache-loader",level:2},{value:"All This Could Be Yours...",id:"all-this-could-be-yours",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("em",{parentName:"p"},(0,a.kt)("a",o({parentName:"em"},{href:"https://medium.com/webpack/typescript-webpack-super-pursuit-mode-83cc568dea79"}),"This post also featured as a webpack Medium publication"),".")),(0,a.kt)("p",null,"If you're like me then you'll like TypeScript and you'll like module bundling with webpack. You may also like speedy builds. That's completely understandable. The fact of the matter is, you sacrifice a bit of build speed to have webpack in the mix. Wouldn't it be great if we could even up the difference?"),(0,a.kt)("p",null,"I'm the primary maintainer of ts-loader, a TypeScript loader for webpack. Just recently a couple of PRs were submitted that said, in other words: ts-loader is like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(71794).Z,width:"400",height:"233"})),(0,a.kt)("p",null,"But it could be like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(6494).Z,width:"400",height:"225"})),(0,a.kt)("p",null,"Apologies for the image quality above; there appear to be no high quality pictures out there of KITT in Super Pursuit Mode for me to defame with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/plemont"}),"Garan Jenkin"),"'s atrocious puns."),(0,a.kt)("h2",o({},{id:"fork-ts-checker-webpack-plugin"}),"fork-ts-checker-webpack-plugin"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/issues/537"}),'"Faster type checking with forked process"')," read the enticing name of the issue. It turned out to be ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/piotr-oles"}),"Piotr Ole\u015b")," (",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/OlesDev"}),"@OlesDev"),") telling the world about his beautiful creation. He'd put together a mighty fine plugin that can be used alongside ts-loader called the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin"}),"fork-ts-checker-webpack-plugin"),". The name is a bit of a mouthful but the purpose is mouth-watering. To quote the README, it is a:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Webpack plugin that runs typescript type checker on a separate process.")),(0,a.kt)("p",null,"What does this mean and how does this fit with ts-loader? Well, ts-loader does 2 jobs:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"It transpiles your TypeScript into JavaScript and hands it off to webpack"),(0,a.kt)("li",{parentName:"ol"},"It collects any TypeScript compilation errors and reports them to webpack")),(0,a.kt)("p",null,'What this plugin does is say, "forget about #2 - we\'ve got this." It removes the responsibility for type checking from ts-loader, so the only work ts-loader does is transpilation. In the meantime, the all important type checking is still happening. To be honest, there would be little reason to recommend this approach otherwise. The difference is ',(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin")," is doing the heavy lifting ",(0,a.kt)("strong",{parentName:"p"},"in a separate process"),". This provides a nice performance boost to your workflow. ts-loader is doing ",(0,a.kt)("strong",{parentName:"p"},"less")," and that's a ",(0,a.kt)("u",null,"good thing")),(0,a.kt)("p",null,"."),(0,a.kt)("p",null,"The approach used here is similar to that employed by awesome-typescript-loader. ATL is another TypeScript loader for webpack by the excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/s-panferov"}),"Stanislav Panferov"),". ATL also has a technique for performing typechecking in a forked process. fork-ts-checker-webpack-plugin was an effort by Piotr to implement something similar but with improved incremental build performance."),(0,a.kt)("p",null,"How do we use it? Add fork-ts-checker-webpack-plugin as a ",(0,a.kt)("inlineCode",{parentName:"p"},"devDependency")," of your project and then amend the ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js")," to set ts-loader into ",(0,a.kt)("inlineCode",{parentName:"p"},"transpileOnly")," mode and drop the plugin into the mix:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var ForkTsCheckerWebpackPlugin = require('fork-ts-checker-webpack-plugin');\n\nvar webpackConfig = {\n  // other config...\n  context: __dirname, // to automatically find tsconfig.json\n  module: {\n    rules: [\n      {\n        test: /\\.tsx?$/,\n        loader: 'ts-loader',\n        options: {\n          // disable type checker - we will use it in fork plugin\n          transpileOnly: true,\n        },\n      },\n    ],\n  },\n  plugins: [new ForkTsCheckerWebpackPlugin()],\n};\n")),(0,a.kt)("p",null,"If you'd like to see an example of how to use the plugin then take a look at a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/tree/master/examples/fork-ts-checker"}),"simple example")," and a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/tree/master/examples/react-babel-karma-gulp-fork-ts-checker"}),"more involved one"),"."),(0,a.kt)("h2",o({},{id:"happypack"}),"HappyPack"),(0,a.kt)("p",null,"Not so long ago I didn't know what ",(0,a.kt)("strike",null,"happyness")),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/amireh/happypack"}),"HappyPack"),' was. "Happiness in the form of faster webpack build times." That\'s what it is.'),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"HappyPack makes webpack builds faster by allowing you to transform multiple files in parallel.")),(0,a.kt)("p",null,"It does this by spinning up multiple threads, each with their own loaders inside. We wanted to do this with ts-loader; to have multiple instances of ts-loader running. Work can then be divided up across these separate loaders. Isn't multi-threading great?"),(0,a.kt)("p",null,"ts-loader did not initially play nicely with HappyPack; essentially this is because ts-loader touches parts of webpack's API that HappyPack replaces. The entirely wonderful ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/aindlq"}),"Artem Kozlov")," submitted a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/547"}),"PR which added HappyPack support to ts-loader"),". Support essentially amounts to switching ts-loader to run in ",(0,a.kt)("inlineCode",{parentName:"p"},"transpileOnly")," mode and ensuring that there is no attempt to talk to parts of the webpack API that HappyPack removes."),(0,a.kt)("p",null,"It would be hard to recommend using HappyPack as is because, as with ",(0,a.kt)("inlineCode",{parentName:"p"},"transpileOnly")," mode you lose all typechecking. Where it becomes worthwhile is where it is combined with the fork-ts-checker-webpack-plugin so you keep the typechecking."),(0,a.kt)("p",null,"Enough with the chitter chatter; how can we achieve this? Add HappyPack as a ",(0,a.kt)("inlineCode",{parentName:"p"},"devDependency")," of your project and then amend the ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js")," as follows:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var HappyPack = require('happypack');\nvar ForkTsCheckerWebpackPlugin = require('fork-ts-checker-webpack-plugin');\n\nmodule.exports = {\n  // other config...\n  context: __dirname, // to automatically find tsconfig.json\n  module: {\n    rules: [\n      {\n        test: /\\.tsx?$/,\n        exclude: /node_modules/,\n        loader: 'happypack/loader?id=ts',\n      },\n    ],\n  },\n  plugins: [\n    new HappyPack({\n      id: 'ts',\n      threads: 2,\n      loaders: [\n        {\n          path: 'ts-loader',\n          query: { happyPackMode: true },\n        },\n      ],\n    }),\n    new ForkTsCheckerWebpackPlugin({ checkSyntacticErrors: true }),\n  ],\n};\n")),(0,a.kt)("p",null,"Note that the ts-loader options are now configured via the HappyPack ",(0,a.kt)("inlineCode",{parentName:"p"},"query")," and that we're setting ts-loader with the ",(0,a.kt)("inlineCode",{parentName:"p"},"happyPackMode")," option set."),(0,a.kt)("p",null,"There's one other thing to note which is important; we're now passing the ",(0,a.kt)("inlineCode",{parentName:"p"},"checkSyntacticErrors")," option to the fork plugin. This ensures that the plugin checks for both syntactic errors (eg ",(0,a.kt)("inlineCode",{parentName:"p"},"const array = [{} {}];"),") and semantic errors (eg ",(0,a.kt)("inlineCode",{parentName:"p"},"const x: number = '1';"),"). By default the plugin only checks for semantic errors. This is because when ts-loader is used with ",(0,a.kt)("inlineCode",{parentName:"p"},"transpileOnly")," set, ts-loader will still report syntactic errors. But when used in ",(0,a.kt)("inlineCode",{parentName:"p"},"happyPackMode")," it does not."),(0,a.kt)("p",null,"If you'd like to see an example of how to use HappyPack then once again we have a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/tree/master/examples/happypack"}),"simple example")," and a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/tree/master/examples/react-babel-karma-gulp-happypack"}),"more involved one"),"."),(0,a.kt)("h2",o({},{id:"thread-loader--cache-loader"}),(0,a.kt)("inlineCode",{parentName:"h2"},"thread-loader")," ","+"," ",(0,a.kt)("inlineCode",{parentName:"h2"},"cache-loader")),(0,a.kt)("p",null,"You might have some reservations about using HappyPack. First of all the quirky configuration required makes your webpack config rather less comprehensible. Also, HappyPack is not officially blessed by webpack. It is a side project developed externally from webpack and there's no guarantees that new versions of webpack won't break it. Neither of these are reasons not to use HappyPack but they are things to bear in mind."),(0,a.kt)("p",null,"What if there were a way to parallelise our builds which dealt with these issues? Well, there is! By using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack-contrib/thread-loader"}),"thread-loader")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack-contrib/cache-loader"}),"cache-loader")," in combination you can both feel happy that you're using an official webpack workflow and you can have a config that's less confusing."),(0,a.kt)("p",null,"What would that config look like? This:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var ForkTsCheckerWebpackPlugin = require('fork-ts-checker-webpack-plugin');\n\nmodule.exports = {\n  // other config...\n  context: __dirname, // to automatically find tsconfig.json\n  module: {\n    rules: {\n      test: /\\.tsx?$/,\n      use: [\n        { loader: 'cache-loader' },\n        {\n          loader: 'thread-loader',\n          options: {\n            // there should be 1 cpu for the fork-ts-checker-webpack-plugin\n            workers: require('os').cpus().length - 1,\n          },\n        },\n        {\n          loader: 'ts-loader',\n          options: {\n            happyPackMode: true, // IMPORTANT! use happyPackMode mode to speed-up compilation and reduce errors reported to webpack\n          },\n        },\n      ],\n    },\n  },\n  plugins: [new ForkTsCheckerWebpackPlugin({ checkSyntacticErrors: true })],\n};\n")),(0,a.kt)("p",null,'As you can see the configuration is much cleaner than with HappyPack. Interestingly ts-loader still needs to run in "',(0,a.kt)("inlineCode",{parentName:"p"},"happyPackMode"),'" and that\'s because thread-loader is essentially behaving in the same fashion as with HappyPack and so ts-loader needs to behave in the same way. Probably ts-loader should have a more generic flag name than "',(0,a.kt)("inlineCode",{parentName:"p"},"happyPackMode"),"\". (Famously, naming things is hard; so if you've a good idea, tell me!)"),(0,a.kt)("p",null,"These loaders are new and so tread carefully. My own experiences have been pretty positive but your mileage may vary. Do note that, as with HappyPack, the thread-loader is highly configurable."),(0,a.kt)("p",null,"If you'd like to see an example of how to use thread-loader and cache-loader then once again we have a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/tree/master/examples/thread-loader"}),"simple example")," and a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/tree/master/examples/react-babel-karma-gulp-thread-loader"}),"more involved one"),"."),(0,a.kt)("h2",o({},{id:"all-this-could-be-yours"}),"All This Could Be Yours..."),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Wow! It looks like we can cut our build time by 4 minutes! ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/hashtag/webpack?src=hash"}),"#","webpack"),(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/typescriptlang"}),"@typescriptlang")," // cc ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/johnny_reilly"}),"@johnny_reilly"),(0,a.kt)("a",o({parentName:"p"},{href:"https://t.co/gjvy9SLBAT"}),"pic.twitter.com/gjvy9SLBAT")),(0,a.kt)("p",{parentName:"blockquote"},"\u2014 Donald Pipowitch (@PipoPeperoni) ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/PipoPeperoni/status/878148978356834304"}),"June 23, 2017"))),(0,a.kt)("script",{async:"",src:"//platform.twitter.com/widgets.js",charSet:"utf-8"}),(0,a.kt)("p",null,"In this post we're improving build speeds with TypeScript and webpack in 3 ways:"),(0,a.kt)("dl",null,(0,a.kt)("dt",null,"fork-ts-checker-webpack-plugin"),(0,a.kt)("dd",null,"With this plugin in play ts-loader only performs transpilation. ts-loader is doing less so the build is faster."),(0,a.kt)("dt",null,"HappyPack"),(0,a.kt)("dd",null,"With HappyPack in the mix, the build is parallelised. That parallelisation means the build is faster."),(0,a.kt)("dt",null,"thread-loader / cache-loader"),(0,a.kt)("dd",null,"With thread-loader and cache-loader, again the build is parallelised and the build is faster.")),(0,a.kt)("iframe",{src:"https://giphy.com/embed/Bo2WsocASVBm0",width:"240",height:"180",frameBorder:"0",allowFullScreen:""}))}d.isMDXComponent=!0},42794:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"fork-ts-checker-webpack-plugin-code",title:"fork-ts-checker-webpack-plugin code clickability",authors:"johnnyreilly",tags:["VS Code","fork-ts-checker-webpack-plugin","ts-loader","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/fork-ts-checker-webpack-plugin-code",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-09-12-fork-ts-checker-webpack-plugin-code/index.md",source:"@site/blog/2017-09-12-fork-ts-checker-webpack-plugin-code/index.md",title:"fork-ts-checker-webpack-plugin code clickability",description:"My name is John Reilly and I'm a VS Code addict. There I said it. I'm also a big fan of TypeScript and webpack. I've recently switched to using the awesome fork-ts-checker-webpack-plugin to speed up my builds.",date:"2017-09-12T00:00:00.000Z",formattedDate:"September 12, 2017",tags:[{label:"VS Code",permalink:"/tags/vs-code"},{label:"fork-ts-checker-webpack-plugin",permalink:"/tags/fork-ts-checker-webpack-plugin"},{label:"ts-loader",permalink:"/tags/ts-loader"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:2.09,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"fork-ts-checker-webpack-plugin-code",title:"fork-ts-checker-webpack-plugin code clickability",authors:"johnnyreilly",tags:["VS Code","fork-ts-checker-webpack-plugin","ts-loader","webpack"],hide_table_of_contents:!1},prevItem:{title:"Working with Extrahop on webpack and ts-loader",permalink:"/working-with-extrahop-on-webpack-and-ts"},nextItem:{title:"TypeScript + Webpack: Super Pursuit Mode",permalink:"/typescript-webpack-super-pursuit-mode"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"My name is John Reilly and I'm a VS Code addict. There I said it. I'm also a big fan of TypeScript and webpack. I've recently switched to using the awesome ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/fork-ts-checker-webpack-plugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"fork-ts-checker-webpack-plugin"))," to speed up my builds."),(0,a.kt)("p",null,"One thing I love is using VS Code both as my editor and my terminal. Using the fork-ts-checker-webpack-plugin I noticed a problem when TypeScript errors showed up in the terminal:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(24901).Z,width:"640",height:"317"})),(0,a.kt)("p",null,"Take a look at the red file location in the console above. What's probably not obvious from the above screenshot is that it is ",(0,a.kt)("strong",{parentName:"p"},"not clickable"),". I'm used to being able to click on link in the console and bounce straight to the error location. It's a really productive workflow; see a problem, click on it, be taken to the cause, fix it."),(0,a.kt)("p",null,'I want to click on "',(0,a.kt)("inlineCode",{parentName:"p"},"C:/source/ts-loader/examples/fork-ts-checker/src/fileWithError.ts(2,7)"),'" and have VS Code open up ',(0,a.kt)("inlineCode",{parentName:"p"},"fileWithError.ts"),", ideally at line 2 and column 7. But here it's not working. Why?"),(0,a.kt)("p",null,"Well, I initially got this slightly wrong; I thought it was about the formatting of the file path. It is. I thought that having the line number and column number in parentheses after the path (eg ",(0,a.kt)("inlineCode",{parentName:"p"},'"(2,7)"'),") was screwing over VS Code. It isn't. Something else is. Look closely at the screenshot; what do you see? Do you notice how the colour of the line number / column number is different to the path? In the words of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://youtu.be/281jMxOvP5k"}),"Delbert Wilkins"),": that's crucial."),(0,a.kt)("p",null,"Yup, the colour change between the path and the line number / column number is the problem. I've submitted a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin/pull/48"}),"PR to fix this")," that I hope will get merged. In the meantime you can avoid this issue by dropping this code into your ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"var chalk = require('chalk');\nvar os = require('os');\n\nfunction clickableFormatter(message, useColors) {\n  var colors = new chalk.constructor({ enabled: useColors });\n  var messageColor = message.isWarningSeverity()\n    ? colors.bold.yellow\n    : colors.bold.red;\n  var fileAndNumberColor = colors.bold.cyan;\n  var codeColor = colors.grey;\n  return [\n    messageColor(message.getSeverity().toUpperCase() + ' in ') +\n      fileAndNumberColor(\n        message.getFile() +\n          '(' +\n          message.getLine() +\n          ',' +\n          message.getCharacter() +\n          ')'\n      ) +\n      messageColor(':'),\n\n    codeColor(message.getFormattedCode() + ': ') + message.getContent(),\n  ].join(os.EOL);\n}\n\nmodule.exports = {\n  // Other config...\n  module: {\n    rules: [\n      {\n        test: /\\.tsx?$/,\n        loader: 'ts-loader',\n        options: { transpileOnly: true },\n      },\n    ],\n  },\n  resolve: {\n    extensions: ['.ts', '.tsx', 'js'],\n  },\n  plugins: [\n    new ForkTsCheckerWebpackPlugin({ formatter: clickableFormatter }), // Here we get our clickability back\n  ],\n};\n")),(0,a.kt)("p",null,"With that in place, what do you we have? This:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(50080).Z,width:"640",height:"317"})),(0,a.kt)("p",null,"VS Code clickability; it's a beautiful thing."))}d.isMDXComponent=!0},28890:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"working-with-extrahop-on-webpack-and-ts",title:"Working with Extrahop on webpack and ts-loader",authors:"johnnyreilly",tags:["ts-loader","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/working-with-extrahop-on-webpack-and-ts",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-10-19-working-with-extrahop-on-webpack-and-ts/index.md",source:"@site/blog/2017-10-19-working-with-extrahop-on-webpack-and-ts/index.md",title:"Working with Extrahop on webpack and ts-loader",description:"I'm quite proud of this//www.extrahop.com/company/blog/2017/extrahop-webpack-accelerating-build-times/",date:"2017-10-19T00:00:00.000Z",formattedDate:"October 19, 2017",tags:[{label:"ts-loader",permalink:"/tags/ts-loader"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:.625,hasTruncateMarker:!1,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"working-with-extrahop-on-webpack-and-ts",title:"Working with Extrahop on webpack and ts-loader",authors:"johnnyreilly",tags:["ts-loader","webpack"],hide_table_of_contents:!1},prevItem:{title:"TypeScript Definitions, webpack and Module Types",permalink:"/typescript-definitions-webpack-and-module-types"},nextItem:{title:"fork-ts-checker-webpack-plugin code clickability",permalink:"/fork-ts-checker-webpack-plugin-code"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I'm quite proud of this: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.extrahop.com/company/blog/2017/extrahop-webpack-accelerating-build-times/"}),"https://www.extrahop.com/company/blog/2017/extrahop-webpack-accelerating-build-times/")),(0,a.kt)("p",null,"If you didn't know, I spend a good amount of my spare time hacking on open source software. You may not know what that is. I would describe OSS as software made with \u2764 by people, for other people to use."),(0,a.kt)("p",null,"You are currently reading this on a platform that was built using OSS. It's all around you, every day. It's on your phone, on your computer, on your TV. It's everywhere."),(0,a.kt)("p",null,"It's my hobby, it's part of my work. This specifically was one of those tremendously rare occasions when I got paid directly to work on my hobby, with people much brighter than me. It was brilliant. I loved it; it was a privilege."),(0,a.kt)("p",null,"Here's to Open Source!"))}d.isMDXComponent=!0},11802:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-definitions-webpack-and-module-types",title:"TypeScript Definitions, webpack and Module Types",authors:"johnnyreilly",tags:["Definitely Typed","typescript","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-definitions-webpack-and-module-types",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-10-20-typescript-definitions-webpack-and-module-types/index.md",source:"@site/blog/2017-10-20-typescript-definitions-webpack-and-module-types/index.md",title:"TypeScript Definitions, webpack and Module Types",description:"A funny thing happened on the way to the registry the other day. Something changed in an npm package I was using and confusion arose. You can read my unfiltered confusion here but here's the slightly clearer explanation.",date:"2017-10-20T00:00:00.000Z",formattedDate:"October 20, 2017",tags:[{label:"Definitely Typed",permalink:"/tags/definitely-typed"},{label:"typescript",permalink:"/tags/typescript"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:3.595,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-definitions-webpack-and-module-types",title:"TypeScript Definitions, webpack and Module Types",authors:"johnnyreilly",tags:["Definitely Typed","typescript","webpack"],hide_table_of_contents:!1},prevItem:{title:"The TypeScript webpack PWA",permalink:"/the-typescript-webpack-pwa"},nextItem:{title:"Working with Extrahop on webpack and ts-loader",permalink:"/working-with-extrahop-on-webpack-and-ts"}},p={authorsImageUrls:[void 0]},u=[{value:"The TL;DR",id:"the-tldr",level:2},{value:"The DR",id:"the-dr",level:2},{value:"UMD / CommonJS **and** Global exports oh my!",id:"umd--commonjs-and-global-exports-oh-my",level:2},{value:"One Definition to Rule Them All",id:"one-definition-to-rule-them-all",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"A funny thing happened on the way to the registry the other day. Something changed in an npm package I was using and confusion arose. You can read my unfiltered confusion ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/issues/18791"}),"here")," but here's the slightly clearer explanation."),(0,a.kt)("h2",o({},{id:"the-tldr"}),"The TL;DR"),(0,a.kt)("p",null,'When modules are imported, your loader will decide which module format it wants to use. CommonJS / AMD etc. The loader decides. It\'s important that the export is of the same "shape" regardless of the module format. For 2 reasons:'),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"You want to be able to reliably use the module regardless of the choice that your loader has made for which export to use."),(0,a.kt)("li",{parentName:"ol"},"Because when it comes to writing type definition files for modules, there is support for a ",(0,a.kt)("em",{parentName:"li"},"single")," external definition. Not one for each module format.")),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(40900).Z,width:"398",height:"383"})),(0,a.kt)("h2",o({},{id:"the-dr"}),"The DR"),(0,a.kt)("p",null,"Once upon a time we decided to use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/MikeMcl/big.js/"}),"big.js")," in our project. It's popular and my old friend ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/nycdotnet"}),"Steve Ognibene")," apparently originally wrote the type definitions which can be found ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/big.js"}),"here"),". Then the definitions were updated by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/googol"}),"Miika H\xe4nninen"),". And then there was pain."),(0,a.kt)("h2",o({},{id:"umd--commonjs-and-global-exports-oh-my"}),"UMD / CommonJS ","*","*","and","*","*"," Global exports oh my!"),(0,a.kt)("p",null,"My usage code was as simple as this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"import * as BigJs from 'big.js';\nconst lookABigJs = new BigJs(1);\n")),(0,a.kt)("p",null,"If you execute it in a browser it works. It makes me a ",(0,a.kt)("inlineCode",{parentName:"p"},"Big"),". However the TypeScript compiler is ","*","*","not","*","*"," happy. No siree. Nope. It's bellowing at me:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"[ts] Cannot use 'new' with an expression whose type lacks a call or construct signature.\n")),(0,a.kt)("p",null,'So I think: "Huh! I guess Miika just missed something off when he updated the definition files. No bother. I\'ll fix it." I take a look at how ',(0,a.kt)("inlineCode",{parentName:"p"},"big.js")," exposes itself to the outside world. At the time, thusly:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"//AMD.\nif (typeof define === 'function' && define.amd) {\n  define(function () {\n    return Big;\n  });\n\n  // Node and other CommonJS-like environments that support module.exports.\n} else if (typeof module !== 'undefined' && module.exports) {\n  module.exports = Big;\n  module.exports.Big = Big;\n  //Browser.\n} else {\n  global.Big = Big;\n}\n")),(0,a.kt)("p",null,"Now, we were using webpack as our script bundler / loader. webpack is supersmart; it can take all kinds of module formats. So although it's more famous for supporting CommonJS, it can roll with AMD. That's exactly what's happening here. When webpack encounters the above code, it goes with the AMD export. So at runtime, ",(0,a.kt)("inlineCode",{parentName:"p"},"import * as BigJs from 'big.js';")," lands up resolving to the ",(0,a.kt)("inlineCode",{parentName:"p"},"return Big;")," above."),(0,a.kt)("p",null,"Now this turns out to be super-relevant. I took a look at the relevant portion of the definition file and found this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"export const Big: BigConstructor;\n")),(0,a.kt)("p",null,"Which tells me that ",(0,a.kt)("inlineCode",{parentName:"p"},"Big")," is being exported as a subproperty of the module. That makes sense; that lines up with the ",(0,a.kt)("inlineCode",{parentName:"p"},"module.exports.Big = Big;"),' statement in the the big.js source code. There\'s a "gotcha" coming; can you guess what it is?'),(0,a.kt)("p",null,"The problem is that our type definition is not exposing ",(0,a.kt)("inlineCode",{parentName:"p"},"Big")," as a default export. So even though it's there; TypeScript won't let us use it. What's killing us further is that webpack is loading the AMD export which ",(0,a.kt)("em",{parentName:"p"},"doesn't")," have ",(0,a.kt)("inlineCode",{parentName:"p"},"Big")," as a subproperty of the module. It only has it as a default."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/kitsonk"}),"Kitson Kelly")," expressed the problem well when he said:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"there is a different shape depending on which loader is being used and I am not sure that makes a huge amount of sense. The AMD shape is different than the CommonJS shape. While that is technically possible, that feels like that is an issue.")),(0,a.kt)("h2",o({},{id:"one-definition-to-rule-them-all"}),"One Definition to Rule Them All"),(0,a.kt)("p",null,'He\'s right; it is an issue. From a TypeScript perspective there is no way to write a definition file that allows for different module "shapes" depending upon the module type. If you really wanted to do that you\'re reduced to writing multiple definition files. That\'s blind alley anyway; what you want is a module to expose itself with the same "shape" regardless of the module type. What you want is this:'),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"AMD === CommonJS === Global")),(0,a.kt)("p",null,"And that's what we now have! Thanks to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/mikemcl"}),"Michael McLaughlin"),", author of big.js, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/MikeMcl/big.js/pull/87#issuecomment-332663587"}),"version 4.0 unified the export shape of the package"),". Miika H\xe4nninen submitted another ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped/pull/20096"}),"PR")," which fixed up the type definitions. And once again the world is a beautiful place!"))}d.isMDXComponent=!0},55752:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"the-typescript-webpack-pwa",title:"The TypeScript webpack PWA",authors:"johnnyreilly",tags:["typescript","PWA","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/the-typescript-webpack-pwa",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-11-19-the-typescript-webpack-pwa/index.md",source:"@site/blog/2017-11-19-the-typescript-webpack-pwa/index.md",title:"The TypeScript webpack PWA",description:"So, there you sit, conflicted. You've got a lovely build setup; it's a thing of beauty. Precious, polished like a diamond, sharpened like a circular saw. There at the core of your carefully crafted setup sits webpack. Heaving, mysterious... powerful.",date:"2017-11-19T00:00:00.000Z",formattedDate:"November 19, 2017",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"PWA",permalink:"/tags/pwa"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:3.335,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"the-typescript-webpack-pwa",title:"The TypeScript webpack PWA",authors:"johnnyreilly",tags:["typescript","PWA","webpack"],hide_table_of_contents:!1},prevItem:{title:"ts-loader 2017 retrospective",permalink:"/ts-loader-2017-retrospective"},nextItem:{title:"TypeScript Definitions, webpack and Module Types",permalink:"/typescript-definitions-webpack-and-module-types"}},p={authorsImageUrls:[void 0]},u=[{value:"Let&#39;s Do It Tonight",id:"lets-do-it-tonight",level:2},{value:"Work(box) It",id:"workbox-it",level:2},{value:"What Have We Got?",id:"what-have-we-got",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"So, there you sit, conflicted. You've got a lovely build setup; it's a thing of beauty. Precious, polished like a diamond, sharpened like a circular saw. There at the core of your carefully crafted setup sits webpack. Heaving, mysterious... powerful."),(0,a.kt)("p",null,"There's more. Not only are you sold on webpack, you're all in TypeScript too. But now you've heard tell of \"Progressive Web Applications\" and \"Service Workers\".... And you want to be dealt in. You want to build web apps that work offline. It can't work can it? Your build setup's going to be like the creature in the episode where they've taken one too many jumps and it's gone into the foetal position."),(0,a.kt)("p",null,"So this is the plan kids. Let's take a simple TypeScript, webpack setup and make it a PWA. Like Victoria Wood said..."),(0,a.kt)("h2",o({},{id:"lets-do-it-tonight"}),(0,a.kt)("a",o({parentName:"h2"},{href:"https://youtu.be/lNU5KVa_Tu8"}),"Let's Do It Tonight")),(0,a.kt)("p",null,"How to begin? Well first comes the plagiarism; ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/tree/master/examples/core-js"}),"here's a simple TypeScript webpack setup"),". Rob it. Stick a gun to its head and order it onto your hard drive. ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn install")," to pick up your dependencies and then ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn start")," to see what you've got. Something like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(81780).Z,width:"320",height:"138"})),(0,a.kt)("p",null,"Beautiful right? And if we ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn build")," we end up with a simple output:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(52831).Z,width:"320",height:"119"})),(0,a.kt)("p",null,"To test what we've built out we want to use a simple web server to serve up the ",(0,a.kt)("inlineCode",{parentName:"p"},"dist")," folder. I've got the npm package ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/http-server"}),"http-server")," installed globally for just such an eventuality. So let's ",(0,a.kt)("inlineCode",{parentName:"p"},"http-server ./dist")," and I'm once again looking at our simple app; it looks exactly the same as when I ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn start"),". Smashing. What would we see if we were offline? Well thanks to the magic of Chrome DevTools we can find out. Offline and refresh our browser..."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(29307).Z,width:"230",height:"320"})),(0,a.kt)("p",null,"Not very user friendly. Once we're done, we should be able to refresh and still see our app."),(0,a.kt)("h2",o({},{id:"workbox-it"}),(0,a.kt)("a",o({parentName:"h2"},{href:"https://youtu.be/UODX_pYpVxk"}),"Work(box) It")),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/web/tools/workbox/"}),"Workbox")," is a project that makes the setting up of Service Workers (aka the magic that powers PWAs) easier. It supports webpack use cases through the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/workbox-webpack-plugin"}),"workbox-webpack-plugin"),"; so let's give it a whirl. Incidentally, there's a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/web/tools/workbox/get-started/webpack"}),"cracking example")," on the Workbox site."),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"yarn add workbox-webpack-plugin --dev")," adds the plugin to our project. To make use of it, punt your way over to the ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.production.config.js")," and add an entry for the plugin. We also need to set the ",(0,a.kt)("inlineCode",{parentName:"p"},"hash")," parameter of the html-webpack-plugin to be false; if it's true it'll cause problems for the ServiceWorker."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const WorkboxPlugin = require('workbox-webpack-plugin');\n\n//...\n\nmodule.exports = {\n  //...\n\n  plugins: [\n    //...\n\n    new HtmlWebpackPlugin({\n      hash: false,\n      inject: true,\n      template: 'src/index.html',\n      minify: {\n        removeComments: true,\n        collapseWhitespace: true,\n        removeRedundantAttributes: true,\n        useShortDoctype: true,\n        removeEmptyAttributes: true,\n        removeStyleLinkTypeAttributes: true,\n        keepClosingSlash: true,\n        minifyJS: true,\n        minifyCSS: true,\n        minifyURLs: true,\n      },\n    }),\n\n    new WorkboxPlugin({\n      // we want our service worker to cache the dist directory\n      globDirectory: 'dist',\n      // these are the sorts of files we want to cache\n      globPatterns: ['**/*.{html,js,css,png,svg,jpg,gif,json}'],\n      // this is where we want our ServiceWorker to be created\n      swDest: path.resolve('dist', 'sw.js'),\n      // these options encourage the ServiceWorkers to get in there fast\n      // and not allow any straggling \"old\" SWs to hang around\n      clientsClaim: true,\n      skipWaiting: true,\n    }),\n  ],\n\n  //...\n};\n")),(0,a.kt)("p",null,"With this in place, ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn build")," will generate a ServiceWorker. Now to alter our code to register it. Open up ",(0,a.kt)("inlineCode",{parentName:"p"},"index.tsx")," and add this to the end of the file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"if ('serviceWorker' in navigator) {\n  window.addEventListener('load', () => {\n    navigator.serviceWorker\n      .register('/sw.js')\n      .then((registration) => {\n        // tslint:disable:no-console\n        console.log('SW registered: ', registration);\n      })\n      .catch((registrationError) => {\n        console.log('SW registration failed: ', registrationError);\n      });\n  });\n}\n")),(0,a.kt)("p",null,"Put it together and..."),(0,a.kt)("h2",o({},{id:"what-have-we-got"}),"What Have We Got?"),(0,a.kt)("p",null,"Let's ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn build")," again."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(48714).Z,width:"640",height:"346"})),(0,a.kt)("p",null,"Oooohh look! A service worker is with us. Does it work? Let's find out... ",(0,a.kt)("inlineCode",{parentName:"p"},"http-server ./dist")," Browse to ",(0,a.kt)("a",o({parentName:"p"},{href:"http://localhost:8080"}),"http://localhost:8080")," and let's have a look at the console."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(43344).Z,width:"640",height:"265"})),(0,a.kt)("p",null,"Looks very exciting. So now the test; let's go offline and refresh:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(54936).Z,width:"640",height:"338"})),(0,a.kt)("p",null,"You are looking at the 200s of success. You're now running with webpack and TypeScript and you have built a Progressive Web Application. Feel good about life."))}d.isMDXComponent=!0},90505:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"ts-loader-2017-retrospective",title:"ts-loader 2017 retrospective",authors:"johnnyreilly",tags:["typescript","ts-loader","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/ts-loader-2017-retrospective",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2017-12-24-ts-loader-2017-retrospective/index.md",source:"@site/blog/2017-12-24-ts-loader-2017-retrospective/index.md",title:"ts-loader 2017 retrospective",description:"2017 is drawing to a close, and it's been a big, big year in webpack-land. It's been a big year for ts-loader too. At the start of the year v1.3.3 was the latest version available, officially supporting webpack 1. (Old school!) We end the year with ts-loader sitting pretty at v3.2.0 and supporting webpack 2 and 3.",date:"2017-12-24T00:00:00.000Z",formattedDate:"December 24, 2017",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"ts-loader",permalink:"/tags/ts-loader"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:3.4,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"ts-loader-2017-retrospective",title:"ts-loader 2017 retrospective",authors:"johnnyreilly",tags:["typescript","ts-loader","webpack"],hide_table_of_contents:!1},prevItem:{title:"Auth0, TypeScript and ASP.NET Core",permalink:"/auth0-typescript-and-aspnet-core"},nextItem:{title:"The TypeScript webpack PWA",permalink:"/the-typescript-webpack-pwa"}},p={authorsImageUrls:[void 0]},u=[{value:"<code>fork-ts-checker-webpack-plugin</code> build speed improvements",id:"fork-ts-checker-webpack-plugin-build-speed-improvements",level:2},{value:"ts-loader 4.0 (Live webpack or Die Hard)",id:"ts-loader-40-live-webpack-or-die-hard",level:2},{value:"Start using the new watch API",id:"start-using-the-new-watch-api",level:3},{value:"Drop custom module resolution",id:"drop-custom-module-resolution",level:3},{value:"Drop support for TypeScript 2.3 and below",id:"drop-support-for-typescript-23-and-below",level:3},{value:"webpack v4 is in alpha now",id:"webpack-v4-is-in-alpha-now",level:3},{value:"<code>contextAsConfigBasePath</code> will be replaced with a <code>context</code>",id:"contextasconfigbasepath-will-be-replaced-with-a-context",level:3},{value:"<code>reportFiles</code> option to be added",id:"reportfiles-option-to-be-added",level:3},{value:"Merry Christmas!",id:"merry-christmas",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"2017 is drawing to a close, and it's been a big, big year in webpack-land. It's been a big year for ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," too. At the start of the year v1.3.3 was the latest version available, officially supporting webpack 1. (Old school!) We end the year with ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," sitting pretty at v3.2.0 and supporting webpack 2 and 3."),(0,a.kt)("p",null,"Many releases were shipped and that was down to a whole bunch of folk. People helped out with bug fixes, features, advice and docs improvements. ",(0,a.kt)("strong",{parentName:"p"},"All of these help."),(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," wouldn't be where it is without you so thanks to everyone that helped out - you rock!"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"Profile image of https://github.com/christiantinauer",src:n(50728).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/Pajn",src:n(63028).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/maier49",src:n(46654).Z,width:"420",height:"420"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/false",src:n(28101).Z,width:"125",height:"125"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/roddypratt",src:n(18230).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/ldrick",src:n(17951).Z,width:"346",height:"346"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/mattlewis92",src:n(94178).Z,width:"400",height:"400"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/Venryx",src:n(15478).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/WillMartin",src:n(45041).Z,width:"420",height:"420"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/Loilo",src:n(44402).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/Brooooooklyn",src:n(35585).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/mengxy",src:n(90603).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/bsouthga",src:n(16220).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/zinserjan",src:n(50798).Z,width:"420",height:"420"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/sokra",src:n(38568).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/vhqtvn",src:n(27368).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/HerringtonDarkholme",src:n(24764).Z,width:"328",height:"328"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/johnnyreilly",src:n(25499).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/jbrantly",src:n(88564).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/octref",src:n(71331).Z,width:"400",height:"400"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/rhyek",src:n(34296).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/develar",src:n(86822).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/donaldpipowitch",src:n(49642).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/schmuli",src:n(96512).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/longlho",src:n(95590).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/Igorbek",src:n(6464).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/aindlq",src:n(28486).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/wearymonkey",src:n(830).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/bancek",src:n(57549).Z,width:"460",height:"460"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Profile image of https://github.com/mredbishop",src:n(82921).Z,width:"460",height:"460"})),(0,a.kt)("p",null,"I'm really grateful to all of you. Thanks so much! (Apologies for those I've missed anyone out - I know there's more still.)"),(0,a.kt)("h2",o({},{id:"fork-ts-checker-webpack-plugin-build-speed-improvements"}),(0,a.kt)("inlineCode",{parentName:"h2"},"fork-ts-checker-webpack-plugin")," build speed improvements"),(0,a.kt)("p",null,"Alongside other's direct contributions to ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader"),", other projects improved the experience of using ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader"),". ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/piotr-oles"}),"Piotr Ole\u015b")," dropped his ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"fork-ts-checker-webpack-plugin"))," this year which nicely increased build speed when used with ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader"),"."),(0,a.kt)("p",null,"That opened up the possibility of adding ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/amireh/happypack"}),"HappyPack")," support. I had the good fortune to work with webpack's ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/sokra"}),"Tobias Koppers")," and ExtraHop's ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/abirmingham"}),"Alex Birmingham")," on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.extrahop.com/company/blog/2017/extrahop-webpack-accelerating-build-times/"}),"improving TypeScript build speed further"),"."),(0,a.kt)("p",null,"So what does the future hold?"),(0,a.kt)("h2",o({},{id:"ts-loader-40-live-webpack-or-die-hard"}),"ts-loader 4.0 (Live webpack or Die Hard)"),(0,a.kt)("p",null,"The web marches on and webpack gallops alongside. Here's what's in the pipeline for ts-loader in 2018:"),(0,a.kt)("h3",o({},{id:"start-using-the-new-watch-api"}),"Start using the new watch API"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/pull/20234"}),"A new watch API is being made available in the TypeScript API"),". We have ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/685"}),"a PR")," from the amazing ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/sheetalkamat"}),"Sheetal Nandi")," which adds support to ts-loader. Given that's quite a big PR we want to merge that before anything else lands. The watch API is still being finalised but once it lands in TypeScript we'll look to merge the PR and ship a new version of ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader"),"."),(0,a.kt)("h3",o({},{id:"drop-custom-module-resolution"}),"Drop custom module resolution"),(0,a.kt)("p",null,"Historically ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," has had it's own module resolution mechanism in place. We're going to look to move to use the TypeScript mechanism instead. The old module resolution be deprecated but will remain available behind a flag for a time. In future we'll look to drop the old mechanism entirely."),(0,a.kt)("h3",o({},{id:"drop-support-for-typescript-23-and-below"}),"Drop support for TypeScript 2.3 and below"),(0,a.kt)("p",null,"The codebase can be made simpler if we drop support for older versions of TypeScript so that's what we plan to do with our next breaking changes release."),(0,a.kt)("h3",o({},{id:"webpack-v4-is-in-alpha-now"}),"webpack v4 is in alpha now"),(0,a.kt)("p",null,"If any changes need to happen to ts-loader to support webpack 4 then they will be. Personally I'm planning to help out with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"fork-ts-checker-webpack-plugin"))," as there will likely be some changes required there."),(0,a.kt)("h3",o({},{id:"contextasconfigbasepath-will-be-replaced-with-a-context"}),(0,a.kt)("inlineCode",{parentName:"h3"},"contextAsConfigBasePath")," will be replaced with a ",(0,a.kt)("inlineCode",{parentName:"h3"},"context")),(0,a.kt)("p",null,"The option that landed in the last month doesn't quite achieve the aims of the original PR's author ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/christiantinauer"}),"Christian Tinauer"),". Consequently it's going to be replaced with a new option. This is queued up and ready to go ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/688"}),"here"),"."),(0,a.kt)("h3",o({},{id:"reportfiles-option-to-be-added"}),(0,a.kt)("inlineCode",{parentName:"h3"},"reportFiles")," option to be added"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/freeman"}),"Michel Rasschaert")," is presently working on adding a ",(0,a.kt)("inlineCode",{parentName:"p"},"reportFiles")," option to ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader"),". You can see the PR in progress ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/701"}),"here"),"."),(0,a.kt)("h2",o({},{id:"merry-christmas"}),"Merry Christmas!"),(0,a.kt)("p",null,"You can expect to see the first releases of ts-loader 4.0 in 2018. In the meantime, I'd like to wish you Merry Christmas and a Happy New Year! And once more, thanks and thanks again to all you generous people who help build ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader"),". You're wonderful and so I'm glad you do what you do... joyeux Noel!"))}d.isMDXComponent=!0},49039:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"auth0-typescript-and-aspnet-core",title:"Auth0, TypeScript and ASP.NET Core",authors:"johnnyreilly",tags:["ASP.Net Core","Auth0","typescript","OAuth","React"],hide_table_of_contents:!1},s=void 0,l={permalink:"/auth0-typescript-and-aspnet-core",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-01-14-auth0-typescript-and-aspnet-core/index.md",source:"@site/blog/2018-01-14-auth0-typescript-and-aspnet-core/index.md",title:"Auth0, TypeScript and ASP.NET Core",description:"Most applications I write have some need for authentication and perhaps authorisation too. In fact, most apps most people write fall into that bracket. Here's the thing: Auth done well is a \\big\\ chunk of work. And the minute you start thinking about that you almost invariably lose focus on the thing you actually want to build and ship.",date:"2018-01-14T00:00:00.000Z",formattedDate:"January 14, 2018",tags:[{label:"ASP.Net Core",permalink:"/tags/asp-net-core"},{label:"Auth0",permalink:"/tags/auth-0"},{label:"typescript",permalink:"/tags/typescript"},{label:"OAuth",permalink:"/tags/o-auth"},{label:"React",permalink:"/tags/react"}],readingTime:9.365,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"auth0-typescript-and-aspnet-core",title:"Auth0, TypeScript and ASP.NET Core",authors:"johnnyreilly",tags:["ASP.Net Core","Auth0","typescript","OAuth","React"],hide_table_of_contents:!1},prevItem:{title:"webpack 4 - ts-loader / fork-ts-checker-webpack-plugin betas",permalink:"/webpack-4-ts-loader-fork-ts-checker"},nextItem:{title:"ts-loader 2017 retrospective",permalink:"/ts-loader-2017-retrospective"}},p={authorsImageUrls:[void 0]},u=[{value:"What I wanted to build",id:"what-i-wanted-to-build",level:2},{value:"Boil a Plate",id:"boil-a-plate",level:2},{value:"The Walkthrough",id:"the-walkthrough",level:2},{value:"Setup Auth0",id:"setup-auth0",level:2},{value:"Client",id:"client",level:3},{value:"API",id:"api",level:3},{value:"Running the App",id:"running-the-app",level:2},{value:"Production build",id:"production-build",level:3},{value:"Debugging",id:"debugging",level:3},{value:"The Tour",id:"the-tour",level:2},{value:"authStore.ts",id:"authstorets",level:3},{value:"UserController.cs",id:"usercontrollercs",level:3},{value:"UserController.cs",id:"usercontrollercs-1",level:3},{value:"Startup.cs",id:"startupcs",level:3},{value:"Authorization",id:"authorization",level:2},{value:"UserController.cs",id:"usercontrollercs-2",level:3},{value:"Scopes.cs",id:"scopescs",level:3},{value:"Startup.cs",id:"startupcs-1",level:3},{value:"HasScopeHandler.cs",id:"hasscopehandlercs",level:3}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Most applications I write have some need for authentication and perhaps authorisation too. In fact, most apps most people write fall into that bracket. Here's the thing: Auth done well is a ","*","big","*"," chunk of work. And the minute you start thinking about that you almost invariably lose focus on the thing you actually want to build and ship."),(0,a.kt)("p",null,"So this Christmas I decided it was time to take a look into offloading that particular problem onto someone else. I knew there were third parties who provided Auth-As-A-Service - time to give them a whirl. On the recommendation of a friend, I made Auth0 my first port of call. Lest you be expecting a full breakdown of the various players in this space, let me stop you now; I liked Auth0 so much I strayed no further. Auth0 kicks AAAS. (I'm so sorry)"),(0,a.kt)("h2",o({},{id:"what-i-wanted-to-build"}),"What I wanted to build"),(0,a.kt)("p",null,'My criteria for "auth success" was this:'),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"I want to build a SPA, specifically a React SPA. Ideally, I shouldn't need a back end of my own at all"),(0,a.kt)("li",{parentName:"ul"},"I want to use TypeScript on my client.")),(0,a.kt)("p",null,"But, for when I do implement a back end:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"I want that to be able to use the client side's Auth tokens to allow access to Auth routes on my server."),(0,a.kt)("li",{parentName:"ul"},"\u200eI want to able to identify the user, given the token, to provide targeted data"),(0,a.kt)("li",{parentName:"ul"},"Oh, and I want to use .NET Core 2 for my server.")),(0,a.kt)("p",null,"And in achieving all of the I want to add minimal code to my app. Not War and Peace. My code should remain focused on doing what it does."),(0,a.kt)("h2",o({},{id:"boil-a-plate"}),"Boil a Plate"),(0,a.kt)("p",null,"I ended up with unqualified ticks for all my criteria, but it took some work to find out. I will say that Auth0 do travel the extra mile in terms of getting you up and running. When you create a new Client in Auth0 you're given the option to download a quick start using the technology of your choice."),(0,a.kt)("p",null,"This was a massive plus for me. I took the quickstart provided and ran with it to get me to the point of meeting my own criteria. You can use this boilerplate for your own ends. Herewith, a walkthrough:"),(0,a.kt)("h2",o({},{id:"the-walkthrough"}),"The Walkthrough"),(0,a.kt)("p",null,"Fork and clone the repo at this location: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/auth0-react-typescript-asp-net-core"}),"https://github.com/johnnyreilly/auth0-react-typescript-asp-net-core"),"."),(0,a.kt)("p",null,"What have we got? 2 folders, ClientApp contains the React app, Web contains the ASP.NET Core app. Now we need to get setup with Auth0 and customise our config."),(0,a.kt)("h2",o({},{id:"setup-auth0"}),"Setup Auth0"),(0,a.kt)("p",null,"Here's how to get the app set up with Auth0; you're going to need to sign up for a (free) Auth0 account. Then login into Auth0 and go to the management portal."),(0,a.kt)("h3",o({},{id:"client"}),"Client"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Create a Client with the name of your choice and use the Single Page Web Applications template."),(0,a.kt)("li",{parentName:"ul"},"From the new Client Settings page take the Domain and Client ID and update the similarly named properties in the ",(0,a.kt)("inlineCode",{parentName:"li"},"appsettings.Development.json")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"appsettings.Production.json")," files with these settings."),(0,a.kt)("li",{parentName:"ul"},"To the Allowed Callback URLs setting add the URLs: ",(0,a.kt)("inlineCode",{parentName:"li"},"http://localhost:3000/callback,http://localhost:5000/callback")," ","-"," the first of these faciliates running in Debug mode, the second in Production mode. If you were to deploy this you'd need to add other callback URLs in here too.")),(0,a.kt)("h3",o({},{id:"api"}),"API"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Create an API with the name of your choice (I recommend the same as the Client to avoid confusion), an identifier which can be anything you like; I like to use the URL of my app but it's your call."),(0,a.kt)("li",{parentName:"ul"},"From the new API Settings page take the Identifier and update the Audience property in the ",(0,a.kt)("inlineCode",{parentName:"li"},"appsettings.Development.json")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"appsettings.Production.json")," files with that value.")),(0,a.kt)("h2",o({},{id:"running-the-app"}),"Running the App"),(0,a.kt)("h3",o({},{id:"production-build"}),"Production build"),(0,a.kt)("p",null,"Build the client app with ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn build")," in the ",(0,a.kt)("inlineCode",{parentName:"p"},"ClientApp")," folder. (Don't forget to ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn install")," first.) Then, in the ",(0,a.kt)("inlineCode",{parentName:"p"},"Web")," folder ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet restore"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet run")," and open your browser to ",(0,a.kt)("a",o({parentName:"p"},{href:"http://localhost:5000"}),(0,a.kt)("inlineCode",{parentName:"a"},"http://localhost:5000"))),(0,a.kt)("h3",o({},{id:"debugging"}),"Debugging"),(0,a.kt)("p",null,"Run the client app using webpack-dev-server using ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn start")," in the ",(0,a.kt)("inlineCode",{parentName:"p"},"ClientApp")," folder. Fire up VS Code in the root of the repo and hit F5 to debug the server. Then open your browser to ",(0,a.kt)("a",o({parentName:"p"},{href:"http://localhost:3000"}),(0,a.kt)("inlineCode",{parentName:"a"},"http://localhost:3000"))),(0,a.kt)("h2",o({},{id:"the-tour"}),"The Tour"),(0,a.kt)("p",null,'When you fire up the app you\'re presented with "you are not logged in!" message and the option to login. Do it, it\'ll take you to the Auth0 "lock" screen where you can sign up / login. Once you do that you\'ll be asked to confirm access:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(68429).Z,width:"395",height:"400"})),(0,a.kt)("p",null,"All this is powered by Auth0's ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/auth0-js"}),"auth0-js")," npm package. (Excellent type definition files are available from Definitely Typed; I'm using the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/@types/auth0-js"}),"@types/auth0-js")," package DT publishes.) Usage of which is super simple; it exposes an ",(0,a.kt)("inlineCode",{parentName:"p"},"authorize")," method that when called triggers the Auth0 lock screen. Once you've \"okayed\" you'll be taken back to the app which will use the ",(0,a.kt)("inlineCode",{parentName:"p"},"parseHash")," method to extract the access token that Auth0 has provided. Take a look at how our ",(0,a.kt)("inlineCode",{parentName:"p"},"authStore")," makes use of auth0-js: (don't be scared; it uses mobx - but you could use anything)"),(0,a.kt)("h3",o({},{id:"authstorets"}),"authStore.ts"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { Auth0UserProfile, WebAuth } from 'auth0-js';\nimport { action, computed, observable, runInAction } from 'mobx';\nimport { IAuth0Config } from '../../config';\nimport { StorageFacade } from '../storageFacade';\n\ninterface IStorageToken {\n  accessToken: string;\n  idToken: string;\n  expiresAt: number;\n}\n\nconst STORAGE_TOKEN = 'storage_token';\n\nexport class AuthStore {\n  @observable.ref auth0: WebAuth;\n  @observable.ref userProfile: Auth0UserProfile;\n  @observable.ref token: IStorageToken;\n\n  constructor(config: IAuth0Config, private storage: StorageFacade) {\n    this.auth0 = new WebAuth({\n      domain: config.domain,\n      clientID: config.clientId,\n      redirectUri: config.redirectUri,\n      audience: config.audience,\n      responseType: 'token id_token',\n      scope: 'openid email profile do:admin:thing', // the do:admin:thing scope is custom and defined in the scopes section of our API in the Auth0 dashboard\n    });\n  }\n\n  initialise() {\n    const token = this.parseToken(this.storage.getItem(STORAGE_TOKEN));\n    if (token) {\n      this.setSession(token);\n    }\n    this.storage.addEventListener(this.onStorageChanged);\n  }\n\n  parseToken(tokenString: string) {\n    const token = JSON.parse(tokenString || '{}');\n    return token;\n  }\n\n  onStorageChanged = (event: StorageEvent) => {\n    if (event.key === STORAGE_TOKEN) {\n      this.setSession(this.parseToken(event.newValue));\n    }\n  };\n\n  @computed get isAuthenticated() {\n    // Check whether the current time is past the\n    // access token's expiry time\n    return this.token && new Date().getTime() < this.token.expiresAt;\n  }\n\n  login = () => {\n    this.auth0.authorize();\n  };\n\n  handleAuthentication = () => {\n    this.auth0.parseHash((err, authResult) => {\n      if (authResult && authResult.accessToken && authResult.idToken) {\n        const token = {\n          accessToken: authResult.accessToken,\n          idToken: authResult.idToken,\n          // Set the time that the access token will expire at\n          expiresAt: authResult.expiresIn * 1000 + new Date().getTime(),\n        };\n\n        this.setSession(token);\n      } else if (err) {\n        // tslint:disable-next-line:no-console\n        console.log(err);\n        alert(`Error: ${err.error}. Check the console for further details.`);\n      }\n    });\n  };\n\n  @action\n  setSession(token: IStorageToken) {\n    this.token = token;\n    this.storage.setItem(STORAGE_TOKEN, JSON.stringify(token));\n  }\n\n  getAccessToken = () => {\n    const accessToken = this.token.accessToken;\n    if (!accessToken) {\n      throw new Error('No access token found');\n    }\n    return accessToken;\n  };\n\n  @action\n  loadProfile = async () => {\n    const accessToken = this.token.accessToken;\n    if (!accessToken) {\n      return;\n    }\n\n    this.auth0.client.userInfo(accessToken, (err, profile) => {\n      if (err) {\n        throw err;\n      }\n\n      if (profile) {\n        runInAction(() => (this.userProfile = profile));\n        return profile;\n      }\n\n      return undefined;\n    });\n  };\n\n  @action\n  logout = () => {\n    // Clear access token and ID token from local storage\n    this.storage.removeItem(STORAGE_TOKEN);\n\n    this.token = null;\n    this.userProfile = null;\n  };\n}\n")),(0,a.kt)("p",null,'Once you\'re logged in the app offers you more in the way of navigation options. A "Profile" screen shows you the details your React app has retrieved from Auth0 about you. This is backed by the ',(0,a.kt)("inlineCode",{parentName:"p"},"client.userInfo")," method on ",(0,a.kt)("inlineCode",{parentName:"p"},"auth0-js"),'. There\'s also a "Ping" screen which is where your React app talks to your ASP.NET Core server. The screenshot below illustrates the result of hitting the "Get Private Data" button:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(94803).Z,width:"400",height:"341"})),(0,a.kt)("p",null,"The \"Get Server to Retrieve Profile Data\" button is interesting as it illustrates that the server can get access to your profile data as well. There's nothing insecure here; it gets the details using the access token retrieved from Auth0 by the ClientApp and passed to the server. It's the API we set up in Auth0 that is in play here. The app uses the Domain and the access token to talk to Auth0 like so:"),(0,a.kt)("h3",o({},{id:"usercontrollercs"}),"UserController.cs"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'// Retrieve the access_token claim which we saved in the OnTokenValidated event\n    var accessToken = User.Claims.FirstOrDefault(c => c.Type == "access_token").Value;\n\n    // If we have an access_token, then retrieve the user\'s information\n    if (!string.IsNullOrEmpty(accessToken))\n    {\n        var domain = _config["Auth0:Domain"];\n        var apiClient = new AuthenticationApiClient(domain);\n        var userInfo = await apiClient.GetUserInfoAsync(accessToken);\n\n        return Ok(userInfo);\n    }\n')),(0,a.kt)("p",null,"We can also access the ",(0,a.kt)("inlineCode",{parentName:"p"},"sub")," claim, which uniquely identifies the user:"),(0,a.kt)("h3",o({},{id:"usercontrollercs-1"}),"UserController.cs"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"// We're not doing anything with this, but hey! It's useful to know where the user id lives\n    var userId = User.Claims.FirstOrDefault(c => c.Type == System.Security.Claims.ClaimTypes.NameIdentifier).Value; // our userId is the sub value\n")),(0,a.kt)("p",null,"The reason our ASP.NET Core app works with Auth0 and that we have access to the access token here in the first place is because of our startup code:"),(0,a.kt)("h3",o({},{id:"startupcs"}),"Startup.cs"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public void ConfigureServices(IServiceCollection services)\n    {\n        var domain = $"https://{Configuration["Auth0:Domain"]}/";\n        services.AddAuthentication(options =>\n        {\n            options.DefaultAuthenticateScheme = JwtBearerDefaults.AuthenticationScheme;\n            options.DefaultChallengeScheme = JwtBearerDefaults.AuthenticationScheme;\n        }).AddJwtBearer(options =>\n        {\n            options.Authority = domain;\n            options.Audience = Configuration["Auth0:Audience"];\n            options.Events = new JwtBearerEvents\n            {\n                OnTokenValidated = context =>\n                {\n                    if (context.SecurityToken is JwtSecurityToken token)\n                    {\n                        if (context.Principal.Identity is ClaimsIdentity identity)\n                        {\n                            identity.AddClaim(new Claim("access_token", token.RawData));\n                        }\n                    }\n\n                    return Task.FromResult(0);\n                }\n            };\n        });\n\n        // ....\n')),(0,a.kt)("h2",o({},{id:"authorization"}),"Authorization"),(0,a.kt)("p",null,"We're pretty much done now; just one magic button to investigate: \"Get Admin Data\". If you presently try and access the admin data you'll get a ",(0,a.kt)("inlineCode",{parentName:"p"},"403 Forbidden"),". It's forbidden because that endpoint relies on the ",(0,a.kt)("inlineCode",{parentName:"p"},'"do:admin:thing"')," scope in our claims:"),(0,a.kt)("h3",o({},{id:"usercontrollercs-2"}),"UserController.cs"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[Authorize(Scopes.DoAdminThing)]\n    [HttpGet("api/userDoAdminThing")]\n    public IActionResult GetUserDoAdminThing()\n    {\n        return Ok("Admin endpoint");\n    }\n')),(0,a.kt)("h3",o({},{id:"scopescs"}),"Scopes.cs"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public static class Scopes\n    {\n         // the do:admin:thing scope is custom and defined in the scopes section of our API in the Auth0 dashboard\n        public const string DoAdminThing = "do:admin:thing";\n    }\n')),(0,a.kt)("p",null,"This wired up in our ASP.NET Core app like so:"),(0,a.kt)("h3",o({},{id:"startupcs-1"}),"Startup.cs"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'services.AddAuthorization(options =>\n    {\n        options.AddPolicy(Scopes.DoAdminThing, policy => policy.Requirements.Add(new HasScopeRequirement(Scopes.DoAdminThing, domain)));\n    });\n\n    // register the scope authorization handler\n    services.AddSingleton<iauthorizationhandler, hasscopehandler="">();\n</iauthorizationhandler,>\n')),(0,a.kt)("h3",o({},{id:"hasscopehandlercs"}),"HasScopeHandler.cs"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public class HasScopeHandler : AuthorizationHandler<hasscoperequirement>\n    {\n        protected override Task HandleRequirementAsync(AuthorizationHandlerContext context, HasScopeRequirement requirement)\n        {\n            // If user does not have the scope claim, get out of here\n            if (!context.User.HasClaim(c => c.Type == "scope" && c.Issuer == requirement.Issuer))\n                return Task.CompletedTask;\n\n            // Split the scopes string into an array\n            var scopes = context.User.FindFirst(c => c.Type == "scope" && c.Issuer == requirement.Issuer).Value.Split(\' \');\n\n            // Succeed if the scope array contains the required scope\n            if (scopes.Any(s => s == requirement.Scope))\n                context.Succeed(requirement);\n\n            return Task.CompletedTask;\n        }\n    }\n</hasscoperequirement>\n')),(0,a.kt)("p",null,"The reason we're 403ing at present is because when our ",(0,a.kt)("inlineCode",{parentName:"p"},"HasScopeHandler")," executes, ",(0,a.kt)("inlineCode",{parentName:"p"},"requirement.Scope")," has the value of ",(0,a.kt)("inlineCode",{parentName:"p"},'"do:admin:thing"')," and our ",(0,a.kt)("inlineCode",{parentName:"p"},"scopes")," do not contain that value. To add it, go to your API in the Auth0 management console and add it:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(77803).Z,width:"400",height:"260"})),(0,a.kt)("p",null,'Note that you can control how this scope is acquired using "Rules" in the Auth0 management portal.'),(0,a.kt)("p",null,"You won't be able to access the admin endpoint yet because you're still rocking with the old access token; pre-newly-added scope. But when you next login to Auth0 you'll see a prompt like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(94210).Z,width:"327",height:"400"})),(0,a.kt)("p",null,"Which demonstrates that you're being granted an extra scope. With your new shiny access token you can now access the oh-so-secret Admin endpoint."),(0,a.kt)("p",null,"I had some more questions about Auth0 as I'm still new to it myself. To see my question (and the very helpful answer!) go here: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://community.auth0.com/questions/13786/get-user-data-server-side-what-is-a-good-approach"}),"https://community.auth0.com/questions/13786/get-user-data-server-side-what-is-a-good-approach")))}d.isMDXComponent=!0},9361:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"webpack-4-ts-loader-fork-ts-checker",title:"webpack 4 - ts-loader / fork-ts-checker-webpack-plugin betas",authors:"johnnyreilly",tags:["fork-ts-checker-webpack-plugin","ts-loader","Webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/webpack-4-ts-loader-fork-ts-checker",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-01-28-webpack-4-ts-loader-fork-ts-checker/index.md",source:"@site/blog/2018-01-28-webpack-4-ts-loader-fork-ts-checker/index.md",title:"webpack 4 - ts-loader / fork-ts-checker-webpack-plugin betas",description:"The first webpack 4 beta dropped on Friday. Very exciting! Following hot on the heels of those announcements, I've some news to share too. Can you guess what it is?",date:"2018-01-28T00:00:00.000Z",formattedDate:"January 28, 2018",tags:[{label:"fork-ts-checker-webpack-plugin",permalink:"/tags/fork-ts-checker-webpack-plugin"},{label:"ts-loader",permalink:"/tags/ts-loader"},{label:"Webpack",permalink:"/tags/webpack"}],readingTime:.99,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"webpack-4-ts-loader-fork-ts-checker",title:"webpack 4 - ts-loader / fork-ts-checker-webpack-plugin betas",authors:"johnnyreilly",tags:["fork-ts-checker-webpack-plugin","ts-loader","Webpack"],hide_table_of_contents:!1},prevItem:{title:"Finding webpack 4 (use a Map)",permalink:"/finding-webpack-4-use-map"},nextItem:{title:"Auth0, TypeScript and ASP.NET Core",permalink:"/auth0-typescript-and-aspnet-core"}},p={authorsImageUrls:[void 0]},u=[{value:"<code>ts-loader</code>",id:"ts-loader",level:2},{value:"<code>fork-ts-checker-webpack-plugin</code>",id:"fork-ts-checker-webpack-plugin",level:2},{value:"PRs",id:"prs",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://medium.com/webpack/webpack-4-beta-try-it-today-6b1d27d7d7e2"}),"The first webpack 4 beta dropped on Friday"),". Very exciting! Following hot on the heels of those announcements, I've some news to share too. Can you guess what it is?"),(0,a.kt)("h2",o({},{id:"ts-loader"}),(0,a.kt)("inlineCode",{parentName:"h2"},"ts-loader")),(0,a.kt)("p",null,"Yes! The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader"}),(0,a.kt)("inlineCode",{parentName:"a"},"ts-loader"))," beta to work with webpack 4 is available. To get hold of the beta:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"When using ",(0,a.kt)("inlineCode",{parentName:"li"},"yarn"),": ",(0,a.kt)("inlineCode",{parentName:"li"},"yarn add ts-loader@4.0.0-beta.0 -D")),(0,a.kt)("li",{parentName:"ul"},"When using ",(0,a.kt)("inlineCode",{parentName:"li"},"npm"),": ",(0,a.kt)("inlineCode",{parentName:"li"},"npm install ts-loader@4.0.0-beta.0 -D"))),(0,a.kt)("p",null,"Remember to use this in concert with the webpack 4 beta. To see a working example take a look at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/ts-loader/tree/master/examples/vanilla"}),'the "vanilla" example'),"."),(0,a.kt)("h2",o({},{id:"fork-ts-checker-webpack-plugin"}),(0,a.kt)("inlineCode",{parentName:"h2"},"fork-ts-checker-webpack-plugin")),(0,a.kt)("p",null,"There's more! You may like to use the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"fork-ts-checker-webpack-plugin")),", (which goes lovely with ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," and a biscuit). There is a beta available for that too:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"When using ",(0,a.kt)("inlineCode",{parentName:"li"},"yarn"),": ",(0,a.kt)("inlineCode",{parentName:"li"},"yarn add johnnyreilly/fork-ts-checker-webpack-plugin#4.0.0-beta.1 -D")),(0,a.kt)("li",{parentName:"ul"},"When using ",(0,a.kt)("inlineCode",{parentName:"li"},"npm"),": ",(0,a.kt)("inlineCode",{parentName:"li"},"npm install johnnyreilly/fork-ts-checker-webpack-plugin#4.0.0-beta.1 -D"))),(0,a.kt)("p",null,"To see a working example take a look at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/ts-loader/tree/master/examples/fork-ts-checker"}),'the "fork-ts-checker" example'),"."),(0,a.kt)("h2",o({},{id:"prs"}),"PRs"),(0,a.kt)("p",null,"If you would like to track the progress of these betas then I encourage you to take a look at the PRs they were built from. The ts-loader PR can be found ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/710"}),"here"),". The fork-ts-checker-webpack-plugin PR can be found ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin/pull/93"}),"here"),"."),(0,a.kt)("p",null,"These are betas so things may change further; though hopefully not significantly."))}d.isMDXComponent=!0},56334:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"finding-webpack-4-use-map",title:"Finding webpack 4 (use a Map)",authors:"johnnyreilly",tags:["webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/finding-webpack-4-use-map",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-01-29-finding-webpack-4-use-map/index.md",source:"@site/blog/2018-01-29-finding-webpack-4-use-map/index.md",title:"Finding webpack 4 (use a Map)",description:"Update: 03/02/2018",date:"2018-01-29T00:00:00.000Z",formattedDate:"January 29, 2018",tags:[{label:"webpack",permalink:"/tags/webpack"}],readingTime:4.55,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"finding-webpack-4-use-map",title:"Finding webpack 4 (use a Map)",authors:"johnnyreilly",tags:["webpack"],hide_table_of_contents:!1},prevItem:{title:"ts-loader 4 / fork-ts-checker-webpack-plugin 0.4",permalink:"/ts-loader-400-fork-ts-checker-webpack"},nextItem:{title:"webpack 4 - ts-loader / fork-ts-checker-webpack-plugin betas",permalink:"/webpack-4-ts-loader-fork-ts-checker"}},p={authorsImageUrls:[void 0]},u=[{value:"Update: 03/02/2018",id:"update-03022018",level:2},{value:"webpack 4",id:"webpack-4",level:2},{value:"Plugins",id:"plugins",level:2},{value:"Custom Hooks",id:"custom-hooks",level:2},{value:"Loaders",id:"loaders",level:2},{value:"I need a <code>Map</code>",id:"i-need-a-map",level:2},{value:"Happy Porting!",id:"happy-porting",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"update-03022018"}),"Update: 03/02/2018"),(0,a.kt)("p",null,"Tobias Koppers has written a migration guide for plugins / loaders as well - take a read ",(0,a.kt)("a",o({parentName:"p"},{href:"https://medium.com/webpack/webpack-4-migration-guide-for-plugins-loaders-20a79b927202"}),"here"),". It's very useful."),(0,a.kt)("h2",o({},{id:"webpack-4"}),"webpack 4"),(0,a.kt)("p",null,"webpack 4 is on the horizon. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://medium.com/webpack/webpack-4-beta-try-it-today-6b1d27d7d7e2"}),"The beta dropped last Friday"),". So what do you, as a plugin / loader author need to do? What needs to change to make your loader / plugin webpack 4 friendly?"),(0,a.kt)("p",null,"This is a guide that should inform you about the changes you might need to make. It's based on my own experiences migrating ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader"}),(0,a.kt)("inlineCode",{parentName:"a"},"ts-loader"))," and the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"fork-ts-checker-webpack-plugin")),". If you'd like to see this in action then take a look at the PRs related to these. The ts-loader PR can be found ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/710"}),"here"),". The fork-ts-checker-webpack-plugin PR can be found ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin/pull/93"}),"here"),"."),(0,a.kt)("h2",o({},{id:"plugins"}),"Plugins"),(0,a.kt)("p",null,"One of the notable changes to webpack with v4 is the change to the plugin architecture. In terms of implications it's worth reading the comments made by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/wsokra"}),"Tobias Koppers"),(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/webpack/issues/6244#issuecomment-357502113"}),"here")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/webpack/issues/6064#issuecomment-349405474"}),"here"),"."),(0,a.kt)("p",null,"Previously, if your plugin was tapping into a compiler hook you'd write code that looked something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"this.compiler.plugin('watch-close', () => {\n  // do your thing here\n});\n")),(0,a.kt)("p",null,"With webpack 4 things done changed. You'd now write something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"this.compiler.hooks.watchClose.tap(\n  'name-to-identify-your-plugin-goes-here',\n  () => {\n    // do your thing here\n  }\n);\n")),(0,a.kt)("p",null,"Hopefully that's fairly clear; we're using the new ",(0,a.kt)("inlineCode",{parentName:"p"},"hooks")," property and tapping into our event of choice by ",(0,a.kt)("inlineCode",{parentName:"p"},"camelCasing")," what was previously ",(0,a.kt)("inlineCode",{parentName:"p"},"kebab-cased"),". So in this case ",(0,a.kt)("inlineCode",{parentName:"p"},"plugin('watch-close' =&gt; hooks.watchClose.tap"),"."),(0,a.kt)("p",null,"In the example above we were attaching to a sync hook. Now let's look at an async hook:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"this.compiler.plugin('watch-run', (watching, callback) => {\n  // do your thing here\n  callback();\n});\n")),(0,a.kt)("p",null,"This would change to be:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"this.compiler.hooks.watchRun.tapAsync(\n  'name-to-identify-your-plugin-goes-here',\n  (compiler, callback) => {\n    // do your thing here\n    callback();\n  }\n);\n")),(0,a.kt)("p",null,"Note that rather than using ",(0,a.kt)("inlineCode",{parentName:"p"},"tap")," here, we're using ",(0,a.kt)("inlineCode",{parentName:"p"},"tapAsync"),". If you're more into promises there's a ",(0,a.kt)("inlineCode",{parentName:"p"},"tapPromise")," you could use instead."),(0,a.kt)("h2",o({},{id:"custom-hooks"}),"Custom Hooks"),(0,a.kt)("p",null,"Prior to webpack 4, you could use your own custom hooks within your plugin. Usage was as simple as this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"this.compiler.applyPluginsAsync('fork-ts-checker-service-before-start', () => {\n  // do your thing here\n});\n")),(0,a.kt)("p",null,"You can still use custom hooks with webpack 4, but there's a little more ceremony involved. Essentially, you need to tell webpack up front what you're planning. Not hard, I promise you."),(0,a.kt)("p",null,"First of all, you'll need to add the package ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/tapable"}),(0,a.kt)("inlineCode",{parentName:"a"},"tapable"))," as a dependency. Then, inside your plugin you'll need to import the type of hook that you want to use; in the case of the ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin")," we used both a sync and an async hook:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const AsyncSeriesHook = require('tapable').AsyncSeriesHook;\nconst SyncHook = require('tapable').SyncHook;\n")),(0,a.kt)("p",null,"Then, inside your ",(0,a.kt)("inlineCode",{parentName:"p"},"apply")," method you need to register your hooks:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"if (\n  this.compiler.hooks.forkTsCheckerServiceBeforeStart ||\n  this.compiler.hooks.forkTsCheckerCancel ||\n  // other hooks...\n  this.compiler.hooks.forkTsCheckerEmit\n) {\n  throw new Error('fork-ts-checker-webpack-plugin hooks are already in use');\n}\nthis.compiler.hooks.forkTsCheckerServiceBeforeStart = new AsyncSeriesHook([]);\n\nthis.compiler.hooks.forkTsCheckerCancel = new SyncHook([]);\n// other sync hooks...\nthis.compiler.hooks.forkTsCheckerDone = new SyncHook([]);\n")),(0,a.kt)("p",null,"If you're interested in backwards compatibility then you should use the ",(0,a.kt)("inlineCode",{parentName:"p"},"_pluginCompat")," to wire that in:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"this.compiler._pluginCompat.tap('fork-ts-checker-webpack-plugin', (options) => {\n  switch (options.name) {\n    case 'fork-ts-checker-service-before-start':\n      options.async = true;\n      break;\n    case 'fork-ts-checker-cancel':\n    // other sync hooks...\n    case 'fork-ts-checker-done':\n      return true;\n  }\n  return undefined;\n});\n")),(0,a.kt)("p",null,"With your registration in place, you just need to replace your calls to ",(0,a.kt)("inlineCode",{parentName:"p"},"compiler.applyPlugins('sync-hook-name', ")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"compiler.applyPluginsAsync('async-hook-name', ")," with calls to ",(0,a.kt)("inlineCode",{parentName:"p"},"compiler.hooks.syncHookName.call(")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"compiler.hooks.asyncHookName.callAsync("),". So to migrate our ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-service-before-start")," hook we'd write:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"this.compiler.hooks.forkTsCheckerServiceBeforeStart.callAsync(() => {\n  // do your thing here\n});\n")),(0,a.kt)("h2",o({},{id:"loaders"}),"Loaders"),(0,a.kt)("p",null,"Loaders are impacted by the changes to the plugin architecture. Mostly this means applying the same plugin changes as discussed above. ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," hooks into 2 plugin events:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"loader._compiler.plugin('after-compile' /* callback goes here */);\nloader._compiler.plugin('watch-run' /* callback goes here */);\n")),(0,a.kt)("p",null,"With webpack 4 these become:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"loader._compiler.hooks.afterCompile.tapAsync(\n  'ts-loader' /* callback goes here */\n);\nloader._compiler.hooks.watchRun.tapAsync('ts-loader' /* callback goes here */);\n")),(0,a.kt)("p",null,"Note again, we're using the string ",(0,a.kt)("inlineCode",{parentName:"p"},'"ts-loader"')," to identify our loader."),(0,a.kt)("h2",o({},{id:"i-need-a-map"}),"I need a ",(0,a.kt)("inlineCode",{parentName:"h2"},"Map")),(0,a.kt)("p",null,"When I initially ported to webpack 4, ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," simply wasn't working. In the end I tied this down to problems in our ",(0,a.kt)("inlineCode",{parentName:"p"},"watch-run")," callback. There's 2 things of note here."),(0,a.kt)("p",null,"Firstly, as per ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/webpack/releases/tag/v4.0.0-beta.0"}),"the changelog"),", the ",(0,a.kt)("inlineCode",{parentName:"p"},"watch-run")," hook now has the ",(0,a.kt)("inlineCode",{parentName:"p"},"Compiler")," as the first parameter. Previously this was a subproperty on the supplied ",(0,a.kt)("inlineCode",{parentName:"p"},"watching")," parameter. So swapping over to use the compiler directly was necessary. Incidentally, ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," previously made use of the ",(0,a.kt)("inlineCode",{parentName:"p"},"watching.startTime")," property that was supplied in webpack's 1, 2 and 3. It seems to be coping without it; so hopefully that's fine."),(0,a.kt)("p",null,"Secondly, with webpack 4 it's \"ES2015 all the things!\" That is to say, with webpack now requiring a minimum of node 6, the codebase is free to start using ES2015. So if you're a consumer of ",(0,a.kt)("inlineCode",{parentName:"p"},"compiler.fileTimestamps")," (and ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," is) then it's time to make a change to cater for the different API that a ",(0,a.kt)("inlineCode",{parentName:"p"},"Map")," offers instead of indexing into an object literal with a ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," key."),(0,a.kt)("p",null,"What this means is, code that would once have looked like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"Object.keys(watching.compiler.fileTimestamps)\n  .filter(\n    (filePath) =>\n      watching.compiler.fileTimestamps[filePath] > lastTimes[filePath]\n  )\n  .forEach((filePath) => {\n    lastTimes[filePath] = times[filePath];\n    // ...\n  });\n")),(0,a.kt)("p",null,"Now looks more like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"for (const [filePath, date] of compiler.fileTimestamps) {\n  if (date > lastTimes.get(filePath)) {\n    continue;\n  }\n\n  lastTimes.set(filePath, date);\n  // ...\n}\n")),(0,a.kt)("h2",o({},{id:"happy-porting"}),"Happy Porting!"),(0,a.kt)("p",null,"I hope your own port to webpack 4 goes well. Do let me know if there's anything I've missed out / any inaccuracies etc and I'll update this guide."))}d.isMDXComponent=!0},88151:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"ts-loader-400-fork-ts-checker-webpack",title:"ts-loader 4 / fork-ts-checker-webpack-plugin 0.4",authors:"johnnyreilly",tags:["webpack","fork-ts-checker-webpack-plugin","ts-loader"],hide_table_of_contents:!1},s=void 0,l={permalink:"/ts-loader-400-fork-ts-checker-webpack",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-02-25-ts-loader-400-fork-ts-checker-webpack/index.md",source:"@site/blog/2018-02-25-ts-loader-400-fork-ts-checker-webpack/index.md",title:"ts-loader 4 / fork-ts-checker-webpack-plugin 0.4",description:"webpack 4 has shipped!",date:"2018-02-25T00:00:00.000Z",formattedDate:"February 25, 2018",tags:[{label:"webpack",permalink:"/tags/webpack"},{label:"fork-ts-checker-webpack-plugin",permalink:"/tags/fork-ts-checker-webpack-plugin"},{label:"ts-loader",permalink:"/tags/ts-loader"}],readingTime:.58,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"ts-loader-400-fork-ts-checker-webpack",title:"ts-loader 4 / fork-ts-checker-webpack-plugin 0.4",authors:"johnnyreilly",tags:["webpack","fork-ts-checker-webpack-plugin","ts-loader"],hide_table_of_contents:!1},prevItem:{title:"It's Not Dead: webpack and dead code elimination limitations",permalink:"/its-not-dead-webpack-and-dead-code"},nextItem:{title:"Finding webpack 4 (use a Map)",permalink:"/finding-webpack-4-use-map"}},p={authorsImageUrls:[void 0]},u=[{value:"<code>ts-loader</code>",id:"ts-loader",level:2},{value:"<code>fork-ts-checker-webpack-plugin</code>",id:"fork-ts-checker-webpack-plugin",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"webpack 4 has shipped!"),(0,a.kt)("h2",o({},{id:"ts-loader"}),(0,a.kt)("inlineCode",{parentName:"h2"},"ts-loader")),(0,a.kt)("p",null,"The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader"}),(0,a.kt)("inlineCode",{parentName:"a"},"ts-loader"))," 4 is available too. For details see our release ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/releases/tag/v4.0.0"}),"here"),". To start using ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," 4:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"When using ",(0,a.kt)("inlineCode",{parentName:"li"},"yarn"),": ",(0,a.kt)("inlineCode",{parentName:"li"},"yarn add ts-loader@4.1.0 -D")),(0,a.kt)("li",{parentName:"ul"},"When using ",(0,a.kt)("inlineCode",{parentName:"li"},"npm"),": ",(0,a.kt)("inlineCode",{parentName:"li"},"npm install ts-loader@4.1.0 -D"))),(0,a.kt)("p",null,"Remember to use this in concert with the webpack 4. To see a working example take a look at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/ts-loader/tree/master/examples/vanilla"}),'the "vanilla" example'),"."),(0,a.kt)("h2",o({},{id:"fork-ts-checker-webpack-plugin"}),(0,a.kt)("inlineCode",{parentName:"h2"},"fork-ts-checker-webpack-plugin")),(0,a.kt)("p",null,"There's more! You may like to use the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"fork-ts-checker-webpack-plugin")),", (aka the ts-loader turbo-booster). The webpack compatible version has been ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin/releases/tag/v0.4.1"}),"released to npm as 0.4.1"),":"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"When using ",(0,a.kt)("inlineCode",{parentName:"li"},"yarn"),": ",(0,a.kt)("inlineCode",{parentName:"li"},"yarn add fork-ts-checker-webpack-plugin@0.4.1 -D")),(0,a.kt)("li",{parentName:"ul"},"When using ",(0,a.kt)("inlineCode",{parentName:"li"},"npm"),": ",(0,a.kt)("inlineCode",{parentName:"li"},"npm install fork-ts-checker-webpack-plugin@0.4.1 -D"))),(0,a.kt)("p",null,"To see a working example take a look at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/ts-loader/tree/master/examples/fork-ts-checker"}),'the "fork-ts-checker" example'),"."))}d.isMDXComponent=!0},59683:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"its-not-dead-webpack-and-dead-code",title:"It's Not Dead: webpack and dead code elimination limitations",authors:"johnnyreilly",tags:["webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/its-not-dead-webpack-and-dead-code",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-03-07-its-not-dead-webpack-and-dead-code/index.md",source:"@site/blog/2018-03-07-its-not-dead-webpack-and-dead-code/index.md",title:"It's Not Dead: webpack and dead code elimination limitations",description:"Webpack has long supported the notion of dead code elimination. webpack facilitates this through use of the DefinePlugin. The compile time value of process.env.NODE_ENV is set either to 'production' or something else. If it's set to 'production' then some dead code hackery can happen. Libraries like React make use of this to serve up different, and crucially smaller, production builds.",date:"2018-03-07T00:00:00.000Z",formattedDate:"March 7, 2018",tags:[{label:"webpack",permalink:"/tags/webpack"}],readingTime:2.125,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"its-not-dead-webpack-and-dead-code",title:"It's Not Dead: webpack and dead code elimination limitations",authors:"johnnyreilly",tags:["webpack"],hide_table_of_contents:!1},prevItem:{title:"Uploading Images to Cloudinary with the Fetch API",permalink:"/uploading-images-to-cloudinary-with-fetch"},nextItem:{title:"ts-loader 4 / fork-ts-checker-webpack-plugin 0.4",permalink:"/ts-loader-400-fork-ts-checker-webpack"}},p={authorsImageUrls:[void 0]},u=[{value:"Limitations",id:"limitations",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Webpack has long supported the notion of dead code elimination. webpack facilitates this through use of the ",(0,a.kt)("inlineCode",{parentName:"p"},"DefinePlugin"),". The compile time value of ",(0,a.kt)("inlineCode",{parentName:"p"},"process.env.NODE_ENV")," is set either to ",(0,a.kt)("inlineCode",{parentName:"p"},"'production'")," or something else. If it's set to ",(0,a.kt)("inlineCode",{parentName:"p"},"'production'")," then some dead code hackery can happen. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://reactjs.org/docs/optimizing-performance.html#webpack"}),"Libraries like React make use of this to serve up different, and crucially smaller, production builds.")),(0,a.kt)("p",null,"Every now and then you can be surprised. Your assumptions turn out to be wrong."),(0,a.kt)("p",null,"A (pre-webpack 4) production config file will typically contain this code:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"new webpack.DefinePlugin({\n    'process.env.NODE_ENV': JSON.stringify('production')\n}),\nnew UglifyJSPlugin(),\n")),(0,a.kt)("p",null,"The result of the above config is that webpack will inject the value 'production' everywhere in the codebase where a ",(0,a.kt)("inlineCode",{parentName:"p"},"process.env.NODE_ENV")," can be found. (In fact, as of webpack 4 setting this magic value is out-of-the-box behaviour for Production mode; yay the #0CJS!)"),(0,a.kt)("p",null,"What this means is, if you've written:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"if (process.env.NODE_ENV !== 'production') {\n  // Do a development mode only thing\n}\n")),(0,a.kt)("p",null,"webpack can and will turn this into"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"if ('production' !== 'production') {\n  // Do a development mode only thing\n}\n")),(0,a.kt)("p",null,"The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack-contrib/uglifyjs-webpack-plugin"}),"UglifyJSPlugin")," is there to minify the JavaScript in your bundles. As an added benefit, this plugin is smart enough to know that ",(0,a.kt)("inlineCode",{parentName:"p"},"'production' !== 'production'")," is always ",(0,a.kt)("inlineCode",{parentName:"p"},"false"),". And because it's smart, it chops the code. Dead code elimated."),(0,a.kt)("p",null,"You can read more about this ",(0,a.kt)("a",o({parentName:"p"},{href:"https://webpack.js.org/guides/production/#specify-the-environment"}),"in the webpack docs"),"."),(0,a.kt)("h2",o({},{id:"limitations"}),"Limitations"),(0,a.kt)("p",null,"Given what I've said, consider the following code:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"export class Config {\n  // Other properties\n\n  get isDevelopment() {\n    return process.env.NODE_ENV !== 'production';\n  }\n}\n")),(0,a.kt)("p",null,"This is a config class that exposes the expression ",(0,a.kt)("inlineCode",{parentName:"p"},"process.env.NODE_ENV !== 'production'")," with the friendly name ",(0,a.kt)("inlineCode",{parentName:"p"},"isDevelopment"),". You'd think that dead code elimination would be your friend here. It's not."),(0,a.kt)("p",null,"My personal expection was that dead code elimination would treat ",(0,a.kt)("inlineCode",{parentName:"p"},"Config.isDevelopment")," and the expression ",(0,a.kt)("inlineCode",{parentName:"p"},"process.env.NODE_ENV !== 'production'")," identically. Because they're identical."),(0,a.kt)("p",null,"However, this turns out not to be the case. Dead code elimination works just as you would hope when using the expression ",(0,a.kt)("inlineCode",{parentName:"p"},"process.env.NODE_ENV !== 'production'")," directly in code. However webpack ",(0,a.kt)("strong",{parentName:"p"},"only")," performs dead code elimination for the ",(0,a.kt)("strong",{parentName:"p"},"direct")," usage of the ",(0,a.kt)("inlineCode",{parentName:"p"},"process.env.NODE_ENV !== 'production'")," expression. I'll say that again: if you want dead code elimination then use the injected values; not an encapsulated version of them. It turns out you cannot rely on webpack flowing values through and performing dead code elimination on that basis."),(0,a.kt)("p",null,"The TL;DR: if you want to elimate dead code then ","*","always","*"," use ",(0,a.kt)("inlineCode",{parentName:"p"},"process.env.NODE_ENV !== 'production'"),"; don't abstract it. It doesn't work."),(0,a.kt)("p",null,"UglifyJS is smart. But not that smart."))}d.isMDXComponent=!0},30196:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"uploading-images-to-cloudinary-with-fetch",title:"Uploading Images to Cloudinary with the Fetch API",authors:"johnnyreilly",tags:["React","Cloudinary"],hide_table_of_contents:!1},s=void 0,l={permalink:"/uploading-images-to-cloudinary-with-fetch",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-03-25-uploading-images-to-cloudinary-with-fetch/index.md",source:"@site/blog/2018-03-25-uploading-images-to-cloudinary-with-fetch/index.md",title:"Uploading Images to Cloudinary with the Fetch API",description:"I was recently checking out a very good post which explained how to upload images using React Dropzone and SuperAgent to Cloudinary.",date:"2018-03-25T00:00:00.000Z",formattedDate:"March 25, 2018",tags:[{label:"React",permalink:"/tags/react"},{label:"Cloudinary",permalink:"/tags/cloudinary"}],readingTime:1.03,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"uploading-images-to-cloudinary-with-fetch",title:"Uploading Images to Cloudinary with the Fetch API",authors:"johnnyreilly",tags:["React","Cloudinary"],hide_table_of_contents:!1},prevItem:{title:"It's Not Dead 2: mobx-react-devtools and the undead",permalink:"/its-not-dead-2-mobx-react-devtools-and-the-undead"},nextItem:{title:"It's Not Dead: webpack and dead code elimination limitations",permalink:"/its-not-dead-webpack-and-dead-code"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I was recently checking out a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://css-tricks.com/image-upload-manipulation-react/"}),"very good post")," which explained how to upload images using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/react-dropzone/react-dropzone"}),"React Dropzone")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/visionmedia/superagent"}),"SuperAgent")," to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://cloudinary.com/"}),"Cloudinary"),"."),(0,a.kt)("p",null,"It's a brilliant post; you should totally read it. Even if you hate images, uploads and JavaScript. However, there was one thing in there that I didn't want; SuperAgent. It's lovely but I'm a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API"}),"Fetch")," guy. That's just how I roll. The question is, how do I do the below using Fetch?"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"handleImageUpload(file) {\n    let upload = request.post(CLOUDINARY_UPLOAD_URL)\n                     .field('upload_preset', CLOUDINARY_UPLOAD_PRESET)\n                     .field('file', file);\n\n    upload.end((err, response) => {\n      if (err) {\n        console.error(err);\n      }\n\n      if (response.body.secure_url !== '') {\n        this.setState({\n          uploadedFileCloudinaryUrl: response.body.secure_url\n        });\n      }\n    });\n  }\n")),(0,a.kt)("p",null,"Well it actually took me longer to work out than I'd like to admit. But now I have, let me save you the bother. To do the above using Fetch you just need this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"handleImageUpload(file) {\n    const formData = new FormData();\n    formData.append(\"file\", file);\n    formData.append(\"upload_preset\", CLOUDINARY_UPLOAD_PRESET); // Replace the preset name with your own\n\n    fetch(CLOUDINARY_UPLOAD_URL, {\n      method: 'POST',\n      body: formData\n    })\n      .then(response => response.json())\n      .then(data => {\n        if (data.secure_url !== '') {\n          this.setState({\n            uploadedFileCloudinaryUrl: data.secure_url\n          });\n        }\n      })\n      .catch(err => console.error(err))\n  }\n")),(0,a.kt)("p",null,"To get a pre-canned project to try this with take a look at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/damonbauer/react-cloudinary"}),"Damon's repo"),"."))}d.isMDXComponent=!0},93013:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"its-not-dead-2-mobx-react-devtools-and-the-undead",title:"It's Not Dead 2: mobx-react-devtools and the undead",authors:"johnnyreilly",tags:["uglifyjs","mobx","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/its-not-dead-2-mobx-react-devtools-and-the-undead",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-03-26-its-not-dead-2-mobx-react-devtools-and-the-undead/index.md",source:"@site/blog/2018-03-26-its-not-dead-2-mobx-react-devtools-and-the-undead/index.md",title:"It's Not Dead 2: mobx-react-devtools and the undead",description:"I spent today digging through our webpack 4 config trying to work out why a production bundle contained code like this:",date:"2018-03-26T00:00:00.000Z",formattedDate:"March 26, 2018",tags:[{label:"uglifyjs",permalink:"/tags/uglifyjs"},{label:"mobx",permalink:"/tags/mobx"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:2.04,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"its-not-dead-2-mobx-react-devtools-and-the-undead",title:"It's Not Dead 2: mobx-react-devtools and the undead",authors:"johnnyreilly",tags:["uglifyjs","mobx","webpack"],hide_table_of_contents:!1},prevItem:{title:"Using Reflection to Identify Unwanted Dependencies",permalink:"/using-reflection-to-identify-unwanted-dependencies"},nextItem:{title:"Uploading Images to Cloudinary with the Fetch API",permalink:"/uploading-images-to-cloudinary-with-fetch"}},p={authorsImageUrls:[void 0]},u=[{value:"Who Betrayed Me?",id:"who-betrayed-me",level:2},{value:"Perhaps We Change the Advice?",id:"perhaps-we-change-the-advice",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I spent today digging through our webpack 4 config trying to work out why a production bundle contained code like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),'if("production"!==e.env.NODE_ENV){//...\n')),(0,a.kt)("p",null,"My expectation was that with webpack 4 and ",(0,a.kt)("inlineCode",{parentName:"p"},"'mode': 'production'")," this meant that behind the scenes all ",(0,a.kt)("inlineCode",{parentName:"p"},"process.env.NODE_ENV")," statements should be converted to ",(0,a.kt)("inlineCode",{parentName:"p"},"'production'"),". Subsequently Uglify would automatically get its groove on with the resulting ",(0,a.kt)("inlineCode",{parentName:"p"},'if("production"!=="production") ...')," and et voil\xe0!... Strip the dead code."),(0,a.kt)("p",null,"It seemed that was not the case. I was seeing (regrettably) undead code. And who here actually likes the undead?"),(0,a.kt)("h2",o({},{id:"who-betrayed-me"}),"Who Betrayed Me?"),(0,a.kt)("p",null,"My beef was with webpack. It done did me wrong. Or... So I thought. webpack did nothing wrong. It is pure and good and unjustly complained about. It was my other love: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/mobxjs/mobx"}),"mobx"),". Or to be more specific: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/mobxjs/mobx-react-devtools"}),"mobx-react-devtools"),"."),(0,a.kt)("p",null,"It turns out that the way you use ",(0,a.kt)("inlineCode",{parentName:"p"},"mobx-react-devtools")," reliably makes the difference. It's the cause of the stray ",(0,a.kt)("inlineCode",{parentName:"p"},'("production"!==e.env.NODE_ENV)')," statements in our bundle output. After a ",(0,a.kt)("strong",{parentName:"p"},"long")," time I happened upon ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/mobxjs/mobx-react-devtools/issues/66#issuecomment-365151531"}),"this issue")," which contained a gem by one ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/gilesbutler"}),"Giles Butler"),". His suggested way to reference ",(0,a.kt)("inlineCode",{parentName:"p"},"mobx-react-devtools")," is (as far as I can tell) the solution!"),(0,a.kt)("p",null,"On a dummy project I had the ",(0,a.kt)("inlineCode",{parentName:"p"},"mobx-react-devtools")," advised code in place:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"import * as React from 'react';\nimport { Layout } from './components/layout';\nimport DevTools from 'mobx-react-devtools';\n\nexport const App: React.SFC<{}> = (_props) => (\n  <div className=\"ui container\">\n    <Layout />\n    {process.env.NODE_ENV !== 'production' ? (\n      <DevTools position={{ bottom: 20, right: 20 }} />\n    ) : null}\n  </div>\n);\n")),(0,a.kt)("p",null,"With this I had a build size of 311kb. Closer examination of my bundle revealed that my ",(0,a.kt)("inlineCode",{parentName:"p"},"bundle.js")," was riddled with ",(0,a.kt)("inlineCode",{parentName:"p"},'("production"!==e.env.NODE_ENV)')," statements. Sucks, right?"),(0,a.kt)("p",null,"Then I tried this instead:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"import * as React from 'react';\nimport { Layout } from './components/layout';\nconst { Fragment } = React;\n\nconst DevTools =\n  process.env.NODE_ENV !== 'production'\n    ? require('mobx-react-devtools').default\n    : Fragment;\n\nexport const App: React.SFC<{}> = (_props) => (\n  <div className=\"ui container\">\n    <Layout />\n    <DevTools position={{ bottom: 20, right: 20 }} />\n  </div>\n);\n")),(0,a.kt)("p",null,"With this approach I got a build size of 191kb. This was thanks to the dead code being actually stripped. That's a saving of 120kb!"),(0,a.kt)("h2",o({},{id:"perhaps-we-change-the-advice"}),"Perhaps We Change the Advice?"),(0,a.kt)("p",null,"There's a suggestion that the README should be changed to reflect this advice - until that happens, I wanted to share this solution. Also, I've a nagging feeling that I've missed something pertinent here; if someone knows something that I should... Tell me please!"))}d.isMDXComponent=!0},49709:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"using-reflection-to-identify-unwanted-dependencies",title:"Using Reflection to Identify Unwanted Dependencies",authors:"johnnyreilly",tags:[".NET"],hide_table_of_contents:!1},s=void 0,l={permalink:"/using-reflection-to-identify-unwanted-dependencies",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-04-28-using-reflection-to-identify-unwanted-dependencies/index.md",source:"@site/blog/2018-04-28-using-reflection-to-identify-unwanted-dependencies/index.md",title:"Using Reflection to Identify Unwanted Dependencies",description:"I having a web app which is fairly complex. It's made up of services, controllers and all sorts of things. So far, so unremarkable. However, I needed to ensure that the controllers did not attempt to access the database via any of their dependencies. Or their dependencies, dependencies. Or their dependencies. You get my point.",date:"2018-04-28T00:00:00.000Z",formattedDate:"April 28, 2018",tags:[{label:".NET",permalink:"/tags/net"}],readingTime:2.545,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"using-reflection-to-identify-unwanted-dependencies",title:"Using Reflection to Identify Unwanted Dependencies",authors:"johnnyreilly",tags:[".NET"],hide_table_of_contents:!1},prevItem:{title:"Compromising: A Guide for Developers",permalink:"/compromising-guide-for-developers"},nextItem:{title:"It's Not Dead 2: mobx-react-devtools and the undead",permalink:"/its-not-dead-2-mobx-react-devtools-and-the-undead"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I having a web app which is fairly complex. It's made up of services, controllers and all sorts of things. So far, so unremarkable. However, I needed to ensure that the controllers did not attempt to access the database via any of their dependencies. Or their dependencies, dependencies. Or their dependencies. You get my point."),(0,a.kt)("p",null,"The why is not important here. What's significant is the idea of walking a dependency tree and identifying, via a reflection based test, when such unwelcome dependencies occur, and where."),(0,a.kt)("p",null,"When they do occur the test should fail, like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-sh"}),"[xUnit.net 00:00:01.6766691]     My.Web.Tests.HousekeepingTests.My_Api_Controllers_do_not_depend_upon_the_database [FAIL]\n[xUnit.net 00:00:01.6782295]       Expected dependsUponTheDatabase.Any() to be False because My.Api.Controllers.ThingyController depends upon the database through My.Data.Services.OohItsAService, but found True.\n")),(0,a.kt)("p",null,"What follows is an example of how you can accomplish this. It is exceedingly far from the most beautiful code I've ever written. But it works. One reservation I have about it is that it doesn't use the Dependency Injection mechanism used at runtime (AutoFac). If I had more time I would amend the code to use that instead; it would become an easier test to read if I did. Also it would better get round the limitations of the code below. Essentially the approach relies on the assumption of there being 1 interface and 1 implementation. That's often not true in complex systems. But this is good enough to roll with for now."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Reflection;\nusing FluentAssertions;\nusing My.Data;\nusing My.Web.Controllers;\nusing Xunit;\n\nnamespace My.Web.Tests {\n    public class OiYouThereGetOutTests {\n        [Fact]\n        public void My_Controllers_do_not_depend_upon_the_database() {\n            var myConcreteTypes = GetMyAssemblies()\n                .SelectMany(assembly => assembly.GetTypes())\n                .ToArray();\n\n            var controllerTypes = typeof(My.Web.Startup).Assembly.GetTypes()\n                .Where(myWebType =>\n                    myWebType != typeof(Microsoft.AspNetCore.Mvc.Controller) &&\n                    typeof(Microsoft.AspNetCore.Mvc.Controller).IsAssignableFrom(myWebType));\n\n            foreach (var controllerType in controllerTypes) {\n                var allTheTypes = GetDependentTypes(controllerType, myConcreteTypes);\n                allTheTypes.Count.Should().BeGreaterThan(0);\n                var dependsUponTheDatabase = allTheTypes.Where(keyValue => keyValue.Key == typeof(MyDbContext));\n                dependsUponTheDatabase.Any().Should().Be(false, because: $"{controllerType} depends upon the database through {string.Join(", ", dependsUponTheDatabase.Select(dod => dod.Value))}");\n            }\n        }\n\n        private static Dictionary<Type, Type> GetDependentTypes(Type type, Type[] typesToCheck, Dictionary<Type, Type> typesSoFar = null) {\n            var types = typesSoFar ?? new Dictionary<Type, Type>();\n            foreach (var constructor in type.GetConstructors().Where(ctor => ctor.IsPublic)) {\n                foreach (var parameter in constructor.GetParameters()) {\n                    if (parameter.ParameterType.IsInterface) {\n                        if (parameter.ParameterType.IsGenericType) {\n                            foreach (var genericType in parameter.ParameterType.GenericTypeArguments) {\n                                AddIfMissing(types, genericType, type);\n                            }\n                        } else {\n                            var typesImplementingInterface = TypesImplementingInterface(parameter.ParameterType, typesToCheck);\n                            foreach (var typeImplementingInterface in typesImplementingInterface) {\n                                AddIfMissing(types, typeImplementingInterface, type);\n                                AddIfMissing(types, GetDependentTypes(typeImplementingInterface, typesToCheck, types).Keys.ToList(), type);\n                            }\n                        }\n                    } else {\n                        AddIfMissing(types, parameter.ParameterType, type);\n                        AddIfMissing(types, GetDependentTypes(parameter.ParameterType, typesToCheck, types).Keys.ToList(), type);\n                    }\n                }\n            }\n            return types;\n        }\n\n        private static void AddIfMissing(Dictionary<Type, Type> types, Type typeToAdd, Type parentType) {\n            if (!types.Keys.Contains(typeToAdd))\n                types.Add(typeToAdd, parentType);\n        }\n\n        private static void AddIfMissing(Dictionary<Type, Type> types, IList<Type> typesToAdd, Type parentType) {\n            foreach (var typeToAdd in typesToAdd) {\n                AddIfMissing(types, typeToAdd, parentType);\n            }\n        }\n\n        private static Type[] TypesImplementingInterface(Type interfaceType, Type[] typesToCheck) =>\n            typesToCheck.Where(type => !type.IsInterface && interfaceType.IsAssignableFrom(type)).ToArray();\n\n        private static bool IsRealClass(Type testType) =>\n            testType.IsAbstract == false &&\n            testType.IsGenericType == false &&\n            testType.IsGenericTypeDefinition == false &&\n            testType.IsInterface == false;\n\n        private static Assembly[] GetMyAssemblies() =>\n            AppDomain\n            .CurrentDomain\n            .GetAssemblies()\n            // Not strictly necessary but it reduces the amount of types returned\n            .Where(assembly => assembly.GetName().Name.StartsWith("My"))\n            .ToArray();\n    }\n}\n')))}d.isMDXComponent=!0},85003:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"compromising-guide-for-developers",title:"Compromising: A Guide for Developers",authors:"johnnyreilly",hide_table_of_contents:!1},s=void 0,l={permalink:"/compromising-guide-for-developers",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-05-13-compromising-guide-for-developers/index.md",source:"@site/blog/2018-05-13-compromising-guide-for-developers/index.md",title:"Compromising: A Guide for Developers",description:"It is a truth universally acknowledged, that a single developer, will not be short of an opinion. Opinions on tabs vs spaces. Upon OOP vs FP. Upon classes vs functions. Just opinions, opinions, opinions. Opinions that are felt with all the sincerity of a Witchfinder General. And, alas, not always the same level of empathy.",date:"2018-05-13T00:00:00.000Z",formattedDate:"May 13, 2018",tags:[],readingTime:2.92,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"compromising-guide-for-developers",title:"Compromising: A Guide for Developers",authors:"johnnyreilly",hide_table_of_contents:!1},prevItem:{title:"VSTS... YAML up!",permalink:"/vsts-yaml-up"},nextItem:{title:"Using Reflection to Identify Unwanted Dependencies",permalink:"/using-reflection-to-identify-unwanted-dependencies"}},p={authorsImageUrls:[void 0]},u=[{value:"On Compromise",id:"on-compromise",level:2},{value:"Weighting Opinion",id:"weighting-opinion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"It is a truth universally acknowledged, that a single developer, will not be short of an opinion. Opinions on tabs vs spaces. Upon OOP vs FP. Upon ",(0,a.kt)("inlineCode",{parentName:"p"},"class"),"es vs ",(0,a.kt)("inlineCode",{parentName:"p"},"function"),"s. Just opinions, opinions, opinions. Opinions that are felt with all the sincerity of a Witchfinder General. And, alas, not always the same level of empathy."),(0,a.kt)("p",null,"Given the wealth of strongly felt desires, it's kind of amazing that developers ever manage to work together. It's rare to find a fellow dev that agrees entirely with your predilections. So how do people ever get past the \"you don't use semi-colons; what's wrong with you\"? Well, not easily to be honest. It involves compromise."),(0,a.kt)("h2",o({},{id:"on-compromise"}),"On Compromise"),(0,a.kt)("p",null,"We've all been in the position where we realise that there's something we don't like in a codebase. The ordering of members in a ",(0,a.kt)("inlineCode",{parentName:"p"},"class"),", naming conventions, a lack of tests... Something."),(0,a.kt)("p",null,"Then comes the moment of trepidation. You suggest a change. You suggest difference. It's time to find out if you're working with psychopaths. It's not untypical to find that you just have to go with the flow."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},'"You\'ve been using 3 spaces?"'),(0,a.kt)("li",{parentName:"ul"},'"Yes we use 3 spaces."'),(0,a.kt)("li",{parentName:"ul"},'"Okay... So we\'ll be using 3 spaces..." ',"[backs away carefully]")),(0,a.kt)("p",null,"I've been in this position so many times I've learned to adapt. It helps that I'm a malleable sort anyway. But what if there were another way?"),(0,a.kt)("h2",o({},{id:"weighting-opinion"}),"Weighting Opinion"),(0,a.kt)("p",null,"Sometimes your opinion is... Well.... Just an opinion. Other opinions are legitimate. At least in theory. If you can acknowledge that, you already have a level of self knowledge not gifted to all in the dev community. If you're able to get that far I feel there's something you might want to consider."),(0,a.kt)("p",null,"Let me frame this up: there's a choice to be made around an approach that could be used in a codebase. There are 2 camps in the team; 1 camp advocating for 1 approach. The other for a different approach. Either one is functionally legitimate. They work. It's just a matter of preference of choice. How do you choose now? Let's look at a technique for splitting the difference."),(0,a.kt)("p",null,"Voting helps. But let's say 50% of the team wants 1 approach and 50% wants the other. What then? Or, to take a more interesting idea, what say 25% want 1 approach and 75% want the other? If it's just 1 person, 1 vote then the 75% wins and that's it."),(0,a.kt)("p",null,"But before we all move on, let's consider another factor. How much do people care? What if the 25% are really, really invested in the choice they're advocating for and the 75% just have a mild preference? From that point forwards the 25% are likely going to be less happy. Maybe they'll even burn inside. They're certainly going to be less productive."),(0,a.kt)("p",null,'It\'s because of situations like this that weighting votes becomes useful. Out of 5, how much do you care? If one person cares "5 out of 5" and the other three are "1 out of 5".... Well go with the 25% It matters to them and that it matters to them should matter to you.'),(0,a.kt)("p",null,"I'll contend that rolling like this makes for more content, happier and more productive teams. Making strength of feeling a factor in choices reduces friction and increases the peace."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(81430).Z,width:"640",height:"427"})),(0,a.kt)("p",null,"I've only recently discovered this technique and I can't claim credit for it. I learned it from the awesome ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/foldr"}),"Jamie McCrindle"),". I commend to you! Be happier!"))}d.isMDXComponent=!0},65041:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"vsts-yaml-up",title:"VSTS... YAML up!",authors:"johnnyreilly",tags:["yaml","vsts","travis","AppVeyor"],hide_table_of_contents:!1},s=void 0,l={permalink:"/vsts-yaml-up",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-06-16-vsts-yaml-up/index.md",source:"@site/blog/2018-06-16-vsts-yaml-up/index.md",title:"VSTS... YAML up!",description:"For the longest time I've been using the likes of Travis and AppVeyor to build open source projects that I work on. They rock. I've also recently been dipping my toes back in the water of Visual Studio Team Services. VSTS offers a whole stack of stuff, but my own area of interest has been the Continuous Integration / Continuous Deployment offering.",date:"2018-06-16T00:00:00.000Z",formattedDate:"June 16, 2018",tags:[{label:"yaml",permalink:"/tags/yaml"},{label:"vsts",permalink:"/tags/vsts"},{label:"travis",permalink:"/tags/travis"},{label:"AppVeyor",permalink:"/tags/app-veyor"}],readingTime:4.42,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"vsts-yaml-up",title:"VSTS... YAML up!",authors:"johnnyreilly",tags:["yaml","vsts","travis","AppVeyor"],hide_table_of_contents:!1},prevItem:{title:"VSTS and EF Core Migrations",permalink:"/vsts-and-ef-core-migrations"},nextItem:{title:"Compromising: A Guide for Developers",permalink:"/compromising-guide-for-developers"}},p={authorsImageUrls:[void 0]},u=[{value:"The New Dawn",id:"the-new-dawn",level:2},{value:"It Begins!",id:"it-begins",level:2},{value:"A Bump in the Road",id:"a-bump-in-the-road",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"For the longest time I've been using the likes of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://travis-ci.org/"}),"Travis")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.appveyor.com/"}),"AppVeyor")," to build open source projects that I work on. They rock. I've also recently been dipping my toes back in the water of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.visualstudio.com/team-services/"}),"Visual Studio Team Services"),". VSTS offers a whole stack of stuff, but my own area of interest has been the Continuous Integration / Continuous Deployment offering."),(0,a.kt)("p",null,"Historically I have been underwhelmed by the CI proposition of Team Foundation Server / VSTS. It was difficult to debug, difficult to configure, difficult to understand. If it worked... Great! If it didn't (and it often didn't), you were toast. But things done changed! I don't know when it happened, but VSTS is now super configurable. You add tasks / configure them, build and you're done! It's really nice."),(0,a.kt)("p",null,"However, there's been something I've been missing from Travis, AppVeyor et al. Keeping my build script with my code. Travis has ",(0,a.kt)("inlineCode",{parentName:"p"},".travis.yml"),", AppVeyor has ",(0,a.kt)("inlineCode",{parentName:"p"},"appveyor.yml"),". VSTS, what's up?"),(0,a.kt)("h2",o({},{id:"the-new-dawn"}),"The New Dawn"),(0,a.kt)("p",null,"Up until now, really not much. It just wasn't possible. Until it was:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"If you prefer a build definition in YAML then we\u2019re currently hard at work on that. You can enable it as a preview feature: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://t.co/hau9Sv8brf"}),"https://t.co/hau9Sv8brf")),(0,a.kt)("p",{parentName:"blockquote"},"\u2014 Martin Woodward (@martinwoodward) ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/martinwoodward/status/970250739510534144?ref_src=twsrc%5Etfw"}),"March 4, 2018"))),(0,a.kt)("script",{async:"",src:"https://platform.twitter.com/widgets.js",charSet:"utf-8"}),(0,a.kt)("p",null,"When I started testing it out I found things to like and some things I didn't understand. Crucially, my CI now builds based upon ",(0,a.kt)("inlineCode",{parentName:"p"},".vsts-ci.yml"),". YAML baby!"),(0,a.kt)("h2",o({},{id:"it-begins"}),"It Begins!"),(0,a.kt)("p",null,'You can get to "Hello World" by looking at ',(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/vsts/pipelines/build/yaml?view=vsts"}),"the docs here")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/vsts-agent/blob/master/docs/preview/yamlgettingstarted/index.md"}),"the examples here"),". But what you really want is your existing build, configured in the UI, exported to YAML. That doesn't seem to quite exist, but there's something that gets you part way. Take a look:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"screenshot of restore task in VSTS",src:n(75673).Z,width:"1600",height:"635"})),(0,a.kt)("p",null,'If you notice, in the top right of the screen, each task now allows you click on a new "View YAML" button. It\'s kinda ',(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Ronseal"}),"Ronseal"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of copy to clipboard in VSTS",src:n(16585).Z,width:"1224",height:"1053"})),(0,a.kt)("p",null,"Using this hotness you can build yourself a ",(0,a.kt)("inlineCode",{parentName:"p"},".vsts-ci.yml")," file task by task."),(0,a.kt)("h2",o({},{id:"a-bump-in-the-road"}),"A Bump in the Road"),(0,a.kt)("p",null,"If you look closely at the message above you'll see there's a message about an undefined variable."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"#Your build definition references an undefined variable named \u2018Parameters.RestoreBuildProjects\u2019. Create or edit the build definition for this YAML file, define the variable on the Variables tab. See https://go.microsoft.com/fwlink/?linkid=865972\nsteps:\n  - task: DotNetCoreCLI@2\n    displayName: Restore\n    inputs:\n      command: restore\n      projects: '$(Parameters.RestoreBuildProjects)'\n")),(0,a.kt)("p",null,"Try as I might, I couldn't locate ",(0,a.kt)("inlineCode",{parentName:"p"},"Parameters.RestoreBuildProjects"),". So no working CI build for me. Then I remembered ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/zerdos"}),"Zoltan Erdos"),". He's hard to forget. Or rather, I remembered an idea of his which I will summarise thusly: \"Have a ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," in the root of your repo, use the ",(0,a.kt)("inlineCode",{parentName:"p"},"scripts"),' for individual tasks and you have a cross platform task runner".'),(0,a.kt)("p",null,"This is a powerful idea and one I decided to put to work. My project is React and TypeScript on the front end, and ASP.Net Core on the back. I wanted a ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," in the root of the repo which I could install dependencies, build, test and publish my whole app. I could call into that from my ",(0,a.kt)("inlineCode",{parentName:"p"},".vsts-ci.yml")," file. Something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "name": "my-amazing-project",\n  "version": "1.0.0",\n  "author": "John Reilly <johnny_reilly@hotmail.com>",\n  "license": "MIT",\n  "private": true,\n  "scripts": {\n    "preinstall": "yarn run install:clientapp && yarn run install:web",\n    "install:clientapp": "cd MyAmazingProject.ClientApp && yarn install",\n    "install:web": "dotnet restore",\n    "prebuild": "yarn install",\n    "build": "yarn run build:clientapp && yarn run build:web",\n    "build:clientapp": "cd MyAmazingProject.ClientApp && yarn run build",\n    "build:web": "dotnet build --configuration Release",\n    "postbuild": "yarn test",\n    "test": "yarn run test:clientapp && yarn run test:web",\n    "test:clientapp": "cd MyAmazingProject.ClientApp && yarn test",\n    "test:web": "cd MyAmazingProject.Web.Tests && dotnet test",\n    "publish:web": "cd MyAmazingProject.Web && dotnet publish MyAmazingProject.Web.csproj --configuration Release"\n  }\n}\n</johnny_reilly@hotmail.com>\n')),(0,a.kt)("p",null,'It doesn\'t matter if I have "an undefined variable named \u2018Parameters.RestoreBuildProjects\u2019". I now have no need to use all the individual tasks in a build. I can convert them into a couple of scripts in my ',(0,a.kt)("inlineCode",{parentName:"p"},"package.json"),". So here's where I've ended up for now. I've a ",(0,a.kt)("inlineCode",{parentName:"p"},".vsts-ci.yml")," file which looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"queue: Hosted VS2017\n\nsteps:\n  - task: geeklearningio.gl-vsts-tasks-yarn.yarn-installer-task.YarnInstaller@2\n    displayName: install yarn itself\n    inputs:\n      checkLatest: true\n  - task: geeklearningio.gl-vsts-tasks-yarn.yarn-task.Yarn@2\n    displayName: yarn build and test\n    inputs:\n      Arguments: build\n  - task: geeklearningio.gl-vsts-tasks-yarn.yarn-task.Yarn@2\n    displayName: yarn publish:web\n    inputs:\n      Arguments: 'run publish:web --output $(build.artifactstagingdirectory)/MyAmazingProject'\n  - task: PublishBuildArtifacts@1\n    displayName: publish build artifact\n    inputs:\n      PathtoPublish: '$(build.artifactstagingdirectory)'\n")),(0,a.kt)("p",null,"This file does the following:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Installs yarn. (By the way VSTS, what's with not having yarn installed by default? I'll say this for the avoidance of doubt: in the npm cli space: yarn has won.)"),(0,a.kt)("li",{parentName:"ol"},"Install our dependencies, build the front end and back end, run all the tests. Effectively ",(0,a.kt)("inlineCode",{parentName:"li"},"yarn build"),"."),(0,a.kt)("li",{parentName:"ol"},"Publish our web app to a directory. Effectively ",(0,a.kt)("inlineCode",{parentName:"li"},"yarn run publish:web"),". This is only separate because we want to pass in the output directory and so it's just easier for it to be a separate step."),(0,a.kt)("li",{parentName:"ol"},"Publish the build artefact to TFS. (This will go on to be picked up by the continuous deployment mechanism and published out to Azure.)")),(0,a.kt)("p",null,"I much prefer this to what I had before. I feel there's much more that can be done here as well. I'm looking forward to the continuous deployment piece becoming scriptable too."),(0,a.kt)("p",null,"Thanks to Zoltan and props to the TFVS team!"))}d.isMDXComponent=!0},57374:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"vsts-and-ef-core-migrations",title:"VSTS and EF Core Migrations",authors:"johnnyreilly",tags:["vsts","Entity Framework"],hide_table_of_contents:!1},s=void 0,l={permalink:"/vsts-and-ef-core-migrations",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-06-24-vsts-and-ef-core-migrations/index.md",source:"@site/blog/2018-06-24-vsts-and-ef-core-migrations/index.md",title:"VSTS and EF Core Migrations",description:"Let me start by telling you a dirty secret. I have an ASP.Net Core project that I build with VSTS. It is deployed to Azure through a CI / CD setup in VSTS. That part I'm happy with. Proud of even. Now to the sordid hiddenness: try as I might, I've never found a nice way to deploy Entity Framework database migrations as part of the deployment flow. So I have [blushes with embarrassment] been using the Startup of my ASP.Net core app to run the migrations on my database. There. I said it. You all know. Absolutely filthy. Don't judge me.",date:"2018-06-24T00:00:00.000Z",formattedDate:"June 24, 2018",tags:[{label:"vsts",permalink:"/tags/vsts"},{label:"Entity Framework",permalink:"/tags/entity-framework"}],readingTime:5.01,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"vsts-and-ef-core-migrations",title:"VSTS and EF Core Migrations",authors:"johnnyreilly",tags:["vsts","Entity Framework"],hide_table_of_contents:!1},prevItem:{title:"Cypress and Auth0",permalink:"/cypress-and-auth0"},nextItem:{title:"VSTS... YAML up!",permalink:"/vsts-yaml-up"}},p={authorsImageUrls:[void 0]},u=[{value:"Console Yourself",id:"console-yourself",level:2},{value:"Build It!",id:"build-it",level:2},{value:"Deploy It!",id:"deploy-it",level:2},{value:"Give It A Whirl",id:"give-it-a-whirl",level:2},{value:"Wrapping Up",id:"wrapping-up",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Let me start by telling you a dirty secret. I have an ASP.Net Core project that I build with VSTS. It is deployed to Azure through a CI / CD setup in VSTS. That part I'm happy with. Proud of even. Now to the sordid hiddenness: try as I might, I've never found a nice way to deploy Entity Framework database migrations as part of the deployment flow. So I have ","[blushes with embarrassment]"," been using the ",(0,a.kt)("inlineCode",{parentName:"p"},"Startup")," of my ASP.Net core app to run the migrations on my database. There. I said it. You all know. Absolutely filthy. Don't judge me."),(0,a.kt)("p",null,"If you care to google, you'll find various discussions around this, and various ways to tackle it. Most of which felt like too much hard work and so I never attempted."),(0,a.kt)("p",null,"It's also worth saying that being on VSTS made me less likely to give these approaches a go. Why? Well, the feedback loop for debugging a CI / CD setup is truly sucky. Make a change. Wait for it to trickle through the CI / CD flow (10 mins at least). Spot a problem, try and fix. Start waiting again. Repeat until you succeed. Or, if you're using the free tier of VSTS, repeat until you run out of build minutes. You have a limited number of build minutes per month with VSTS. Last time I fiddled with the build, I bled my way through a full month's minutes in 2 days. I have now adopted the approach of only playing with the setup in the last week of the month. That way if I end up running out of minutes, at least I'll roll over to the new allowance in a matter of days."),(0,a.kt)("p",null,"Digression over. I could take the guilt of my EF migrations secret no longer, I decided to try and tackle it another way. I used the approach suggested by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/broersa"}),"Andre Broers"),(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/aspnet/EntityFrameworkCore/issues/9841#issuecomment-395712061"}),"here"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"I worked around by adding a dotnetcore consoleapp project where I run the migration via the Context. In the Build I build this consoleapp in the release I execute it.")),(0,a.kt)("h2",o({},{id:"console-yourself"}),"Console Yourself"),(0,a.kt)("p",null,"First things first, we need a console app added to our solution. Fire up PowerShell in the root of your project and:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-console"}),"md MyAwesomeProject.MigrateDatabase\ncd .\\MyAwesomeProject.MigrateDatabase\\\ndotnet new console\n")),(0,a.kt)("p",null,"Next we need that project to know about Entity Framework and also our DbContext (which I store in a dedicated project):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-console"}),"dotnet add package Microsoft.EntityFrameworkCore.Design\ndotnet add package Microsoft.EntityFrameworkCore.SqlServer\ndotnet add reference ..\\MyAwesomeProject.Database\\MyAwesomeProject.Database.csproj\n")),(0,a.kt)("p",null,"Add our new project to our solution: (I always forget to do this)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-console"}),"cd ../\ndotnet sln add .\\MyAwesomeProject.MigrateDatabase\\MyAwesomeProject.MigrateDatabase.csproj\n")),(0,a.kt)("p",null,"You should now be the proud possessor of a ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj")," file that looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<Project Sdk="Microsoft.NET.Sdk">\n\n  <PropertyGroup>\n    <OutputType>Exe</OutputType>\n    <TargetFramework>netcoreapp2.1</TargetFramework>\n  </PropertyGroup>\n\n  <ItemGroup>\n    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="2.1.1" />\n    <PackageReference Include="Microsoft.EntityFrameworkCore.SqlServer" Version="2.1.1" />\n  </ItemGroup>\n\n  <ItemGroup>\n    <ProjectReference Include="..\\MyAwesomeProject.Database\\MyAwesomeProject.Database.csproj" />\n  </ItemGroup>\n\n</Project>\n')),(0,a.kt)("p",null,"Replace the contents of the ",(0,a.kt)("inlineCode",{parentName:"p"},"Program.cs")," file with this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.IO;\nusing MyAwesomeProject.Database;\nusing Microsoft.EntityFrameworkCore;\n\nnamespace MyAwesomeProject.MigrateDatabase {\n    class Program {\n        // Example usage:\n        // dotnet MyAwesomeProject.MigrateDatabase.dll "Server=(localdb)\\\\mssqllocaldb;Database=MyAwesomeProject;Trusted_Connection=True;"\n        static void Main(string[] args) {\n            if (args.Length == 0)\n                throw new Exception("No connection string supplied!");\n\n            var myAwesomeProjectConnectionString = args[0];\n\n            // Totally optional debug information\n            Console.WriteLine("About to migrate this database:");\n            var connectionBits = myAwesomeProjectConnectionString.Split(";");\n            foreach (var connectionBit in connectionBits) {\n                if (!connectionBit.StartsWith("Password", StringComparison.CurrentCultureIgnoreCase))\n                    Console.WriteLine(connectionBit);\n            }\n\n            try {\n                var optionsBuilder = new DbContextOptionsBuilder<MyAwesomeProjectContext>();\n                optionsBuilder.UseSqlServer(myAwesomeProjectConnectionString);\n\n                using(var context = new MyAwesomeProjectContext(optionsBuilder.Options)) {\n                    context.Database.Migrate();\n                }\n                Console.WriteLine("This database is migrated like it\'s the Serengeti!");\n            } catch (Exception exc) {\n                var failedToMigrateException = new Exception("Failed to apply migrations!", exc);\n                Console.WriteLine($"Didn\'t succeed in applying migrations: {exc.Message}");\n                throw failedToMigrateException;\n            }\n        }\n    }\n}\n')),(0,a.kt)("p",null,"This code takes the database connection string passed as an argument, spins up a db context with that, and migrates like it's the Serengeti."),(0,a.kt)("h2",o({},{id:"build-it"}),"Build It!"),(0,a.kt)("p",null,"The next thing we need is to ensure that this is included as part of the build process in VSTS. The following commands need to be run during the build to include the MigrateDatabase project in the build output in a ",(0,a.kt)("inlineCode",{parentName:"p"},"MigrateDatabase")," folder:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"cd MyAwesomeProject.MigrateDatabase\ndotnet build\ndotnet publish --configuration Release --output $(build.artifactstagingdirectory)/MigrateDatabase\n")),(0,a.kt)("p",null,"There's various ways to accomplish this which I wont reiterate now. ",(0,a.kt)("a",o({parentName:"p"},{href:"/vsts-yaml-up"}),"I recommend YAML"),"."),(0,a.kt)("h2",o({},{id:"deploy-it"}),"Deploy It!"),(0,a.kt)("p",null,"Now to execute our console app as part of the deployment process we need to add a CommandLine task to our VSTS build definition. It should execute the following command:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'dotnet MyAwesomeProject.MigrateDatabase.dll "$(ConnectionStrings.MyAwesomeProjectDatabaseConnection)"\n')),(0,a.kt)("p",null,"In the following folder:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"$(System.DefaultWorkingDirectory)/my-awesome-project-YAML/drop/MigrateDatabase\n")),(0,a.kt)("p",null,"Do note that the command uses the ",(0,a.kt)("inlineCode",{parentName:"p"},"ConnectionStrings.MyAwesomeProjectDatabaseConnection")," variable which you need to create and set to the value of your connection string."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(51076).Z,width:"640",height:"293"})),(0,a.kt)("h2",o({},{id:"give-it-a-whirl"}),"Give It A Whirl"),(0,a.kt)("p",null,"Let's find out what happens when the rubber hits the road. I'll add a new entity to my database project:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using System;\n\nnamespace MyAwesomeProject.Database.Entities {\n    public class NewHotness {\n        public Guid NewHotnessId { get; set; }\n    }\n}\n")),(0,a.kt)("p",null,"And reference it in my DbContext:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using MyAwesomeProject.Database.Entities;\nusing Microsoft.EntityFrameworkCore;\n\nnamespace MyAwesomeProject.Database {\n    public class MyAwesomeProjectContext : DbContext {\n        public MyAwesomeProjectContext(DbContextOptions<MyAwesomeProjectContext> options) : base(options) { }\n\n        // ...\n\n        public DbSet<NewHotness> NewHotnesses { get; set; }\n\n        // ...\n    }\n}\n")),(0,a.kt)("p",null,"Let's let EF know by adding a migration to my project:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"dotnet ef migrations add TestOurMigrationsApproach\n")),(0,a.kt)("p",null,"Commit my change, push it to VSTS, wait for the build to run and a deployment to take place.... Okay. It's done. Looks good."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(55915).Z,width:"640",height:"269"})),(0,a.kt)("p",null,"Let's take a look in the database:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-console"}),"select * from NewHotnesses\ngo\n")),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(13030).Z,width:"640",height:"436"})),(0,a.kt)("p",null,"It's there! We are migrating our database upon deployment; and not in our ASP.Net Core app itself. I feel a burden lifted."),(0,a.kt)("h2",o({},{id:"wrapping-up"}),"Wrapping Up"),(0,a.kt)("p",null,"The EF Core team are aware of the lack of guidance around deploying migrations and have recently announced plans to fix that in the docs. You can track the progress of this issue ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/aspnet/EntityFramework.Docs/issues/691"}),"here"),". There's good odds that once they come out with this I'll find there's a better way than the approach I've outlined in this post. Until that glorious day!"))}d.isMDXComponent=!0},79714:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"cypress-and-auth0",title:"Cypress and Auth0",authors:"johnnyreilly",tags:["auth0-js","Auth0","cypress","auth"],hide_table_of_contents:!1},s=void 0,l={permalink:"/cypress-and-auth0",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-07-09-cypress-and-auth0/index.md",source:"@site/blog/2018-07-09-cypress-and-auth0/index.md",title:"Cypress and Auth0",description:"Cypress is a fantastic way to write UI tests for your web apps. Just world class. Wait, no. Galaxy class. I'm going to go one further: universe class. You get my drift.",date:"2018-07-09T00:00:00.000Z",formattedDate:"July 9, 2018",tags:[{label:"auth0-js",permalink:"/tags/auth-0-js"},{label:"Auth0",permalink:"/tags/auth-0"},{label:"cypress",permalink:"/tags/cypress"},{label:"auth",permalink:"/tags/auth"}],readingTime:4.44,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"cypress-and-auth0",title:"Cypress and Auth0",authors:"johnnyreilly",tags:["auth0-js","Auth0","cypress","auth"],hide_table_of_contents:!1},prevItem:{title:"Azure App Service: nested configuration for ASP.NET running in Web App for Containers using Application Settings",permalink:"/azure-app-service-web-app-containers-asp-net-nested-configuration"},nextItem:{title:"VSTS and EF Core Migrations",permalink:"/vsts-and-ef-core-migrations"}},p={authorsImageUrls:[void 0]},u=[{value:"Commanding Auth0",id:"commanding-auth0",level:2},{value:"Using It",id:"using-it",level:2},{value:"One More Thing...",id:"one-more-thing",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://www.cypress.io/"}),"Cypress")," is a fantastic way to write UI tests for your web apps. Just world class. Wait, no. Galaxy class. I'm going to go one further: universe class. You get my drift."),(0,a.kt)("p",null,"Here's a pickle for you. You have functionality that lies only behind the walled garden of authentication. You want to write tests for these capabilities. Assuming that authentication takes place within your application that's no great shakes. Authentication is part of your app; it's no big deal using Cypress to automate logging in."),(0,a.kt)("p",null,"Auth is a serious business and, as Cypress is best in class for UI testing, I'll say that Auth0 is romping home with the same title in the auth-as-a-service space. My app is using Auth0 for authentication. What's important to note about this is the flow. Typically when using auth-as-a-service, the user is redirected to the auth provider's site to authenticate and then be redirected back to the application post-login."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/brian-mann"}),"Brian Mann")," (of Cypress fame) has been ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/cypress-io/cypress/issues/1342#issuecomment-366747803"}),"fairly clear when talking about testing with this sort of authentication flow"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"You're trying to test SSO - and we have recipes showing you exactly how to do this."),(0,a.kt)("p",{parentName:"blockquote"},"Also best practice is never to visit or test 3rd party sites not under your control. You don't control ",(0,a.kt)("inlineCode",{parentName:"p"},"microsoftonline"),", so there's no reason to use the UI to test this. You can programmatically test the integration between it and your app with ",(0,a.kt)("inlineCode",{parentName:"p"},"cy.request")," ","-"," which is far faster, more reliable, and still gives you 100% confidence.")),(0,a.kt)("p",null,"I want to automate logging into Auth0 from my Cypress tests. But hopefully in a good way. Not a bad way. Wouldn't want to make Brian sad."),(0,a.kt)("h2",o({},{id:"commanding-auth0"}),"Commanding Auth0"),(0,a.kt)("p",null,"To automate our login, we're going to use the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/auth0/auth0.js"}),"auth0-js client library"),". This is the same library the application uses; but we're going to do something subtly different with it."),(0,a.kt)("p",null,"The application uses ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/auth0/auth0.js#api"}),(0,a.kt)("inlineCode",{parentName:"a"},"authorize"))," to log users in. This function redirects the user into the Auth0 lock screen, and then, post authentication, redirects the user back to the application with a token in the URL. The app parses the token (using the auth0 client library) and sets the token and the expiration of said token in the browser sessionStorage."),(0,a.kt)("p",null,"What we're going to do is automate our login by using ",(0,a.kt)("inlineCode",{parentName:"p"},"login")," instead. First of all, we need to add ",(0,a.kt)("inlineCode",{parentName:"p"},"auth0-js")," as a dependency of our e2e tests:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"yarn add auth0-js --dev\n")),(0,a.kt)("p",null,"Next, we're going to create ourselves a custom command called loginAsAdmin:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const auth0 = require('auth0-js');\n\nCypress.Commands.add('loginAsAdmin', (overrides = {}) => {\n  Cypress.log({\n    name: 'loginAsAdminBySingleSignOn',\n  });\n\n  const webAuth = new auth0.WebAuth({\n    domain: 'my-super-duper-domain.eu.auth0.com', // Get this from https://manage.auth0.com/#/applications and your application\n    clientID: 'myclientid', // Get this from https://manage.auth0.com/#/applications and your application\n    responseType: 'token id_token',\n  });\n\n  webAuth.client.login(\n    {\n      realm: 'Username-Password-Authentication',\n      username: 'mytestemail@something.co.uk',\n      password: 'SoVeryVeryVery$ecure',\n      audience: 'myaudience', // Get this from https://manage.auth0.com/#/apis and your api, use the identifier property\n      scope: 'openid email profile',\n    },\n    function (err, authResult) {\n      // Auth tokens in the result or an error\n      if (authResult && authResult.accessToken && authResult.idToken) {\n        const token = {\n          accessToken: authResult.accessToken,\n          idToken: authResult.idToken,\n          // Set the time that the access token will expire at\n          expiresAt: authResult.expiresIn * 1000 + new Date().getTime(),\n        };\n\n        window.sessionStorage.setItem(\n          'my-super-duper-app:storage_token',\n          JSON.stringify(token)\n        );\n      } else {\n        console.error('Problem logging into Auth0', err);\n        throw err;\n      }\n    }\n  );\n});\n")),(0,a.kt)("p",null,"This command logs in using the ",(0,a.kt)("inlineCode",{parentName:"p"},"auth0-js")," API and then sets the result into ",(0,a.kt)("inlineCode",{parentName:"p"},"sessionStorage")," in the same way that our app does. This allows our app to read the value out of ",(0,a.kt)("inlineCode",{parentName:"p"},"sessionStorage")," and use it. We're also going to put together one other command:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"Cypress.Commands.add('visitHome', (overrides = {}) => {\n  cy.visit('/', {\n    onBeforeLoad: (win) => {\n      win.sessionStorage.clear();\n    },\n  });\n});\n")),(0,a.kt)("p",null,"This visits the root of our application and wipes the ",(0,a.kt)("inlineCode",{parentName:"p"},"sessionStorage"),". This is necessary because Cypress doesn't clear down ",(0,a.kt)("inlineCode",{parentName:"p"},"sessionStorage")," between tests. (",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/cypress-io/cypress/issues/413"}),"That's going to change though."),")"),(0,a.kt)("h2",o({},{id:"using-it"}),"Using It"),(0,a.kt)("p",null,"Let's write a test that uses our new commands to see if it gets access to our admin functionality:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"describe('access secret admin functionality', () => {\n  it('should be able to navigate to', () => {\n    cy.visitHome()\n      .loginAsAdmin()\n      .get('[href=\"/secret-adminny-stuff\"]') // This link should only be visible to admins\n      .click()\n      .url()\n      .should('contain', 'secret-adminny-stuff/'); // non-admins should be redirected away from this url\n  });\n});\n")),(0,a.kt)("p",null,"Well, the test looks good but it's failing. If I fire up the Chrome Dev Tools in Cypress (did I mention that Cypress is absolutely fabulous?) then I see this response tucked away in the network tab:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{error: "unauthorized_client",\u2026} error : "unauthorized_client" error_description : "Grant type \'http://auth0.com/oauth/grant-type/password-realm\' not allowed for the client."\n')),(0,a.kt)("p",null,"Hmmm... So sad. If you go to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://manage.auth0.com/#/applications"}),"https://manage.auth0.com/#/applications"),", select your application, ",(0,a.kt)("inlineCode",{parentName:"p"},"Show Advanced Settings")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"Grant Types")," you'll see a ",(0,a.kt)("inlineCode",{parentName:"p"},"Password")," option is unselected."),(0,a.kt)("p",null,"Select it, Save Changes and try again."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(24557).Z,width:"640",height:"449"})),(0,a.kt)("p",null,"You now have a test which automates your Auth0 login using Cypress and goes on to test your application functionality with it!"),(0,a.kt)("h2",o({},{id:"one-more-thing"}),"One More Thing..."),(0,a.kt)("p",null,"It's worth saying that it's worth setting up different tenants in Auth0 to support your testing scenarios. This is generally a good idea so you can separate your testing accounts from Production accounts. Further to that, you don't need to have your Production setup supporting the ",(0,a.kt)("inlineCode",{parentName:"p"},"Password``Grant Type"),"."),(0,a.kt)("p",null,"Also, if you're curious about what the application under test is like then read ",(0,a.kt)("a",o({parentName:"p"},{href:"/auth0-typescript-and-aspnet-core"}),"this"),"."))}d.isMDXComponent=!0},53286:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-app-service-web-app-containers-asp-net-nested-configuration",title:"Azure App Service: nested configuration for ASP.NET running in Web App for Containers using Application Settings",authors:"johnnyreilly",tags:[],image:"./appservice_classic.webp",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-app-service-web-app-containers-asp-net-nested-configuration",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-07-28-azure-app-service-web-app-containers-asp-net-nested-configuration/index.md",source:"@site/blog/2018-07-28-azure-app-service-web-app-containers-asp-net-nested-configuration/index.md",title:"Azure App Service: nested configuration for ASP.NET running in Web App for Containers using Application Settings",description:"How can we configure an ASP.NET application with nested properties Azure App Service Web App for Containers using Application Settings in Azure? Colons don't work.",date:"2018-07-28T00:00:00.000Z",formattedDate:"July 28, 2018",tags:[],readingTime:1.895,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-app-service-web-app-containers-asp-net-nested-configuration",title:"Azure App Service: nested configuration for ASP.NET running in Web App for Containers using Application Settings",authors:"johnnyreilly",tags:[],image:"./appservice_classic.webp",hide_table_of_contents:!1},prevItem:{title:"Using TypeScript and webpack alias: goodbye relative paths",permalink:"/typescript-webpack-alias-goodbye-relative-paths"},nextItem:{title:"Cypress and Auth0",permalink:"/cypress-and-auth0"}},p={image:n(33269).Z,authorsImageUrls:[void 0]},u=[{value:"Containers on App Service",id:"containers-on-app-service",level:2},{value:"The Mystery of Configuration",id:"the-mystery-of-configuration",level:2},{value:"How do we configure without colons?",id:"how-do-we-configure-without-colons",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"How can we configure an ASP.NET application with nested properties ",(0,a.kt)("a",o({parentName:"p"},{href:"https://azure.microsoft.com/en-gb/services/app-service/containers/"}),"Azure App Service Web App for Containers")," using Application Settings in Azure? Colons don't work."),(0,a.kt)("h2",o({},{id:"containers-on-app-service"}),"Containers on App Service"),(0,a.kt)("p",null,"App Services have long been a super simple way to spin up a web app in Azure. The barrier to entry is low, maintenance is easy. It just works. App Services recently got a turbo boost in the form of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/app-service/containers/app-service-linux-intro"}),"Azure App Service on Linux"),". Being able to deploy to Linux is exciting enough; but another reason this is notable because ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/app-service/containers/tutorial-custom-docker-image"}),"you can deploy Docker images that will be run as app services"),"."),(0,a.kt)("p",null,"I cannot over-emphasise just how easy this makes getting a Docker image into Production. Yay Azure!"),(0,a.kt)("h2",o({},{id:"the-mystery-of-configuration"}),"The Mystery of Configuration"),(0,a.kt)("p",null,"Applications need configuration. ASP.Net Core applications are typically configured by an ",(0,a.kt)("inlineCode",{parentName:"p"},"appsettings.json")," file which might look like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "Parent": {\n    "ChildOne": "I\'m a little teapot",\n    "ChildTwo": "Short and stout"\n  }\n}\n')),(0,a.kt)("p",null,"With a classic App Service you could override a setting in the ",(0,a.kt)("inlineCode",{parentName:"p"},"appsettings.json"),' by updating "Application settings" within the Azure portal. You\'d do this in the style of creating an Application setting called ',(0,a.kt)("inlineCode",{parentName:"p"},"Parent:ChildOne")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"Parent:ChildTwo"),". To be clear: using colons to target a specific piece of config."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"screenshot of an App Service Application Settings in the Azure Portal, nested properties configured using colons",src:n(33269).Z,width:"640",height:"336"})),(0,a.kt)("p",null,"You can read about this approach ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.microsoft.com/waws/2018/06/12/asp-net-core-settings-for-azure-app-service/"}),"here"),". Now there's something I want you to notice; consider the colons below:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of an App Service specific Application Setting nested property configured using colons - all good",src:n(72270).Z,width:"584",height:"96"})),(0,a.kt)("p",null,"If you try and follow the same steps when you're using Web App for Containers / i.e. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/app-service/containers/app-service-linux-intro"}),"a Docker image deployed to an Azure App Service on Linux ")," you ",(0,a.kt)("strong",{parentName:"p"},"cannot")," use colons:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of a Web App for Containers specific Application Setting nested property configured using colons - errors",src:n(90357).Z,width:"640",height:"65"})),(0,a.kt)("p",null,"When you hover over the error you see this message: ",(0,a.kt)("inlineCode",{parentName:"p"},'This field can only contain letters, numbers (0-9), periods ("."), and underscores ("_")'),". Using ",(0,a.kt)("inlineCode",{parentName:"p"},".")," does not work alas."),(0,a.kt)("h2",o({},{id:"how-do-we-configure-without-colons"}),"How do we configure without colons?"),(0,a.kt)("p",null,"It's simple. Where you would use ",(0,a.kt)("inlineCode",{parentName:"p"},":")," on a classic App Service, you should use a ",(0,a.kt)("inlineCode",{parentName:"p"},"__")," (double underscore) on an App Service with containers. So ",(0,a.kt)("inlineCode",{parentName:"p"},"Parent__ChildOne")," instead of ",(0,a.kt)("inlineCode",{parentName:"p"},"Parent:ChildOne"),". It's as simple as that."))}d.isMDXComponent=!0},57013:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-webpack-alias-goodbye-relative-paths",title:"Using TypeScript and webpack alias: goodbye relative paths",authors:"johnnyreilly",tags:["typescript","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-webpack-alias-goodbye-relative-paths",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-08-21-typescript-webpack-alias-goodbye-relative-paths/index.md",source:"@site/blog/2018-08-21-typescript-webpack-alias-goodbye-relative-paths/index.md",title:"Using TypeScript and webpack alias: goodbye relative paths",description:"This post shows how you can use TypeScript with webpack alias to move away from using relative paths in your import statements.",date:"2018-08-21T00:00:00.000Z",formattedDate:"August 21, 2018",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:2.865,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-webpack-alias-goodbye-relative-paths",title:"Using TypeScript and webpack alias: goodbye relative paths",authors:"johnnyreilly",tags:["typescript","webpack"],hide_table_of_contents:!1},prevItem:{title:"Semantic Versioning and Definitely Typed",permalink:"/semantic-versioning-and-definitely-typed"},nextItem:{title:"Azure App Service: nested configuration for ASP.NET running in Web App for Containers using Application Settings",permalink:"/azure-app-service-web-app-containers-asp-net-nested-configuration"}},p={authorsImageUrls:[void 0]},u=[{value:"Long relative paths",id:"long-relative-paths",level:2},{value:"TypeScript",id:"typescript",level:2},{value:"webpack <code>resolve.alias</code> to the rescue!",id:"webpack-resolvealias-to-the-rescue",level:2},{value:"DRY with the <code>tsconfig-paths-webpack-plugin</code>",id:"dry-with-the-tsconfig-paths-webpack-plugin",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This post shows how you can use TypeScript with webpack ",(0,a.kt)("inlineCode",{parentName:"p"},"alias")," to move away from using relative paths in your ",(0,a.kt)("inlineCode",{parentName:"p"},"import")," statements."),(0,a.kt)("h2",o({},{id:"long-relative-paths"}),"Long relative paths"),(0,a.kt)("p",null,"I write a lot of TypeScript. Because I like modularity, I split up my codebases into discreet modules and ",(0,a.kt)("inlineCode",{parentName:"p"},"import")," from them as necessary."),(0,a.kt)("p",null,"Take a look at this ",(0,a.kt)("inlineCode",{parentName:"p"},"import"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import * as utils from '../../../../../../../shared/utils';\n")),(0,a.kt)("p",null,"Now take a look at this import:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import * as utils from 'shared/utils';\n")),(0,a.kt)("p",null,'Which do you prefer? If the answer was "the first" then read no further. You have all you need, go forth and be happy. If the answer was "the second" then stick around; I can help!'),(0,a.kt)("h2",o({},{id:"typescript"}),"TypeScript"),(0,a.kt)("p",null,"There's been a solution for this in TypeScript-land for some time. You can read the detail ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/docs/handbook/module-resolution.html#path-mapping"}),'in the "path mapping" docs here'),"."),(0,a.kt)("p",null,"Let's take a slightly simpler example; we have a folder structure that looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-console"}),"projectRoot\n\u251c\u2500\u2500 components\n\u2502 \u2514\u2500\u2500 page.tsx (imports '../shared/utils')\n\u251c\u2500\u2500 shared\n\u2502 \u251c\u2500\u2500 folder1\n\u2502 \u2514\u2500\u2500 folder2\n\u2502 \u2514\u2500\u2500 utils.ts\n\u2514\u2500\u2500 tsconfig.json\n")),(0,a.kt)("p",null,"We would like ",(0,a.kt)("inlineCode",{parentName:"p"},"page.tsx")," to import ",(0,a.kt)("inlineCode",{parentName:"p"},"'shared/utils'")," instead of ",(0,a.kt)("inlineCode",{parentName:"p"},"'../shared/utils'"),". We can, if we augment our ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," with the following properties:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "compilerOptions": {\n    "baseUrl": ".",\n    "paths": {\n      "components/*": ["components/*"],\n      "shared/*": ["shared/*"]\n    }\n  }\n}\n')),(0,a.kt)("p",null,"Then we can use option 2. We can happily write:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import * as utils from 'shared/utils';\n")),(0,a.kt)("p",null,"My code compiles, yay.... Ship it!"),(0,a.kt)("p",null,"Let's not get over-excited. Actually, we're only part-way there; you can compile this code with the TypeScript compiler.... But is that enough?"),(0,a.kt)("p",null,"I bundle my TypeScript with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader"}),"ts-loader"),' and webpack. If I try and use my new exciting import statement above with my build system then disappointment is in my future. webpack will be all like "import whuuuuuuuut?"'),(0,a.kt)("p",null,"You see, webpack doesn't know what we told the TypeScript compiler in the ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json"),". Why would it? It was our little secret."),(0,a.kt)("h2",o({},{id:"webpack-resolvealias-to-the-rescue"}),"webpack ",(0,a.kt)("inlineCode",{parentName:"h2"},"resolve.alias")," to the rescue!"),(0,a.kt)("p",null,"This same functionality has existed in webpack for a long time; actually much longer than it has existed in TypeScript. It's the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://webpack.js.org/configuration/resolve/#resolve-alias"}),(0,a.kt)("inlineCode",{parentName:"a"},"resolve.alias"))," functionality."),(0,a.kt)("p",null,"So, looking at that I should be able to augment my ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js")," like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"module.exports = {\n  //...\n  resolve: {\n    alias: {\n      components: path.resolve(process.cwd(), 'components/'),\n      shared: path.resolve(process.cwd(), 'shared/'),\n    },\n  },\n};\n")),(0,a.kt)("p",null,"And now both webpack and TypeScript are up to speed with how to resolve modules."),(0,a.kt)("h2",o({},{id:"dry-with-the-tsconfig-paths-webpack-plugin"}),"DRY with the ",(0,a.kt)("a",o({parentName:"h2"},{href:"https://github.com/dividab/tsconfig-paths-webpack-plugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"tsconfig-paths-webpack-plugin"))),(0,a.kt)("p",null,"When I look at the ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," and the ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js")," something occurs to me: I don't like to repeat myself. As well as that, I don't like to repeat myself. It's so... Repetitive."),(0,a.kt)("p",null,"The declarations you make in the ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," are re-stated in the ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js"),". Who wants to maintain two sets of code where one would do? Not me."),(0,a.kt)("p",null,"Fortunately, you don't have to. There's the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dividab/tsconfig-paths-webpack-plugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"tsconfig-paths-webpack-plugin"))," for webpack which will do the job for you. You can replace your verbose ",(0,a.kt)("inlineCode",{parentName:"p"},"resolve.alias")," with this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),'module.exports = {\n  //...\n  resolve: {\n    plugins: [\n      new TsconfigPathsPlugin({\n        /*configFile: "./path/to/tsconfig.json" */\n      }),\n    ],\n  },\n};\n')),(0,a.kt)("p",null,"This does the hard graft of reading your ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," and translating path mappings into webpack ",(0,a.kt)("inlineCode",{parentName:"p"},"alias"),"es. From this point forward, you need only edit the ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," and everything else will just work."),(0,a.kt)("p",null,"Thanks to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jonaskello"}),"Jonas Kello"),", author of the plugin; it's tremendous! Thanks also to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/TheLarkInn"}),"Sean Larkin")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/s-panferov"}),"Stanislav Panferov")," (of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/s-panferov/awesome-typescript-loader"}),"awesome-typescript-loader"),") who together worked on the original plugin that I understand the ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig-paths-webpack-plugin")," is based on. Great work!"))}d.isMDXComponent=!0},1573:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"semantic-versioning-and-definitely-typed",title:"Semantic Versioning and Definitely Typed",authors:"johnnyreilly",tags:["Definitely Typed","typescript"],image:"./i-must-break-you.webp",hide_table_of_contents:!1},s=void 0,l={permalink:"/semantic-versioning-and-definitely-typed",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-09-15-semantic-versioning-and-definitely-typed/index.md",source:"@site/blog/2018-09-15-semantic-versioning-and-definitely-typed/index.md",title:"Semantic Versioning and Definitely Typed",description:"This a tale of things that are and things that aren't. It's a tale of semantic versioning, the lack thereof and heartbreak. It's a story of terror and failing builds. But it has a bittersweet ending wherein our heroes learn a lesson and understand the need for compromise. We all come out better and wiser people. Hopefully there's something for everybody; let's start with an exciting opener and see where it goes...",date:"2018-09-15T00:00:00.000Z",formattedDate:"September 15, 2018",tags:[{label:"Definitely Typed",permalink:"/tags/definitely-typed"},{label:"typescript",permalink:"/tags/typescript"}],readingTime:4.61,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"semantic-versioning-and-definitely-typed",title:"Semantic Versioning and Definitely Typed",authors:"johnnyreilly",tags:["Definitely Typed","typescript"],image:"./i-must-break-you.webp",hide_table_of_contents:!1},prevItem:{title:"ts-loader Project References: First Blood",permalink:"/ts-loader-project-references-first-blood"},nextItem:{title:"Using TypeScript and webpack alias: goodbye relative paths",permalink:"/typescript-webpack-alias-goodbye-relative-paths"}},p={image:n(59183).Z,authorsImageUrls:[void 0]},u=[{value:"Definitely Typed",id:"definitely-typed",level:2},{value:"I Couldn&#39;t Help But Notice Your Pain",id:"i-couldnt-help-but-notice-your-pain",level:2},{value:"You Were Already Broken - I Just Showed You How",id:"you-were-already-broken---i-just-showed-you-how",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This a tale of things that are and things that aren't. It's a tale of semantic versioning, the lack thereof and heartbreak. It's a story of terror and failing builds. But it has a bittersweet ending wherein our heroes learn a lesson and understand the need for compromise. We all come out better and wiser people. Hopefully there's something for everybody; let's start with an exciting opener and see where it goes..."),(0,a.kt)("h2",o({},{id:"definitely-typed"}),"Definitely Typed"),(0,a.kt)("p",null,"This is often the experience people have of using type definitions from Definitely Typed:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"Ivan Drago saying &quot;I must break you&quot;",src:n(59183).Z,width:"500",height:"485"})),(0,a.kt)("p",null,"Specifically, people are used to the idea of semantic versioning and expect it from types published to npm by Definitely Typed. They wait in vain. ",(0,a.kt)("a",o({parentName:"p"},{href:"/typescript-types-and-repeatable-builds"}),"I've written before about the Definitely Typed / @types semantic version compromise.")," And I wanted to talk about it a little further as (watching the issues raised on DT) I don't think the message has quite got out there. To summarise:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"npm is built on top of ",(0,a.kt)("a",o({parentName:"p"},{href:"http://semver.org/"}),"semantic versioning")," and they ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.npmjs.com/getting-started/semantic-versioning"}),"take it seriously"),". When a package is published it should be categorised as a major release (breaking changes), a minor release (extra functionality which is backwards compatible) or a patch release (backwards compatible bug fixes).")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Definitely Typed publishes type definitions to npm under the ",(0,a.kt)("inlineCode",{parentName:"p"},"@types")," namespace")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"To make consumption of type definitions easier, the versioning of a type definition package will seek to emulate the versioning of the npm package it supports. For example, right now ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/react-router"}),(0,a.kt)("inlineCode",{parentName:"a"},"react-router")),"'s latest version is ",(0,a.kt)("inlineCode",{parentName:"p"},"4.3.1"),". The corresponding type definition ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/@types/react-router"}),(0,a.kt)("inlineCode",{parentName:"a"},"@types/react-router")),"'s latest version is ",(0,a.kt)("inlineCode",{parentName:"p"},"4.0.31"),". (It's fairly common for type definition versions to lag behind the package they type.)"))),(0,a.kt)("p",null,"If there's a breaking change to the ",(0,a.kt)("inlineCode",{parentName:"p"},"react-router")," type definition then the new version published will have a version number that begins ",(0,a.kt)("inlineCode",{parentName:"p"},'"4.0."'),". If you are relying on semantic versioning this will break you."),(0,a.kt)("h2",o({},{id:"i-couldnt-help-but-notice-your-pain"}),"I Couldn't Help But Notice Your Pain"),(0,a.kt)("p",null,"If you're reading this and can't quite believe that @types would be so inconsiderate as to break the conventions of the ecosystem it lives in, I understand. But hopefully you can see there are reasons for this. In the end, being able to use npm as a delivery mechanism for versioned type definitions associated with another package has a cost; that cost is semantic versioning for the type definitions themselves. It wasn't a choice taken lightly; it's a pragmatic compromise."),(0,a.kt)("p",null,'"But what about my failing builds? Fine, people are going to change type definitions, but why should I burn because of their choices?"'),(0,a.kt)("p",null,"Excellent question. Truly. Well here's my advice: don't expect semantic versioning where there is none. Use specific package versions. You can do that directly with your ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json"),". For example replace something like this: ",(0,a.kt)("inlineCode",{parentName:"p"},'"@types/react-router": "^4.0.0"')," with a specific version number: ",(0,a.kt)("inlineCode",{parentName:"p"},'"@types/react-router": "4.0.31"'),". With this approach it's a specific activity to upgrade your type definitions. A chore if you will; but a chore that guarantees builds will not fail unexpectedly due to changing type defs."),(0,a.kt)("p",null,"My own personal preference is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://yarnpkg.com/lang/en/"}),"yarn"),". Mother, I'm in love with a ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn.lock")," file. It is the alternative npm client that came out of Facebook. It pins the exact versions of all packages used in your ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn.lock")," file and guarantees to install the same versions each time. Problem solved; and it even allows me to keep the semantic versioning in my ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," as is."),(0,a.kt)("p",null,"This has some value in that when I upgrade I probably want to upgrade to a newer version following the semantic versioning convention. I should just expect that I'll need to check valid compilation when I do so. yarn even has it's own built in utility that tells you when things are out of date: ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn outdated"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of outdated dependencies in yarn",src:n(95299).Z,width:"640",height:"159"})),(0,a.kt)("p",null,"So lovely."),(0,a.kt)("h2",o({},{id:"you-were-already-broken---i-just-showed-you-how"}),"You Were Already Broken - I Just Showed You How"),(0,a.kt)("p",null,"Before I finish I wanted to draw out one reason why breaking changes can be a reason for happiness. Because sometimes your code is wrong. An update to a type definition may highlight that. This is analogous to when the TypeScript compiler ships a new version. When I upgrade to a newer version of TypeScript it lights up errors in my codebase that I hadn't spotted. Yay compiler!"),(0,a.kt)("p",null,"An example of this is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped/pull/28868"}),"a PR I submitted to DefinitelyTyped earlier this week"),". This PR changed how ",(0,a.kt)("inlineCode",{parentName:"p"},"react-router")," models the parameters of a ",(0,a.kt)("inlineCode",{parentName:"p"},"Match"),". Until now, an object was expected; the user could define any object they liked. However, ",(0,a.kt)("inlineCode",{parentName:"p"},"react-router")," will only produce ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," values for a parameter. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/ReactTraining/react-router/blob/34ff1f8077d95edf01e9d5ca8ea4708b8d0290e2/packages/react-router/modules/matchPath.js#L36"}),"If you look at the underlying code it's nothing more than an ",(0,a.kt)("inlineCode",{parentName:"a"},"exec")," on a regular expression.")),(0,a.kt)("p",null,"My PR enforces this at type level by changing this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export interface match<P> {\n  params: P;\n  // ...\n}\n")),(0,a.kt)("p",null,"To this"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export interface match<Params extends { [K in keyof Params]?: string } = {}> {\n  params: Params;\n  // ...\n}\n")),(0,a.kt)("p",null,"So any object definition supplied must have ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," values (and you don't actually need to supply an object definition; that's optional now)."),(0,a.kt)("p",null,"I expected this PR to break people ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped/issues/28894"}),"and it did"),". But this is a useful break. If they were relying upon their parameters to be types other than strings they would be experiencing some unexpected behaviour. In fact, it's exactly this that prompted my PR in the first place. A colleague had defined his parameters as ",(0,a.kt)("inlineCode",{parentName:"p"},"number"),"s and couldn't understand why they weren't behaving like ",(0,a.kt)("inlineCode",{parentName:"p"},"number"),"s. Because they weren't ",(0,a.kt)("inlineCode",{parentName:"p"},"number"),"s! And wonderfully, this will now be caught at compile time; not runtime. Yay!"))}d.isMDXComponent=!0},84112:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"ts-loader-project-references-first-blood",title:"ts-loader Project References: First Blood",authors:"johnnyreilly",tags:["typescript","project references","ts-loader","Webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/ts-loader-project-references-first-blood",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-09-23-ts-loader-project-references-first-blood/index.md",source:"@site/blog/2018-09-23-ts-loader-project-references-first-blood/index.md",title:"ts-loader Project References: First Blood",description:"So project references eh? They shipped with TypeScript 3. We've just shipped initial support for project references in ts-loader v5.2.0. All the hard work was done by the amazing Andrew Branch. In fact I'd recommend taking a gander at the PR. Yay Andrew!",date:"2018-09-23T00:00:00.000Z",formattedDate:"September 23, 2018",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"project references",permalink:"/tags/project-references"},{label:"ts-loader",permalink:"/tags/ts-loader"},{label:"Webpack",permalink:"/tags/webpack"}],readingTime:3.39,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"ts-loader-project-references-first-blood",title:"ts-loader Project References: First Blood",authors:"johnnyreilly",tags:["typescript","project references","ts-loader","Webpack"],hide_table_of_contents:!1},prevItem:{title:"Brand New Fonting Awesomeness",permalink:"/font-awesome-brand-icons-react"},nextItem:{title:"Semantic Versioning and Definitely Typed",permalink:"/semantic-versioning-and-definitely-typed"}},p={authorsImageUrls:[void 0]},u=[{value:"TL;DR",id:"tldr",level:2},{value:"Like <code>tsc</code>, but <em>not</em> like <code>tsc --build</code>",id:"like-tsc-but-not-like-tsc---build",level:2},{value:"\u201cHey, don\u2019t you think that sounds kind of useless and terrible?\u201d",id:"hey-dont-you-think-that-sounds-kind-of-useless-and-terrible",level:2},{value:"<code>outDir</code> Windows problemo.",id:"outdir-windows-problemo",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"So ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/docs/handbook/project-references.html"}),"project references")," eh? They shipped with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blogs.msdn.microsoft.com/typescript/2018/07/30/announcing-typescript-3-0/#project-references"}),"TypeScript 3"),". We've just shipped initial support for project references in ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/releases/tag/v5.2.0"}),(0,a.kt)("inlineCode",{parentName:"a"},"ts-loader v5.2.0")),". All the hard work was done by the amazing ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/atcb"}),"Andrew Branch"),". In fact I'd recommend taking a gander at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/817"}),"the PR"),". Yay Andrew!"),(0,a.kt)("p",null,"This post will take us through the nature of the support for project references in ts-loader now and what we hope the future will bring. It ",(0,a.kt)("strike",null,"rips off shamelessly")),(0,a.kt)("p",null,"borrows from the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader#projectreferences-boolean-defaultfalse"}),(0,a.kt)("inlineCode",{parentName:"a"},"README/index.md"))," documentation that Andrew wrote as part of the PR. Because I am not above stealing."),(0,a.kt)("h2",o({},{id:"tldr"}),"TL;DR"),(0,a.kt)("p",null,"Using project references currently requires building referenced projects outside of ts-loader. We don\u2019t want to keep it that way, but we\u2019re releasing what we\u2019ve got now. To try it out, you\u2019ll need to pass ",(0,a.kt)("inlineCode",{parentName:"p"},"projectReferences: true")," to ",(0,a.kt)("inlineCode",{parentName:"p"},"loaderOptions"),"."),(0,a.kt)("h2",o({},{id:"like-tsc-but-not-like-tsc---build"}),"Like ",(0,a.kt)("inlineCode",{parentName:"h2"},"tsc"),", but ",(0,a.kt)("em",{parentName:"h2"},"not")," like ",(0,a.kt)("inlineCode",{parentName:"h2"},"tsc --build")),(0,a.kt)("p",null,"ts-loader has partial support for ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/docs/handbook/project-references.html"}),"project references")," in that it will ",(0,a.kt)("em",{parentName:"p"},"load")," dependent composite projects that are already built, but will not currently ",(0,a.kt)("em",{parentName:"p"},"build/rebuild")," those upstream projects. The best way to explain exactly what this means is through an example. Say you have a project with a project reference pointing to the ",(0,a.kt)("inlineCode",{parentName:"p"},"lib/")," directory:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-sh"}),"tsconfig.json\napp.ts\nlib/\n  tsconfig.json\n  niftyUtil.ts\n")),(0,a.kt)("p",null,"And we\u2019ll assume that the root ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," has ",(0,a.kt)("inlineCode",{parentName:"p"},'{ "references": { "path": "lib" } }'),", which means that any import of a file that\u2019s part of the ",(0,a.kt)("inlineCode",{parentName:"p"},"lib")," sub-project is treated as a reference to another project, not just a reference to a TypeScript file. Before discussing how ts-loader handles this, it\u2019s helpful to review at a really basic level what ",(0,a.kt)("inlineCode",{parentName:"p"},"tsc")," itself does here. If you were to run ",(0,a.kt)("inlineCode",{parentName:"p"},"tsc")," on this tiny example project, the build would fail with the error:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-sh"}),"error TS6305: Output file 'lib/niftyUtil.d.ts' has not been built from source file 'lib/niftyUtil.ts'.\n")),(0,a.kt)("p",null,"Using project references actually instructs ",(0,a.kt)("inlineCode",{parentName:"p"},"tsc"),(0,a.kt)("em",{parentName:"p"},"not")," to build anything that\u2019s part of another project from source, but rather to look for any ",(0,a.kt)("inlineCode",{parentName:"p"},".d.ts")," and ",(0,a.kt)("inlineCode",{parentName:"p"},".js")," files that have already been generated from a previous build. Since we\u2019ve never built the project in ",(0,a.kt)("inlineCode",{parentName:"p"},"lib")," before, those files don\u2019t exist, so building the root project fails. Still just thinking about how ",(0,a.kt)("inlineCode",{parentName:"p"},"tsc")," works, there are two options to make the build succeed: either run ",(0,a.kt)("inlineCode",{parentName:"p"},"tsc -p lib/tsconfig.json"),(0,a.kt)("em",{parentName:"p"},"first"),", or simply run ",(0,a.kt)("inlineCode",{parentName:"p"},"tsc --build"),", which will figure out that ",(0,a.kt)("inlineCode",{parentName:"p"},"lib")," hasn\u2019t been built and build it first for you."),(0,a.kt)("p",null,"Ok, so how is that relevant to ts-loader? Because the best way to think about what ts-loader does with project references is that it acts like ",(0,a.kt)("inlineCode",{parentName:"p"},"tsc"),", but ",(0,a.kt)("em",{parentName:"p"},"not")," like ",(0,a.kt)("inlineCode",{parentName:"p"},"tsc --build"),". If you run ts-loader on a project that\u2019s using project references, and any upstream project hasn\u2019t been built, you\u2019ll get the exact same ",(0,a.kt)("inlineCode",{parentName:"p"},"error TS6305")," that you would get with ",(0,a.kt)("inlineCode",{parentName:"p"},"tsc"),". If you modify a source file in an upstream project and don\u2019t rebuild that project, ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," won\u2019t have any idea that you\u2019ve changed anything\u2014it will still be looking at the output from the last time you ",(0,a.kt)("em",{parentName:"p"},"built")," that file."),(0,a.kt)("h2",o({},{id:"hey-dont-you-think-that-sounds-kind-of-useless-and-terrible"}),"\u201cHey, don\u2019t you think that sounds kind of useless and terrible?\u201d"),(0,a.kt)("p",null,"Well, sort of. You can consider it a work-in-progress. It\u2019s true that on its own, as of today, ts-loader doesn\u2019t have everything you need to take advantage of project references in webpack. In practice, though, ",(0,a.kt)("em",{parentName:"p"},"consuming")," upstream projects and ",(0,a.kt)("em",{parentName:"p"},"building")," upstream projects are somewhat separate concerns. Building them will likely come in a future release. For background, see the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/issues/815"}),"original issue"),"."),(0,a.kt)("h2",o({},{id:"outdir-windows-problemo"}),(0,a.kt)("inlineCode",{parentName:"h2"},"outDir")," Windows problemo."),(0,a.kt)("p",null,"At the moment, composite projects built using the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/docs/handbook/compiler-options.html"}),(0,a.kt)("inlineCode",{parentName:"a"},"outDir")," compiler option"),' cannot be consumed using ts-loader on Windows. If you try to, ts-loader throws a "',(0,a.kt)("inlineCode",{parentName:"p"},"has not been built from source file"),'" error. ',(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/817#issuecomment-422245998"}),"You can see Andrew and I puzzling over it in the PR.")," We don't know why yet; it's possible there's a bug in ",(0,a.kt)("inlineCode",{parentName:"p"},"tsc"),". It's more likely there's a bug in ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader"),". Hopefully it's going to get solved at some point. (Hey, maybe you're the one to solve it!) Either way, we didn't want to hold back from releasing. So if you're building on Windows then avoid building ",(0,a.kt)("inlineCode",{parentName:"p"},"composite")," projects using ",(0,a.kt)("inlineCode",{parentName:"p"},"outDir"),"."))}d.isMDXComponent=!0},10546:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"font-awesome-brand-icons-react",title:"Brand New Fonting Awesomeness",authors:"johnnyreilly",tags:["React"],hide_table_of_contents:!1},s=void 0,l={permalink:"/font-awesome-brand-icons-react",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-10-07-font-awesome-brand-icons-react/index.md",source:"@site/blog/2018-10-07-font-awesome-brand-icons-react/index.md",title:"Brand New Fonting Awesomeness",description:"Love me some Font Awesome. Absolutely wonderful. However, I came a cropper when following the instructions on using the all new Font Awesome 5 with React. The instructions for standard icons work fine. But if you want to use brand icons then this does not help you out much. There's 2 problems:",date:"2018-10-07T00:00:00.000Z",formattedDate:"October 7, 2018",tags:[{label:"React",permalink:"/tags/react"}],readingTime:1.435,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"font-awesome-brand-icons-react",title:"Brand New Fonting Awesomeness",authors:"johnnyreilly",tags:["React"],hide_table_of_contents:!1},prevItem:{title:"Making a Programmer",permalink:"/making-a-programmer"},nextItem:{title:"ts-loader Project References: First Blood",permalink:"/ts-loader-project-references-first-blood"}},p={authorsImageUrls:[void 0]},u=[{value:"Brand Me Up Buttercup",id:"brand-me-up-buttercup",level:2},{value:"Update: It is documented!",id:"update-it-is-documented",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Love me some ",(0,a.kt)("a",o({parentName:"p"},{href:"https://fontawesome.com"}),"Font Awesome"),". Absolutely wonderful. However, I came a cropper when following the instructions ",(0,a.kt)("a",o({parentName:"p"},{href:"https://fontawesome.com/how-to-use/on-the-web/using-with/react"}),"on using the all new Font Awesome 5 with React"),". The instructions for standard icons work ",(0,a.kt)("em",{parentName:"p"},"fine"),". But if you want to use brand icons then this does not help you out much. There's 2 problems:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Font Awesome's brand icons are not part of ",(0,a.kt)("a",o({parentName:"li"},{href:"https://www.npmjs.com/package/@fortawesome/free-solid-svg-icons"}),(0,a.kt)("inlineCode",{parentName:"a"},"@fortawesome/free-solid-svg-icons"))," package"),(0,a.kt)("li",{parentName:"ol"},"The method of icon usage illustrated (i.e. with the ",(0,a.kt)("inlineCode",{parentName:"li"},"FontAwesomeIcon")," component) doesn't work. It doesn't render owt.")),(0,a.kt)("h2",o({},{id:"brand-me-up-buttercup"}),"Brand Me Up Buttercup"),(0,a.kt)("p",null,"You want brands? Well you need the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/@fortawesome/free-brands-svg-icons"}),(0,a.kt)("inlineCode",{parentName:"a"},"@fortawesome/free-brands-svg-icons")),". Obvs, right?"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-sh"}),"yarn add @fortawesome/fontawesome-svg-core\nyarn add @fortawesome/free-brands-svg-icons\nyarn add @fortawesome/react-fontawesome\n")),(0,a.kt)("p",null,"Now usage:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-jsx"}),"import * as React from 'react';\nimport { FontAwesomeIcon } from '@fortawesome/react-fontawesome';\nimport { faReact } from '@fortawesome/free-brands-svg-icons';\n\nexport const Framework = () => (\n  <div>\n    Favorite Framework: <FontAwesomeIcon icon={faReact} />\n  </div>\n);\n")),(0,a.kt)("p",null,"Here we've ditched the \"library / magic-string\" approach from the documentation for one which explicitly imports and uses the required icons. I suspect this will be good for tree-shaking as well but, hand-on-heart, I haven't rigorously tested that. I'm not sure why the approach I'm using isn't documented actually. Mysterious! I've seen no ill-effects from using it but perhaps YMMV. Proceed with caution..."),(0,a.kt)("h2",o({},{id:"update-it-is-documented"}),"Update: It is documented!"),(0,a.kt)("p",null,"Yup - information on this approach is out there; but it's less obvious than you might hope. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/FortAwesome/react-fontawesome#explicit-import"}),"Read all about it here.")," For what it's worth, the explicit import approach seems to be playing second fiddle to the library / magic-string one. I'm not too sure why. For my money, explicit imports are clearer, less prone to errors and better setup for optimisation. Go figure..."),(0,a.kt)("p",null,"Feel free to set me straight in the comments!"))}d.isMDXComponent=!0},98883:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"making-a-programmer",title:"Making a Programmer",authors:"johnnyreilly",hide_table_of_contents:!1},s=void 0,l={permalink:"/making-a-programmer",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-10-27-making-a-programmer/index.md",source:"@site/blog/2018-10-27-making-a-programmer/index.md",title:"Making a Programmer",description:"I recently had the good fortune to help run a coding bootcamp. The idea was simple: there are many people around us who are interested in programming but don't know where to start. Let's take some folk who do and share the knowledge.",date:"2018-10-27T00:00:00.000Z",formattedDate:"October 27, 2018",tags:[],readingTime:6.02,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"making-a-programmer",title:"Making a Programmer",authors:"johnnyreilly",hide_table_of_contents:!1},prevItem:{title:"Snapshot Testing for C#",permalink:"/snapshot-testing-for-c"},nextItem:{title:"Brand New Fonting Awesomeness",permalink:"/font-awesome-brand-icons-react"}},p={authorsImageUrls:[void 0]},u=[{value:"Code Review",id:"code-review",level:2},{value:"Merging to Master",id:"merging-to-master",level:2},{value:"RTM",id:"rtm",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I recently had the good fortune to help run a coding bootcamp. The idea was simple: there are many people around us who are interested in programming but don't know where to start. Let's take some folk who do and share the knowledge."),(0,a.kt)("p",null,"The bootcamp went tremendously! (Well, I say that... Frankly I had a blast. \ud83d\ude00 )"),(0,a.kt)("p",null,"Coding padawans walked in at the start with laptops and questions, and six weeks later they left with the groundwork of development experience. We ran a session for an hour during lunchtime once a week. Between that, people would have the opportunity to learn online, do exercises and reach out to the facilitators and their fellow apprentices for help."),(0,a.kt)("p",null,"We'd never done this before. We were student teachers; learning how to teach as we ran the course. So what did we do? Are you curious? Read on, Macduff!"),(0,a.kt)("h2",o({},{id:"code-review"}),"Code Review"),(0,a.kt)("p",null,"It's worth saying now that we started our course with a plan: the plan was that we would be ready to change the plan. Or to put it another way, we were ready to pivot as we went."),(0,a.kt)("p",null,'We (by which I mean myself and the other course organisers) are interested in feedback. Sitting back and saying "Hey! We did this thing.... What do you think about it?" Because sometimes your plans are great. Do more of that hotness! But also, not all your ideas pan out... Maybe bail on those guys. Finally, never forget: other folk have brain tickling notions too.... We\'re with Picasso on this: good artists copy; great artists steal.'),(0,a.kt)("p",null,"We're heavily invested in feedback in both what we build and how we build it. So we were totally going to apply this to doing something we'd never done before. So seized were we of this that we made feedback part of the session. For the last five minutes each week we'd run a short retrospective. We'd stick up happy, sad and \"meh\" emojis to the wall, hand out post-its and everyone got to stick up their thoughts."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(29825).Z,width:"400",height:"341"})),(0,a.kt)("p",null,"From that we learned what was working, what wasn't and when we were very lucky there were suggestions too. We listened to all the feedback and the next week's session would be informed by what we'd just learned."),(0,a.kt)("h2",o({},{id:"merging-to-master"}),"Merging to Master"),(0,a.kt)("p",null,"So, what did we end up with? What did our coding bootcamp look like?"),(0,a.kt)("p",null,"Well, to start each session we kicked off with an icebreaker. We very much wanted the sessions to be interactive experiences; we wanted them to feel playful and human. So an icebreaker was a good way to get things off on the right foot."),(0,a.kt)("p",null,'The IBs were connected with the subject at hand. For example: Human FizzBuzz. We took the classic interview question and applied it to wannabe coders. We explained the rules, and went round in a circle, each person was the next iteration of the loop. As each dev-in-training opened their mouths they had to say a number or "Fizz" or "Buzz" or "FizzBuzz". (It turns out this is harder than you think; and makes for a surprisingly entertaining parlour game. I intend to do this at my next dinner party.)'),(0,a.kt)("p",null,"After that we covered the rules of the game. (Yup, learning is a game and it's a good 'un.) Certainly the most important rule was this: ",(0,a.kt)("u",null,"there are ",(0,a.kt)("strong",null,(0,a.kt)("em",{parentName:"p"},"no"))," stupid questions")),(0,a.kt)("p",null,". If people think there are, then they might be hesitant to ask. And any question benched is a learning opportunity lost. We don't want that."),(0,a.kt)("p",null,'"Ask any question!" we said each week. Kudos to the people who have the courage to pipe up. We salute you! You\'re likely putting voice to a common area of misunderstanding.'),(0,a.kt)("p",null,"Then we'd move onto the main content. The initial plan was to make use of the excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.edx.org/learn/python"}),"EdX Python course")," Between each session our learners would do a module and then we'd come together and talk around that topic somewhat. Whilst this was a good initial plan it did make the learning experience somewhat passive and less interactive than we'd hoped."),(0,a.kt)("p",null,"One week we tried something different. It turns out that the amazing ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/foldr"}),"JMac")," has quite the skill for writing programming exercises. Small coding challenges that people can tackle independently. JMac put together a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://repl.it/"}),"repl.it")," of exercises and encouraged the class to get stuck in. They did. So much so that at the end of the session it was hard to get everyone's attention to let them know the session was over. They were in the zone. When we did finally disrupt their flow, the feedback was pretty unanimous: we'd hit paydirt."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(75760).Z,width:"400",height:"357"})),(0,a.kt)("p",null,"Consequently, that was the format going onwards. JMac would come up with a number of exercises for the class. Wisely they were constructed so that they gently levelled up in terms of complexity as you went on. You'd get the dopamine hit of satisfaction as you did the earliest challenges that would give you the confidence to tackle the more complex later problems. If peeps got stuck they could ask someone to advise them, a facilitator or a peer. Or they could google it.... Like any other dev."),(0,a.kt)("p",null,"Having the chance to talk with others when you're stuck is fantastic. You can talk through a problem. The act of doing that is a useful exercise. When you talk through a problem out loud you can unlock your understanding and often get to the point where you can tackle this yourself. This is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Rubber_duck_debugging"}),"rubber duck debugging"),". Any dev does this in their everyday; it makes complete sense to have it as part of a coding bootcamp."),(0,a.kt)("p",null,'We learned that it was useful, very useful, to have repitition in the exercises. Repitition. Repitition. Repitition. As the exercises started each week they would typically begin by recapping and repeating the content covered the previous week. The best way to learn is to practice. It\'s not for nothing the Karate Kid had to "wax on, wax off".'),(0,a.kt)("p",null,"Finally, we did this together. The course wasn't run by one person; we had a gang! We had three facilitators who helped to run the sessions; JMac, Jonesy and myself. We also had the amazing ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/janicewarden"}),"Janice")," who handled the general organisation and logistics. And made us laugh. A lot. This was obviously great from a camaraderie and sharing the load perspective. It turns out that having that number of facilitators in the session meant that everyone who needed help could get it. It's worth noting that having more than a single facilitator is useful in terms of the dynamic it creates. You can bounce things off one another; you can use each other for examples and illustrations. You can crack each other up. Done well it reduces the instructor / learner divide and that breaking down of barriers is something worth seeking."),(0,a.kt)("h2",o({},{id:"rtm"}),"RTM"),(0,a.kt)("p",null,"We've run a bootcamp once now. Where we are is informed by the experience we've just had. A different group of learners may well have resulted in a slightly different format; though I have a feeling not overly dissimilar. We feel pretty sure that what we've got is pretty solid. That said, just as the attendees are learning about development, we're still learning about learning!"))}d.isMDXComponent=!0},37047:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"snapshot-testing-for-c",title:"Snapshot Testing for C#",authors:"johnnyreilly",tags:["snapshot testing","c#","jest"],hide_table_of_contents:!1},s=void 0,l={permalink:"/snapshot-testing-for-c",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-11-17-snapshot-testing-for-c/index.md",source:"@site/blog/2018-11-17-snapshot-testing-for-c/index.md",title:"Snapshot Testing for C#",description:"If you're a user of Jest, you've no doubt heard of and perhaps made use of snapshot testing.",date:"2018-11-17T00:00:00.000Z",formattedDate:"November 17, 2018",tags:[{label:"snapshot testing",permalink:"/tags/snapshot-testing"},{label:"c#",permalink:"/tags/c"},{label:"jest",permalink:"/tags/jest"}],readingTime:5.69,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"snapshot-testing-for-c",title:"Snapshot Testing for C#",authors:"johnnyreilly",tags:["snapshot testing","c#","jest"],hide_table_of_contents:!1},prevItem:{title:"Cache Rules Everything Around Me",permalink:"/cache-rules-everything-around-me"},nextItem:{title:"Making a Programmer",permalink:"/making-a-programmer"}},p={authorsImageUrls:[void 0]},u=[{value:"Putting the Snapshot into C#",id:"putting-the-snapshot-into-c",level:2},{value:"Taking Snapshot for a Spin",id:"taking-snapshot-for-a-spin",level:2},{value:"Time Passes...",id:"time-passes",level:2},{value:"Next Steps",id:"next-steps",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"If you're a user of Jest, you've no doubt heard of and perhaps made use of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://jestjs.io/docs/en/snapshot-testing"}),"snapshot testing"),"."),(0,a.kt)("p",null,"Snapshot testing is an awesome tool that is generally discussed in the context of JavaScript React UI testing. But snapshot testing has a wider application than that. Essentially it is profoundly useful where you have functions which produce a complex structured output. It could be a React UI, it could be a list of FX prices. The type of data is immaterial; it's the amount of it that's key."),(0,a.kt)("p",null,"Typically there's a direct correlation between the size and complexity of the output of a method and the length of the tests that will be written for it. Let's say you're outputting a class that contains 20 properties. Congratulations! You get to write 20 assertions in one form or another for each test case. Or a single assertion whereby you supply the expected output by hand specifying each of the 20 properties. Either way, that's not going to be fun. And just imagine the time it would take to update multiple test cases if you wanted to change the behaviour of the method in question. Ouchy."),(0,a.kt)("p",null,"Time is money kid. What you need is snapshot testing. Say goodbye to handcrafted assertions and hello to JSON serialised output checked into source control. Let's unpack that a little bit. The usefulness of snapshot testing that I want in C# is predominantly about removing the need to write and maintain multiple assertions. Instead you write tests that compare the output of a call to your method with JSON serialised output you've generated on a previous occasion."),(0,a.kt)("p",null,"This approach takes less time to write, less time to maintain and the solid readability of JSON makes it more likely you'll pick up on bugs. It's so much easier to scan JSON than it is a list of assertions."),(0,a.kt)("h2",o({},{id:"putting-the-snapshot-into-c"}),"Putting the Snapshot into C#"),(0,a.kt)("p",null,"Now if you're writing tests in JavaScript or TypeScript then Jest already has your back with CLI snapshot generation and ",(0,a.kt)("inlineCode",{parentName:"p"},"shouldMatchSnapshot"),". However getting to nearly the same place in C# is delightfully easy. What are we going to need?"),(0,a.kt)("p",null,"First up, a serializer which can take your big bad data structures and render them as JSON. Also we'll use it to rehydrate our data structure into an object ready for comparison. We're going to use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.newtonsoft.com/json"}),"Json.NET"),"."),(0,a.kt)("p",null,"Next up we need a way to compare our outputs with our rehydrated snapshots - we need a C# ",(0,a.kt)("inlineCode",{parentName:"p"},"shouldMatchSnapshot"),". There's many choices out there, but for my money ",(0,a.kt)("a",o({parentName:"p"},{href:"https://fluentassertions.com"}),"Fluent Assertions")," is king of the hill."),(0,a.kt)("p",null,"Finally we're going to need Snapshot, a little helper utility I put together:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.IO;\nusing Newtonsoft.Json;\nusing Newtonsoft.Json.Serialization;\n\nnamespace Test.Utilities {\n    public static class Snapshot {\n        private static readonly JsonSerializer StubSerializer = new JsonSerializer {\n            ContractResolver = new CamelCasePropertyNamesContractResolver(),\n            NullValueHandling = NullValueHandling.Ignore\n        };\n\n        private static JsonTextWriter MakeJsonTextWriter(TextWriter sw) => new JsonTextWriter(sw) {\n            Formatting = Formatting.Indented,\n            IndentChar = \' \',\n            Indentation = 2\n        };\n\n        /// <summary>\n        /// Make yourself some JSON! Usage looks like this:\n        /// Stubs.Make($"{System.AppDomain.CurrentDomain.BaseDirectory}..\\\\..\\\\..\\\\data.json", myData);\n        /// </summary>\n        public static void Make<T>(string stubPath, T data) {\n            try {\n                if (string.IsNullOrEmpty(stubPath))\n                    throw new ArgumentNullException(nameof(stubPath));\n                if (data == null)\n                    throw new ArgumentNullException(nameof(data));\n\n                using(var sw = new StreamWriter(stubPath))\n                using(var writer = MakeJsonTextWriter(sw)) {\n                    StubSerializer.Serialize(writer, data);\n                }\n            } catch (Exception exc) {\n                throw new Exception($"Failed to make {stubPath}", exc);\n            }\n        }\n\n        public static string Serialize<T>(T data) {\n            using (var sw = new StringWriter())\n            using(var writer = MakeJsonTextWriter(sw)) {\n                StubSerializer.Serialize(writer, data);\n                return sw.ToString();\n            }\n        }\n\n        public static string Load(string filename) {\n            var content = new StreamReader(\n                File.OpenRead(filename)\n            ).ReadToEnd();\n\n            return content;\n        }\n    }\n}\n')),(0,a.kt)("p",null,"Let's look at the methods: ",(0,a.kt)("inlineCode",{parentName:"p"},"Make")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"Load"),". Make is what we're going to use to create our snapshots. Load is what we're going to use to, uh, load our snapshots."),(0,a.kt)("p",null,"What does usage look like? Great question. Let's go through the process of writing a C# snapshot test."),(0,a.kt)("h2",o({},{id:"taking-snapshot-for-a-spin"}),"Taking Snapshot for a Spin"),(0,a.kt)("p",null,"First of all, we're going to need a method to test that outputs a data structure which is more than just a scalar value. Let's use this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public class Leopard {\n    public string Name { get; set; }\n    public int Spots { get; set; }\n}\n\npublic class LeopardService {\n    public Leopard[] GetTheLeopards() {\n        return new Leopard[] {\n            new Leopard { Spots = 42, Name = "Nimoy" },\n            new Leopard { Spots = 900, Name = "Dotty" }\n        };\n    }\n}\n')),(0,a.kt)("p",null,"Yes - our trusty ",(0,a.kt)("inlineCode",{parentName:"p"},"LeopardService"),". As you can see, the ",(0,a.kt)("inlineCode",{parentName:"p"},"GetTheLeopards")," method returns an array of ",(0,a.kt)("inlineCode",{parentName:"p"},"Leopard"),"s. For now, let's write a test using ",(0,a.kt)("inlineCode",{parentName:"p"},"Snapshot"),": (ours is an XUnit test; but ",(0,a.kt)("inlineCode",{parentName:"p"},"Snapshot")," is agnostic of this)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[Fact]\npublic void GetTheLeopards_should_return_expected_Leopards() {\n    // Arrange\n    var leopardService = new LeopardService();\n\n    // Act\n    var leopards = leopardService.GetTheLeopards();\n\n    // UNCOMMENT THE LINE BELOW *ONLY* WHEN YOU WANT TO GENERATE THE SNAPSHOT\n    Snapshot.Make($"{System.AppDomain.CurrentDomain.BaseDirectory}..\\\\..\\\\..\\\\Snapshots\\\\leopardsSnapshot.json", leopards);\n\n    // Assert\n    var snapshotLeopards = JsonConvert.DeserializeObject<leopard[]>(Snapshot.Load("Snapshots/leopardsSnapshot.json"));\n    snapshotLeopards.Should().BeEquivalentTo(leopards);\n}\n</leopard[]>\n')),(0,a.kt)("p",null,"Before we run this for the first time we need to setup our testing project to be ready for snapshots. First of all we add a ",(0,a.kt)("inlineCode",{parentName:"p"},"Snapshot")," folder to the test project. The we also add the following to the ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<ItemGroup>\n    <Content Include="Snapshots\\**">\n      <CopyToOutputDirectory>Always</CopyToOutputDirectory>\n    </Content>\n  </ItemGroup>\n')),(0,a.kt)("p",null,"This includes the snapshots in the compile output for when tests are being run."),(0,a.kt)("p",null,"Now let's run the test. It will generate a ",(0,a.kt)("inlineCode",{parentName:"p"},"leopardsSnapshot.json")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'[\n  {\n    "name": "Nimoy",\n    "spots": 42\n  },\n  {\n    "name": "Dotty",\n    "spots": 900\n  }\n]\n')),(0,a.kt)("p",null,"With our snapshot in place, we comment out the ",(0,a.kt)("inlineCode",{parentName:"p"},"Snapshot.Make...")," line and we have a passing test. Let's commit our code, push and go about our business."),(0,a.kt)("h2",o({},{id:"time-passes"}),"Time Passes..."),(0,a.kt)("p",null,"Someone decides that the implementation of ",(0,a.kt)("inlineCode",{parentName:"p"},"GetTheLeopards")," needs to change. Defying expectations it seems that Dotty the leopard should now have 90 spots. I know... Business requirements, right?"),(0,a.kt)("p",null,"If we make that change we'd ideally expect our trusty test to fail. Let's see what happens:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"----- Test Execution Summary -----\n\nLeopard.Tests.Services.LeopardServiceTests.GetTheLeopards_should_return_expected_Leopards:\n    Outcome: Failed\n    Error Message:\n    Expected item[1].Spots to be 90, but found 900.\n")),(0,a.kt)("p",null,"Boom! We are protected!"),(0,a.kt)("p",null,"Since this is a change we're completely happy with we want to update our ",(0,a.kt)("inlineCode",{parentName:"p"},"leopardsSnapshot.json")," file. We could make our test pass by manually updating the JSON. That'd be fine. But why work when you don't have to? Let's uncomment our ",(0,a.kt)("inlineCode",{parentName:"p"},"Snapshot.Make...")," line and run the test the once."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'[\n  {\n    "name": "Nimoy",\n    "spots": 42\n  },\n  {\n    "name": "Dotty",\n    "spots": 90\n  }\n]\n')),(0,a.kt)("p",null,"That's right, we have an updated snapshot! Minimal effort."),(0,a.kt)("h2",o({},{id:"next-steps"}),"Next Steps"),(0,a.kt)("p",null,"This is a basic approach to getting the goodness of snapshot testing in C#. It could be refined further. To my mind the uncommenting / commenting of code is not the most elegant way to approach this and so there's some work that could be done around this area."),(0,a.kt)("p",null,"Happy snapshotting!"))}d.isMDXComponent=!0},97139:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"cache-rules-everything-around-me",title:"Cache Rules Everything Around Me",authors:"johnnyreilly",tags:["asp.net core"],hide_table_of_contents:!1},s=void 0,l={permalink:"/cache-rules-everything-around-me",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-12-10-cache-rules-everything-around-me/index.md",source:"@site/blog/2018-12-10-cache-rules-everything-around-me/index.md",title:"Cache Rules Everything Around Me",description:"One thing that ASP.Net Core really got right was caching. IMemoryCache is a caching implementation that does just what I want. I love it. I take it everywhere. I've introduced it to my family.",date:"2018-12-10T00:00:00.000Z",formattedDate:"December 10, 2018",tags:[{label:"asp.net core",permalink:"/tags/asp-net-core"}],readingTime:1.575,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"cache-rules-everything-around-me",title:"Cache Rules Everything Around Me",authors:"johnnyreilly",tags:["asp.net core"],hide_table_of_contents:!1},prevItem:{title:"You Might Not Need thread-loader",permalink:"/you-might-not-need-thread-loader"},nextItem:{title:"Snapshot Testing for C#",permalink:"/snapshot-testing-for-c"}},p={authorsImageUrls:[void 0]},u=[{value:"TimeSpan, TimeSpan Expiration Y&#39;all",id:"timespan-timespan-expiration-yall",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"One thing that ASP.Net Core really got right was caching. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/aspnet/core/performance/caching/memory"}),(0,a.kt)("inlineCode",{parentName:"a"},"IMemoryCache"))," is a caching implementation that does just what I want. I love it. I take it everywhere. I've introduced it to my family."),(0,a.kt)("h2",o({},{id:"timespan-timespan-expiration-yall"}),"TimeSpan, TimeSpan Expiration Y'all"),(0,a.kt)("p",null,"To make usage of the ",(0,a.kt)("inlineCode",{parentName:"p"},"IMemoryCache")," ",(0,a.kt)("em",{parentName:"p"},"even")," more lovely I've written an extension method. I follow pretty much one cache strategy: ",(0,a.kt)("inlineCode",{parentName:"p"},"SetAbsoluteExpiration")," and I just vary the expiration by an amount of time. This extension method implements that in a simple way; I call it ",(0,a.kt)("inlineCode",{parentName:"p"},"GetOrCreateForTimeSpanAsync")," - catchy right? It looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"using System;\nusing System.Threading.Tasks;\nusing Microsoft.Extensions.Caching.Memory;\n\nnamespace My.Helpers {\n\n    public static class CacheHelpers {\n\n        public static async Task<TItem> GetOrCreateForTimeSpanAsync<TItem>(\n            this IMemoryCache cache,\n            string key,\n            Func<Task<TItem>> itemGetterAsync,\n            TimeSpan timeToCache\n        ) {\n            if (!cache.TryGetValue(key, out object result)) {\n                result = await itemGetterAsync();\n                if (result == null)\n                    return default(TItem);\n\n                var cacheEntryOptions = new MemoryCacheEntryOptions()\n                    .SetAbsoluteExpiration(timeToCache);\n\n                cache.Set(key, result, cacheEntryOptions);\n            }\n\n            return (TItem) result;\n        }\n    }\n}\n")),(0,a.kt)("p",null,"Usage looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'private Task<SuperInterestingThing> GetSuperInterestingThingFromCache(Guid superInterestingThingId) =>\n    _cache.GetOrCreateForTimeSpanAsync(\n        key: $"{nameof(MyClass)}:GetSuperInterestingThing:{superInterestingThingId}",\n        itemGetterAsync: () => GetSuperInterestingThing(superInterestingThingId),\n        timeToCache: TimeSpan.FromMinutes(5)\n    );\n')),(0,a.kt)("p",null,"This helper allows the consumer to provide three things:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"The ",(0,a.kt)("inlineCode",{parentName:"li"},"key")," key for the item to be cached with"),(0,a.kt)("li",{parentName:"ul"},"A ",(0,a.kt)("inlineCode",{parentName:"li"},"itemGetterAsync")," which is the method that is used to retrieve a new value if an item cannot be found in the cache"),(0,a.kt)("li",{parentName:"ul"},"A ",(0,a.kt)("inlineCode",{parentName:"li"},"timeToCache")," which is the period of time that an item should be cached")),(0,a.kt)("p",null,"If an item can't be looked up by the ",(0,a.kt)("inlineCode",{parentName:"p"},"itemGetterAsync")," then ",(0,a.kt)("em",{parentName:"p"},"nothing")," will be cached and a the ",(0,a.kt)("inlineCode",{parentName:"p"},"default")," value of the expected type will be returned. This is important because lookups can fail, and there's nothing worse than a lookup failing and you caching ",(0,a.kt)("inlineCode",{parentName:"p"},"null")," as a result."),(0,a.kt)("p",null,"Go on, ask me how I know."),(0,a.kt)("p",null,"This is a simple, clear and helpful API which makes interacting with ",(0,a.kt)("inlineCode",{parentName:"p"},"IMemoryCache")," even more lovely than it was. Peep it y'all."))}d.isMDXComponent=!0},19083:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"you-might-not-need-thread-loader",title:"You Might Not Need thread-loader",authors:"johnnyreilly",tags:["fork-ts-checker-webpack-plugin","ts-loader","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/you-might-not-need-thread-loader",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2018-12-22-you-might-not-need-thread-loader/index.md",source:"@site/blog/2018-12-22-you-might-not-need-thread-loader/index.md",title:"You Might Not Need thread-loader",description:"It all started with a GitHub issue. Ernst Ammann reported:",date:"2018-12-22T00:00:00.000Z",formattedDate:"December 22, 2018",tags:[{label:"fork-ts-checker-webpack-plugin",permalink:"/tags/fork-ts-checker-webpack-plugin"},{label:"ts-loader",permalink:"/tags/ts-loader"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:3.68,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"you-might-not-need-thread-loader",title:"You Might Not Need thread-loader",authors:"johnnyreilly",tags:["fork-ts-checker-webpack-plugin","ts-loader","webpack"],hide_table_of_contents:!1},prevItem:{title:"GitHub Actions and Yarn",permalink:"/github-actions-and-yarn"},nextItem:{title:"Cache Rules Everything Around Me",permalink:"/cache-rules-everything-around-me"}},p={authorsImageUrls:[void 0]},u=[{value:"All I Want For Christmas is Faster Builds",id:"all-i-want-for-christmas-is-faster-builds",level:2},{value:"<code>thread-loader</code>: Infinity War",id:"thread-loader-infinity-war",level:2},{value:"&quot;Maybe You&#39;ve Thread Enough&quot;",id:"maybe-youve-thread-enough",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"It all started with a GitHub issue. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/namics/webpack-config-plugins/issues/24"}),"Ernst Ammann reported"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Without the thread-loader, compilation takes three to four times less time on changes. We could remove it.")),(0,a.kt)("p",null,"If you're not aware of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/namics/webpack-config-plugins"}),(0,a.kt)("inlineCode",{parentName:"a"},"webpack-config-plugins"))," project then I commend it to you. Famously, webpack configuration can prove tricky. ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack-config-plugins")," borrows the idea of presets from Babel. It provides a number of pluggable webpack configurations which give a best practice setup for different webpack use cases. So if you're no expert with webpack and you want a good setup for building your TypeScript / Sass / JavaScript then ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack-config-plugins")," has got your back."),(0,a.kt)("p",null,"One of the people behind the project is the very excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jantimon"}),"Jan Nicklas")," who is well known for his work on the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jantimon/html-webpack-plugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"html-webpack-plugin")),"."),(0,a.kt)("p",null,"It was Jan who responded to Ernst's issue and decided to look into it."),(0,a.kt)("h2",o({},{id:"all-i-want-for-christmas-is-faster-builds"}),"All I Want For Christmas is Faster Builds"),(0,a.kt)("p",null,"Everyone wants fast builds. I do. You do. We all do. ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack-config-plugins")," is about giving these to the user in a precooked package."),(0,a.kt)("p",null,"There's a webpack loader called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack-contrib/thread-loader"}),(0,a.kt)("inlineCode",{parentName:"a"},"thread-loader"))," which spawns multiple processes and splits up work between them. It was originally inspired by the work in the happypack project which does a similar thing."),(0,a.kt)("p",null,"I wrote ",(0,a.kt)("a",o({parentName:"p"},{href:"https://medium.com/p/83cc568dea79"}),"a blog post")," some time ago which gave details about ways to speed up your TypeScript builds by combining the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader"}),(0,a.kt)("inlineCode",{parentName:"a"},"ts-loader"))," project (which I manage) with the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"fork-ts-checker-webpack-plugin"))," project (which I'm heavily involved with)."),(0,a.kt)("p",null,"That post was written back in the days of webpack 2 / 3. It advocated use of both ",(0,a.kt)("inlineCode",{parentName:"p"},"happypack")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"thread-loader")," to drop your build times even further. As you'll see, now that we're well into the world of webpack 4 (with webpack 5 waiting in the wings) the advantage of ",(0,a.kt)("inlineCode",{parentName:"p"},"happypack")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"thread-loader")," are no longer so profound."),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"webpack-config-plugins")," follows the advice I set out in my post; it uses ",(0,a.kt)("inlineCode",{parentName:"p"},"thread-loader")," in its pluggable configurations. Now, back to Ernst's issue."),(0,a.kt)("h2",o({},{id:"thread-loader-infinity-war"}),(0,a.kt)("inlineCode",{parentName:"h2"},"thread-loader"),": Infinity War"),(0,a.kt)("p",null,"Jan quickly identified the problem. He did that rarest of things; he read the documentation which said:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"// timeout for killing the worker processes when idle\n      // defaults to 500 (ms)\n      // can be set to Infinity for watching builds to keep workers alive\n      poolTimeout: 2000,\n")),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack-config-plugins")," configurations (running in watch mode) were subject to the thread loaders being killed after 500ms. They got resurrected when they were next needed; but that's not as instant as you might hope. Jan then did a test:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-sh"}),"(default pool - 30 runs - 1000 components ) average: 2.668068965517241\n(no thread-loader - 30 runs - 1000 components ) average: 1.2674137931034484\n(Infinity pool - 30 runs - 1000 components ) average: 1.371827586206896\n")),(0,a.kt)("p",null,"This demonstrates that using ",(0,a.kt)("inlineCode",{parentName:"p"},"thread-loader")," in watch mode with ",(0,a.kt)("inlineCode",{parentName:"p"},"poolTimeout: Infinity")," performs significantly better than when it defaults to 500ms. But perhaps more significantly, not using ",(0,a.kt)("inlineCode",{parentName:"p"},"thread-loader")," performs even better still."),(0,a.kt)("h2",o({},{id:"maybe-youve-thread-enough"}),'"Maybe You\'ve Thread Enough"'),(0,a.kt)("p",null,"When I tested using ",(0,a.kt)("inlineCode",{parentName:"p"},"thread-loader")," in watch mode with ",(0,a.kt)("inlineCode",{parentName:"p"},"poolTimeout: Infinity")," on my own builds I got the same benefit Jan had. I also got ",(0,a.kt)("em",{parentName:"p"},"even")," more benefit from dropping ",(0,a.kt)("inlineCode",{parentName:"p"},"thread-loader")," entirely."),(0,a.kt)("p",null,"A likely reason for this benefit is that typically when you're developing, you're working on one file at a time. Hence you only transpile one file at a time:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(97023).Z,width:"640",height:"173"})),(0,a.kt)("p",null,"So there's not a great deal of value that ",(0,a.kt)("inlineCode",{parentName:"p"},"thread-loader")," can add here; mostly it's twiddling thumbs and adding an overhead. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack-contrib/thread-loader/blob/master/README/index.md#usage"}),"To quote the docs:")),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Each worker is a separate node.js process, which has an overhead of ","~","600ms. There is also an overhead of inter-process communication."),(0,a.kt)("p",{parentName:"blockquote"},"Use this loader only for expensive operations!")),(0,a.kt)("p",null,"Now, my build is not your build. I can't guarantee that you'll get the same results as Jan and I experienced; but I would encourage you to investigate if you're using ",(0,a.kt)("inlineCode",{parentName:"p"},"thread-loader")," correctly and whether it's actually helping you. In these days of webpack 4+ perhaps it isn't."),(0,a.kt)("p",null,"There are still scenarios where ",(0,a.kt)("inlineCode",{parentName:"p"},"thread-loader")," still provides an advantage. It can speed up production builds. It can speed up the initial startup of watch mode. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack-contrib/thread-loader/pull/52"}),"In fact Jan has subsequently actually improved the ",(0,a.kt)("inlineCode",{parentName:"a"},"thread-loader")," to that specific end.")," Yay Jan!"),(0,a.kt)("p",null,"If this is all too much for you, and you want to hand off the concern to someone else then perhaps all of this serves as a motivation to just sit back, put your feet up and start using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/namics/webpack-config-plugins"}),(0,a.kt)("inlineCode",{parentName:"a"},"webpack-config-plugins"))," instead of doing your own configuration."))}d.isMDXComponent=!0},409:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"github-actions-and-yarn",title:"GitHub Actions and Yarn",authors:"johnnyreilly",tags:["docker","yarn","GitHub Actions"],hide_table_of_contents:!1},s=void 0,l={permalink:"/github-actions-and-yarn",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2019-01-05-github-actions-and-yarn/index.md",source:"@site/blog/2019-01-05-github-actions-and-yarn/index.md",title:"GitHub Actions and Yarn",description:"I'd been meaning to automate the npm publishing of ts-loader for the longest time. I had attempted to use Travis to do this in the same way as fork-ts-checker-webpack-plugin. Alas using secure environment variables in Travis has unfortunate implications for ts-loader's test pack.",date:"2019-01-05T00:00:00.000Z",formattedDate:"January 5, 2019",tags:[{label:"docker",permalink:"/tags/docker"},{label:"yarn",permalink:"/tags/yarn"},{label:"GitHub Actions",permalink:"/tags/git-hub-actions"}],readingTime:4,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"github-actions-and-yarn",title:"GitHub Actions and Yarn",authors:"johnnyreilly",tags:["docker","yarn","GitHub Actions"],hide_table_of_contents:!1},prevItem:{title:"TypeScript and webpack: Watch It",permalink:"/typescript-and-webpack-watch-it"},nextItem:{title:"You Might Not Need thread-loader",permalink:"/you-might-not-need-thread-loader"}},p={authorsImageUrls:[void 0]},u=[{value:"Automate What?",id:"automate-what",level:2},{value:"GitHub Action for <code>npm</code>",id:"github-action-for-npm",level:2},{value:"GitHub Action for <code>npm</code> for <code>yarn</code>",id:"github-action-for-npm-for-yarn",level:2},{value:"Going With The Workflow",id:"going-with-the-workflow",level:2},{value:"You Don&#39;t Actually Need the npm GitHub Action",id:"you-dont-actually-need-the-npm-github-action",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I'd been meaning to automate the npm publishing of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader"}),(0,a.kt)("inlineCode",{parentName:"a"},"ts-loader"))," for the longest time. I had attempted to use Travis to do this in the same way as ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"fork-ts-checker-webpack-plugin")),". Alas using secure environment variables in Travis has unfortunate implications for ts-loader's test pack."),(0,a.kt)("p",null,"Be not afeard. I've heard there's a new shiny thing from GitHub that I could use instead... It's a sign; I must use it!"),(0,a.kt)("p",null,"GitHub Actions are still in beta. Technically Actions are ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.github.com/actions/creating-github-actions/"}),"code run in Docker containers")," in response to events. This didn't mean a great deal to me until I started thinking about what I wanted to do with ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader"),"'s publishing flow."),(0,a.kt)("h2",o({},{id:"automate-what"}),"Automate What?"),(0,a.kt)("p",null,"Each time I publish a release of ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," I execute the following node commands by hand:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"yarn install")," ","-"," to install ",(0,a.kt)("inlineCode",{parentName:"li"},"ts-loader"),"'s dependencies"),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"yarn build")," ","-"," to build ",(0,a.kt)("inlineCode",{parentName:"li"},"ts-loader")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"yarn test")," ","-"," to run ",(0,a.kt)("inlineCode",{parentName:"li"},"ts-loader"),"'s test packs"),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"npm publish")," ","-"," to publish the release of ",(0,a.kt)("inlineCode",{parentName:"li"},"ts-loader")," to npm")),(0,a.kt)("p",null,"Having read up on GitHub Actions it seemed like they were born to handle this sort of task."),(0,a.kt)("h2",o({},{id:"github-action-for-npm"}),"GitHub Action for ",(0,a.kt)("inlineCode",{parentName:"h2"},"npm")),(0,a.kt)("p",null,"I quickly discovered that someone out there ",(0,a.kt)("s",null,"loves me")),(0,a.kt)("p",null,"had ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/actions/npm"}),"already written a GitHub Action for ",(0,a.kt)("inlineCode",{parentName:"a"},"npm")),"."),(0,a.kt)("p",null,"The example in the ",(0,a.kt)("inlineCode",{parentName:"p"},"README/index.md")," could be easily tweaked to meet my needs with one caveat: I had to use ",(0,a.kt)("inlineCode",{parentName:"p"},"npm")," in place of ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn"),". I didn't want to switch from ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn"),". What to do?"),(0,a.kt)("p",null,"Well, remember when I said actions are code run in Docker containers? Another way to phrase that is to say: GitHub Actions are Docker images. Let's look under the covers of the ",(0,a.kt)("inlineCode",{parentName:"p"},"npm")," GitHub Action. As we peer inside the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/actions/npm/blob/e7aaefed7c9f2e83d493ff810f17fa5ccd7ed437/Dockerfile#L1"}),(0,a.kt)("inlineCode",{parentName:"a"},"Dockerfile"))," what do we find?"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"FROM node:10-slim\n")),(0,a.kt)("p",null,"Hmmmm.... Interesting. The base image of the ",(0,a.kt)("inlineCode",{parentName:"p"},"npm")," GitHub Action is ",(0,a.kt)("inlineCode",{parentName:"p"},"node:10-slim"),". Looking it up, it seems the ",(0,a.kt)("inlineCode",{parentName:"p"},"-slim")," Docker images come with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/nodejs/docker-node/blob/master/Dockerfile-slim.template"}),(0,a.kt)("inlineCode",{parentName:"a"},"yarn")," included"),". Which means we should be able to use ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn")," inside the ",(0,a.kt)("inlineCode",{parentName:"p"},"npm")," GitHub Action. Nice!"),(0,a.kt)("h2",o({},{id:"github-action-for-npm-for-yarn"}),"GitHub Action for ",(0,a.kt)("inlineCode",{parentName:"h2"},"npm")," for ",(0,a.kt)("inlineCode",{parentName:"h2"},"yarn")),(0,a.kt)("p",null,"Using ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn")," from the GitHub Action for ",(0,a.kt)("inlineCode",{parentName:"p"},"npm")," is delightfully simple. Here's what running ",(0,a.kt)("inlineCode",{parentName:"p"},"npm install")," looks like:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'# install with npm\naction "install" {\n  uses = "actions/npm@1.0.0"\n  args = "install"\n}\n')),(0,a.kt)("p",null,"Pivoting to use ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn install")," instead of ",(0,a.kt)("inlineCode",{parentName:"p"},"npm install")," is as simple as:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'# install with yarn\naction "install" {\n  uses = "actions/npm@1.0.0"\n  runs = "yarn"\n  args = "install"\n}\n')),(0,a.kt)("p",null,"You can see we've introduced the ",(0,a.kt)("inlineCode",{parentName:"p"},'runs = "yarn"')," and after that the ",(0,a.kt)("inlineCode",{parentName:"p"},"args")," are whatever you need them to be."),(0,a.kt)("h2",o({},{id:"going-with-the-workflow"}),"Going With The Workflow"),(0,a.kt)("p",null,"A GitHub Workflow that implements the steps I need would look like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'workflow "build, test and publish on release" {\n  on = "push"\n  resolves = "publish"\n}\n\n# install with yarn\naction "install" {\n  uses = "actions/npm@1.0.0"\n  runs = "yarn"\n  args = "install"\n}\n\n# build with yarn\naction "build" {\n  needs = "install"\n  uses = "actions/npm@1.0.0"\n  runs = "yarn"\n  args = "build"\n}\n\n# test with yarn\naction "test" {\n  needs = "build"\n  uses = "actions/npm@1.0.0"\n  runs = "yarn"\n  args = "test"\n}\n\n# filter for a new tag\naction "check for new tag" {\n  needs = "Test"\n  uses = "actions/bin/filter@master"\n  args = "tag"\n}\n\n# publish with npm\naction "publish" {\n  needs = "check for new tag"\n  uses = "actions/npm@1.0.0"\n  args = "publish"\n  secrets = ["NPM_AUTH_TOKEN"]\n}\n')),(0,a.kt)("p",null,"As you can see, this is a direct automation of steps 1-4 I listed earlier. Since all these actions are executed in the same container, we can skip from ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn")," to ",(0,a.kt)("inlineCode",{parentName:"p"},"npm")," with gay abandon."),(0,a.kt)("p",null,"What's absolutely amazing is, when I got access to GitHub Actions ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/blob/master/.github/main.workflow"}),"my hand crafted workflow")," looked like it should work first time! I know, right? Don't you love it when that happens? ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/actions/bin/issues/13"}),"Alas there's presently a problem with filters in GitHub Actions"),". But that's by the by, if you're just looking to use a GitHub Action with yarn instead of npm then you are home free."),(0,a.kt)("h2",o({},{id:"you-dont-actually-need-the-npm-github-action"}),"You Don't Actually Need the npm GitHub Action"),(0,a.kt)("p",null,"You heard me right. Docker containers be Docker containers. You don't actually need to use this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'uses = "actions/npm@1.0.0"\n')),(0,a.kt)("p",null,"You can use ",(0,a.kt)("em",{parentName:"p"},"any")," Docker container which has node / npm installed! So if you'd like to use say node 11 instead you could just do this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'uses = "docker://node:11"\n')),(0,a.kt)("p",null,"Which would use the node 11 image on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://hub.docker.com/_/node"}),"docker hub"),"."),(0,a.kt)("p",null,"Which is pretty cool. You know what's even more incredible? Inside a workflow you can switch ",(0,a.kt)("inlineCode",{parentName:"p"},"uses")," mid-workflow and keep the output. That's right; you can have a work flow with say three actions running ",(0,a.kt)("inlineCode",{parentName:"p"},'uses = "docker://node:11"')," and then a fourth running ",(0,a.kt)("inlineCode",{parentName:"p"},'uses = "actions/npm@1.0.0"'),". That's ",(0,a.kt)("em",{parentName:"p"},"so")," flexible and powerful!"),(0,a.kt)("p",null,"Thanks to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/mcolyer"}),"Matt Colyer")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/LandonSchropp"}),"Landon Schropp")," for ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/actions/npm/issues/9"}),"schooling me on the intricicies of GitHub Actions"),". Much \u2764"))}d.isMDXComponent=!0},65007:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-and-webpack-watch-it",title:"TypeScript and webpack: Watch It",authors:"johnnyreilly",tags:["typescript","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-and-webpack-watch-it",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2019-01-13-typescript-and-webpack-watch-it/index.md",source:"@site/blog/2019-01-13-typescript-and-webpack-watch-it/index.md",title:"TypeScript and webpack: Watch It",description:'All I ask for is a compiler and a tight feedback loop. Narrowing the gap between making a change to a program and seeing the effect of that is a productivity boon. The TypeScript team are wise cats and dig this. They\'ve taken strides to improve the developer experience of TypeScript users by introducing a "watch" API which can be leveraged by other tools. To quote the docs:',date:"2019-01-13T00:00:00.000Z",formattedDate:"January 13, 2019",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:2.375,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-and-webpack-watch-it",title:"TypeScript and webpack: Watch It",authors:"johnnyreilly",tags:["typescript","webpack"],hide_table_of_contents:!1},prevItem:{title:"ASP.NET Core: Proxying HTTP Requests with an AllowList",permalink:"/aspnet-core-allowlist-proxying-http-requests"},nextItem:{title:"GitHub Actions and Yarn",permalink:"/github-actions-and-yarn"}},p={authorsImageUrls:[void 0]},u=[{value:"You Can Watch Too",id:"you-can-watch-too",level:2},{value:"Mary Poppins",id:"mary-poppins",level:2},{value:"Roadmap",id:"roadmap",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"All I ask for is a compiler and a tight feedback loop. Narrowing the gap between making a change to a program and seeing the effect of that is a productivity boon. The TypeScript team are wise cats and dig this. They've taken strides to improve the developer experience of TypeScript users by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/wiki/Using-the-Compiler-API#writing-an-incremental-program-watcher"}),'introducing a "watch" API which can be leveraged by other tools'),". To quote the docs:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},'TypeScript 2.7 introduces two new APIs: one for creating "watcher" programs that provide set of APIs to trigger rebuilds, and a "builder" API that watchers can take advantage of... This can speed up large projects with many files.')),(0,a.kt)("p",null,"Recently the wonderful ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/0xorial"}),"0xorial")," ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin/pull/198"}),"opened a PR to add support for the watch API")," to the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"fork-ts-checker-webpack-plugin")),"."),(0,a.kt)("p",null,'I took this PR for a spin on a large project that I work on. With my machine, I was averaging 12 seconds between incremental builds. (I will charitably describe the machine in question as "challenged"; hobbled by one of the most aggressive virus checkers known to mankind. Fist bump InfoSec \ud83e\udd1c\ud83e\udd1b\ud83d\ude09) Switching to using the watch API dropped this to a mere 1.5 seconds!'),(0,a.kt)("h2",o({},{id:"you-can-watch-too"}),"You Can Watch Too"),(0,a.kt)("p",null,"0xorial's PR was merged toot suite and was been released as ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin/releases/tag/v1.0.0-alpha.2"}),(0,a.kt)("inlineCode",{parentName:"a"},"fork-ts-checker-webpack-plugin@1.0.0-alpha.2")),". If you'd like to take this for a spin then you can. Just:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Up your version of the plugin to ",(0,a.kt)("inlineCode",{parentName:"li"},"fork-ts-checker-webpack-plugin@next")," in your ",(0,a.kt)("inlineCode",{parentName:"li"},"package.json")),(0,a.kt)("li",{parentName:"ol"},"Add ",(0,a.kt)("inlineCode",{parentName:"li"},"useTypescriptIncrementalApi: true")," to the plugin when you initialise it in your ",(0,a.kt)("inlineCode",{parentName:"li"},"webpack.config.js"),".")),(0,a.kt)("p",null,"That's it."),(0,a.kt)("h2",o({},{id:"mary-poppins"}),"Mary Poppins"),(0,a.kt)("p",null,"Sorry, I was trying to paint a word picture of something you might watch that was also comforting. Didn't quite work..."),(0,a.kt)("p",null,'Anyway, you might be thinking "wait, just hold on a minute.... he said ',(0,a.kt)("inlineCode",{parentName:"p"},"@next")," ","-"," I am ",(0,a.kt)("em",{parentName:"p"},"not")," that bleeding edge.\" Well, it's not like that. Don't be scared."),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin")," has merely been updated for webpack 5 (which is in alpha) and the ",(0,a.kt)("inlineCode",{parentName:"p"},"@next")," reflects that. To be clear, the ",(0,a.kt)("inlineCode",{parentName:"p"},"@next")," version of the plugin still supports (remarkably!) webpack 2, 3 and 4 as well as 5 alpha. Users of current and historic versions of webpack should feel safe using the ",(0,a.kt)("inlineCode",{parentName:"p"},"@next")," version; for webpack 2, 3 and 4 expect stability. webpack 5 users should expect potential changes to align with webpack 5 as it progresses."),(0,a.kt)("h2",o({},{id:"roadmap"}),"Roadmap"),(0,a.kt)("p",null,"This is available now and we'd love for you to try it out. As you can see, at the moment it's opt-in. You have to explicitly choose to use the new behaviour. Depending upon how testing goes, we may look to make this the default behaviour for the plugin in future (assuming users are running a high enough version of TypeScript). It would be great to hear from people if they have any views on that, or feedback in general."),(0,a.kt)("p",null,"Much \u2764\ufe0f y'all. And many thanks to the very excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/0xorial"}),"0xorial")," for the hard work."))}d.isMDXComponent=!0},47588:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"aspnet-core-allowlist-proxying-http-requests",title:"ASP.NET Core: Proxying HTTP Requests with an AllowList",authors:"johnnyreilly",tags:[".NET"],image:"./hang-on-lads-ive-got-a-great-idea.webp",hide_table_of_contents:!1},s=void 0,l={permalink:"/aspnet-core-allowlist-proxying-http-requests",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2019-02-22-aspnet-core-allowlist-proxying-http-requests/index.md",source:"@site/blog/2019-02-22-aspnet-core-allowlist-proxying-http-requests/index.md",title:"ASP.NET Core: Proxying HTTP Requests with an AllowList",description:"This post demonstrates a mechanism for proxying HTTP requests in ASP.NET Core. It doesn't proxy all requests; it only proxies requests that match entries on an \"allowlist\" - so we only proxy the traffic that we've actively decided is acceptable as determined by taking the form of an expected URL and HTTP verb (GET / POST etc).",date:"2019-02-22T00:00:00.000Z",formattedDate:"February 22, 2019",tags:[{label:".NET",permalink:"/tags/net"}],readingTime:6.49,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"aspnet-core-allowlist-proxying-http-requests",title:"ASP.NET Core: Proxying HTTP Requests with an AllowList",authors:"johnnyreilly",tags:[".NET"],image:"./hang-on-lads-ive-got-a-great-idea.webp",hide_table_of_contents:!1},prevItem:{title:"fork-ts-checker-webpack-plugin v1.0",permalink:"/fork-ts-checker-webpack-plugin-v1"},nextItem:{title:"TypeScript and webpack: Watch It",permalink:"/typescript-and-webpack-watch-it"}},p={image:n(64251).Z,authorsImageUrls:[void 0]},u=[{value:"Why do we need to proxy?",id:"why-do-we-need-to-proxy",level:2},{value:"The Proxy Regroup",id:"the-proxy-regroup",level:2},{value:"Proxy Part 1",id:"proxy-part-1",level:2},{value:"Proxy Part 2",id:"proxy-part-2",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This post demonstrates a mechanism for proxying HTTP requests in ASP.NET Core. It doesn't proxy all requests; it only proxies requests that match entries on an \"allowlist\" - so we only proxy the traffic that we've actively decided is acceptable as determined by taking the form of an expected URL and HTTP verb (GET / POST etc)."),(0,a.kt)("h2",o({},{id:"why-do-we-need-to-proxy"}),"Why do we need to proxy?"),(0,a.kt)("p",null,'Once upon a time there lived a young team who were building a product. They were ready to go live with their beta and so they set off on a journey to a mystical land they had heard tales of. This magical kingdom was called "Production". However, Production was a land with walls and but one gate. That gate was jealously guarded by a defender named "InfoSec". InfoSec was there to make sure that only the the right people, noble of thought and pure of deed were allowed into the promised land. InfoSec would ask questions like "are you serving over HTTPS" and "what are you doing about cross site scripting"?'),(0,a.kt)("p",null,'The team felt they had good answers to InfoSec\'s questions. However, just as they were about to step through the gate, InfoSec held up their hand and said "your application wants to access a database... database access needs to take place on our own internal network. Not over the publicly accessible internet."'),(0,a.kt)("p",null,'The team, with one foot in the air, paused. They swallowed and said "can you give us five minutes?"'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"image taken from the end of the classic movie &quot;The Italian Job&quot; of the bus hanging half off a mountainside",src:n(64251).Z,width:"640",height:"271"})),(0,a.kt)("h2",o({},{id:"the-proxy-regroup"}),"The Proxy Regroup"),(0,a.kt)("p",null,"And so it came to pass that the teams product (which took the form of ASP.Net Core web application) had to be changed. Where once there had been a single application, there would now be two; one that lived on the internet (the ",(0,a.kt)("em",{parentName:"p"},"web")," app) and one that lived on the companies private network (the ",(0,a.kt)("em",{parentName:"p"},"API")," app). The API app would do all the database access. In fact the product team opted to move all significant operations into the API as well. This left the web app with two purposes:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"the straightforward serving of HTML, CSS, JS and images"),(0,a.kt)("li",{parentName:"ol"},"the proxying of API calls through to the API app")),(0,a.kt)("h2",o({},{id:"proxy-part-1"}),"Proxy Part 1"),(0,a.kt)("p",null,"In the early days of this proxying the team reached for ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/twitchax/AspNetCore.Proxy"}),(0,a.kt)("inlineCode",{parentName:"a"},"AspNetCore.Proxy")),". It's a great open source project that allows you to proxy HTTP requests. It gives you complete control over the construction of proxy requests, so that you can have a request come into your API and end up proxying it to a URL with a completely different path on the proxy server."),(0,a.kt)("h2",o({},{id:"proxy-part-2"}),"Proxy Part 2"),(0,a.kt)("p",null,"The approach offered by ",(0,a.kt)("inlineCode",{parentName:"p"},"AspNetCore.Proxy")," is fantastically powerful in terms of control. However, we didn't actually need that level of configurability. In fact, it resulted in us writing a great deal of boilerplate code. You see in our case we'd opted to proxy path for path, changing only the server name on each proxied request. So if a GET request came in going to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://web.app.com/api/version"}),"https://web.app.com/api/version")," then we would want to proxy it to a GET request to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://api.app.com/api/version"}),"https://api.app.com/api/version"),". You see? All we did was swap ",(0,a.kt)("a",o({parentName:"p"},{href:"https://web.app.com"}),"https://web.app.com")," for ",(0,a.kt)("a",o({parentName:"p"},{href:"https://api.app.com."}),"https://api.app.com.")," Nothing more. We did that as a rule. We knew we ",(0,a.kt)("em",{parentName:"p"},"always")," wanted to do just this."),(0,a.kt)("p",null,"So we ended up spinning up our own solution which allowed just the specification of paths we wanted to proxy with their corresponding HTTP verbs. Let's talk through it. Usage of our approach ended up as a middleware within our web app's ",(0,a.kt)("inlineCode",{parentName:"p"},"Startup.cs"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public void Configure(IApplicationBuilder app) {\n    // ...\n\n    app.UseProxyAllowList(\n        // where ServerToProxyToBaseUrl is the server you want requests to be proxied to\n        // eg "https://the-server-we-proxy-to"\n        proxyAddressTweaker: (requestPath) => $"{ServerToProxyToBaseUrl}{requestPath}",\n        allowListProxyRoutes: new [] {\n            // An anonymous request\n            AllowListProxy.AnonymousRoute("api/version", HttpMethod.Get),\n\n            // An authenticated request; to send this we must know who the user is\n            AllowListProxy.Route("api/account/{accountId:int}/all-the-secret-info", HttpMethod.Get, HttpMethod.Post),\n    });\n\n\n    app.UseMvc();\n\n    // ...\n}\n')),(0,a.kt)("p",null,"If you look at the code above you can see that we are proxing requests to a single server: ",(0,a.kt)("inlineCode",{parentName:"p"},"ServerToProxyToBaseUrl"),". We're also only proxying requests which match an entry on our allowlist (as represented by ",(0,a.kt)("inlineCode",{parentName:"p"},"allowListProxyRoutes"),"). So in this case we're proxying two different requests:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"GET")," requests to ",(0,a.kt)("inlineCode",{parentName:"li"},"api/version")," are proxied through as ",(0,a.kt)("em",{parentName:"li"},"anonymous"),(0,a.kt)("inlineCode",{parentName:"li"},"GET")," requests."),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"GET")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"POST")," requests to ",(0,a.kt)("inlineCode",{parentName:"li"},"api/account/{accountId:int}/all-the-secret-info")," are proxied through as ",(0,a.kt)("inlineCode",{parentName:"li"},"GET")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"POST")," requests. These requests require that a user be authenticated first.")),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"AllowListProxy")," proxy class we've been using looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Collections.Generic;\nusing System.Net.Http;\n\nnamespace My.Web.Proxy {\n    public class AllowListProxy {\n        public string Path { get; set; }\n        public IEnumerable<HttpMethod> Methods { get; set; }\n        public bool IsAnonymous { get; set; }\n\n        private AllowListProxy(string path, bool isAnonymous, params HttpMethod[] methods) {\n            if (methods == null || methods.Length == 0)\n                throw new ArgumentException($"You need at least a single HttpMethod to be specified for {path}");\n\n            Path = path;\n            IsAnonymous = isAnonymous;\n            Methods = methods;\n        }\n\n        public static AllowListProxy Route(string path, params HttpMethod[] methods) =>\n            new AllowListProxy(path, isAnonymous: false, methods: methods);\n\n        public static AllowListProxy AnonymousRoute(string path, params HttpMethod[] methods) =>\n            new AllowListProxy(path, isAnonymous: true, methods: methods);\n    }\n}\n')),(0,a.kt)("p",null,"The middleware for proxying (our ",(0,a.kt)("inlineCode",{parentName:"p"},"UseProxyAllowList"),") looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Collections.Generic;\nusing System.ComponentModel;\nusing System.Linq;\nusing System.Net.Http;\nusing System.Reflection;\nusing System.Threading.Tasks;\nusing Microsoft.AspNetCore.Authentication;\nusing Microsoft.AspNetCore.Builder;\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Routing;\nusing Microsoft.Extensions.DependencyModel;\nusing Microsoft.Extensions.DependencyInjection;\nusing Serilog;\n\nnamespace My.Web.Proxy {\n    public static class ProxyRouteExtensions {\n        /// <summary>\n        /// Middleware which proxies the supplied allowlist routes\n        /// </summary>\n        public static void UseProxyAllowList(\n            this IApplicationBuilder app,\n            Func<string, string> proxyAddressTweaker,\n            Action<HttpContext, HttpRequestMessage> preSendProxyRequestAction,\n            IEnumerable<AllowListProxy> allowListProxyRoutes\n        ) {\n            app.UseRouter(builder => {\n                foreach (var allowListProxy in allowListProxyRoutes) {\n                    foreach (var method in allowListProxy.Methods) {\n                        builder.MapMiddlewareVerb(method.ToString(), allowListProxy.Path, proxyApp => {\n                            proxyApp.UseProxy_Challenge(allowListProxy.IsAnonymous);\n                            proxyApp.UseProxy_Run(proxyAddressTweaker, preSendProxyRequestAction);\n                        });\n                    }\n                }\n            });\n        }\n\n        private static void UseProxy_Challenge(this IApplicationBuilder app, bool allowAnonymous) {\n            app.Use((context, next) =>\n            {\n                var routePath = context.Request.Path.Value;\n\n                var weAreAuthenticatedOrWeDontNeedToBe =\n                    context.User.Identity.IsAuthenticated || allowAnonymous;\n                if (weAreAuthenticatedOrWeDontNeedToBe)\n                    return next();\n\n                return context.ChallengeAsync();\n            });\n        }\n\n        private static void UseProxy_Run(\n            this IApplicationBuilder app,\n            Func<string, string> proxyAddressTweaker,\n            Action<HttpContext, HttpRequestMessage> preSendProxyRequestAction\n            )\n        {\n            app.Run(async context => {\n                var proxyAddress = "";\n                try {\n                    proxyAddress = proxyAddressTweaker(context.Request.Path.Value);\n\n                    var proxyRequest = context.Request.CreateProxyHttpRequest(proxyAddress);\n\n                    if (preSendProxyRequestAction != null)\n                        preSendProxyRequestAction(context, proxyRequest);\n\n                    var httpClients = context.RequestServices.GetService<IHttpClients>(); // IHttpClients is just a wrapper for HttpClient - insert your own here\n\n                    var proxyResponse = await httpClients.SendRequestAsync(proxyRequest,\n                            HttpCompletionOption.ResponseHeadersRead, context.RequestAborted)\n                        .ConfigureAwait(false);\n\n                    await context.CopyProxyHttpResponse(proxyResponse).ConfigureAwait(false);\n                }\n                catch (OperationCanceledException ex) {\n                    if (ex.CancellationToken.IsCancellationRequested)\n                        return;\n\n                    if (!context.Response.HasStarted)\n                    {\n                        context.Response.StatusCode = 408;\n                        await context.Response\n                            .WriteAsync("Request timed out.");\n                    }\n                }\n                catch (Exception e) {\n                    if (!context.Response.HasStarted)\n                    {\n                        context.Response.StatusCode = 500;\n                        await context.Response\n                            .WriteAsync(\n                                $"Request could not be proxied.\\n\\n{e.Message}\\n\\n{e.StackTrace}.");\n                    }\n                }\n            });\n        }\n\n        public static void AddOrReplaceHeader(this HttpRequestMessage request, string headerName, string headerValue) {\n            // It\'s possible for there to be multiple headers with the same name; we only want a single header to remain.  Our one.\n            while (request.Headers.TryGetValues(headerName, out var existingAuthorizationHeader)) {\n                request.Headers.Remove(headerName);\n            }\n            request.Headers.TryAddWithoutValidation(headerName, headerValue);\n        }\n\n        public static HttpRequestMessage CreateProxyHttpRequest(this HttpRequest request, string uriString) {\n            var uri = new Uri(uriString + request.QueryString);\n\n            var requestMessage = new HttpRequestMessage();\n            var requestMethod = request.Method;\n            if (!HttpMethods.IsGet(requestMethod) &&\n                !HttpMethods.IsHead(requestMethod) &&\n                !HttpMethods.IsDelete(requestMethod) &&\n                !HttpMethods.IsTrace(requestMethod)) {\n                var streamContent = new StreamContent(request.Body);\n                requestMessage.Content = streamContent;\n            }\n\n            // Copy the request headers.\n            if (requestMessage.Content != null)\n                foreach (var header in request.Headers)\n                    if (!requestMessage.Headers.TryAddWithoutValidation(header.Key, header.Value.ToArray()))\n                        requestMessage.Content?.Headers.TryAddWithoutValidation(header.Key, header.Value.ToArray());\n\n            requestMessage.Headers.Host = uri.Authority;\n            requestMessage.RequestUri = uri;\n            requestMessage.Method = new HttpMethod(request.Method);\n\n            return requestMessage;\n        }\n\n        public static async Task CopyProxyHttpResponse(this HttpContext context, HttpResponseMessage responseMessage) {\n            var response = context.Response;\n\n            response.StatusCode = (int) responseMessage.StatusCode;\n            foreach (var header in responseMessage.Headers) {\n                response.Headers[header.Key] = header.Value.ToArray();\n            }\n\n            if (responseMessage.Content != null) {\n                foreach (var header in responseMessage.Content.Headers) {\n                    response.Headers[header.Key] = header.Value.ToArray();\n                }\n            }\n\n            response.Headers.Remove("transfer-encoding");\n\n            using(var responseStream = await responseMessage.Content.ReadAsStreamAsync().ConfigureAwait(false)) {\n                await responseStream.CopyToAsync(response.Body, 81920, context.RequestAborted).ConfigureAwait(false);\n            }\n        }\n    }\n}\n')),(0,a.kt)("p",null,"This works out to be a flexible and simple approach to allowlist proxying."))}d.isMDXComponent=!0},60105:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"fork-ts-checker-webpack-plugin-v1",title:"fork-ts-checker-webpack-plugin v1.0",authors:"johnnyreilly",tags:["typescript","fork-ts-checker-webpack-plugin","ts-loader","tslint","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/fork-ts-checker-webpack-plugin-v1",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2019-03-06-fork-ts-checker-webpack-plugin-v1/index.md",source:"@site/blog/2019-03-06-fork-ts-checker-webpack-plugin-v1/index.md",title:"fork-ts-checker-webpack-plugin v1.0",description:"It's time for the first major version of fork-ts-checker-webpack-plugin. It's been a long time coming :-)",date:"2019-03-06T00:00:00.000Z",formattedDate:"March 6, 2019",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"fork-ts-checker-webpack-plugin",permalink:"/tags/fork-ts-checker-webpack-plugin"},{label:"ts-loader",permalink:"/tags/ts-loader"},{label:"tslint",permalink:"/tags/tslint"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:1.895,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"fork-ts-checker-webpack-plugin-v1",title:"fork-ts-checker-webpack-plugin v1.0",authors:"johnnyreilly",tags:["typescript","fork-ts-checker-webpack-plugin","ts-loader","tslint","webpack"],hide_table_of_contents:!1},prevItem:{title:"Google Analytics API and ASP.Net Core",permalink:"/google-analytics-api-and-aspnet-core"},nextItem:{title:"ASP.NET Core: Proxying HTTP Requests with an AllowList",permalink:"/aspnet-core-allowlist-proxying-http-requests"}},p={authorsImageUrls:[void 0]},u=[{value:"A Little History",id:"a-little-history",level:2},{value:"One Point Oh",id:"one-point-oh",level:2},{value:"Incremental Watch API on by Default",id:"incremental-watch-api-on-by-default",level:2},{value:"Compatibility",id:"compatibility",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin/releases/tag/v1.0.0"}),"It's time for the first major version of ",(0,a.kt)("inlineCode",{parentName:"a"},"fork-ts-checker-webpack-plugin")),". It's been a long time coming :-)"),(0,a.kt)("h2",o({},{id:"a-little-history"}),"A Little History"),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin")," was originally the handiwork of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/piotr-oles"}),"Piotr Ole\u015b"),". He raised an issue with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/issues/537"}),(0,a.kt)("inlineCode",{parentName:"a"},"ts-loader"))," suggesting it could be the McCartney to ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader"),"'s Lennon:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Hi everyone!"),(0,a.kt)("p",{parentName:"blockquote"},"I've created webpack plugin: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin"}),"fork-ts-checker-webpack-plugin")," that plays nicely with ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader"),". The idea is to compile project with ",(0,a.kt)("inlineCode",{parentName:"p"},"transpileOnly: true")," and check types on separate process (async). With this approach, webpack build is not blocked by type checker and we have semantic check with fast incremental build. More info on github repo :)"),(0,a.kt)("p",{parentName:"blockquote"},"So if you like it and you think it would be good to add some info in README/index.md about this plugin, I would be greatful."),(0,a.kt)("p",{parentName:"blockquote"},"Thanks :)")),(0,a.kt)("p",null,"We did like it. We did think it would be good. We took him up on his kind offer."),(0,a.kt)("p",null,"Since that time many people have had their paws on the ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin")," codebase. We love them all."),(0,a.kt)("h2",o({},{id:"one-point-oh"}),"One Point Oh"),(0,a.kt)("p",null,'We could have had our first major release a long time ago. The idea first occurred when webpack 5 alpha appeared. "Huh, look at that, a major version number.... Maybe we should do that?" "',(0,a.kt)("em",{parentName:"p"},"Great"),' idea chap - do it!" So here it is; fresh out the box: v1.0.0'),(0,a.kt)("p",null,"There are actually no breaking changes that we're aware of; users of 0.x ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin")," should be be able to upgrade without any drama."),(0,a.kt)("h2",o({},{id:"incremental-watch-api-on-by-default"}),"Incremental Watch API on by Default"),(0,a.kt)("p",null,"Users of TypeScript 3+ may notice a performance improvement as by default the plugin now uses the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/pull/20234"}),"incremental watch API")," in TypeScript."),(0,a.kt)("p",null,"Should this prove problematic you can opt out of using it by supplying ",(0,a.kt)("inlineCode",{parentName:"p"},"useTypescriptIncrementalApi: false"),". We are aware of an ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin/issues/219"}),"issue with Vue and the incremental API"),". We hope it will be fixed soon - a generous member of the community is taking a look. In the meantime, we will ",(0,a.kt)("em",{parentName:"p"},"not")," default to using the incremental watch API when in Vue mode."),(0,a.kt)("h2",o({},{id:"compatibility"}),"Compatibility"),(0,a.kt)("p",null,"As it stands, the plugin supports webpack 2, 3, 4 and 5 alpha. It is compatible with TypeScript 2.1+ and TSLint 4+."),(0,a.kt)("p",null,"Right that's it - enjoy it! And thanks everyone for contributing - we really dig your help. Much love."))}d.isMDXComponent=!0},95708:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"google-analytics-api-and-aspnet-core",title:"Google Analytics API and ASP.Net Core",authors:"johnnyreilly",tags:["asp net core","google analytics"],hide_table_of_contents:!1},s=void 0,l={permalink:"/google-analytics-api-and-aspnet-core",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2019-03-22-google-analytics-api-and-aspnet-core/index.md",source:"@site/blog/2019-03-22-google-analytics-api-and-aspnet-core/index.md",title:"Google Analytics API and ASP.Net Core",description:"I recently had need to be able to access the API for Google Analytics from ASP.Net Core. Getting this up and running turned out to be surprisingly tough because of an absence of good examples. So here it is; an example of how you can access a simple page access stat using the API:",date:"2019-03-22T00:00:00.000Z",formattedDate:"March 22, 2019",tags:[{label:"asp net core",permalink:"/tags/asp-net-core"},{label:"google analytics",permalink:"/tags/google-analytics"}],readingTime:1.89,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"google-analytics-api-and-aspnet-core",title:"Google Analytics API and ASP.Net Core",authors:"johnnyreilly",tags:["asp net core","google analytics"],hide_table_of_contents:!1},prevItem:{title:"Template Tricks for a Dainty DOM",permalink:"/template-tricks-for-dainty-dom"},nextItem:{title:"fork-ts-checker-webpack-plugin v1.0",permalink:"/fork-ts-checker-webpack-plugin-v1"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I recently had need to be able to access the API for Google Analytics from ASP.Net Core. Getting this up and running turned out to be surprisingly tough because of an absence of good examples. So here it is; an example of how you can access a simple page access stat using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.nuget.org/packages/Google.Apis.AnalyticsReporting.v4/"}),"the API"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'async Task<SomeKindOfDataStructure[]> GetUsageFromGoogleAnalytics(DateTime startAtThisDate, DateTime endAtThisDate)\n{\n    // Create the DateRange object. Here we want data from last week.\n    var dateRange = new DateRange\n    {\n        StartDate = startAtThisDate.ToString("yyyy-MM-dd"),\n        EndDate = endAtThisDate.ToString("yyyy-MM-dd")\n    };\n    // Create the Metrics and dimensions object.\n    // var metrics = new List<Metric> { new Metric { Expression = "ga:sessions", Alias = "Sessions" } };\n    // var dimensions = new List<Dimension> { new Dimension { Name = "ga:pageTitle" } };\n    var metrics = new List<Metric> { new Metric { Expression = "ga:uniquePageviews" } };\n    var dimensions = new List<Dimension> {\n        new Dimension { Name = "ga:date" },\n        new Dimension { Name = "ga:dimension1" }\n    };\n\n    // Get required View Id from configuration\n    var viewId = $"ga:{"[VIEWID]"}";\n\n    // Create the Request object.\n    var reportRequest = new ReportRequest\n    {\n        DateRanges = new List<DateRange> { dateRange },\n        Metrics = metrics,\n        Dimensions = dimensions,\n        FiltersExpression = "ga:pagePath==/index.html",\n        ViewId = viewId\n    };\n\n    var getReportsRequest = new GetReportsRequest {\n        ReportRequests = new List<ReportRequest> { reportRequest }\n    };\n\n    //Invoke Google Analytics API call and get report\n    var analyticsService = GetAnalyticsReportingServiceInstance();\n    var response = await (analyticsService.Reports.BatchGet(getReportsRequest)).ExecuteAsync();\n\n    var logins = response.Reports[0].Data.Rows.Select(row => new SomeKindOfDataStructure {\n        Date = new DateTime(\n            year: Convert.ToInt32(row.Dimensions[0].Substring(0, 4)),\n            month: Convert.ToInt32(row.Dimensions[0].Substring(4, 2)),\n            day: Convert.ToInt32(row.Dimensions[0].Substring(6, 2))),\n        NumberOfLogins = Convert.ToInt32(row.Metrics[0].Values[0])\n    })\n    .OrderByDescending(login => login.Date)\n    .ToArray();\n\n    return logins;\n}\n\n/// <summary>\n/// Intializes and returns Analytics Reporting Service Instance\n/// </summary>\nAnalyticsReportingService GetAnalyticsReportingServiceInstance() {\n    var googleAuthFlow = new GoogleAuthorizationCodeFlow(new GoogleAuthorizationCodeFlow.Initializer {\n        ClientSecrets = new ClientSecrets {\n            ClientId = "[CLIENTID]",\n            ClientSecret = "[CLIENTSECRET]"\n        }\n    });\n\n    var responseToken = new TokenResponse {\n        AccessToken = "[ANALYTICSTOKEN]",\n        RefreshToken = "[REFRESHTOKEN]",\n        Scope = AnalyticsReportingService.Scope.AnalyticsReadonly, //Read-only access to Google Analytics,\n        TokenType = "Bearer",\n    };\n\n    var credential = new UserCredential(googleAuthFlow, "", responseToken);\n\n    // Create the  Analytics service.\n    return new AnalyticsReportingService(new BaseClientService.Initializer {\n        HttpClientInitializer = credential,\n        ApplicationName = "my-super-applicatio",\n    });\n}\n')),(0,a.kt)("p",null,"You can see above that you need various credentials to be able to use the API. You can acquire these by logging into GA. Enjoy!"))}d.isMDXComponent=!0},39665:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"template-tricks-for-dainty-dom",title:"Template Tricks for a Dainty DOM",authors:"johnnyreilly",tags:["Materialized"],hide_table_of_contents:!1},s=void 0,l={permalink:"/template-tricks-for-dainty-dom",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2019-03-24-template-tricks-for-dainty-dom/index.md",source:"@site/blog/2019-03-24-template-tricks-for-dainty-dom/index.md",title:"Template Tricks for a Dainty DOM",description:"I'm somewhat into code golf. Placing restrictions on what you're \"allowed\" to do in code and seeing what the happens as a result. I'd like to share with you something that came out of some recent dabblings.",date:"2019-03-24T00:00:00.000Z",formattedDate:"March 24, 2019",tags:[{label:"Materialized",permalink:"/tags/materialized"}],readingTime:5.27,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"template-tricks-for-dainty-dom",title:"Template Tricks for a Dainty DOM",authors:"johnnyreilly",tags:["Materialized"],hide_table_of_contents:!1},prevItem:{title:"react-select with less typing lag",permalink:"/react-select-with-less-typing-lag"},nextItem:{title:"Google Analytics API and ASP.Net Core",permalink:"/google-analytics-api-and-aspnet-core"}},p={authorsImageUrls:[void 0]},u=[{value:"&quot;Oh All Right; Just a Splash&quot;",id:"oh-all-right-just-a-splash",level:2},{value:"The DOM Bunker",id:"the-dom-bunker",level:2},{value:"Smuggling DOM in Templates",id:"smuggling-dom-in-templates",level:2},{value:"&quot;That Sounds Complicated...&quot;",id:"that-sounds-complicated",level:2},{value:"Do It Yourself",id:"do-it-yourself",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I'm somewhat into code golf. Placing restrictions on what you're \"allowed\" to do in code and seeing what the happens as a result. I'd like to share with you something that came out of some recent dabblings."),(0,a.kt)("p",null,"Typically I spend a good amount of time playing with TypeScript. Either working on build tools or making web apps with it. (Usually with a portion of React on the side.) This is something different."),(0,a.kt)("p",null,"I have a side project on the go which is essentially a mini analytics dashboard. For the purposes of this piece let's call it \"StatsDash\". When I was starting it I thought: let's try something different. Let's build StatsDash with HTML ",(0,a.kt)("em",{parentName:"p"},"only"),". The actual HTML is hand cranked by me and generated in ASP.Net Core / C# using a combination of LINQ and string interpolation. (Who needs Razor? \ud83d\ude0e) I'll say it's pretty fun - but the back end is not what I want to focus on."),(0,a.kt)("p",null,"I got something up and running pretty quickly in pure HTML. The first lesson I learned was this: HTML alone is hella ugly. So I relaxed my criteria; I allowed CSS to come play as long as I didn't have to write any / much myself. There followed some experimentation with different CSS frameworks. For a while I rolled with Bootstrap (old school!), then Bulma and finally I settled on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://materializecss.com/"}),"Materialized"),". Materialized is a heavily inspired by Google's Material Design and is hence quite beautiful. With my HTML and Materialize's CSS we were rolling. Beautiful stats - no JS."),(0,a.kt)("h2",o({},{id:"oh-all-right-just-a-splash"}),'"Oh All Right; Just a Splash"'),(0,a.kt)("p",null,"Lovely as things were, StatsDash quickly got to the point where there was too much information on the screen. It was time to make some changes. If data is to convey a message, it must first be comprehensible."),(0,a.kt)("p",null,"I needed a way to hide and show data as people interacted with StatsDash. I wanted to achieve this ",(0,a.kt)("em",{parentName:"p"},"without")," starting to render on the client side and also without going back to the server each time."),(0,a.kt)("p",null,"If you want interactions in your UI all roads lead to JS. It's certainly possible to do some tricks with CSS but that's a round of code golf I'm ill equipped to play. So, I took a look at what Materialized had to offer. Usefully it has a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://materializecss.com/modals.html"}),"Modal")," component. With that in play I'd be able to separate the detailed information into different modals which the users could show and hide as required. Perfect!"),(0,a.kt)("p",null,"It required a little JS. What's a line or two between friends? Dear reader, I compromised once more."),(0,a.kt)("h2",o({},{id:"the-dom-bunker"}),"The DOM Bunker"),(0,a.kt)("p",null,'With my handy modals, StatsDash was now a one stop shop for a great deal of information. Info which took the form of DOM nodes. Lots of them. And by "lots of them" I want you to think along the lines of "space is big, really big...".'),(0,a.kt)("p",null,"This was impacting users. Clicking to open a modal resulted in a noticeable lag. It would take 2+ seconds for the browser to respond. Users found themselves clicking multiple times; wondering why nothing seemed to occur. In the end the modal would shuffle into view. However, this wasn't the best experience. The lack of responsiveness was getting in the way of users enjoying all StatsDash had to offer."),(0,a.kt)("p",null,"Running an audit of StatsDash in Chrome DevTools there was no doubt we had a DOM problem:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(55337).Z,width:"640",height:"298"})),(0,a.kt)("p",null,"What to do? I still didn't want to go back to the server on each click in StatsDash. And I didn't want to start writing rendering code on the client as well either. I have in the past mixed client and server side rendering and I know well that it's a first class ticket to a confusing codebase."),(0,a.kt)("h2",o({},{id:"smuggling-dom-in-templates"}),"Smuggling DOM in Templates"),(0,a.kt)("p",null,"There's a mechanism that supports this use case directly: the ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;template&gt;")," element. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/HTML/Element/template"}),"To quote MDN"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"The HTML Content Template (",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;template&gt;"),") element is a mechanism for holding client-side content that is not to be rendered when a page is loaded but may subsequently be instantiated during runtime using JavaScript.")),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Think of a template as a content fragment that is being stored for subsequent use in the document.")),(0,a.kt)("p",null,"This is ",(0,a.kt)("em",{parentName:"p"},"exactly")," what I'm after. I can keep my rendering server side, but instead wrap content that isn't immediately visible to users inside a ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;template&gt;")," element and render that only when users need it."),(0,a.kt)("p",null,"So in the case of my modals (where most of my DOM lives), I can tuck the contents of each modal into a ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;template&gt;")," element. Then, when the user clicks to open a modal we move that template content into the DOM so they can see it. Likewise, as they close a modal we can clear out the modal's DOM content to ease the load on the dear old browser."),(0,a.kt)("h2",o({},{id:"that-sounds-complicated"}),'"That Sounds Complicated..."'),(0,a.kt)("p",null,"It's not. Let me show you how easily this is accomplished. First of all, wrap all your modal contents into ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;template&gt;")," elements. They should look a little something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<div>\n  <button data-target="modalId" class="btn modal-trigger">\n    Open the Modal!\n  </button>\n\n  <template>\n    \x3c!--\n        loads of DOM nodes\n        --\x3e\n  </template>\n\n  <div id="modalId" class="modal modal-fixed-footer"></div>\n</div>\n')),(0,a.kt)("p",null,"Next, where you initialise your modals you need to make a little tweak:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"document.addEventListener('DOMContentLoaded', function () {\n  M.Modal.init(document.querySelectorAll('.modal'), {\n    onOpenStart: (modalDiv) => {\n      const template = modalDiv.parentNode.querySelector('template');\n\n      modalDiv.appendChild(document.importNode(template.content, true));\n    },\n    onCloseEnd: (modalDiv) => {\n      while (modalDiv.firstChild) {\n        modalDiv.removeChild(modalDiv.firstChild);\n      }\n    },\n  });\n});\n")),(0,a.kt)("p",null,"That's it! As you can see, before we open our modals, the ",(0,a.kt)("inlineCode",{parentName:"p"},"onOpenStart")," callback will fire which creates the actual DOM elements based upon the ",(0,a.kt)("inlineCode",{parentName:"p"},"template"),". And when the modals finish closing the ",(0,a.kt)("inlineCode",{parentName:"p"},"onCloseEnd")," callback runs to remove those DOM elements once more."),(0,a.kt)("p",null,"For this minimal change, the client gets a dramatically different user experience. StatsDash went from super laggy to satisfyingly fast. Using ",(0,a.kt)("inlineCode",{parentName:"p"},"template"),"s, The number of initial DOM nodes dropped from more than ",(0,a.kt)("em",{parentName:"p"},"20,000")," to ",(0,a.kt)("em",{parentName:"p"},"200"),". That's right \ud83d\udcaf times smaller!"),(0,a.kt)("h2",o({},{id:"do-it-yourself"}),"Do It Yourself"),(0,a.kt)("p",null,"The code examples above rely upon the Materialize modals. However the principles used here are broadly applicable. It's easy for you to take the approach outlined here and apply it in a different situation."),(0,a.kt)("p",null,"If you're interested in some of the other exciting things you can do with templates then I recommend ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.html5rocks.com/en/tutorials/webcomponents/template/"}),"Eric Bidelman's post on the topic"),"."))}d.isMDXComponent=!0},9309:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"react-select-with-less-typing-lag",title:"react-select with less typing lag",authors:"johnnyreilly",tags:["react-select"],hide_table_of_contents:!1},s=void 0,l={permalink:"/react-select-with-less-typing-lag",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2019-04-27-react-select-with-less-typing-lag/index.md",source:"@site/blog/2019-04-27-react-select-with-less-typing-lag/index.md",title:"react-select with less typing lag",description:"This is going out to all those people using react-select with 1000+ items to render. To those people typing into the select and saying out loud \"it's so laggy.... This can't be... It's 2019... I mean, right?\" To the people who read this GitHub issue top to bottom 30 times and still came back unsure of what to do. This is for you.",date:"2019-04-27T00:00:00.000Z",formattedDate:"April 27, 2019",tags:[{label:"react-select",permalink:"/tags/react-select"}],readingTime:2.04,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"react-select-with-less-typing-lag",title:"react-select with less typing lag",authors:"johnnyreilly",tags:["react-select"],hide_table_of_contents:!1},prevItem:{title:"TypeScript and high CPU usage - watch don't stare!",permalink:"/typescript-and-high-cpu-usage-watch"},nextItem:{title:"Template Tricks for a Dainty DOM",permalink:"/template-tricks-for-dainty-dom"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This is going out to all those people using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://react-select.com"}),(0,a.kt)("inlineCode",{parentName:"a"},"react-select"))," with 1000+ items to render. To those people typing into the select and saying out loud \"it's ",(0,a.kt)("em",{parentName:"p"},"so")," laggy.... This can't be... It's 2019... I mean, right?\" To the people who read this ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/JedWatson/react-select/issues/3128"}),"GitHub issue")," top to bottom 30 times and still came back unsure of what to do. This is for you."),(0,a.kt)("p",null,"I'm lying. Mostly this goes out to me. I have a select box. I need it to render 2000+ items. I want it to be lovely. I want my users to be delighted as they use it. I want them to type in and (",(0,a.kt)("em",{parentName:"p"},"this is the crucial part!"),") for the control to feel responsive. Not laggy. Not like each keypress is going to Jupiter and back before it renders to the screen."),(0,a.kt)("p",null,"Amongst the various gems on the GitHub issue are shared CodeSandboxes illustrating ways to integrate react-select with react-window. That's great and they do improve things. However, they don't do much to improve the laggy typing feel. There's ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/JedWatson/react-select/issues/3128#issuecomment-431397942"}),"brief mention")," of a props tweak you can make to react-select; this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"filterOption={createFilter({ ignoreAccents: false })}\n")),(0,a.kt)("p",null,"What does this do? Well, this improves the typing lag experience ",(0,a.kt)("em",{parentName:"p"},"massively"),". For why? Well, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/JedWatson/react-select/blob/292bad3298f2cafad6767f2134bd79a9c27e4073/src/filters.js#L21"}),"if you look at the code")," you find that the default value is ",(0,a.kt)("inlineCode",{parentName:"p"},"ignoreAccents: true"),". This default makes react-select invoke an expensive (and scary sounding) function called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/JedWatson/react-select/blob/292bad3298f2cafad6767f2134bd79a9c27e4073/src/diacritics.js#L90"}),(0,a.kt)("inlineCode",{parentName:"a"},"stripDiacritics")),". Not once but twice. Ouchy. And this kills performance."),(0,a.kt)("p",null,"But if you're okay with accents not being ignored (and ",(0,a.kt)("em",{parentName:"p"},"spoiler"),": I am) then this is the option for you."),(0,a.kt)("p",null,"Here's a CodeSandbox which also includes the ",(0,a.kt)("inlineCode",{parentName:"p"},"ignoreAccents: false")," tweak. Enjoy!"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://codesandbox.io/s/zn70lqp31m?fontsize=14"}),(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"Edit johnnyreilly/react-window-with-react-select-less-laggy",src:n(62702).Z,width:"184",height:"40"}))),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"import React, { Component } from 'react';\nimport ReactDOM from 'react-dom';\nimport Select, { createFilter } from 'react-select';\nimport { FixedSizeList as List } from 'react-window';\n\nimport './styles.css';\n\nconst options = [];\nfor (let i = 0; i < 2500; i = i + 1) {\n  options.push({ value: i, label: `Option ${i}` });\n}\n\nconst height = 35;\n\nclass MenuList extends Component {\n  render() {\n    const { options, children, maxHeight, getValue } = this.props;\n    const [value] = getValue();\n    const initialOffset = options.indexOf(value) * height;\n\n    return (\n      <List\n        height={maxHeight}\n        itemCount={children.length}\n        itemSize={height}\n        initialScrollOffset={initialOffset}\n      >\n        {({ index, style }) => <div style={style}>{children[index]}</div>}\n      </List>\n    );\n  }\n}\n\nconst App = () => (\n  <Select\n    filterOption={createFilter({ ignoreAccents: false })} // this makes all the difference!\n    components={{ MenuList }}\n    options={options}\n  />\n);\n\nReactDOM.render(<App />, document.getElementById('root'));\n")))}d.isMDXComponent=!0},58118:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-and-high-cpu-usage-watch",title:"TypeScript and high CPU usage - watch don't stare!",authors:"johnnyreilly",tags:["typescript","fork-ts-checker-webpack-plugin","webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-and-high-cpu-usage-watch",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2019-05-23-typescript-and-high-cpu-usage-watch/index.md",source:"@site/blog/2019-05-23-typescript-and-high-cpu-usage-watch/index.md",title:"TypeScript and high CPU usage - watch don't stare!",description:"I'm one of the maintainers of the fork-ts-checker-webpack-plugin. Hi there!",date:"2019-05-23T00:00:00.000Z",formattedDate:"May 23, 2019",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"fork-ts-checker-webpack-plugin",permalink:"/tags/fork-ts-checker-webpack-plugin"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:2.735,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-and-high-cpu-usage-watch",title:"TypeScript and high CPU usage - watch don't stare!",authors:"johnnyreilly",tags:["typescript","fork-ts-checker-webpack-plugin","webpack"],hide_table_of_contents:!1},prevItem:{title:"TypeScript / webpack - you down with PnP? Yarn, you know me!",permalink:"/typescript-webpack-you-down-with-pnp"},nextItem:{title:"react-select with less typing lag",permalink:"/react-select-with-less-typing-lag"}},p={authorsImageUrls:[void 0]},u=[{value:"Why High?",id:"why-high",level:2},{value:"&quot;there is another&quot;",id:"there-is-another",level:2},{value:"workaround!",id:"workaround",level:2},{value:"The Future",id:"the-future",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I'm one of the maintainers of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin"}),"fork-ts-checker-webpack-plugin"),". Hi there!"),(0,a.kt)("p",null,"Recently, various issues have been raised against create-react-app (which uses fork-ts-checker-webpack-plugin) as well as against the plugin itself. They've been related to the level of CPU usage in watch mode on idle; i.e. it's high!"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/Realytics/fork-ts-checker-webpack-plugin/issues/236"}),"https://github.com/Realytics/fork-ts-checker-webpack-plugin/issues/236")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/facebook/create-react-app/issues/6792"}),"https://github.com/facebook/create-react-app/issues/6792"))),(0,a.kt)("h2",o({},{id:"why-high"}),"Why High?"),(0,a.kt)("p",null,"Now, under the covers, the ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin")," uses the TypeScript watch API."),(0,a.kt)("p",null,"The marvellous ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/NeKJ"}),"John")," (not me - another John) did some digging and discovered the root cause came down to the way that the TypeScript watch API watches files:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"TS uses internally the ",(0,a.kt)("inlineCode",{parentName:"p"},"fs.watch")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"fs.watchFile")," API functions of nodejs for their watch mode. The latter function ",(0,a.kt)("a",o({parentName:"p"},{href:"https://nodejs.org/api/fs.html#fs_fs_watchfile_filename_options_listener"}),"is even not recommended by nodejs documentation")," for performance reasons, and urges to use ",(0,a.kt)("inlineCode",{parentName:"p"},"fs.watch")," instead."),(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("strong",{parentName:"p"},"NodeJS doc:")),(0,a.kt)("blockquote",{parentName:"blockquote"},(0,a.kt)("p",{parentName:"blockquote"},"Using fs.watch() is more efficient than fs.watchFile and fs.unwatchFile. fs.watch should be used instead of fs.watchFile and fs.unwatchFile when possible."))),(0,a.kt)("h2",o({},{id:"there-is-another"}),'"there is another"'),(0,a.kt)("p",null,"John also found that there are other file watching behaviours offered by TypeScript. What's more, the file watching behaviour is ",(0,a.kt)("em",{parentName:"p"},"configurable with an environment variable"),". That's right, if an environment variable called ",(0,a.kt)("inlineCode",{parentName:"p"},"TSC_WATCHFILE")," is set, it controls the file watching approach used. Big news!"),(0,a.kt)("p",null,"John did some rough benchmarking of the performance of the different options that be set on his PC running linux 64 bit. Here's how it came out:"),(0,a.kt)("table",null,(0,a.kt)("thead",{parentName:"table"},(0,a.kt)("tr",{parentName:"thead"},(0,a.kt)("th",o({parentName:"tr"},{align:null}),"Value"),(0,a.kt)("th",o({parentName:"tr"},{align:null}),"CPU usage on idle"))),(0,a.kt)("tbody",{parentName:"table"},(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"TS default ",(0,a.kt)("em",{parentName:"td"},"(TSC_WATCHFILE not set)")),(0,a.kt)("td",o({parentName:"tr"},{align:null}),(0,a.kt)("strong",{parentName:"td"},"7",".","4%"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"UseFsEventsWithFallbackDynamicPolling"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),"0",".","2%")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"UseFsEventsOnParentDirectory"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),"0",".","2%")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"PriorityPollingInterval"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),(0,a.kt)("strong",{parentName:"td"},"6",".","2%"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"DynamicPriorityPolling"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),"0",".","5%")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"UseFsEvents"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),"0",".","2%")))),(0,a.kt)("p",null,"As you can see, the default performs poorly. On the other hand, an option like ",(0,a.kt)("inlineCode",{parentName:"p"},"UseFsEventsWithFallbackDynamicPolling")," is comparative greasy lightning."),(0,a.kt)("h2",o({},{id:"workaround"}),"workaround!"),(0,a.kt)("p",null,"To get this better experience into your world now, you could just set an environment variable on your machine. However, that doesn't scale; let's instead look at introducing the environment variable into your project explicitly."),(0,a.kt)("p",null,"We're going to do this in a cross platform way using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/kentcdodds/cross-env"}),(0,a.kt)("inlineCode",{parentName:"a"},"cross-env")),". This is a mighty useful utility by Kent C Dodds which allows you to set environment variables in a way that will work on Windows, Mac and Linux. Imagine it as the jQuery of the environment variables world :-)"),(0,a.kt)("p",null,"Let's add it as a ",(0,a.kt)("inlineCode",{parentName:"p"},"devDependency"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"yarn add -D cross-env\n")),(0,a.kt)("p",null,"Then take a look at your ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json"),". You've probably got a ",(0,a.kt)("inlineCode",{parentName:"p"},"start")," script that looks something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'"start": "webpack-dev-server --progress --color --mode development --config webpack.config.development.js",\n')),(0,a.kt)("p",null,"Or if you're a create-react-app user maybe this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'"start": "react-scripts start",\n')),(0,a.kt)("p",null,"Prefix your ",(0,a.kt)("inlineCode",{parentName:"p"},"start")," script with ",(0,a.kt)("inlineCode",{parentName:"p"},"cross-env TSC_WATCHFILE=UseFsEventsWithFallbackDynamicPolling"),". This will, when run, initialise an environment variable called ",(0,a.kt)("inlineCode",{parentName:"p"},"TSC_WATCHFILE")," with the value ",(0,a.kt)("inlineCode",{parentName:"p"},"UseFsEventsWithFallbackDynamicPolling"),". Then it will start your development server as it did before. When TypeScript is fired up by webpack it will see this environment variable and use it to configure the file watching behaviour to one of the more performant options."),(0,a.kt)("p",null,"So, in the case of a ",(0,a.kt)("inlineCode",{parentName:"p"},"create-react-app")," user, your finished ",(0,a.kt)("inlineCode",{parentName:"p"},"start")," script would look like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'"start": "cross-env TSC_WATCHFILE=UseFsEventsWithFallbackDynamicPolling react-scripts start",\n')),(0,a.kt)("h2",o({},{id:"the-future"}),"The Future"),(0,a.kt)("p",null,"There's a possibility that the default watch behaviour may change in TypeScript in future. It's currently under discussion, you can read more ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/TypeScript/issues/31048"}),"here"),"."))}d.isMDXComponent=!0},22456:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-webpack-you-down-with-pnp",title:"TypeScript / webpack - you down with PnP? Yarn, you know me!",authors:"johnnyreilly",tags:["typescript","yarn","webpack","PnP"],hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-webpack-you-down-with-pnp",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2019-06-07-typescript-webpack-you-down-with-pnp/index.md",source:"@site/blog/2019-06-07-typescript-webpack-you-down-with-pnp/index.md",title:"TypeScript / webpack - you down with PnP? Yarn, you know me!",description:"Yarn PnP is an innovation by the Yarn team designed to speed up module resolution by node. To quote the (excellent) docs:",date:"2019-06-07T00:00:00.000Z",formattedDate:"June 7, 2019",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"yarn",permalink:"/tags/yarn"},{label:"webpack",permalink:"/tags/webpack"},{label:"PnP",permalink:"/tags/pn-p"}],readingTime:5.52,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-webpack-you-down-with-pnp",title:"TypeScript / webpack - you down with PnP? Yarn, you know me!",authors:"johnnyreilly",tags:["typescript","yarn","webpack","PnP"],hide_table_of_contents:!1},prevItem:{title:"Using TypeScript and ESLint with webpack (fork-ts-checker-webpack-plugin new feature!)",permalink:"/typescript-and-eslint-meet-fork-ts-checker-webpack-plugin"},nextItem:{title:"TypeScript and high CPU usage - watch don't stare!",permalink:"/typescript-and-high-cpu-usage-watch"}},p={authorsImageUrls:[void 0]},u=[{value:"Vanilla <code>ts-loader</code>",id:"vanilla-ts-loader",level:2},{value:"<code>fork-ts-checker-webpack-plugin</code> with <code>ts-loader</code>",id:"fork-ts-checker-webpack-plugin-with-ts-loader",level:2},{value:"Living on the Bleeding Edge",id:"living-on-the-bleeding-edge",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Yarn PnP is an innovation by the Yarn team designed to speed up module resolution by node. To quote the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://yarnpkg.com/en/docs/pnp"}),"(excellent) docs"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Plug\u2019n\u2019Play is an alternative installation strategy unveiled in September 2018..."),(0,a.kt)("p",{parentName:"blockquote"},"The way regular installs work is simple: Yarn generates a ",(0,a.kt)("inlineCode",{parentName:"p"},"node_modules")," directory that Node is then able to consume. In this context, Node doesn\u2019t know the first thing about what a package is: it only reasons in terms of files. \u201cDoes this file exist here? No? Let\u2019s look in the parent ",(0,a.kt)("inlineCode",{parentName:"p"},"node_modules")," then. Does it exist here? Still no? Too bad\u2026 parent folder it is!\u201d - and it does this until it matches something that matches one of the possibilities. That\u2019s vastly inefficient."),(0,a.kt)("p",{parentName:"blockquote"},"When you think about it, Yarn knows everything about your dependency tree - it evens installs it! So why is Node tasked with locating your packages on the disk? Why don\u2019t we simply query Yarn, and let it tell us where to look for a package X required by a package Y? That\u2019s what Plug\u2019n\u2019Play (abbreviated PnP) is. Instead of generating a node_modules directory and leaving the resolution to Node, we now generate a single .pnp.js file and let Yarn tell us where to find our packages.")),(0,a.kt)("p",null,"Yarn has been worked upon, amongst others, by the excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/arcanis"}),"Ma\xebl Nison"),". You can hear him talking about it in person ",(0,a.kt)("a",o({parentName:"p"},{href:"https://youtu.be/XePfzVs852s"}),"in this talk at JSConfEU"),"."),(0,a.kt)("p",null,"Thanks particularly to Ma\xebl's work, it's possible to use Yarn PnP with TypeScript using webpack with ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," ",(0,a.kt)("em",{parentName:"p"},"and"),(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin"),". This post intends to show you just how simple it is to convert a project that uses either to work with Yarn PnP."),(0,a.kt)("h2",o({},{id:"vanilla-ts-loader"}),"Vanilla ",(0,a.kt)("inlineCode",{parentName:"h2"},"ts-loader")),(0,a.kt)("p",null,"Your project is built using standalone ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader"),"; i.e. a simple setup that handles both transpilation and type checking."),(0,a.kt)("p",null,"First things first, add this property to your ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json"),": (this is only required if you are using Yarn 1; this tag will be optional starting from the v2, where projects will switch to PnP by default.)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'{\n    "installConfig": {\n        "pnp": true\n    }\n}\n')),(0,a.kt)("p",null,"Also, because this is webpack, we're going to need to add an extra dependency in the form of ",(0,a.kt)("inlineCode",{parentName:"p"},"pnp-webpack-plugin"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"yarn add -D pnp-webpack-plugin\n")),(0,a.kt)("p",null,"To quote the excellent docs, make the following amends to your ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"const PnpWebpackPlugin = require(`pnp-webpack-plugin`);\n\nmodule.exports = {\n    module: {\n        rules: [{\n            test: /\\.ts$/,\n            loader: require.resolve('ts-loader'),\n            options: PnpWebpackPlugin.tsLoaderOptions(),\n        }],\n    },\n    resolve: {\n        plugins: [ PnpWebpackPlugin, ],\n    },\n    resolveLoader: {\n        plugins: [ PnpWebpackPlugin.moduleLoader(module), ],\n    },\n};\n")),(0,a.kt)("p",null,"If you have any options you want to pass to ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader"),", just pass them as parameter of ",(0,a.kt)("inlineCode",{parentName:"p"},"pnp-webpack-plugin"),"'s ",(0,a.kt)("inlineCode",{parentName:"p"},"tsLoaderOptions")," function and it will take care of forwarding them properly. Behind the scenes the ",(0,a.kt)("inlineCode",{parentName:"p"},"tsLoaderOptions")," function is providing ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," with the options necessary to switch into Yarn PnP mode."),(0,a.kt)("p",null,"Congratulations; you now have ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," functioning with Yarn PnP support!"),(0,a.kt)("h2",o({},{id:"fork-ts-checker-webpack-plugin-with-ts-loader"}),(0,a.kt)("inlineCode",{parentName:"h2"},"fork-ts-checker-webpack-plugin")," with ",(0,a.kt)("inlineCode",{parentName:"h2"},"ts-loader")),(0,a.kt)("p",null,"You may well be using ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin")," to handle type checking whilst ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," gets on with the transpilation. This workflow is also supported using ",(0,a.kt)("inlineCode",{parentName:"p"},"pnp-webpack-plugin"),". You'll have needed to follow the same steps as the ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," setup. It's just the ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js")," tweaks that will be different."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"const PnpWebpackPlugin = require(`pnp-webpack-plugin`);\n\nmodule.exports = {\n    plugins: {\n        new ForkTsCheckerWebpackPlugin(PnpWebpackPlugin.forkTsCheckerOptions({\n            useTypescriptIncrementalApi: false, // not possible to use this until: https://github.com/microsoft/TypeScript/issues/31056\n        })),\n    }\n    module: {\n        rules: [{\n            test: /\\.ts$/,\n            loader: require.resolve('ts-loader'),\n            options: PnpWebpackPlugin.tsLoaderOptions({ transpileOnly: true }),\n        }],\n    },\n    resolve: {\n        plugins: [ PnpWebpackPlugin, ],\n    },\n    resolveLoader: {\n        plugins: [ PnpWebpackPlugin.moduleLoader(module), ],\n    },\n};\n")),(0,a.kt)("p",null,"Again if you have any options you want to pass to ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader"),", just pass them as parameter of ",(0,a.kt)("inlineCode",{parentName:"p"},"pnp-webpack-plugin"),"'s ",(0,a.kt)("inlineCode",{parentName:"p"},"tsLoaderOptions")," function. As we're using ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin")," we're going to want to stop ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," doing type checking with the ",(0,a.kt)("inlineCode",{parentName:"p"},"transpileOnly: true")," option."),(0,a.kt)("p",null,"We're now initialising ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin")," with ",(0,a.kt)("inlineCode",{parentName:"p"},"pnp-webpack-plugin"),"'s ",(0,a.kt)("inlineCode",{parentName:"p"},"forkTsCheckerOptions")," function. Behind the scenes the ",(0,a.kt)("inlineCode",{parentName:"p"},"forkTsCheckerOptions")," function is providing the ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin")," with the options necessary to switch into Yarn PnP mode."),(0,a.kt)("p",null,"And that's it! You now have ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin")," functioning with Yarn PnP support!"),(0,a.kt)("h2",o({},{id:"living-on-the-bleeding-edge"}),"Living on the Bleeding Edge"),(0,a.kt)("p",null,"Whilst you can happily develop and build using Yarn PnP, it's worth bearing in mind that this is a new approach. As such, there's some rough edges right now."),(0,a.kt)("p",null,"If you're interested in Yarn PnP, it's worth taking the v2 of Yarn (Berry) for a spin. You can find it here: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/yarnpkg/berry"}),"https://github.com/yarnpkg/berry"),". It's where most of the Yarn PnP work happens, and it includes zip loading - two birds, one stone!"),(0,a.kt)("p",null,"Because there isn't first class support for Yarn PnP in TypeScript itself yet, you cannot make use of the Watch API through ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin"),". (You can read about that issue ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/TypeScript/issues/31056"}),"here"),")"),(0,a.kt)("p",null,"As you've likely noticed, the webpack configuration required makes for a noisy ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js"),". Further to that, VS Code (which is powered by TypeScript remember) has no support for Yarn PnP yet and so will present resolution errors to you. If you can ignore the sea of red squigglies all over your source files in the editor and just look at your webpack build you'll be fine."),(0,a.kt)("p",null,"There is a tool called ",(0,a.kt)("inlineCode",{parentName:"p"},"PnPify")," that adds support for PnP to TypeScript (in particular tsc). You can find more information here: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://yarnpkg.github.io/berry/advanced/pnpify"}),"https://yarnpkg.github.io/berry/advanced/pnpify"),". For tsc it would be:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"$> yarn pnpify tsc [...]\n")),(0,a.kt)("p",null,"The gist is that it simulates the existence of ",(0,a.kt)("inlineCode",{parentName:"p"},"node_modules")," by leveraging the data from the PnP file. As such it's not a perfect fix (",(0,a.kt)("inlineCode",{parentName:"p"},"pnp-webpack-plugin")," is a better integration), but it's a very useful tool to have to unblock yourself when using a project that doesn't support it."),(0,a.kt)("p",null,"PnPify actually allows us to use TypeScript in VSCode with PnP! Its documentation is here: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://yarnpkg.github.io/berry/advanced/pnpify#vscode-support"}),"https://yarnpkg.github.io/berry/advanced/pnpify#vscode-support")),(0,a.kt)("p",null,"All of these hindrances should hopefully be resolved in future. Ideally, one day a good developer experience can be the default experience. In the meantime, you can still dev - just be prepared for the rough edges. Here's some useful resources to track the future of support:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"You can follow more on built in webpack support here: ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/webpack/enhanced-resolve/issues/162"}),"https://github.com/webpack/enhanced-resolve/issues/162")),(0,a.kt)("li",{parentName:"ul"},"And on built in TypeScript support here: ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/Microsoft/TypeScript/issues/18896"}),"https://github.com/Microsoft/TypeScript/issues/18896")),(0,a.kt)("li",{parentName:"ul"},"Finally, there it's worth watching the ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/nodejs/modules"}),"nodejs/module")," repository, which debates amongst other things how to properly integrate loaders with Node.")),(0,a.kt)("p",null,"This last one would be nice because:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"We'd stop having to patch require"),(0,a.kt)("li",{parentName:"ul"},"We probably wouldn't have to use yarn node if Node itself was able to find the loader somehow (such as if it was listed in the package.json metadata)")),(0,a.kt)("p",null,"Thanks to Ma\xebl for his tireless work on Yarn. To my mind Ma\xebl is certainly a candidate for the hardest worker in open source. I've been shamelessly borrowing his excellent docs for this post - thanks for writing so excellently Ma\xebl!"))}d.isMDXComponent=!0},82627:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-and-eslint-meet-fork-ts-checker-webpack-plugin",title:"Using TypeScript and ESLint with webpack (fork-ts-checker-webpack-plugin new feature!)",authors:"johnnyreilly",tags:["ESLint","typescript","fork-ts-checker-webpack-plugin","Webpack"],hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-and-eslint-meet-fork-ts-checker-webpack-plugin",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2019-07-13-typescript-and-eslint-meet-fork-ts-checker-webpack-plugin/index.md",source:"@site/blog/2019-07-13-typescript-and-eslint-meet-fork-ts-checker-webpack-plugin/index.md",title:"Using TypeScript and ESLint with webpack (fork-ts-checker-webpack-plugin new feature!)",description:"The fork-ts-checker-webpack-plugin has, since its inception, performed two classes of checking:",date:"2019-07-13T00:00:00.000Z",formattedDate:"July 13, 2019",tags:[{label:"ESLint",permalink:"/tags/es-lint"},{label:"typescript",permalink:"/tags/typescript"},{label:"fork-ts-checker-webpack-plugin",permalink:"/tags/fork-ts-checker-webpack-plugin"},{label:"Webpack",permalink:"/tags/webpack"}],readingTime:4.615,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-and-eslint-meet-fork-ts-checker-webpack-plugin",title:"Using TypeScript and ESLint with webpack (fork-ts-checker-webpack-plugin new feature!)",authors:"johnnyreilly",tags:["ESLint","typescript","fork-ts-checker-webpack-plugin","Webpack"],hide_table_of_contents:!1},prevItem:{title:"ASP.NET Core authentication: hard-coding a claim in development",permalink:"/asp-net-authentication-hard-coding-claims"},nextItem:{title:"TypeScript / webpack - you down with PnP? Yarn, you know me!",permalink:"/typescript-webpack-you-down-with-pnp"}},p={authorsImageUrls:[void 0]},u=[{value:"How do you migrate from TSLint to ESLint?",id:"how-do-you-migrate-from-tslint-to-eslint",level:2},{value:"Go Configure",id:"go-configure",level:2},{value:"Performance and Power Tools",id:"performance-and-power-tools",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin")," has, since its inception, performed two classes of checking:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Compilation errors which the TypeScript compiler surfaces up"),(0,a.kt)("li",{parentName:"ol"},"Linting issues which TSLint reports")),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://eslint.org/blog/2019/01/future-typescript-eslint"}),"You may have caught the announcement that TSLint is being deprecated and ESLint is the future of linting in the TypeScript world.")," This plainly has a bearing on linting in ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin"),"."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/fork-ts-checker-webpack-plugin/pull/305"}),"I've been beavering away at adding support for ESLint to the fork-ts-checker-webpack-plugin.")," I'm happy to say, the plugin now supports ESLint. Do you want to get your arms all around ESLint with ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin"),"? Read on!"),(0,a.kt)("h2",o({},{id:"how-do-you-migrate-from-tslint-to-eslint"}),"How do you migrate from TSLint to ESLint?"),(0,a.kt)("p",null,"Well, first of all you need the latest and greatest ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin"),". Support for ESLint shipped with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/fork-ts-checker-webpack-plugin/releases/tag/v1.4.0"}),"v1.4.0"),"."),(0,a.kt)("p",null,"You need to change the options you supply to the plugin in your ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js")," to look something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"new ForkTsCheckerWebpackPlugin({ eslint: true });\n")),(0,a.kt)("p",null,"You'll also need the various ESLint related packages to your ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"yarn add eslint @typescript-eslint/parser @typescript-eslint/eslint-plugin --dev\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"eslint")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@typescript-eslint/parser"),": The parser that will allow ESLint to lint TypeScript code"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@typescript-eslint/eslint-plugin"),": A plugin that contains ESLint rules that are TypeScript specific")),(0,a.kt)("p",null,"If you want, you can pass options to ESLint using the ",(0,a.kt)("inlineCode",{parentName:"p"},"eslintOptions")," option as well. These will be passed through to the underlying ESLint CLI Engine when it is instantiated. Docs on the supported options are ",(0,a.kt)("a",o({parentName:"p"},{href:"https://eslint.org/docs/developer-guide/nodejs-api#cliengine"}),"documented here"),"."),(0,a.kt)("h2",o({},{id:"go-configure"}),"Go Configure"),(0,a.kt)("p",null,"Now you're ready to use ESLint, you just need to give it some configuration. Typically, an ",(0,a.kt)("inlineCode",{parentName:"p"},".eslintrc.js")," is what you want here."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const path = require('path');\nmodule.exports = {\n  parser: '@typescript-eslint/parser', // Specifies the ESLint parser\n  plugins: ['@typescript-eslint'],\n  env: {\n    browser: true,\n    jest: true,\n  },\n  extends: [\n    'plugin:@typescript-eslint/recommended', // Uses the recommended rules from the @typescript-eslint/eslint-plugin\n  ],\n  parserOptions: {\n    project: path.resolve(__dirname, './tsconfig.json'),\n    tsconfigRootDir: __dirname,\n    ecmaVersion: 2018, // Allows for the parsing of modern ECMAScript features\n    sourceType: 'module', // Allows for the use of imports\n  },\n  rules: {\n    // Place to specify ESLint rules. Can be used to overwrite rules specified from the extended configs\n    // e.g. \"@typescript-eslint/explicit-function-return-type\": \"off\",\n    '@typescript-eslint/explicit-function-return-type': 'off',\n    '@typescript-eslint/no-unused-vars': 'off',\n  },\n};\n")),(0,a.kt)("p",null,"If you're a React person (and I am!) then you'll also need: ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn add eslint-plugin-react"),". Then enrich your ",(0,a.kt)("inlineCode",{parentName:"p"},"eslintrc.js")," a little:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const path = require('path');\nmodule.exports = {\n  parser: '@typescript-eslint/parser', // Specifies the ESLint parser\n  plugins: [\n    '@typescript-eslint',\n    'react',\n    // 'prettier' commented as we don't want to run prettier through eslint because performance\n  ],\n  env: {\n    browser: true,\n    jest: true,\n  },\n  extends: [\n    'plugin:@typescript-eslint/recommended', // Uses the recommended rules from the @typescript-eslint/eslint-plugin\n    'prettier/@typescript-eslint', // Uses eslint-config-prettier to disable ESLint rules from @typescript-eslint/eslint-plugin that would conflict with prettier\n    // 'plugin:react/recommended', // Uses the recommended rules from @eslint-plugin-react\n    'prettier/react', // disables react-specific linting rules that conflict with prettier\n    // 'plugin:prettier/recommended' // Enables eslint-plugin-prettier and displays prettier errors as ESLint errors. Make sure this is always the last configuration in the extends array.\n  ],\n  parserOptions: {\n    project: path.resolve(__dirname, './tsconfig.json'),\n    tsconfigRootDir: __dirname,\n    ecmaVersion: 2018, // Allows for the parsing of modern ECMAScript features\n    sourceType: 'module', // Allows for the use of imports\n    ecmaFeatures: {\n      jsx: true, // Allows for the parsing of JSX\n    },\n  },\n  rules: {\n    // Place to specify ESLint rules. Can be used to overwrite rules specified from the extended configs\n    // e.g. \"@typescript-eslint/explicit-function-return-type\": \"off\",\n    '@typescript-eslint/explicit-function-return-type': 'off',\n    '@typescript-eslint/no-unused-vars': 'off',\n\n    // These rules don't add much value, are better covered by TypeScript and good definition files\n    'react/no-direct-mutation-state': 'off',\n    'react/no-deprecated': 'off',\n    'react/no-string-refs': 'off',\n    'react/require-render-return': 'off',\n\n    'react/jsx-filename-extension': [\n      'warn',\n      {\n        extensions: ['.jsx', '.tsx'],\n      },\n    ], // also want to use with \".tsx\"\n    'react/prop-types': 'off', // Is this incompatible with TS props type?\n  },\n  settings: {\n    react: {\n      version: 'detect', // Tells eslint-plugin-react to automatically detect the version of React to use\n    },\n  },\n};\n")),(0,a.kt)("p",null,"You can add Prettier into the mix too. You can see how it is used in the above code sample. But given the impact that has on performance I wouldn't recommend it; hence it's commented out. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://dev.to/robertcoopercode/using-eslint-and-prettier-in-a-typescript-project-53jb"}),"There's a good piece by Rob Cooper's for more details on setting up Prettier and VS Code with TypeScript and ESLint.")),(0,a.kt)("h2",o({},{id:"performance-and-power-tools"}),"Performance and Power Tools"),(0,a.kt)("p",null,'It\'s worth noting that support for TypeScript in ESLint is still brand new. As such, the rule of "Make it Work, Make it Right, Make it Fast" applies.... ESLint with TypeScript still has some performance issues which should be ironed out in the fullness of time. You can ',(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/typescript-eslint/typescript-eslint/issues/389"}),"track them here"),"."),(0,a.kt)("p",null,"This is important to bear in mind as, when I converted a large codebase over to using ESLint, I discovered that initial performance of linting was terribly slow. Something that's worth doing right now is identifying which rules are costing you most timewise and tweaking based on whether you think they're earning their keep."),(0,a.kt)("p",null,"The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://eslint.org/docs/developer-guide/working-with-rules#per-rule-performance"}),(0,a.kt)("inlineCode",{parentName:"a"},"TIMING")," environment variable")," can be used to provide a report on the relative cost performance wise of running each rule. A nice way to plug this into your workflow is to add the ",(0,a.kt)("inlineCode",{parentName:"p"},"cross-env")," package to your project: ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn add cross-env -D")," and then add 2 scripts to your ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'"lint": "eslint ./",\n"lint-rule-timings": "cross-env TIMING=1 yarn lint"\n')),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"lint")," ","-"," just runs the linter standalone"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"lint-rule-timings")," ","-"," does the same but with the ",(0,a.kt)("inlineCode",{parentName:"li"},"TIMING")," environment variable set to 1 so a report will be generated.")),(0,a.kt)("p",null,"I'd advise, making use of ",(0,a.kt)("inlineCode",{parentName:"p"},"lint-rule-timings")," to identify which rules are costing you performance and then turning ",(0,a.kt)("inlineCode",{parentName:"p"},"off")," rules as you need to. Remember, different rules have different value."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/960"}),"Finally, if you'd like to see how it's done, here's an example of porting from TSLint to ESLint.")))}d.isMDXComponent=!0},86163:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"asp-net-authentication-hard-coding-claims",title:"ASP.NET Core authentication: hard-coding a claim in development",authors:"johnnyreilly",tags:["ASP.Net Core","Authentication"],hide_table_of_contents:!1},s=void 0,l={permalink:"/asp-net-authentication-hard-coding-claims",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2019-08-02-asp-net-authentication-hard-coding-claims/index.md",source:"@site/blog/2019-08-02-asp-net-authentication-hard-coding-claims/index.md",title:"ASP.NET Core authentication: hard-coding a claim in development",description:"This post demonstrates how you can hard code user authentication claims in ASP.NET Core; a useful technique to facilate testing during development.",date:"2019-08-02T00:00:00.000Z",formattedDate:"August 2, 2019",tags:[{label:"ASP.Net Core",permalink:"/tags/asp-net-core"},{label:"Authentication",permalink:"/tags/authentication"}],readingTime:2.775,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"asp-net-authentication-hard-coding-claims",title:"ASP.NET Core authentication: hard-coding a claim in development",authors:"johnnyreilly",tags:["ASP.Net Core","Authentication"],hide_table_of_contents:!1},prevItem:{title:"Symbiotic Definitely Typed",permalink:"/symbiotic-definitely-typed"},nextItem:{title:"Using TypeScript and ESLint with webpack (fork-ts-checker-webpack-plugin new feature!)",permalink:"/typescript-and-eslint-meet-fork-ts-checker-webpack-plugin"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This post demonstrates how you can hard code user authentication claims in ASP.NET Core; a useful technique to facilate testing during development."),(0,a.kt)("p",null,"I was recently part of a hackathon team that put together an API in just 30 hours. We came second. (Not bitter, not bitter...)"),(0,a.kt)("p",null,"We were moving pretty quickly during the hackathon and, when we came to the end of it, we had a working API which we were able to demo. The good news is that the API is going to graduate to be a product! We're going to ship this. Before we can do that though, there's a little tidy up to do."),(0,a.kt)("p",null,"The first thing I remembered / realised when I picked up the codebase again, was the shortcuts we'd made on the developer experience. We'd put the API together using ASP.Net Core. We're handling authentication using JWTs which is nicely supported. When we're deployed, an external facing proxy calls our application with the appropriate JWT and everything works as you'd hope."),(0,a.kt)("p",null,"The question is, what's it like to develop against this on your laptop? Getting a JWT for when I'm debugging locally is too much friction. I want to be able to work on the problem at hand, going away to get a JWT each time is a timesuck. So what to do? Well, during the hackathon, we just commented out ",(0,a.kt)("inlineCode",{parentName:"p"},"[Authorize]")," attributes and hardcoded user ids in our controllers. This works, but it's a messy developer experience; it's easy to forget to uncomment things you've commented and break things. There must be a better way."),(0,a.kt)("p",null,"The solution I landed on was this: in development mode (which we only use whilst debugging) we hardcode an authenticated user. The way our authentication works is that we have a claim on our principal called something like ",(0,a.kt)("inlineCode",{parentName:"p"},'"our-user-id"'),", the value of which is our authenticated user id. So in the ",(0,a.kt)("inlineCode",{parentName:"p"},"ConfigureServices")," method of our ",(0,a.kt)("inlineCode",{parentName:"p"},"Startup.cs")," we have a conditional authentication registration like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'// Whilst developing, we don\'t want to authenticate; we hardcode to a particular users id\nif (Env.IsDevelopment()) {\n    services.AddAuthentication(nameof(DevelopmentModeAuthenticationHandler))\n        .AddScheme<DevelopmentModeAuthenticationOptions, DevelopmentModeAuthenticationHandler>(\n            nameof(DevelopmentModeAuthenticationHandler),\n            options => {\n                options.UserIdToSetInClaims = "this-is-a-user-id";\n            }\n        );\n}\nelse {\n    // The application typically uses this\n    services.AddAuthentication(JwtBearerDefaults.AuthenticationScheme)\n        .AddJwtBearer(options => {\n            // ...\n        });\n}\n')),(0,a.kt)("p",null,"As you can see, we're using a special ",(0,a.kt)("inlineCode",{parentName:"p"},"DevelopmentModeAuthenticationHandler")," authentication scheme in development mode, instead of JWT. As we register that, we declare the user id that we want to use. Whenever the app runs using the ",(0,a.kt)("inlineCode",{parentName:"p"},"DevelopmentModeAuthenticationHandler")," auth, all requests will arrive using a principal with an ",(0,a.kt)("inlineCode",{parentName:"p"},'"our-user-id"')," claim with a value of ",(0,a.kt)("inlineCode",{parentName:"p"},'"this-is-a-user-id"')," (or whatever you've set it to.)"),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"DevelopmentModeAuthenticationHandler")," looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System.Collections.Generic;\nusing System.Security.Claims;\nusing System.Text.Encodings.Web;\nusing System.Threading.Tasks;\nusing Microsoft.AspNetCore.Authentication;\nusing Microsoft.Extensions.Logging;\nusing Microsoft.Extensions.Options;\n\nnamespace OurApp\n{\n    public class DevelopmentModeAuthenticationOptions : AuthenticationSchemeOptions\n    {\n        public string UserIdToSetInClaims { get; set; }\n    }\n\n    public class DevelopmentModeAuthenticationHandler : AuthenticationHandler<DevelopmentModeAuthenticationOptions> {\n        private readonly ILoggingService _loggingService;\n\n        public DevelopmentModeAuthenticationHandler(\n            IOptionsMonitor<DevelopmentModeAuthenticationOptions> options,\n            ILoggerFactory logger,\n            UrlEncoder encoder,\n            ISystemClock clock\n        ) : base(options, logger, encoder, clock) {\n        }\n\n        protected override Task<AuthenticateResult> HandleAuthenticateAsync() {\n            var claims = new List<Claim> { new Claim("our-user-id", Options.UserIdToSetInClaims) };\n\n            var identity = new ClaimsIdentity(claims, nameof(DevelopmentModeAuthenticationHandler));\n            var ticket = new AuthenticationTicket(new ClaimsPrincipal(identity), Scheme.Name);\n\n            return Task.FromResult(AuthenticateResult.Success(ticket));\n        }\n    }\n}\n')),(0,a.kt)("p",null,"Now, developing locally is frictionless! We don't comment out ",(0,a.kt)("inlineCode",{parentName:"p"},"[Authorize]")," attributes, we don't hard code user ids in controllers."))}d.isMDXComponent=!0},23065:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"symbiotic-definitely-typed",title:"Symbiotic Definitely Typed",authors:"johnnyreilly",tags:["typescript","react-testing-library","Definitely Typed"],hide_table_of_contents:!1},s=void 0,l={permalink:"/symbiotic-definitely-typed",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2019-08-17-symbiotic-definitely-typed/index.md",source:"@site/blog/2019-08-17-symbiotic-definitely-typed/index.md",title:"Symbiotic Definitely Typed",description:'I did ponder calling this post "how to enable a good TypeScript developer experience for npm modules that aren\'t written in TypeScript"... Not exactly pithy though.',date:"2019-08-17T00:00:00.000Z",formattedDate:"August 17, 2019",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"react-testing-library",permalink:"/tags/react-testing-library"},{label:"Definitely Typed",permalink:"/tags/definitely-typed"}],readingTime:5.64,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"symbiotic-definitely-typed",title:"Symbiotic Definitely Typed",authors:"johnnyreilly",tags:["typescript","react-testing-library","Definitely Typed"],hide_table_of_contents:!1},prevItem:{title:"Coming Soon: Definitely Typed",permalink:"/coming-soon-definitely-typed"},nextItem:{title:"ASP.NET Core authentication: hard-coding a claim in development",permalink:"/asp-net-authentication-hard-coding-claims"}},p={authorsImageUrls:[void 0]},u=[{value:"Update: Use a Loose Version Range in <code>package.json</code>",id:"update-use-a-loose-version-range-in-packagejson",level:2},{value:"Updated 2: Further Discussions!",id:"updated-2-further-discussions",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'I did ponder calling this post "how to enable a good TypeScript developer experience for npm modules that aren\'t written in TypeScript"... Not exactly pithy though.'),(0,a.kt)("p",null,"Definitely Typed is the resource which allows developers to use TypeScript with existing JavaScript libraries that ship without their own type definitions."),(0,a.kt)("p",null,"DT began as a way to enable interop between JS and TS. When DT started, everything on npm was JavaScript. Over time it has become more common for libraries (eg ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/mobxjs/mobx"}),"Mobx")," / ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/angular/angular"}),"Angular"),") to be written (or rewritten) in TypeScript. For publishing, they are compiled down to JS with perfect type definitions generated from the TypeScript alongside the compiled JavaScript. These libraries do not need to exist in Definitely Typed anymore."),(0,a.kt)("p",null,"Another pattern that has emerged over time is that of type definitions being removed from Definitely Typed to live and be maintained alongside the libraries they support. An example of this is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/moment/moment"}),"MomentJS"),"."),(0,a.kt)("p",null,"This week, I think for the first time, there emerged another approach. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://kentcdodds.com/"}),"Kent C Dodds"),"' ",(0,a.kt)("inlineCode",{parentName:"p"},"react-testing-library")," had started out with the MomentJS approach of hosting type definitions alongside the JavaScript source code. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/testing-library/react-testing-library/pull/437"}),"Alex Krolic raised a PR which proposed removing the type definitions from the RTL repo in favor of having the community maintain them at DefinitelyTyped.")),(0,a.kt)("p",null,"I'll directly quote Kent's explanation of the motivation for this:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"We were getting a lot of drive-by contributions to the TypeScript typings and many pull requests would either sit without being reviewed by someone who knows TypeScript well enough, or be merged by a maintainer who just hoped the contributor knew what they were doing. This resulted in a poor experience for TypeScript users who could experience type definition churn and delays, and it became a burden on project maintainers as well (most of us don't know TypeScript very well). Moving the type definitions to DefinitelyTyped puts the maintenance in much more capable hands.")),(0,a.kt)("p",null,"I have to admit I was reticent about this idea in the first place. I like the idea that types ship with the package they support. It's a good developer experience; users install your package and it works with TypeScript straight out of the box. However Alex's PR addressed a real issue: what do you do when the authors of a package aren't interested / equipped / don't have the time to support TypeScript? Or don't want to deal with the noise of TypeScript related PRs which aren't relevant to them. What then?"),(0,a.kt)("p",null,"Alex was saying, let's not force it. Let the types and the library be maintained separately. This can and is done well already; React is a case in point. The React team does not work on the type definitions for React, that's done (excellently) by a crew of dedicated React lovers in Definitely Typed."),(0,a.kt)("p",null,"It's a fair point. The thing that was sad about this move was that the developer experience was going to have more friction. Users would have to ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn add -D @testing-library/react")," and then subsequently ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn add -D @types/testing-library__react")," to get the types."),(0,a.kt)("p",null,"This two step process isn't the end of the world, but it does make it marginally harder for TypeScript users to get up and running. It reduces the developer joy. As a side note, this is made more unlovely by ",(0,a.kt)("inlineCode",{parentName:"p"},"@testing-library/react")," being a scoped package. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://stackoverflow.com/questions/47296731/how-can-i-install-typescript-declarations-for-scoped-namespaced-packages-via-ty"}),"Types for a scoped package have a quirky convention for publishing.")," A fictional scoped package of ",(0,a.kt)("inlineCode",{parentName:"p"},"@foo/bar")," would be published to npm as: ",(0,a.kt)("inlineCode",{parentName:"p"},"@types/foo__bar"),". This is functional but non-obvious; it's tricky to discover. A two step process instead of a one step process is a non-useful friction that it would be great to eliminate."),(0,a.kt)("p",null,"Fortunately, Kent and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/FredyC"}),"Daniel K")," had one of these moments:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(3141).Z,width:"640",height:"271"})),(0,a.kt)("p",null,"Kent suggested that at the same time as dropping the type definitions that were shipped with the library, we try making ",(0,a.kt)("inlineCode",{parentName:"p"},"@types/testing-library__react")," a dependency of ",(0,a.kt)("inlineCode",{parentName:"p"},"@testing-library/react"),". This would mean that people installing ",(0,a.kt)("inlineCode",{parentName:"p"},"@testing-library/react")," would get ",(0,a.kt)("inlineCode",{parentName:"p"},"@types/testing-library__react")," installed ",(0,a.kt)("em",{parentName:"p"},"automatically"),". So from the developers point of view, it's as though the type definitions shipped with the package directly."),(0,a.kt)("p",null,"To cut a long story short reader, that's what happened. If you're using ",(0,a.kt)("inlineCode",{parentName:"p"},"@testing-library/react")," from 9.1.2 you're getting Definitely Typed under the covers. This was ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/testing-library/react-testing-library/pull/437#issuecomment-521763117"}),"nicely illustrated by Kent")," showing what the TypeScript consumption experience looked like before the Definitely Typed switch:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(33118).Z,width:"640",height:"385"})),(0,a.kt)("p",null,"And here's what it looked like after:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(60746).Z,width:"640",height:"403"})),(0,a.kt)("p",null,"Identical! i.e it worked. I grant you this is one of the more boring before / after comparisons there is\u2026 But hopefully you can see it demonstrates that this is giving us exactly what we need."),(0,a.kt)("p",null,"To quote Kent once more:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"By adding the type definitions to the dependencies of React Testing Library, the experience for users is completely unchanged. So it's a huge improvement for the maintenance of the type definitions without any breaking changes for the users of those definitions.")),(0,a.kt)("p",null,"This is clearly an approach that's useful; it adds value. It would be tremendous to see other libraries that aren't written in TypeScript but would like to enable a good TypeScript experience for those people that do use TS also adopting this approach."),(0,a.kt)("h2",o({},{id:"update-use-a-loose-version-range-in-packagejson"}),"Update: Use a Loose Version Range in ",(0,a.kt)("inlineCode",{parentName:"h2"},"package.json")),(0,a.kt)("p",null,"When I ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/johnny_reilly/status/1162843916661592064"}),"tweeted this article")," it prompted this helpful response from ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/atcb"}),"Andrew Branch")," of the TypeScript team:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},">"," use a loose version range This is my advice as well and should probably be mentioned in the article TBH."),(0,a.kt)("p",{parentName:"blockquote"},"\u2014 Kent C. Dodds (@kentcdodds) ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/kentcdodds/status/1162876792287293440?ref_src=twsrc%5Etfw"}),"August 18, 2019"))),(0,a.kt)("script",{async:"",src:"https://platform.twitter.com/widgets.js",charSet:"utf-8"}),(0,a.kt)("p",null,"Andrew makes the useful point that if you are adding support for TypeScript via an ",(0,a.kt)("inlineCode",{parentName:"p"},"@types/...")," dependency then it's wise to do so with a loose version range. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/testing-library/react-testing-library/blob/c4ba755e42938018ec67dbc716037cfafca15e03/package.json#L46"}),"In the case of RTL we did it like this:")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"@types/testing-library__react": "^9.1.0"\n')),(0,a.kt)("p",null,"i.e. Any type definition with a version of ",(0,a.kt)("inlineCode",{parentName:"p"},"9.1")," or greater (whilst still lower than ",(0,a.kt)("inlineCode",{parentName:"p"},"10.0.0"),") is considered valid. You could go even looser than that. If you really don't want to think about TypeScript beyond adding the dependency then a completely loose version range would do:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"@types/testing-library__react": "*"\n')),(0,a.kt)("p",null,"This will always install the latest version of the ",(0,a.kt)("inlineCode",{parentName:"p"},"@types/testing-library__react")," dependency and (importantly) allow users to override if there's a problematic ",(0,a.kt)("inlineCode",{parentName:"p"},"@types/testing-library__react")," out there. This level of looseness is not really advised though. As in the scenario when a library (and associated type definitions) do a major release, users of the old major would get the wrong definitions by default when installing or upgrading (in range)."),(0,a.kt)("p",null,"Probably the most helpful approach is the approach followed by RTL; fixing the major version but allowing all minor and patch releases ",(0,a.kt)("em",{parentName:"p"},"inside")," a major version."),(0,a.kt)("h2",o({},{id:"updated-2-further-discussions"}),"Updated 2: Further Discussions!"),(0,a.kt)("p",null,"The technique used in this blog post sparked an interesting conversation with members of the TypeScript team when it was applied to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/testing-library/jest-dom"}),(0,a.kt)("inlineCode",{parentName:"a"},"https://github.com/testing-library/jest-dom")),". ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/testing-library/jest-dom/issues/123#issuecomment-523586977"}),"The conversation can be read here"),"."))}d.isMDXComponent=!0},6804:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"coming-soon-definitely-typed",title:"Coming Soon: Definitely Typed",authors:"johnnyreilly",tags:["typescript","Definitely Typed"],hide_table_of_contents:!1},s=void 0,l={permalink:"/coming-soon-definitely-typed",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2019-09-14-coming-soon-definitely-typed/index.md",source:"@site/blog/2019-09-14-coming-soon-definitely-typed/index.md",title:"Coming Soon: Definitely Typed",description:"A long time ago (well, 2012) in a galaxy far, far away (okay; Plovdiv, Bulgaria)....",date:"2019-09-14T00:00:00.000Z",formattedDate:"September 14, 2019",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"Definitely Typed",permalink:"/tags/definitely-typed"}],readingTime:.99,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"coming-soon-definitely-typed",title:"Coming Soon: Definitely Typed",authors:"johnnyreilly",tags:["typescript","Definitely Typed"],hide_table_of_contents:!1},prevItem:{title:"Start Me Up: ts-loader meet .tsbuildinfo",permalink:"/start-me-up-ts-loader-meet-tsbuildinfo"},nextItem:{title:"Symbiotic Definitely Typed",permalink:"/symbiotic-definitely-typed"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"A long time ago (well, 2012) in a galaxy far, far away (okay; Plovdiv, Bulgaria)...."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped"}),"Definitely Typed")," began!"),(0,a.kt)("p",null,"This is a project that set out to provide type definitions for every JavaScript library that lacked them. An ambitious goal. Have you ever wondered what the story that lay behind it was?"),(0,a.kt)("p",null,'Perhaps you know that the project was started by a shadowy figure named "Boris Yankov". And maybe you know that the TypeScript team is now part of the Definitely Typed team. There\'s a lot more to tell.'),(0,a.kt)("p",null,"This autumn, I'd like to tell you the story of how Definitely Typed came to be what it is. From an individual commit in a repo that Boris created in 2012 to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://octoverse.github.com/projects"}),"the number 10 project by contributions on GitHub in 2018"),". I'm part of that story. Basarat Ali Syed is part of that story. Masahi Wakame too. Blake Embrey. Steve Fenton. Igor Oleinikov. It's an amazing and unexpected tale. One that turns upon the actions of individuals. They changed your life and I'd love you to learn how."),(0,a.kt)("p",null,"So, coming soon to a blog post near you, is the story of Definitely Typed. It's very exciting! Stay tuned..."))}d.isMDXComponent=!0},9397:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"start-me-up-ts-loader-meet-tsbuildinfo",title:"Start Me Up: ts-loader meet .tsbuildinfo",authors:"johnnyreilly",tags:["ts-loader","typescript"],hide_table_of_contents:!1},s=void 0,l={permalink:"/start-me-up-ts-loader-meet-tsbuildinfo",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2019-09-30-start-me-up-ts-loader-meet-tsbuildinfo/index.md",source:"@site/blog/2019-09-30-start-me-up-ts-loader-meet-tsbuildinfo/index.md",title:"Start Me Up: ts-loader meet .tsbuildinfo",description:"With TypeScript 3.4, a new behaviour landed and a magical new file type appeared; .tsbuildinfo",date:"2019-09-30T00:00:00.000Z",formattedDate:"September 30, 2019",tags:[{label:"ts-loader",permalink:"/tags/ts-loader"},{label:"typescript",permalink:"/tags/typescript"}],readingTime:1.735,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"start-me-up-ts-loader-meet-tsbuildinfo",title:"Start Me Up: ts-loader meet .tsbuildinfo",authors:"johnnyreilly",tags:["ts-loader","typescript"],hide_table_of_contents:!1},prevItem:{title:"Definitely Typed: The Movie",permalink:"/definitely-typed-the-movie"},nextItem:{title:"Coming Soon: Definitely Typed",permalink:"/coming-soon-definitely-typed"}},p={authorsImageUrls:[void 0]},u=[{value:"<code>ts-loader v7.0.0</code>",id:"ts-loader-v700",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"With TypeScript 3.4, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-4.html"}),"a new behaviour landed and a magical new file type appeared; ",(0,a.kt)("inlineCode",{parentName:"a"},".tsbuildinfo"))),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"TypeScript 3.4 introduces a new flag called ",(0,a.kt)("inlineCode",{parentName:"p"},"--incremental")," which tells TypeScript to save information about the project graph from the last compilation. The next time TypeScript is invoked with ",(0,a.kt)("inlineCode",{parentName:"p"},"--incremental"),", it will use that information to detect the least costly way to type-check and emit changes to your project."),(0,a.kt)("p",{parentName:"blockquote"},"..."),(0,a.kt)("p",{parentName:"blockquote"},"These ",(0,a.kt)("inlineCode",{parentName:"p"},".tsbuildinfo")," files can be safely deleted and don\u2019t have any impact on our code at runtime - they\u2019re purely used to make compilations faster.")),(0,a.kt)("p",null,"This was all very exciting, but until the release of TypeScript 3.6 there were no APIs available to allow third party tools like ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," to hook into them. The wait is over! Because with TypeScript 3.6 the APIs landed: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-6.html#apis-to-support---build-and---incremental"}),"https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-6.html#apis-to-support---build-and---incremental")),(0,a.kt)("p",null,"This was the handiwork of the very excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/sheetalkamat"}),"@sheetalkamat")," of the TypeScript team - you can see her PR here: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/TypeScript/pull/31432"}),"https://github.com/microsoft/TypeScript/pull/31432")),(0,a.kt)("p",null,"What's more, Sheetal took the PR for a test drive using ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader"),", and her hard work has just shipped with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/releases/tag/v6.2.0"}),(0,a.kt)("inlineCode",{parentName:"a"},"v6.2.0")),":"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/TypeStrong/ts-loader/pull/1012"}),"https://github.com/TypeStrong/ts-loader/pull/1012")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/TypeStrong/ts-loader/pull/1017"}),"https://github.com/TypeStrong/ts-loader/pull/1017"))),(0,a.kt)("p",null,"If you're a ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," user, and you're using TypeScript 3.6+ then you can get the benefit of this now. That is, if you make use of the ",(0,a.kt)("inlineCode",{parentName:"p"},"experimentalWatchApi: true")," option. With this set:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"ts-loader will both emit and consume the ",(0,a.kt)("inlineCode",{parentName:"p"},".tsbuildinfo")," artefact.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"This applies both when a project has ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," options ",(0,a.kt)("inlineCode",{parentName:"p"},"composite")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"incremental")," set to ",(0,a.kt)("inlineCode",{parentName:"p"},"true"),".")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"The net result of people using this should be faster cold starts in build time where a previous compilation has taken place."))),(0,a.kt)("h2",o({},{id:"ts-loader-v700"}),(0,a.kt)("inlineCode",{parentName:"h2"},"ts-loader v7.0.0")),(0,a.kt)("p",null,"We would love for you to take this new functionality for a spin. Partly because we think it will make your life better. And partly because we're planning to make using the watch API the default behaviour of ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," when we come to ship ",(0,a.kt)("inlineCode",{parentName:"p"},"v7.0.0"),"."),(0,a.kt)("p",null,"If you can take this for a spin before we make that change we'd be so grateful. Thanks so much to Sheetal for persevering away on this feature. It's amazing work and so very appreciated."))}d.isMDXComponent=!0},69982:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"definitely-typed-the-movie",title:"Definitely Typed: The Movie",authors:"johnnyreilly",tags:["typescript","Definitely Typed"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/definitely-typed-the-movie",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2019-10-08-definitely-typed-the-movie/index.md",source:"@site/blog/2019-10-08-definitely-typed-the-movie/index.md",title:"Definitely Typed: The Movie",description:"I'd like to tell you a story. It's the tale of the ecosystem that grew up around a language: TypeScript. TypeScript is, for want of a better description, JavaScript after a trip to Saville Row. Essentially the same language, but a little more together, a little less wild west. JS with a decent haircut and a new suit. These days, the world seems to be written in TypeScript. And when you pause to consider just how young the language is, well, that's kind of amazing.",date:"2019-10-08T00:00:00.000Z",formattedDate:"October 8, 2019",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"Definitely Typed",permalink:"/tags/definitely-typed"}],readingTime:47.96,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"definitely-typed-the-movie",title:"Definitely Typed: The Movie",authors:"johnnyreilly",tags:["typescript","Definitely Typed"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"Teams notification webhooks",permalink:"/teams-notification-webhooks"},nextItem:{title:"Start Me Up: ts-loader meet .tsbuildinfo",permalink:"/start-me-up-ts-loader-meet-tsbuildinfo"}},p={image:n(22653).Z,authorsImageUrls:[void 0]},u=[{value:"Prolog(ue)",id:"prologue",level:2},{value:"The First Type Definition",id:"the-first-type-definition",level:2},{value:"Boris Yankov",id:"boris-yankov",level:2},{value:"Definitely Typed",id:"definitely-typed",level:2},{value:"How Do You Test a Type Definition?",id:"how-do-you-test-a-type-definition",level:2},{value:"Independence",id:"independence",level:2},{value:"Basarat Ali Syed",id:"basarat-ali-syed",level:2},{value:"John Reilly",id:"john-reilly",level:2},{value:"Policy time",id:"policy-time",level:2},{value:"Masahiro Wakame",id:"masahiro-wakame",level:2},{value:"Blake Embrey",id:"blake-embrey",level:2},{value:"Typings",id:"typings",level:2},{value:"The TypeScript Team",id:"the-typescript-team",level:2},{value:"A Plan Emerges",id:"a-plan-emerges",level:2},{value:"TypeScript 2.0 / Definitely Typed 2.0",id:"typescript-20--definitely-typed-20",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I'd like to tell you a story. It's the tale of the ecosystem that grew up around a language: TypeScript. TypeScript is, for want of a better description, JavaScript after a trip to Saville Row. Essentially the same language, but a little more together, a little less wild west. JS with a decent haircut and a new suit. These days, the world seems to be written in TypeScript. And when you pause to consider just how young the language is, well, that's kind of amazing."),(0,a.kt)("p",null,"Who could have predicted it would end up like this? When I was a boy I remember coming down the stairs in my childhood home. Shuffling to the edge of each step on my bottom before thumping down to the one beneath. When I look at those same stairs now they're so small. I barely notice the difference between one step and the next. But back then each step seemed giant, each one so far apart. Definitely Typed had any number of steps in its evolution. They all seemed so significant then; whereas now they're just a memory. Let's remember together\u2026"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"A title image that reads &quot;Definitely Typed: The Movie&quot;",src:n(22653).Z,width:"700",height:"300"})),(0,a.kt)("h2",o({},{id:"prologue"}),"Prolog(ue)"),(0,a.kt)("p",null,'When it was first unveiled to the world by Anders Hejlsberg back in 2012, there was nothing to suggest TypeScript was going to be seismic in its effects. The language brought two important things to the table. First of all, the ability to write JavaScript with optional static typing (imagine this as "belts and braces" for JS). The second feature was interoperability with existing JavaScript.'),(0,a.kt)("p",null,"The reason TypeScript has the traction that it does, is a consequence of the latter feature. The JavaScript ecosystem was already a roaring success by 2012. Many useful libraries were out there, authored in vanilla JavaScript. jQuery, Backbone, Knockout were all going concerns. People were building things."),(0,a.kt)("p",null,'Wisely, having TypeScript able to work with existing JavaScript libraries was a goal of the language right from the off. This made sense; otherwise it would have been like unveiling Netflix to the world whilst saying "sorry you can\'t use a television set to watch this". Remember, JS was great as is - people wanted static typing so they could be more productive and so they could sleep better at night. ("Oh wait, did I write that unit test to check all the properties? Dammit, it\'s 3am!") If TypeScript had hove onto the scene requiring that everything was written ',(0,a.kt)("em",{parentName:"p"},"in")," TypeScript then I would not be writing this. It didn't."),(0,a.kt)("p",null,'Interoperability was made possible by the concept of "type definitions". Analogous to header files in C, these are TypeScript files with a ',(0,a.kt)("inlineCode",{parentName:"p"},".d.ts")," suffix that tell the compiler about an existing JavaScript library which is in scope. This means you can write TypeScript and use jQuery or ","[insert your favourite library name here]",". Even though they are not written in TypeScript."),(0,a.kt)("p",null,"At the time of the initial TypeScript announcement (v0.8.1) there was no concept of a repository of type definitions. I mean, there was every chance that TypeScript wasn't going to be a big deal. Success wasn't guaranteed. But it happened. You're reading this in a world where Definitely Typed is one of the most popular repos on GitHub and where type definitions from it are published out to npm for consumption by developers greedy for static types. A world where the TypeScript team has pretty much achieved its goal of \"types on every desk\"."),(0,a.kt)("p",null,"I want to tell you the story of the history of type definitions in the TypeScript world. I'm pretty well placed to do this since I've been involved since the early days. Others involved have been kind enough to give me their time and tell me their stories. There's likely to be errors and omissions, and that's on me. It's an amazing tale though; I'm fortunate to get to tell it."),(0,a.kt)("h2",o({},{id:"the-first-type-definition"}),"The First Type Definition"),(0,a.kt)("p",null,"I was hanging out for something like TypeScript. I'd been busily developing rich client applications in JS and, whilst I loved the language, I was dearly missing static typing. All the things broke all of the time and I wanted help. I wanted a compiler to take me by the hand and say \"hey John, you just did a silly thing. Don't do it John; you'll only be filled with regret...\". The TypeScript team wrote that compiler."),(0,a.kt)("p",null,"When TypeScript was announced, it was important that the world could see that interop with JS was a first class citizen. Accordingly, a jQuery type definition was demonstrated as well. At the time, jQuery was the number one JavaScript library downloaded on the internet. So naturally it was the obvious choice for a demo. The type definition was fairly rough and ready but it worked. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://channel9.msdn.com/posts/Anders-Hejlsberg-Introducing-TypeScript"}),"You can see Anders Hejlsberg showing off the jQuery definition 45 minutes into this presentation introducing TypeScript.")),(0,a.kt)("p",null,"Consumption was straightforward, if perhaps quirky. You took the ",(0,a.kt)("inlineCode",{parentName:"p"},"jquery.d.ts")," file, copied it into your project location. Back then, to let the compiler know that a JS library had come to the party you had to use a kind of comment pragma in the header of your TypeScript files. For example: ",(0,a.kt)("inlineCode",{parentName:"p"},'/// <reference path="jquery/jquery.d.ts" />'),". This let TypeScript know that the type definition living at that path was relevant for the current script and it should scope it in."),(0,a.kt)("p",null,"There was no discussion of \u201chow do we type the world\u201d? Even if they wanted to, the TypeScript team didn't really have the resources at that point to support this. They'd got as far as they had on the person power of four or five developers and some testers as well. There was a problem clearly waiting to be solved. As luck would have it, in Bulgaria a man named Boris Yankov had been watching the TypeScript announcement."),(0,a.kt)("h2",o({},{id:"boris-yankov"}),"Boris Yankov"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"photograph of Boris Yankov looking mean, moody and magnificent",src:n(25431).Z,width:"320",height:"320"})),(0,a.kt)("p",null,"Boris Yankov was a handsome thirty year old man, living in the historic Bulgarian city of Plovdiv. He was swarthy with dark hair; like Ben Affleck if had been hanging out in Eastern Europe for a couple of years."),(0,a.kt)("p",null,"Boris was a backend developer who'd found himself doing more and more frontend. More JavaScript. He was accustomed to C# on the backend with static typing a-gogo. From his point of view JS was brittle. It was super easy to break things and have no idea until runtime that you'd done so. It seemed so backward. He was ready for something TypeScript shaped."),(0,a.kt)("p",null,'"What people forget is how different it was back then. Microsoft made this announcement, but probably most of the people that were listening were part of the MS ecosystem. I certainly was. Remember, back then if you had a Mac or did Linux you probably didn\'t think about MS too much."'),(0,a.kt)("p",null,"Boris thought TypeScript just seemed like this interesting and weird thing that Microsoft were doing. He was excited by types; he was missing them and there was a real need there. A problem to solve. There were already people trying to address this. But the attempts so far had been underwhelming. Boris had encountered Google Closure Compiler; a tool built by Google which, amongst other things, introduces some measure of type safety to JavaScript by reading annotations in JSDoc format. Boris viewed GCC as a tentative first step. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/google/closure-compiler/wiki/Annotating-JavaScript-for-the-Closure-Compiler"}),"One which lead the way for things like TypeScript and Flow to follow.")),(0,a.kt)("p",null,"The other aspect of TypeScript that excited Boris was transpilation. Transpilation is the term coined to describe what TypeScript does when it comes to emit output. It takes in TypeScript and pumps out JavaScript. The question is: what sort of JavaScript? One choice the TypeScript team could have made was just having the compiler stripping out types from the codebase. If it worked that way then you'd get out the JavaScript equivalent of the TypeScript you wrote. You wrote a ",(0,a.kt)("inlineCode",{parentName:"p"},"class"),"? TypeScript emits a ",(0,a.kt)("inlineCode",{parentName:"p"},"class"),"; just; one shorn of types and interfaces."),(0,a.kt)("p",null,"The TypeScript team made a different choice. They wrote the compiler such that the user could write ES6 style TypeScript syntax and have the TypeScript compiler transpile that down to ES5 or even ES3 syntax. This made TypeScript a much more interesting proposition than it already was, for a couple of reasons."),(0,a.kt)("p",null,"ES6 had been in the works for some time at this point. The release was shaping up to be the biggest incremental change to JavaScript that had so far happened. Or that would ever happen. Prior to this, JavaScript had experienced no small amount of tension and disagreement as it sought to evolve and develop. These played out in the form of the abandoned fourth edition of the language. There were arguments, harsh words, public disagreements and finally a failure to ship ECMAScript 4. In an alternate universe this was the end of the road for JavaScript. However, in our universe JavaScript got another throw of the dice."),(0,a.kt)("p",null,"It's telling that ES5 was for a long time known also as ES3.1; reflecting that it was initially planned to be the stepping stone between ES3 and ES4. In reality it ended up being the stepping stone between ES3 and ES6. As it turned out, it was a vital one too, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.m.wikipedia.org/wiki/ECMAScript"}),"it allowed the TC39 to recalibrate after a very public shelving of plans.")),(0,a.kt)("p",null,"The band was back together (albeit with a new rhythm section) and ES6 was going to be ",(0,a.kt)("em",{parentName:"p"},"massive"),". JavaScript was going to get new constructs such as ",(0,a.kt)("inlineCode",{parentName:"p"},"Map"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"Set"),", new scoping possibilities with ",(0,a.kt)("inlineCode",{parentName:"p"},"let")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"const"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"Promise"),"s which paved the way for new kinds of async programming, the contentious ",(0,a.kt)("inlineCode",{parentName:"p"},"class"),'es\u2026. And who can forget where they were when they first heard about "fat" arrow functions?'),(0,a.kt)("p",null,"People salivated at the idea of it all. Such new shiny toys! But how could we use them? Whilst all this new hotness was on the way, where could you actually run your new style code? Complete browser implementations of ES6 wouldn't start to materialise until 2018. Given the slowness of people to upgrade and the need to support the lowest common denominator of browser this could have meant that all the excitement was trapped in a never tomorrow situation."),(0,a.kt)("p",null,"Back to TypeScript. The team had a solution for this issue. In their wisdom, the TypeScript team allowed us to write ES6 TypeScript and the compiler could (with some limitations) transpile it down to ES3 JavaScript. The audacity of this was immense. The TypeScript team brought the future back to the past. What's more, they made it work in Internet Explorer 6. Now that's rock'n'roll. It's nothing short of miraculous!"),(0,a.kt)("p",null,"The significance of transpilation to TypeScript cannot be overstated."),(0,a.kt)("p",null,"You might be thinking to yourself, \"that's just Babel, right?\" Right. It's just that Babel didn't exist then. 6to5 was still an idea waiting for Sebastian McKenzie to think of. Even if you were kind of \"meh\" on types, the attraction of using a tool which allowed you to use new JavaScript constructs without breaking your customers was a significant draw. People may have come for types, but once they'd experienced the joy of a lexically bound ",(0,a.kt)("inlineCode",{parentName:"p"},"this")," in a fat arrow function they were ",(0,a.kt)("em",{parentName:"p"},"never")," going back."),(0,a.kt)("p",null,"Success has many parents. TypeScript is a successful project. One reason for this is that it's an excellent product that fills a definite need. Another reason is one that can't be banked upon; timing. TypeScript has enjoyed phenomenal timing. Appearing just when JavaScript was going off like a rocket and having the twin benefits of types and future JS today when nothing else offered anything close, that's perfect timing. It got people's curiosity. Now it got Boris's attention."),(0,a.kt)("h2",o({},{id:"definitely-typed"}),"Definitely Typed"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"The Definitely Typed logo",src:n(25236).Z,width:"140",height:"140"})),(0,a.kt)("p",null,"Boris had been feeling unproductive. He would build applications in JS and watch them unaccountably break as he made simple tweaks to them. He was constantly changing things, breaking them, fixing them and hoping he hadn't broken something else along the way. It was exhausting. He saw the promise in what TypeScript was offering and decided to give it a go."),(0,a.kt)("p",null,"It was great. He fired up Visual Studio and converted a ",(0,a.kt)("inlineCode",{parentName:"p"},".js")," file to end with the mystical TypeScript suffix of ",(0,a.kt)("inlineCode",{parentName:"p"},".ts"),". In front of his eyes, red squiggly lines started to appear here and there in his code. As he looked at the visual noise he could see this was TypeScript delivering on its promise. It was finding the bugs he hadn't spotted. These migrations were also addictive; the more information you could feed the compiler, the more problems it found. Boris felt it was time to start writing type definitions, whatever they were."),(0,a.kt)("p",null,"Boris quickly learned how to write a type definition and set to work. Most libraries weren't well documented and so he found himself reading the source code of libraries he used in order that he could write the definitions. At first, the definitions were just files dropped in his ASP.NET MVC projects that he copied around. That wasn't going to scale; there needed to be somewhere he could go to grab type definitions when he needed them. And so on October 5th 2012 he created a repository under his profile at GitHub called \"DefinitelyTyped\": ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped/commit/647369a322be470d84f8d226e297267a7d1a0796"}),"https://github.com/DefinitelyTyped/DefinitelyTyped/commit/647369a322be470d84f8d226e297267a7d1a0796")),(0,a.kt)("p",null,"Boris took his type definitions and put them into this repository. Were you ever curious what the first definition added was? Close your eyes and think... You might imagine it was the (then number one JavaScript library on the web) jQuery. In fact it was Modernizr. Then Underscore followed, and then jQuery. Take a look:"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped/commits?after=4a4cf23ff4301835a45bb138bbb62bf5f0759255+699&author=borisyankov"}),"https://github.com/DefinitelyTyped/DefinitelyTyped/commits?after=4a4cf23ff4301835a45bb138bbb62bf5f0759255+699&author=borisyankov")),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A screenshot of the initial commits to Definitely Typed on GitHub",src:n(4689).Z,width:"640",height:"191"})),(0,a.kt)("p",null,"It wasn't complicated; it was just a folder with subfolders underneath; each folder representing a project. One for jQuery, one for jQuery UI, one for Knockout.... You get the idea. It's not so different now."),(0,a.kt)("p",null,"Boris had laid simple but dependable foundations. Definitely Typed had been born."),(0,a.kt)("h2",o({},{id:"how-do-you-test-a-type-definition"}),"How Do You Test a Type Definition?"),(0,a.kt)("p",null,"Boris was careful too. Right from the first type definition he added tests alongside them. Now tests for a type definition were a conundrum. How do you write a test for interfaces that don't exist in the runtime environment? Code that is expunged as part of the compilation process. Well, the answer Boris came to was this: a compilation test."),(0,a.kt)("p",null,"Someone once said: compilation is the first unit test... But it's a doozy. They're right. The value you get from compilation, from a computer checking the assertions your code makes, is significant. Simply put, it takes a large amount of tests to get the same level of developer confidence. Computers are wonderful at attention to detail in a way that puts even the most anally retentive human being to shame."),(0,a.kt)("p",null,"So if Boris had written a definition called ",(0,a.kt)("inlineCode",{parentName:"p"},"mylib.d.ts"),", he'd write a file that exercises this type definition. A ",(0,a.kt)("inlineCode",{parentName:"p"},"mylib.tests.ts")," if you will. This file would contain code that exercises the type definition in the way that it should correctly be used. This is code that will never be executed in the way that tests normally are; a test program is never actually run. Rather these tests exist solely for compilation time. (In much the same way that TypeScript types only exist for compilation time.) Boris's plan was this: no compilation errors in ",(0,a.kt)("inlineCode",{parentName:"p"},"mylib.tests.ts")," represents passing tests. Compilation errors in ",(0,a.kt)("inlineCode",{parentName:"p"},"mylib.tests.ts")," represents failing tests. It was functional, brutal and also beautiful in it's simplicity."),(0,a.kt)("p",null,"So, imagine your definition looked like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"declare function turnANumberIntoAString(\n  numberToMakeStringOutOf: number\n): string;\n")),(0,a.kt)("p",null,"You might write a compilation test that looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const itIsAString: string = turnANumberIntoAString(42);\n")),(0,a.kt)("p",null,"This test ensures that you can use your function in the way you'd expect. It returns the types you'd desire (a ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," in this case) and it accepts the parameters you'd expect (a single ",(0,a.kt)("inlineCode",{parentName:"p"},"number")," for this example). If someone changed the definition in future, such that a different type was returned or a different set of parameters was required it would break the test. The test code wouldn't compile anymore. That's the nature of our \"test\". It's blunt but effective."),(0,a.kt)("p",null,"This is the very first test committed to Definitely Typed; a test for Modernizr."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped/blob/a976315cacbcfc151d5f57b25f4325dc7deca6f2/Tests/modernizr.ts"}),"https://github.com/DefinitelyTyped/DefinitelyTyped/blob/a976315cacbcfc151d5f57b25f4325dc7deca6f2/Tests/modernizr.ts")),(0,a.kt)("p",null,"This idea represents what tests look like throughout Definitely Typed today. They're now \"run\" as part of Continuous Integration and type definitions are tested in concert with one another to ensure that a change to one type definition doesn't break another. But there is nothing fundamentally different in place today to what Boris originally came up with."),(0,a.kt)("h2",o({},{id:"independence"}),"Independence"),(0,a.kt)("p",null,'Very quickly, Definitely Typed became a known project. People like Steve Fenton (author of the first book about TypeScript) were vocal supporters of the project. The TypeScript team talked up the project and were entirely supportive of its existence. In fact, at every given opportunity Anders Hejlsberg would sing its praises. For a while you could guarantee that any TypeScript talk by Anders would include a variant of "this guy called Boris started a project called Definitely Typed". The impression he gave was that he was kind of amazed, and thoroughly delighted, the project existed.'),(0,a.kt)("p",null,'The TypeScript team were completely uninvolved with Definitely Typed. That in itself is worth considering. The perception of Microsoft by developers generally in 2012 was at best, highly suspicious. "Embrace, extend, extinguish" - a strategy attributed to MS was very much a current perspective. This was born out in online comments and conversations at meetups. ',(0,a.kt)("a",o({parentName:"p"},{href:"https://news.ycombinator.com/item?id=4597716"}),"The Hacker News comments on the TypeScript release were a mixed bag.")," The reaction on social media was rather less generous. Certainly it was harsh enough to prompt Scott Hanselman to write something of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.hanselman.com/blog/WhyDoesTypeScriptHaveToBeTheAnswerToAnything.aspx"}),"a defence of TypeScripts right to exist"),"."),(0,a.kt)("p",null,"Given that TypeScript had arrived with the promise of transforming the JavaScript developer experience, the developer community was understandably cautious. Was Microsoft doing a good or ill? Could they be trusted? There were already signs that MS was changing. For example, it had been shipping open source libraries such as jQuery with ASP.Net MVC for some time. Microsoft was starting to engage with the world of open source software."),(0,a.kt)("p",null,"How Microsoft interacted with the (very open source driven) JS community was going to be key to the success (or not) of TypeScript. What happened with the establishment of Definitely Typed very much indicated TypeScripts direction of travel."),(0,a.kt)("p",null,"On day one of its existence, Boris took type definitions written by Microsoft and made them available via Definitely Typed. A ballsy move. It would have been completely possible for MS to object to this. They didn't."),(0,a.kt)("p",null,"People like Diullei Gomes started submitting pull requests to improve the existing definitions and add new ones. Diullei even wrote the first command line tooling which allowed people to install type definitions: TSD. Within a surprisingly short period, DT had become the default home of type definitions on the web. There were briefly alternative Definitely Typed styled collections of type definitions elsewhere on GitHub but they didn't last."),(0,a.kt)("p",null,"This all happened completely independently of the TypeScript team. Definitely Typed existing actually allowed TypeScript itself to prosper. It was worth persevering with this bleeding edge language because of the interoperability Definitely Typed was providing to the community. So the hands off attitude of MS was both surprising and encouraging. It showed trust of the community; something that hadn't hitherto been a commonly noted characteristic of MS."),(0,a.kt)("p",null,"Boris started adding contributors to Definitely Typed to help him with the work. Definitely Typed was no longer a one man band, it had taken an important step. It was built and maintained by an increasing number of creative and generous people. All motivated by a simple aim: the best developer experience when working with TypeScript and existing JS libraries."),(0,a.kt)("h2",o({},{id:"basarat-ali-syed"}),"Basarat Ali Syed"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A photograph of Basarat",src:n(98556).Z,width:"320",height:"320"})),(0,a.kt)("p",null,"Basarat Ali Syed was a 27 year old who had recently moved to Melbourne, Australia from Pakistan. You might know of him for a number of reasons, not least being the TypeScript equivalent of Jon Skeet. That, incidentally, is not a coincidence. Basarat had watched Jon Skeet's impressive work, being ",(0,a.kt)("em",{parentName:"p"},"the"),' gold standard in C# answers and thought "there\'s something worth emulating here".'),(0,a.kt)("p",null,'Bas was working for a startup who had a JS frontend. About six months before TypeScript was announced to the world he watched Anders Hejlsberg do a presentation on JavaScript which included Anders saying to the audience "don\'t you just wish you had type safety?" with a twinkle in his eye. TypeScript was of course well underway by this time; just not yet public. Bas remembered the comment and, when TypeScript was announced, he was ready. He made it his personal mission to be the goto person answering questions about TypeScript on Stack Overflow.'),(0,a.kt)("p",null,"In those early days of TypeScript, if you put a question about TypeScript onto Stack Overflow there was a very good chance that Bas would answer it. And Bas was more helpful than your typical SO answerer. Not only would he provide helpful commentary and useful guidance, he would often find him answering \"yeah, the problem isn't your code, it's the type definition. It needs improvement. In fact, I've raised a PR to fix it here\u2026\""),(0,a.kt)("p",null,"Boris saw the drip, drip of Basarat PRs turning into a flood. So, very quickly, he invited Basarat join Definitely Typed. Now Bas could not just suggest changes, he could ensure they were made. Step by step the quality of type definitions improved."),(0,a.kt)("p",null,"Basarat describes himself as a \"serial OSS contributor and mover on-er\". It's certainly true. As well as his Stack Overflow work, he's been someone involved in the early days of any number of open source projects. Not just Definitely Typed. Bas also worked on the TypeScript port of the JavaScript task runner; Grunt TS. He met up with Pete Hunt (he of React) at a Decompress conference and together they hacked together a POC webpack TypeScript loader. (That POC ultimately lead to James Brantly creating ts-loader which I maintain.) Bas wrote the atom-typescript plugin which offers first class support for TypeScript in Atom. Not content with that he went on to write a full blown editor of his own called alm-tools."),(0,a.kt)("p",null,"This is not an exhaustive list of his achievements and already I'm tired. Besides this he wrote the TypeScript Deep Dive book and the VS Code TypeScript God extension. And more."),(0,a.kt)("p",null,"Bas had the level of self knowledge required to realise that getting others involved was key to the success of open source projects. Particularly given that he knew he had a predilection to eventually move on, to work on other things. So Bas kept his eyes open and welcomed in new maintainers for projects he was working on. Bas' actions in particular were to be crucial. Bas grew the Definitely Typed team; he invited others in, he got people involved."),(0,a.kt)("p",null,"On December 28th 2013 Basarat decided that a regular contributor to Definitely Typed might be a potential team member. Bas opened up Twitter and sent a Direct Message to John Reilly."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A screenshot of direct message Basarat sent to John Reilly in Twitter",src:n(87399).Z,width:"640",height:"371"})),(0,a.kt)("h2",o({},{id:"john-reilly"}),"John Reilly"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A photograph of John Reilly",src:n(74999).Z,width:"320",height:"320"})),(0,a.kt)("p",null,"That's me. Or ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/johnny_reilly"}),"johnny_reilly on Twitter")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly"}),"johnnyreilly")," on GitHub (as John Papa and I have learned to our chagrin; GitHub don't support the \"","_","\" character in usernames). Relatively few people call me Johnny. I'm named that online because back when I applied for an email address, someone had already bagsied john","_",(0,a.kt)("a",o({parentName:"p"},{href:"mailto:reilly@popularemailhotness.com."}),"reilly@popularemailhotness.com.")," So rather than sully my handle with a number or a middle name I settled for johnny_reilly. I haven't looked back and have generally tried to keep that nom de plume wherever I lay my hat online."),(0,a.kt)("p",null,"In contrast to others I was a relatively late starter to TypeScript. I was intrigued right from the initial announcement, but held off from properly getting my hands dirty until generics was added to the language in 0.9. (This predisposition towards generics in a language perhaps explains why I didn't get too far with Golang.)"),(0,a.kt)("p",null,"At that point I was working in London for a private equity house. It was based in the historic and affluent area of St James. St James is an interesting part of London, caught midway between the Government, Buckingham Palace and the heart of the West End. It's old fashioned, dripping with money and physically delightful. It's the sort of place film crews dash towards when they're called upon to show old fashioned London in all its pomp. It rocks."),(0,a.kt)("p",null,'My team hated JavaScript. Absolutely loathed it. I was the solo voice saying "but it\'s really cool!" whilst they all but burned effigies of Brendan Eich in each code review. However, to my delight (and their abject horror) the project we were working on could only be implemented using JS. Essentially the house wanted an application offering rich interactivity which had to be a web app. So\u2026 JS. We were coding then with a combination of jQuery and Knockout JS. And, in large part due to the majority of the team being unfamiliar with JS, we were shipping bugs. The kind of bugs that could be caught by a compiler. By static typing. Not to put too fine a point on it; by TypeScript.'),(0,a.kt)("p",null,"So I proposed an experiment: \"Let's take one screen and develop it with TypeScript. Let's leave the rest of the app as is; JavaScript as usual. And then once we're done with that screen let's see how we feel about it. TypeScript might not be that great. But that's fine, if it isn't we'll take the generated JS, keep that and throw away the TypeScript. Deal?\""),(0,a.kt)("p",null,"The team were on board and, one sprint review later, we decided that all future JS functionality would be implemented with TypeScript. We were in!"),(0,a.kt)("p",null,"From day one of using TypeScript I was in love. I had the functionality of JavaScript, the future semantics of JavaScript and I was making less mistakes. Our team had become more productive. We were shipping faster and more reliably with fewer errors. People were noticing; our reputation as a team was improving, in part due to our usage of TypeScript. We had a jetpack."),(0,a.kt)("p",null,"However. I wasn't satisfied. As I tapped away at my keyboard I found type definitions to be\u2026 imperfect. And that niggled. Did it ever niggle. By then ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/staxmanade"}),"Jason Jarrett")," had wired up Definitely Typed packages to be published out to Nuget. Devs using ASP.NET MVC 4 (as I then was) were busily installing type definitions alongside AutoFac and other dependencies. Whilst most of those dependencies arrived like polished diamonds, finished products ready to be plugged into the project and start adding value. The type definitions by contrast felt very beta. And of course, they were. TypeScript was beta. The definitions reflected the newness of the language."),(0,a.kt)("p",null,"I could make it better."),(0,a.kt)("p",null,"I started submitting pull requests. The first problem I decided to solve was IntelliSense. I wanted IntelliSense for jQuery. If you went to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://api.jquery.com"}),"https://api.jquery.com")," there was rich documentation for every method jQuery exposed. I wanted to see that documentation inside Visual Studio as I coded. If I keyed in ",(0,a.kt)("inlineCode",{parentName:"p"},"$.appendTo(")," I wanted VS to be filled with the content from ",(0,a.kt)("a",o({parentName:"p"},{href:"https://api.jquery.com/appendTo/"}),"https://api.jquery.com/appendTo/")," . That was my mission. For each overload of the method I'd add something akin to this to the type definition file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"/**\n * Insert every element in the set of matched elements to the end of the target.\n *\n * @param value A selector, element, HTML string, array of elements, or jQuery\n *              object; the matched set of elements will be inserted at the end\n *              of the element(s) specified by this parameter.\n */\nappendTo(target: string): JQuery;\n")),(0,a.kt)("p",null,"It was a tedious task plugging it all in, but the pleasure I got from having rich IntelliSense in VS more than made up for it to me. Along the way I added and fixed sections of the jQuery API that hadn't been implemented, or had been implemented incorrectly. It got to a point where jQuery was a good example of what a type definition should look like. That remains the case to this day; surprisingly few type definitions enjoy the JSDoc richness of jQuery. ",(0,a.kt)("a",o({parentName:"p"},{href:"/typescript-jsdoc-and-intellisense"}),"I have tried to encourage more use of this with blog posts code reviews and the like, but it's never got the traction I'd hoped.")),(0,a.kt)("p",null,"I'm fairly relentless when I put my mind to something. I work very hard to make things come to pass. What this meant at one point was the Definitely Typed maintainers receiving multiple PRs a day. Which prompted Bas to wonder \"I wonder if he'd like to join us?\""),(0,a.kt)("p",null,"I happily accepted Bas' invitation and soon found myself reading this email:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"From: Bas"),(0,a.kt)("p",{parentName:"blockquote"},"Sent: 28 December 2013 11:47"),(0,a.kt)("p",{parentName:"blockquote"},"To: Boris Yankov; johnny","_",(0,a.kt)("a",o({parentName:"p"},{href:"mailto:reilly@hotmail.com"}),"reilly@hotmail.com"),"; Bas; vvakame; Bart van der Schoor; Diullei Gomes; steve fenton; Jason Jarret Subject: DefinitelyTyped team introduction"),(0,a.kt)("p",{parentName:"blockquote"},"Dear All,"),(0,a.kt)("p",{parentName:"blockquote"},"Meet John Reilly (github : ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly"}),"https://github.com/johnnyreilly")," , twitter : ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/johnny%5C_reilly"}),"https://twitter.com/johnny\\_reilly"),") who will be helping with Definitely Typed definitions."),(0,a.kt)("p",{parentName:"blockquote"},"Boris manages the project and he can add you as a collaborator."),(0,a.kt)("p",{parentName:"blockquote"},"Additional team member introductions:"),(0,a.kt)("p",{parentName:"blockquote"},"Admin : Boris Yankov"),(0,a.kt)("p",{parentName:"blockquote"},"TSD package manager : ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/tsd"}),"https://github.com/DefinitelyTyped/tsd")," : Diullei / Bart van der Schoor"),(0,a.kt)("p",{parentName:"blockquote"},"NUGET: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/NugetAutomation"}),"https://github.com/DefinitelyTyped/NugetAutomation")," : Json Jarret"),(0,a.kt)("p",{parentName:"blockquote"},"Passionate TypeScript users like yourself: Wakame, Myself and SteveFenton ."),(0,a.kt)("p",{parentName:"blockquote"},"Cheers, Bas (Basarat)")),(0,a.kt)("p",null,"Some of those names you'll recognise; some perhaps not. Jason Jarrett wrote the Nuget distribution mechanism for type definitions that ended up existing for far longer than anyone (least of all Jason) anticipated. Steve Fenton was largely a cheerleader for Definitely Typed in its early days. Diullei and Bart, amongst other things, worked on the initial command line tooling for DT: TSD."),(0,a.kt)("p",null,"After being powered up in Definitely Typed, my contributions only increased. Anything that I was using in my day to day work, I wanted to have an amazing TypeScript experience. I wanted the language to thrive and I was pretty sure I could help by trying to get users the best-in-class developer experience as they used JS libraries. I've always found good developer experience a strong motivation; the idea being, if someone loves their tools, they'll do great work. The end customer (of whatever they're building) gets a better product sooner. Great developer experience is a force multiplier for building software."),(0,a.kt)("h2",o({},{id:"policy-time"}),"Policy time"),(0,a.kt)("p",null,'TypeScript was now at version 0.9.1. Still very much beta. Back then every release was breaking. Breaking. Very much with a capital "B".'),(0,a.kt)("p",null,"TypeScript had, since the very early days, made a commitment to track the ECMAScript standard. All JavaScript is valid TypeScript. However, there was briefly a period where this might not have been so. One of the things people most remember from the initial release is that they could now write classes. These were already the standardised classes of ES6 but it almost wasn't to be. For a brief period there had been consideration of doing something subtly different. In fact Anders would describe the TypeScript team's journey towards embracing the standards as a tale tinged with regret. In doing so they'd had to say goodbye to a different implementation of classes which he'd preferred but which they'd ditched because they weren't standard."),(0,a.kt)("p",null,"Alongside differences like this there were other delineations. Types had different names in the past which, as time went by, were renamed to align with standards. ",(0,a.kt)("inlineCode",{parentName:"p"},"boolean")," was originally ",(0,a.kt)("inlineCode",{parentName:"p"},"bool")," for instance; likely a reflection of Anders involvement with C#."),(0,a.kt)("p",null,"These sorts of changes, alongside any number of others, meant that each release of TypeScript sometimes entirely broke the definitions in Definitely Typed. Most notable was the 0.9.1 -> 0.9.5 migration. This was both an exercise in serious pain endurance and also a testament to the already strong commitment to TypeScript that existed. The reason people were willing to put the effort in to keep these migrations going was because they believed it was worth it. They believed in TypeScript. This PR is testament to that: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped/pull/1385"}),"https://github.com/DefinitelyTyped/DefinitelyTyped/pull/1385")),(0,a.kt)("p",null,"A level of flux meant that for a long time Definitely Typed committed only to support the latest version of TypeScript and the latest version of packages therein. These days it's not so brutal, but then it had to be as a matter of necessity."),(0,a.kt)("p",null,'The compiler was changing too fast and there were too few people involved to allow for any realistic alternative. As is often the case in software development, it was "good enough". Any other choice would probably have increased the workload of maintainers to a point where the project would no longer be a going concern. It was a choice with downsides; trade-offs. But it was the choice that best served the future of Definitely Typed and TypeScript.'),(0,a.kt)("h2",o({},{id:"masahiro-wakame"}),"Masahiro Wakame"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A photograph of Masahiro Wakame",src:n(88396).Z,width:"320",height:"320"})),(0,a.kt)("p",null,"Time passed. Autumn turned into winter, winter into spring. TypeScript reached 1.0. It wasn't beta anymore. As each release came, the changes in the compiler became more gradual. This was a blessing for the Definitely Typed team. The projects popularity was ticking up and up. New definitions were added each day. The trickle of issues and PRs had become a stream, then a river. A river very much ready to burst its banks."),(0,a.kt)("p",null,"It was taking its toll. Inside Definitely Typed roles were shifting. Boris was starting to step back from day to day reviewing of PRs. New members were joining the project, like Igor Oleinikov. But the pace was insatiable."),(0,a.kt)("p",null,"Some people left the project entirely, burned out by the never ending issues and PRs. Basarat started contributing less, beginning to turn his attention to one of his many sidejams. Fortunately, it turned out that before Basarat stepped back, he had done a very fine thing. In Tokyo, Japan was a 28 year old developer named Masahiro Wakame."),(0,a.kt)("p",null,"Mas was using JS to build the web applications he worked on. But ECMAScript 5 wasn't hitting the mark for him. For a time Masahiro used CoffeeScript (Jeremy Ashkenas Ruby style JS alternative). He liked it, but, as he put it: \"I was shooting my foot everyday\". Looking out for that elusive solution he landed on Dart. It looked amazing. But it wasn't ECMAScript. Masahiro worried he'd be locked in. He'd built some libraries and a testing framework using Dart. But he didn't feel he could suggest that his company adopted it; it was too different and only he knew it. He was left with the \"what if I go under a bus?\" problem. If he left the company, his colleagues would find it hard to move away from using Dart. This made him very hesitant. He didn't feel he could justify the choice."),(0,a.kt)("p",null,'Then Masahiro heard about TypeScript. Like Goldilocks and the three bears, this third language sounded just right. He loved the type safety. It also had a compelling proposition: the transpiled JS that TypeScript generated was human readable and idiomatic. Generating idiomatic JS as opposed to some kind of strange byte code was a goal of the language from the early days, as Anders Hejlsberg would repeatedly explain. This generation of "real JS" made test driving TypeScript a low risk proposition. One that appealed to the likes of Masahiro. No lock-in. You decide TypeScript isn\'t for you? Fine. Take the generated JS files and shake the TypeScript dust off your sandals. Masahiro consequently went all in on TypeScript. This was his bet. And he was going to cover his bet by trying to make the ecosystem even stronger.'),(0,a.kt)("p",null,'Masahiro started out trying to improve the testing framework in DT; sending in pull requests. Before too long, Basarat messaged him to say "do you wanna become a committer?" ',(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped/pull/1358"}),"Masahiro became a committer.")),(0,a.kt)("p",null,"It turned out that MH had a special qualities that DT was going to sorely need: he was willing and able to review PR after PR, day after day. His stamina was incredible."),(0,a.kt)("p",null,'Whilst it may not have been obvious from the outside, by now Definitely Typed was a slightly troubled project. The speed at which issues and PRs landed was relentless. Anyone who had once set GitHub to "watching" for Definitely Typed soon unsubscribed. It was becoming unmanageable. And whilst almost everyone else in the project was in the process of burning out / moving on / stepping back and similar, Masahiro kept going. He kept showing up. He kept reviewing. He kept merging. At his peek he was spending 2 hours a day, every day, glued to his screen in Tokyo and reviewing PRs for GitHub. The pulse of Definitely Typed may have slowed. But Masahiro kept the heart beating.'),(0,a.kt)("p",null,"As Masahiro kept the lights on, in a hotel room in Buenos Aires an Australian named Blake Embrey was making plans..."),(0,a.kt)("h2",o({},{id:"blake-embrey"}),"Blake Embrey"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A photograph of Blake Embrey",src:n(97121).Z,width:"320",height:"320"})),(0,a.kt)("p",null,"Blake was a 21 year old Australian. He was a nomadic developer, travelling around the world and working remotely. He travelled from country to country armed with a suitcase and his trusty MacBook in search of WiFi. He found himself dialing into standups from caf\xe9s in Vietnam at 1am to provide Jira updates, coding from airports as he criss-crossed the globe. It was an unusual life."),(0,a.kt)("p",null,"A friend showed Blake TypeScript somewhere around the TypeScript 1.2 era. He was interested. He was mostly working on backend NodeJS at the time. He could see the potential that TypeScript had to help him. Around the TypeScript 1.5 era Blake started to take a really good look at what was possible. From his vantage point, there was good and there was also bad. And he thought he could help."),(0,a.kt)("p",null,"As a module author and developer, he loved TypeScript. It allowed him to write, publish and consume 100% type-safe JavaScript. Features like autocompletion, type validation and ES6 features became part of his typical workflow. It was so good!"),(0,a.kt)("p",null,"However, one step in this development lifecycle was broken to his mind. The problem was module shaped. Yeah, modules. Wade into the controversy!"),(0,a.kt)("p",null,"Thanks again to Basarat, Blake soon became a DT contributor. Of all the contributors to Definitely Typed, Blake was the first one who was looking hard at the module problem. This was because whilst he wanted TypeScript to solve the same problems as everyone else, he wanted to solve them in a world of package dependencies. He wanted to solve for Node."),(0,a.kt)("p",null,"Now it's worth taking a moment to draw a comparison between web development then, and web development now. Because it's changed. The phrase \"web development fatigue\" exists with good reason. Web development in 2014 as compared to web development in 2019 is a very different proposition. Historically, JavaScript has not had a good story around modularisation. The language meandered forwards without ever gaining an official approach to modularisation until ES6. So for twenty years, if you wanted to write a large JS application you had to think hard about how to solve this problem. And even when modules were nailed down it was longer still until module loading was standardised."),(0,a.kt)("p",null,"But that didn't stop us. JavaScript apps were still being built on the frontend and the backend. On the frontend an approach to modularisation emerged called the Asynchronous Module Definition. It had some adoption but in the main that wasn't how people rolled. The frontend was generally a sea of global variables. People would write programs that depended upon global variables and worked hard to make sure that they didn\u2019t collide. Everything did this. Everything. Underscore? It was a global variable called ",(0,a.kt)("inlineCode",{parentName:"p"},"_"),". jQuery? It was two global variables: ",(0,a.kt)("inlineCode",{parentName:"p"},"$")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"jQuery"),". That's just what people did. I'm a person. I did that. If you were there you probably did too."),(0,a.kt)("p",null,"On the server side, in Node JS land, a different standard had emerged: CommonJS. Unlike AMD, CommonJS was simply how the Node JS community worked. Everything was a CommonJS module. Alongside Node, npm was growing and growing. Exposing Node developers to a rich ecosystem of modules or packages that they could drop into their apps with merely a tap tap tap of ",(0,a.kt)("inlineCode",{parentName:"p"},"npm install super-cool-package")," and then ",(0,a.kt)("inlineCode",{parentName:"p"},"var scp = require('super-cool-package')"),"."),(0,a.kt)("p",null,"And therein, as the Bard would have it, lay the rub. You see, in the frontend it was simpler. Uglier but simpler. By and large, the global variables were fine. They weren't beautiful but they were functional. It may have impaired the development of frontend apps, but it certainly didn't stop it."),(0,a.kt)("p",null,"And since a design goal of TypeScript was to meet JavaScript developers where they were and try and make their lives better, the initial focus of Definitely Typed was necessarily types that existed in the global namespace. So ",(0,a.kt)("inlineCode",{parentName:"p"},"jquery.d.ts")," would declare global ",(0,a.kt)("inlineCode",{parentName:"p"},"$")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"jQuery")," variables and underneath them all the jQuery methods and variables that were implemented. Alongside jQuery, maybe an application would have jQuery UI which would extend the ",(0,a.kt)("inlineCode",{parentName:"p"},"$")," variable and add extra functionality. In addition maybe there'd be a couple of jQuery plugins in play too. (It's worth saying that jQuery was the crack cocaine of web development back in the day. People just couldn't get enough.)"),(0,a.kt)("p",null,"TypeScript catered for this world by allowing type definitions to extend interfaces created by other definition files. The focus of most of the Definitely Typed contributors up to this point was frontend and hence DT was an ocean of global type definitions."),(0,a.kt)("p",null,"Of course, this is not what the frontend world looks like these days. The frontend now is all about npm thanks to tools like Browserify, webpack, Rollup and the like. Client and server side development is mighty similar these days. Or at least, it's swimming in more of the same waters. There's a good TypeScript story to tell about this as well. But there wasn't always. Back to Blake."),(0,a.kt)("p",null,"Blake had published a bunch of modules on npm. But no one had ever been able to consume the type definitions from them. Why was that? Well, without delving into great detail it comes down to type definitions of a package generally conflicting with type definitions that a user installs themselves."),(0,a.kt)("p",null,'This essentially came down to how TSD worked and what Definitely Typed contained. TSD was a pretty simple tool; by and large it worked by copying files from Definitely Typed into a users project. The files copied would contain type definitions which contained global types. So even though you cared solely about external modules, because of Definitely Typed you found yourself installing globals alongside which lead to conflicts between different type definitions. Different type definitions punching it out whilst the TypeScript compiler stood in between ineffectually shouting "leave it alone mate - it\'s not worth it!"'),(0,a.kt)("p",null,"How could we have a world where external modules and global were treated distinctly? Blake had ideas\u2026 Plan one was to rewrite TSD to support external modules; the type of modules that were standard in Node land. After working hard on that for some time, Blake came to conclusion that solving global variables alongside external modules was a hard problem. A very hard problem. And perhaps that just running with external modules, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/tsd/issues/150"}),"a new start if you will, represented the best way forwards"),"."),(0,a.kt)("h2",o({},{id:"typings"}),"Typings"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A screenshot of the Typings project",src:n(58991).Z,width:"320",height:"320"})),(0,a.kt)("p",null,"Blake made ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/typings/typings"}),"typings"),". Typings was a number of things; it was a new command line tool to replace TSD, it was a new approach to distributing type definitions and it was a registry. But Typings was a registry which pointed out to the web. Typings installation was entirely decentralized and the typings themselves could be downloaded from almost anywhere - GitHub, NPM, Bower and even over HTTP or the filesystem. Those type definitions could be external modules or globals."),(0,a.kt)("p",null,"It was radical. From centralisation to decentralisation. As Blake described it:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"This decentralization solves the biggest pain point I see with maintaining DefinitelyTyped. How does an author of one typings package maintain their file in DefinitelyTyped when they get notifications on thousands of others? How do you make sure typings maintain quality when you have 1000s to review? The solution in typings is you don\u2019t, the community does. If typings are incorrect, I can just write and install my own from wherever I want, something that TSD doesn\u2019t really allow. There\u2019s no merge or review process you need to wait for (300+ open pull requests!)."),(0,a.kt)("p",{parentName:"blockquote"},"However, decentralization comes with the cost of discoverability. To solve this, a registry exists that maintains locations of where the best typing can currently be installed from, for any version. If there\u2019s a newer typing, patches, or the old typing author has somehow disappeared, you can replace the entry with your own so people will be directed to your typings from now on.")),(0,a.kt)("p",null,"The world started to use Typings as the default CLI for type definitions. ",(0,a.kt)("inlineCode",{parentName:"p"},"typings.json")," files started appearing in people's repos. Typings allowed consumption of types both from the Typings registry and from Definitely Typed and so there was an easy on ramp for people to start using Typings."),(0,a.kt)("p",null,"Little by little, people started consuming type definitions that came from the typings registry rather than from Definitely Typed. Typings began to thrive whilst DT continued to choke. The community was beginning to diverge."),(0,a.kt)("h2",o({},{id:"the-typescript-team"}),"The TypeScript Team"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A photograph of the TypeScript team",src:n(22361).Z,width:"640",height:"327"})),(0,a.kt)("p",null,"Over in Seattle, the TypeScript team was thinking hard about the type definition ecosystem. About Definitely Typed and Typings. And about tooling and distribution."),(0,a.kt)("p",null,"At this point, there wasn't a dedicated registry for type definitions. There was GitHub. By and large, all type definitions lived in GitHub. Since GitHub is a git based source control provider it was possible for it to be used as a makeshift registry. So that's exactly what Definitely Typed and Typings were doing; piggy backing on GitHub and MacGyvering \"infrastructure\". It worked."),(0,a.kt)("p",null,"There wasn't a great versioning story. Definitely Typed just didn't do versioning. The latest and greatest was supported. Nothing else. The Typings approach was more nuanced. It did have an approach for versioning. It supported it by dint of allowing a version number in the registry to point to a specific git hash in a repo. It was an elegant and smart approach. Blake Embrey was one sharp cat."),(0,a.kt)("p",null,"Innovative though it was, the decentralised Typings approach presented potential security risks as it pointed out to the web making auditing harder. Alongside this, The TypeScript team was pondering ways they could reduce friction for developers that wanted to use TypeScript."),(0,a.kt)("p",null,"By now, the JavaScript ecosystem had started to coalesce around npm as the registry du jour. Bower and jspm were starting to fade in popularity. NuGet (the .NET package manager) was no longer being encouraged as a place to house JS. npm was standard. TypeScript users found themselves using npm to install jQuery and reaching for tsd or Typings to install the associated type definitions. That's two commands. With two package managers. Each with subtly different syntax. And then perhaps you had to fiddle with the ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," to get the compiler looking in the right places. It worked. But it didn't feel \u2026. idiomatic. It didn't feel like TypeScript was meeting their users where they were."),(0,a.kt)("p",null,"The likes of Daniel Rosenwasser, Mohamed Hegazy and Ryan Cavanaugh found themselves pondering the problem. Alongside this, they were thinking more about what a first class module support experience in TypeScript would look like, motivated in part by the critical mass around npm, which was entirely module / package based."),(0,a.kt)("p",null,"That wasn\u2019t the only thing on their minds; there was also the testing story. Definitely Typed had a straightforward testing story due to being a real mega-repo. Everything lived together and could be tested together. Thanks to the hard work of the Definitely Typed team this was already in place; every PR spun up Travis and tested all the type definitions individually and in concert with one another. Typings didn\u2019t have this. What\u2019s more, it would be hard to build. The decentralised nature of Typings meant that you\u2019d need to build infrastructure to crawl the Typings registry, download the type definitions and then perform the tests. It was non-trivial and unlikely to be speedy."),(0,a.kt)("p",null,"There was one more factor in play. The TypeScript team were aware that for the longest time they'd been working on the language. But they'd become distant from one of the most significant aspects of how the language was used. They weren\u2019t well enough informed about the rough edges in the type definition space. They weren\u2019t feeling their users pain. They needed to address this and really there was only one thing to do... It was time for the TypeScript team to start eating their own dogfood."),(0,a.kt)("h2",o({},{id:"a-plan-emerges"}),"A Plan Emerges"),(0,a.kt)("p",null,"The TypeScript team reached out to Blake Embrey and started to talk about ways forward. They started collaborating over Slack."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A screenshot of the collaboration on Slack",src:n(54670).Z,width:"314",height:"320"})),(0,a.kt)("p",null,"The TypeScript team had also been in contact with the Definitely Typed team. They were, at this point, aware that Definitely Typed was being kept going mainly due to the hard graft of Masahiro Wakame. As Daniel observed \u201cvvakame was a champ\u201d."),(0,a.kt)("p",null,"At this point I have to stick my own hand up and confess to thinking that Definitely Typed was not long for this world. Steve Ognibene (another DT member) and others were all feeling similarly. It seemed inevitable."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A photograph of Steve Ognibe",src:n(14448).Z,width:"640",height:"542"})),(0,a.kt)("p",null,"The TypeScript team were about to change that. After talking, thinking, thinking and talking they put together a plan. It was going to change TypeScript and change Definitely Typed. It was also going to effectively end Typings."),(0,a.kt)("p",null,"It\u2019s worth saying at this point that the TypeScript team didn\u2019t enter into this lightly. They were hugely impressed by Typings. It was, to quote Daniel Rosenwasser, \u201can impressive piece of work\u201d. It also had the most amazing command line experience. Everyone on the team felt that it was an incredible endeavour and had their proverbial hats off to Blake Embrey. But Definitely Typed had critical mass and, whilst it had known problems, they were problems that could be likely solved (or ameliorated) through automation. The Typings approach was very innovative, but it presented other issues which seemed harder to solve. The TypeScript team made a bet. They placed their money on Definitely Typed."),(0,a.kt)("p",null,"To remove friction in the type acquisition space they decided to change the compiler. It would now look out for a special scoped namespace on npm named @types. Type definitions from Definitely Typed would be published out to @types. They would land as type definition packages that matched the non @types package. This meant that TypeScript was now sharing the same infrastructure as the rest of the JS ecosystem: npm. And consequently, installation of a package like jQuery in a TypeScript workflow now looked like this: ",(0,a.kt)("inlineCode",{parentName:"p"},"npm install jquery @types/jquery"),". One command, one tool, one registry."),(0,a.kt)("p",null,"They published their plans here: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/TypeScript/issues/9184"}),"https://github.com/Microsoft/TypeScript/issues/9184")),(0,a.kt)("p",null,"There was more. The TypeScript team had really enjoyed knowing that this open source project which ran completely independently from the TypeScript team existed. And whilst they were focused directly on the language that was reasonable. But with the changes that were being planned, TypeScript was about to start explicitly depending upon Definitely Typed. It had been unofficially true up until that point. But now it was different; TypeScript were going to automate publishing Definitely Typed packages to the special @types scope in npm which the TypeScript compiler gave preference to. TypeScript and Definitely Typed were going from dating to being engaged."),(0,a.kt)("p",null,"It was time for the TypeScript team to get involved."),(0,a.kt)("p",null,"The team committed to doing weekly rotations of a TypeScript team member working on Definitely Typed. Reviewing PRs, merging them and, crucially, helping with automation and testing."),(0,a.kt)("p",null,"TypeScript was now part of Definitely Typed. Definitely Typed was part of TypeScript."),(0,a.kt)("h2",o({},{id:"typescript-20--definitely-typed-20"}),"TypeScript 2.0 / Definitely Typed 2.0"),(0,a.kt)("p",null,"Blake was immensely disappointed. He'd put his heart and soul into Typings. It was a massive amount of work and he'd not only started a project, he'd started a community that he felt responsible for."),(0,a.kt)("p",null,"Although that work had arguably kickstarted the discussion of what the future of type acquisition in TypeScript should look like, Typings wouldn't be coming along for the ride. It was a burner rocket, carrying the good ship TypeScript into outer orbit, dropping back to Earth once it's job was done."),(0,a.kt)("p",null,"Very much, Blake had in mind all the people that had contributed to Typings. That all their work was going to be abandoned. He felt a sense of responsibility. It was both frustrating and heartbreaking."),(0,a.kt)("p",null,"When TypeScript 2.0 shipped, in the release announcement was the following statement: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://devblogs.microsoft.com/typescript/announcing-typescript-2-0/"}),"https://devblogs.microsoft.com/typescript/announcing-typescript-2-0/")),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"We\u2019d like to thank Blake Embrey for his work on Typings and helping us bring this solution forward.")),(0,a.kt)("p",null,'Blake really appreciated the recognition. In years to come Blake would come to feel that the decisions made were the right ones. That they lead to TypeScripts continued success and served the community well. But he has regrets. He says now "I am disappointed we didn\'t get to integrate the two philosophies for managing types. It hurt Typings registry contributors without a story in place, I didn\u2019t want to let down and alienate potential contributors of type definitions."'),(0,a.kt)("p",null,"A young Australian man had helped change the direction of TypeScript. It was time for him to take a well earned rest."),(0,a.kt)("p",null,"In the meantime, the TypeScript team was starting to get stuck into the work of giving Definitely Typed a make-over."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the rota for Definitely Typed work for the TypeScript team",src:n(39334).Z,width:"691",height:"1260"})),(0,a.kt)("p",null,"At this point, Definitely Typed had more than 500 open pull requests. Most of which had been open for a very long time. The most urgent and pressing problem was getting that down. The TypeScript team committed to, in perpetuity, a weekly rotation where one team member would review PRs. This would, in future, mean that PRs were handled in a timely fashion and that the number of open PRs was generally kept beneath 100."),(0,a.kt)("p",null,"Alongside this, changes were being made to the TypeScript compiler. In large part these related to enabling automatic type acquisition through the @types scope. To make that work, the TypeScript team realised pretty quickly that many of the type definitions would not work as is. Ryan wrote up this report:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Ryan Cavanagh&#39;s report on what to do in Definitely Typed",src:n(79713).Z,width:"640",height:"380"})),(0,a.kt)("p",null,"At this point in time there were around 1700 type definitions. Pretty much all of them required some massaging. Roughly speaking, with TS 2.0, the language was going to move from a name based type acquisition approach to a file based one. New features were added to TypeScript 2.0 such as the ",(0,a.kt)("inlineCode",{parentName:"p"},"export as namespace")," syntax to support a type definition supporting both being used in modules (where there are ",(0,a.kt)("inlineCode",{parentName:"p"},"import")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"export"),"s) but also in script files (where there aren't)"),(0,a.kt)("p",null,"Ryan Cavanaugh put together scripts that migrated 1200 of the type definitions to TypeScript 2.0 syntax. The remaining 500 were delicately transitioned by hand by diligent TypeScript team members. It was a task of utter drudgery that still sparks flickers of PTSD in those who were involved. It was like being in the digital equivalent of a Dickensian workhouse."),(0,a.kt)("p",null,"This was one of the reasons why going with the centralised approach of Definitely Typed instead of the decentralised one of Typings was necessary. Because the TypeScript team were involved in DT they could help make things happen. They could do the hard work. In a decentralised world that wouldn't be possible; everything would constantly be held up, waiting."),(0,a.kt)("p",null,'It took a long time to get the types 2.0 branch to a point where CI went green. All this time, merges we\'re taking place between the master branch and the future one. It was hard, unglamorous work. As Ryan put it, "I partied hard when CI went green for the first time on types 2.0."'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of @types going green",src:n(76473).Z,width:"640",height:"193"})),(0,a.kt)("p",null,"The first and most obvious addition was the automation of TypeScript definitions being published out to npm."),(0,a.kt)("p",null,'Next came a solution for the "notification flood" issue. It was no longer feasible for a user to have Definitely Typed set up as "watching" in GitHub. That way lead an unstoppable deluge of information about issues and pull requests. The result of that was that users were generally unaware of changes / issues and so on. People, as much as they wanted to be, were becoming disconnected from the type definitions they were interested in in DT.'),(0,a.kt)("p",null,"The solution for this problem was, as with so many problems, a bot. It would send notifications to the users who had historically worked on a type definition when someone sent a PR. This was hugely useful. It made it possible for people to become effective stewards of the type definitions they knew about. It meant people could effectively remain involved with DT; giving them targeted information. It was the solution to a communications problem."),(0,a.kt)("p",null,"As Ryan Cavanaugh put it when he looked back upon TypeScripts story, he had this to say: \u201cDefinitely Typed is the best thing that could exist from our perspective\u201d."),(0,a.kt)("p",null,"He was speaking from the perspective of a TypeScript team member. He could as well be speaking for the developer world at large. Definitely Typed is an organic monster of open source goodness; bringing types to the world thanks to nearly 10,000 contributors. Each person of which has donated at least an hour or their time for the greater good. Far more than that in many cases. It\u2019s incredible. I\u2019m glad I get to be part of it. I never would have guessed it would have turned out like this."))}d.isMDXComponent=!0},45952:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"teams-notification-webhooks",title:"Teams notification webhooks",authors:"johnnyreilly",tags:["Microsoft Teams","webhook"],image:"./teams-notification.gif",hide_table_of_contents:!1},s=void 0,l={permalink:"/teams-notification-webhooks",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2019-12-18-teams-notification-webhooks/index.md",source:"@site/blog/2019-12-18-teams-notification-webhooks/index.md",title:"Teams notification webhooks",description:"Teams notifications are mighty useful. You can send them using Markdown via a webhook.",date:"2019-12-18T00:00:00.000Z",formattedDate:"December 18, 2019",tags:[{label:"Microsoft Teams",permalink:"/tags/microsoft-teams"},{label:"webhook",permalink:"/tags/webhook"}],readingTime:3.195,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"teams-notification-webhooks",title:"Teams notification webhooks",authors:"johnnyreilly",tags:["Microsoft Teams","webhook"],image:"./teams-notification.gif",hide_table_of_contents:!1},prevItem:{title:"EF Core 3.1 breaks left join with no navigation property",permalink:"/ef-core-31-breaks-left-join-with-no-navigation-property"},nextItem:{title:"Definitely Typed: The Movie",permalink:"/definitely-typed-the-movie"}},p={image:n(65586).Z,authorsImageUrls:[void 0]},u=[{value:"Notifications via Webhooks",id:"notifications-via-webhooks",level:2},{value:"Markdown",id:"markdown",level:2},{value:"ASP.Net Core",id:"aspnet-core",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Teams notifications are mighty useful. You can send them using Markdown via a webhook."),(0,a.kt)("p",null,"This post will explain the following:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"How you can automate the sending of notifications using Teams."),(0,a.kt)("li",{parentName:"ol"},"How Teams supports Markdown in notifications."),(0,a.kt)("li",{parentName:"ol"},"How you can use ASP.Net Core to automate sending notifications.")),(0,a.kt)("h2",o({},{id:"notifications-via-webhooks"}),"Notifications via Webhooks"),(0,a.kt)("p",null,"Now, it's not obvious from Teams that there is a simple webhooks integration for Teams, but there is. It's tucked away under \"Connectors\". If you want to create a webhook of your own, find your team, your channel, click on the menu, then connectors and create a hook. Like so:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"animation of setting up a webhook connector in Teams",src:n(27544).Z,width:"791",height:"569"})),(0,a.kt)("p",null,"With the URL you've just obtained, you are now free to send notifications to that channel via a simple ",(0,a.kt)("inlineCode",{parentName:"p"},"curl"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),'curl -H "Content-Type: application/json" -d "{\\"text\\": \\"Hello World\\"}" https://outlook.office.com/webhook/big-long-guid1/IncomingWebhook/big-long-guid2\n')),(0,a.kt)("h2",o({},{id:"markdown"}),"Markdown"),(0,a.kt)("p",null,"Let's see if we can make this more interesting. It turns out that the the webhook can receive JSON as the body of the payload. And there's 3 properties we'd like our JSON to contain:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"title")," - this is optional and is the title of your notification if supplied."),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"textFormat")," - provide the value ",(0,a.kt)("inlineCode",{parentName:"li"},'"markdown"')," and then..."),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"text")," - provide your markdown notification content!")),(0,a.kt)("p",null,"So if we have a notification payload file called ",(0,a.kt)("inlineCode",{parentName:"p"},"down.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "title": "Your Notification Title",\n  "textFormat": "markdown",\n  "text": "*Wow*\\nThis is [markdown](https://en.wikipedia.org/wiki/Markdown)!\\n![do a little dance!](https://media.giphy.com/media/YJ5OlVLZ2QNl6/giphy.gif)\\n**Huzzah**!"\n}\n')),(0,a.kt)("p",null,"We can trigger it with this ",(0,a.kt)("inlineCode",{parentName:"p"},"curl"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),'curl -H "Content-Type: application/json" -d @down.json https://outlook.office.com/webhook/big-long-guid1/IncomingWebhook/big-long-guid2\n')),(0,a.kt)("p",null,"As you can see from the example above, you can use all the qualities of Markdown that you know and love. Text, bold text, italics, links and even images too. It's ",(0,a.kt)("em",{parentName:"p"},"great"),"!"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"animation of Teams notification",src:n(65586).Z,width:"721",height:"526"})),(0,a.kt)("h2",o({},{id:"aspnet-core"}),"ASP.Net Core"),(0,a.kt)("p",null,"Finally, I wanted to illustrate just how simple the WebHooks API makes plugging notifications into an existing app. In our case we're going to use ASP.Net Core, but really there's nothing particular about how we're going to do this."),(0,a.kt)("p",null,"Here's a class called ",(0,a.kt)("inlineCode",{parentName:"p"},"TeamsNotificationService"),". It exposes 2 methods:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"SendNotification")," which allows the consumer to just provide a ",(0,a.kt)("inlineCode",{parentName:"li"},"title")," and a ",(0,a.kt)("inlineCode",{parentName:"li"},"message")," - you could consume this from anywhere in your app and use it to publish the notification of your choice."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"SendExcitingNotification")," which actually uses ",(0,a.kt)("inlineCode",{parentName:"li"},"SendNotification")," and illustrates how you might provide an exciting notification to publish out.")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Collections.Generic;\nusing System.Net.Http;\nusing System.Net.Http.Headers;\nusing System.Threading.Tasks;\n\nnamespace My.Services {\n    public interface ITeamsNotificationService {\n        Task SendNotification(string title, string message);\n        Task SendExcitingNotification(Guid someAppId, string person);\n    }\n\n    public class TeamsNotificationService : ITeamsNotificationService {\n\n        // in Startup.ConfigureServices you\'re going to want to add this line:\n        // services.AddHttpClient(TeamsNotificationService.TEAMS_NOTIFIER_CLIENT);\n\n        public const string TEAMS_NOTIFIER_CLIENT = "TEAMS_NOTIFIER_CLIENT";\n\n        private readonly ILogger<TeamsNotificationService> logger;\n        private readonly IHttpClientFactory _clientFactory;\n\n\n        public TeamsNotificationService(\n            ILogger<TeamsNotificationService> logger,\n            IHttpClientFactory clientFactory\n        ) {\n            _logger = logger;\n            _clientFactory = clientFactory;\n        }\n\n        private HttpClient CreateClient() {\n            var client = _clientFactory.CreateClient(TEAMS_NOTIFIER);\n\n            client.DefaultRequestHeaders.Clear();\n            client.DefaultRequestHeaders.Accept.Clear();\n            client.DefaultRequestHeaders.Accept.Add(new MediaTypeWithQualityHeaderValue("application/json"));\n\n            return client;\n        }\n\n        public async Task SendNotification(string title, string message) {\n            try {\n                var client = CreateClient();\n\n                var messageContents = string.IsNullOrEmpty(title)\n                    ? new JsonContent(new { text = message, textFormat = "markdown" })\n                    : new JsonContent(new { title = title, text = message, textFormat = "markdown" });\n\n                var webhookUrl = "https://outlook.office.com/webhook/big-long-guid1/IncomingWebhook/big-long-guid2";\n                var response = await client.PostAsync(webhookUrl, messageContents);\n\n                _logger.LogInformation("Sent {title} notification to Teams using {url}; received this response: {responseStatusCode}", title, url, response.StatusCode);\n            }\n            catch (Exception exc) {\n                _logger.LogError(exc, $"Failed to send {title} notification to Teams");\n            }\n        }\n\n        public async Task SendExcitingNotification(Guid someAppId, string person) {\n            var celebration = GetCelebration();\n            await SendNotification(\n                title: "Incredible Thing Alert!",\n                message: $@"**{person}** has done something incredible! &#x1F44B;\n\n![celebration time!]({celebration})\n\n[Go see for yourself](https://my.app/some-page/{someAppId})"\n            );\n        }\n\n        string GetCelebration() => GetRandomItem(_celebrations);\n        string GetRandomItem(string[] arrayOfStrings) => arrayOfStrings[new Random().Next(0, arrayOfStrings.Length)];\n\n        string[] _celebrations = new string[] {\n            "https://media.giphy.com/media/KYElw07kzDspaBOwf9/giphy.gif",\n            "https://media.giphy.com/media/GStLeae4F7VIs/giphy.gif",\n            "https://media.giphy.com/media/NbXTwsoD7hvag/giphy.gif",\n            "https://media.giphy.com/media/d86kftzaeizO8/giphy.gif",\n            "https://media.giphy.com/media/YJ5OlVLZ2QNl6/giphy.gif",\n            "https://media.giphy.com/media/kyLYXonQYYfwYDIeZl/giphy.gif",\n            "https://media.giphy.com/media/KYElw07kzDspaBOwf9/giphy.gif",\n            "https://media.giphy.com/media/6nuiJjOOQBBn2/giphy.gif",\n            "https://media.giphy.com/media/hZj44bR9FVI3K/giphy.gif",\n            "https://media.giphy.com/media/31lPv5L3aIvTi/giphy.gif"\n        };\n    }\n}\n')),(0,a.kt)("p",null,"It's as simple as that \ud83d\ude04"))}d.isMDXComponent=!0},54596:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"ef-core-31-breaks-left-join-with-no-navigation-property",title:"EF Core 3.1 breaks left join with no navigation property",authors:"johnnyreilly",tags:["Entity Framework"],hide_table_of_contents:!1},s=void 0,l={permalink:"/ef-core-31-breaks-left-join-with-no-navigation-property",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-01-02-ef-core-31-breaks-left-join-with-no-navigation-property/index.md",source:"@site/blog/2020-01-02-ef-core-31-breaks-left-join-with-no-navigation-property/index.md",title:"EF Core 3.1 breaks left join with no navigation property",description:"Just recently my team took on the challenge of upgrading our codebase from .NET Core 2.2 to .NET Core 3.1. Along the way we encountered a quirky issue which caused us much befuddlement. Should you be befuddled too, then maybe this can help you.",date:"2020-01-02T00:00:00.000Z",formattedDate:"January 2, 2020",tags:[{label:"Entity Framework",permalink:"/tags/entity-framework"}],readingTime:2.38,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"ef-core-31-breaks-left-join-with-no-navigation-property",title:"EF Core 3.1 breaks left join with no navigation property",authors:"johnnyreilly",tags:["Entity Framework"],hide_table_of_contents:!1},prevItem:{title:"LICENSE to kill your PWA",permalink:"/license-to-kill-your-pwa"},nextItem:{title:"Teams notification webhooks",permalink:"/teams-notification-webhooks"}},p={authorsImageUrls:[void 0]},u=[{value:"Join me!",id:"join-me",level:2},{value:"Navigation properties to the rescue!",id:"navigation-properties-to-the-rescue",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Just recently my team took on the challenge of upgrading our codebase from .NET Core 2.2 to .NET Core 3.1. Along the way we encountered a quirky issue which caused us much befuddlement. Should you be befuddled too, then maybe this can help you."),(0,a.kt)("p",null,"Whilst running our app, we started encountering an error with an Entity Framework Query that looked like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"var stuffWeCareAbout = await context.Things\n    .Include(thing => thing.ThisIsFine)\n    .Include(thing => thing.Problematic)\n    .Where(thing => thing.CreatedOn > startFromThisTime && thing.CreatedOn < endAtThisTime)\n    .OrderByDescending(thing => thing.CreatedOn)\n    .ToArrayAsync();\n")),(0,a.kt)("h2",o({},{id:"join-me"}),"Join me!"),(0,a.kt)("p",null,"As EF Core tried to join from the ",(0,a.kt)("inlineCode",{parentName:"p"},"Things")," table to the ",(0,a.kt)("inlineCode",{parentName:"p"},"Problematic")," table (some obfuscation in table names here), that which worked in .NET Core 2.2 was ",(0,a.kt)("em",{parentName:"p"},"not")," working in .NET Core 3.1. Digging into the issue, we discovered EF Core was generating an invalid ",(0,a.kt)("inlineCode",{parentName:"p"},"LEFT JOIN"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-sql"}),"fail: Microsoft.EntityFrameworkCore.Database.Command[20102]\n      Failed executing DbCommand (18ms) [Parameters=[@__startFromThisTime_0='?' (DbType = DateTime2), @__endAtThisTime_1='?' (DbType = DateTime2)], CommandType='Text', CommandTimeout='30']\n      SELECT [o].[ThingId], [o].[AnonymousId], [o].[CreatedOn],  [o].[Status], [o].[UpdatedOn], [o0].[Id], [o0].[ThingId], [o0].[Name], [o1].[ThingId], [o1].[Status], [o1].[CreatedOn], [o1].[ThingThingId], [o1].[SentOn]\n      FROM [Things] AS [o]\n      LEFT JOIN [ThisIsFines] AS [o0] ON [o].[ThingId] = [o0].[ThingId]\n      LEFT JOIN [Problematic] AS [o1] ON [o].[ThingId] = [o1].[ThingThingId]\n      WHERE ([o].[CreatedOn] @__startFromThisTime_0) AND ([o].[CreatedOn] < @__endAtThisTime_1)\n      ORDER BY [o].[CreatedOn] DESC, [o].[ThingId], [o1].[ThingId], [o1].[Status]\nMicrosoft.EntityFrameworkCore.Database.Command: Error: Failed executing DbCommand (18ms) [Parameters=[@__startFromThisTime_0='?' (DbType = DateTime2), @__endAtThisTime_1='?' (DbType = DateTime2)], CommandType='Text', CommandTimeout='30']\nSELECT [o].[ThingId], [o].[AnonymousId], [o].[CreatedOn], [o].[Status], [o].[UpdatedOn], [o0].[Id], [o0].[ThingId], [o0].[Name], [o1].[ThingId], [o1].[Status], [o1].[CreatedOn], [o1].[ThingThingId], [o1].[SentOn]\nFROM [Things] AS [o]\nLEFT JOIN [ThisIsFines] AS [o0] ON [o].[ThingId] = [o0].[ThingId]\nLEFT JOIN [Problematic] AS [o1] ON [o].[ThingId] = [o1].[ThingThingId]\nWHERE ([o].[CreatedOn] @__startFromThisTime_0) AND ([o].[CreatedOn] < @__endAtThisTime_1)\nORDER BY [o].[CreatedOn] DESC, [o].[ThingId], [o1].[ThingId], [o1].[Status]\n")),(0,a.kt)("p",null,"Do you see it? Probably not; it took us a while too... The issue lay here:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-sql"}),"LEFT JOIN [Problematic] AS [o1] ON [o].[ThingId] = [o1].[ThingThingId]\n")),(0,a.kt)("p",null,"This should actually have been:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-sql"}),"LEFT JOIN [Problematic] AS [o1] ON [o].[ThingId] = [o1].[ThingId]\n")),(0,a.kt)("p",null,"For some reason EF Core was looking for ",(0,a.kt)("inlineCode",{parentName:"p"},"ThingThingId")," where it should have looked for ",(0,a.kt)("inlineCode",{parentName:"p"},"ThingId"),". But why?"),(0,a.kt)("h2",o({},{id:"navigation-properties-to-the-rescue"}),"Navigation properties to the rescue!"),(0,a.kt)("p",null,"This was the ",(0,a.kt)("inlineCode",{parentName:"p"},"Problematic")," class:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.ComponentModel.DataAnnotations;\nusing System.ComponentModel.DataAnnotations.Schema;\n\nnamespace Treasury.Data.Entities\n{\n    public class Problematic\n    {\n        [ForeignKey("Thing")]\n        [Required]\n        public Guid ThingId { get; set; }\n        [Required]\n        public DateTime CreatedOn { get; set; }\n        public DateTime SentOn { get; set; }\n    }\n}\n')),(0,a.kt)("p",null,"If you look closely you'll see it has a ",(0,a.kt)("inlineCode",{parentName:"p"},"ForeignKey")," but ",(0,a.kt)("em",{parentName:"p"},"no")," accompanying Navigation property. So let's add one:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.ComponentModel.DataAnnotations;\nusing System.ComponentModel.DataAnnotations.Schema;\n\nnamespace Our.App\n{\n    public class Problematic\n    {\n        [ForeignKey("Thing")]\n        [Required]\n        public Guid ThingId { get; set; }\n        [Required]\n        public DateTime CreatedOn { get; set; }\n        public DateTime SentOn { get; set; }\n\n        /* THIS NAVIGATION PROPERTY IS WHAT WE NEEDED!!! */\n        public virtual Thing Thing { get; set; }\n    }\n}\n')),(0,a.kt)("p",null,"With this in place our app starts generating the SQL we need."))}d.isMDXComponent=!0},68956:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"license-to-kill-your-pwa",title:"LICENSE to kill your PWA",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},s=void 0,l={permalink:"/license-to-kill-your-pwa",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-01-21-license-to-kill-your-pwa/index.md",source:"@site/blog/2020-01-21-license-to-kill-your-pwa/index.md",title:"LICENSE to kill your PWA",description:"Update: 26/01/2020 - LICENSE to kill revoked!",date:"2020-01-21T00:00:00.000Z",formattedDate:"January 21, 2020",tags:[],readingTime:3.81,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"license-to-kill-your-pwa",title:"LICENSE to kill your PWA",authors:"johnnyreilly",tags:[],hide_table_of_contents:!1},prevItem:{title:"From create-react-app to PWA",permalink:"/from-create-react-app-to-pwa"},nextItem:{title:"EF Core 3.1 breaks left join with no navigation property",permalink:"/ef-core-31-breaks-left-join-with-no-navigation-property"}},p={authorsImageUrls:[void 0]},u=[{value:"Update: 26/01/2020 - LICENSE to kill revoked!",id:"update-26012020---license-to-kill-revoked",level:2},{value:"The tragedy",id:"the-tragedy",level:2},{value:"The mystery",id:"the-mystery",level:2},{value:"The investigation",id:"the-investigation",level:2},{value:"The resolution",id:"the-resolution",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",o({},{id:"update-26012020---license-to-kill-revoked"}),"Update: 26/01/2020 - LICENSE to kill revoked!"),(0,a.kt)("p",null,"Following the original publication of this post I received this tweet suggesting we should change the behaviour of the underlying ",(0,a.kt)("inlineCode",{parentName:"p"},"terser-webpack-plugin"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Send a PR to change the name to .LICENSE.txt by default."),(0,a.kt)("p",{parentName:"blockquote"},"\u2014 Tobias Koppers (@wSokra) ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/wSokra/status/1220069497660411904?ref_src=twsrc%5Etfw"}),"January 22, 2020"))),(0,a.kt)("script",{async:"",src:"https://platform.twitter.com/widgets.js",charSet:"utf-8"}),(0,a.kt)("p",null,"That seemed like an excellent idea! I raised ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack-contrib/terser-webpack-plugin/pull/210"}),"this PR")," which changes the behaviour such that instead of ",(0,a.kt)("inlineCode",{parentName:"p"},".LICENSE")," files being produced, ",(0,a.kt)("inlineCode",{parentName:"p"},".LICENSE.txt")," files are pumped out instead. Crucially they are IIS (and other servers) friendly. The great news is that future users of webpack / create-react-app etc will not face this problem at all; result!"),(0,a.kt)("h2",o({},{id:"the-tragedy"}),"The tragedy"),(0,a.kt)("p",null,"Recently my beloved PWA died. I didn't realise it at first. It wasn't until a week or so after the tragedy that I realised he'd gone. In his place was the stale memory of service workers gone by. Last week's code; cached and repeatedly served up to a disappointed audience. Terrible news."),(0,a.kt)("p",null,"What had happened? What indeed. The problem was quirky and (now that I know the answer) I'm going to share it with you. Because it's entirely non-obvious."),(0,a.kt)("h2",o({},{id:"the-mystery"}),"The mystery"),(0,a.kt)("p",null,"Once I realised that I was repeatedly being served up an old version of my PWA, I got to wondering.... Why? What's happening? What's wrong? What did I do? I felt bad. I stared at the ceiling. I sighed and opened my Chrome devtools. With no small amount of sadness I went to the ",(0,a.kt)("inlineCode",{parentName:"p"},"Application")," tab, hit ",(0,a.kt)("inlineCode",{parentName:"p"},"Service Workers")," and then ",(0,a.kt)("inlineCode",{parentName:"p"},"Unregister"),"."),(0,a.kt)("p",null,"Then I hit refresh and took a look at console. I saw this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(4543).Z,width:"640",height:"32"})),(0,a.kt)("p",null,'What does this mean? Something about a "bad-precaching-response". And apparently this was happening whilst trying to load this resource: ',(0,a.kt)("inlineCode",{parentName:"p"},"/static/js/6.20102e99.chunk.js.LICENSE?__WB_REVISION__=e2fc36")),(0,a.kt)("p",null,"This ",(0,a.kt)("inlineCode",{parentName:"p"},"404")," was preventing pre-caching from executing successfully. This was what was killing my PWA. This was the perpetrator. How to fix this? Read on!"),(0,a.kt)("h2",o({},{id:"the-investigation"}),"The investigation"),(0,a.kt)("p",null,"Time to find out what's going on. I dropped that URL into my browser to see what would happen. ",(0,a.kt)("inlineCode",{parentName:"p"},"404")," city man:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(40204).Z,width:"400",height:"233"})),(0,a.kt)("p",null,"So, to disk. I took a look at what was actually on the server in that location. Sure enough, the file existed. When I opened it up I found this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"/**\n * A better abstraction over CSS.\n *\n * @copyright Oleg Isonen (Slobodskoi) / Isonen 2014-present\n * @website https://github.com/cssinjs/jss\n * @license MIT\n */\n\n/*\nobject-assign\n(c) Sindre Sorhus\n@license MIT\n*/\n\n/** @license React v16.12.0\n * react.production.min.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n/** @license React v16.12.0\n * react-dom.production.min.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n/** @license React v0.18.0\n * scheduler.production.min.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n/** @license React v16.12.0\n * react-is.production.min.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n")),(0,a.kt)("p",null,"What is this? Well, as the name of the file suggests, it's licenses. For some reason, my build was scraping the licenses from the head of some of my files and placing them in a separate ",(0,a.kt)("inlineCode",{parentName:"p"},"6.20102e99.chunk.js.LICENSE")," file. Doing some more digging I happened upon ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/create-react-app/issues/6441"}),"this discussion against the ",(0,a.kt)("inlineCode",{parentName:"a"},"create-react-app"))," project. It's worth saying, that my PWA was an ejected ",(0,a.kt)("inlineCode",{parentName:"p"},"create-react-app")," project."),(0,a.kt)("p",null,"It turned out the the issue was related to the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack-contrib/terser-webpack-plugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"terser-webpack-plugin")),". The default behaviour performs this kind of license file extraction. The app was being served by an IIS server and it wasn't configured to support the ",(0,a.kt)("inlineCode",{parentName:"p"},".LICENSE")," file type."),(0,a.kt)("h2",o({},{id:"the-resolution"}),"The resolution"),(0,a.kt)("p",null,"The simplest solution was simply this: wave goodbye to ",(0,a.kt)("inlineCode",{parentName:"p"},"LICENSE")," files. If you haven't ejected from your ",(0,a.kt)("inlineCode",{parentName:"p"},"create-react-app")," then this might be a problem. But since I had, I was able to make this tweak to the terser settings in the ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"new TerserPlugin({\n    /* TURN OFF LICENSE FILES - SEE https://github.com/facebook/create-react-app/issues/6441 */\n    extractComments: false,\n    /* TURN OFF LICENSE FILES - Tweak by John Reilly */\n    terserOptions: {\n        // ....\n")),(0,a.kt)("p",null,"And with this we say goodbye to our ",(0,a.kt)("inlineCode",{parentName:"p"},"404"),"s and hello to a resurrected PWA!"))}d.isMDXComponent=!0},40296:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"from-create-react-app-to-pwa",title:"From create-react-app to PWA",authors:"johnnyreilly",tags:["create-react-app","PWA"],hide_table_of_contents:!1},s=void 0,l={permalink:"/from-create-react-app-to-pwa",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-01-31-from-create-react-app-to-pwa/index.md",source:"@site/blog/2020-01-31-from-create-react-app-to-pwa/index.md",title:"From create-react-app to PWA",description:"Progressive Web Apps are a (terribly named) wonderful idea. You can build an app once using web technologies which serves all devices and form factors. It can be accessible over the web, but also surface on the home screen of your Android / iOS device. That app can work offline, have a splash screen when it launches and have notifications too.",date:"2020-01-31T00:00:00.000Z",formattedDate:"January 31, 2020",tags:[{label:"create-react-app",permalink:"/tags/create-react-app"},{label:"PWA",permalink:"/tags/pwa"}],readingTime:10.745,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"from-create-react-app-to-pwa",title:"From create-react-app to PWA",authors:"johnnyreilly",tags:["create-react-app","PWA"],hide_table_of_contents:!1},prevItem:{title:"Web Workers, comlink, TypeScript and React",permalink:"/web-workers-comlink-typescript-and-react"},nextItem:{title:"LICENSE to kill your PWA",permalink:"/license-to-kill-your-pwa"}},p={authorsImageUrls:[void 0]},u=[{value:"From console to web app",id:"from-console-to-web-app",level:2},{value:"From web app to PWA",id:"from-web-app-to-pwa",level:2},{value:"Icons and splash screens and A2HS, oh my!",id:"icons-and-splash-screens-and-a2hs-oh-my",level:2},{value:"Where are we?",id:"where-are-we",level:2},{value:"Code splitting",id:"code-splitting",level:2},{value:"Deploy your PWA",id:"deploy-your-pwa",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Progressive Web Apps are a (terribly named) wonderful idea. You can build an app ",(0,a.kt)("em",{parentName:"p"},"once")," using web technologies which serves all devices and form factors. It can be accessible over the web, but also surface on the home screen of your Android / iOS device. That app can work offline, have a splash screen when it launches and have notifications too."),(0,a.kt)("p",null,"PWAs can be a money saver for your business. The alternative, should you want an app experience for your users, is building the same application using three different technologies (one for web, one for Android and one for iOS). When you take this path it's hard to avoid a multiplication of cost and complexity. It often leads to dividing up the team as each works on a different stack. It's common to lose a certain amount of focus as a consequence. PWAs can help here; they are a compelling alternative, not just from a developers standpoint, but from a resourcing one too."),(0,a.kt)("p",null,"However, the downside of PWAs is that they are more complicated than normal web apps. Writing one from scratch is just less straightforward than a classic web app. There are easy onramps to building a PWA that help you fall into the pit of success. This post will highlight one of these. How you can travel from zero to a PWA of your very own using React and TypeScript."),(0,a.kt)("p",null,"This post presumes knowledge of:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"React"),(0,a.kt)("li",{parentName:"ul"},"TypeScript"),(0,a.kt)("li",{parentName:"ul"},"Node")),(0,a.kt)("h2",o({},{id:"from-console-to-web-app"}),"From console to web app"),(0,a.kt)("p",null,"To create our PWA we're going to use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://create-react-app.dev/"}),(0,a.kt)("inlineCode",{parentName:"a"},"create-react-app")),". This excellent project has long had inbuilt support for making PWAs. In recent months that support has matured to a very satisfactory level. To create ourselves a TypeScript React app using ",(0,a.kt)("inlineCode",{parentName:"p"},"create-react-app")," enter this ",(0,a.kt)("inlineCode",{parentName:"p"},"npx")," command at the console:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"npx create-react-app pwa-react-typescript --template typescript\n")),(0,a.kt)("p",null,"This builds you a react web app built with TypeScript; it can be tested locally with:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"cd pwa-react-typescript\nyarn start\n")),(0,a.kt)("h2",o({},{id:"from-web-app-to-pwa"}),"From web app to PWA"),(0,a.kt)("p",null,"From web app to PWA is incredibly simple; it\u2019s just a question of opting in to offline behaviour. If you open up the ",(0,a.kt)("inlineCode",{parentName:"p"},"index.tsx")," file in your newly created project you'll find this code:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"// If you want your app to work offline and load faster, you can change\n// unregister() to register() below. Note this comes with some pitfalls.\n// Learn more about service workers: https://bit.ly/CRA-PWA\nserviceWorker.unregister();\n")),(0,a.kt)("p",null,"As the hint suggests, swap ",(0,a.kt)("inlineCode",{parentName:"p"},"serviceWorker.unregister()")," for ",(0,a.kt)("inlineCode",{parentName:"p"},"serviceWorker.register()")," and you now have a PWA. Amazing! What does this mean? Well to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://create-react-app.dev/docs/making-a-progressive-web-app/#why-opt-in"}),"quote the docs"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"},"All static site assets are cached so that your page loads fast on subsequent visits, regardless of network connectivity (such as 2G or 3G). Updates are downloaded in the background."),(0,a.kt)("li",{parentName:"ul"},"Your app will work regardless of network state, even if offline. This means your users will be able to use your app at 10,000 feet and on the subway.")),(0,a.kt)("p",{parentName:"blockquote"},"... it will take care of generating a service worker file that will automatically precache all of your local assets and keep them up to date as you deploy updates. The service worker will use a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/web/fundamentals/instant-and-offline/offline-cookbook/#cache-falling-back-to-network"}),"cache-first strategy"),"for handling all requests for local assets, including ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/web/fundamentals/primers/service-workers/high-performance-loading#first_what_are_navigation_requests"}),"navigation requests")," for your HTML, ensuring that your web app is consistently fast, even on a slow or unreliable network.")),(0,a.kt)("p",null,"Under the bonnet, ",(0,a.kt)("inlineCode",{parentName:"p"},"create-react-app")," is achieving this through the use of technology called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/web/tools/workbox"}),'"Workbox"'),". Workbox describes itself as:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"a set of libraries and Node modules that make it easy to cache assets and take full advantage of features used to build ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/web/progressive-web-apps/"}),"Progressive Web Apps"),".")),(0,a.kt)("p",null,"The good folks of Google are aware that writing your own PWA can be tricky. There's much new behaviour to configure and be aware of; it's easy to make mistakes. Workbox is there to help ease the way forward by implementing default strategies for caching / offline behaviour which can be controlled through configuration."),(0,a.kt)("p",null,"A downside of the usage of ",(0,a.kt)("inlineCode",{parentName:"p"},"Workbox")," in ",(0,a.kt)("inlineCode",{parentName:"p"},"create-react-app")," is that (as with most things ",(0,a.kt)("inlineCode",{parentName:"p"},"create-react-app"),") there's little scope for configuration of your own if the defaults don't serve your purpose. This may change in the future, indeed ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/create-react-app/pull/5369"}),"there's an open PR that adds this support"),"."),(0,a.kt)("h2",o({},{id:"icons-and-splash-screens-and-a2hs-oh-my"}),"Icons and splash screens and A2HS, oh my!"),(0,a.kt)("p",null,"But it's not just an offline experience that makes this a PWA. Other important factors are:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},'That the app can be added to your home screen (A2HS AKA "installed").'),(0,a.kt)("li",{parentName:"ul"},"That the app has a name and an icon which can be customised."),(0,a.kt)("li",{parentName:"ul"},"That there's a splash screen displayed to the user as the app starts up.")),(0,a.kt)("p",null,'All of the above is "in the box" with ',(0,a.kt)("inlineCode",{parentName:"p"},"create-react-app"),". Let's start customizing these."),(0,a.kt)("p",null,"First of all, we'll give our app a name. Fire up ",(0,a.kt)("inlineCode",{parentName:"p"},"index.html")," and replace ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;title&gt;React App&lt;/title&gt;")," with ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;title&gt;My PWA&lt;/title&gt;"),". (Feel free to concoct a more imaginative name than the one I've suggested.) Next open up ",(0,a.kt)("inlineCode",{parentName:"p"},"manifest.json")," and replace:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"short_name": "React App",\n  "name": "Create React App Sample",\n')),(0,a.kt)("p",null,"with:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"short_name": "My PWA",\n  "name": "My PWA",\n')),(0,a.kt)("p",null,"Your app now has a name. The question you might be asking is: what is this ",(0,a.kt)("inlineCode",{parentName:"p"},"manifest.json")," file? Well to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/web/fundamentals/web-app-manifest"}),"quote the good folks of Google"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/Manifest"}),"web app manifest")," is a simple JSON file that tells the browser about your web application and how it should behave when 'installed' on the user's mobile device or desktop. Having a manifest is required by Chrome to show the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/web/fundamentals/app-install-banners/"}),"Add to Home Screen prompt"),"."),(0,a.kt)("p",{parentName:"blockquote"},"A typical manifest file includes information about the app name, icons it should use, the start_url it should start at when launched, and more.")),(0,a.kt)("p",null,"So the ",(0,a.kt)("inlineCode",{parentName:"p"},"manifest.json")," is essentially metadata about your app. Here's what it should look like right now:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "short_name": "My PWA",\n  "name": "My PWA",\n  "icons": [\n    {\n      "src": "favicon.ico",\n      "sizes": "64x64 32x32 24x24 16x16",\n      "type": "image/x-icon"\n    },\n    {\n      "src": "logo192.png",\n      "type": "image/png",\n      "sizes": "192x192"\n    },\n    {\n      "src": "logo512.png",\n      "type": "image/png",\n      "sizes": "512x512"\n    }\n  ],\n  "start_url": ".",\n  "display": "standalone",\n  "theme_color": "#000000",\n  "background_color": "#ffffff"\n}\n')),(0,a.kt)("p",null,"You can use the above properties (and others not yet configured) to control how your app behaves. For instance, if you want to replace icons your app uses then it's a simple matter of:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"placing new logo files in the ",(0,a.kt)("inlineCode",{parentName:"li"},"public")," folder"),(0,a.kt)("li",{parentName:"ul"},"updating references to them in the ",(0,a.kt)("inlineCode",{parentName:"li"},"manifest.json")),(0,a.kt)("li",{parentName:"ul"},"finally, for older Apple devices, updating the ",(0,a.kt)("inlineCode",{parentName:"li"},'&lt;link rel="apple-touch-icon" ... /&gt;')," in the ",(0,a.kt)("inlineCode",{parentName:"li"},"index.html"),".")),(0,a.kt)("h2",o({},{id:"where-are-we"}),"Where are we?"),(0,a.kt)("p",null,"So far, we have a basic PWA in place. It's installable. You can run it locally and develop it with ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn start"),". You can build it for deployment with ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn build"),"."),(0,a.kt)("p",null,"What this isn't, is recognisably a web app. In the sense that it doesn't have support for different pages / URLs. We're typically going to want to break up our application this way. Let's do that now. We're going to use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/ReactTraining/react-router"}),(0,a.kt)("inlineCode",{parentName:"a"},"react-router")),"; the de facto routing solution for React. To add it to our project (and the required type definitions for TypeScript) we use:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"yarn add react-router-dom @types/react-router-dom\n")),(0,a.kt)("p",null,"Now let's split up our app into a couple of pages. We'll replace the existing ",(0,a.kt)("inlineCode",{parentName:"p"},"App.tsx")," with this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"import React from 'react';\nimport { BrowserRouter as Router, Switch, Route, Link } from 'react-router-dom';\nimport About from './About';\nimport Home from './Home';\n\nconst App: React.FC = () => (\n  <Router>\n    <nav>\n      <ul>\n        <li>\n          <Link to=\"/\">Home</Link>\n        </li>\n        <li>\n          <Link to=\"/about\">About</Link>\n        </li>\n      </ul>\n    </nav>\n    <Switch>\n      <Route path=\"/about\">\n        <About />\n      </Route>\n      <Route path=\"/\">\n        <Home />\n      </Route>\n    </Switch>\n  </Router>\n);\n\nexport default App;\n")),(0,a.kt)("p",null,"This will be our root page. It has the responsiblity of using ",(0,a.kt)("inlineCode",{parentName:"p"},"react-router")," to render the pages we want to serve, and also to provide the links that allow users to navigate to those pages. In making our changes we'll have broken our test (which checked for a link we've now deleted), so we'll fix it like so:"),(0,a.kt)("p",null,"Replace the ",(0,a.kt)("inlineCode",{parentName:"p"},"App.test.tsx")," with this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"import React from 'react';\nimport { render } from '@testing-library/react';\nimport App from './App';\n\ntest('renders about link', () => {\n  const { getByText } = render(<App />);\n  const linkElement = getByText(/about/i);\n  expect(linkElement).toBeInTheDocument();\n});\n")),(0,a.kt)("p",null,"You'll have noticed that in our new ",(0,a.kt)("inlineCode",{parentName:"p"},"App.tsx")," we import two new components (or pages); ",(0,a.kt)("inlineCode",{parentName:"p"},"About")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"Home"),". Let's create those. First ",(0,a.kt)("inlineCode",{parentName:"p"},"About.tsx"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"import React from 'react';\n\nconst About: React.FC = () => <h1>This is a PWA</h1>;\n\nexport default About;\n")),(0,a.kt)("p",null,"Then ",(0,a.kt)("inlineCode",{parentName:"p"},"Home.tsx"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"import React from 'react';\n\nconst Home: React.FC = () => <h1>Welcome to your PWA!</h1>;\n\nexport default Home;\n")),(0,a.kt)("h2",o({},{id:"code-splitting"}),"Code splitting"),(0,a.kt)("p",null,"Now we've split up our app into multiple sections, we're going to split the code too. A good way to improve loading times for PWAs is to ensure that the code is not built into big files. At the moment our app builds a ",(0,a.kt)("inlineCode",{parentName:"p"},"single-file.js"),". If you run ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn build")," you'll see what this looks like:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"47.88 KB  build/static/js/2.89bc6648.chunk.js\n  784 B     build/static/js/runtime-main.9c116153.js\n  555 B     build/static/js/main.bc740179.chunk.js\n  269 B     build/static/css/main.5ecd60fb.chunk.css\n")),(0,a.kt)("p",null,"Notice the ",(0,a.kt)("inlineCode",{parentName:"p"},"build/static/js/main.bc740179.chunk.js")," file. This is our ",(0,a.kt)("inlineCode",{parentName:"p"},"single-file.js"),". It represents the compiled output of building the TypeScript files that make up our app. It will grow and grow as our app grows, eventually becoming problematic from a user loading speed perspective."),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"create-react-app")," is built upon webpack. There is excellent support for code splitting in webpack and hence ",(0,a.kt)("a",o({parentName:"p"},{href:"https://reactjs.org/docs/code-splitting.html#code-splitting"}),"create-react-app supports it by default"),". Let's apply it to our app. Again we're going to change ",(0,a.kt)("inlineCode",{parentName:"p"},"App.tsx"),"."),(0,a.kt)("p",null,"Where we previously had:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"import About from './About';\nimport Home from './Home';\n")),(0,a.kt)("p",null,"Let's replace with:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"const About = lazy(() => import('./About'));\nconst Home = lazy(() => import('./Home'));\n")),(0,a.kt)("p",null,"This is the syntax to lazily load components in React. You'll note that it internally uses the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/tc39/proposal-dynamic-import"}),"dynamic ",(0,a.kt)("inlineCode",{parentName:"a"},"import()")," syntax"),' which webpack uses as a "split point".'),(0,a.kt)("p",null,"Let's also give React something to render whilst it waits for the dynamic imports to be resolved. Just inside our ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;Router&gt;")," component we'll add a ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;Suspense&gt;")," component too:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"<Router>\n  <Suspense fallback={<div>Loading...</div>}>{/*...*/}</Suspense>\n</Router>\n")),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;Suspense&gt;")," component will render the ",(0,a.kt)("inlineCode",{parentName:"p"},"&lt;div&gt;Loading...&lt;/div&gt;")," whilst it waits for a routes code to be dynamically loaded. So our final ",(0,a.kt)("inlineCode",{parentName:"p"},"App.tsx")," component ends up looking like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"import React, { lazy, Suspense } from 'react';\nimport { BrowserRouter as Router, Switch, Route, Link } from 'react-router-dom';\nconst About = lazy(() => import('./About'));\nconst Home = lazy(() => import('./Home'));\n\nconst App: React.FC = () => (\n  <Router>\n    <Suspense fallback={<div>Loading...</div>}>\n      <nav>\n        <ul>\n          <li>\n            <Link to=\"/\">Home</Link>\n          </li>\n          <li>\n            <Link to=\"/about\">About</Link>\n          </li>\n        </ul>\n      </nav>\n      <Switch>\n        <Route path=\"/about\">\n          <About />\n        </Route>\n        <Route path=\"/\">\n          <Home />\n        </Route>\n      </Switch>\n    </Suspense>\n  </Router>\n);\n\nexport default App;\n")),(0,a.kt)("p",null,"This is now a code split application. How can we tell? If we run ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn build")," again we'll see something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"47.88 KB          build/static/js/2.89bc6648.chunk.js\n  1.18 KB (+428 B)  build/static/js/runtime-main.415ab5ea.js\n  596 B (+41 B)     build/static/js/main.e60948bb.chunk.js\n  269 B             build/static/css/main.5ecd60fb.chunk.css\n  233 B             build/static/js/4.0c85e1cb.chunk.js\n  228 B             build/static/js/3.eed49094.chunk.js\n")),(0,a.kt)("p",null,"Note that we now have multiple ",(0,a.kt)("inlineCode",{parentName:"p"},"*.chunk.js")," files. Our initial ",(0,a.kt)("inlineCode",{parentName:"p"},"main.*.chunk.js")," and then ",(0,a.kt)("inlineCode",{parentName:"p"},"3.*.chunk.js")," representing ",(0,a.kt)("inlineCode",{parentName:"p"},"Home.tsx")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"4.*.chunk.js")," representing ",(0,a.kt)("inlineCode",{parentName:"p"},"About.tsx"),"."),(0,a.kt)("p",null,"As we continue to build out our app from this point we'll have a great approach in place to ensure that users load files as they need to and that those files should not be too large. Great performance which will scale."),(0,a.kt)("h2",o({},{id:"deploy-your-pwa"}),"Deploy your PWA"),(0,a.kt)("p",null,"Now that we have our basic PWA in place, let's deploy it so the outside world can appreciate it. We're going to use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.netlify.com/"}),"Netlify")," for this."),(0,a.kt)("p",null,"The source code of our PWA lives on GitHub here: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/pwa-react-typescript"}),"https://github.com/johnnyreilly/pwa-react-typescript")),(0,a.kt)("p",null,"We're going to log into Netlify, click on the \"Create a new site\" option and select GitHub as the provider. We'll need to authorize Netlify to access our GitHub."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"screenshot of the Netlify auth flow",src:n(32750).Z,width:"1144",height:"1511"})),(0,a.kt)("p",null,'You may need to click the "Configure Netlify on GitHub" button to grant permissions for Netlify to access your repo like so:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Netlify permissions flow",src:n(54740).Z,width:"1167",height:"1577"})),(0,a.kt)("p",null,"Then you can select your repo from within Netlify. All of the default settings that Netlify provides should work for our use case:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Netlify deploy settings",src:n(57825).Z,width:"1361",height:"1377"})),(0,a.kt)("p",null,"Let's hit the magic \"Deploy site\" button! In a matter of minutes you'll find that Netlify has deployed your PWA."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Netlify deployed site",src:n(14900).Z,width:"1411",height:"471"})),(0,a.kt)("p",null,"If we browse to the URL provided by Netlify we'll be able to see the deployed PWA in action. (You also have the opportunity to set up a custom domain name that you would typically want outside of a simple demo such as this.) Importantly this will be served over HTTPS which will allow our Service Worker to operate."),(0,a.kt)("p",null,"Now that we know it's there, let's see how what we've built holds up according to the professionals. We're going to run the Google Chrome Developer Tools Audit against our PWA:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the PWA audit looking good",src:n(36003).Z,width:"3060",height:"601"})),(0,a.kt)("p",null,"That is a good start for our PWA!"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/from-create-react-app-to-pwa/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/from-create-react-app-to-pwa/"})),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/pwa-react-typescript"}),"The source code for this project can be found here.")))}d.isMDXComponent=!0},33038:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"web-workers-comlink-typescript-and-react",title:"Web Workers, comlink, TypeScript and React",authors:"johnnyreilly",tags:["typescript","React"],hide_table_of_contents:!1},s=void 0,l={permalink:"/web-workers-comlink-typescript-and-react",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-02-21-web-workers-comlink-typescript-and-react/index.md",source:"@site/blog/2020-02-21-web-workers-comlink-typescript-and-react/index.md",title:"Web Workers, comlink, TypeScript and React",description:"JavaScript is famously single threaded. However, if you're developing for the web, you may well know that this is not quite accurate. There are Web Workers:",date:"2020-02-21T00:00:00.000Z",formattedDate:"February 21, 2020",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"React",permalink:"/tags/react"}],readingTime:9.715,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"web-workers-comlink-typescript-and-react",title:"Web Workers, comlink, TypeScript and React",authors:"johnnyreilly",tags:["typescript","React"],hide_table_of_contents:!1},prevItem:{title:"Dual boot authentication with ASP.NET",permalink:"/dual-boot-authentication-with-aspnetcore"},nextItem:{title:"From create-react-app to PWA",permalink:"/from-create-react-app-to-pwa"}},p={authorsImageUrls:[void 0]},u=[{value:"A use case for a Web Worker",id:"a-use-case-for-a-web-worker",level:2},{value:"Hello <code>worker-plugin</code> and <code>comlink</code>",id:"hello-worker-plugin-and-comlink",level:2},{value:"Workerize our slow process",id:"workerize-our-slow-process",level:2},{value:"Using Web Workers in React",id:"using-web-workers-in-react",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"JavaScript is famously single threaded. However, if you're developing for the web, you may well know that this is not quite accurate. There are ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers"}),(0,a.kt)("inlineCode",{parentName:"a"},"Web Workers")),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"A worker is an object created using a constructor (e.g. ",(0,a.kt)("inlineCode",{parentName:"p"},"Worker()"),") that runs a named JavaScript file \u2014 this file contains the code that will run in the worker thread; workers run in another global context that is different from the current window.")),(0,a.kt)("p",null,"Given that there is a way to use other threads for background processing, why doesn't this happen all the time? Well there's a number of reasons; not the least of which is the ceremony involved in interacting with Web Workers. Consider the following example that illustrates moving a calculation into a worker:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"// main.js\nfunction add2NumbersUsingWebWorker() {\n  const myWorker = new Worker('worker.js');\n\n  myWorker.postMessage([42, 7]);\n  console.log('Message posted to worker');\n\n  myWorker.onmessage = function (e) {\n    console.log('Message received from worker', e.data);\n  };\n}\n\nadd2NumbersUsingWebWorker();\n\n// worker.js\nonmessage = function (e) {\n  console.log('Worker: Message received from main script');\n  const result = e.data[0] * e.data[1];\n  if (isNaN(result)) {\n    postMessage('Please write two numbers');\n  } else {\n    const workerResult = 'Result: ' + result;\n    console.log('Worker: Posting message back to main script');\n    postMessage(workerResult);\n  }\n};\n")),(0,a.kt)("p",null,(0,a.kt)("em",{parentName:"p"},"This is not simple.")," It's hard to understand what's happening. Also, this approach only supports a single method call. I'd much rather write something that looked more like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"// main.js\nfunction add2NumbersUsingWebWorker() {\n  const myWorker = new Worker('worker.js');\n\n  const total = myWorker.add2Numbers([42, 7]);\n  console.log('Message received from worker', total);\n}\n\nadd2NumbersUsingWebWorker();\n\n// worker.js\nexport function add2Numbers(firstNumber, secondNumber) {\n  const result = firstNumber + secondNumber;\n  return isNaN(result) ? 'Please write two numbers' : 'Result: ' + result;\n}\n")),(0,a.kt)("p",null,"There's a way to do this using a library made by Google called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/GoogleChromeLabs/comlink"}),"comlink"),". This post will demonstrate how we can use this. We'll use TypeScript and webpack. We'll also examine how to integrate this approach into a React app."),(0,a.kt)("h2",o({},{id:"a-use-case-for-a-web-worker"}),"A use case for a Web Worker"),(0,a.kt)("p",null,"Let's make ourselves a TypeScript web app. We're going to use ",(0,a.kt)("inlineCode",{parentName:"p"},"create-react-app")," for this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"npx create-react-app webworkers-comlink-typescript-react --template typescript\n")),(0,a.kt)("p",null,"Create a ",(0,a.kt)("inlineCode",{parentName:"p"},"takeALongTimeToDoSomething.ts")," file alongside ",(0,a.kt)("inlineCode",{parentName:"p"},"index.tsx"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export function takeALongTimeToDoSomething() {\n  console.log('Start our long running job...');\n  const seconds = 5;\n  const start = new Date().getTime();\n  const delay = seconds * 1000;\n\n  while (true) {\n    if (new Date().getTime() - start > delay) {\n      break;\n    }\n  }\n  console.log('Finished our long running job');\n}\n")),(0,a.kt)("p",null,"To ",(0,a.kt)("inlineCode",{parentName:"p"},"index.tsx")," add this code:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { takeALongTimeToDoSomething } from './takeALongTimeToDoSomething';\n\n// ...\n\nconsole.log('Do something');\ntakeALongTimeToDoSomething();\nconsole.log('Do another thing');\n")),(0,a.kt)("p",null,"When our application runs we see this behaviour:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(87544).Z,width:"640",height:"245"})),(0,a.kt)("p",null,"The app starts and logs ",(0,a.kt)("inlineCode",{parentName:"p"},"Do something")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"Start our long running job...")," to the console. It then blocks the UI until the ",(0,a.kt)("inlineCode",{parentName:"p"},"takeALongTimeToDoSomething")," function has completed running. During this time the screen is empty and unresponsive. This is a poor user experience."),(0,a.kt)("h2",o({},{id:"hello-worker-plugin-and-comlink"}),"Hello ",(0,a.kt)("inlineCode",{parentName:"h2"},"worker-plugin")," and ",(0,a.kt)("inlineCode",{parentName:"h2"},"comlink")),(0,a.kt)("p",null,"To start using comlink we're going to need to eject our ",(0,a.kt)("inlineCode",{parentName:"p"},"create-react-app")," application. The way ",(0,a.kt)("inlineCode",{parentName:"p"},"create-react-app")," works is by giving you a setup that handles a high percentage of the needs for a typical web app. When you encounter an unsupported use case, you can run the ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn eject")," command to get direct access to the configuration of your setup."),(0,a.kt)("p",null,"Web Workers are not that commonly used in day to day development at present. Consequently there isn't yet a \"plug'n'play\" solution for workers supported by ",(0,a.kt)("inlineCode",{parentName:"p"},"create-react-app"),". There's a number of potential ways to support this use case and you can track the various discussions happening against ",(0,a.kt)("inlineCode",{parentName:"p"},"create-react-app")," that covers this. For now, let's eject with:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"yarn eject\n")),(0,a.kt)("p",null,"Then let's install the packages we're going to be using:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/GoogleChromeLabs/worker-plugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"worker-plugin"))," ","-"," this webpack plugin automatically compiles modules loaded in Web Workers"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"comlink")," ","-"," this library provides the RPC-like experience that we want from our workers")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"yarn add comlink worker-plugin\n")),(0,a.kt)("p",null,"We now need to tweak our ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js")," to use the ",(0,a.kt)("inlineCode",{parentName:"p"},"worker-plugin"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const WorkerPlugin = require('worker-plugin');\n\n// ....\n\n    plugins: [\n      new WorkerPlugin(),\n\n// ....\n")),(0,a.kt)("p",null,"Do note that there's a number of ",(0,a.kt)("inlineCode",{parentName:"p"},"plugins")," statements in the ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js"),". You want the top level one; look out for the ",(0,a.kt)("inlineCode",{parentName:"p"},"new HtmlWebpackPlugin")," statement and place your ",(0,a.kt)("inlineCode",{parentName:"p"},"new WorkerPlugin(),")," before that."),(0,a.kt)("h2",o({},{id:"workerize-our-slow-process"}),"Workerize our slow process"),(0,a.kt)("p",null,"Now we're ready to take our long running process and move it into a worker. Inside the ",(0,a.kt)("inlineCode",{parentName:"p"},"src")," folder, create a new folder called ",(0,a.kt)("inlineCode",{parentName:"p"},"my-first-worker"),". Our worker is going to live in here. Into this folder we're going to add a ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'{\n  "compilerOptions": {\n    "strict": true,\n    "target": "esnext",\n    "module": "esnext",\n    "lib": [\n      "webworker",\n      "esnext"\n    ],\n    "moduleResolution": "node",\n    "noUnusedLocals": true,\n    "sourceMap": true,\n    "allowJs": false,\n    "baseUrl": "."\n  }\n}\n')),(0,a.kt)("p",null,"This file exists to tell TypeScript that this is a Web Worker. Do note the ",(0,a.kt)("inlineCode",{parentName:"p"},'"lib": [ "webworker"')," usage which does exactly that."),(0,a.kt)("p",null,"Alongside the ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," file, let's create an ",(0,a.kt)("inlineCode",{parentName:"p"},"index.ts")," file. This will be our worker:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { expose } from 'comlink';\nimport { takeALongTimeToDoSomething } from '../takeALongTimeToDoSomething';\n\nconst exports = {\n  takeALongTimeToDoSomething,\n};\nexport type MyFirstWorker = typeof exports;\n\nexpose(exports);\n")),(0,a.kt)("p",null,"There's a number of things happening in our small worker file. Let's go through this statement by statement:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { expose } from 'comlink';\n")),(0,a.kt)("p",null,"Here we're importing the ",(0,a.kt)("inlineCode",{parentName:"p"},"expose")," method from comlink. Comlink\u2019s goal is to make ",(0,a.kt)("em",{parentName:"p"},"expose"),"d values from one thread available in the other. The ",(0,a.kt)("inlineCode",{parentName:"p"},"expose")," method can be viewed as the comlink equivalent of ",(0,a.kt)("inlineCode",{parentName:"p"},"export"),". It is used to export the RPC style signature of our worker. We'll see it's use later."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { takeALongTimeToDoSomething } from '../takeALongTimeToDoSomething';\n")),(0,a.kt)("p",null,"Here we're going to import our ",(0,a.kt)("inlineCode",{parentName:"p"},"takeALongTimeToDoSomething")," function that we wrote previously, so we can use it in our worker."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const exports = {\n  takeALongTimeToDoSomething,\n};\n")),(0,a.kt)("p",null,"Here we're creating the public facing API that we're going to expose."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export type MyFirstWorker = typeof exports;\n")),(0,a.kt)("p",null,"We're going to want our worker to be strongly typed. This line creates a type called ",(0,a.kt)("inlineCode",{parentName:"p"},"MyFirstWorker")," which is derived from our ",(0,a.kt)("inlineCode",{parentName:"p"},"exports")," object literal."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"expose(exports);\n")),(0,a.kt)("p",null,"Finally we expose the ",(0,a.kt)("inlineCode",{parentName:"p"},"exports")," using comlink. We're done; that's our worker finished. Now let's consume it. Let's change our ",(0,a.kt)("inlineCode",{parentName:"p"},"index.tsx")," file to use it. Replace our import of ",(0,a.kt)("inlineCode",{parentName:"p"},"takeALongTimeToDoSomething"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { takeALongTimeToDoSomething } from './takeALongTimeToDoSomething';\n")),(0,a.kt)("p",null,"With an import of ",(0,a.kt)("inlineCode",{parentName:"p"},"wrap")," from comlink that creates a local ",(0,a.kt)("inlineCode",{parentName:"p"},"takeALongTimeToDoSomething")," function that wraps interacting with our worker:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { wrap } from 'comlink';\n\nfunction takeALongTimeToDoSomething() {\n  const worker = new Worker('./my-first-worker', {\n    name: 'my-first-worker',\n    type: 'module',\n  });\n  const workerApi = wrap<import('./my-first-worker').MyFirstWorker>(worker);\n  workerApi.takeALongTimeToDoSomething();\n}\n")),(0,a.kt)("p",null,"Now we're ready to demo our application using our function offloaded into a Web Worker. It now behaves like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(51026).Z,width:"640",height:"251"})),(0,a.kt)("p",null,"There's a number of exciting things to note here:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"The application is now non-blocking. Our long running function is now not preventing the UI from updating"),(0,a.kt)("li",{parentName:"ol"},"The functionality is lazily loaded via a ",(0,a.kt)("inlineCode",{parentName:"li"},"my-first-worker.chunk.worker.js")," that has been created by the ",(0,a.kt)("inlineCode",{parentName:"li"},"worker-plugin")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"comlink"),".")),(0,a.kt)("h2",o({},{id:"using-web-workers-in-react"}),"Using Web Workers in React"),(0,a.kt)("p",null,"The example we've showed so far demostrates how you could use Web Workers and why you might want to. However, it's a far cry from a real world use case. Let's take the next step and plug our Web Worker usage into our React application. What would that look like? Let's find out."),(0,a.kt)("p",null,"We'll return ",(0,a.kt)("inlineCode",{parentName:"p"},"index.tsx")," back to it's initial state. Then we'll make a simple adder function that takes some values and returns their total. To our ",(0,a.kt)("inlineCode",{parentName:"p"},"takeALongTimeToDoSomething.ts")," module let's add:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export function takeALongTimeToAddTwoNumbers(number1: number, number2: number) {\n  console.log('Start to add...');\n  const seconds = 5;\n  const start = new Date().getTime();\n  const delay = seconds * 1000;\n  while (true) {\n    if (new Date().getTime() - start > delay) {\n      break;\n    }\n  }\n  const total = number1 + number2;\n  console.log('Finished adding');\n  return total;\n}\n")),(0,a.kt)("p",null,"Let's start using our long running calculator in a React component. We'll update our ",(0,a.kt)("inlineCode",{parentName:"p"},"App.tsx")," to use this function and create a simple adder component:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"import React, { useState } from 'react';\nimport './App.css';\nimport { takeALongTimeToAddTwoNumbers } from './takeALongTimeToDoSomething';\n\nconst App: React.FC = () => {\n  const [number1, setNumber1] = useState(1);\n  const [number2, setNumber2] = useState(2);\n\n  const total = takeALongTimeToAddTwoNumbers(number1, number2);\n\n  return (\n    <div className=\"App\">\n      <h1>Web Workers in action!</h1>\n\n      <div>\n        <label>Number to add: </label>\n        <input\n          type=\"number\"\n          onChange={(e) => setNumber1(parseInt(e.target.value))}\n          value={number1}\n        />\n      </div>\n      <div>\n        <label>Number to add: </label>\n        <input\n          type=\"number\"\n          onChange={(e) => setNumber2(parseInt(e.target.value))}\n          value={number2}\n        />\n      </div>\n      <h2>Total: {total}</h2>\n    </div>\n  );\n};\n\nexport default App;\n")),(0,a.kt)("p",null,"When you try it out you'll notice that entering a single digit locks the UI for 5 seconds whilst it adds the numbers. From the moment the cursor stops blinking to the moment the screen updates the UI is non-responsive:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(77670).Z,width:"544",height:"248"})),(0,a.kt)("p",null,"So far, so classic. Let's Web Workerify this!"),(0,a.kt)("p",null,"We'll update our ",(0,a.kt)("inlineCode",{parentName:"p"},"my-first-worker/index.ts")," to import this new function:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { expose } from 'comlink';\nimport {\n  takeALongTimeToDoSomething,\n  takeALongTimeToAddTwoNumbers,\n} from '../takeALongTimeToDoSomething';\n\nconst exports = {\n  takeALongTimeToDoSomething,\n  takeALongTimeToAddTwoNumbers,\n};\nexport type MyFirstWorker = typeof exports;\n\nexpose(exports);\n")),(0,a.kt)("p",null,"Alongside our ",(0,a.kt)("inlineCode",{parentName:"p"},"App.tsx")," file let's create an ",(0,a.kt)("inlineCode",{parentName:"p"},"App.hooks.ts")," file."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { wrap, releaseProxy } from 'comlink';\nimport { useEffect, useState, useMemo } from 'react';\n\n/**\n * Our hook that performs the calculation on the worker\n */\nexport function useTakeALongTimeToAddTwoNumbers(\n  number1: number,\n  number2: number\n) {\n  // We'll want to expose a wrapping object so we know when a calculation is in progress\n  const [data, setData] = useState({\n    isCalculating: false,\n    total: undefined as number | undefined,\n  });\n\n  // acquire our worker\n  const { workerApi } = useWorker();\n\n  useEffect(() => {\n    // We're starting the calculation here\n    setData({ isCalculating: true, total: undefined });\n\n    workerApi\n      .takeALongTimeToAddTwoNumbers(number1, number2)\n      .then((total) => setData({ isCalculating: false, total })); // We receive the result here\n  }, [workerApi, setData, number1, number2]);\n\n  return data;\n}\n\nfunction useWorker() {\n  // memoise a worker so it can be reused; create one worker up front\n  // and then reuse it subsequently; no creating new workers each time\n  const workerApiAndCleanup = useMemo(() => makeWorkerApiAndCleanup(), []);\n\n  useEffect(() => {\n    const { cleanup } = workerApiAndCleanup;\n\n    // cleanup our worker when we're done with it\n    return () => {\n      cleanup();\n    };\n  }, [workerApiAndCleanup]);\n\n  return workerApiAndCleanup;\n}\n\n/**\n * Creates a worker, a cleanup function and returns it\n */\nfunction makeWorkerApiAndCleanup() {\n  // Here we create our worker and wrap it with comlink so we can interact with it\n  const worker = new Worker('./my-first-worker', {\n    name: 'my-first-worker',\n    type: 'module',\n  });\n  const workerApi = wrap<import('./my-first-worker').MyFirstWorker>(worker);\n\n  // A cleanup function that releases the comlink proxy and terminates the worker\n  const cleanup = () => {\n    workerApi[releaseProxy]();\n    worker.terminate();\n  };\n\n  const workerApiAndCleanup = { workerApi, cleanup };\n\n  return workerApiAndCleanup;\n}\n")),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"useWorker")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"makeWorkerApiAndCleanup")," functions make up the basis of a shareable worker hooks approach. It would take very little work to paramaterise them so this could be used elsewhere. That's outside the scope of this post but would be extremely straightforward to accomplish."),(0,a.kt)("p",null,"Time to test! We'll change our ",(0,a.kt)("inlineCode",{parentName:"p"},"App.tsx")," to use the new ",(0,a.kt)("inlineCode",{parentName:"p"},"useTakeALongTimeToAddTwoNumbers")," hook:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"import React, { useState } from 'react';\nimport './App.css';\nimport { useTakeALongTimeToAddTwoNumbers } from './App.hooks';\n\nconst App: React.FC = () => {\n  const [number1, setNumber1] = useState(1);\n  const [number2, setNumber2] = useState(2);\n\n  const total = useTakeALongTimeToAddTwoNumbers(number1, number2);\n\n  return (\n    <div className=\"App\">\n      <h1>Web Workers in action!</h1>\n\n      <div>\n        <label>Number to add: </label>\n        <input\n          type=\"number\"\n          onChange={(e) => setNumber1(parseInt(e.target.value))}\n          value={number1}\n        />\n      </div>\n      <div>\n        <label>Number to add: </label>\n        <input\n          type=\"number\"\n          onChange={(e) => setNumber2(parseInt(e.target.value))}\n          value={number2}\n        />\n      </div>\n      <h2>\n        Total:{' '}\n        {total.isCalculating ? (\n          <em>Calculating...</em>\n        ) : (\n          <strong>{total.total}</strong>\n        )}\n      </h2>\n    </div>\n  );\n};\n\nexport default App;\n")),(0,a.kt)("p",null,"Now our calculation takes place off the main thread and the UI is no longer blocked!"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(86124).Z,width:"544",height:"248"})),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/integrating-web-workers-in-a-react-app-with-comlink/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/integrating-web-workers-in-a-react-app-with-comlink/"})),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/webworkers-comlink-typescript-react"}),"The source code for this project can be found here.")))}d.isMDXComponent=!0},1104:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"dual-boot-authentication-with-aspnetcore",title:"Dual boot authentication with ASP.NET",authors:"johnnyreilly",tags:["Authentication","Azure AD","ASP.NET"],hide_table_of_contents:!1},s=void 0,l={permalink:"/dual-boot-authentication-with-aspnetcore",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-03-22-dual-boot-authentication-with-aspnetcore/index.md",source:"@site/blog/2020-03-22-dual-boot-authentication-with-aspnetcore/index.md",title:"Dual boot authentication with ASP.NET",description:"This is a post about having two kinds of authentication working at the same time in ASP.Net Core. But choosing which authentication method to use dynamically at runtime; based upon the criteria of your choice.",date:"2020-03-22T00:00:00.000Z",formattedDate:"March 22, 2020",tags:[{label:"Authentication",permalink:"/tags/authentication"},{label:"Azure AD",permalink:"/tags/azure-ad"},{label:"ASP.NET",permalink:"/tags/asp-net"}],readingTime:8.05,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"dual-boot-authentication-with-aspnetcore",title:"Dual boot authentication with ASP.NET",authors:"johnnyreilly",tags:["Authentication","Azure AD","ASP.NET"],hide_table_of_contents:!1},prevItem:{title:"Offline storage in a PWA",permalink:"/offline-storage-in-pwa"},nextItem:{title:"Web Workers, comlink, TypeScript and React",permalink:"/web-workers-comlink-typescript-and-react"}},p={authorsImageUrls:[void 0]},u=[{value:"Let us speak of the past",id:"let-us-speak-of-the-past",level:2},{value:"A new hope",id:"a-new-hope",level:2},{value:"Show me the code",id:"show-me-the-code",level:2},{value:"The mystery of no documentation",id:"the-mystery-of-no-documentation",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This is a post about having two kinds of authentication working at the same time in ASP.Net Core. But choosing which authentication method to use dynamically at runtime; based upon the criteria of your choice."),(0,a.kt)("p",null,"Already this sounds complicated; let's fix that. Perhaps I should describe my situation to you. I've an app which has two classes of user. One class, let's call them \"customers\" (because... uh... they're customers). The customers access our application via a public facing website. Traffic rolls through Cloudflare and into our application. The public facing URL is something fancy like ",(0,a.kt)("a",o({parentName:"p"},{href:"https://mega-app.com"}),"https://mega-app.com"),". That's one class of user."),(0,a.kt)("p",null,'The other class of user we\'ll call "our peeps"; because they are ',(0,a.kt)("em",{parentName:"p"},"us"),'. We use the app that we build. Traffic from "us" comes from a different hostname; only addressable on our network. So URLs from requests that we make are more along the lines of ',(0,a.kt)("a",o({parentName:"p"},{href:"https://strictly4mypeeps.io"}),"https://strictly4mypeeps.io"),"."),(0,a.kt)("p",null,"So far, so uncontroversial. Now it starts to get interesting. Our customers log into our application using their super secret credentials. It's ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/aspnet/core/security/authentication/cookie?view=aspnetcore-3.1#create-an-authentication-cookie"}),"cookie based authentication"),". But for our peeps we do something different. Having to enter your credentials each time you use the app is friction. It gets in the way. So for us we have ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/aspnet/core/security/authentication/azure-active-directory/?view=aspnetcore-3.1"}),"Azure AD")," in the mix. Azure AD is how we authenticate ourselves; and that means we don't spend 5% of each working day entering credentials."),(0,a.kt)("h2",o({},{id:"let-us-speak-of-the-past"}),"Let us speak of the past"),(0,a.kt)("p",null,'Now our delightful little application grew up in a simpler time. A time where you went to the marketplace, picked out some healthy looking servers, installed software upon them, got them attached to the internet, deployed an app onto them and said "hey presto, we\'re live!".'),(0,a.kt)("p",null,"Way back when, we had some servers on the internet, that's how our customers got to our app. Our peeps, us, we went to other servers that lived on our network. So we had multiple instances of our app, deployed to different machines. The ones on the internet were configured to use cookie based auth, the ones on our internal network were Azure AD."),(0,a.kt)("p",null,"As I said, a simpler time."),(0,a.kt)("h2",o({},{id:"a-new-hope"}),"A new hope"),(0,a.kt)("p",null,"We've been going through the process of cloudifying our app. Bye, bye servers, hello ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.docker.com/"}),"Docker")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://kubernetes.io/"}),"Kubernetes"),". So exciting! As we change the way our app is built and deployed; we've been thinking about whether the choices we make still make sense."),(0,a.kt)("p",null,'When it came to authentication, my initial thoughts were to continue the same road we\'re travelling; just in containers and pods. So where we had "internal" servers, we\'d have "internal" pods, and where we\'d have "external" servers we\'d have external pods. I had the good fortune to be working with the amazingly talented ',(0,a.kt)("a",o({parentName:"p"},{href:"https://uk.linkedin.com/in/robert-grzankowski-53618114"}),"Robski"),'. Robski knows far more about K8s and networking than I\'m ever likely to. He\'d regularly say things like "ingress" and "MTLS" whilst I stared blankly at him. He definitely knows stuff.'),(0,a.kt)("p",null,"Robski challenged my plans. \"We don't need it. Have one pod that does both sorts of auth. If you do that, your implementation is simpler and scaling is more straightforward. You'll only need half the pods because you won't need internal ",(0,a.kt)("em",{parentName:"p"},"and")," external ones; one pod can handle both sets of traffic. You'll save money.\""),(0,a.kt)("p",null,"I loved the idea but I didn't think that ASP.Net Core supported it. \"It's just not a thing Robski; ASP.Net Core doesn't suppport it.\" Robski didn't believe me. That turned out to a ",(0,a.kt)("em",{parentName:"p"},"very good thing"),". There followed a period of much googling and experimentation. One day of hunting in, I was still convinced there was no way to do it that would allow me to look in the mirror without self loathing. Then Robski sent me this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"screenshot of WhatsApp message with a link in it",src:n(75148).Z,width:"400",height:"364"})),(0,a.kt)("p",null,"It was a link to the amazing ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/davidfowl"}),"David Fowler")," talking about ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/aspnet/Security/issues/1469#issuecomment-335027005"}),"some API I'd never heard of called ",(0,a.kt)("inlineCode",{parentName:"a"},"SchemeSelector")),". It turned out that this was the starting point for exactly what we needed; a way to dynamically select an authentication scheme at runtime."),(0,a.kt)("h2",o({},{id:"show-me-the-code"}),"Show me the code"),(0,a.kt)("p",null,"This API did end up landing in ASP.Net Core, but with the name ",(0,a.kt)("inlineCode",{parentName:"p"},"ForwardDefaultSelector"),". Not the most descriptive of names and I've struggled to find any documentation on it at all. What I did discover was ",(0,a.kt)("a",o({parentName:"p"},{href:"https://stackoverflow.com/a/51897159/761388"}),"an answer on StackOverflow by the marvellous Barbara Post"),". I was able to take the approach Barbara laid out and use it to my own ends. I ended up with this snippet of code added to my ",(0,a.kt)("inlineCode",{parentName:"p"},"Startup.ConfigureServices"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'services\n    .AddAuthentication(sharedOptions => {\n        sharedOptions.DefaultScheme = "WhichAuthDoWeUse";\n        sharedOptions.DefaultAuthenticateScheme = "WhichAuthDoWeUse";\n        sharedOptions.DefaultChallengeScheme = "WhichAuthDoWeUse";\n    })\n    .AddPolicyScheme("WhichAuthDoWeUse", "Azure AD or Cookies", options => {\n        options.ForwardDefaultSelector = context => {\n            var (isExternalRequest, requestUrl) = context.Request.GetIsExternalRequestAndDomain();\n            if (isExternalRequest) {\n                _logger.LogInformation(\n                    "Request ({RequestURL}) has come from external domain ({Domain}) so using Cookie Authentication",\n                    requestUrl, ExternalBaseUrl);\n\n                return CookieAuthenticationDefaults.AuthenticationScheme;\n           }\n\n           _logger.LogInformation(\n               "Request ({RequestURL}) has not come from external domain ({Domain}) so using Azure AD Authentication",\n               requestUrl, ExternalBaseUrl);\n\n            return AzureADDefaults.AuthenticationScheme;\n        };\n    })\n    .AddAzureAD(options => {\n        Configuration.Bind("AzureAd", options);\n    })\n    .AddCookie(options => {\n        options.Cookie.SecurePolicy = CookieSecurePolicy.Always;\n        options.Cookie.SameSite = SameSiteMode.Strict;\n        options.Cookie.HttpOnly = true;\n        options.Events.OnRedirectToAccessDenied = (context) => {\n            context.Response.StatusCode = Microsoft.AspNetCore.Http.StatusCodes.Status401Unauthorized;\n            return Task.CompletedTask;\n        };\n\n        options.Events.OnRedirectToLogin = (context) => {\n            context.Response.StatusCode = Microsoft.AspNetCore.Http.StatusCodes.Status401Unauthorized;\n            return Task.CompletedTask;\n        };\n    });\n')),(0,a.kt)("p",null,"If you look at this code it's doing these things:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},'Registering three types of authentication: Cookie, Azure AD and "WhichAuthDoWeUse"'),(0,a.kt)("li",{parentName:"ol"},"Registers the default ",(0,a.kt)("inlineCode",{parentName:"li"},"Scheme"),' to be "WhichAuthDoWeUse".')),(0,a.kt)("p",null,'"WhichAuthDoWeUse" is effectively an ',(0,a.kt)("inlineCode",{parentName:"p"},"if")," statement that says, ",(0,a.kt)("em",{parentName:"p"},'"if this is an external ',(0,a.kt)("inlineCode",{parentName:"em"},"Request"),' use Cookies authentication, otherwise use Azure AD"'),'. Given that "WhichAuthDoWeUse" is the default scheme, this code runs for each request, to determine which authentication method to use.'),(0,a.kt)("p",null,"Alongside this mechanism I added these extension methods:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Http.Extensions;\n\nnamespace My.App.Auth {\n    public static class AuthExtensions {\n        public const string ExternalBaseUrl = "https://mega-app.com";\n        public const string InternalBaseUrl = "https://strictly4mypeeps.io";\n\n        /// <summary>\n        /// Determines if a request is an "external" URL (eg begins "https://mega-app.com")\n        /// or an "internal" URL (eg begins "https://strictly4mypeeps.io")\n        /// </summary>\n        public static (bool, string) GetIsExternalRequestAndDomain(this HttpRequest request) {\n            var (requestUrl, domain) = GetRequestUrlAndDomain(request);\n\n            var isExternalUrl = domain == ExternalBaseUrl;\n\n            var isUnknownPath = domain == null; // This scenario is extremely unlikely but has been observed once during testing so we will cater for it\n\n            var isExternalRequest = isExternalUrl || isUnknownPath; // If unknown we\'ll treat as "external" for a safe fallback\n\n            return (isExternalRequest, requestUrl);\n        }\n\n        /// <summary>\n        /// Determines if a request is an "external" URL (eg begins "https://mega-app.com")\n        /// or an "internal" URL (eg begins "https://strictly4mypeeps.io")\n        /// </summary>\n        public static (bool, string) GetIsInternalRequestAndDomain(this HttpRequest request) {\n            var (requestUrl, domain) = GetRequestUrlAndDomain(request);\n\n            var isInternalRequest = domain == InternalBaseUrl;\n\n            return (isInternalRequest, requestUrl);\n        }\n\n        private static (string, string) GetRequestUrlAndDomain(HttpRequest request) {\n            string requestUrl = null;\n            string domain = null;\n            if (request.Host.HasValue) {\n                requestUrl = request.GetEncodedUrl();\n                domain = new Uri(requestUrl).GetLeftPart(UriPartial.Authority);\n            }\n\n            return (requestUrl, domain);\n        }\n    }\n}\n')),(0,a.kt)("p",null,"Finally, I updated the ",(0,a.kt)("inlineCode",{parentName:"p"},"SpaController.cs")," (which serves initial requests to our Single Page Application) to cater for having two types of Auth in play:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'        /// <summary>\n        /// ASP.NET will try and load the index.html using the FileServer if we don\'t have a route\n        /// here to match `/`. These attributes can\'t be on Index or the spa fallback doesn\'t work\n        /// Note: this is almost perfect except that if someone actually calls /index.html they\'ll get\n        /// the FileServer one, not the one from this file.\n        /// </summary>\n        [HttpGet("/")]\n        [AllowAnonymous]\n        public async Task<IActionResult> SpaFallback([FromQuery] string returnUrl) {\n            var redirectUrlIfUserIsInternalAndNotAuthenticated = GetRedirectUrlIfUserIsInternalAndNotAuthenticated(returnUrl);\n\n            if (redirectUrlIfUserIsInternalAndNotAuthenticated != null)\n                return LocalRedirect(redirectUrlIfUserIsInternalAndNotAuthenticated);\n\n            return await Index(); // Index just serves up our SPA index.html\n        }\n\n        /// <summary>\n        /// SPA landing with authorisation - this endpoint will typically not be directly navigated to by a user;\n        /// rather it will be redirected to from the IndexWithoutAuthorisation and SpaFallback actions above\n        /// in the case where a user is *not* authenticated but has come from an internal URL eg https://strictlyformypeeps.io\n        /// </summary>\n        [HttpGet("/login-with-azure-ad")]\n        [Authorize]\n        public async Task<IActionResult> IndexWithAuthorisation()\n        {\n            return await Index(); // Index just serves up our SPA index.html\n        }\n\n        /// <summary>\n        /// This method returns a RedirectURL if a request is coming from an internal URL\n        /// eg https://int.prd.our.cloud and is not authenticated.  In this case\n        /// we likely want to trigger authentication by redirecting to an authorized endpoint\n        /// </summary>\n        string GetRedirectUrlIfUserIsInternalAndNotAuthenticated(string returnUrl)\n        {\n            // If a user is authenticated then we don\'t need to trigger authentication\n            var isAuthenticated = User?.Identity?.Name != null;\n            if (isAuthenticated)\n                return null;\n\n            // This scenario is extremely unlikely but has been observed once during testing so we will cater for it\n            var (isInternalRequest, requestUrl) = Request.GetIsInternalRequestAndDomain();\n\n            if (isInternalRequest) {\n                var redirectUrl = $"/login-with-azure-ad{(string.IsNullOrEmpty(returnUrl) ? "" : "?returnUrl=" + WebUtility.UrlEncode(returnUrl))}";\n                _logger.LogInformation(\n                    "Request ({RequestURL}) has come from internal domain ({InternalDomain}) but is not authenticated; redirecting to {RedirectURL}",\n                    requestUrl, AuthExtensions.InternalBaseUrl, redirectUrl);\n\n                return redirectUrl;\n            }\n\n            return null;\n        }\n')),(0,a.kt)("p",null,"The code above allows anonymous requests to land in our app through the ",(0,a.kt)("inlineCode",{parentName:"p"},"AllowAnonymous")," attribute. However, it checks the request when it comes in to see if:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"It's an internal request (i.e. the Request URL starts \"",(0,a.kt)("a",o({parentName:"li"},{href:"https://strictly4mypeeps.io/%22"}),'https://strictly4mypeeps.io/"'),")"),(0,a.kt)("li",{parentName:"ol"},"The current user is ",(0,a.kt)("em",{parentName:"li"},"not")," authenticated.")),(0,a.kt)("p",null,"In this case the user is redirected to the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://strictly4mypeeps.io/login-with-azure-ad"}),"https://strictly4mypeeps.io/login-with-azure-ad")," route which is decorated with the ",(0,a.kt)("inlineCode",{parentName:"p"},"Authorize")," attribute. This will trigger authentication for our unauthenticated internal users and drive them through the Azure AD login process."),(0,a.kt)("h2",o({},{id:"the-mystery-of-no-documentation"}),"The mystery of no documentation"),(0,a.kt)("p",null,"I'm so surprised that this approach hasn't yet been better documented on the (generally superb) ASP.Net Core docs. It's such a potentially useful approach; and in our case, money saving too! I hope the official docs feature something on this in future. If they do, and I've just missed it (possible!) then please hit me up in the comments."))}d.isMDXComponent=!0},9306:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"offline-storage-in-pwa",title:"Offline storage in a PWA",authors:"johnnyreilly",tags:["PWA"],hide_table_of_contents:!1},s=void 0,l={permalink:"/offline-storage-in-pwa",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-03-29-offline-storage-in-pwa/index.md",source:"@site/blog/2020-03-29-offline-storage-in-pwa/index.md",title:"Offline storage in a PWA",description:"When you are building any kind of application it's typical to want to store information which persists beyond a single user session. Sometimes that will be information that you'll want to live in some kind of centralised database, but not always.",date:"2020-03-29T00:00:00.000Z",formattedDate:"March 29, 2020",tags:[{label:"PWA",permalink:"/tags/pwa"}],readingTime:9.07,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"offline-storage-in-pwa",title:"Offline storage in a PWA",authors:"johnnyreilly",tags:["PWA"],hide_table_of_contents:!1},prevItem:{title:"Up to the clouds!",permalink:"/up-to-clouds"},nextItem:{title:"Dual boot authentication with ASP.NET",permalink:"/dual-boot-authentication-with-aspnetcore"}},p={authorsImageUrls:[void 0]},u=[{value:"The problem with <code>localStorage</code>",id:"the-problem-with-localstorage",level:2},{value:"IndexedDB to the rescue?",id:"indexeddb-to-the-rescue",level:2},{value:"IDB-Keyval to the rescue!",id:"idb-keyval-to-the-rescue",level:2},{value:"Simple usage",id:"simple-usage",level:2},{value:"Usage in React",id:"usage-in-react",level:2},{value:"Usage as a React hook",id:"usage-as-a-react-hook",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"When you are building any kind of application it's typical to want to store information which persists beyond a single user session. Sometimes that will be information that you'll want to live in some kind of centralised database, but not always."),(0,a.kt)("p",null,"Also, you may want that data to still be available if your user is offline. Even if they can't connect to the network, the user may still be able to use the app to do meaningful tasks; but the app will likely require a certain amount of data to drive that."),(0,a.kt)("p",null,"How can we achieve this in the context of a PWA?"),(0,a.kt)("h2",o({},{id:"the-problem-with-localstorage"}),"The problem with ",(0,a.kt)("inlineCode",{parentName:"h2"},"localStorage")),(0,a.kt)("p",null,"If you were building a classic web app you'd probably be reaching for ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage"}),(0,a.kt)("inlineCode",{parentName:"a"},"Window.localStorage"))," at this point. ",(0,a.kt)("inlineCode",{parentName:"p"},"Window.localStorage")," is a long existing API that stores data beyond a single session. It has a simple API and is very easy to use. However, it has a couple of problems:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"Window.localStorage")," is synchronous. Not a tremendous problem for every app, but if you're building something that has significant performance needs then this could become an issue."),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"Window.localStorage")," cannot be used in the context of a ",(0,a.kt)("inlineCode",{parentName:"li"},"Worker")," or a ",(0,a.kt)("inlineCode",{parentName:"li"},"ServiceWorker"),". The APIs are not available there."),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"Window.localStorage")," stores only ",(0,a.kt)("inlineCode",{parentName:"li"},"string"),"s. Given ",(0,a.kt)("a",o({parentName:"li"},{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify"}),(0,a.kt)("inlineCode",{parentName:"a"},"JSON.stringify"))," and ",(0,a.kt)("a",o({parentName:"li"},{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse"}),(0,a.kt)("inlineCode",{parentName:"a"},"JSON.parse"))," that's not a big problem. But it's an inconvenience.")),(0,a.kt)("p",null,"The second point here is the significant one. If we've a need to access our offline data in the context of a ",(0,a.kt)("inlineCode",{parentName:"p"},"ServiceWorker")," (and if you're offline you'll be using a ",(0,a.kt)("inlineCode",{parentName:"p"},"ServiceWorker"),") then what do you do?"),(0,a.kt)("h2",o({},{id:"indexeddb-to-the-rescue"}),"IndexedDB to the rescue?"),(0,a.kt)("p",null,"Fortunately, ",(0,a.kt)("inlineCode",{parentName:"p"},"localStorage")," is not the only game in town. There's alternative offline storage mechanism available in browsers with the curious name of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API"}),"IndexedDB"),". To quote the docs:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"IndexedDB is a transactional database system, like an SQL-based RDBMS. However, unlike SQL-based RDBMSes, which use fixed-column tables, IndexedDB is a JavaScript-based object-oriented database. IndexedDB lets you store and retrieve objects that are indexed with a key; any objects supported by the structured clone algorithm can be stored. You need to specify the database schema, open a connection to your database, and then retrieve and update data within a series of transactions.")),(0,a.kt)("p",null,"It's clear that IndexedDB is ",(0,a.kt)("em",{parentName:"p"},"very")," powerful. But it doesn't sound very simple. A further look at the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/mdn/to-do-notifications/blob/8b3e1708598e42062b0136608b1c5fbb66520f0a/scripts/todo.js#L48"}),"MDN example")," of how to interact with IndexedDB does little to remove that thought."),(0,a.kt)("p",null,"We'd like to be able to access data offline; but in a simple fashion. Like we could with ",(0,a.kt)("inlineCode",{parentName:"p"},"localStorage")," which has a wonderfully straightforward API. If only someone would build an astraction on top of IndexedDB to make our lives easier..."),(0,a.kt)("p",null,"Someone did."),(0,a.kt)("h2",o({},{id:"idb-keyval-to-the-rescue"}),"IDB-Keyval to the rescue!"),(0,a.kt)("p",null,"The excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/jaffathecake"}),"Jake Archibald")," of Google has written ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jakearchibald/idb-keyval"}),"IDB-Keyval")," which is:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"A super-simple-small promise-based keyval store implemented with IndexedDB")),(0,a.kt)("p",null,"The API is essentially equivalent to ",(0,a.kt)("inlineCode",{parentName:"p"},"localStorage")," with a few lovely differences:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"The API is promise based; all functions return a ",(0,a.kt)("inlineCode",{parentName:"li"},"Promise"),"; this makes it a non-blocking API."),(0,a.kt)("li",{parentName:"ol"},"The API is not restricted to ",(0,a.kt)("inlineCode",{parentName:"li"},"string"),"s as ",(0,a.kt)("inlineCode",{parentName:"li"},"localStorage")," is. To quote the docs: ",(0,a.kt)("em",{parentName:"li"},"this is IDB-backed, you can store anything structured-clonable (numbers, arrays, objects, dates, blobs etc)")),(0,a.kt)("li",{parentName:"ol"},"Because this is abstraction built on top of IndexedDB, it can be used both in the context of a typical web app and also in a ",(0,a.kt)("inlineCode",{parentName:"li"},"Worker")," or a ",(0,a.kt)("inlineCode",{parentName:"li"},"ServiceWorker")," if required.")),(0,a.kt)("h2",o({},{id:"simple-usage"}),"Simple usage"),(0,a.kt)("p",null,"Let's take a look at what usage of ",(0,a.kt)("inlineCode",{parentName:"p"},"IDB-Keyval")," might be like. For that we're going to need an application. It would be good to be able to demonstrate both simple usage and also how usage in the context of an application might look."),(0,a.kt)("p",null,"Let's spin up a TypeScript React app with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://create-react-app.dev/"}),"Create React App"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"npx create-react-app offline-storage-in-a-pwa --template typescript\n")),(0,a.kt)("p",null,"This creates us a simple app. Now let's add IDB-Keyval to it:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"yarn add idb-keyval\n")),(0,a.kt)("p",null,"Then, let's update the ",(0,a.kt)("inlineCode",{parentName:"p"},"index.tsx")," file to add a function that tests using IDB-Keyval:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"import React from 'react';\nimport ReactDOM from 'react-dom';\nimport { set, get } from 'idb-keyval';\nimport './index.css';\nimport App from './App';\nimport * as serviceWorker from './serviceWorker';\n\nReactDOM.render(<App />, document.getElementById('root'));\n\nserviceWorker.register();\n\nasync function testIDBKeyval() {\n  await set('hello', 'world');\n  const whatDoWeHave = await get('hello');\n  console.log(\n    `When we queried idb-keyval for 'hello', we found: ${whatDoWeHave}`\n  );\n}\n\ntestIDBKeyval();\n")),(0,a.kt)("p",null,"As you can see, we've added a ",(0,a.kt)("inlineCode",{parentName:"p"},"testIDBKeyval")," function which does the following:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Adds a value of ",(0,a.kt)("inlineCode",{parentName:"li"},"'world'")," to IndexedDB using IDB-Keyval for the key of ",(0,a.kt)("inlineCode",{parentName:"li"},"'hello'")),(0,a.kt)("li",{parentName:"ol"},"Queries IndexedDB using IDB-Keyval for the key of ",(0,a.kt)("inlineCode",{parentName:"li"},"'hello'")," and stores it in the variable ",(0,a.kt)("inlineCode",{parentName:"li"},"whatDoWeHave")),(0,a.kt)("li",{parentName:"ol"},"Logs out what we found.")),(0,a.kt)("p",null,"You'll also note that ",(0,a.kt)("inlineCode",{parentName:"p"},"testIDBKeyval")," is an ",(0,a.kt)("inlineCode",{parentName:"p"},"async")," function. This is so that we can use ",(0,a.kt)("inlineCode",{parentName:"p"},"await")," when we're interacting with IDB-Keyval. Given that its API is ",(0,a.kt)("inlineCode",{parentName:"p"},"Promise")," based, it is ",(0,a.kt)("inlineCode",{parentName:"p"},"await")," friendly. Where you're performing more than an a single asynchronous operation at a time, it's often valuable to use ",(0,a.kt)("inlineCode",{parentName:"p"},"async")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"await")," to increase the readability of your codebase."),(0,a.kt)("p",null,"What happens when we run our application with ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn start"),"? Let's do that and take a look at the devtools:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(75271).Z,width:"640",height:"484"})),(0,a.kt)("p",null,"We successfully wrote something into IndexedDB, read it back and printed that value to the console. Amazing!"),(0,a.kt)("h2",o({},{id:"usage-in-react"}),"Usage in React"),(0,a.kt)("p",null,"What we've done so far is slightly abstract. It would be good to implement a real-world use case. Let's create an application which gives users the choice between using a \"Dark mode\" version of the app or not. To do that we'll replace our ",(0,a.kt)("inlineCode",{parentName:"p"},"App.tsx")," with this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"import React, { useState } from 'react';\nimport './App.css';\n\nconst sharedStyles = {\n  height: '30rem',\n  fontSize: '5rem',\n  textAlign: 'center',\n} as const;\n\nfunction App() {\n  const [darkModeOn, setDarkModeOn] = useState(true);\n  const handleOnChange = ({ target }: React.ChangeEvent<HTMLInputElement>) =>\n    setDarkModeOn(target.checked);\n\n  const styles = {\n    ...sharedStyles,\n    ...(darkModeOn\n      ? {\n          backgroundColor: 'black',\n          color: 'white',\n        }\n      : {\n          backgroundColor: 'white',\n          color: 'black',\n        }),\n  };\n\n  return (\n    <div style={styles}>\n      <input\n        type=\"checkbox\"\n        value=\"darkMode\"\n        checked={darkModeOn}\n        id=\"darkModeOn\"\n        name=\"darkModeOn\"\n        style={{ width: '3rem', height: '3rem' }}\n        onChange={handleOnChange}\n      />\n      <label htmlFor=\"darkModeOn\">Use dark mode?</label>\n    </div>\n  );\n}\n\nexport default App;\n")),(0,a.kt)("p",null,"When you run the app you can see how it works:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(73797).Z,width:"640",height:"127"})),(0,a.kt)("p",null,"Looking at the code you'll be able to see that this is implemented using React's ",(0,a.kt)("inlineCode",{parentName:"p"},"useState")," hook. So any user preference selected will be lost on a page refresh. Let's see if we can take this state and move it into IndexedDB using ",(0,a.kt)("inlineCode",{parentName:"p"},"IDB-Keyval"),"."),(0,a.kt)("p",null,"We'll change the code like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"import React, { useState, useEffect } from 'react';\nimport { set, get } from 'idb-keyval';\nimport './App.css';\n\nconst sharedStyles = {\n  height: '30rem',\n  fontSize: '5rem',\n  textAlign: 'center',\n} as const;\n\nfunction App() {\n  const [darkModeOn, setDarkModeOn] = useState<boolean | undefined>(undefined);\n\n  useEffect(() => {\n    get<boolean>('darkModeOn').then((value) =>\n      // If a value is retrieved then use it; otherwise default to true\n      setDarkModeOn(value ?? true)\n    );\n  }, [setDarkModeOn]);\n\n  const handleOnChange = ({ target }: React.ChangeEvent<HTMLInputElement>) => {\n    setDarkModeOn(target.checked);\n\n    set('darkModeOn', target.checked);\n  };\n\n  const styles = {\n    ...sharedStyles,\n    ...(darkModeOn\n      ? {\n          backgroundColor: 'black',\n          color: 'white',\n        }\n      : {\n          backgroundColor: 'white',\n          color: 'black',\n        }),\n  };\n\n  return (\n    <div style={styles}>\n      {darkModeOn === undefined ? (\n        <>Loading preferences...</>\n      ) : (\n        <>\n          <input\n            type=\"checkbox\"\n            value=\"darkMode\"\n            checked={darkModeOn}\n            id=\"darkModeOn\"\n            name=\"darkModeOn\"\n            style={{ width: '3rem', height: '3rem' }}\n            onChange={handleOnChange}\n          />\n          <label htmlFor=\"darkModeOn\">Use dark mode?</label>\n        </>\n      )}\n    </div>\n  );\n}\n\nexport default App;\n")),(0,a.kt)("p",null,"The changes here are:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"darkModeOn")," is now initialised to ",(0,a.kt)("inlineCode",{parentName:"li"},"undefined")," and the app displays a loading message until ",(0,a.kt)("inlineCode",{parentName:"li"},"darkModeOn")," has a value."),(0,a.kt)("li",{parentName:"ol"},"The app attempts to app load a value from IDB-Keyval with the key ",(0,a.kt)("inlineCode",{parentName:"li"},"'darkModeOn'")," and set ",(0,a.kt)("inlineCode",{parentName:"li"},"darkModeOn")," with the retrieved value. If no value is retrieved then it sets ",(0,a.kt)("inlineCode",{parentName:"li"},"darkModeOn")," to ",(0,a.kt)("inlineCode",{parentName:"li"},"true"),"."),(0,a.kt)("li",{parentName:"ol"},"When the checkbox is changed, the corresponding value is both applied to ",(0,a.kt)("inlineCode",{parentName:"li"},"darkModeOn")," and saved to IDB-Keyval with the key ",(0,a.kt)("inlineCode",{parentName:"li"},"'darkModeOn'"))),(0,a.kt)("p",null,"As you can see, this means that we are persisting preferences beyond page refresh in a fashion that will work both online ",(0,a.kt)("em",{parentName:"p"},"and")," offline!"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(98321).Z,width:"640",height:"315"})),(0,a.kt)("h2",o({},{id:"usage-as-a-react-hook"}),"Usage as a React hook"),(0,a.kt)("p",null,"Finally it's time for bonus points. Wouldn't it be nice if we could move this functionality into a reusable React hook? Let's do it!"),(0,a.kt)("p",null,"Let's create a new ",(0,a.kt)("inlineCode",{parentName:"p"},"usePersistedState.ts")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { useState, useEffect, useCallback } from 'react';\nimport { set, get } from 'idb-keyval';\n\nexport function usePersistedState<TState>(\n  keyToPersistWith: string,\n  defaultState: TState\n) {\n  const [state, setState] = useState<TState | undefined>(undefined);\n\n  useEffect(() => {\n    get<TState>(keyToPersistWith).then((retrievedState) =>\n      // If a value is retrieved then use it; otherwise default to defaultValue\n      setState(retrievedState ?? defaultState)\n    );\n  }, [keyToPersistWith, setState, defaultState]);\n\n  const setPersistedValue = useCallback(\n    (newValue: TState) => {\n      setState(newValue);\n      set(keyToPersistWith, newValue);\n    },\n    [keyToPersistWith, setState]\n  );\n\n  return [state, setPersistedValue] as const;\n}\n")),(0,a.kt)("p",null,"This new hook is modelled after the API of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://reactjs.org/docs/hooks-reference.html#usestate"}),(0,a.kt)("inlineCode",{parentName:"a"},"useState"))," and is named ",(0,a.kt)("inlineCode",{parentName:"p"},"usePersistentState"),". It requires that a key be supplied which is the key that will be used to save the data. It also requires a default value to use in the case that nothing is found during the lookup."),(0,a.kt)("p",null,"It returns (just like ",(0,a.kt)("inlineCode",{parentName:"p"},"useState"),") a stateful value, and a function to update it. Finally, let's switch over our ",(0,a.kt)("inlineCode",{parentName:"p"},"App.tsx")," to use our shiny new hook:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"import React from 'react';\nimport './App.css';\nimport { usePersistedState } from './usePersistedState';\n\nconst sharedStyles = {\n  height: '30rem',\n  fontSize: '5rem',\n  textAlign: 'center',\n} as const;\n\nfunction App() {\n  const [darkModeOn, setDarkModeOn] = usePersistedState<boolean>(\n    'darkModeOn',\n    true\n  );\n\n  const handleOnChange = ({ target }: React.ChangeEvent<HTMLInputElement>) =>\n    setDarkModeOn(target.checked);\n\n  const styles = {\n    ...sharedStyles,\n    ...(darkModeOn\n      ? {\n          backgroundColor: 'black',\n          color: 'white',\n        }\n      : {\n          backgroundColor: 'white',\n          color: 'black',\n        }),\n  };\n\n  return (\n    <div style={styles}>\n      {darkModeOn === undefined ? (\n        <>Loading preferences...</>\n      ) : (\n        <>\n          <input\n            type=\"checkbox\"\n            value=\"darkMode\"\n            checked={darkModeOn}\n            id=\"darkModeOn\"\n            name=\"darkModeOn\"\n            style={{ width: '3rem', height: '3rem' }}\n            onChange={handleOnChange}\n          />\n          <label htmlFor=\"darkModeOn\">Use dark mode?</label>\n        </>\n      )}\n    </div>\n  );\n}\n\nexport default App;\n")),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"This post has demonstrate how a web application or a PWA can safely store data that is persisted between sessions using native browser capabilities easily. IndexedDB powered the solution we've built. We used used ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jakearchibald/idb-keyval"}),"IDB-Keyval")," for the delightful and familiar abstraction it offers over IndexedDB. It's allowed us to come up with a solution with a similarly lovely API. It's worth knowing that there are alternatives to IDB-Keyval available such as ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/localForage/localForage"}),"localForage"),". If you are building for older browsers which may lack good IndexedDB support then this would be a good choice. But be aware that with greater backwards compatibility comes greater download size. Do consider this and make the tradeoffs that make sense for you."),(0,a.kt)("p",null,"Finally, I've finished this post illustrating what usage would look like in a React context. Do be aware that there's nothing React specific about our offline storage mechanism. So if you're rolling with Vue, Angular or something else entirely: ",(0,a.kt)("em",{parentName:"p"},"this is for you too"),"! Offline storage is a feature that provide much greater user experiences. Please do consider making use of it in your applications."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/offline-storage-for-pwas/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/offline-storage-for-pwas/"})),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/offline-storage-in-a-pwa"}),"The source code for this project can be found here.")))}d.isMDXComponent=!0},38023:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"up-to-clouds",title:"Up to the clouds!",authors:"johnnyreilly",tags:["docker","kubernetes","asp net core"],hide_table_of_contents:!1},s=void 0,l={permalink:"/up-to-clouds",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-04-04-up-to-clouds/index.md",source:"@site/blog/2020-04-04-up-to-clouds/index.md",title:"Up to the clouds!",description:"This last four months has been quite the departure for me. Most typically I find myself building applications; for this last period of time I've been taking the platform that I work on, and been migrating it from running on our on premise servers to running in the cloud.",date:"2020-04-04T00:00:00.000Z",formattedDate:"April 4, 2020",tags:[{label:"docker",permalink:"/tags/docker"},{label:"kubernetes",permalink:"/tags/kubernetes"},{label:"asp net core",permalink:"/tags/asp-net-core"}],readingTime:10.65,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"up-to-clouds",title:"Up to the clouds!",authors:"johnnyreilly",tags:["docker","kubernetes","asp net core"],hide_table_of_contents:!1},prevItem:{title:"From react-window to react-virtual",permalink:"/from-react-window-to-react-virtual"},nextItem:{title:"Offline storage in a PWA",permalink:"/offline-storage-in-pwa"}},p={authorsImageUrls:[void 0]},u=[{value:"The mission",id:"the-mission",level:2},{value:"Kubernetes and Docker",id:"kubernetes-and-docker",level:2},{value:"Jenkins",id:"jenkins",level:2},{value:"Vault",id:"vault",level:2},{value:"Networking",id:"networking",level:2},{value:"Kerberos",id:"kerberos",level:2},{value:"Hangfire",id:"hangfire",level:2},{value:"Azure Active Directory Single Sign-On",id:"azure-active-directory-single-sign-on",level:2},{value:"Do the right thing and tell people about it",id:"do-the-right-thing-and-tell-people-about-it",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This last four months has been quite the departure for me. Most typically I find myself building applications; for this last period of time I've been taking the platform that I work on, and been migrating it from running on our on premise servers to running in the cloud."),(0,a.kt)("p",null,"This turned out to be much more difficult than I'd expected and for reasons that often surprised me. We knew where we wanted to get to, but not all of what we'd need to do to get there. So many things you can only learn by doing. Whilst these experiences are still fresh in my mind I wanted to document some of the challenges we faced."),(0,a.kt)("h2",o({},{id:"the-mission"}),"The mission"),(0,a.kt)("p",null,"At the start of January, the team decided to make a concerted effort to take our humble ASP.NET Core application and migrate it to the cloud. We sat down with some friends from the DevOps team who are part of our organisation. We're fortunate in that these marvellous people are very talented engineers indeed. It was going to be a collaboration between our two teams of budding cloudmongers that would make this happen."),(0,a.kt)("p",null,"Now our application is young. It is not much more than a year old. However it is growing ",(0,a.kt)("em",{parentName:"p"},"fast"),". And as we did the migration from on premise to the cloud, that wasn't going to stop. Development of the application was to continue as is, shipping new versions daily. Without impeding that, we were to try and get the application migrated to the cloud."),(0,a.kt)("p",null,"I would liken it to boarding a speeding train, fighting your way to the front, taking the driver hostage and then diverting the train onto a different track. It was challenging. Really, really challenging."),(0,a.kt)("p",null,"So many things had to change for us to get from on premise servers to the cloud, all the while keeping our application a going (and shipping) concern. Let's go through them one by one."),(0,a.kt)("h2",o({},{id:"kubernetes-and-docker"}),"Kubernetes and Docker"),(0,a.kt)("p",null,"Our application was built using ASP.NET Core. A technology that is entirely cloud friendly (that's one of the reasons we picked it). We were running on a collection of hand installed, hand configured Windows servers. That had to change. We wanted to move our application to run on Kubernetes; so we didn't have to manually configure servers. Rather k8s would manage the provisioning and deployment of containers running our application. Worth saying now: I knew ",(0,a.kt)("em",{parentName:"p"},"nothing")," about Kubernetes. Or nearly nothing. I learned a bunch along the way, but, as I've said, this was a collaboration between our team and the mighty site reliability engineers of the DevOps team. They knew a ",(0,a.kt)("em",{parentName:"p"},"lot")," about this k8s stuff and moreoften than not, our team stood back and let them work their magic."),(0,a.kt)("p",null,"In order that we could migrate to running in k8s, we first needed to containerise our application. We needed a ",(0,a.kt)("inlineCode",{parentName:"p"},"Dockerfile"),". There followed a good amount of experimentation as we worked out how to build ourselves images. There's an art to building an optimal Docker image."),(0,a.kt)("p",null,"So that we can cover a lot of ground, this post will remain relatively high level. So here's a number of things that we encountered along the way that are worth considering:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Multi-stage builds were an absolute necessity for us. We'd build the front end of our app (React / TypeScript) using one stage with a ",(0,a.kt)("a",o({parentName:"li"},{href:"https://hub.docker.com/_/node"}),"Node base image"),". Then we'd build our app using a ",(0,a.kt)("a",o({parentName:"li"},{href:"https://hub.docker.com/_/microsoft-dotnet-core-sdk/"}),".NET Core SDK base image"),". Finally, we'd use a ",(0,a.kt)("a",o({parentName:"li"},{href:"https://hub.docker.com/_/microsoft-dotnet-core-aspnet"}),"ASP.Net")," image to run the app; copying in the output of previous stages."),(0,a.kt)("li",{parentName:"ul"},"Our application accesses various SQL Server databases. We struggled to get our application to connect to them. The issue related to the SSL configuration of our runner image. The fix was simple but frustrating; use a ",(0,a.kt)("inlineCode",{parentName:"li"},"-bionic")," image as it has the configuration you need. We found that gem ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/dotnet/SqlClient/issues/222#issuecomment-535802822"}),"here"),"."),(0,a.kt)("li",{parentName:"ul"},"Tests. Automated tests. We want to run them in our build; but how? Once more multi-stage builds to the rescue. We'd build our application, then in a separate stage we'd run the tests; copying in the app from the build stage. If the tests failed, the build failed. If they passed then the intermediate stage containing the tests would be discarded by Docker. No unnecessary bloat of the image; all that testing goodness still; now in containerised form!")),(0,a.kt)("h2",o({},{id:"jenkins"}),"Jenkins"),(0,a.kt)("p",null,"Our on premise world used TeamCity for our continuous integration needs and Octopus for deployment. We liked these tools well enough; particularly Octopus. However, the DevOps team were very much of the mind that we should be use Jenkins instead. And ",(0,a.kt)("a",o({parentName:"p"},{href:"https://jenkins.io/doc/book/pipeline/"}),"Pipeline"),". It was here that we initially struggled. To quote the docs:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},'Jenkins Pipeline (or simply "Pipeline" with a capital "P") is a suite of plugins which supports implementing and integrating continuous delivery pipelines into Jenkins.')),(0,a.kt)("p",null,"Whilst continuous delivery is super cool, and is something our team was interested in, we weren't ready for it yet. We didn't yet have the kind of automated testing in place that gave us the confidence that we'd need to move to it. One day, but not today. For now there was still some manual testing done on each release, prior to shipping. Octopus suited us very well here as it allowed us to deploy, on demand, a build of our choice to a given environment. So the question was: what to do? Fortunately the immensely talented Aby Egea came up with a mechanism that supported that very notion. A pipeline that would, optionally, deploy our build to a specified environment. So we were good!"),(0,a.kt)("p",null,"One thing we got to really appreciate about Jenkins was that the build is scripted with a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://jenkins.io/doc/book/pipeline/jenkinsfile/"}),"Jenkinsfile"),". This was in contrast to our TeamCity world where it was all manually configured. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://jenkins.io/projects/jcasc/"}),"Configuration as code")," is truly a wonderful thing as your build pipeline becomes part of your codebase; open for everyone to see and understand. If anyone wants to change the build pipeline it has to get code reviewed like everything else. It was as code in our ",(0,a.kt)("inlineCode",{parentName:"p"},"Jenkinsfile")," that the deployment mechanism lived."),(0,a.kt)("h2",o({},{id:"vault"}),"Vault"),(0,a.kt)("p",null,"Another thing that we used Octopus for was secrets. Applications run on configuration; these are settings that drive the behaviour of your application. A subset of configuration is \"secrets\". Secrets are configuration that can't be stored in source code; they would represent a risk if they did. For instance a database connection string. We'd been merrily using Octopus for this; as Octopus deploys an application to a server it enriches the ",(0,a.kt)("inlineCode",{parentName:"p"},"appsettings.json")," file with any required secrets."),(0,a.kt)("p",null,"Without Octopus in the mix, how were we to handle our secrets? The answer is with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.vaultproject.io/"}),"Hashicorp Vault"),". We'd store our secrets in there and, thanks to clever work by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://uk.linkedin.com/in/robert-grzankowski-53618114"}),"Robski")," of the DevOps team, when our container was brought up by Kubernetes, it would mount into the filesystem an ",(0,a.kt)("inlineCode",{parentName:"p"},"appsettings.Vault.json")," file which we read thanks to our trusty friend ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/?view=aspnetcore-3.1#json-configuration-provider"}),(0,a.kt)("inlineCode",{parentName:"a"},".AddJsonFile"))," with ",(0,a.kt)("inlineCode",{parentName:"p"},"optional: true"),". (As the file didn't exist in our development environment.)"),(0,a.kt)("p",null,"Hey presto! Safe secrets in k8s."),(0,a.kt)("h2",o({},{id:"networking"}),"Networking"),(0,a.kt)("p",null,"Our on premise servers sat on the company network. They could see ",(0,a.kt)("em",{parentName:"p"},"everything")," that there was to see. All the other servers around them on the network, bleeping and blooping. The opposite was true in AWS. There was nothing to see. Nothing to access. As it should be. It's safer that way should a machine become compromised. For each database and each API our application depended upon, we needed to specifically allowlist access."),(0,a.kt)("h2",o({},{id:"kerberos"}),"Kerberos"),(0,a.kt)("p",null,"There's always a fly in the ointment. A nasty surprise on a dark night. Ours was realising that our application depended upon an API that was secured using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/iis/configuration/system.webserver/security/authentication/windowsauthentication/"}),"Windows Authentication"),". Our application was accessing it by running under a service account which had been permissioned to access it. However, in AWS, our application wasn't running as under a service account on the company network. Disappointingly, in the short term the API was not going to support an alternate authentication mechanism."),(0,a.kt)("p",null,"What to do? Honestly it wasn't looking good. We were considering proxying through one of our Windows servers just to get access to that API. I was tremendously disappointed. At this point our hero arrived; one ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/foldr"}),"JMac")," hacked together a Kerberos sidecar approach one weekend. You can see a similar approach ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/edseymour/kinit-sidecar"}),"here"),". This got us to a point that allowed us to access the API we needed to."),(0,a.kt)("p",null,"I'm kind of amazed that there isn't better documentation out there around have a Kerberos sidecar in a k8s setup. Tragically Windows Authentication is a widely used authentication mechanism. That being the case, having good docs to show how you can get a Kerberos sidecar in place would likely greatly advance the ability of enterprises to migrate to the cloud. The best docs I've found are ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.openshift.com/kerberos-sidecar-container/"}),"here"),". It is super hard though. ",(0,a.kt)("em",{parentName:"p"},"So hard!")),(0,a.kt)("h2",o({},{id:"hangfire"}),"Hangfire"),(0,a.kt)("p",null,"We were using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services?view=aspnetcore-3.1&tabs=visual-studio"}),"Hosted Services")," to perform background task running in our app. The nature of our background tasks meant that it was important to only run a single instance of a background task at a time. Or bad things would happen. This was going to become a problem since we had ambitions to be able to horizontally scale our application; to add new pods as running our app as demand determined."),(0,a.kt)("p",null,"So we started to use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.hangfire.io/"}),"Hangfire")," to perform task running in our app. With Hangfire, when a job is picked up it gets locked so other servers can't pick it up. That's what we need."),(0,a.kt)("p",null,"Hangfire is pretty awesome. However it turns out that there's quirks when you move to a containerised environment. We have a number of recurring jobs that are scheduled to run at certain dates and times. In order that Hangfire can ascertain what time it is, it needs a timezone. It turns out that timezones on Windows != timezones in Docker / Linux."),(0,a.kt)("p",null,"This was a problem because, as we limbered up for the great migration, we were trying to run our cloud implementation side by side with our on premise one. And Windows picked a fight with Linux over timezones. You can see others bumping into this condition ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/HangfireIO/Hangfire/issues/1268"}),"here"),". We learned this the hard way; jobs mysteriously stopping due to timezone related errors. Windows Hangfire not able to recognise Linux Hangfire timezones and vica versa."),(0,a.kt)("p",null,"The TL;DR is that we had to do a hard switch with Hangfire; it couldn't run side by side. Not the end of the world, but surprising."),(0,a.kt)("h2",o({},{id:"azure-active-directory-single-sign-on"}),"Azure Active Directory Single Sign-On"),(0,a.kt)("p",null,"Historically our application had used two modes of authentication; Windows Authentication and cookies. Windows Authentication doesn't generally play nicely with Docker. It's doable, but it's not the hill you want to die on. So we didn't; we swapped out Windows Authentication for ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/active-directory/manage-apps/what-is-single-sign-on"}),"Azure AD SSO")," and didn't look back."),(0,a.kt)("p",null,"We also made some changes so our app would support cookies auth alongside Azure AD auth; ",(0,a.kt)("a",o({parentName:"p"},{href:"/dual-boot-authentication-with-aspnetcore"}),"I've written about this previously"),"."),(0,a.kt)("h2",o({},{id:"do-the-right-thing-and-tell-people-about-it"}),"Do the right thing and tell people about it"),(0,a.kt)("p",null,"We're there now; we've made the move. It was a difficult journey but one worth making; it sets up our platform for where we want to take it in the future. Having infrastructure as code makes all kinds of approaches possible that weren't before. Here's some things we're hoping to get out of the move:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"blue green deployments - shipping without taking down our platform"),(0,a.kt)("li",{parentName:"ul"},"provision environments on demand - currently we have a highly contended situation when it comes to test environments. With k8s and AWS we can look at spinning up environments as we need them and throwing them away also"),(0,a.kt)("li",{parentName:"ul"},"autoscaling for need - we can start to look at spinning up new containers in times of high load and removing excessive containers in times of low load")),(0,a.kt)("p",null,"We've also become more efficient as a team. We are no longer maintaining servers, renewing certificates, installing software, RDPing onto boxes. All that time and effort we can plough back into making awesome experiences for our users."),(0,a.kt)("p",null,"There's a long list of other benefits and it's very exciting indeed! It's not enough for us to have done this though. It's important that we tell the story of what we've done and how and why we've done it. That way people have empathy for the work. Also they can start to think about how they could start to reap similar benefits themselves. By talking to others about the road we've travelled, we can save them time and help them to travel a similar road. This is good for them and it's good for us; it helps our relationships and it helps us all to move forwards together."),(0,a.kt)("p",null,"A rising tide lifts all boats. By telling others about our journey, we raise the water level. Up to the clouds!"))}d.isMDXComponent=!0},11610:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"from-react-window-to-react-virtual",title:"From react-window to react-virtual",authors:"johnnyreilly",tags:["react-virtual","react-window","React"],hide_table_of_contents:!1},s=void 0,l={permalink:"/from-react-window-to-react-virtual",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-05-10-from-react-window-to-react-virtual/index.md",source:"@site/blog/2020-05-10-from-react-window-to-react-virtual/index.md",title:"From react-window to react-virtual",description:'The tremendous Tanner Linsley recently released react-virtual. react-virtual provides "hooks for virtualizing scrollable elements in React".',date:"2020-05-10T00:00:00.000Z",formattedDate:"May 10, 2020",tags:[{label:"react-virtual",permalink:"/tags/react-virtual"},{label:"react-window",permalink:"/tags/react-window"},{label:"React",permalink:"/tags/react"}],readingTime:2.555,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"from-react-window-to-react-virtual",title:"From react-window to react-virtual",authors:"johnnyreilly",tags:["react-virtual","react-window","React"],hide_table_of_contents:!1},prevItem:{title:"Autofac, WebApplicationFactory and integration tests",permalink:"/autofac-webapplicationfactory-integration-tests"},nextItem:{title:"Up to the clouds!",permalink:"/up-to-clouds"}},p={authorsImageUrls:[void 0]},u=[{value:"Make that change",id:"make-that-change",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The tremendous ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/tannerlinsley"}),"Tanner Linsley")," recently released ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/tannerlinsley/react-virtual"}),(0,a.kt)("inlineCode",{parentName:"a"},"react-virtual")),". ",(0,a.kt)("inlineCode",{parentName:"p"},"react-virtual"),' provides "hooks for virtualizing scrollable elements in React".'),(0,a.kt)("p",null,"I was already using the (also excellent) ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/bvaughn/react-window"}),(0,a.kt)("inlineCode",{parentName:"a"},"react-window"))," for this purpose. ",(0,a.kt)("inlineCode",{parentName:"p"},"react-window")," does the virtualising job and does it very well indeed However, I was both intrigued by the lure of the new shiny thing. I've also never been the biggest fan of ",(0,a.kt)("inlineCode",{parentName:"p"},"react-window"),"'s API. So I tried switching over from ",(0,a.kt)("inlineCode",{parentName:"p"},"react-window")," to ",(0,a.kt)("inlineCode",{parentName:"p"},"react-virtual")," as an experiment. To my delight, the experiment went so well I didn't look back!"),(0,a.kt)("p",null,"What did I get out of the switch?"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Simpler code / nicer developer ergonomics. The API for ",(0,a.kt)("inlineCode",{parentName:"li"},"react-virtual")," allowed me to simplify my code and lose a layer of components."),(0,a.kt)("li",{parentName:"ul"},"TypeScript support in the box"),(0,a.kt)("li",{parentName:"ul"},"Improved perceived performance. I didn't run any specific tests to quantify this, but I can say that the same functionality now feels snappier.")),(0,a.kt)("p",null,"I tweeted my delight at this and Tanner asked if there was commit diff I could share. I couldn't as it's a private codebase, but I thought it could form the basis of a blogpost."),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Nice! Do you have a commit diff we could see?"),(0,a.kt)("p",{parentName:"blockquote"},"\u2014 Tanner Linsley \u269b\ufe0f (@tannerlinsley) ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/tannerlinsley/status/1259503283103608832?ref_src=twsrc%5Etfw"}),"May 10, 2020"))),(0,a.kt)("script",{async:"",src:"https://platform.twitter.com/widgets.js",charSet:"utf-8"}),(0,a.kt)("p",null,"In case you hadn't guessed, this is that blog post..."),(0,a.kt)("h2",o({},{id:"make-that-change"}),"Make that change"),(0,a.kt)("p",null,"So what does the change look like? Well first remove ",(0,a.kt)("inlineCode",{parentName:"p"},"react-window")," from your project:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"yarn remove react-window @types/react-window\n")),(0,a.kt)("p",null,"Add the dependency to ",(0,a.kt)("inlineCode",{parentName:"p"},"react-virtual"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"yarn add react-virtual\n")),(0,a.kt)("p",null,"Change your imports from:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { FixedSizeList, ListChildComponentProps } from 'react-window';\n")),(0,a.kt)("p",null,"to:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { useVirtual } from 'react-virtual';\n")),(0,a.kt)("p",null,"Change your component code from:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"type ImportantDataListProps = {\n  classes: ReturnType<typeof useStyles>;\n  importants: ImportantData[];\n};\n\nconst ImportantDataList: React.FC<ImportantDataListProps> = React.memo(\n  (props) => (\n    <FixedSizeList\n      height={400}\n      width={'100%'}\n      itemSize={80}\n      itemCount={props.importants.length}\n      itemData={props}\n    >\n      {RenderRow}\n    </FixedSizeList>\n  )\n);\n\ntype ListItemProps = {\n  classes: ReturnType<typeof useStyles>;\n  importants: ImportantData[];\n};\n\nfunction RenderRow(props: ListChildComponentProps) {\n  const { index, style } = props;\n  const { importants, classes } = props.data as ListItemProps;\n  const important = importants[index];\n\n  return (\n    <ListItem button style={style} key={index}>\n      <ImportantThing classes={classes} important={important} />\n    </ListItem>\n  );\n}\n")),(0,a.kt)("p",null,"Of the above you can delete the ",(0,a.kt)("inlineCode",{parentName:"p"},"ListItemProps")," type and the associate ",(0,a.kt)("inlineCode",{parentName:"p"},"RenderRow")," function. You won't need them again! There's no longer a need to pass down data to the child element and then extract it for usage; it all comes down into a single simpler component."),(0,a.kt)("p",null,"Replace the ",(0,a.kt)("inlineCode",{parentName:"p"},"ImportantDataList")," component with this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const ImportantDataList: React.FC<ImportantDataListProps> = React.memo(\n  (props) => {\n    const parentRef = React.useRef<HTMLDivElement>(null);\n\n    const rowVirtualizer = useVirtual({\n      size: props.importants.length,\n      parentRef,\n      estimateSize: React.useCallback(() => 80, []), // This is just a best guess\n      overscan: 5,\n    });\n\n    return (\n      <div\n        ref={parentRef}\n        style={{\n          width: `100%`,\n          height: `500px`,\n          overflow: 'auto',\n        }}\n      >\n        <div\n          style={{\n            height: `${rowVirtualizer.totalSize}px`,\n            width: '100%',\n            position: 'relative',\n          }}\n        >\n          {rowVirtualizer.virtualItems.map((virtualRow) => (\n            <div\n              key={virtualRow.index}\n              ref={virtualRow.measureRef}\n              className={props.classes.hoverRow}\n              style={{\n                position: 'absolute',\n                top: 0,\n                left: 0,\n                width: '100%',\n                height: `${virtualRow.size}px`,\n                transform: `translateY(${virtualRow.start}px)`,\n              }}\n            >\n              <ImportantThing\n                classes={props.classes}\n                important={props.importants[virtualRow.index]}\n              />\n            </div>\n          ))}\n        </div>\n      </div>\n    );\n  }\n);\n")),(0,a.kt)("p",null,"And you are done! Thanks Tanner for this tremendous library!"))}d.isMDXComponent=!0},43206:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"autofac-webapplicationfactory-integration-tests",title:"Autofac, WebApplicationFactory and integration tests",authors:"johnnyreilly",tags:["autofac","ASP.Net Core","Integration Testing"],image:"./autofac-webapplicationfactory-tests.webp",hide_table_of_contents:!1},s=void 0,l={permalink:"/autofac-webapplicationfactory-integration-tests",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-05-21-autofac-webapplicationfactory-integration-tests/index.md",source:"@site/blog/2020-05-21-autofac-webapplicationfactory-integration-tests/index.md",title:"Autofac, WebApplicationFactory and integration tests",description:"Updated 2nd Oct 2020: for an approach that works with Autofac 6 and ConfigureTestContainer see this post.",date:"2020-05-21T00:00:00.000Z",formattedDate:"May 21, 2020",tags:[{label:"autofac",permalink:"/tags/autofac"},{label:"ASP.Net Core",permalink:"/tags/asp-net-core"},{label:"Integration Testing",permalink:"/tags/integration-testing"}],readingTime:3.565,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"autofac-webapplicationfactory-integration-tests",title:"Autofac, WebApplicationFactory and integration tests",authors:"johnnyreilly",tags:["autofac","ASP.Net Core","Integration Testing"],image:"./autofac-webapplicationfactory-tests.webp",hide_table_of_contents:!1},prevItem:{title:"Task.WhenAll / Select is a footgun \ud83d\udc5f\ud83d\udd2b",permalink:"/taskwhenall-select-is-footgun"},nextItem:{title:"From react-window to react-virtual",permalink:"/from-react-window-to-react-virtual"}},p={image:n(17806).Z,authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Updated 2nd Oct 2020:")," ",(0,a.kt)("em",{parentName:"p"},"for an approach that works with Autofac 6 and ",(0,a.kt)("inlineCode",{parentName:"em"},"ConfigureTestContainer")," see ",(0,a.kt)("a",o({parentName:"em"},{href:"/autofac-6-integration-tests-and-generic-hosting"}),"this post"),".")),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"A title image for the blog featuring the Autofac logo",src:n(17806).Z,width:"1170",height:"502"})),(0,a.kt)("p",null,"This is one of those occasions where I'm not writing up my own work so much as my discovery after in depth googling."),(0,a.kt)("p",null,"Integration tests with ASP.NET Core are the best. They spin up an in memory version of your application and let you fire requests at it. They've gone through a number of iterations since ASP.NET Core has been around. You may also be familiar with the ",(0,a.kt)("inlineCode",{parentName:"p"},"TestServer")," approach of earlier versions. For some time, the advised approach has been using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/aspnet/core/test/integration-tests?view=aspnetcore-3.1#basic-tests-with-the-default-webapplicationfactory"}),(0,a.kt)("inlineCode",{parentName:"a"},"WebApplicationFactory")),"."),(0,a.kt)("p",null,"What makes this approach particularly useful / powerful is that you can swap out dependencies of your running app with fakes / stubs etc. Just like unit tests! But potentially more useful because they run your whole app and hence give you a greater degree of confidence. What does this mean? Well, imagine you changed a piece of middleware in your application; this could potentially break functionality. Unit tests would probably not reveal this. Integration tests would."),(0,a.kt)("p",null,"There is a fly in the ointment. A hair in the gazpacho. ASP.NET Core ships with dependency injection in the box. It has its own Inversion of Control container which is perfectly fine. However, many people are accustomed to using other IOC containers such as ",(0,a.kt)("a",o({parentName:"p"},{href:"https://autofac.org/"}),"Autofac"),"."),(0,a.kt)("p",null,"What's the problem? Well, swapping out dependencies registered using ASP.NET Core's IOC requires using a hook called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/aspnet/core/test/integration-tests?view=aspnetcore-3.1#inject-mock-services"}),(0,a.kt)("inlineCode",{parentName:"a"},"ConfigureTestServices")),". There's an equivalent hook for swapping out services registered using a custom IOC container: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.testhost.webhostbuilderextensions.configuretestcontainer?view=aspnetcore-3.0"}),(0,a.kt)("inlineCode",{parentName:"a"},"ConfigureTestContainer")),". Unfortunately, there is a bug in ASP.NET Core as of version 3.0: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dotnet/aspnetcore/issues/14907"}),"When using GenericHost, in tests ",(0,a.kt)("inlineCode",{parentName:"a"},"ConfigureTestContainer")," is not executed")),(0,a.kt)("p",null,"This means you cannot swap out dependencies that have been registered with Autofac and the like. According to the tremendous ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.twitter.com/davidfowl"}),"David Fowler")," of the ASP.NET team, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dotnet/aspnetcore/issues/14907#issuecomment-592102145"}),"this will hopefully be resolved"),"."),(0,a.kt)("p",null,"In the meantime, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dotnet/aspnetcore/issues/14907#issuecomment-620750841"}),"there's a workaround thanks to various commenters on the thread"),". Instead of using ",(0,a.kt)("inlineCode",{parentName:"p"},"WebApplicationFactory")," directly, subclass it and create a custom ",(0,a.kt)("inlineCode",{parentName:"p"},"AutofacWebApplicationFactory")," (the name is not important). This custom class overrides the behavior of ",(0,a.kt)("inlineCode",{parentName:"p"},"ConfigureServices")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"CreateHost")," with a ",(0,a.kt)("inlineCode",{parentName:"p"},"CustomServiceProviderFactory"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'namespace My.Web.Tests.Helpers {\n    /// <summary>\n    /// Based upon https://github.com/dotnet/AspNetCore.Docs/tree/master/aspnetcore/test/integration-tests/samples/3.x/IntegrationTestsSample\n    /// </summary>\n    /// <typeparam name="TStartup"></typeparam>\n    public class AutofacWebApplicationFactory<TStartup> : WebApplicationFactory<TStartup> where TStartup : class {\n        protected override void ConfigureWebHost(IWebHostBuilder builder) {\n            builder.ConfigureServices(services => {\n                    services.AddSingleton<IAuthorizationHandler>(new PassThroughPermissionedRolesHandler());\n                })\n                .ConfigureTestServices(services => {\n                }).ConfigureTestContainer<Autofac.ContainerBuilder>(builder => {\n                    // called after Startup.ConfigureContainer\n                });\n        }\n\n        protected override IHost CreateHost(IHostBuilder builder) {\n            builder.UseServiceProviderFactory(new CustomServiceProviderFactory());\n            return base.CreateHost(builder);\n        }\n    }\n\n    /// <summary>\n    /// Based upon https://github.com/dotnet/aspnetcore/issues/14907#issuecomment-620750841 - only necessary because of an issue in ASP.NET Core\n    /// </summary>\n    public class CustomServiceProviderFactory : IServiceProviderFactory<CustomContainerBuilder> {\n        public CustomContainerBuilder CreateBuilder(IServiceCollection services) => new CustomContainerBuilder(services);\n\n        public IServiceProvider CreateServiceProvider(CustomContainerBuilder containerBuilder) =>\n        new AutofacServiceProvider(containerBuilder.CustomBuild());\n    }\n\n    public class CustomContainerBuilder : Autofac.ContainerBuilder {\n        private readonly IServiceCollection services;\n\n        public CustomContainerBuilder(IServiceCollection services) {\n            this.services = services;\n            this.Populate(services);\n        }\n\n        public Autofac.IContainer CustomBuild() {\n            var sp = this.services.BuildServiceProvider();\n#pragma warning disable CS0612 // Type or member is obsolete\n            var filters = sp.GetRequiredService<IEnumerable<IStartupConfigureContainerFilter<Autofac.ContainerBuilder>>>();\n#pragma warning restore CS0612 // Type or member is obsolete\n\n            foreach (var filter in filters) {\n                filter.ConfigureContainer(b => { }) (this);\n            }\n\n            return this.Build();\n        }\n    }\n}\n')),(0,a.kt)("p",null,"I'm going to level with you; I don't understand all of this code. I'm not au fait with the inner workings of ASP.NET Core or Autofac but I can tell you what this allows. With this custom ",(0,a.kt)("inlineCode",{parentName:"p"},"WebApplicationFactory")," in play you get ",(0,a.kt)("inlineCode",{parentName:"p"},"ConfigureTestContainer")," back in the mix! You get to write code like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Net;\nusing System.Net.Http.Headers;\nusing System.Threading.Tasks;\nusing FakeItEasy;\nusing FluentAssertions;\nusing Microsoft.AspNetCore.TestHost;\nusing Microsoft.Extensions.DependencyInjection;\nusing Xunit;\nusing Microsoft.Extensions.Options;\nusing Autofac;\nusing System.Net.Http;\nusing Newtonsoft.Json;\n\nnamespace My.Web.Tests.Controllers\n{\n    public class MyControllerTests : IClassFixture<AutofacWebApplicationFactory<My.Web.Startup>> {\n        private readonly AutofacWebApplicationFactory<My.Web.Startup> _factory;\n\n        public MyControllerTests(\n            AutofacWebApplicationFactory<My.Web.Startup> factory\n        ) {\n            _factory = factory;\n        }\n\n        [Fact]\n        public async Task My() {\n            var fakeSomethingService = A.Fake<IMySomethingService>();\n            var fakeConfig = Options.Create(new MyConfiguration {\n                SomeConfig = "Important thing",\n                OtherConfigMaybeAnEmailAddress = "johnny_reilly@hotmail.com"\n            });\n\n            A.CallTo(() => fakeSomethingService.DoSomething(A<string>.Ignored))\n                .Returns(Task.FromResult(true));\n\n            void ConfigureTestServices(IServiceCollection services) {\n                services.AddSingleton(fakeConfig);\n            }\n\n            void ConfigureTestContainer(ContainerBuilder builder) {\n                builder.RegisterInstance(fakeSomethingService);\n            }\n\n            var client = _factory\n                .WithWebHostBuilder(builder => {\n                    builder.ConfigureTestServices(ConfigureTestServices);\n                    builder.ConfigureTestContainer<Autofac.ContainerBuilder>(ConfigureTestContainer);\n                })\n                .CreateClient();\n\n            // Act\n            var request = StringContent("{\\"sommat\\":\\"to see\\"}");\n            request.Headers.ContentType = MediaTypeHeaderValue.Parse("application/json");\n            var response = await client.PostAsync("/something/submit", request);\n\n            // Assert\n            response.StatusCode.Should().Be(HttpStatusCode.OK);\n\n            A.CallTo(() => fakeSomethingService.DoSomething(A<string>.Ignored))\n                .MustHaveHappened();\n        }\n\n    }\n}\n')))}d.isMDXComponent=!0},19886:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"taskwhenall-select-is-footgun",title:"Task.WhenAll / Select is a footgun \ud83d\udc5f\ud83d\udd2b",authors:"johnnyreilly",tags:["C#","LINQ"],hide_table_of_contents:!1},s=void 0,l={permalink:"/taskwhenall-select-is-footgun",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-06-21-taskwhenall-select-is-footgun/index.md",source:"@site/blog/2020-06-21-taskwhenall-select-is-footgun/index.md",title:"Task.WhenAll / Select is a footgun \ud83d\udc5f\ud83d\udd2b",description:'This post differs from my typical fayre. Most often I write "here\'s how to do a thing". This is not that. It\'s more "don\'t do this thing I did". And maybe also, "how can we avoid a situation like this happening again in future?". On this topic I very much don\'t have all the answers - but by putting my thoughts down maybe I\'ll learn and maybe others will educate me. I would love that!',date:"2020-06-21T00:00:00.000Z",formattedDate:"June 21, 2020",tags:[{label:"C#",permalink:"/tags/c"},{label:"LINQ",permalink:"/tags/linq"}],readingTime:5.975,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"taskwhenall-select-is-footgun",title:"Task.WhenAll / Select is a footgun \ud83d\udc5f\ud83d\udd2b",authors:"johnnyreilly",tags:["C#","LINQ"],hide_table_of_contents:!1},prevItem:{title:"Devcontainers and SSL interception",permalink:"/devcontainers-and-ssl-interception"},nextItem:{title:"Autofac, WebApplicationFactory and integration tests",permalink:"/autofac-webapplicationfactory-integration-tests"}},p={authorsImageUrls:[void 0]},u=[{value:"Doing things that don&#39;t scale",id:"doing-things-that-dont-scale",level:2},{value:"So cool, so terrible",id:"so-cool-so-terrible",level:2},{value:"What is the problem?",id:"what-is-the-problem",level:2},{value:"What will we change in future?",id:"what-will-we-change-in-future",level:2},{value:"What did we do right now?",id:"what-did-we-do-right-now",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'This post differs from my typical fayre. Most often I write "here\'s how to do a thing". This is not that. It\'s more "don\'t do this thing I did". And maybe also, "how can we avoid a situation like this happening again in future?". On this topic I very much don\'t have all the answers - but by putting my thoughts down maybe I\'ll learn and maybe others will educate me. I would love that!'),(0,a.kt)("h2",o({},{id:"doing-things-that-dont-scale"}),"Doing things that don't scale"),(0,a.kt)("p",null,"The platform that I work on once had zero users. We used to beg people to log in and see what we had built. Those days are (happily) but a memory. We're getting popular."),(0,a.kt)("p",null,"As our platform has grown in popularity it has revealed some bad choices we made. Approaches that look fine on the surface (and that work just dandy when you have no users) may start to cause problems as your number of users grows."),(0,a.kt)("p",null,'I wanted to draw attention to one approach in particular that impacted us severely. In this case "impacted us severely" is a euphemism for "brought the site down and caused a critical incident".'),(0,a.kt)("p",null,"You don't want this to happen to you. Trust me. So, what follows is a cautionary tale. The purpose of which is simply this: reader, do you have code of this ilk in your codebase? If you do: out, damn'd spot! out, I say!"),(0,a.kt)("h2",o({},{id:"so-cool-so-terrible"}),"So cool, so terrible"),(0,a.kt)("p",null,"I love LINQ. I love a declarative / functional style of coding. It appeals to me on some gut level. I find it tremendously readable. Read any C# of mine and the odds are pretty good that you'll find some LINQ in the mix."),(0,a.kt)("p",null,"Imagine this scenario: you have a collection of user ids. You want to load the details of each user represented by their id from an API. You want to bag up all of those users into some kind of collection and send it back to the calling code."),(0,a.kt)("p",null,"Reading that, if you're like me, you're imagining some kind of map operation which loads the user details for each user id. Something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"var users = userIds.Select(userId => GetUserDetails(userId)).ToArray(); // users is User[]\n")),(0,a.kt)("p",null,"Lovely. But you'll note that I'm loading users from an API. Oftentimes, APIs are asynchronous. Certainly, in my case they were. So rather than calling a ",(0,a.kt)("inlineCode",{parentName:"p"},"GetUserDetails")," function I found myself calling a ",(0,a.kt)("inlineCode",{parentName:"p"},"GetUserDetailsAsync")," function, behind which an HTTP request is being sent and, later, a response is being returned."),(0,a.kt)("p",null,"So how do we deal with this? ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.task.whenall?view=netcore-3.1#System_Threading_Tasks_Task_WhenAll__1_System_Collections_Generic_IEnumerable_System_Threading_Tasks_Task___0___"}),(0,a.kt)("inlineCode",{parentName:"a"},"Task.WhenAll"))," my friends!"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"var userTasks = userIds.Select(userId => GetUserDetailsAsync(userId));\nvar users = await Task.WhenAll(tasks); // users is User[]\n")),(0,a.kt)("p",null,"It worked great! Right up until to the point where it didn't. These sorts of shenanigans were fine when we had a minimal number of users... But there came a point where problems arose. It got to the point where that simple looking mapping operation became a cause of many, many, ",(0,a.kt)("em",{parentName:"p"},"many")," HTTP requests being fired concurrently. Then bad things started to happen. Not only did we realise we were launching a denial of service attack on the API we were consuming, we were bringing our own application to collapse."),(0,a.kt)("p",null,"Not a proud day."),(0,a.kt)("h2",o({},{id:"what-is-the-problem"}),"What is the problem?"),(0,a.kt)("p",null,"Through log analysis, code reading and speculation, (with the help of the invaluable ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.linkedin.com/in/robert-grzankowski-53618114"}),"Robski"),") we came to realise that the cause of our woes was the ",(0,a.kt)("inlineCode",{parentName:"p"},"Task.WhenAll")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"Select")," combination. Exercising that codepath was a surefire way to bring the application to its knees."),(0,a.kt)("p",null,"As I read around on the topic I happened upon ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.twitter.com/mark_heath"}),"Mark Heath"),"'s excellent list of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://markheath.net/post/async-antipatterns"}),"Async antipatterns"),'. Number #6 on the list is "Excessive parallelization". It describes a nearly identical scenario to my own:'),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},'Now, this does "work", but what if there were 10,000 orders? We\'ve flooded the thread pool with thousands of tasks, potentially preventing other useful work from completing. If ',(0,a.kt)("inlineCode",{parentName:"p"},"ProcessOrderAsync")," makes downstream calls to another service like a database or a microservice, we'll potentially overload that with too high a volume of calls.")),(0,a.kt)("p",null,"We're definitely overloading the API we're consuming with too high a volume of calls. I have to admit that I'm less clear on the direct reason that a ",(0,a.kt)("inlineCode",{parentName:"p"},"Task.WhenAll")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"Select")," combination could prove fatal to our application. Mark suggests this approach will flood the thread pool with tasks. As I read around on ",(0,a.kt)("inlineCode",{parentName:"p"},"async")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"await")," it's repeated again and again that a ",(0,a.kt)("inlineCode",{parentName:"p"},"Task")," is not the same thing as a ",(0,a.kt)("inlineCode",{parentName:"p"},"Thread"),". I have to hold my hands up here and say that I don't understand the implementation of ",(0,a.kt)("inlineCode",{parentName:"p"},"async")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"await")," in C# well enough. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/standard/async-in-depth#deeper-dive-into-tasks-for-an-io-bound-operation"}),"These docs are helpful but I still don't think the penny has fully dropped for me yet.")," I will continue to read."),(0,a.kt)("p",null,"One thing we learned as we debugged the production k8s pod was that, prior to its collapse, our app appeared to be opening up 1 million connections to the API we were consuming. Which seemed a bit much. Worthy of investigation. It's worth saying that we're not certain this is exactly what is happening; we have less instrumentation in place than we'd like. But some fancy wc grepping on Robski's behalf suggested this was the case."),(0,a.kt)("h2",o({},{id:"what-will-we-change-in-future"}),"What will we change in future?"),(0,a.kt)("p",null,"A learning that came out of this for us was this: we need more metrics exposed. We don't understand our application's behaviour under load as well as we'd like. So we're planning to do some work with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.app-metrics.io/"}),"App Metrics")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://grafana.com/"}),"Grafana")," so we've a better idea of how our application performs. If you want to improve something, first measure it."),(0,a.kt)("p",null,"Another fly in the ointment was that we were unable to reproduce the issue when running locally. It's worth saying here that I develop on a Windows machine and, when deployed, our application runs in a (Linux) Docker container. So there's a difference and a distance between our development experience and our running one."),(0,a.kt)("p",null,"I'm planning to migrate to developing in a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://code.visualstudio.com/docs/remote/containers"}),"devcontainer")," where that's possible. That should narrow the gap between our production experience and our development one. Reducing the difference between the two is always useful as it means you're less likely to get different behaviour (ie \"problems\") in production as compared to development. I'm curious as to whether I'll be able to replicate that behaviour in a devcontainer."),(0,a.kt)("h2",o({},{id:"what-did-we-do-right-now"}),"What did we do right now?"),(0,a.kt)("p",null,"To solve the immediate issue we were able to pivot away to a completely different approach. We moved aggregation from our ASP.NET Core web application to our TypeScript / React client with a (pretty sweet) custom hook. The topic for a subsequent blog post."),(0,a.kt)("p",null,"Moving to a different approach solved my immediate issue. But it left me puzzling. What was actually going wrong? Is it thread pool exhaustion? Is it something else? So many possibilities!"),(0,a.kt)("p",null,"If anyone has any insights they'd like to share that would be incredible! I've also ",(0,a.kt)("a",o({parentName:"p"},{href:"https://stackoverflow.com/questions/62490098/task-whenall-with-select-is-a-footgun-but-why/62490705"}),"asked a question on Stack Overflow")," which has kindly had answers from generous souls. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/jamesskimming"}),"James Skimming"),"'s answer lead me to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.stevejgordon.co.uk/httpclient-connection-pooling-in-dotnet-core"}),"Steve Gordon's excellent post on connection pooling")," which I'm still absorbing and seems like it could be relevant."))}d.isMDXComponent=!0},68994:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"devcontainers-and-ssl-interception",title:"Devcontainers and SSL interception",authors:"johnnyreilly",tags:["devcontainer","ssl interception"],hide_table_of_contents:!1},s=void 0,l={permalink:"/devcontainers-and-ssl-interception",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-07-11-devcontainers-and-ssl-interception/index.md",source:"@site/blog/2020-07-11-devcontainers-and-ssl-interception/index.md",title:"Devcontainers and SSL interception",description:"Devcontainers are cool. They are the infrastructure as code equivalent for developing software.",date:"2020-07-11T00:00:00.000Z",formattedDate:"July 11, 2020",tags:[{label:"devcontainer",permalink:"/tags/devcontainer"},{label:"ssl interception",permalink:"/tags/ssl-interception"}],readingTime:3.225,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"devcontainers-and-ssl-interception",title:"Devcontainers and SSL interception",authors:"johnnyreilly",tags:["devcontainer","ssl interception"],hide_table_of_contents:!1},prevItem:{title:"Devcontainers AKA performance in a secure sandbox",permalink:"/devcontainers-aka-performance-in-secure"},nextItem:{title:"Task.WhenAll / Select is a footgun \ud83d\udc5f\ud83d\udd2b",permalink:"/taskwhenall-select-is-footgun"}},p={authorsImageUrls:[void 0]},u=[{value:"Certificates: I&#39;m starting with the man in the middle",id:"certificates-im-starting-with-the-man-in-the-middle",level:2},{value:"&quot;Devcontainers don&#39;t work at work!&quot;",id:"devcontainers-dont-work-at-work",level:2},{value:"Devcontainer + MITM cert = working",id:"devcontainer--mitm-cert--working",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://code.visualstudio.com/docs/remote/containers"}),"Devcontainers")," are cool. They are the infrastructure as code equivalent for developing software."),(0,a.kt)("p",null,"Imagine your new starter joins the team, you'd like them to be contributing code on ",(0,a.kt)("em",{parentName:"p"},"day 1"),". But if the first thing that happens is you hand them a sheaf of paper upon which are the instructions for how to get their machines set up for development, well, maybe it's going to be a while. But if your project has a devcontainer then you're off to the races. One trusty ",(0,a.kt)("inlineCode",{parentName:"p"},"git clone"),", fire up VS Code and they can get going."),(0,a.kt)("p",null,"That's the dream right?"),(0,a.kt)("p",null,"I've recently been doing some work getting a project I work on set up with a devcontainer. As I've worked on that I've become aware of some of the hurdles that might hamper your adoption of devcontainers in a corporate environment."),(0,a.kt)("h2",o({},{id:"certificates-im-starting-with-the-man-in-the-middle"}),"Certificates: I'm starting with the man in the middle"),(0,a.kt)("p",null,"It is a common practice in company networks to perform ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.citrix.com/en-us/citrix-adc/13/forward-proxy/ssl-interception.html"}),"SSL interception"),". Not SSL inception; that'd be more fun."),(0,a.kt)("iframe",{src:"https://giphy.com/embed/l7JDTHpsXM26k",width:"100%",height:"100%",frameBorder:"0",allowFullScreen:""}),(0,a.kt)("p",null,"SSL interception is the practice of installing a \"man-in-the-middle\" (MITM) CA certificate on users machines. When SSL traffic takes place from a users machine, it goes through a proxy. That proxy performs the SSL on behalf of that user and, if it's happy, supplies another certificate back to the users machine which satisfies the MITM CA certificate. So rather than seeing, for example, Google's certificate from ",(0,a.kt)("a",o({parentName:"p"},{href:"https://google.com"}),"https://google.com")," you'd see the one resulting from the SSL interception. You can read more ",(0,a.kt)("a",o({parentName:"p"},{href:"https://security.stackexchange.com/questions/107542/is-it-common-practice-for-companies-to-mitm-https-traffic"}),"here"),"."),(0,a.kt)("p",null,"Now this is a little known and less understood practice. I barely understand it myself. Certificates are ",(0,a.kt)("em",{parentName:"p"},"hard"),". Even having read the above you may be none the wiser about why this is relevant. Let's get to the broken stuff."),(0,a.kt)("h2",o({},{id:"devcontainers-dont-work-at-work"}),'"Devcontainers don\'t work at work!"'),(0,a.kt)("p",null,"So, you're ready to get going with your first devcontainer. You fire up the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/vscode-dev-containers"}),"vscode-dev-containers")," repo and find the container that's going to work for you. Copy pasta the ",(0,a.kt)("inlineCode",{parentName:"p"},".devcontainer")," into your repo, install the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack"}),"Remote Development")," extension into VS Code and enter the ",(0,a.kt)("inlineCode",{parentName:"p"},"Remote-Containers: Reopen Folder in Container"),". Here comes the future!"),(0,a.kt)("p",null,"But when it comes to performing SSL inside the devcontainer, trouble awaits. Here's what a ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn install")," results in:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'yarn install v1.22.4\n[1/4] Resolving packages...\n[2/4] Fetching packages...\nerror An unexpected error occurred: "https://registry.yarnpkg.com/@octokit/core/-/core-2.5.0.tgz: self signed certificate in certificate chain".\n')),(0,a.kt)("p",null,"Oh no!"),(0,a.kt)("p",null,"Gosh but it's okay - you're just bumping on the SSL interception. Why though? Well it's like this: when you fire up your devcontainer it builds a new Docker container. It's as well to imagine the container as a virtual operating system. So what's the difference between this operating system and the one our machine is running? Well a number of things, but crucially our host operating system has the MITM CA certificate installed. So when we SSL, we have the certificate that will match up with what the proxy sends back to us certificate-wise. And inside our trusty devcontainer we don't have that. Hence the sadness."),(0,a.kt)("h2",o({},{id:"devcontainer--mitm-cert--working"}),"Devcontainer + MITM cert = working"),(0,a.kt)("p",null,"We need to do two things to get this working:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Acquire the requisite CA certificate(s) from your friendly neighbourhood networking team. Place them in a ",(0,a.kt)("inlineCode",{parentName:"li"},"certs")," folder inside your repo, in the ",(0,a.kt)("inlineCode",{parentName:"li"},".devcontainer")," folder."),(0,a.kt)("li",{parentName:"ol"},"Add the following lines to your ",(0,a.kt)("inlineCode",{parentName:"li"},".devcontainer/Dockerfile"),", just after the initial ",(0,a.kt)("inlineCode",{parentName:"li"},"FROM")," statement:")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"# Because MITM certificates\nCOPY certs/. /usr/local/share/ca-certificates/\nENV NODE_EXTRA_CA_CERTS=/usr/local/share/ca-certificates/mitm.pem\nRUN update-ca-certificates\n")),(0,a.kt)("p",null,"Which does the following:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Copies the certs into the devcontainer"),(0,a.kt)("li",{parentName:"ul"},"This is a Node example and so we set an environment variable called ",(0,a.kt)("a",o({parentName:"li"},{href:"https://nodejs.org/api/cli.html#cli_node_extra_ca_certs_file"}),(0,a.kt)("inlineCode",{parentName:"a"},"NODE_EXTRA_CA_CERTS"))," which points to the path of your MITM CA certificate file inside your devcontainer."),(0,a.kt)("li",{parentName:"ul"},"updates the directory ",(0,a.kt)("inlineCode",{parentName:"li"},"/etc/ssl/certs")," to hold SSL certificates and generates ",(0,a.kt)("inlineCode",{parentName:"li"},"ca-certificates.crt"))),(0,a.kt)("p",null,"With these in place then you should be able to build your devcontainer with no SSL trauma. Enjoy!"))}d.isMDXComponent=!0},75124:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"devcontainers-aka-performance-in-secure",title:"Devcontainers AKA performance in a secure sandbox",authors:"johnnyreilly",tags:["devcontainer"],hide_table_of_contents:!1},s=void 0,l={permalink:"/devcontainers-aka-performance-in-secure",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-08-09-devcontainers-aka-performance-in-secure/index.md",source:"@site/blog/2020-08-09-devcontainers-aka-performance-in-secure/index.md",title:"Devcontainers AKA performance in a secure sandbox",description:"Many corporate machines arrive in engineers hands with a preponderance of pre-installed background tools; from virus checkers to backup utilities to port blockers; the list is long.",date:"2020-08-09T00:00:00.000Z",formattedDate:"August 9, 2020",tags:[{label:"devcontainer",permalink:"/tags/devcontainer"}],readingTime:6.545,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"devcontainers-aka-performance-in-secure",title:"Devcontainers AKA performance in a secure sandbox",authors:"johnnyreilly",tags:["devcontainer"],hide_table_of_contents:!1},prevItem:{title:"Why your team needs a newsfeed",permalink:"/why-your-team-needs-newsfeed"},nextItem:{title:"Devcontainers and SSL interception",permalink:"/devcontainers-and-ssl-interception"}},p={authorsImageUrls:[void 0]},u=[{value:"&quot;Hide from the virus checkers*** in a devcontainer&quot;",id:"hide-from-the-virus-checkers-in-a-devcontainer",level:2},{value:"Make me a devcontainer...",id:"make-me-a-devcontainer",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Many corporate machines arrive in engineers hands with a preponderance of pre-installed background tools; from virus checkers to backup utilities to port blockers; the list is long."),(0,a.kt)("p",null,"The reason that these tools are installed is generally noble. However, the implementation can often be problematic. The tools may be set up in such a way as they impact and interfere with one another. Really powerful machines with 8 CPUs and hardy SSDs can be slowed to a crawl. Put simply: the good people responsible for ensuring security are rarely encouraged to incentivise performance alongside it. And so don't."),(0,a.kt)("p",null,"The unfortunate consequence of considering the role of security without regard to performance is this: sluggish computers. The further consequence (and this is the one I want you to think long and hard about) is ",(0,a.kt)("em",{parentName:"p"},"low developer productivity"),". And that sucks. It impacts what an organisation is able to do, how fast an organisation is able to move. Put simply: it can be the difference between success and failure."),(0,a.kt)("p",null,"The most secure computer is off. But you won't ship much with it. Encouraging your organisation to consider tackling security with performance in mind is worthwhile. It's a long game though. In the meantime what can we do?"),(0,a.kt)("h2",o({},{id:"hide-from-the-virus-checkers-in-a-devcontainer"}),'"Hide from the virus checkers',"*","*","*",' in a devcontainer"'),(0,a.kt)("p",null,"Devcontainers, the infrastructure as code equivalent for developing software, have an underappreciated quality: unlocking your machine's performance."),(0,a.kt)("p",null,"Devcontainers are isolated secure sandboxes in which you can build software. To quote the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://code.visualstudio.com/docs/remote/containers"}),"docs"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"A ",(0,a.kt)("inlineCode",{parentName:"p"},"devcontainer.json")," file in your project tells VS Code how to access (or create) a development container with a well-defined tool and runtime stack. This container can be used to run an application or to sandbox tools, libraries, or runtimes needed for working with a codebase."),(0,a.kt)("p",{parentName:"blockquote"},"Workspace files are mounted from the local file system or copied or ",(0,a.kt)("em",{parentName:"p"},"cloned into the container"),".")),(0,a.kt)("p",null,"We're going to set up a devcontainer to code an ASP.NET Core application with a JavaScript (well TypeScript) front end. If there's one thing that's sure to catch a virus checkers beady eye, it's ",(0,a.kt)("inlineCode",{parentName:"p"},"node_modules"),". ",(0,a.kt)("inlineCode",{parentName:"p"},"node_modules")," contains more files than a black hole has mass. Consider a project with 5,000 source files. One trusty ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn")," later and the folder now has a tidy 250,000 files. The virus checker is now really sitting up and taking notice."),(0,a.kt)("p",null,"Our project has a ",(0,a.kt)("inlineCode",{parentName:"p"},"git commit")," hook set up with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/typicode/husky"}),"Husky")," that formats our TypeScript files with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://prettier.io/"}),"Prettier"),". Every commit the files are formatted to align with the project standard. With all the virus checkers in place a ",(0,a.kt)("inlineCode",{parentName:"p"},"git commit")," takes around 45 seconds. Inside a devcontainer we can drop this to 5 seconds. That's nine times faster. I'll repeat that: that's ",(0,a.kt)("strong",{parentName:"p"},"nine times faster"),"!"),(0,a.kt)("p",null,"The \"cloned into a container\" above is key to what we're going to do. We're ",(0,a.kt)("em",{parentName:"p"},"not")," going to mount our local file system into the devcontainer. Oh no. We're going to build a devcontainer with ASP.NET CORE and JavaScript in. Then, inside there, we're going to clone our repo. Then we can develop, build and debug all inside the container. It will feel like we're working on our own machine because VS Code does such a damn fine job. In reality, we're connecting to another computer (a Linux computer to boot) that is running in isolation to our own. In our case that machine is sharing our hardware; but that's just an implementation detail. It could be anywhere (and in the future may well be)."),(0,a.kt)("h2",o({},{id:"make-me-a-devcontainer"}),"Make me a devcontainer..."),(0,a.kt)("p",null,"Enough talk... We're going to need a ",(0,a.kt)("inlineCode",{parentName:"p"},".devcontainer/devcontainer.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "name": "my devcontainer",\n  "dockerComposeFile": "../docker-compose.devcontainer.yml",\n  "service": "my-devcontainer",\n  "workspaceFolder": "/workspace",\n\n  // Set *default* container specific settings.json values on container create.\n  "settings": {\n    "terminal.integrated.shell.linux": "/bin/zsh"\n  },\n\n  // Add the IDs of extensions you want installed when the container is created.\n  "extensions": [\n    "ms-dotnettools.csharp",\n    "dbaeumer.vscode-eslint",\n    "esbenp.prettier-vscode",\n    "ms-mssql.mssql",\n    "eamodio.gitlens",\n    "ms-azuretools.vscode-docker",\n    "k--kato.docomment",\n    "Leopotam.csharpfixformat"\n  ],\n\n  // Use \'postCreateCommand\' to clone the repo into the workspace folder when the devcontainer starts\n  // and copy in the .env file\n  "postCreateCommand": "git clone git@github.com:my-org/my-repo.git . && cp /.env /workspace/.env"\n\n  // "remoteUser": "vscode"\n}\n')),(0,a.kt)("p",null,"Now the ",(0,a.kt)("inlineCode",{parentName:"p"},"docker-compose.devcontainer.yml")," which lives in the root of the project. It provisions a SQL Server container (using the official image) and our devcontainer:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'version: "3.7"\nservices:\n  my-devcontainer:\n    image: my-devcontainer\n    build:\n      context: .\n      dockerfile: Dockerfile.devcontainer\n    command: /bin/zsh -c "while sleep 1000; do :; done"\n    volumes:\n      # mount .zshrc from home - make sure it doesn\'t contain Windows line endings\n      - ~/.zshrc:/root/.zshrc\n\n    # user: vscode\n    ports:\n      - "5000:5000"\n      - "8080:8080"\n    environment:\n      - CONNECTIONSTRINGS__MYDATABASECONNECTION\n    depends_on:\n      - db\n  db:\n    image: mcr.microsoft.com/mssql/server:2019-latest\n    privileged: true\n    ports:\n      - 1433:1433\n    environment:\n      SA_PASSWORD: "Your_password123"\n      ACCEPT_EULA: "Y"\n')),(0,a.kt)("p",null,"The devcontainer will be built with the ",(0,a.kt)("inlineCode",{parentName:"p"},"Dockerfile.devcontainer")," in the root of our repo. It relies upon your SSH keys and a ",(0,a.kt)("inlineCode",{parentName:"p"},".env")," file being available to be copied in:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'#-----------------------------------------------------------------------------------------------------------\n# Based upon: https://github.com/microsoft/vscode-dev-containers/tree/master/containers/dotnetcore\n#-----------------------------------------------------------------------------------------------------------\nARG VARIANT="3.1-bionic"\nFROM mcr.microsoft.com/dotnet/core/sdk:${VARIANT}\n\n# Because MITM certificates\nCOPY ./docker/certs/. /usr/local/share/ca-certificates/\nENV NODE_EXTRA_CA_CERTS=/usr/local/share/ca-certificates/mitm.pem\nRUN update-ca-certificates\n\n# This Dockerfile adds a non-root user with sudo access. Use the "remoteUser"\n# property in devcontainer.json to use it. On Linux, the container user\'s GID/UIDs\n# will be updated to match your local UID/GID (when using the dockerFile property).\n# See https://aka.ms/vscode-remote/containers/non-root-user for details.\nARG USERNAME=vscode\nARG USER_UID=1000\nARG USER_GID=$USER_UID\n\n# Options for common package install script\nARG INSTALL_ZSH="true"\nARG UPGRADE_PACKAGES="true"\nARG COMMON_SCRIPT_SOURCE="https://raw.githubusercontent.com/microsoft/vscode-dev-containers/master/script-library/common-debian.sh"\nARG COMMON_SCRIPT_SHA="dev-mode"\n\n# Settings for installing Node.js.\nARG INSTALL_NODE="true"\nARG NODE_SCRIPT_SOURCE="https://raw.githubusercontent.com/microsoft/vscode-dev-containers/master/script-library/node-debian.sh"\nARG NODE_SCRIPT_SHA="dev-mode"\n\n# ARG NODE_VERSION="lts/*"\nARG NODE_VERSION="14"\nENV NVM_DIR=/usr/local/share/nvm\n\n# Have nvm create a "current" symlink and add to path to work around https://github.com/microsoft/vscode-remote-release/issues/3224\nENV NVM_SYMLINK_CURRENT=true\nENV PATH=${NVM_DIR}/current/bin:${PATH}\n\n# Configure apt and install packages\nRUN apt-get update \\\n    && export DEBIAN_FRONTEND=noninteractive \\\n    #\n    # Verify git, common tools / libs installed, add/modify non-root user, optionally install zsh\n    && apt-get -y install --no-install-recommends curl ca-certificates 2>&1 \\\n    && curl -sSL ${COMMON_SCRIPT_SOURCE} -o /tmp/common-setup.sh \\\n    && ([ "${COMMON_SCRIPT_SHA}" = "dev-mode" ] || (echo "${COMMON_SCRIPT_SHA} */tmp/common-setup.sh" | sha256sum -c -)) \\\n    && /bin/bash /tmp/common-setup.sh "${INSTALL_ZSH}" "${USERNAME}" "${USER_UID}" "${USER_GID}" "${UPGRADE_PACKAGES}" \\\n    #\n    # Install Node.js\n    && curl -sSL ${NODE_SCRIPT_SOURCE} -o /tmp/node-setup.sh \\\n    && ([ "${NODE_SCRIPT_SHA}" = "dev-mode" ] || (echo "${COMMON_SCRIPT_SHA} */tmp/node-setup.sh" | sha256sum -c -)) \\\n    && /bin/bash /tmp/node-setup.sh "${NVM_DIR}" "${NODE_VERSION}" "${USERNAME}" \\\n    #\n    # Clean up\n    && apt-get autoremove -y \\\n    && apt-get clean -y \\\n    && rm -f /tmp/common-setup.sh /tmp/node-setup.sh \\\n    && rm -rf /var/lib/apt/lists/* \\\n    #\n    # Workspace\n    && mkdir workspace \\\n    && chown -R ${NONROOT_USER}:root workspace\n\n\n# Install Vim\nRUN apt-get update && apt-get install -y \\\n    vim \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Set up a timezone in the devcontainer - necessary for anything timezone dependent\nENV TZ=Europe/London\nRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone \\\n && apt-get update \\\n && apt-get install --no-install-recommends -y \\\n    apt-utils \\\n    tzdata  \\\n && apt-get autoremove -y \\\n && apt-get clean -y \\\n && rm -rf /var/lib/apt/lists/*\n\nENV DOTNET_RUNNING_IN_CONTAINER=true\n\n# Copy across SSH keys so you can git clone\nRUN mkdir /root/.ssh\nRUN chmod 700 /root/.ssh\n\nCOPY .ssh/id_rsa /root/.ssh\nRUN chmod 600 /root/.ssh/id_rsa\n\nCOPY .ssh/id_rsa.pub /root/.ssh\nRUN chmod 644 /root/.ssh/id_rsa.pub\n\nCOPY .ssh/known_hosts /root/.ssh\nRUN chmod 644 /root/.ssh/known_hosts\n\n# Disable initial git clone prompt\nRUN echo "StrictHostKeyChecking no" >> /etc/ssh/ssh_config\n\n# Copy across .env file so you can customise environment variables\n# This will be copied into the root of the repo post git clone\nCOPY .env /.env\nRUN chmod 644 /.env\n\n# Install dotnet entity framework tools\nRUN dotnet tool install dotnet-ef --tool-path /usr/local/bin --version 3.1.2\n')),(0,a.kt)("p",null,"With this devcontainer you're good to go for an ASP.NET Core / JavaScript developer setup that is blazing fast! Remember to fire up Docker and give it goodly access to the resources of your host machine. All the CPUs, lots of memory and all the performance that there ought to be."),(0,a.kt)("p",null,(0,a.kt)("em",{parentName:"p"},"*",' "virus checkers" is a euphemism here for all the background tools that may be running. It was that or calling them "we are legion"')))}d.isMDXComponent=!0},16968:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"why-your-team-needs-newsfeed",title:"Why your team needs a newsfeed",authors:"johnnyreilly",hide_table_of_contents:!1},s=void 0,l={permalink:"/why-your-team-needs-newsfeed",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-09-04-why-your-team-needs-newsfeed/index.md",source:"@site/blog/2020-09-04-why-your-team-needs-newsfeed/index.md",title:"Why your team needs a newsfeed",description:"I'm part of a team that builds an online platform. I'm often preoccupied by how to narrow the gap between our users and \"us\" - the people that build the platform. It's important we understand how people use and interact with what we've built. If we don't then we're liable to waste our time and energy building the wrong things. Or the wrong amount of the right things.",date:"2020-09-04T00:00:00.000Z",formattedDate:"September 4, 2020",tags:[],readingTime:4.995,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"why-your-team-needs-newsfeed",title:"Why your team needs a newsfeed",authors:"johnnyreilly",hide_table_of_contents:!1},prevItem:{title:"Autofac 6, integration tests and .NET generic hosting",permalink:"/autofac-6-integration-tests-and-generic-hosting"},nextItem:{title:"Devcontainers AKA performance in a secure sandbox",permalink:"/devcontainers-aka-performance-in-secure"}},p={authorsImageUrls:[void 0]},u=[{value:"How do you build a newsfeed?",id:"how-do-you-build-a-newsfeed",level:2},{value:"Implementation",id:"implementation",level:2},{value:"What&#39;s next?",id:"whats-next",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I'm part of a team that builds an online platform. I'm often preoccupied by how to narrow the gap between our users and \"us\" - the people that build the platform. It's important we understand how people use and interact with what we've built. If we don't then we're liable to waste our time and energy building the wrong things. Or the wrong amount of the right things."),(0,a.kt)("p",null,"On a recent holiday I spent a certain amount of time pondering how to narrow the gap between our user and us. We have lots of things that help us; we use various analytics tools like ",(0,a.kt)("a",o({parentName:"p"},{href:"https://mixpanel.com/"}),"mixpanel"),", we've got a mini analytics platform of our own, we have teams notifications that pop up client feedback and so on. They are all great, but they're somewhat disparate; they don't give us a clear insight as to who uses our platform and how they do so. The information is there, but it's tough to grok. It doesn't make for a joined up story."),(0,a.kt)("p",null,"Reaching around for how to solve this I had an idea: what if our platform had a newsfeed? The kind of thing that social media platforms the likes of Twitter and Facebook have used to great effect; a stream of mini-activities which show how the community interacts with the product. People logging in and browsing around, using features on the platform. If we could see this in near real time we'd be brought closer to our users; we'd have something that would help us have real empathy and understanding. We'd see our product as the stories of users interacting with it."),(0,a.kt)("h2",o({},{id:"how-do-you-build-a-newsfeed"}),"How do you build a newsfeed?"),(0,a.kt)("p",null,'This was an experiment that seemed worth pursuing. So I decided to build a proof of concept and see what happened. Now I intended to put the "M" into MVP with this; I went in with a number of intentional constraints:'),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"The news feed wouldn't auto update (users have the F5 key for that)"),(0,a.kt)("li",{parentName:"ol"},"We'd host the newsfeed in our own mini analytics platform (which is already used by the team to understand how people use the platform)"),(0,a.kt)("li",{parentName:"ol"},'News stories wouldn\'t be stored anywhere; we\'d generate them on the fly by querying various databases / APIs. The cost of this would be that our news stories wouldn\'t be "persistent"; you wouldn\'t be able to address them with a URL; there\'d be no way to build "like" or "share" functionality.')),(0,a.kt)("p",null,"All of the above constraints are, importantly, reversable decisions. If we want auto update it could be built later. If we want the newsfeed to live somewhere else we could move it. If we wanted news stories to be persisted then we could do that."),(0,a.kt)("h2",o({},{id:"implementation"}),"Implementation"),(0,a.kt)("p",null,"With these constraints in mind, I turned my attention to the implementation. I built a ",(0,a.kt)("inlineCode",{parentName:"p"},"NewsFeedService")," that would be queried for news stories. The interface I decided to build looked like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"NewsFeedService.getNewsFeed(from: Date, to: Date): NewsFeed\n\ntype NewsFeed {\n    startedAt: Date;\n    ended at: Date;\n    stories: NewsStory[];\n}\n\ntype NewsStory {\n    /** When the story happened */\n    happenedAt: Date;\n    /** A code that represents the type of story this is; eg USER_SESSION */\n    storyCode: string\n    /** The story details in markdown format */\n    story: string;\n}\n")),(0,a.kt)("p",null,"Each query to ",(0,a.kt)("inlineCode",{parentName:"p"},"NewsFeedService.getNewsFeed")," would query various databases / APIs related to our product, looking for interesting events. Whether it be users logging in, users performing some kind of action, whatever. For each interested event a news story like this would be produced:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Jane Smith logged in at 10:03am for 25 minutes. They placed ",(0,a.kt)("a",o({parentName:"p"},{href:"https://my-glorious-platform.io/orders/janes-order"}),"an order")," worth \xa33,000.")),(0,a.kt)("p",null,"Now the killer feature here is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Markdown#:~:text=Markdown%20is%20a%20lightweight%20markup,using%20a%20plain%20text%20editor."}),"Markdown"),". Our stories are written in Markdown. Why is Markdown cool? Well ",(0,a.kt)("a",o({parentName:"p"},{href:"https://web.archive.org/web/20040402182332/http://daringfireball.net/projects/markdown/"}),"to quote the creators of Markdown"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Markdown allows you to write using an easy-to-read, easy-to-write plain text format, then convert it to structurally valid XHTML (or HTML).")),(0,a.kt)("p",null,"This crucially includes the ability to include links. This was significant because I want us to be able to be able to click on pieces of information in the stories and be taken to the relevant place in the platform to see more details. Just as you see status updates on, for example, Twitter which lead you on to more details:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"This is the history of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/DefinitelyTyped?ref_src=twsrc%5Etfw"}),"@DefinitelyTyped"),": ",(0,a.kt)("a",o({parentName:"p"},{href:"https://t.co/AY6s3bWnKP"}),"https://t.co/AY6s3bWnKP")," Thanks to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/SeaRyanC?ref_src=twsrc%5Etfw"}),"@SeaRyanC")," & ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/drosenwasser?ref_src=twsrc%5Etfw"}),"@drosenwasser")," of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/typescript?ref_src=twsrc%5Etfw"}),"@typescript")," team, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/blakeembrey?ref_src=twsrc%5Etfw"}),"@blakeembrey")," inventor of typings, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/vvakame?ref_src=twsrc%5Etfw"}),"@vvakame"),", ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/_stevefenton?ref_src=twsrc%5Etfw"}),"@","_","stevefenton"),", ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/basarat?ref_src=twsrc%5Etfw"}),"@basarat"),", and of course ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/borisyankov?ref_src=twsrc%5Etfw"}),"@borisyankov")," for telling me their parts of the story\u2764\ufe0f\ud83c\udf3b"),(0,a.kt)("p",{parentName:"blockquote"},"\u2014 John Reilly (@johnny_reilly) ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/johnny_reilly/status/1181542739994976256?ref_src=twsrc%5Etfw"}),"October 8, 2019"))),(0,a.kt)("script",{async:"",src:"https://platform.twitter.com/widgets.js",charSet:"utf-8"}),(0,a.kt)("p",null,"Again consider this example news story:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Jane Smith logged in at 10:03am for 25 minutes. They placed ",(0,a.kt)("a",o({parentName:"p"},{href:"https://my-glorious-platform.io/orders/janes-order"}),"an order")," worth \xa33,000.")),(0,a.kt)("p",null,"Consider that story but without a link. It's not the same is it? A newsfeed without links would be missing a trick. Markdown gives us links. And happily due to my extensive work down the open source mines, I speak it like a native."),(0,a.kt)("p",null,"The first consumer of the newsfeed was to be our own mini analytics platform, which is a React app. Converting the markdown stories to React is a solved problem thanks to the wonderful ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/rexxars/react-markdown"}),"react-markdown"),". You can simply sling Markdown at it and out comes HTML. Et voil\xe0 a news feed!"),(0,a.kt)("h2",o({},{id:"whats-next"}),"What's next?"),(0,a.kt)("p",null,"So that's it! We've built a (primitive) news feed. We can now see in real time how are users are getting on. We're closer to them, we understand them better as a consequence. If we want to take it further there's a number of things we could do:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"We could make the feed auto-update"),(0,a.kt)("li",{parentName:"ol"},"We could push news stories to other destinations. Markdown is a gloriously portable format which can be used in a variety of environments. For instance the likes of Slack and ",(0,a.kt)("a",o({parentName:"li"},{href:"/teams-notification-webhooks"}),"Teams")," accept it and apps like these are generally open on people's desktops and phones all the time anyway. Another way to narrow the gap between us and and our users.")),(0,a.kt)("p",null,"It's very exciting!"))}d.isMDXComponent=!0},74541:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"autofac-6-integration-tests-and-generic-hosting",title:"Autofac 6, integration tests and .NET generic hosting",authors:"johnnyreilly",tags:["autofac","asp.net","Integration Testing"],image:"./autofac-integration-tests.webp",hide_table_of_contents:!1},s=void 0,l={permalink:"/autofac-6-integration-tests-and-generic-hosting",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-10-02-autofac-6-integration-tests-and-generic-hosting/index.md",source:"@site/blog/2020-10-02-autofac-6-integration-tests-and-generic-hosting/index.md",title:"Autofac 6, integration tests and .NET generic hosting",description:"I blogged a little while ago around to support integration tests using Autofac. This was specific to Autofac but documented a workaround for a long standing issue with ConfigureTestContainer that was introduced into .NET core 3.0 which affects all third-party containers that use ConfigureTestContainer in their tests.",date:"2020-10-02T00:00:00.000Z",formattedDate:"October 2, 2020",tags:[{label:"autofac",permalink:"/tags/autofac"},{label:"asp.net",permalink:"/tags/asp-net"},{label:"Integration Testing",permalink:"/tags/integration-testing"}],readingTime:2.235,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"autofac-6-integration-tests-and-generic-hosting",title:"Autofac 6, integration tests and .NET generic hosting",authors:"johnnyreilly",tags:["autofac","asp.net","Integration Testing"],image:"./autofac-integration-tests.webp",hide_table_of_contents:!1},prevItem:{title:"Safari: The Mysterious Case of the Empty Download",permalink:"/safari-empty-download-content-type"},nextItem:{title:"Why your team needs a newsfeed",permalink:"/why-your-team-needs-newsfeed"}},p={image:n(50721).Z,authorsImageUrls:[void 0]},u=[{value:"Concern for third-party containers",id:"concern-for-third-party-containers",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I ",(0,a.kt)("a",o({parentName:"p"},{href:"/autofac-webapplicationfactory-integration-tests"}),"blogged a little while ago around to support integration tests using Autofac"),". This was specific to Autofac but documented a workaround for a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dotnet/aspnetcore/issues/14907"}),"long standing issue with ",(0,a.kt)("inlineCode",{parentName:"a"},"ConfigureTestContainer")," that was introduced into .NET core 3.0")," which affects ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection?view=aspnetcore-3.1#default-service-container-replacement"}),"all third-party containers")," that use ",(0,a.kt)("inlineCode",{parentName:"p"},"ConfigureTestContainer")," in their tests."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"A title image for the blog featuring the Autofac logo",src:n(50721).Z,width:"1185",height:"493"})),(0,a.kt)("p",null,"I'll not repeat the contents of the previous post - it all still stands. However, with Autofac 6 the approach documented there will cease to work. This is because the previous approach relied upon ",(0,a.kt)("inlineCode",{parentName:"p"},"ContainerBuilder")," not being sealed. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/autofac/Autofac/issues/1120"}),"As of Autofac 6 it is.")),(0,a.kt)("p",null,"Happily the tremendous ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/evocationist"}),"Alistair Evans")," came up with an ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/autofac/Autofac/issues/1207#issuecomment-701961371"}),"alternative approach")," which is listed below:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'/// <summary>\n/// Based upon https://github.com/dotnet/AspNetCore.Docs/tree/master/aspnetcore/test/integration-tests/samples/3.x/IntegrationTestsSample\n/// </summary>\n/// <typeparam name="TStartup"></typeparam>\npublic class AutofacWebApplicationFactory<TStartup> : WebApplicationFactory<TStartup> where TStartup : class\n{\n    protected override IHost CreateHost(IHostBuilder builder)\n    {\n        builder.UseServiceProviderFactory<ContainerBuilder>(new CustomServiceProviderFactory());\n        return base.CreateHost(builder);\n    }\n}\n\n/// <summary>\n/// Based upon https://github.com/dotnet/aspnetcore/issues/14907#issuecomment-620750841 - only necessary because of an issue in ASP.NET Core\n/// </summary>\npublic class CustomServiceProviderFactory : IServiceProviderFactory<ContainerBuilder>\n{\n    private AutofacServiceProviderFactory _wrapped;\n    private IServiceCollection _services;\n\n    public CustomServiceProviderFactory()\n    {\n        _wrapped = new AutofacServiceProviderFactory();\n    }\n\n    public ContainerBuilder CreateBuilder(IServiceCollection services)\n    {\n        // Store the services for later.\n        _services = services;\n\n        return _wrapped.CreateBuilder(services);\n    }\n\n    public IServiceProvider CreateServiceProvider(ContainerBuilder containerBuilder)\n    {\n        var sp = _services.BuildServiceProvider();\n#pragma warning disable CS0612 // Type or member is obsolete\n        var filters = sp.GetRequiredService<IEnumerable<IStartupConfigureContainerFilter<ContainerBuilder>>>();\n#pragma warning restore CS0612 // Type or member is obsolete\n\n        foreach (var filter in filters)\n        {\n            filter.ConfigureContainer(b => { })(containerBuilder);\n        }\n\n        return _wrapped.CreateServiceProvider(containerBuilder);\n    }\n}\n')),(0,a.kt)("p",null,"Using this in place of the previous approach should allow you continue running your integration tests with Autofac 6. Thanks Alistair!"),(0,a.kt)("h2",o({},{id:"concern-for-third-party-containers"}),"Concern for third-party containers"),(0,a.kt)("p",null,"Whilst this gets us back up and running, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/autofac/Autofac/issues/1207#issuecomment-702250044"}),"Alistair pointed out that this approach depends upon a deprecated interface"),". This is the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.hosting.istartupconfigurecontainerfilter-1.configurecontainer?view=aspnetcore-3.1"}),(0,a.kt)("inlineCode",{parentName:"a"},"IStartupConfigureContainerFilter"))," which ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dotnet/aspnetcore/pull/11505"}),"has been marked as ",(0,a.kt)("inlineCode",{parentName:"a"},"Obsolete")," since mid 2019"),". What this means is, at some point, this approach will stop working."),(0,a.kt)("p",null,"The marvellous David Fowler has said that ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/autofac/Autofac/issues/1207#issuecomment-702361608"}),(0,a.kt)("inlineCode",{parentName:"a"},"ConfigureTestContainer")," issue should be resolved in .NET"),". However it's worth noting that this has been an issue since .NET Core 3 shipped and unfortunately the wonderful ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dotnet/aspnetcore/issues/14907#issuecomment-702287717"}),"Chris Ross has advised that it's not likely to be fixed for .NET 5"),"."),(0,a.kt)("p",null,"I'm very keen this does get resolved in .NET. Building tests upon an ",(0,a.kt)("inlineCode",{parentName:"p"},"Obsolete")," attribute doesn't fill me with confidence. I'm a long time user of Autofac and I'd like to continue to be. Here's hoping that's made possible by a fix landing in .NET. If this is something you care about, it may be worth upvoting / commenting on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dotnet/aspnetcore/issues/14907"}),"the issue in GitHub")," so the team are aware of desire around this being resolved."))}d.isMDXComponent=!0},62466:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"safari-empty-download-content-type",title:"Safari: The Mysterious Case of the Empty Download",authors:"johnnyreilly",tags:["Safari"],hide_table_of_contents:!1},s=void 0,l={permalink:"/safari-empty-download-content-type",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-10-19-safari-empty-download-content-type/index.md",source:"@site/blog/2020-10-19-safari-empty-download-content-type/index.md",title:"Safari: The Mysterious Case of the Empty Download",description:"Safari wants a Content-Type header in responses. Even if the response is Content-Length: 0. Without this, Safari can attempt to trigger an empty download. Don't argue; just go with it; some browsers are strange.",date:"2020-10-19T00:00:00.000Z",formattedDate:"October 19, 2020",tags:[{label:"Safari",permalink:"/tags/safari"}],readingTime:2.22,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"safari-empty-download-content-type",title:"Safari: The Mysterious Case of the Empty Download",authors:"johnnyreilly",tags:["Safari"],hide_table_of_contents:!1},prevItem:{title:"Azure DevOps Client for Node.js - GitApi / WikiApi limitations",permalink:"/azure-devops-node-api-git-api-getrefs-wiki-api"},nextItem:{title:"Autofac 6, integration tests and .NET generic hosting",permalink:"/autofac-6-integration-tests-and-generic-hosting"}},p={authorsImageUrls:[void 0]},u=[{value:"The longer version",id:"the-longer-version",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Safari wants a ",(0,a.kt)("inlineCode",{parentName:"p"},"Content-Type")," header in responses. Even if the response is ",(0,a.kt)("inlineCode",{parentName:"p"},"Content-Length: 0"),". Without this, Safari can attempt to trigger an empty download. Don't argue; just go with it; some browsers are strange."),(0,a.kt)("h2",o({},{id:"the-longer-version"}),"The longer version"),(0,a.kt)("p",null,"Every now and then a mystery presents itself. A puzzle which just doesn't make sense and yet stubbornly continues to exist. I happened upon one of these the other day and to say it was frustrating does it no justice at all."),(0,a.kt)("p",null,"It all came back to the default iOS and Mac browser; Safari. When our users log into our application, they are redirected to a shared login provider which, upon successful authentication, hands over a cookie containing auth details and redirects back to our application. A middleware in our app reads what it needs from the cookie and then creates a cookie of its own which is to be used throughout the session. As soon as the cookie is set, the page refreshes and the app boots up in an authenticated state."),(0,a.kt)("p",null,"That's the background. This mechanism had long been working fine with Chrome (which the majority of our users browse with), Edge, Firefox and Internet Explorer. But we started to get reports from Safari users that, once they'd supplied their credentials, they'd not be authenticated and redirected back to our application. Instead they'd be prompted to download an empty document and the redirect would not take place."),(0,a.kt)("p",null,"As a team we could not fathom why this should be the case; it just didn't make sense. There followed hours of experimentation before ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/hennie_spies"}),"Hennie")," noticed something. It was at the point when the redirect back to our app from the login provider took place. Specifically the initial response that came back which contained our custom cookie and a ",(0,a.kt)("inlineCode",{parentName:"p"},"Refresh: 0")," header to trigger a refresh in the browser. There was no content in the response, save for headers. It was ",(0,a.kt)("inlineCode",{parentName:"p"},"Content-Length: 0")," all the way."),(0,a.kt)("p",null,"Hennie noticed that there was no ",(0,a.kt)("inlineCode",{parentName:"p"},"Content-Type")," set and wondered if that was significant. It didn't seem like it would be a necessary header given there was no content. But Safari reckons not with logic. As an experiment we tried setting the response header to ",(0,a.kt)("inlineCode",{parentName:"p"},"Content-Type: text/html"),". It worked! No mystery download, no failed redirect (which it turned out was actually a successful redirect which wasn't being surfaced in Safari's network request tab)."),(0,a.kt)("p",null,"It appears that always providing a ",(0,a.kt)("inlineCode",{parentName:"p"},"Content-Type")," header in your responses is wise if only for the case of Safari. In fact, it's generally unlikely that this won't be set anyway, but it can happen as we have experienced. Hopefully we've suffered so you don't have to."))}d.isMDXComponent=!0},69137:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-devops-node-api-git-api-getrefs-wiki-api",title:"Azure DevOps Client for Node.js - GitApi / WikiApi limitations",authors:"johnnyreilly",tags:["azure devops api","Node.js"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-devops-node-api-git-api-getrefs-wiki-api",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-10-31-azure-devops-node-api-git-api-getrefs-wiki-api/index.md",source:"@site/blog/2020-10-31-azure-devops-node-api-git-api-getrefs-wiki-api/index.md",title:"Azure DevOps Client for Node.js - GitApi / WikiApi limitations",description:"The Azure DevOps Client library for Node.js has limitations and missing features, IGitApi.getRefs is missing pagination and IWikiApi is missing page create or update. This post details some of these issues and illustrates a workaround using the Azure DevOps REST API.",date:"2020-10-31T00:00:00.000Z",formattedDate:"October 31, 2020",tags:[{label:"azure devops api",permalink:"/tags/azure-devops-api"},{label:"Node.js",permalink:"/tags/node-js"}],readingTime:4.695,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-devops-node-api-git-api-getrefs-wiki-api",title:"Azure DevOps Client for Node.js - GitApi / WikiApi limitations",authors:"johnnyreilly",tags:["azure devops api","Node.js"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"Throttling data requests with React Hooks",permalink:"/throttle-data-requests-with-react-hooks"},nextItem:{title:"Safari: The Mysterious Case of the Empty Download",permalink:"/safari-empty-download-content-type"}},p={image:n(28672).Z,authorsImageUrls:[void 0]},u=[{value:"The Azure DevOps REST API and Client Libraries",id:"the-azure-devops-rest-api-and-client-libraries",level:2},{value:"<code>GitApi</code> and <code>WikiApi</code> shortcomings",id:"gitapi-and-wikiapi-shortcomings",level:2},{value:"Handrolled Wiki API",id:"handrolled-wiki-api",level:2},{value:"Handrolled Git API",id:"handrolled-git-api",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The Azure DevOps Client library for Node.js has limitations and missing features, ",(0,a.kt)("inlineCode",{parentName:"p"},"IGitApi.getRefs")," is missing pagination and ",(0,a.kt)("inlineCode",{parentName:"p"},"IWikiApi")," is missing page create or update. This post details some of these issues and illustrates a workaround using the Azure DevOps REST API."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"A title image that reads &quot;Azure DevOps Client for Node.js - working around limitations&quot;",src:n(28672).Z,width:"915",height:"430"})),(0,a.kt)("h2",o({},{id:"the-azure-devops-rest-api-and-client-libraries"}),"The Azure DevOps REST API and Client Libraries"),(0,a.kt)("p",null,"I've been taking a good look at the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/rest/api/azure/devops/?view=azure-devops-rest-6.1"}),"REST API for Azure DevOps"),". I'm delighted to say that it's a very full API. However, there's quirks."),(0,a.kt)("p",null,"I'm writing a tool that interrogates Azure DevOps in order that it can construct release documentation. That release documentation we would like to publish to the project wiki."),(0,a.kt)("p",null,"To make integration with Azure DevOps even easier, the ADO team have put a good amount of work into ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/rest/api/azure/devops/?view=azure-devops-rest-6.1#client-libraries"}),"client libraries"),' that allow you to code in your language of choice. In my case I\'m writing a Node.js tool (using TypeScript) and happily the client lib for Node is written and published with TypeScript too. Tremendous! However, there is a "but" coming....'),(0,a.kt)("h2",o({},{id:"gitapi-and-wikiapi-shortcomings"}),(0,a.kt)("inlineCode",{parentName:"h2"},"GitApi")," and ",(0,a.kt)("inlineCode",{parentName:"h2"},"WikiApi")," shortcomings"),(0,a.kt)("p",null,"As I've been using the Node client lib, I've found minor quirks. Such as the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/azure-devops-node-api/issues/415"}),(0,a.kt)("inlineCode",{parentName:"a"},"GitApi.getRefs")," missing the pagination parts of the API"),"."),(0,a.kt)("p",null,"Whilst the ",(0,a.kt)("inlineCode",{parentName:"p"},"GitApi")," was missing some parameters on a method, the ",(0,a.kt)("inlineCode",{parentName:"p"},"WikiApi")," was ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/azure-devops-node-api/issues/416"}),"missing whole endpoints, such as the Pages - Create Or Update")," one. The various ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/azure-devops-node-api/blob/master/CONTRIBUTING/index.md#general-contribution-guide"}),"client libraries are auto-generated")," which makes contribution a difficult game. The lovely ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/vtbassmatt"}),"Matt Cooper")," has ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/azure-devops-node-api/issues/415#issuecomment-717991914"}),"alerted the team")),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"These clients are generated from the server-side controllers, and at a glance, I don't understand why those two parameters weren't included. Full transparency, we don't dedicate a lot of cycles here, but I will get it on the team's radar to investigate/improve.")),(0,a.kt)("p",null,"In the meantime, I still had a tool to write."),(0,a.kt)("h2",o({},{id:"handrolled-wiki-api"}),"Handrolled Wiki API"),(0,a.kt)("p",null,"Whilst the Node.js client lib was missing some crucial pieces, there did seem to be a way forward. Using the API directly; not using the client lib to do our HTTP and using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/axios/axios"}),"axios")," instead. Happily the types we needed were still available for be leveraged."),(0,a.kt)("p",null,"Looking at the docs it seemed it ought to be simple:"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/rest/api/azure/devops/?view=azure-devops-rest-6.1#assemble-the-request"}),"https://docs.microsoft.com/en-us/rest/api/azure/devops/?view=azure-devops-rest-6.1#assemble-the-request")),(0,a.kt)("p",null,"But when I attempted this I found my requests erroring out with 203 Non-Authoritative Informations. It didn't make sense. I couldn't get a single request to be successful, they all failed. It occurred to me that the answer was hiding in ",(0,a.kt)("inlineCode",{parentName:"p"},"node_modules"),". I'd managed to make successful requests to the API using the client lib. What was it doing that I wasn't?"),(0,a.kt)("p",null,"The answer ended up being an authorization one-liner:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const request = await axios({\n        url,\n        headers: {\n            Accept: 'application/json',\n            'Content-Type': 'application/json',\n            // This!\n            Authorization: `Basic ${Buffer.from(`PAT:${adoPersonalAccessToken}`).toString('base64')}`,\n            'X-TFS-FedAuthRedirect': 'Suppress',\n        },\n    });\n}\n")),(0,a.kt)("p",null,"With this in hand everything started to work and I found myself able to write my own clients to fill in the missing pieces from the client lib:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import axios from 'axios';\nimport {\n  WikiPage,\n  WikiPageCreateOrUpdateParameters,\n  WikiType,\n} from 'azure-devops-node-api/interfaces/WikiInterfaces';\nimport { IWikiApi } from 'azure-devops-node-api/WikiApi';\n\nasync function getWikiPage({\n  adoUrl,\n  adoProject,\n  adoPat,\n  wikiId,\n  path,\n}: {\n  adoUrl: string;\n  adoProject: string;\n  adoPat: string;\n  wikiId: string;\n  path: string;\n}) {\n  try {\n    const url = `${makeBaseApiUrl({\n      adoUrl,\n      adoProject,\n    })}/wiki/wikis/${wikiId}/pages?${apiVersion}&path=${path}&includeContent=True&recursionLevel=full`;\n    const request = await axios({\n      url,\n      headers: makeHeaders(adoPat),\n    });\n\n    const page: WikiPage = request.data;\n    return page;\n  } catch (error) {\n    return undefined;\n  }\n}\n\nasync function createWikiPage({\n  adoUrl,\n  adoProject,\n  adoPat,\n  wikiId,\n  path,\n  data,\n}: {\n  adoUrl: string;\n  adoProject: string;\n  adoPat: string;\n  wikiId: string;\n  path: string;\n  data: WikiPageCreateOrUpdateParameters;\n}) {\n  try {\n    const url = `${makeBaseApiUrl({\n      adoUrl,\n      adoProject,\n    })}/wiki/wikis/${wikiId}/pages?${apiVersion}&path=${path}`;\n\n    const request = await axios({\n      method: 'PUT',\n      url,\n      headers: makeHeaders(adoPat),\n      data,\n    });\n\n    const newPage: WikiPage = request.data;\n    return newPage;\n  } catch (error) {\n    return undefined;\n  }\n}\n\nconst apiVersion = 'api-version=6.0';\n\n/**\n * Create the headers necessary to ake Azure DevOps happy\n * @param adoPat Personal Access Token from ADO\n */\nfunction makeHeaders(adoPat: string) {\n  return {\n    Accept: 'application/json',\n    'Content-Type': 'application/json',\n    Authorization: `Basic ${Buffer.from(`PAT:${adoPat}`).toString('base64')}`,\n    'X-TFS-FedAuthRedirect': 'Suppress',\n  };\n}\n\n/**\n * eg https://dev.azure.com/{organization}/{project}/_apis\n */\nfunction makeBaseApiUrl({\n  adoUrl,\n  adoProject,\n}: {\n  adoUrl: string;\n  adoProject: string;\n}) {\n  return `${adoUrl}/${adoProject}/_apis`;\n}\n")),(0,a.kt)("p",null,"With this I was able to write code like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"let topLevelPage = await getWikiPage({\n  adoUrl,\n  adoProject,\n  adoPat,\n  wikiId,\n  path: config.wikiTopLevelName,\n});\n\nif (!topLevelPage)\n  topLevelPage = await createWikiPage({\n    adoUrl,\n    adoProject,\n    adoPat,\n    wikiId,\n    path: config.wikiTopLevelName,\n    data: { content: '' },\n  });\n")),(0,a.kt)("p",null,"and the wikis were ours!"),(0,a.kt)("h2",o({},{id:"handrolled-git-api"}),"Handrolled Git API"),(0,a.kt)("p",null,"Similarly it's possible to write a client for the Git API that reuses the types from the client lib."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"/**\n * Get the refs for the repo using Axios\n * IGitApi.getRefs seems to be missing pagination parts of API, see: https://github.com/microsoft/azure-devops-node-api/issues/415\n */\nexport async function getRefs({\n  adoUrl,\n  adoProject,\n  repositoryId,\n  filter,\n  logger,\n}: {\n  adoUrl: string;\n  adoProject: string;\n  repositoryId: string;\n  adoPat: string;\n  filter: string;\n}): Promise<GitRef[]> {\n  const batchSize = 100;\n  let continuationToken = '';\n  const refs: GitRef[] = [];\n  // eslint-disable-next-line no-constant-condition\n  while (true) {\n    try {\n      const url = `${makeBaseApiUrl({\n        adoUrl,\n        adoProject,\n      })}/git/repositories/${repositoryId}/refs?${apiVersion}&filter=${filter}&peelTags=True&$top=${batchSize}&continuationToken=${continuationToken}`;\n\n      const response = await axios({\n        method: 'GET',\n        url,\n        headers: makeHeaders(adoPat),\n        data,\n      });\n\n      continuationToken = response.headers['x-ms-continuationtoken'] || '';\n\n      const nextRefs: { value: GitRef[] } = response.data;\n\n      refs.push(...nextRefs.value);\n\n      const noMoreRefs = nextRefs.value.length === 0 || !continuationToken;\n      if (noMoreRefs) break;\n    } catch (err: any) {\n      logger.error(\n        'Failed to load refs',\n        err?.message,\n        err?.response?.status,\n        err?.response?.data\n      );\n      throw new Error('Failed to load refs');\n    }\n  }\n\n  return refs;\n}\n")),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"The client lib is great, but it's not perfect. It's missing some APIs and it's missing some features. But as we can see, it's possible to work around the shortcomings and write our own clients to fill in the gaps."))}d.isMDXComponent=!0},95018:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"throttle-data-requests-with-react-hooks",title:"Throttling data requests with React Hooks",authors:"johnnyreilly",tags:["React"],hide_table_of_contents:!1},s=void 0,l={permalink:"/throttle-data-requests-with-react-hooks",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-11-10-throttle-data-requests-with-react-hooks/index.md",source:"@site/blog/2020-11-10-throttle-data-requests-with-react-hooks/index.md",title:"Throttling data requests with React Hooks",description:"When an application loads data, typically relatively few HTTP requests will be made. For example, if we imagine we're making a student administration application, then a \"view\" screen might make a single HTTP request to load that student's data before displaying it.",date:"2020-11-10T00:00:00.000Z",formattedDate:"November 10, 2020",tags:[{label:"React",permalink:"/tags/react"}],readingTime:13.18,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"throttle-data-requests-with-react-hooks",title:"Throttling data requests with React Hooks",authors:"johnnyreilly",tags:["React"],hide_table_of_contents:!1},prevItem:{title:"Bulletproof uniq with TypeScript generics (yay code reviews!)",permalink:"/bulletproof-uniq-with-typescript"},nextItem:{title:"Azure DevOps Client for Node.js - GitApi / WikiApi limitations",permalink:"/azure-devops-node-api-git-api-getrefs-wiki-api"}},p={authorsImageUrls:[void 0]},u=[{value:"Let&#39;s bring Chrome to its knees",id:"lets-bring-chrome-to-its-knees",level:2},{value:"Throttle me this",id:"throttle-me-this",level:2},{value:"What shall we build?",id:"what-shall-we-build",level:2},{value:"1. List repository contributors",id:"1-list-repository-contributors",level:3},{value:"2. Get a user",id:"2-get-a-user",level:3},{value:"Blogging devs v1.0",id:"blogging-devs-v10",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"When an application loads data, typically relatively few HTTP requests will be made. For example, if we imagine we're making a student administration application, then a \"view\" screen might make a single HTTP request to load that student's data before displaying it."),(0,a.kt)("p",null,"Occasionally there's a need for an application to make a large number of HTTP requests. Consider a reporting application which loads data and then aggregates it for presentation purposes."),(0,a.kt)("p",null,"This need presents two interesting problems to solve:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"how do we load data gradually?"),(0,a.kt)("li",{parentName:"ol"},"how do we present loading progress to users?")),(0,a.kt)("p",null,"This post will talk about how we can tackle these and demonstrate using a custom React Hook."),(0,a.kt)("h2",o({},{id:"lets-bring-chrome-to-its-knees"}),"Let's bring Chrome to its knees"),(0,a.kt)("p",null,"We'll begin our journey by spinning up a TypeScript React app with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://create-react-app.dev/"}),"Create React App"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"npx create-react-app throttle-requests-react-hook --template typescript\n")),(0,a.kt)("p",null,"Because we're going to be making a number of asynchronous calls, we're going to simplify the code by leaning on the widely used ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/streamich/react-use"}),(0,a.kt)("inlineCode",{parentName:"a"},"react-use"))," for a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/streamich/react-use/blob/master/docs/useAsync/index.md"}),(0,a.kt)("inlineCode",{parentName:"a"},"useAsync"))," hook."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"cd throttle-requests-react-hook\nyarn add react-use\n")),(0,a.kt)("p",null,"We'll replace the ",(0,a.kt)("inlineCode",{parentName:"p"},"App.css")," file with this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-css"}),".App {\n  text-align: center;\n}\n\n.App-header {\n  background-color: #282c34;\n  min-height: 100vh;\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  justify-content: center;\n  font-size: calc(10px + 2vmin);\n  color: white;\n}\n\n.App-labelinput > * {\n  margin: 0.5em;\n  font-size: 24px;\n}\n\n.App-link {\n  color: #61dafb;\n}\n\n.App-button {\n  font-size: calc(10px + 2vmin);\n  margin-top: 0.5em;\n  padding: 1em;\n  background-color: cornflowerblue;\n  color: #ffffff;\n  text-align: center;\n}\n\n.App-progress {\n  padding: 1em;\n  background-color: cadetblue;\n  color: #ffffff;\n}\n\n.App-results {\n  display: flex;\n  flex-wrap: wrap;\n}\n\n.App-results > * {\n  padding: 1em;\n  margin: 0.5em;\n  background-color: darkblue;\n  flex: 1 1 300px;\n}\n")),(0,a.kt)("p",null,"Then we'll replace the ",(0,a.kt)("inlineCode",{parentName:"p"},"App.tsx")," contents with this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"import React, { useState } from 'react';\nimport { useAsync } from 'react-use';\nimport './App.css';\n\nfunction use10_000Requests(startedAt: string) {\n  const responses = useAsync(async () => {\n    if (!startedAt) return;\n\n    // make 10,000 unique HTTP requests\n    const results = await Promise.all(\n      Array.from(Array(10_000)).map(async (_, index) => {\n        const response = await fetch(\n          `/manifest.json?querystringValueToPreventCaching=${startedAt}_request-${index}`\n        );\n        const json = await response.json();\n        return json;\n      })\n    );\n\n    return results;\n  }, [startedAt]);\n\n  return responses;\n}\n\nfunction App() {\n  const [startedAt, setStartedAt] = useState('');\n  const responses = use10_000Requests(startedAt);\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <h1>The HTTP request machine</h1>\n        <button\n          className=\"App-button\"\n          onClick={(_) => setStartedAt(new Date().toISOString())}\n        >\n          Make 10,000 requests\n        </button>\n        {responses.loading && <div>{progressMessage}</div>}\n        {responses.error && <div>Something went wrong</div>}\n        {responses.value && (\n          <div className=\"App-results\">\n            {responses.value.length} requests completed successfully\n          </div>\n        )}\n      </header>\n    </div>\n  );\n}\n\nexport default App;\n")),(0,a.kt)("p",null,"The app that we've built is very simple; it's a button which, when you press it, fires 10,000 HTTP requests in parallel using the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API"}),"Fetch API"),". The data being requested in this case is an arbitrary JSON file; the ",(0,a.kt)("inlineCode",{parentName:"p"},"manifest.json"),". If you look closely you'll see we're doing some querystring tricks with our URL to avoid getting cached data."),(0,a.kt)("p",null,"In fact, for this demo we're not interested in the results of these HTTP requests; rather we're interested in how the browser copes with this approach. (Spoiler: not well!) It's worth considering that requesting a text file from a server running on the same machine as the browser should be fast."),(0,a.kt)("p",null,"So we'll run ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn start")," and go to ",(0,a.kt)("a",o({parentName:"p"},{href:"http://localhost:3000"}),"http://localhost:3000")," to get to the app. Running with Devtools open results in the following unhappy affair:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",src:n(65521).Z,width:"600",height:"273"})),(0,a.kt)("p",null,"The GIF above has been edited significantly for length. In reality it took 20 seconds for the first request to be fired, prior to that Chrome was unresponsive. When requests did start to fire, a significant number failed with ",(0,a.kt)("inlineCode",{parentName:"p"},"net::ERR_INSUFFICIENT_RESOURCES"),'. Further to that, those requests that were fired sat in "Stalled" state prior to being executed. This is a consequence of ',(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/web/tools/chrome-devtools/network/reference#timing"}),"Chrome limiting the number of connections - all browsers do this"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"There are already six TCP connections open for this origin, which is the limit. Applies to HTTP/1.0 and HTTP/1.1 only.")),(0,a.kt)("p",null,"In summary, the problems with the current approach are:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"the browser becoming unresponsive"),(0,a.kt)("li",{parentName:"ol"},"failing HTTP requests due to insufficient resources"),(0,a.kt)("li",{parentName:"ol"},"no information displayed to the user around progress")),(0,a.kt)("h2",o({},{id:"throttle-me-this"}),"Throttle me this"),(0,a.kt)("p",null,"Instead of hammering the browser by firing all the requests at once, we could instead implement a throttle. A throttle is a mechanism which allows you to limit the rate at which operations are performed. In this case we want to limit the rate at which HTTP requests are made. A throttle will tackle problems 1 and 2 - essentially keeping the browser free and easy and ensuring that requests are all successfully sent. We also want to keep our users informed around how progress is going. It's time to unveil the ",(0,a.kt)("inlineCode",{parentName:"p"},"useThrottleRequests")," hook:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { useMemo, useReducer } from 'react';\nimport { AsyncState } from 'react-use/lib/useAsync';\n\n/** Function which makes a request */\nexport type RequestToMake = () => Promise<void>;\n\n/**\n * Given an array of requestsToMake and a limit on the number of max parallel requests\n * queue up those requests and start firing them\n * - inspired by Rafael Xavier's approach here: https://stackoverflow.com/a/48007240/761388\n *\n * @param requestsToMake\n * @param maxParallelRequests the maximum number of requests to make - defaults to 6\n */\nasync function throttleRequests(\n  requestsToMake: RequestToMake[],\n  maxParallelRequests = 6\n) {\n  // queue up simultaneous calls\n  const queue: Promise<void>[] = [];\n  for (let requestToMake of requestsToMake) {\n    // fire the async function, add its promise to the queue,\n    // and remove it from queue when complete\n    const promise = requestToMake().then((res) => {\n      queue.splice(queue.indexOf(promise), 1);\n      return res;\n    });\n    queue.push(promise);\n\n    // if the number of queued requests matches our limit then\n    // wait for one to finish before enqueueing more\n    if (queue.length >= maxParallelRequests) {\n      await Promise.race(queue);\n    }\n  }\n  // wait for the rest of the calls to finish\n  await Promise.all(queue);\n}\n\n/**\n * The state that represents the progress in processing throttled requests\n */\nexport type ThrottledProgress<TData> = {\n  /** the number of requests that will be made */\n  totalRequests: number;\n  /** the errors that came from failed requests */\n  errors: Error[];\n  /** the responses that came from successful requests */\n  values: TData[];\n  /** a value between 0 and 100 which represents the percentage of requests that have been completed (whether successfully or not) */\n  percentageLoaded: number;\n  /** whether the throttle is currently processing requests */\n  loading: boolean;\n};\n\nfunction createThrottledProgress<TData>(\n  totalRequests: number\n): ThrottledProgress<TData> {\n  return {\n    totalRequests,\n    percentageLoaded: 0,\n    loading: false,\n    errors: [],\n    values: [],\n  };\n}\n\n/**\n * A reducing function which takes the supplied `ThrottledProgress` and applies a new value to it\n */\nfunction updateThrottledProgress<TData>(\n  currentProgress: ThrottledProgress<TData>,\n  newData: AsyncState<TData>\n): ThrottledProgress<TData> {\n  const errors = newData.error\n    ? [...currentProgress.errors, newData.error]\n    : currentProgress.errors;\n\n  const values = newData.value\n    ? [...currentProgress.values, newData.value]\n    : currentProgress.values;\n\n  const percentageLoaded =\n    currentProgress.totalRequests === 0\n      ? 0\n      : Math.round(\n          ((errors.length + values.length) / currentProgress.totalRequests) *\n            100\n        );\n\n  const loading =\n    currentProgress.totalRequests === 0\n      ? false\n      : errors.length + values.length < currentProgress.totalRequests;\n\n  return {\n    totalRequests: currentProgress.totalRequests,\n    loading,\n    percentageLoaded,\n    errors,\n    values,\n  };\n}\n\ntype ThrottleActions<TValue> =\n  | {\n      type: 'initialise';\n      totalRequests: number;\n    }\n  | {\n      type: 'requestSuccess';\n      value: TValue;\n    }\n  | {\n      type: 'requestFailed';\n      error: Error;\n    };\n\n/**\n * Create a ThrottleRequests and an updater\n */\nexport function useThrottleRequests<TValue>() {\n  function reducer(\n    throttledProgressAndState: ThrottledProgress<TValue>,\n    action: ThrottleActions<TValue>\n  ): ThrottledProgress<TValue> {\n    switch (action.type) {\n      case 'initialise':\n        return createThrottledProgress(action.totalRequests);\n\n      case 'requestSuccess':\n        return updateThrottledProgress(throttledProgressAndState, {\n          loading: false,\n          value: action.value,\n        });\n\n      case 'requestFailed':\n        return updateThrottledProgress(throttledProgressAndState, {\n          loading: false,\n          error: action.error,\n        });\n    }\n  }\n\n  const [throttle, dispatch] = useReducer(\n    reducer,\n    createThrottledProgress<TValue>(/** totalRequests */ 0)\n  );\n\n  const updateThrottle = useMemo(() => {\n    /**\n     * Update the throttle with a successful request\n     * @param values from request\n     */\n    function requestSucceededWithData(value: TValue) {\n      return dispatch({\n        type: 'requestSuccess',\n        value,\n      });\n    }\n\n    /**\n     * Update the throttle upon a failed request with an error message\n     * @param error error\n     */\n    function requestFailedWithError(error: Error) {\n      return dispatch({\n        type: 'requestFailed',\n        error,\n      });\n    }\n\n    /**\n     * Given an array of requestsToMake and a limit on the number of max parallel requests\n     * queue up those requests and start firing them\n     * - based upon https://stackoverflow.com/a/48007240/761388\n     *\n     * @param requestsToMake\n     * @param maxParallelRequests the maximum number of requests to make - defaults to 6\n     */\n    function queueRequests(\n      requestsToMake: RequestToMake[],\n      maxParallelRequests = 6\n    ) {\n      dispatch({\n        type: 'initialise',\n        totalRequests: requestsToMake.length,\n      });\n\n      return throttleRequests(requestsToMake, maxParallelRequests);\n    }\n\n    return {\n      queueRequests,\n      requestSucceededWithData,\n      requestFailedWithError,\n    };\n  }, [dispatch]);\n\n  return {\n    throttle,\n    updateThrottle,\n  };\n}\n")),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"useThrottleRequests")," hook returns 2 properties:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"throttle")," ","-"," a ",(0,a.kt)("inlineCode",{parentName:"p"},"ThrottledProgress&lt;TData&gt;")," that contains the following data:"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"totalRequests")," ","-"," the number of requests that will be made"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"errors")," ","-"," the errors that came from failed requests"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"values")," ","-"," the responses that came from successful requests"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"percentageLoaded")," ","-"," a value between 0 and 100 which represents the percentage of requests that have been completed (whether successfully or not)"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"loading")," ","-"," whether the throttle is currently processing requests"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"updateThrottle")," ","-"," an object which exposes 3 functions:"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"queueRequests")," ","-"," the function to which you pass the requests that should be queued and executed in a throttled fashion"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"requestSucceededWithData")," ","-"," the function which is called if a request succeeds to provide the data"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"requestFailedWithError")," ","-"," the function which is called if a request fails to provide the error")))),(0,a.kt)("p",null,"That's a lot of words to describe our ",(0,a.kt)("inlineCode",{parentName:"p"},"useThrottleRequests")," hook. Let's look at what it looks like by migrating our ",(0,a.kt)("inlineCode",{parentName:"p"},"use10_000Requests")," hook to (no pun intended) use it. Here's a new implementation of ",(0,a.kt)("inlineCode",{parentName:"p"},"App.tsx"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"import React, { useState } from 'react';\nimport { useAsync } from 'react-use';\nimport { useThrottleRequests } from './useThrottleRequests';\nimport './App.css';\n\nfunction use10_000Requests(startedAt: string) {\n  const { throttle, updateThrottle } = useThrottleRequests();\n  const [progressMessage, setProgressMessage] = useState('not started');\n\n  useAsync(async () => {\n    if (!startedAt) return;\n\n    setProgressMessage('preparing');\n\n    const requestsToMake = Array.from(Array(10_000)).map(\n      (_, index) => async () => {\n        try {\n          setProgressMessage(`loading ${index}...`);\n\n          const response = await fetch(\n            `/manifest.json?querystringValueToPreventCaching=${startedAt}_request-${index}`\n          );\n          const json = await response.json();\n\n          updateThrottle.requestSucceededWithData(json);\n        } catch (error) {\n          console.error(`failed to load ${index}`, error);\n          updateThrottle.requestFailedWithError(error);\n        }\n      }\n    );\n\n    await updateThrottle.queueRequests(requestsToMake);\n  }, [startedAt, updateThrottle, setProgressMessage]);\n\n  return { throttle, progressMessage };\n}\n\nfunction App() {\n  const [startedAt, setStartedAt] = useState('');\n\n  const { progressMessage, throttle } = use10_000Requests(startedAt);\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <h1>The HTTP request machine</h1>\n        <button\n          className=\"App-button\"\n          onClick={(_) => setStartedAt(new Date().toISOString())}\n        >\n          Make 10,000 requests\n        </button>\n        {throttle.loading && <div>{progressMessage}</div>}\n        {throttle.values.length > 0 && (\n          <div className=\"App-results\">\n            {throttle.values.length} requests completed successfully\n          </div>\n        )}\n        {throttle.errors.length > 0 && (\n          <div className=\"App-results\">\n            {throttle.errors.length} requests errored\n          </div>\n        )}\n      </header>\n    </div>\n  );\n}\n\nexport default App;\n")),(0,a.kt)("p",null,"Looking at the new ",(0,a.kt)("inlineCode",{parentName:"p"},"use10_000Requests")," hook, there's a few subtle differences to our prior implementation. First of all, we're now exposing the ",(0,a.kt)("inlineCode",{parentName:"p"},"throttle"),"; a ",(0,a.kt)("inlineCode",{parentName:"p"},"ThrottleProgress&lt;TData&gt;"),". Our updated hook also exposes a ",(0,a.kt)("inlineCode",{parentName:"p"},"progressMessage")," which is a simple ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," stored with ",(0,a.kt)("inlineCode",{parentName:"p"},"useState")," that we update as our throttle runs. In truth the information being surfaced here isn't that interesting. The ",(0,a.kt)("inlineCode",{parentName:"p"},"progressMessage")," is in place just to illustrate that you could capture some data from your requests as they complete for display purposes; a running total for instance."),(0,a.kt)("p",null,"So, how does our new hook approach perform?"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(84774).Z,width:"600",height:"273"})),(0,a.kt)("p",null,"Very well indeed! Please note that the above GIF has again been edited for brevity. If we look back at the problems we faced with the prior approach, how do we compare?"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("del",{parentName:"li"},"the browser becoming unresponsive")," ","-"," the browser remains responsive."),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("del",{parentName:"li"},"failing HTTP requests due to insufficient resources")," ","-"," the browser does not experience failing HTTP requests."),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("del",{parentName:"li"},"no information displayable to the user around progress")," ","-"," details of progress are displayed to the user throughout.")),(0,a.kt)("p",null,"Tremendous!"),(0,a.kt)("h2",o({},{id:"what-shall-we-build"}),"What shall we build?"),(0,a.kt)("p",null,"Our current example is definitely contrived. Let's try and apply our ",(0,a.kt)("inlineCode",{parentName:"p"},"useThrottleRequests")," hook to a more realistic scenario. We're going to build an application which, given a repo on GitHub, lists all the contributors blogs. (You can specify a blog URL on your GitHub profile; many people use this to specify their Twitter profile.)"),(0,a.kt)("p",null,"We can build this thanks to the excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.github.com/en/free-pro-team@latest/rest"}),"GitHub REST API"),". It exposes two endpoints of interest given our goal."),(0,a.kt)("h3",o({},{id:"1-list-repository-contributors"}),"1","."," List repository contributors"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.github.com/en/free-pro-team@latest/rest/reference/repos#list-repository-contributors"}),"List repository contributors")," lists contributors to the specified repository at this URL: ",(0,a.kt)("inlineCode",{parentName:"p"},"GET https://api.github.com/repos/{owner}/{repo}/contributors"),". The response is an array of objects, crucially featuring a ",(0,a.kt)("inlineCode",{parentName:"p"},"url")," property that points to the user in question's API endpoint:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"[\n  // ...\n  {\n    // ...\n    url: 'https://api.github.com/users/octocat',\n    // ...\n  },\n  // ...\n];\n")),(0,a.kt)("h3",o({},{id:"2-get-a-user"}),"2","."," Get a user"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.github.com/en/free-pro-team@latest/rest/reference/users#get-a-user"}),"Get a user")," is the API that the ",(0,a.kt)("inlineCode",{parentName:"p"},"url")," property above is referring to. When called it returns an object representing the publicly available information about a user:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),'{\n  // ...\n  "name": "The Octocat",\n  // ...\n  "blog": "https://github.blog",\n  // ...\n}\n')),(0,a.kt)("h2",o({},{id:"blogging-devs-v10"}),"Blogging devs v1.0"),(0,a.kt)("p",null,"We're now ready to build our blogging devs app; let's replace the existing ",(0,a.kt)("inlineCode",{parentName:"p"},"App.tsx")," with:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),'import React, { useCallback, useMemo, useState } from \'react\';\nimport { useAsync } from \'react-use\';\nimport { useThrottleRequests } from \'./useThrottleRequests\';\nimport \'./App.css\';\n\ntype GitHubUser = { name: string; blog?: string };\n\nfunction timeout(ms: number) {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\n\nfunction useContributors(contributorsUrlToLoad: string) {\n  const { throttle, updateThrottle } = useThrottleRequests<GitHubUser>();\n  const [progressMessage, setProgressMessage] = useState(\'\');\n\n  useAsync(async () => {\n    if (!contributorsUrlToLoad) return;\n\n    setProgressMessage(\'loading contributors\');\n\n    // load contributors from GitHub\n    const contributorsResponse = await fetch(contributorsUrlToLoad);\n    const contributors: { url: string }[] = await contributorsResponse.json();\n\n    setProgressMessage(`loading ${contributors.length} contributors...`);\n\n    // For each entry in result, retrieve the given user from GitHub\n    const requestsToMake = contributors.map(({ url }, index) => async () => {\n      try {\n        setProgressMessage(\n          `loading ${index} / ${contributors.length}: ${url}...`\n        );\n\n        const response = await fetch(url);\n        const json: GitHubUser = await response.json();\n\n        // wait for 1 second before completing the request\n        // - makes for better demos\n        await timeout(1000);\n\n        updateThrottle.requestSucceededWithData(json);\n      } catch (error) {\n        console.error(`failed to load ${url}`, error);\n        updateThrottle.requestFailedWithError(error);\n      }\n    });\n\n    await updateThrottle.queueRequests(requestsToMake);\n\n    setProgressMessage(\'\');\n  }, [contributorsUrlToLoad, updateThrottle, setProgressMessage]);\n\n  return { throttle, progressMessage };\n}\n\nfunction App() {\n  // The owner and repo to query; we\'re going to default\n  // to using DefinitelyTyped as an example repo as it\n  // is one of the most contributed to repos on GitHub\n  const [owner, setOwner] = useState(\'DefinitelyTyped\');\n  const [repo, setRepo] = useState(\'DefinitelyTyped\');\n  const handleOwnerChange = useCallback(\n    (event: React.ChangeEvent<HTMLInputElement>) =>\n      setOwner(event.target.value),\n    [setOwner]\n  );\n  const handleRepoChange = useCallback(\n    (event: React.ChangeEvent<HTMLInputElement>) => setRepo(event.target.value),\n    [setRepo]\n  );\n\n  const contributorsUrl = `https://api.github.com/repos/${owner}/${repo}/contributors`;\n\n  const [contributorsUrlToLoad, setUrlToLoad] = useState(\'\');\n  const { progressMessage, throttle } = useContributors(contributorsUrlToLoad);\n\n  const bloggers = useMemo(\n    () => throttle.values.filter((contributor) => contributor.blog),\n    [throttle]\n  );\n\n  return (\n    <div className="App">\n      <header className="App-header">\n        <h1>Blogging devs</h1>\n\n        <p>\n          Show me the{\' \'}\n          <a\n            className="App-link"\n            href={contributorsUrl}\n            target="_blank"\n            rel="noopener noreferrer"\n          >\n            contributors for {owner}/{repo}\n          </a>{\' \'}\n          who have blogs.\n        </p>\n\n        <div className="App-labelinput">\n          <label htmlFor="owner">GitHub Owner</label>\n          <input\n            id="owner"\n            type="text"\n            value={owner}\n            onChange={handleOwnerChange}\n          />\n          <label htmlFor="repo">GitHub Repo</label>\n          <input\n            id="repo"\n            type="text"\n            value={repo}\n            onChange={handleRepoChange}\n          />\n        </div>\n\n        <button\n          className="App-button"\n          onClick={(e) => setUrlToLoad(contributorsUrl)}\n        >\n          Load bloggers from GitHub\n        </button>\n\n        {progressMessage && (\n          <div className="App-progress">{progressMessage}</div>\n        )}\n\n        {throttle.percentageLoaded > 0 && (\n          <>\n            <h3>Behold {bloggers.length} bloggers:</h3>\n            <div className="App-results">\n              {bloggers.map((blogger) => (\n                <div key={blogger.name}>\n                  <div>{blogger.name}</div>\n                  <a\n                    className="App-link"\n                    href={blogger.blog}\n                    target="_blank"\n                    rel="noopener noreferrer"\n                  >\n                    {blogger.blog}\n                  </a>\n                </div>\n              ))}\n            </div>\n          </>\n        )}\n\n        {throttle.errors.length > 0 && (\n          <div className="App-results">\n            {throttle.errors.length} requests errored\n          </div>\n        )}\n      </header>\n    </div>\n  );\n}\n\nexport default App;\n')),(0,a.kt)("p",null,"The application gives users the opportunity to enter the organisation and repository of a GitHub project. Then, when the button is clicked, it:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"loads the contributors"),(0,a.kt)("li",{parentName:"ul"},"for each contributor it loads the individual user (separate HTTP request for each)"),(0,a.kt)("li",{parentName:"ul"},"as it loads it communicates how far through the loading progress it has got"),(0,a.kt)("li",{parentName:"ul"},"as users are loaded, it renders a tile for each user with a listed blog")),(0,a.kt)("p",null,"Just to make the demo a little clearer we've artificially slowed the duration of each request by a second. What does it look like when you put it together? Well like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",src:n(51593).Z,width:"600",height:"273"})),(0,a.kt)("p",null,"We have built a React Hook which allows us to:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"gradually load data"),(0,a.kt)("li",{parentName:"ul"},"without blocking the UI of the browser"),(0,a.kt)("li",{parentName:"ul"},"and which provides progress data to keep users informed.")),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/throttling-data-requests-with-react-hooks/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/throttling-data-requests-with-react-hooks/"})))}d.isMDXComponent=!0},28376:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"bulletproof-uniq-with-typescript",title:"Bulletproof uniq with TypeScript generics (yay code reviews!)",authors:"johnnyreilly",tags:["typescript"],hide_table_of_contents:!1},s=void 0,l={permalink:"/bulletproof-uniq-with-typescript",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-11-14-bulletproof-uniq-with-typescript/index.md",source:"@site/blog/2020-11-14-bulletproof-uniq-with-typescript/index.md",title:"Bulletproof uniq with TypeScript generics (yay code reviews!)",description:"Never neglect the possibilities of a code review. There are times when you raise a PR and all you want is for everyone to hit approve so you can merge, merge and ship, ship! This can be a missed opportunity. For as much as I'd like to imagine my code is perfect, it's patently not. There's always scope for improvement.",date:"2020-11-14T00:00:00.000Z",formattedDate:"November 14, 2020",tags:[{label:"typescript",permalink:"/tags/typescript"}],readingTime:3.86,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"bulletproof-uniq-with-typescript",title:"Bulletproof uniq with TypeScript generics (yay code reviews!)",authors:"johnnyreilly",tags:["typescript"],hide_table_of_contents:!1},prevItem:{title:"Visual Studio Marketplace: images in Markdown!",permalink:"/images-in-markdown-for-azure-devops-marketplace"},nextItem:{title:"Throttling data requests with React Hooks",permalink:"/throttle-data-requests-with-react-hooks"}},p={authorsImageUrls:[void 0]},u=[{value:"&quot;What&#39;s this?&quot;",id:"whats-this",level:2},{value:"<code>uniq</code> v1",id:"uniq-v1",level:2},{value:"<code>uniq</code> v2",id:"uniq-v2",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Never neglect the possibilities of a code review. There are times when you raise a PR and all you want is for everyone to hit approve so you can merge, merge and ship, ship! This can be a missed opportunity. For as much as I'd like to imagine my code is perfect, it's patently not. There's always scope for improvement."),(0,a.kt)("h2",o({},{id:"whats-this"}),'"What\'s this?"'),(0,a.kt)("p",null,"This week afforded me that opportunity. I was walking through a somewhat complicated PR on a call and someone said \"what's this?\". They'd spotted an expression much like this in my code:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const myValues = [...new Set(allTheValuesSupplied)];\n")),(0,a.kt)("p",null,"What is that? Well, it's a number of things:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",o({parentName:"li"},{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Set#Remove_duplicate_elements_from_the_array"}),"It's a way to get the unique values in a collection.")),(0,a.kt)("li",{parentName:"ol"},"It's a pro-tip and a coding BMX trick.")),(0,a.kt)("p",null,"What do I mean? Well, this is indeed a technique for getting the unique values in a collection. But it relies upon you knowing a bunch of things:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Set"}),(0,a.kt)("inlineCode",{parentName:"a"},"Set"))," contains unique values. If you add multiple identical values, only a single value will be stored."),(0,a.kt)("li",{parentName:"ul"},"The ",(0,a.kt)("a",o({parentName:"li"},{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Set/Set"}),(0,a.kt)("inlineCode",{parentName:"a"},"Set")," constructor")," takes ",(0,a.kt)("a",o({parentName:"li"},{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Iteration_protocols#The_iterable_protocol"}),"iterable objects"),". This means we can ",(0,a.kt)("inlineCode",{parentName:"li"},"new")," up a ",(0,a.kt)("inlineCode",{parentName:"li"},"Set"),' with an array that we want to "unique-ify" and we will have a ',(0,a.kt)("inlineCode",{parentName:"li"},"Set")," that contains those unique values."),(0,a.kt)("li",{parentName:"ul"},"If you want to go on to do filtering / mapping etc on your unique values, you'll need to get them out of the ",(0,a.kt)("inlineCode",{parentName:"li"},"Set"),". This is because (regrettably) ECMAScript iterables don't implicitly support these operations and neither are methods such as these part of the ",(0,a.kt)("inlineCode",{parentName:"li"},"Set")," API. The easiest way to do that is to ",(0,a.kt)("a",o({parentName:"li"},{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Spread_syntax"}),"spread")," into a new array which you can then operate upon.")),(0,a.kt)("p",null,"I have this knowledge. Lots of people have this knowledge. But whilst this may be the case, using this technique goes against what I would generally consider to be a good tenet of programming: comprehensibility. When you read this code above, it doesn't immediately tell you what it's doing. This is a strike against it."),(0,a.kt)("p",null,'Further to that, it\'s "noisy". Even if the reader does have this knowledge, as they digest the code, they have to mentally unravel it. "Oh it\'s a ',(0,a.kt)("inlineCode",{parentName:"p"},"Set"),", we're passing in values, then spreading it out, it's probably intended to get the unique values.... Right, cool, cool.... Continue!\""),(0,a.kt)("iframe",{src:"https://giphy.com/embed/4NnSe87mg3h25JYIDh",width:"100%",height:"100%",frameBorder:"0",allowFullScreen:""}),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/margaridagp"}),"Margarida Pereira")," explicitly called this out and I found myself agreeing. Let's make a ",(0,a.kt)("inlineCode",{parentName:"p"},"uniq")," function!"),(0,a.kt)("h2",o({},{id:"uniq-v1"}),(0,a.kt)("inlineCode",{parentName:"h2"},"uniq")," v1"),(0,a.kt)("p",null,"I wrote a very simple ",(0,a.kt)("inlineCode",{parentName:"p"},"uniq")," function which looked like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"/**\n * Return the unique values found in the passed iterable\n */\nfunction uniq<TElement>(iterableToGetUniqueValuesOf: Iterable<TElement>) {\n  return [...new Set(iterableToGetUniqueValuesOf)];\n}\n")),(0,a.kt)("p",null,"Usage of this was simple:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"uniq([1, 1, 1, 3, 1, 1, 2]); // produces [1, 3, 2]\nuniq(['John', 'Guida', 'Ollie', 'Divya', 'John']); // produces [\"John\", \"Guida\", \"Ollie\", \"Divya\"]\n")),(0,a.kt)("p",null,"And I thought this was tremendous. I committed and pushed. I assumed there was no more to be done. Guida (Margarida) then made this very helpful comment:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"BTW, I found a big bold warning that ",(0,a.kt)("inlineCode",{parentName:"p"},"new Set()")," compares objects by reference (unless they're primitives) so it might be worth adding a comment to warn people that uniq/distinct compares objects by reference: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://codeburst.io/javascript-array-distinct-5edc93501dc4"}),"https://codeburst.io/javascript-array-distinct-5edc93501dc4"))),(0,a.kt)("p",null,"She was right! If a caller was to, say, pass a collection of objects to ",(0,a.kt)("inlineCode",{parentName:"p"},"uniq")," then they'd end up highly disappointed. Consider:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"uniq([{ name: 'John' }, { name: 'John' }]); // produces [{ name: \"John\" }, { name: \"John\" }]\n")),(0,a.kt)("p",null,"We can do better!"),(0,a.kt)("h2",o({},{id:"uniq-v2"}),(0,a.kt)("inlineCode",{parentName:"h2"},"uniq")," v2"),(0,a.kt)("p",null,"I like compilers shouting at me. Or more accurately, I like compilers telling me when something isn't valid / supported / correct. I wanted ",(0,a.kt)("inlineCode",{parentName:"p"},"uniq")," to mirror the behaviour of ",(0,a.kt)("inlineCode",{parentName:"p"},"Set")," ","-"," to only support primitives such as ",(0,a.kt)("inlineCode",{parentName:"p"},"string"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"number")," etc. So I made a new version of ",(0,a.kt)("inlineCode",{parentName:"p"},"uniq")," that hardened up the generic contraints:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"/**\n * Return the unique values found in the passed iterable\n */\nfunction uniq<TElement extends string | number | bigint | boolean | symbol>(\n  iterableToGetUniqueValuesOf: Iterable<TElement>\n) {\n  return [...new Set(iterableToGetUniqueValuesOf)];\n}\n")),(0,a.kt)("p",null,"With this in place, the compiler started shouting in the most helpful way. When I re-attemped ",(0,a.kt)("inlineCode",{parentName:"p"},'[{ name: "John" }, { name: "John" }]')," the compiler hit me with:"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"Argument of type '{ name: string; }[]' is not assignable to parameter of type 'Iterable&lt;string | number | bigint | boolean | symbol&gt;'.")),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/play?#code/FAYw9gdgzmA2CmA6WYDmAKArhAlgR3QG0BvAAggEMBbeALlICIApMACwgdIF8AaUsyjXrM2HbgF0AlJNCQYCZGiy4ChEewZ91HKTOAB6AFSHgpQ6QBK8AC6YAThFLXW8UtnyZXANwqxPUUgAzMGwAE1IcR2dXAAcKKCh4cJxreDsKACMEU0N9YEDsEGscSDcVAB4AFQBRBBoIa1J4AA9UiFCAqGs7SNRSAB9yTCoMtIHSDJxUSMbBjLA4eApHQagATxG4AD50U1J9lLTMhEqwAHEbAFUVTwA1X38AeUD6AElU9Kz4Ktr4eustsBJPw9vs7DZ7I5CIgYRB4AB3UgAZRs6EOnxO5yuN3g9z88Cgz0k4gA3MAuMAgA"}),"Take a look.")),(0,a.kt)("p",null,"This is good. This is descriptive code that only allows legitimate inputs. It should lead to less confusion and a reduced likelihood of issues in Production. It's also a nice example of how code review can result in demonstrably better code. Thanks Guida!"))}d.isMDXComponent=!0},6876:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"images-in-markdown-for-azure-devops-marketplace",title:"Visual Studio Marketplace: images in Markdown!",authors:"johnnyreilly",tags:["azure devops marketplace","Visual Studio Marketplace"],image:"./azure-devops-marketplace.webp",description:"Publish your README/index.md and associated images to Visual Studio Marketplace.",hide_table_of_contents:!1},s=void 0,l={permalink:"/images-in-markdown-for-azure-devops-marketplace",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-11-28-images-in-markdown-for-azure-devops-marketplace/index.md",source:"@site/blog/2020-11-28-images-in-markdown-for-azure-devops-marketplace/index.md",title:"Visual Studio Marketplace: images in Markdown!",description:"Publish your README/index.md and associated images to Visual Studio Marketplace.",date:"2020-11-28T00:00:00.000Z",formattedDate:"November 28, 2020",tags:[{label:"azure devops marketplace",permalink:"/tags/azure-devops-marketplace"},{label:"Visual Studio Marketplace",permalink:"/tags/visual-studio-marketplace"}],readingTime:2.41,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"images-in-markdown-for-azure-devops-marketplace",title:"Visual Studio Marketplace: images in Markdown!",authors:"johnnyreilly",tags:["azure devops marketplace","Visual Studio Marketplace"],image:"./azure-devops-marketplace.webp",description:"Publish your README/index.md and associated images to Visual Studio Marketplace.",hide_table_of_contents:!1},prevItem:{title:"azure-pipelines-task-lib and isOutput setVariable",permalink:"/azure-pipelines-task-lib-and-isoutput-setvariable"},nextItem:{title:"Bulletproof uniq with TypeScript generics (yay code reviews!)",permalink:"/bulletproof-uniq-with-typescript"}},p={image:n(94120).Z,authorsImageUrls:[void 0]},u=[{value:"How can our tasks look as lovely?",id:"how-can-our-tasks-look-as-lovely",level:2},{value:"Mark(Down) our manifest",id:"markdown-our-manifest",level:2},{value:"Now the images...",id:"now-the-images",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I've recently found myself developing ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/devops/extend/develop/add-build-task?view=azure-devops"}),"custom pipelines task extensions for Azure DevOps"),". The extensions being developed end up in the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://marketplace.visualstudio.com/azuredevops"}),"Azure DevOps Marketplace"),". What you see there when you look at existing extensions is some pretty lovely documentation."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"screenshot of a rich Markdown powered screen with images in Visual Studio Marketplace",src:n(94120).Z,width:"600",height:"413"})),(0,a.kt)("h2",o({},{id:"how-can-our-tasks-look-as-lovely"}),"How can our tasks look as lovely?"),(0,a.kt)("p",null,"That, my friends, is the question to answer. Good documentation is key to success. Here's the ask: when a custom task is installed it becomes available in the marketplace, we want it to:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"contain documentation"),(0,a.kt)("li",{parentName:"ul"},"that documentation should support images... For a picture, famously, speaks a thousand words")),(0,a.kt)("h2",o({},{id:"markdown-our-manifest"}),"Mark(Down) our manifest"),(0,a.kt)("p",null,"To get documentation showing up in the marketplace, we need to take a look at the ",(0,a.kt)("inlineCode",{parentName:"p"},"vss-extension.json")," file which lies at the root of our extension folder. It's a kind of manifest file and is documented ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/devops/extend/develop/manifest?view=azure-devops"}),"here"),"."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/devops/extend/develop/manifest?view=azure-devops#discovery-attributes"}),"Tucked away in the docs, you'll find mention of a ",(0,a.kt)("inlineCode",{parentName:"a"},"content")," property and the words:")),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Dictionary of content files that describe your extension to users... Each file is assumed to be in ",(0,a.kt)("a",o({parentName:"p"},{href:"https://help.github.com/articles/github-flavored-markdown/"}),"GitHub Flavored Markdown format"),". The path of each item is the path to the markdown file in the extension. Valid keys: ",(0,a.kt)("inlineCode",{parentName:"p"},"details"),".")),(0,a.kt)("p",null,"This means we can have a Markdown file in our repo which documents our task. To stay consistent with most projects, a solid choice is to use the ",(0,a.kt)("inlineCode",{parentName:"p"},"README/index.md")," that sits in the root of the project to this end."),(0,a.kt)("p",null,"So the simple addition of this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  //...\n  "content": {\n    "details": {\n      "path": "README/index.md"\n    }\n  }\n  //...\n}\n')),(0,a.kt)("p",null,"Gives us documentation in the marketplace. Yay!"),(0,a.kt)("h2",o({},{id:"now-the-images"}),"Now the images..."),(0,a.kt)("p",null,"If we are referencing images in our ",(0,a.kt)("inlineCode",{parentName:"p"},"README/index.md")," then, as it stands right now, they won't show up in the marketplace. It'll be broken link city. Imagine some Markdown like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-md"}),"![alt text](images/screenshot.png)\n")),(0,a.kt)("p",null,"This is entirely correct and supported, but won't work by default. This is because these images need to be specified in the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/devops/extend/develop/manifest?view=azure-devops#files"}),(0,a.kt)("inlineCode",{parentName:"a"},"files")," property")," of the ",(0,a.kt)("inlineCode",{parentName:"p"},"vss-extension.json"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  //...\n  "content": {\n    "details": {\n      "path": "README/index.md"\n    }\n  },\n  "files": [\n    {\n      "path": "images",\n      "addressable": true\n    }\n  ]\n  //...\n}\n')),(0,a.kt)("p",null,"Consider the above; the ",(0,a.kt)("inlineCode",{parentName:"p"},"path")," of ",(0,a.kt)("inlineCode",{parentName:"p"},"images")," includes everything inside the ",(0,a.kt)("inlineCode",{parentName:"p"},"images")," folder in the task. However, it's crucial that the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/devops/extend/develop/manifest?view=azure-devops#properties-1"}),(0,a.kt)("inlineCode",{parentName:"a"},'"addressable": true'))," is present as well. It's this that makes the files in this ",(0,a.kt)("inlineCode",{parentName:"p"},"path")," URL-addressable. And without that, the images won't be displayed."),(0,a.kt)("p",null,"That's it! We're done! We can have rich, image inclusive, documentation in our custom tasks."),(0,a.kt)("p",null,"A final note: it's possible to specify individual files rather than whole paths in the ",(0,a.kt)("inlineCode",{parentName:"p"},"files")," directory and you might want to do that if you're being very careful around file size. There is a maximum size for a custom task and it's easy to breach it. But by and large I find that \"allowlisting\" a single directory is easier."))}d.isMDXComponent=!0},91174:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-pipelines-task-lib-and-isoutput-setvariable",title:"azure-pipelines-task-lib and isOutput setVariable",authors:"johnnyreilly",tags:["Azure Pipelines"],hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-pipelines-task-lib-and-isoutput-setvariable",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-12-09-azure-pipelines-task-lib-and-isoutput-setvariable/index.md",source:"@site/blog/2020-12-09-azure-pipelines-task-lib-and-isoutput-setvariable/index.md",title:"azure-pipelines-task-lib and isOutput setVariable",description:'Some blog posts are insightful treatises on the future of web development, some are "here\'s how I solved my problem". This is most assuredly the latter.',date:"2020-12-09T00:00:00.000Z",formattedDate:"December 9, 2020",tags:[{label:"Azure Pipelines",permalink:"/tags/azure-pipelines"}],readingTime:1.62,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-pipelines-task-lib-and-isoutput-setvariable",title:"azure-pipelines-task-lib and isOutput setVariable",authors:"johnnyreilly",tags:["Azure Pipelines"],hide_table_of_contents:!1},prevItem:{title:"Nullable reference types; CSharp's very own strictNullChecks",permalink:"/nullable-reference-types-csharp-strictnullchecks"},nextItem:{title:"Visual Studio Marketplace: images in Markdown!",permalink:"/images-in-markdown-for-azure-devops-marketplace"}},p={authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'Some blog posts are insightful treatises on the future of web development, some are "here\'s how I solved my problem". This is most assuredly the latter.'),(0,a.kt)("p",null,"I'm writing an ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/devops/extend/develop/add-build-task?view=azure-devops"}),"custom pipelines task extension for Azure Pipelines"),". It's written with TypeScript and the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/azure-pipelines-task-lib"}),"azure-pipelines-task-lib"),"."),(0,a.kt)("p",null,"The pipeline needs to output a variable. Azure Pipelines does that using the ",(0,a.kt)("inlineCode",{parentName:"p"},"setvariable")," command combined with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=azure-devops&tabs=yaml%2Cbatch#set-a-multi-job-output-variable"}),"isOutput=true"),". This looks something like this: ",(0,a.kt)("inlineCode",{parentName:"p"},'##vso[task.setvariable variable=myOutputVar;isOutput=true]this is the value"'),"."),(0,a.kt)("p",null,"The bad news is that the lib ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/azure-pipelines-task-lib/issues/688"}),"doesn't presently support ",(0,a.kt)("inlineCode",{parentName:"a"},"isOutput=true")),". Gosh it makes me sad. Hopefully in future it will be resolved. But what now?"),(0,a.kt)("p",null,"For now we can hack ourselves a workaround:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import * as tl from 'azure-pipelines-task-lib/task';\nimport * as tcm from 'azure-pipelines-task-lib/taskcommand';\nimport * as os from 'os';\n\n/**\n * Sets a variable which will be output as well.\n *\n * @param     name    name of the variable to set\n * @param     val     value to set\n * @param     secret  whether variable is secret.  Multi-line secrets are not allowed.  Optional, defaults to false\n * @returns   void\n */\nexport function setOutputVariable(\n  name: string,\n  val: string,\n  secret = false\n): void {\n  // use the implementation of setVariable to set all the internals,\n  // then subsequently set the output variable manually\n  tl.setVariable(name, val, secret);\n\n  const varValue = val || '';\n\n  // write the command\n  // see https://docs.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=azure-devops&tabs=yaml%2Cbatch#set-a-multi-job-output-variable\n  _command(\n    'task.setvariable',\n    {\n      variable: name || '',\n      isOutput: 'true',\n      issecret: (secret || false).toString(),\n    },\n    varValue\n  );\n}\n\nconst _outStream = process.stdout;\n\nfunction _writeLine(str: string): void {\n  _outStream.write(str + os.EOL);\n}\n\nfunction _command(command: string, properties: any, message: string) {\n  const taskCmd = new tcm.TaskCommand(command, properties, message);\n  _writeLine(taskCmd.toString());\n}\n")),(0,a.kt)("p",null,"The above is effectively a wrapper for the existing ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/azure-pipelines-task-lib/blob/90e9cde0e509cba77185a80ef3af2fc898fb026c/node/task.ts#L162"}),(0,a.kt)("inlineCode",{parentName:"a"},"setVariable")),". However, once it's called into the initial implementation, ",(0,a.kt)("inlineCode",{parentName:"p"},"setOutputVariable")," then writes out the same variable once more, but this time bolting on ",(0,a.kt)("inlineCode",{parentName:"p"},"isOutput=true"),"."),(0,a.kt)("p",null,"Finally, I've raised a PR to see if ",(0,a.kt)("inlineCode",{parentName:"p"},"isOutput")," can be added directly to the library. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/azure-pipelines-task-lib/pull/691"}),"You can track progress on that here.")))}d.isMDXComponent=!0},31056:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"nullable-reference-types-csharp-strictnullchecks",title:"Nullable reference types; CSharp's very own strictNullChecks",authors:"johnnyreilly",tags:["C#","nullable reference types"],hide_table_of_contents:!1},s=void 0,l={permalink:"/nullable-reference-types-csharp-strictnullchecks",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-12-20-nullable-reference-types-csharp-strictnullchecks/index.md",source:"@site/blog/2020-12-20-nullable-reference-types-csharp-strictnullchecks/index.md",title:"Nullable reference types; CSharp's very own strictNullChecks",description:"'Tis the season to play with new compiler settings! I'm a very keen TypeScript user and have been merrily using strictNullChecks since it shipped. I was dimly aware that C# was also getting a similar feature by the name of nullable reference types.",date:"2020-12-20T00:00:00.000Z",formattedDate:"December 20, 2020",tags:[{label:"C#",permalink:"/tags/c"},{label:"nullable reference types",permalink:"/tags/nullable-reference-types"}],readingTime:3.855,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"nullable-reference-types-csharp-strictnullchecks",title:"Nullable reference types; CSharp's very own strictNullChecks",authors:"johnnyreilly",tags:["C#","nullable reference types"],hide_table_of_contents:!1},prevItem:{title:"Make Microsoft.Identity.Web respond with 403 forbidden instead of a 302 redirect",permalink:"/how-to-make-azure-ad-403"},nextItem:{title:"azure-pipelines-task-lib and isOutput setVariable",permalink:"/azure-pipelines-task-lib-and-isoutput-setvariable"}},p={authorsImageUrls:[void 0]},u=[{value:"Turning on nullable reference types",id:"turning-on-nullable-reference-types",level:2},{value:"Really make it hurt",id:"really-make-it-hurt",level:2},{value:"What do they mean?",id:"what-do-they-mean",level:2},{value:"Widening the type to include <code>null</code>",id:"widening-the-type-to-include-null",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"'Tis the season to play with new compiler settings! I'm a very keen TypeScript user and have been merrily using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/docs/handbook/release-notes/typescript-2-0.html#--strictnullchecks"}),(0,a.kt)("inlineCode",{parentName:"a"},"strictNullChecks"))," since it shipped. I was dimly aware that C# was also getting a similar feature by the name of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/csharp/tutorials/nullable-reference-types"}),"nullable reference types"),"."),(0,a.kt)("p",null,"It's only now that I've got round to taking at look at this marvellous feature. I thought I'd share what moving to nullable reference types looked like for me; and what code changes I found myself making as a consequence."),(0,a.kt)("h2",o({},{id:"turning-on-nullable-reference-types"}),"Turning on nullable reference types"),(0,a.kt)("p",null,"To turn on nullable reference types in a C# project you should pop open the ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj")," file and ensure it contains a ",(0,a.kt)("inlineCode",{parentName:"p"},"<Nullable>enable</Nullable>"),". So if you had a .NET Core 3.1 codebase it might look like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),"<PropertyGroup>\n    <TargetFramework>netcoreapp3.1</TargetFramework>\n    <Nullable>enable</Nullable>\n</PropertyGroup>\n")),(0,a.kt)("p",null,"When you compile from this point forward, possible null reference types are reported as warnings. Consider this C#:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[ApiController]\npublic class UserController : ControllerBase\n{\n    private readonly ILogger<UserController> _logger;\n\n    public UserController(ILogger<UserController> logger)\n    {\n        _logger = logger;\n    }\n\n    [AllowAnonymous]\n    [HttpGet("UserName")]\n    public string GetUserName()\n    {\n        if (User.Identity.IsAuthenticated) {\n            _logger.LogInformation("{User} is getting their username", User.Identity.Name);\n            return User.Identity.Name;\n        }\n\n        _logger.LogInformation("The user is not authenticated");\n        return null;\n    }\n}\n')),(0,a.kt)("p",null,"A ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet build")," results in this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"dotnet build --configuration release\n\nMicrosoft (R) Build Engine version 16.7.1+52cd83677 for .NET\nCopyright (C) Microsoft Corporation. All rights reserved.\n\n  Determining projects to restore...\n  Restored /Users/jreilly/code/app/src/server-app/Server/app.csproj (in 471 ms).\nControllers/UserController.cs(38,24): warning CS8603: Possible null reference return. [/Users/jreilly/code/app/src/server-app/Server/app.csproj]\nControllers/UserController.cs(42,20): warning CS8603: Possible null reference return. [/Users/jreilly/code/app/src/server-app/Server/app.csproj]\n  app -> /Users/jreilly/code/app/src/server-app/Server/bin/release/netcoreapp3.1/app.dll\n  app -> /Users/jreilly/code/app/src/server-app/Server/bin/release/netcoreapp3.1/app.Views.dll\n\nBuild succeeded.\n\nControllers/UserController.cs(38,24): warning CS8603: Possible null reference return. [/Users/jreilly/code/app/src/server-app/Server/app.csproj]\nControllers/UserController.cs(42,20): warning CS8603: Possible null reference return. [/Users/jreilly/code/app/src/server-app/Server/app.csproj]\n    2 Warning(s)\n    0 Error(s)\n")),(0,a.kt)("p",null,"You see the two ",(0,a.kt)("inlineCode",{parentName:"p"},'"Possible null reference return."')," warnings? Bingo"),(0,a.kt)("h2",o({},{id:"really-make-it-hurt"}),"Really make it hurt"),(0,a.kt)("p",null,"This is good - information is being surfaced up. But it's a warning. I could ignore it. I like compilers to get really up in my face and force me to make a change. I'm not into warnings; I'm into errors. Know what works for you. If you're similarly minded, you can upgrade nullable reference warnings to errors by tweaking the ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj")," a touch further. Add yourself a ",(0,a.kt)("inlineCode",{parentName:"p"},"<WarningsAsErrors>nullable</WarningsAsErrors>")," element. So maybe your ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj")," now looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),"<PropertyGroup>\n    <TargetFramework>netcoreapp3.1</TargetFramework>\n    <Nullable>enable</Nullable>\n    <WarningsAsErrors>nullable</WarningsAsErrors>\n</PropertyGroup>\n")),(0,a.kt)("p",null,"And a ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet build")," will result in this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"dotnet build --configuration release\n\nMicrosoft (R) Build Engine version 16.7.1+52cd83677 for .NET\nCopyright (C) Microsoft Corporation. All rights reserved.\n\n  Determining projects to restore...\n  Restored /Users/jreilly/code/app/src/server-app/Server/app.csproj (in 405 ms).\nControllers/UserController.cs(38,24): error CS8603: Possible null reference return. [/Users/jreilly/code/app/src/server-app/Server/app.csproj]\nControllers/UserController.cs(42,20): error CS8603: Possible null reference return. [/Users/jreilly/code/app/src/server-app/Server/app.csproj]\n\nBuild FAILED.\n\nControllers/UserController.cs(38,24): error CS8603: Possible null reference return. [/Users/jreilly/code/app/src/server-app/Server/app.csproj]\nControllers/UserController.cs(42,20): error CS8603: Possible null reference return. [/Users/jreilly/code/app/src/server-app/Server/app.csproj]\n    0 Warning(s)\n    2 Error(s)\n")),(0,a.kt)("p",null,"Yay! Errors!"),(0,a.kt)("h2",o({},{id:"what-do-they-mean"}),"What do they mean?"),(0,a.kt)("p",null,'"',(0,a.kt)("inlineCode",{parentName:"p"},"Possible null reference return"),"\" isn't the clearest of errors. What does that actually amount to? Well, it amounts to the compiler saying \"you're a liar! (maybe)\". Let's look again at the code where this error is reported:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[AllowAnonymous]\n[HttpGet("UserName")]\npublic string GetUserName()\n{\n    if (User.Identity.IsAuthenticated) {\n        _logger.LogInformation("{User} is getting their username", User.Identity.Name);\n        return User.Identity.Name;\n    }\n\n    _logger.LogInformation("The user is not authenticated");\n    return null;\n}\n')),(0,a.kt)("p",null,"We're getting that error reported where we're returning ",(0,a.kt)("inlineCode",{parentName:"p"},"null")," and where we're returning ",(0,a.kt)("inlineCode",{parentName:"p"},"User.Identity.Name")," which ",(0,a.kt)("em",{parentName:"p"},"may")," be ",(0,a.kt)("inlineCode",{parentName:"p"},"null"),". And we're getting that because as far as the compiler is concerned ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," has changed. Before we turned on nullable reference types the compiler considered ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," to mean ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," ",(0,a.kt)("em",{parentName:"p"},"OR"),(0,a.kt)("inlineCode",{parentName:"p"},"null"),". Now, ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," means ",(0,a.kt)("inlineCode",{parentName:"p"},"string"),"."),(0,a.kt)("p",null,"This is the same sort of behaviour as TypeScripts ",(0,a.kt)("inlineCode",{parentName:"p"},"strictNullChecks"),". With TypeScript, before you turn on ",(0,a.kt)("inlineCode",{parentName:"p"},"strictNullChecks"),", as far as the compiler is concerned, ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," means ",(0,a.kt)("inlineCode",{parentName:"p"},"string"),(0,a.kt)("em",{parentName:"p"},"OR"),(0,a.kt)("inlineCode",{parentName:"p"},"null"),(0,a.kt)("em",{parentName:"p"},"OR"),(0,a.kt)("inlineCode",{parentName:"p"},"undefined")," (JavaScript didn't feel one null-ish value was enough and so has two - don't ask). Once ",(0,a.kt)("inlineCode",{parentName:"p"},"strictNullChecks")," is on, ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," means ",(0,a.kt)("inlineCode",{parentName:"p"},"string"),"."),(0,a.kt)("p",null,"It's a lot clearer. And that's why the compiler is getting antsy. The method signature is ",(0,a.kt)("inlineCode",{parentName:"p"},"string"),", but it can see ",(0,a.kt)("inlineCode",{parentName:"p"},"null")," potentially being returned. It doesn't like it. By and large that's good. We want the compiler to notice this as that's the entire point. We want to catch accidental ",(0,a.kt)("inlineCode",{parentName:"p"},"null"),"s before they hit a user. This is ",(0,a.kt)("em",{parentName:"p"},"great"),"! However, what do you do if have a method (as we do) that legitimately returns a ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"null"),"?"),(0,a.kt)("h2",o({},{id:"widening-the-type-to-include-null"}),"Widening the type to include ",(0,a.kt)("inlineCode",{parentName:"h2"},"null")),(0,a.kt)("p",null,"We change the signature from this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public string GetUserName()\n")),(0,a.kt)("p",null,"To this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public string? GetUserName()\n")),(0,a.kt)("p",null,"That's right, the simple addition of ",(0,a.kt)("inlineCode",{parentName:"p"},"?")," marks a reference type (like a string) as potentially being ",(0,a.kt)("inlineCode",{parentName:"p"},"null"),". Adding that means that we're potentially returning ",(0,a.kt)("inlineCode",{parentName:"p"},"null"),", but we're sure about it; there's intention here - it's not accidental. Wonderful!"))}d.isMDXComponent=!0},51990:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"how-to-make-azure-ad-403",title:"Make Microsoft.Identity.Web respond with 403 forbidden instead of a 302 redirect",authors:"johnnyreilly",tags:["Azure AD","ASP.NET"],image:"./Forbidden.webp",hide_table_of_contents:!1},s=void 0,l={permalink:"/how-to-make-azure-ad-403",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-12-21-how-to-make-azure-ad-403/index.md",source:"@site/blog/2020-12-21-how-to-make-azure-ad-403/index.md",title:"Make Microsoft.Identity.Web respond with 403 forbidden instead of a 302 redirect",description:"By default Microsoft.Identity.Web responds to unauthorized requests with a 302 (redirect). Do you want a 403 (forbidden) instead? Here's how.",date:"2020-12-21T00:00:00.000Z",formattedDate:"December 21, 2020",tags:[{label:"Azure AD",permalink:"/tags/azure-ad"},{label:"ASP.NET",permalink:"/tags/asp-net"}],readingTime:2.72,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"how-to-make-azure-ad-403",title:"Make Microsoft.Identity.Web respond with 403 forbidden instead of a 302 redirect",authors:"johnnyreilly",tags:["Azure AD","ASP.NET"],image:"./Forbidden.webp",hide_table_of_contents:!1},prevItem:{title:"dotnet-format: Prettier your C# with lint-staged & husky",permalink:"/prettier-your-csharp-with-dotnet-format-and-lint-staged"},nextItem:{title:"Nullable reference types; CSharp's very own strictNullChecks",permalink:"/nullable-reference-types-csharp-strictnullchecks"}},p={image:n(34929).Z,authorsImageUrls:[void 0]},u=[{value:"Give us <code>403</code>",id:"give-us-403",level:2},{value:"Extra customisation bonus points",id:"extra-customisation-bonus-points",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"By default ",(0,a.kt)("inlineCode",{parentName:"p"},"Microsoft.Identity.Web")," responds to unauthorized requests with a 302 (redirect). Do you want a 403 (forbidden) instead? Here's how."),(0,a.kt)("p",null,"If you're using the tremendous ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/active-directory/develop/scenario-web-app-sign-user-app-configuration?tabs=aspnetcore"}),"Azure Active Directory for authentication with ASP.NET")," then there's a good chance you're using the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/AzureAD/microsoft-identity-web"}),(0,a.kt)("inlineCode",{parentName:"a"},"Microsoft.Identity.Web"))," library. It's this that allows us to drop the following statement into the ",(0,a.kt)("inlineCode",{parentName:"p"},"ConfigureServices")," method of our ",(0,a.kt)("inlineCode",{parentName:"p"},"Startup")," class:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"services.AddMicrosoftIdentityWebAppAuthentication(Configuration);\n")),(0,a.kt)("p",null,"Which (combined with configuration in our ",(0,a.kt)("inlineCode",{parentName:"p"},"appsettings.json")," files) hooks us up with Azure AD for authentication. This is 95% awesome. The 5% is what we're here for. Here's a screenshot of the scenario that troubles us:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"a screenshot of Chrome Devtools showing a 302",src:n(99028).Z,width:"2326",height:"1090"})),(0,a.kt)("p",null,"We've made a request to ",(0,a.kt)("inlineCode",{parentName:"p"},"/WeatherForecast"),"; a secured endpoint (a controller decorated with the ",(0,a.kt)("inlineCode",{parentName:"p"},"Authorize")," attribute). We're authenticated; the app knows who we are. But we're not authorized / allowed to access this endpoint. We don't have permission. The HTTP specification caters directly for this scenario with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://tools.ietf.org/html/rfc7231#section-6.5.3"}),"status code ",(0,a.kt)("inlineCode",{parentName:"a"},"403 Forbidden")),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"The 403 (Forbidden) status code indicates that the server understood the request but refuses to authorize it.")),(0,a.kt)("p",null,"However, ",(0,a.kt)("inlineCode",{parentName:"p"},"Microsoft.Identity.Web")," is ploughing another furrow. Instead of returning ",(0,a.kt)("inlineCode",{parentName:"p"},"403"),", it's returning ",(0,a.kt)("inlineCode",{parentName:"p"},"302 Found")," and redirecting the browser to ",(0,a.kt)("inlineCode",{parentName:"p"},"https://localhost:5001/Account/AccessDenied?ReturnUrl=%2FWeatherForecast"),". Now the intentions here are ",(0,a.kt)("em",{parentName:"p"},"great"),". If you wanted to implement a page in your application at that endpoint that displayed some kind of useful message it would be really useful. However, what if you want the more HTTP-y behaviour instead? In the case of a HTTP request triggered by JavaScript (typical for Single Page Applications) then this redirect isn't that helpful. JavaScript doesn't really know what to do with the ",(0,a.kt)("inlineCode",{parentName:"p"},"302")," and whilst you could code around this, it's not desirable."),(0,a.kt)("p",null,"We want ",(0,a.kt)("inlineCode",{parentName:"p"},"403")," - we don't want ",(0,a.kt)("inlineCode",{parentName:"p"},"302"),"."),(0,a.kt)("h2",o({},{id:"give-us-403"}),"Give us ",(0,a.kt)("inlineCode",{parentName:"h2"},"403")),(0,a.kt)("p",null,"You can have this behaviour by dropping the following code after your ",(0,a.kt)("inlineCode",{parentName:"p"},"services.AddMicrosoftIdentityWebAppAuthentication"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"services.Configure<CookieAuthenticationOptions>(CookieAuthenticationDefaults.AuthenticationScheme, options =>\n{\n    options.Events.OnRedirectToAccessDenied = new Func<RedirectContext<CookieAuthenticationOptions>, Task>(context =>\n    {\n        context.Response.StatusCode = StatusCodes.Status403Forbidden;\n        return context.Response.CompleteAsync();\n    });\n});\n")),(0,a.kt)("p",null,"This code hijacks the redirect to AccessDenied and transforms it into a ",(0,a.kt)("inlineCode",{parentName:"p"},"403")," instead. Tremendous! What does this look like?"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"a screenshot of Chrome Devtools showing a 403",src:n(34929).Z,width:"2326",height:"1090"})),(0,a.kt)("p",null,"This is the behaviour we want!"),(0,a.kt)("h2",o({},{id:"extra-customisation-bonus-points"}),"Extra customisation bonus points"),(0,a.kt)("p",null,"You may want to have some nuance to the way you handle unauthorized requests. Because of the nature of ",(0,a.kt)("inlineCode",{parentName:"p"},"OnRedirectToAccessDenied")," this is entirely possible; you have complete access to the requests coming in which you can use to direct behaviour. To take a single example, let's say we want to direct normal browsing behaviour (AKA humans clicking about in Chrome) which is not authorized to a given screen, otherwise provide ",(0,a.kt)("inlineCode",{parentName:"p"},"403"),"s. What would that look like?"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'services.Configure<CookieAuthenticationOptions>(CookieAuthenticationDefaults.AuthenticationScheme, options =>\n{\n    options.Events.OnRedirectToAccessDenied = new Func<RedirectContext<CookieAuthenticationOptions>, Task>(context =>\n    {\n        var isRequestForHtml = context.Request.Headers["Accept"].ToString().Contains("text/html");\n        if (isRequestForHtml) {\n            context.Response.StatusCode = StatusCodes.Status302Found;\n            context.Response.Headers["Location"] = "/unauthorized";\n        }\n        else {\n            context.Response.StatusCode = StatusCodes.Status403Forbidden;\n        }\n\n        return context.Response.CompleteAsync();\n    });\n});\n')),(0,a.kt)("p",null,"So above, we check the request ",(0,a.kt)("inlineCode",{parentName:"p"},"Accept")," headers and see if they contain ",(0,a.kt)("inlineCode",{parentName:"p"},'"text/html"'),"; which we're using as a signal that the request came from a users browsing. (This may not be bulletproof; better suggestions gratefully received.) If the request does contain a ",(0,a.kt)("inlineCode",{parentName:"p"},'"text/html"``Accept')," header then we redirect the client to an ",(0,a.kt)("inlineCode",{parentName:"p"},"/unauthorized")," screen, otherwise we return ",(0,a.kt)("inlineCode",{parentName:"p"},"403")," as we did before. Super flexible and powerful!"))}d.isMDXComponent=!0},97120:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"prettier-your-csharp-with-dotnet-format-and-lint-staged",title:"dotnet-format: Prettier your C# with lint-staged & husky",authors:"johnnyreilly",image:"./title-image.png",tags:["Prettier"],hide_table_of_contents:!1},s=void 0,l={permalink:"/prettier-your-csharp-with-dotnet-format-and-lint-staged",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-12-22-prettier-your-csharp-with-dotnet-format-and-lint-staged/index.md",source:"@site/blog/2020-12-22-prettier-your-csharp-with-dotnet-format-and-lint-staged/index.md",title:"dotnet-format: Prettier your C# with lint-staged & husky",description:"Consistent formatting in a codebase is a good thing. We can achieve this in dotnet using dotnet format, used in combination with the npm packages husky and lint-staged. This post shows how.",date:"2020-12-22T00:00:00.000Z",formattedDate:"December 22, 2020",tags:[{label:"Prettier",permalink:"/tags/prettier"}],readingTime:4.375,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"prettier-your-csharp-with-dotnet-format-and-lint-staged",title:"dotnet-format: Prettier your C# with lint-staged & husky",authors:"johnnyreilly",image:"./title-image.png",tags:["Prettier"],hide_table_of_contents:!1},prevItem:{title:"Azure Pipelines meet Jest",permalink:"/azure-pipelines-meet-jest"},nextItem:{title:"Make Microsoft.Identity.Web respond with 403 forbidden instead of a 302 redirect",permalink:"/how-to-make-azure-ad-403"}},p={image:n(87158).Z,authorsImageUrls:[void 0]},u=[{value:"Updated 17/09/2021",id:"updated-17092021",level:2},{value:"Updated linting 07/04/2022",id:"updated-linting-07042022",level:2},{value:"Why format?",id:"why-format",level:2},{value:"<code>dotnet-format</code>: a new hope",id:"dotnet-format-a-new-hope",level:2},{value:"Customising our formatting",id:"customising-our-formatting",level:2},{value:"<code>lint-staged</code> / <code>husky</code> integration",id:"lint-staged--husky-integration",level:2},{value:"CSharpier - update 16/05/2021",id:"csharpier---update-16052021",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Consistent formatting in a codebase is a good thing. We can achieve this in dotnet using ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet format"),", used in combination with the npm packages ",(0,a.kt)("inlineCode",{parentName:"p"},"husky")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"lint-staged"),". This post shows how."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;dotnet-format: Prettier your CSharp with lint-staged and husky&quot; and the dotnet-format logo",src:n(87158).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"updated-17092021"}),"Updated 17/09/2021"),(0,a.kt)("p",null,"This has been updated to work with the latest versions of ",(0,a.kt)("inlineCode",{parentName:"p"},"lint-staged")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"husky"),"."),(0,a.kt)("h2",o({},{id:"updated-linting-07042022"}),"Updated linting 07/04/2022"),(0,a.kt)("p",null,"If you're interested in formatting, you might be interested in linting; formatting's big sister. C# has linting too; ",(0,a.kt)("a",o({parentName:"p"},{href:"/eslint-your-csharp-in-vs-code-with-roslyn-analyzers"}),"read about it here"),"."),(0,a.kt)("h2",o({},{id:"why-format"}),"Why format?"),(0,a.kt)("p",null,'Consistent formatting makes code less confusing to newcomers and it allows whoever is working on the codebase to reliably focus on the task at hand. Not "fixing curly braces because Janice messed them up with her last commit". (A ',(0,a.kt)("inlineCode",{parentName:"p"},"git commit")," message that would be tragic in so many ways.)"),(0,a.kt)("p",null,"Once we've agreed that we want to have consistent formatting, we want it to be enforced. Enter, stage left, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://prettier.io/"}),"Prettier"),", the fantastic tool for formatting code. It rocks; I've been using on my JavaScript / TypeScript for the longest time. But what about C#? Well, there is a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/warrenseine/prettier-plugin-csharp"}),"Prettier plugin for C#"),".... Sort of. It appears to be abandoned and contains the worrying message in the ",(0,a.kt)("inlineCode",{parentName:"p"},"README/index.md"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Please note that this plugin is under active development, and might not be ready to run on production code yet. It will break your code.")),(0,a.kt)("p",null,"Not a ringing endorsement."),(0,a.kt)("h2",o({},{id:"dotnet-format-a-new-hope"}),(0,a.kt)("inlineCode",{parentName:"h2"},"dotnet-format"),": a new hope"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/margaridagp"}),"Margarida Pereira")," recently pointed me in the direction of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dotnet/format"}),(0,a.kt)("inlineCode",{parentName:"a"},"dotnet-format"))," which is a formatter for .NET. It's a .NET tool which:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"is a code formatter for dotnet that applies style preferences to a project or solution. Preferences will be read from an ",(0,a.kt)("inlineCode",{parentName:"p"},".editorconfig")," file, if present, otherwise a default set of preferences will be used.")),(0,a.kt)("p",null,"It can be installed with:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"dotnet tool install -g dotnet-format\n")),(0,a.kt)("p",null,"The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dotnet/format/issues/648#issuecomment-614905524"}),"VS Code C# extension will make use of this formatter"),", we just need to set the following in our ",(0,a.kt)("inlineCode",{parentName:"p"},"settings.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"omnisharp.enableRoslynAnalyzers": true,\n"omnisharp.enableEditorConfigSupport": true\n')),(0,a.kt)("h2",o({},{id:"customising-our-formatting"}),"Customising our formatting"),(0,a.kt)("p",null,"If we'd like to deviate from the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/fundamentals/code-analysis/code-style-rule-options"}),"default formatting options")," then create ourselves an ",(0,a.kt)("inlineCode",{parentName:"p"},".editorconfig")," file in the root of our project. Let's say we prefer more of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Indentation_style#K&R_style"}),"K & R style")," approach to braces instead of the C# default of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Indentation_style#Allman_style"}),"Allman style"),". To make ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet-format")," use that we'd set the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ini"}),"# Remove the line below if you want to inherit .editorconfig settings from higher directories\nroot = true\n\n# See https://github.com/dotnet/format/blob/master/docs/Supported-.editorconfig-options/index.md for reference\n[*.cs]\ncsharp_new_line_before_open_brace = none\ncsharp_new_line_before_catch = false\ncsharp_new_line_before_else = false\ncsharp_new_line_before_finally = false\ncsharp_new_line_before_members_in_anonymous_types = false\ncsharp_new_line_before_members_in_object_initializers = false\ncsharp_new_line_between_query_expression_clauses = true\n")),(0,a.kt)("p",null,"With this in place it's K & R all the way baby!"),(0,a.kt)("h2",o({},{id:"lint-staged--husky-integration"}),(0,a.kt)("inlineCode",{parentName:"h2"},"lint-staged")," / ",(0,a.kt)("inlineCode",{parentName:"h2"},"husky")," integration"),(0,a.kt)("p",null,"It's become somewhat standard to use the marvellous ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/typicode/husky"}),(0,a.kt)("inlineCode",{parentName:"a"},"husky"))," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/okonet/lint-staged"}),(0,a.kt)("inlineCode",{parentName:"a"},"lint-staged"))," to enforce code quality. To quote the docs:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Run linters against staged git files and don't let \ud83d\udca9 slip into our code base!")),(0,a.kt)("p",null,"To add this to our (otherwise C# codebase), we're going to need a ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-sh"}),"npm init --yes\n")),(0,a.kt)("p",null,"We'll install ",(0,a.kt)("inlineCode",{parentName:"p"},"husky")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"lint-staged"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-sh"}),"npx husky-init && npm install\nnpm install lint-staged --save-dev\n")),(0,a.kt)("p",null,"We should have a new file living at ",(0,a.kt)("inlineCode",{parentName:"p"},".husky/pre-commit")," which is our pre-commit hook."),(0,a.kt)("p",null,"Within that file we should replace ",(0,a.kt)("inlineCode",{parentName:"p"},"npm test")," with ",(0,a.kt)("inlineCode",{parentName:"p"},"npx lint-staged --relative"),". This is the command that will be run on commit. ",(0,a.kt)("inlineCode",{parentName:"p"},"lint-staged")," will be run and we're specifying ",(0,a.kt)("inlineCode",{parentName:"p"},"relative")," so that ",(0,a.kt)("strong",{parentName:"p"},"relative")," file paths will be used. This is important as ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet format"),"'s ",(0,a.kt)("inlineCode",{parentName:"p"},"--include"),' accepts "a list of relative file or folder paths to include in formatting". ',(0,a.kt)("strong",{parentName:"p"},"Absolute paths (the default) won't work - and if we pass them to ",(0,a.kt)("inlineCode",{parentName:"strong"},"dotnet format"),", it will not format the files.")),(0,a.kt)("p",null,"Finally we add the following entry to the ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'  "lint-staged": {\n    "*.cs": "dotnet format --include"\n  }\n')),(0,a.kt)("p",null,"This is the task that will be invoked by ",(0,a.kt)("inlineCode",{parentName:"p"},"lint-staged")," against files with a ",(0,a.kt)("inlineCode",{parentName:"p"},".cs")," suffix on commit. When ",(0,a.kt)("inlineCode",{parentName:"p"},"lint-staged")," runs, it will pass a list of relative file paths to ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet format"),". So if we'd staged two files it might end up executing a command like this:"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"dotnet format --include src/server-app/Server/Controllers/UserController.cs src/server-app/Server/Controllers/WeatherForecastController.cs")),(0,a.kt)("p",null,"We should end up with a ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," that looks something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "name": "app",\n  "version": "1.0.0",\n  "description": "[![Shared Build Status](https://dev.azure.com/investec/maas/_apis/build/status/shared?repoName=maas)](https://dev.azure.com/investec/maas/_build/latest?definitionId=1128&repoName=maas)",\n  "main": "index.js",\n  "dependencies": {\n    "husky": "^7.0.2"\n  },\n  "devDependencies": {\n    "husky": "^7.0.0",\n    "lint-staged": "^11.1.2"\n  },\n  "scripts": {\n    "test": "echo \\"Error: no test specified\\" && exit 1",\n    "prepare": "husky install"\n  },\n  "lint-staged": {\n    "*.cs": "dotnet format --include"\n  },\n  "repository": {\n    "type": "git",\n    "url": "https://investec@dev.azure.com/investec/maas/_git/maas"\n  },\n  "keywords": [],\n  "author": "",\n  "license": "ISC"\n}\n')),(0,a.kt)("p",null,"By and large we don't have to think about this; the important take home is that we're now enforcing standardised formatting for all C# files upon commit. Everything that goes into the codebase will be formatted in a consistent fashion."),(0,a.kt)("h2",o({},{id:"csharpier---update-16052021"}),"CSharpier - update 16/05/2021"),(0,a.kt)("p",null,"There is an alternative to the CSharp Prettier project. It's being worked on by\n",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/belav"}),"Bela VanderVoort")," and it goes by the name of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/belav/csharpier"}),"csharpier"),". When comparing CSharpier and dotnet-format, Bela put it like this:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"I could see CSharpier being the non-configurable super opinionated formatter and dotnet-format being for the people that do want to have options.")),(0,a.kt)("p",null,"Check it out!"))}d.isMDXComponent=!0},68539:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-pipelines-meet-jest",title:"Azure Pipelines meet Jest",authors:"johnnyreilly",image:"./test-results.webp",tags:["azure-pipelines","jest"],hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-pipelines-meet-jest",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2020-12-30-azure-pipelines-meet-jest/index.md",source:"@site/blog/2020-12-30-azure-pipelines-meet-jest/index.md",title:"Azure Pipelines meet Jest",description:"This post explains how to integrate the tremendous test runner Jest with the continuous integration platform Azure Pipelines. Perhaps we're setting up a new project and we've created a new React app with Create React App. This ships with Jest support out of the box. How do we get that plugged into Pipelines such that:",date:"2020-12-30T00:00:00.000Z",formattedDate:"December 30, 2020",tags:[{label:"azure-pipelines",permalink:"/tags/azure-pipelines"},{label:"jest",permalink:"/tags/jest"}],readingTime:3.275,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-pipelines-meet-jest",title:"Azure Pipelines meet Jest",authors:"johnnyreilly",image:"./test-results.webp",tags:["azure-pipelines","jest"],hide_table_of_contents:!1},prevItem:{title:"Create React App with ts-loader and CRACO",permalink:"/create-react-app-with-ts-loader-and-craco"},nextItem:{title:"dotnet-format: Prettier your C# with lint-staged & husky",permalink:"/prettier-your-csharp-with-dotnet-format-and-lint-staged"}},p={image:n(26693).Z,authorsImageUrls:[void 0]},u=[{value:"Tests run as part of our pipeline",id:"tests-run-as-part-of-our-pipeline",level:2},{value:"Tests results are reported in Azure Pipelines UI",id:"tests-results-are-reported-in-azure-pipelines-ui",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This post explains how to integrate the tremendous test runner ",(0,a.kt)("a",o({parentName:"p"},{href:"https://jestjs.io/"}),"Jest")," with the continuous integration platform ",(0,a.kt)("a",o({parentName:"p"},{href:"https://azure.microsoft.com/en-gb/services/devops/pipelines/?nav=min"}),"Azure Pipelines"),". Perhaps we're setting up a new project and we've created a new React app with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://create-react-app.dev/"}),"Create React App"),". This ships with Jest support out of the box. How do we get that plugged into Pipelines such that:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Tests run as part of our pipeline"),(0,a.kt)("li",{parentName:"ol"},"A failing test fails the build"),(0,a.kt)("li",{parentName:"ol"},"Test results are reported in Azure Pipelines UI?")),(0,a.kt)("h2",o({},{id:"tests-run-as-part-of-our-pipeline"}),"Tests run as part of our pipeline"),(0,a.kt)("p",null,"First of all, lets get the tests running. Crack open your ",(0,a.kt)("inlineCode",{parentName:"p"},"azure-pipelines.yml")," file and, in the appropriate place add the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- task: Npm@1\n  displayName: npm run test\n  inputs:\n    command: 'custom'\n    workingDir: 'src/client-app'\n    customCommand: 'run test'\n")),(0,a.kt)("p",null,"The above will, when run, trigger a ",(0,a.kt)("inlineCode",{parentName:"p"},"npm run test")," in the ",(0,a.kt)("inlineCode",{parentName:"p"},"src/client-app")," folder of my project (it's here where my React app lives). You'd imagine this would just work\u2122\ufe0f - but life is not that simple. This is because Jest, by default, runs in watch mode. This is blocking and so not appropriate for CI."),(0,a.kt)("p",null,"In our ",(0,a.kt)("inlineCode",{parentName:"p"},"src/client-app/package.json")," let's create a new script that runs the tests but ",(0,a.kt)("em",{parentName:"p"},"not")," in watch mode:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"test:ci": "npm run test -- --watchAll=false",\n')),(0,a.kt)("p",null,"and switch our ",(0,a.kt)("inlineCode",{parentName:"p"},"azure-pipelines.yml")," to use it:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- task: Npm@1\n  displayName: npm run test\n  inputs:\n    command: 'custom'\n    workingDir: 'src/client-app'\n    customCommand: 'run test:ci'\n")),(0,a.kt)("p",null,"Boom! We're now running tests as part of our pipeline. And also, failing tests will fail the build, because of Jest's default behaviour of exiting with status code 1 on failed tests."),(0,a.kt)("h2",o({},{id:"tests-results-are-reported-in-azure-pipelines-ui"}),"Tests results are reported in Azure Pipelines UI"),(0,a.kt)("p",null,"Pipelines has a really nice UI for reporting test results. If you're using something like .NET then you'll find that test results just magically show up there. We'd like that for our Jest tests as well. And we can have it."),(0,a.kt)("p",null,"The way we achieve this is by:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Producing test results in a format that can be subsequently processed"),(0,a.kt)("li",{parentName:"ol"},"Using those test results to publish to Azure Pipelines")),(0,a.kt)("p",null,"The way that you configure Jest test output is through usage of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://jestjs.io/docs/en/cli#--reporters"}),(0,a.kt)("inlineCode",{parentName:"a"},"reporters")),". However, Create React App doesn't support these. However that's not an issue, as the marvellous ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/dan_abramov"}),"Dan Abramov")," demonstrates ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/create-react-app/issues/2474#issuecomment-306340526"}),"here"),"."),(0,a.kt)("p",null,"We need to install the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jest-community/jest-junit"}),(0,a.kt)("inlineCode",{parentName:"a"},"jest-junit"))," package to our ",(0,a.kt)("inlineCode",{parentName:"p"},"client-app"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"npm install jest-junit --save-dev\n")),(0,a.kt)("p",null,"And we'll tweak our ",(0,a.kt)("inlineCode",{parentName:"p"},"test:ci")," script to use the ",(0,a.kt)("inlineCode",{parentName:"p"},"jest-junit")," reporter as well:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"test:ci": "npm run test -- --watchAll=false --reporters=default --reporters=jest-junit",\n')),(0,a.kt)("p",null,"We also need to add some configuration to our ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," in the form of a ",(0,a.kt)("inlineCode",{parentName:"p"},"jest-junit")," element:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"jest-junit": {\n        "suiteNameTemplate": "{filepath}",\n        "outputDirectory": ".",\n        "outputName": "junit.xml"\n    }\n')),(0,a.kt)("p",null,"The above configuration will use the name of the test file as the suite name in the results, which should speed up the tracking down of the failing test. The other values specify where the test results should be published to, in this case the root of our ",(0,a.kt)("inlineCode",{parentName:"p"},"client-app")," with the filename ",(0,a.kt)("inlineCode",{parentName:"p"},"junit.xml"),"."),(0,a.kt)("p",null,"Now our CI is producing our test results, how do we get them into Pipelines? For that we need the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/test/publish-test-results?view=azure-devops&tabs=trx%2Cyaml"}),"Publish test results task")," and a new step in our ",(0,a.kt)("inlineCode",{parentName:"p"},"azure-pipelines.yml")," ",(0,a.kt)("em",{parentName:"p"},"after")," our ",(0,a.kt)("inlineCode",{parentName:"p"},"npm run test")," step:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- task: Npm@1\n  displayName: npm run test\n  inputs:\n    command: 'custom'\n    workingDir: 'src/client-app'\n    customCommand: 'run test:ci'\n\n- task: PublishTestResults@2\n  displayName: 'supply npm test results to pipelines'\n  condition: succeededOrFailed() # because otherwise we won't know what tests failed\n  inputs:\n    testResultsFiles: 'src/client-app/junit.xml'\n")),(0,a.kt)("p",null,"This will read the test results from our ",(0,a.kt)("inlineCode",{parentName:"p"},"src/client-app/junit.xml")," file and pump them into Pipelines. Do note that we're ",(0,a.kt)("em",{parentName:"p"},"always")," running this step; so if the previous step failed (as it would in the case of a failing test) we still pump out the details of what that failure was. Like so:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"screenshot of test results being published to Azure Pipelines regardless of passing or failing tests",src:n(45981).Z,width:"592",height:"136"})),(0,a.kt)("p",null,"And that's it! Azure Pipelines and Jest integrated."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of test results published to Azure Pipelines",src:n(26693).Z,width:"600",height:"153"})))}d.isMDXComponent=!0},8511:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"create-react-app-with-ts-loader-and-craco",title:"Create React App with ts-loader and CRACO",authors:"johnnyreilly",tags:["typescript","fork-ts-checker-webpack-plugin","ts-loader"],hide_table_of_contents:!1},s=void 0,l={permalink:"/create-react-app-with-ts-loader-and-craco",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-01-02-create-react-app-with-ts-loader-and-craco/index.md",source:"@site/blog/2021-01-02-create-react-app-with-ts-loader-and-craco/index.md",title:"Create React App with ts-loader and CRACO",description:"Create React App is a fantastic way to get up and running building a web app with React. It also supports using TypeScript with React. Simply entering the following:",date:"2021-01-02T00:00:00.000Z",formattedDate:"January 2, 2021",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"fork-ts-checker-webpack-plugin",permalink:"/tags/fork-ts-checker-webpack-plugin"},{label:"ts-loader",permalink:"/tags/ts-loader"}],readingTime:3.41,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"create-react-app-with-ts-loader-and-craco",title:"Create React App with ts-loader and CRACO",authors:"johnnyreilly",tags:["typescript","fork-ts-checker-webpack-plugin","ts-loader"],hide_table_of_contents:!1},prevItem:{title:"react-query: strongly typing useQueries",permalink:"/strongly-typing-react-query-s-usequeries"},nextItem:{title:"Azure Pipelines meet Jest",permalink:"/azure-pipelines-meet-jest"}},p={authorsImageUrls:[void 0]},u=[{value:"<del><code>babel-loader</code></del> <code>ts-loader</code>",id:"babel-loader-ts-loader",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://create-react-app.dev/"}),"Create React App")," is a fantastic way to get up and running building a web app with React. It also supports using TypeScript with React. Simply entering the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"npx create-react-app my-app --template typescript\n")),(0,a.kt)("p",null,"Will give you a great TypeScript React project to get building with. There's two parts to the TypeScript support that exist:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},'Transpilation AKA "turning our TypeScript into JavaScript". Back since ',(0,a.kt)("a",o({parentName:"li"},{href:"https://devblogs.microsoft.com/typescript/typescript-and-babel-7/"}),"Babel 7 launched, Babel has enjoyed great support for transpiling TypeScript into JavaScript"),". Create React App leverages this; using the Babel webpack loader, ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/babel/babel-loader"}),"babel-loader"),", for transpilation."),(0,a.kt)("li",{parentName:"ol"},'Type checking AKA "seeing if our code compiles". Create React App uses the ',(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/TypeStrong/fork-ts-checker-webpack-plugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"fork-ts-checker-webpack-plugin"))," to run the TypeScript type checker on a separate process and report any issues that may exist.")),(0,a.kt)("p",null,"This is a great setup and works very well for the majority of use cases. However, what if we'd like to tweak this setup? What if we'd like to swap out ",(0,a.kt)("inlineCode",{parentName:"p"},"babel-loader")," for ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," for compilation purposes? Can we do that?"),(0,a.kt)("p",null,"Yes you can! And that's what we're going to do using a tool named ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/gsoft-inc/craco"}),(0,a.kt)("inlineCode",{parentName:"a"},"CRACO"))," ","-",' the pithy shortening of "Create React App Configuration Override". This is a tool that allows us to:'),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Get all the benefits of create-react-app and customization without using 'eject' by adding a single ",(0,a.kt)("inlineCode",{parentName:"p"},"craco.config.js")," file at the root of your application and customize your eslint, babel, postcss configurations and many more.")),(0,a.kt)("h2",o({},{id:"babel-loader-ts-loader"}),(0,a.kt)("del",{parentName:"h2"},(0,a.kt)("inlineCode",{parentName:"del"},"babel-loader"))," ",(0,a.kt)("inlineCode",{parentName:"h2"},"ts-loader")),(0,a.kt)("p",null,"So let's do the swap. First of all we're going to need to add ",(0,a.kt)("inlineCode",{parentName:"p"},"CRACO")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," to our project:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"npm install @craco/craco ts-loader --save-dev\n")),(0,a.kt)("p",null,"Then we'll swap over our various ",(0,a.kt)("inlineCode",{parentName:"p"},"scripts")," in our ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," to use ",(0,a.kt)("inlineCode",{parentName:"p"},"CRACO"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"start": "craco start",\n"build": "craco build",\n"test": "craco test",\n')),(0,a.kt)("p",null,"Finally we'll add a ",(0,a.kt)("inlineCode",{parentName:"p"},"craco.config.js")," file to the root of our project. This is where we swap out ",(0,a.kt)("inlineCode",{parentName:"p"},"babel-loader")," for ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const {\n  addAfterLoader,\n  removeLoaders,\n  loaderByName,\n  getLoaders,\n  throwUnexpectedConfigError,\n} = require('@craco/craco');\n\nconst throwError = (message) =>\n  throwUnexpectedConfigError({\n    packageName: 'craco',\n    githubRepo: 'gsoft-inc/craco',\n    message,\n    githubIssueQuery: 'webpack',\n  });\n\nmodule.exports = {\n  webpack: {\n    configure: (webpackConfig, { paths }) => {\n      const { hasFoundAny, matches } = getLoaders(\n        webpackConfig,\n        loaderByName('babel-loader')\n      );\n      if (!hasFoundAny) throwError('failed to find babel-loader');\n\n      console.log('removing babel-loader');\n      const { hasRemovedAny, removedCount } = removeLoaders(\n        webpackConfig,\n        loaderByName('babel-loader')\n      );\n      if (!hasRemovedAny) throwError('no babel-loader to remove');\n      if (removedCount !== 2)\n        throwError('had expected to remove 2 babel loader instances');\n\n      console.log('adding ts-loader');\n\n      const tsLoader = {\n        test: /\\.(js|mjs|jsx|ts|tsx)$/,\n        include: paths.appSrc,\n        loader: require.resolve('ts-loader'),\n        options: { transpileOnly: true },\n      };\n\n      const { isAdded: tsLoaderIsAdded } = addAfterLoader(\n        webpackConfig,\n        loaderByName('url-loader'),\n        tsLoader\n      );\n      if (!tsLoaderIsAdded) throwError('failed to add ts-loader');\n      console.log('added ts-loader');\n\n      console.log('adding non-application JS babel-loader back');\n      const { isAdded: babelLoaderIsAdded } = addAfterLoader(\n        webpackConfig,\n        loaderByName('ts-loader'),\n        matches[1].loader // babel-loader\n      );\n      if (!babelLoaderIsAdded)\n        throwError('failed to add back babel-loader for non-application JS');\n      console.log('added non-application JS babel-loader back');\n\n      return webpackConfig;\n    },\n  },\n};\n")),(0,a.kt)("p",null,"So what's happening here? The script looks for ",(0,a.kt)("inlineCode",{parentName:"p"},"babel-loader")," usages in the default Create React App config. There will be two; one for TypeScript / JavaScript application code (we want to replace this) and one for non application JavaScript code. I'm actually not too clear what non application JavaScript code there is or can be, but we'll leave it in place; it may be important."),(0,a.kt)("p",null,"You cannot remove a ",(0,a.kt)("em",{parentName:"p"},"single")," loader using ",(0,a.kt)("inlineCode",{parentName:"p"},"CRACO"),", so instead we'll remove both and we'll add back the non application JavaScript ",(0,a.kt)("inlineCode",{parentName:"p"},"babel-loader"),". We'll also add ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," with the ",(0,a.kt)("inlineCode",{parentName:"p"},"transpileOnly: true")," option set (to ensure ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," doesn't do type checking)."),(0,a.kt)("p",null,"Now the next time we run ",(0,a.kt)("inlineCode",{parentName:"p"},"npm start")," we'll have Create React App running using ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," and ",(0,a.kt)("em",{parentName:"p"},"without")," having ejected. If we want to adjust the options of ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," further then we're completely at liberty to do so, adjusting the ",(0,a.kt)("inlineCode",{parentName:"p"},"options")," in our ",(0,a.kt)("inlineCode",{parentName:"p"},"craco.config.js"),"."),(0,a.kt)("p",null,"If you value debugging your original source code rather than the transpiled JavaScript, remember to set the ",(0,a.kt)("inlineCode",{parentName:"p"},'"sourceMap": true')," property in your ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json"),"."),(0,a.kt)("p",null,"Finally, if we wanted to go even further, we could remove the ",(0,a.kt)("inlineCode",{parentName:"p"},"fork-ts-checker-webpack-plugin")," and move ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," to use ",(0,a.kt)("inlineCode",{parentName:"p"},"transpileOnly: false")," so it performs type checking also. However, generally it may be better to stay with the setup with post outlines for performance reasons."))}d.isMDXComponent=!0},4573:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"strongly-typing-react-query-s-usequeries",title:"react-query: strongly typing useQueries",authors:"johnnyreilly",image:"./strongly-typing-usequeries.webp",tags:["useQueries","react-query"],hide_table_of_contents:!1},s=void 0,l={permalink:"/strongly-typing-react-query-s-usequeries",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-01-03-strongly-typing-react-query-s-usequeries/index.md",source:"@site/blog/2021-01-03-strongly-typing-react-query-s-usequeries/index.md",title:"react-query: strongly typing useQueries",description:"react-query has a weakly typed hook named useQueries. It's possible to turn that into a strong typed hook; this post shows you how.",date:"2021-01-03T00:00:00.000Z",formattedDate:"January 3, 2021",tags:[{label:"useQueries",permalink:"/tags/use-queries"},{label:"react-query",permalink:"/tags/react-query"}],readingTime:7.84,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"strongly-typing-react-query-s-usequeries",title:"react-query: strongly typing useQueries",authors:"johnnyreilly",image:"./strongly-typing-usequeries.webp",tags:["useQueries","react-query"],hide_table_of_contents:!1},prevItem:{title:"Azure Easy Auth and Roles with .NET (and .NET Core)",permalink:"/azure-easy-auth-and-roles-with-dotnet-and-core"},nextItem:{title:"Create React App with ts-loader and CRACO",permalink:"/create-react-app-with-ts-loader-and-craco"}},p={image:n(13630).Z,authorsImageUrls:[void 0]},u=[{value:"Updated April 2022",id:"updated-april-2022",level:2},{value:"What is <code>useQueries</code>?",id:"what-is-usequeries",level:2},{value:"<code>useQueriesTyped</code> - a strongly typed wrapper for <code>useQueries</code>",id:"usequeriestyped---a-strongly-typed-wrapper-for-usequeries",level:2},{value:"Usage",id:"usage",level:2},{value:"In the box?",id:"in-the-box",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"react-query")," has a weakly typed hook named ",(0,a.kt)("inlineCode",{parentName:"p"},"useQueries"),". It's possible to turn that into a strong typed hook; this post shows you how."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image that says &quot;react-query: strongly typings useQueries&quot;",src:n(13630).Z,width:"800",height:"237"})),(0,a.kt)("h2",o({},{id:"updated-april-2022"}),"Updated April 2022"),(0,a.kt)("p",null,"You don't need this blog post! Just use a ",(0,a.kt)("inlineCode",{parentName:"p"},"react-query@3.28.0")," or greater; ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/artysidorenko"}),"artysidorenko")," ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/tannerlinsley/react-query/pull/2634"}),"contributed a PR that moved this behaviour into the package"),"."),(0,a.kt)("h2",o({},{id:"what-is-usequeries"}),"What is ",(0,a.kt)("inlineCode",{parentName:"h2"},"useQueries"),"?"),(0,a.kt)("p",null,"If you haven't used ",(0,a.kt)("a",o({parentName:"p"},{href:"https://react-query.tanstack.com/"}),(0,a.kt)("inlineCode",{parentName:"a"},"react-query"))," then I heartily recommend it. It provides (to quote the docs):"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Hooks for fetching, caching and updating asynchronous data in React")),(0,a.kt)("p",null,"With version 3 of ",(0,a.kt)("inlineCode",{parentName:"p"},"react-query"),", a new hook was added: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://react-query.tanstack.com/reference/useQueries"}),(0,a.kt)("inlineCode",{parentName:"a"},"useQueries")),". This hook allows you fetch a variable number of queries at the same time. An example of what usage looks like is this (",(0,a.kt)("a",o({parentName:"p"},{href:"https://react-query.tanstack.com/guides/parallel-queries#dynamic-parallel-queries-with-usequeries"}),"borrowed from the excellent docs"),"):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"function App({ users }) {\n  const userQueries = useQueries(\n    users.map((user) => {\n      return {\n        queryKey: ['user', user.id],\n        queryFn: () => fetchUserById(user.id),\n      };\n    })\n  );\n}\n")),(0,a.kt)("p",null,"Whilst ",(0,a.kt)("inlineCode",{parentName:"p"},"react-query")," is written in TypeScript, the way that ",(0,a.kt)("inlineCode",{parentName:"p"},"useQueries")," is presently written strips the types that are supplied to it. Consider ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/tannerlinsley/react-query/blob/d25ab3ef8260ea1c02b52b7082c3ce4120596b31/src/react/useQueries.ts#L8"}),"the signature of the ",(0,a.kt)("inlineCode",{parentName:"a"},"useQueries")),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export function useQueries(queries: UseQueryOptions[]): UseQueryResult[] {\n")),(0,a.kt)("p",null,"This returns an array of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/tannerlinsley/react-query/blob/d25ab3ef8260ea1c02b52b7082c3ce4120596b31/src/react/types.ts#L42"}),(0,a.kt)("inlineCode",{parentName:"a"},"UseQueryResult")),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export type UseQueryResult<\n  TData = unknown,\n  TError = unknown\n> = UseBaseQueryResult<TData, TError>;\n")),(0,a.kt)("p",null,"As you can see, no type parameters are passed to ",(0,a.kt)("inlineCode",{parentName:"p"},"UseQueryResult")," in the ",(0,a.kt)("inlineCode",{parentName:"p"},"useQueries")," signature and so it takes the default types of ",(0,a.kt)("inlineCode",{parentName:"p"},"unknown"),". This forces the consumer to either assert the type that they believe to be there, or to use type narrowing to ensure the type. The former approach exposes a possibility of errors (the user can specify incorrect types) and the latter approach requires our code to perform type narrowing operations which are essentially unnecessary (the type hasn't changed since it was returned; it's simply been discarded)."),(0,a.kt)("p",null,"What if there was a way to strongly type ",(0,a.kt)("inlineCode",{parentName:"p"},"useQueries")," so we neither risked specifying incorrect types, nor wasted precious lines of code and CPU cycles performing type narrowing? There is my friends, read on!"),(0,a.kt)("h2",o({},{id:"usequeriestyped---a-strongly-typed-wrapper-for-usequeries"}),(0,a.kt)("inlineCode",{parentName:"h2"},"useQueriesTyped")," - a strongly typed wrapper for ",(0,a.kt)("inlineCode",{parentName:"h2"},"useQueries")),(0,a.kt)("p",null,"It's possible to wrap the ",(0,a.kt)("inlineCode",{parentName:"p"},"useQueries")," hook with our own ",(0,a.kt)("inlineCode",{parentName:"p"},"useQueriesTyped")," hook which exposes a strongly typed API. It looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { useQueries, UseQueryOptions, UseQueryResult } from 'react-query';\n\ntype Awaited<T> = T extends PromiseLike<infer U> ? Awaited<U> : T;\n\nexport function useQueriesTyped<TQueries extends readonly UseQueryOptions[]>(\n  queries: [...TQueries]\n): {\n  [ArrayElement in keyof TQueries]: UseQueryResult<\n    TQueries[ArrayElement] extends { select: infer TSelect }\n      ? TSelect extends (data: any) => any\n        ? ReturnType<TSelect>\n        : never\n      : Awaited<\n          ReturnType<\n            NonNullable<\n              Extract<TQueries[ArrayElement], UseQueryOptions>['queryFn']\n            >\n          >\n        >\n  >;\n} {\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  return useQueries(\n    queries as UseQueryOptions<unknown, unknown, unknown>[]\n  ) as any;\n}\n")),(0,a.kt)("p",null,"Let's unpack this. The first and most significant thing to note here is that ",(0,a.kt)("inlineCode",{parentName:"p"},"queries")," moves from being ",(0,a.kt)("inlineCode",{parentName:"p"},"UseQueryOptions[]")," to being ",(0,a.kt)("inlineCode",{parentName:"p"},"TQueries extends readonly UseQueryOptions[]")," ","-"," far more fancy! The reason for this change is we want the type parameters to flow through on an element by element basis in the supplied array. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/docs/handbook/release-notes/typescript-4-0.html#variadic-tuple-types"}),"TypeScript 4's variadic tuple types")," should allow us to support this. So the new array signature looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"queries: [...TQueries];\n")),(0,a.kt)("p",null,"Where ",(0,a.kt)("inlineCode",{parentName:"p"},"TQueries")," is"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"TQueries extends readonly UseQueryOptions[]\n")),(0,a.kt)("p",null,"What this means is, that each element of the rest parameters array must have a type of ",(0,a.kt)("inlineCode",{parentName:"p"},"readonly UseQueryOptions"),". Otherwise the compiler will shout at us (and rightly so)."),(0,a.kt)("p",null,"So that's what's coming in.... What's going out? Well the return type of ",(0,a.kt)("inlineCode",{parentName:"p"},"useQueriesTyped")," is the tremendously verbose:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"{\n  [ArrayElement in keyof TQueries]: UseQueryResult<\n    TQueries[ArrayElement] extends { select: infer TSelect }\n      ? TSelect extends (data: any) => any\n        ? ReturnType<TSelect>\n        : never\n      : Awaited<\n          ReturnType<\n            NonNullable<\n              Extract<TQueries[ArrayElement], UseQueryOptions>['queryFn']\n            >\n          >\n        >\n  >\n}\n")),(0,a.kt)("p",null,"Let's walk this through. First of all we'll look at this bit:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"{ [ArrayElement in keyof TQueries]: /* the type has been stripped to protect your eyes */ }\n")),(0,a.kt)("p",null,"On the face of it, it looks like we're returning an ",(0,a.kt)("inlineCode",{parentName:"p"},"Object"),", not an ",(0,a.kt)("inlineCode",{parentName:"p"},"Array"),". There's nuance here; ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array"}),"JavaScript ",(0,a.kt)("inlineCode",{parentName:"a"},"Array"),"s are ",(0,a.kt)("inlineCode",{parentName:"a"},"Object"),"s"),"."),(0,a.kt)("p",null,"More specifically, by approaching the signature this way, we can acquire the ",(0,a.kt)("inlineCode",{parentName:"p"},"ArrayElement")," type which represents each of the keys of the array. Consider this array:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"[1, 'two', new Date()];\n")),(0,a.kt)("p",null,"For the above, ",(0,a.kt)("inlineCode",{parentName:"p"},"ArrayElement")," would take the values ",(0,a.kt)("inlineCode",{parentName:"p"},"0"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"1")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"2"),". And this is going to prove useful in a moment as we're going to index into our ",(0,a.kt)("inlineCode",{parentName:"p"},"TQueries")," object to surface up the return types for each element of our return array from there."),(0,a.kt)("p",null,"Now let's look at the return type for each element. The signature of that looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"UseQueryResult<\n  TQueries[ArrayElement] extends { select: infer TSelect }\n    ? TSelect extends (data: any) => any\n      ? ReturnType<TSelect>\n      : never\n    : Awaited<\n        ReturnType<\n          NonNullable<\n            Extract<TQueries[ArrayElement], UseQueryOptions>['queryFn']\n          >\n        >\n      >\n>;\n")),(0,a.kt)("p",null,"Gosh... Well there's a lot going on here. Let's start in the middle and work our way out."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"TQueries[ArrayElement];\n")),(0,a.kt)("p",null,"The above code indexes into our ",(0,a.kt)("inlineCode",{parentName:"p"},"TQueries")," array for each element of our strongly typed indexer ",(0,a.kt)("inlineCode",{parentName:"p"},"ArrayElement"),". So it might resolve the first element of an array to ",(0,a.kt)("inlineCode",{parentName:"p"},"{ queryKey: 'key1', queryFn: () =&gt; 1 }"),", for example. Next:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"Extract < TQueries[ArrayElement], UseQueryOptions > ['queryFn'];\n")),(0,a.kt)("p",null,"We're now taking the type of each element provided, and grabbing the type of the ",(0,a.kt)("inlineCode",{parentName:"p"},"queryFn")," property. It's this type which contains the type of the data that will be passed back, that we want to make use of. So for an examples of ",(0,a.kt)("inlineCode",{parentName:"p"},"[{ queryKey: 'key1', queryFn: () =&gt; 1 }, { queryKey: 'key2', queryFn: () =&gt; 'two' }, { queryKey: 'key3', queryFn: () =&gt; new Date() }]")," we'd have the type: ",(0,a.kt)("inlineCode",{parentName:"p"},"const result: [() =&gt; number, () =&gt; string, () =&gt; Date]"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"NonNullable<Extract<TQueries[ArrayElement], UseQueryOptions>['queryFn']>;\n")),(0,a.kt)("p",null,"The next stage is using ",(0,a.kt)("inlineCode",{parentName:"p"},"NonNullable")," on our ",(0,a.kt)("inlineCode",{parentName:"p"},"queryFn"),", given that on ",(0,a.kt)("inlineCode",{parentName:"p"},"UseQueryOptions")," it's an optional type. In our use case it is not optional / nullable and so we need to enforce that."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"ReturnType<\n  NonNullable<Extract<TQueries[ArrayElement], UseQueryOptions>['queryFn']>\n>;\n")),(0,a.kt)("p",null,"Now we want to get the return type of our ",(0,a.kt)("inlineCode",{parentName:"p"},"queryFn")," ","-"," as that's the data type we're interested. So we use TypeScript's ",(0,a.kt)("inlineCode",{parentName:"p"},"ReturnType")," for that."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"ReturnType<\n  NonNullable<Extract<TQueries[ArrayElement], UseQueryOptions>['queryFn']>\n>;\n")),(0,a.kt)("p",null,"Here we're using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://devblogs.microsoft.com/typescript/announcing-typescript-4-1/#recursive-conditional-types"}),"TypeScript 4.1's recursive conditional types")," to unwrap a ",(0,a.kt)("inlineCode",{parentName:"p"},"Promise")," (or not) to the relevant type. This allows us to get the actual type we're interested in, as opposed to the ",(0,a.kt)("inlineCode",{parentName:"p"},"Promise")," of that type. Finally we have the type we need! So we can do this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"type Awaited<T> = T extends PromiseLike<infer U> ? Awaited<U> : T;\n\nAwaited<\n  ReturnType<\n    NonNullable<Extract<TQueries[ArrayElement], UseQueryOptions>['queryFn']>\n  >\n>;\n")),(0,a.kt)("p",null,"It's at this point where we reach a conditional type in our type definition. Essentially, we have two different typing behaviours in play:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Where we're inferring the return type of the query"),(0,a.kt)("li",{parentName:"ol"},"Where we're inferring the return type of a ",(0,a.kt)("inlineCode",{parentName:"li"},"select"),". A ",(0,a.kt)("inlineCode",{parentName:"li"},"select")," option can be used to transform or select a part of the data returned by the query function. It has the signature: ",(0,a.kt)("inlineCode",{parentName:"li"},"select: (data: TData) => TSelect"))),(0,a.kt)("p",null,"We've been unpacking the first of these so far. Now we encounter the conditional type that chooses between them:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"TQueries[ArrayElement] extends { select: infer TSelect }\n      ? TSelect extends (data: any) => any\n        ? ReturnType<TSelect>\n        : never\n      : Awaited< /*...*/ >\n  >\n")),(0,a.kt)("p",null,"What's happening here is:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"if a query includes a ",(0,a.kt)("inlineCode",{parentName:"li"},"select")," option, we infer what that is and then subsequently extract the return type of the ",(0,a.kt)("inlineCode",{parentName:"li"},"select"),"."),(0,a.kt)("li",{parentName:"ul"},"otherwise we use the query return type (as we we've previously examined)")),(0,a.kt)("p",null,"Finally, whichever type we end up with, we supply that type as a parameter to ",(0,a.kt)("inlineCode",{parentName:"p"},"UseQueryResult"),". And that is what is going to surface up our types to our users."),(0,a.kt)("h2",o({},{id:"usage"}),"Usage"),(0,a.kt)("p",null,"So what does using our ",(0,a.kt)("inlineCode",{parentName:"p"},"useQueriesTyped")," hook look like?"),(0,a.kt)("p",null,"Well, supplying ",(0,a.kt)("inlineCode",{parentName:"p"},"queryFn"),"s with different signatures looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const result = useQueriesTyped(\n  { queryKey: 'key1', queryFn: () => 1 },\n  { queryKey: 'key2', queryFn: () => 'two' }\n);\n// const result: [QueryObserverResult<number, unknown>, QueryObserverResult<string, unknown>]\n\nif (result[0].data) {\n  // number\n}\nif (result[1].data) {\n  // string\n}\n")),(0,a.kt)("p",null,"As you can see, we're being returned a ",(0,a.kt)("inlineCode",{parentName:"p"},"Tuple")," and the exact types are flowing through."),(0,a.kt)("p",null,"Next let's look at a ",(0,a.kt)("inlineCode",{parentName:"p"},".map")," example with identical types in our supplied array:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const resultWithAllTheSameTypes = useQueriesTyped(\n  ...[1, 2].map((x) => ({ queryKey: `${x}`, queryFn: () => x }))\n);\n// const resultWithAllTheSameTypes: QueryObserverResult<number, unknown>[]\n\nif (resultWithAllTheSameTypes[0].data) {\n  // number\n}\n")),(0,a.kt)("p",null,"The return type of ",(0,a.kt)("inlineCode",{parentName:"p"},"number")," is flowing through for each element."),(0,a.kt)("p",null,"Finally let's look at how ",(0,a.kt)("inlineCode",{parentName:"p"},".map")," handles arrays with different types of elements:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const resultWithDifferentTypes = useQueriesTyped(\n  ...[1, 'two', new Date()].map((x) => ({ queryKey: `${x}`, queryFn: () => x }))\n);\n//const resultWithDifferentTypes: QueryObserverResult<string | number | Date, unknown>[]\n\nif (resultWithDifferentTypes[0].data) {\n  // string | number | Date\n}\n\nif (resultWithDifferentTypes[1].data) {\n  // string | number | Date\n}\n\nif (resultWithDifferentTypes[2].data) {\n  // string | number | Date\n}\n")),(0,a.kt)("p",null,"Admittedly this last example is a somewhat unlikely scenario. But again we can see the types flowing through - though further narrowing would be required here to get to the exact type."),(0,a.kt)("h2",o({},{id:"in-the-box"}),"In the box?"),(0,a.kt)("p",null,"It's great that we can wrap ",(0,a.kt)("inlineCode",{parentName:"p"},"useQueries")," to get a strongly typed experience. It would be tremendous if this functionality was available by default. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/tannerlinsley/react-query/pull/1527"}),"There's a discussion going on around this"),". It's possible that this wrapper may no longer need to exist, and that would be amazing. In the meantime; enjoy!"))}d.isMDXComponent=!0},46541:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-easy-auth-and-roles-with-dotnet-and-core",title:"Azure Easy Auth and Roles with .NET (and .NET Core)",authors:"johnnyreilly",tags:["Azure","authorization","authentication","Azure AD"],hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-easy-auth-and-roles-with-dotnet-and-core",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-01-14-azure-easy-auth-and-roles-with-dotnet-and-core/index.md",source:"@site/blog/2021-01-14-azure-easy-auth-and-roles-with-dotnet-and-core/index.md",title:"Azure Easy Auth and Roles with .NET (and .NET Core)",description:"If this post is interesting to you, you may also want to look at this one where we try to use Microsoft.Identity.Web for the same purpose.",date:"2021-01-14T00:00:00.000Z",formattedDate:"January 14, 2021",tags:[{label:"Azure",permalink:"/tags/azure"},{label:"authorization",permalink:"/tags/authorization"},{label:"authentication",permalink:"/tags/authentication"},{label:"Azure AD",permalink:"/tags/azure-ad"}],readingTime:5.64,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-easy-auth-and-roles-with-dotnet-and-core",title:"Azure Easy Auth and Roles with .NET (and .NET Core)",authors:"johnnyreilly",tags:["Azure","authorization","authentication","Azure AD"],hide_table_of_contents:!1},prevItem:{title:"Azure Easy Auth and Roles with .NET and Microsoft.Identity.Web",permalink:"/azure-easy-auth-and-roles-with-net-and-microsoft-identity-web"},nextItem:{title:"react-query: strongly typing useQueries",permalink:"/strongly-typing-react-query-s-usequeries"}},p={authorsImageUrls:[void 0]},u=[{value:"Where are our roles?",id:"where-are-our-roles",level:2},{value:"Role up, role up!",id:"role-up-role-up",level:2},{value:"Update: Potential ways forward",id:"update-potential-ways-forward",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("em",{parentName:"p"},"If this post is interesting to you, you may also want to ",(0,a.kt)("a",o({parentName:"em"},{href:"/azure-easy-auth-and-roles-with-net-and-microsoft-identity-web"}),"look at this one where we try to use Microsoft.Identity.Web for the same purpose."))),(0,a.kt)("p",null,"Azure has a feature which is intended to allow Authentication and Authorization to be applied outside of your application code. It's called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/app-service/overview-authentication-authorization"}),'"Easy Auth"'),". Unfortunately, in the context of App Services it doesn't work with .NET Core and .NET. Perhaps it would be better to say: of the various .NETs, it supports .NET Framework. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/app-service/overview-authentication-authorization#userapplication-claims"}),"To quote the docs"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"At this time, ASP.NET Core does not currently support populating the current user with the Authentication/Authorization feature. However, some ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/MaximRouiller/MaximeRouiller.Azure.AppService.EasyAuth"}),"3rd party, open source middleware components")," do exist to help fill this gap.")),(0,a.kt)("p",null,"Thanks to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/MaximRouiller"}),"Maxime Rouiller")," there's a way forward here. However, as I was taking this for a spin today, I discovered another issue."),(0,a.kt)("h2",o({},{id:"where-are-our-roles"}),"Where are our roles?"),(0,a.kt)("p",null,"Consider the following .NET controller:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[Authorize(Roles = "Administrator,Reader")]\n[HttpGet("api/admin-reader")]\npublic string GetWithAdminOrReader() =>\n    "this is a secure endpoint that users with the Administrator or Reader role can access";\n\n[Authorize(Roles = "Administrator")]\n[HttpGet("api/admin")]\npublic string GetWithAdmin() =>\n    "this is a secure endpoint that users with the Administrator role can access";\n\n[Authorize(Roles = "Reader")]\n[HttpGet("api/reader")]\npublic string GetWithReader() =>\n    "this is a secure endpoint that users with the Reader role can access";\n')),(0,a.kt)("p",null,"The three endpoints above restrict access based upon roles. However, even with Maxime's marvellous shim in the mix, authorization doesn't work when deployed to an Azure App Service. Why? Well, it comes down to how roles are mapped to claims."),(0,a.kt)("p",null,"Let's back up a bit. First of all we've added a dependency to our project:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"dotnet add package MaximeRouiller.Azure.AppService.EasyAuth\n")),(0,a.kt)("p",null,"Next we've updated our ",(0,a.kt)("inlineCode",{parentName:"p"},"Startup.ConfigureServices")," such that it looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'if (Env.IsDevelopment()) {\n    services.AddMicrosoftIdentityWebAppAuthentication(Configuration);\nelse\n    services.AddAuthentication("EasyAuth").AddEasyAuthAuthentication((o) => { });\n')),(0,a.kt)("p",null,"With the above in place, either the Microsoft Identity platform will directly be used for authentication, or Maxime's package will be used as the default authentication scheme. The driver for this is ",(0,a.kt)("inlineCode",{parentName:"p"},"Env")," which is an ",(0,a.kt)("inlineCode",{parentName:"p"},"IHostEnvironment")," that was injected to the ",(0,a.kt)("inlineCode",{parentName:"p"},"Startup.cs"),". Running locally, both authentication and authorization will work. However, deployed to an Azure App Service, only authentication will work."),(0,a.kt)("p",null,"It turns out that directly using the Microsoft Identity platform, we see roles claims coming through like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'[\n  // ...\n  {\n    "type": "http://schemas.microsoft.com/ws/2008/06/identity/claims/role",\n    "value": "Administrator"\n  },\n  {\n    "type": "http://schemas.microsoft.com/ws/2008/06/identity/claims/role",\n    "value": "Reader"\n  }\n  // ...\n]\n')),(0,a.kt)("p",null,"But in Azure we see roles claims showing up with a different ",(0,a.kt)("inlineCode",{parentName:"p"},"type"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'[\n  // ...\n  {\n    "type": "roles",\n    "value": "Administrator"\n  },\n  {\n    "type": "roles",\n    "value": "Reader"\n  }\n  // ...\n]\n')),(0,a.kt)("p",null,"This is the crux of the problem; .NET and .NET Core are looking in a different place for roles."),(0,a.kt)("h2",o({},{id:"role-up-role-up"}),"Role up, role up!"),(0,a.kt)("p",null,"There wasn't an obvious way to make this work with Maxime's package. So we ended up lifting the source code of Maxime's package and tweaking it. Take a look:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using Microsoft.AspNetCore.Authentication;\nusing Microsoft.Extensions.DependencyInjection;\nusing Microsoft.Extensions.Logging;\nusing Microsoft.Extensions.Options;\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Security.Claims;\nusing System.Text.Encodings.Web;\nusing System.Text.Json;\nusing System.Text.Json.Serialization;\nusing System.Threading.Tasks;\n\n/// <summary>\n/// Based on https://github.com/MaximRouiller/MaximeRouiller.Azure.AppService.EasyAuth\n/// Essentially EasyAuth only supports .NET Framework: https://docs.microsoft.com/en-us/azure/app-service/app-service-authentication-how-to#access-user-claims\n/// This allows us to get support for Authentication and Authorization (using roles) with .NET\n/// </summary>\nnamespace EasyAuth {\n    public static class EasyAuthAuthenticationBuilderExtensions {\n        public static AuthenticationBuilder AddEasyAuthAuthentication(\n            this IServiceCollection services) =>\n            services.AddAuthentication("EasyAuth").AddEasyAuthAuthenticationScheme(o => { });\n\n        public static AuthenticationBuilder AddEasyAuthAuthenticationScheme(\n            this AuthenticationBuilder builder,\n            Action<EasyAuthAuthenticationOptions> configure) =>\n                builder.AddScheme<EasyAuthAuthenticationOptions, EasyAuthAuthenticationHandler>(\n                    "EasyAuth",\n                    "EasyAuth",\n                    configure);\n    }\n\n    public class EasyAuthAuthenticationOptions : AuthenticationSchemeOptions {\n        public EasyAuthAuthenticationOptions() {\n            Events = new object();\n        }\n    }\n\n    public class EasyAuthAuthenticationHandler : AuthenticationHandler<EasyAuthAuthenticationOptions> {\n        public EasyAuthAuthenticationHandler(\n            IOptionsMonitor<EasyAuthAuthenticationOptions> options,\n            ILoggerFactory logger,\n            UrlEncoder encoder,\n            ISystemClock clock)\n            : base(options, logger, encoder, clock) {\n        }\n\n        protected override Task<AuthenticateResult> HandleAuthenticateAsync() {\n            try {\n                var easyAuthEnabled = string.Equals(Environment.GetEnvironmentVariable("WEBSITE_AUTH_ENABLED", EnvironmentVariableTarget.Process), "True", StringComparison.InvariantCultureIgnoreCase);\n                if (!easyAuthEnabled) return Task.FromResult(AuthenticateResult.NoResult());\n\n                var easyAuthProvider = Context.Request.Headers["X-MS-CLIENT-PRINCIPAL-IDP"].FirstOrDefault();\n                var msClientPrincipalEncoded = Context.Request.Headers["X-MS-CLIENT-PRINCIPAL"].FirstOrDefault();\n                if (string.IsNullOrWhiteSpace(easyAuthProvider) ||\n                    string.IsNullOrWhiteSpace(msClientPrincipalEncoded))\n                    return Task.FromResult(AuthenticateResult.NoResult());\n\n                var decodedBytes = Convert.FromBase64String(msClientPrincipalEncoded);\n                var msClientPrincipalDecoded = System.Text.Encoding.Default.GetString(decodedBytes);\n                var clientPrincipal = JsonSerializer.Deserialize<MsClientPrincipal>(msClientPrincipalDecoded);\n                if (clientPrincipal == null) return Task.FromResult(AuthenticateResult.NoResult());\n\n                var mappedRolesClaims = clientPrincipal.Claims\n                    .Where(claim => claim.Type == "roles")\n                    .Select(claim => new Claim(ClaimTypes.Role, claim.Value))\n                    .ToList();\n\n                var claims = clientPrincipal.Claims.Select(claim => new Claim(claim.Type, claim.Value)).ToList();\n                claims.AddRange(mappedRolesClaims);\n\n                var principal = new ClaimsPrincipal();\n                principal.AddIdentity(new ClaimsIdentity(claims, clientPrincipal.AuthenticationType, clientPrincipal.NameType, clientPrincipal.RoleType));\n\n                var ticket = new AuthenticationTicket(principal, easyAuthProvider);\n                var success = AuthenticateResult.Success(ticket);\n                Context.User = principal;\n\n                return Task.FromResult(success);\n            } catch (Exception ex) {\n                return Task.FromResult(AuthenticateResult.Fail(ex));\n            }\n        }\n    }\n\n    public class MsClientPrincipal {\n        [JsonPropertyName("auth_typ")]\n        public string? AuthenticationType { get; set; }\n        [JsonPropertyName("claims")]\n        public IEnumerable<UserClaim> Claims { get; set; } = Array.Empty<UserClaim>();\n        [JsonPropertyName("name_typ")]\n        public string? NameType { get; set; }\n        [JsonPropertyName("role_typ")]\n        public string? RoleType { get; set; }\n    }\n\n    public class UserClaim {\n        [JsonPropertyName("typ")]\n        public string Type { get; set; } = string.Empty;\n        [JsonPropertyName("val")]\n        public string Value { get; set; } = string.Empty;\n    }\n}\n')),(0,a.kt)("p",null,"There's a number of changes in the above code to Maxime's package. Three changes that are not significant and one that is. First the insignificant changes:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"It uses ",(0,a.kt)("a",o({parentName:"li"},{href:"https://docs.microsoft.com/en-us/dotnet/standard/serialization/system-text-json-how-to?pivots=dotnet-5-0"}),(0,a.kt)("inlineCode",{parentName:"a"},"System.Text.Json"))," in place of JSON.NET"),(0,a.kt)("li",{parentName:"ol"},"It uses ",(0,a.kt)("a",o({parentName:"li"},{href:"/nullable-reference-types-csharp-strictnullchecks"}),"C#s nullable reference types")),(0,a.kt)("li",{parentName:"ol"},"It changes the extension method signature such that instead of entering ",(0,a.kt)("inlineCode",{parentName:"li"},"services.AddAuthentication().AddEasyAuthAuthentication((o) => { })")," we now need only enter ",(0,a.kt)("inlineCode",{parentName:"li"},"services.AddEasyAuthAuthentication()"))),(0,a.kt)("p",null,"Now the significant change:"),(0,a.kt)("p",null,"Where the middleware encounters claims in the ",(0,a.kt)("inlineCode",{parentName:"p"},"X-MS-CLIENT-PRINCIPAL")," header with the ",(0,a.kt)("inlineCode",{parentName:"p"},"Type")," of ",(0,a.kt)("inlineCode",{parentName:"p"},'"roles"')," it creates brand new claims for each, with the same ",(0,a.kt)("inlineCode",{parentName:"p"},"Value")," but with the official ",(0,a.kt)("inlineCode",{parentName:"p"},"Type")," supplied by ",(0,a.kt)("inlineCode",{parentName:"p"},"ClaimsTypes.Role")," of ",(0,a.kt)("inlineCode",{parentName:"p"},'"http://schemas.microsoft.com/ws/2008/06/identity/claims/role"'),". The upshot of this, is that when the processed claims are inspected in Azure they now look more like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'[\n  // ...\n  {\n    "type": "roles",\n    "value": "Administrator"\n  },\n  {\n    "type": "roles",\n    "value": "Reader"\n  },\n  // ...\n  {\n    "type": "http://schemas.microsoft.com/ws/2008/06/identity/claims/role",\n    "value": "Administrator"\n  },\n  {\n    "type": "http://schemas.microsoft.com/ws/2008/06/identity/claims/role",\n    "value": "Reader"\n  }\n]\n')),(0,a.kt)("p",null,"As you can see, we now have both the originally supplied roles ",(0,a.kt)("em",{parentName:"p"},"as well")," as roles of the type that .NET and .NET Core expect. Consequently, roles based behaviour starts to work. Thanks to Maxime for his fine work on the initial solution. It would be tremendous if neither the code in this blog post nor Maxime's shim were required. Still, until that glorious day!"),(0,a.kt)("h2",o({},{id:"update-potential-ways-forward"}),"Update: Potential ways forward"),(0,a.kt)("p",null,"When I was tweeting this post, Maxime was good enough to respond and suggest that this may be resolved within Azure itself in future:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Oh, so that's why they removed the name? \ud83d\ude32\ud83d\ude1c Jokes aside, we hope that this package won't be necessary for the future. I know that ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/mattchenderson?ref_src=twsrc%5Etfw"}),"@mattchenderson")," is part of a working group to update Easy Auth. Might want to make sure you follow him as well. \ud83d\ude01"),(0,a.kt)("p",{parentName:"blockquote"},"\u2014 Maxime Rouiller (@MaximRouiller) ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/MaximRouiller/status/1349804324713615366?ref_src=twsrc%5Etfw"}),"January 14, 2021"))),(0,a.kt)("p",null,"There's a prospective PR that would add an event to Maxime's API. If something along these lines was merged, then my workaround would no longer be necessary. Follow the PR ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/MaximRouiller/MaximeRouiller.Azure.AppService.EasyAuth/pull/13"}),"here"),"."))}d.isMDXComponent=!0},39058:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-easy-auth-and-roles-with-net-and-microsoft-identity-web",title:"Azure Easy Auth and Roles with .NET and Microsoft.Identity.Web",authors:"johnnyreilly",tags:["Azure","Easy Auth","ASP.NET","authorization"],hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-easy-auth-and-roles-with-net-and-microsoft-identity-web",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-01-17-azure-easy-auth-and-roles-with-net-and-microsoft-identity-web/index.md",source:"@site/blog/2021-01-17-azure-easy-auth-and-roles-with-net-and-microsoft-identity-web/index.md",title:"Azure Easy Auth and Roles with .NET and Microsoft.Identity.Web",description:"I wrote recently about how to get Azure Easy Auth to work with roles. This involved borrowing the approach used by MaximeRouiller.Azure.AppService.EasyAuth.",date:"2021-01-17T00:00:00.000Z",formattedDate:"January 17, 2021",tags:[{label:"Azure",permalink:"/tags/azure"},{label:"Easy Auth",permalink:"/tags/easy-auth"},{label:"ASP.NET",permalink:"/tags/asp-net"},{label:"authorization",permalink:"/tags/authorization"}],readingTime:2.355,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-easy-auth-and-roles-with-net-and-microsoft-identity-web",title:"Azure Easy Auth and Roles with .NET and Microsoft.Identity.Web",authors:"johnnyreilly",tags:["Azure","Easy Auth","ASP.NET","authorization"],hide_table_of_contents:!1},prevItem:{title:"Azure Pipelines Build Info in an ASP.NET React app",permalink:"/surfacing-azure-pipelines-build-info-in-an-aspnet-react-app"},nextItem:{title:"Azure Easy Auth and Roles with .NET (and .NET Core)",permalink:"/azure-easy-auth-and-roles-with-dotnet-and-core"}},p={authorsImageUrls:[void 0]},u=[{value:"Getting set up",id:"getting-set-up",level:2},{value:"You gotta <code>roles</code> with it",id:"you-gotta-roles-with-it",level:2},{value:"Claims transformation FTW",id:"claims-transformation-ftw",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"/azure-easy-auth-and-roles-with-dotnet-and-core"}),"I wrote recently about how to get Azure Easy Auth to work with roles"),". This involved borrowing the approach used by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/MaximRouiller/MaximeRouiller.Azure.AppService.EasyAuth"}),"MaximeRouiller.Azure.AppService.EasyAuth"),"."),(0,a.kt)("p",null,"As a consequence of writing that post I came to learn that official support for Azure Easy Auth had landed in October 2020 in v1.2 of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/AzureAD/microsoft-identity-web/wiki/1.2.0#integration-with-azure-app-services-authentication-of-web-apps-running-with-microsoftidentityweb"}),"Microsoft.Identity.Web"),". This was great news; I was delighted."),(0,a.kt)("p",null,"However, it turns out that the same authorization issue that ",(0,a.kt)("inlineCode",{parentName:"p"},"MaximeRouiller.Azure.AppService.EasyAuth")," suffers from, is visited upon ",(0,a.kt)("inlineCode",{parentName:"p"},"Microsoft.Identity.Web")," as well."),(0,a.kt)("h2",o({},{id:"getting-set-up"}),"Getting set up"),(0,a.kt)("p",null,"We're using a .NET 5 project, running in an Azure App Service (Linux). In our ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj")," we have:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<PackageReference Include="Microsoft.Identity.Web" Version="1.4.1" />\n')),(0,a.kt)("p",null,"In our ",(0,a.kt)("inlineCode",{parentName:"p"},"Startup.cs")," we're using:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public void ConfigureServices(IServiceCollection services) {\n    //...\n    services.AddMicrosoftIdentityWebAppAuthentication(Configuration);\n    //...\n}\n\npublic void Configure(IApplicationBuilder app, IWebHostEnvironment env) {\n    //...\n    app.UseAuthentication();\n    app.UseAuthorization();\n    //...\n}\n")),(0,a.kt)("h2",o({},{id:"you-gotta-roles-with-it"}),"You gotta ",(0,a.kt)("inlineCode",{parentName:"h2"},"roles")," with it"),(0,a.kt)("p",null,"Whilst the authentication works, authorization does not. So whilst my app knows who I am - the authorization is not working with relation to ",(0,a.kt)("strong",{parentName:"p"},"roles"),"."),(0,a.kt)("p",null,"When directly using ",(0,a.kt)("inlineCode",{parentName:"p"},"Microsoft.Identity.Web")," when running locally, we see these claims:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'[\n  // ...\n  {\n    "type": "http://schemas.microsoft.com/ws/2008/06/identity/claims/role",\n    "value": "Administrator"\n  },\n  {\n    "type": "http://schemas.microsoft.com/ws/2008/06/identity/claims/role",\n    "value": "Reader"\n  }\n  // ...\n]\n')),(0,a.kt)("p",null,"However, we get different behaviour with EasyAuth; it provides roles related claims with a ",(0,a.kt)("strong",{parentName:"p"},"different type"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'[\n  // ...\n  {\n    "type": "roles",\n    "value": "Administrator"\n  },\n  {\n    "type": "roles",\n    "value": "Reader"\n  }\n  // ...\n]\n')),(0,a.kt)("p",null,"This means that roles related authorization ",(0,a.kt)("em",{parentName:"p"},"does not work")," with Easy Auth:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[Authorize(Roles = "Reader")]\n[HttpGet("api/reader")]\npublic string GetWithReader() =>\n    "this is a secure endpoint that users with the Reader role can access";\n')),(0,a.kt)("p",null,"This is because .NET is looking for claims with a ",(0,a.kt)("inlineCode",{parentName:"p"},"type")," of ",(0,a.kt)("inlineCode",{parentName:"p"},'"http://schemas.microsoft.com/ws/2008/06/identity/claims/role"')," and not finding them with Easy Auth."),(0,a.kt)("h2",o({},{id:"claims-transformation-ftw"}),"Claims transformation FTW"),(0,a.kt)("p",null,"There is a way to work around this issue .NET using ",(0,a.kt)("inlineCode",{parentName:"p"},"IClaimsTransformation"),". This is a poorly documented feature, but fortunately ",(0,a.kt)("a",o({parentName:"p"},{href:"https://gunnarpeipman.com/aspnet-core-adding-claims-to-existing-identity/"}),"Gunnar Peipman's blog does a grand job of explaining it"),"."),(0,a.kt)("p",null,"Inside our ",(0,a.kt)("inlineCode",{parentName:"p"},"Startup.cs")," I've registered a claims transformer:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"services.AddScoped<IClaimsTransformation, AddRolesClaimsTransformation>();\n")),(0,a.kt)("p",null,"And that claims transformer looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public class AddRolesClaimsTransformation : IClaimsTransformation {\n    private readonly ILogger<AddRolesClaimsTransformation> _logger;\n\n    public AddRolesClaimsTransformation(ILogger<AddRolesClaimsTransformation> logger) {\n        _logger = logger;\n    }\n\n    public Task<ClaimsPrincipal> TransformAsync(ClaimsPrincipal principal) {\n        var mappedRolesClaims = principal.Claims\n            .Where(claim => claim.Type == "roles")\n            .Select(claim => new Claim(ClaimTypes.Role, claim.Value))\n            .ToList();\n\n        // Clone current identity\n        var clone = principal.Clone();\n\n        if (clone.Identity is not ClaimsIdentity newIdentity) return Task.FromResult(principal);\n\n        // Add role claims to cloned identity\n        foreach (var mappedRoleClaim in mappedRolesClaims)\n            newIdentity.AddClaim(mappedRoleClaim);\n\n        if (mappedRolesClaims.Count > 0)\n            _logger.LogInformation("Added roles claims {mappedRolesClaims}", mappedRolesClaims);\n        else\n            _logger.LogInformation("No roles claims added");\n\n        return Task.FromResult(clone);\n    }\n}\n')),(0,a.kt)("p",null,"The class above creates a new principal with ",(0,a.kt)("inlineCode",{parentName:"p"},'"roles"')," claims mapped across to ",(0,a.kt)("inlineCode",{parentName:"p"},'"http://schemas.microsoft.com/ws/2008/06/identity/claims/role"'),". This is enough to get .NET treating roles the way you'd hope."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/AzureAD/microsoft-identity-web/issues/881"}),"I've raised an issue against the ",(0,a.kt)("inlineCode",{parentName:"a"},"Microsoft.Identity.Web")," repo")," about this. Perhaps one day this workaround will no longer be necessary."))}d.isMDXComponent=!0},16992:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"surfacing-azure-pipelines-build-info-in-an-aspnet-react-app",title:"Azure Pipelines Build Info in an ASP.NET React app",authors:"johnnyreilly",image:"./about-page.png",tags:["azure pipelines"],hide_table_of_contents:!1},s=void 0,l={permalink:"/surfacing-azure-pipelines-build-info-in-an-aspnet-react-app",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-01-29-surfacing-azure-pipelines-build-info-in-an-aspnet-react-app/index.md",source:"@site/blog/2021-01-29-surfacing-azure-pipelines-build-info-in-an-aspnet-react-app/index.md",title:"Azure Pipelines Build Info in an ASP.NET React app",description:'How do you answer the question: "what version of my application is running in Production right now?" This post demonstrates how to surface the build metadata that represents the version of your app, from your app using Azure Pipelines and ASP.NET.',date:"2021-01-29T00:00:00.000Z",formattedDate:"January 29, 2021",tags:[{label:"azure pipelines",permalink:"/tags/azure-pipelines"}],readingTime:6.54,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"surfacing-azure-pipelines-build-info-in-an-aspnet-react-app",title:"Azure Pipelines Build Info in an ASP.NET React app",authors:"johnnyreilly",image:"./about-page.png",tags:["azure pipelines"],hide_table_of_contents:!1},prevItem:{title:"ASP.NET, Serilog and Application Insights",permalink:"/aspnet-serilog-and-application-insights"},nextItem:{title:"Azure Easy Auth and Roles with .NET and Microsoft.Identity.Web",permalink:"/azure-easy-auth-and-roles-with-net-and-microsoft-identity-web"}},p={image:n(25418).Z,authorsImageUrls:[void 0]},u=[{value:"Putting build info into <code>azure-pipelines.yml</code>",id:"putting-build-info-into-azure-pipelinesyml",level:2},{value:"Surfacing the server build info",id:"surfacing-the-server-build-info",level:2},{value:"Surfacing the client build info",id:"surfacing-the-client-build-info",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'How do you answer the question: "what version of my application is running in Production right now?" This post demonstrates how to surface the build metadata that represents the version of your app, from your app using Azure Pipelines and ASP.NET.'),(0,a.kt)("p",null,"Many is the time where I've been pondering over why something isn't working as expected and burned a disappointing amount of time before realising that I'm playing with an old version of an app. Wouldn't it be great give our app a way to say: \"Hey! I'm version 1.2.3.4 of your app; built from this commit hash, I was built on Wednesday, I was the nineth build that day and I was built from the ",(0,a.kt)("inlineCode",{parentName:"p"},"main")," branch. And I'm an Aries.\" Or something like that."),(0,a.kt)("p",null,"This post was inspired by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.hanselman.com/blog/adding-a-git-commit-hash-and-azure-devops-build-number-and-build-id-to-an-aspnet-website"}),"Scott Hanselman's similar post on the topic"),". Ultimately this ended up going in a fairly different direction and so seemed worthy of a post of its own."),(0,a.kt)("p",null,'A particular difference is that this is targeting SPAs. Famously, cache invalidation is hard. It\'s possible for the HTML/JS/CSS of your app to be stale due to aggressive caching. So we\'re going to make it possible to see build information for both when the SPA (or "client") is built, as well as when the .NET app (or "server") is built. We\'re using a specific type of SPA here; a ',(0,a.kt)("a",o({parentName:"p"},{href:"https://reactjs.org/"}),"React")," SPA built with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/"}),"TypeScript")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://material-ui.com/"}),"Material UI"),", however the principles here are general; you could surface this up any which way you choose."),(0,a.kt)("h2",o({},{id:"putting-build-info-into-azure-pipelinesyml"}),"Putting build info into ",(0,a.kt)("inlineCode",{parentName:"h2"},"azure-pipelines.yml")),(0,a.kt)("p",null,"The first thing we're going to do is to inject our build details into two identical ",(0,a.kt)("inlineCode",{parentName:"p"},"buildinfo.json")," files; one that sits in the server codebase and which will be used to drive the server build information, and one that sits in the client codebase to drive the client equivalent. They'll end up looking something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "buildNumber": "20210130.1",\n  "buildId": "123456",\n  "branchName": "main",\n  "commitHash": "7089620222c30c1ad88e4b556c0a7908ddd34a8e"\n}\n')),(0,a.kt)("p",null,"We generate this by adding the following ",(0,a.kt)("inlineCode",{parentName:"p"},"yml")," to the beginning of our ",(0,a.kt)("inlineCode",{parentName:"p"},"azure-pipelines.yml")," (crucially before the client or server build take place):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),'- script: |\n      echo -e -n "{\\"buildNumber\\":\\"$(Build.BuildNumber)\\",\\"buildId\\":\\"$(Build.BuildId)\\",\\"branchName\\":\\"$(Build.SourceBranchName)\\",\\"commitHash\\":\\"$(Build.SourceVersion)\\"}" > "$(Build.SourcesDirectory)/src/client-app/src/buildinfo.json"\n      echo -e -n "{\\"buildNumber\\":\\"$(Build.BuildNumber)\\",\\"buildId\\":\\"$(Build.BuildId)\\",\\"branchName\\":\\"$(Build.SourceBranchName)\\",\\"commitHash\\":\\"$(Build.SourceVersion)\\"}" > "$(Build.SourcesDirectory)/src/server-app/Server/buildinfo.json"\n    displayName: "emit build details as JSON"\n    failOnStderr: true\n')),(0,a.kt)("p",null,"As you can see, we're placing the following variables that are available at build time in Azure Pipelines, into the ",(0,a.kt)("inlineCode",{parentName:"p"},"buildinfo.json"),":"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"BuildNumber")," - The name of the completed build; which usually takes the form of a date in the ",(0,a.kt)("inlineCode",{parentName:"li"},"yyyyMMdd")," format, suffixed by ",(0,a.kt)("inlineCode",{parentName:"li"},".x")," where ",(0,a.kt)("inlineCode",{parentName:"li"},"x")," is a number that increments representing the number of builds that have taken place on the given day."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"BuildId")," - The ID of the record for the completed build."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"SourceVersion")," - This is the commit hash of the source code in Git"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"SourceBranchName")," - The name of the branch in Git.")),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/devops/pipelines/build/variables?view=azure-devops&tabs=yaml#build-variables-devops-services"}),"There's many variables available in Azure Pipelines that can be used")," - we've picked out the ones most interesting to us."),(0,a.kt)("h2",o({},{id:"surfacing-the-server-build-info"}),"Surfacing the server build info"),(0,a.kt)("p",null,"Our pipeline is dropping the ",(0,a.kt)("inlineCode",{parentName:"p"},"buildinfo.json")," over pre-existing stub ",(0,a.kt)("inlineCode",{parentName:"p"},"buildinfo.json")," files in both our client and server codebases. The stub files look like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "buildNumber": "yyyyMMdd.x",\n  "buildId": "xxxxxx",\n  "branchName": "",\n  "commitHash": "LOCAL_BUILD"\n}\n')),(0,a.kt)("p",null,"In our .NET app, the ",(0,a.kt)("inlineCode",{parentName:"p"},"buildinfo.json")," file has been dropped in the root of the app. And as luck would have it, all JSON files are automatically included in a .NET build and so it will be available at runtime. We want to surface this file through an API, and we also want to use it to stamp details into our logs."),(0,a.kt)("p",null,"So we need to parse the file, and for that we'll use this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.IO;\nusing System.Text.Json;\n\nnamespace Server {\n    public record BuildInfo(string BranchName, string BuildNumber, string BuildId, string CommitHash);\n\n    public static class AppVersionInfo {\n        private const string _buildFileName = "buildinfo.json";\n        private static BuildInfo _fileBuildInfo = new(\n            BranchName: "",\n            BuildNumber: DateTime.UtcNow.ToString("yyyyMMdd") + ".0",\n            BuildId: "xxxxxx",\n            CommitHash: $"Not yet initialised - call {nameof(InitialiseBuildInfoGivenPath)}"\n        );\n\n        public static void InitialiseBuildInfoGivenPath(string path) {\n            var buildFilePath = Path.Combine(path, _buildFileName);\n            if (File.Exists(buildFilePath)) {\n                try {\n                    var buildInfoJson = File.ReadAllText(buildFilePath);\n                    var buildInfo = JsonSerializer.Deserialize<BuildInfo>(buildInfoJson, new JsonSerializerOptions {\n                        PropertyNamingPolicy = JsonNamingPolicy.CamelCase\n                    });\n                    if (buildInfo == null) throw new Exception($"Failed to deserialise {_buildFileName}");\n\n                    _fileBuildInfo = buildInfo;\n                } catch (Exception) {\n                    _fileBuildInfo = new BuildInfo(\n                        BranchName: "",\n                        BuildNumber: DateTime.UtcNow.ToString("yyyyMMdd") + ".0",\n                        BuildId: "xxxxxx",\n                        CommitHash: "Failed to load build info from buildinfo.json"\n                    );\n                }\n            }\n        }\n\n        public static BuildInfo GetBuildInfo() => _fileBuildInfo;\n    }\n}\n')),(0,a.kt)("p",null,"The above code reads the ",(0,a.kt)("inlineCode",{parentName:"p"},"buildinfo.json")," file and deserialises it into a ",(0,a.kt)("inlineCode",{parentName:"p"},"BuildInfo")," record which is then surfaced up by the ",(0,a.kt)("inlineCode",{parentName:"p"},"GetBuildInfo")," method. We initialise this at the start of our ",(0,a.kt)("inlineCode",{parentName:"p"},"Program.cs")," like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public static int Main(string[] args) {\n    AppVersionInfo.InitialiseBuildInfoGivenPath(Directory.GetCurrentDirectory());\n    // Now we're free to call AppVersionInfo.GetBuildInfo()\n    // ....\n}\n")),(0,a.kt)("p",null,"Now we need a controller to surface this information up. We'll add ourselves a ",(0,a.kt)("inlineCode",{parentName:"p"},"BuildInfoController.cs"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using Microsoft.AspNetCore.Authorization;\nusing Microsoft.AspNetCore.Mvc;\n\nnamespace Server.Controllers {\n    [ApiController]\n    public class BuildInfoController : ControllerBase {\n        [AllowAnonymous]\n        [HttpGet("api/build")]\n        public BuildInfo GetBuild() => AppVersionInfo.GetBuildInfo();\n    }\n}\n')),(0,a.kt)("p",null,"This exposes an ",(0,a.kt)("inlineCode",{parentName:"p"},"api/build")," endpoint in our .NET app that, when hit, will display the following JSON:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"screenshot of api/build output",src:n(94754).Z,width:"1050",height:"248"})),(0,a.kt)("h2",o({},{id:"surfacing-the-client-build-info"}),"Surfacing the client build info"),(0,a.kt)("p",null,"Our server now lets the world know which version it is running and this is tremendous. Now let's make our client do the same."),(0,a.kt)("p",null,"Very little is required to achieve this. Again we have a ",(0,a.kt)("inlineCode",{parentName:"p"},"buildinfo.json")," sat in the root of our codebase. We're able to import it as a module in TypeScript because we've set the following property in our ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"resolveJsonModule": true,\n')),(0,a.kt)("p",null,"As a consequence, consumption is as simple as:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import clientBuildInfo from './buildinfo.json';\n")),(0,a.kt)("p",null,"Which provides us with a ",(0,a.kt)("inlineCode",{parentName:"p"},"clientBuildInfo")," which TypeScript automatically derives as this type:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"type ClientBuildInfo = {\n  buildNumber: string;\n  buildId: string;\n  branchName: string;\n  commitHash: string;\n};\n")),(0,a.kt)("p",null,'How you choose to use that information is entirely your choice. We\'re going to add ourselves an "about" screen in our app, which displays both client info (loaded using the mechanism above) and server info (',(0,a.kt)("inlineCode",{parentName:"p"},"fetch"),"ed from the ",(0,a.kt)("inlineCode",{parentName:"p"},"/api/build")," endpoint)."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),'import {\n  Card,\n  CardContent,\n  CardHeader,\n  createStyles,\n  Grid,\n  makeStyles,\n  Theme,\n  Typography,\n  Zoom,\n} from \'@material-ui/core\';\nimport React from \'react\';\nimport clientBuildInfo from \'../../buildinfo.json\';\nimport { projectsPurple } from \'../shared/colors\';\nimport { Loading } from \'../shared/Loading\';\nimport { TransitionContainer } from \'../shared/TransitionContainer\';\n\nconst useStyles = (cardColor: string) =>\n  makeStyles((theme: Theme) =>\n    createStyles({\n      card: {\n        padding: theme.spacing(0),\n        backgroundColor: cardColor,\n        color: theme.palette.common.white,\n        minHeight: theme.spacing(28),\n      },\n      avatar: {\n        backgroundColor: theme.palette.getContrastText(cardColor),\n        color: cardColor,\n      },\n      main: {\n        padding: theme.spacing(2),\n      },\n    })\n  )();\n\ntype Styles = ReturnType<typeof useStyles>;\n\nconst AboutPage: React.FC = () => {\n  const [serverBuildInfo, setServerBuildInfo] =\n    React.useState<typeof clientBuildInfo>();\n\n  React.useEffect(() => {\n    fetch(\'/api/build\')\n      .then((response) => response.json())\n      .then(setServerBuildInfo);\n  }, []);\n\n  const classes = useStyles(projectsPurple);\n\n  return (\n    <TransitionContainer>\n      <Grid container spacing={3}>\n        <Grid item xs={12} sm={12} container alignItems="center">\n          <Grid item>\n            <Typography variant="h4" component="h1">\n              About\n            </Typography>\n          </Grid>\n        </Grid>\n      </Grid>\n      <Grid container spacing={1}>\n        <BuildInfo\n          classes={classes}\n          title="Client Version"\n          {...clientBuildInfo}\n        />\n      </Grid>\n      <br />\n      <Grid container spacing={1}>\n        {serverBuildInfo ? (\n          <BuildInfo\n            classes={classes}\n            title="Server Version"\n            {...serverBuildInfo}\n          />\n        ) : (\n          <Loading />\n        )}\n      </Grid>\n    </TransitionContainer>\n  );\n};\n\ninterface Props {\n  classes: Styles;\n  title: string;\n  branchName: string;\n  buildNumber: string;\n  buildId: string;\n  commitHash: string;\n}\n\nconst BuildInfo: React.FC<Props> = ({\n  classes,\n  title,\n  branchName,\n  buildNumber,\n  buildId,\n  commitHash,\n}) => (\n  <Zoom mountOnEnter unmountOnExit in={true}>\n    <Card className={classes.card}>\n      <CardHeader title={title} />\n      <CardContent className={classes.main}>\n        <Typography variant="body1" component="p">\n          <b>Build Number</b> {buildNumber}\n        </Typography>\n        <Typography variant="body1" component="p">\n          <b>Build Id</b> {buildId}\n        </Typography>\n        <Typography variant="body1" component="p">\n          <b>Branch Name</b> {branchName}\n        </Typography>\n        <Typography variant="body1" component="p">\n          <b>Commit Hash</b> {commitHash}\n        </Typography>\n      </CardContent>\n    </Card>\n  </Zoom>\n);\n\nexport default AboutPage;\n')),(0,a.kt)("p",null,"When the above page is viewed it looks like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of our web app surfacing up the build information",src:n(25418).Z,width:"1050",height:"1056"})),(0,a.kt)("p",null,"And that's it! Our app is clearly telling us what version is being run, both on the server and in the client. Thanks to Scott Hanselman for his work which inspired this."))}d.isMDXComponent=!0},69841:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"aspnet-serilog-and-application-insights",title:"ASP.NET, Serilog and Application Insights",authors:"johnnyreilly",image:"./title-image.png",tags:["asp.net","Azure","Application Insights","Serilog"],hide_table_of_contents:!1},s=void 0,l={permalink:"/aspnet-serilog-and-application-insights",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-01-30-aspnet-serilog-and-application-insights/index.md",source:"@site/blog/2021-01-30-aspnet-serilog-and-application-insights/index.md",title:"ASP.NET, Serilog and Application Insights",description:"If you're deploying an ASP.NET application to Azure App Services / Azure Container Apps or similar, there's a decent chance you'll also be using the fantastic Serilog and will want to plug it into Azure's Application Insights.",date:"2021-01-30T00:00:00.000Z",formattedDate:"January 30, 2021",tags:[{label:"asp.net",permalink:"/tags/asp-net"},{label:"Azure",permalink:"/tags/azure"},{label:"Application Insights",permalink:"/tags/application-insights"},{label:"Serilog",permalink:"/tags/serilog"}],readingTime:3.875,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"aspnet-serilog-and-application-insights",title:"ASP.NET, Serilog and Application Insights",authors:"johnnyreilly",image:"./title-image.png",tags:["asp.net","Azure","Application Insights","Serilog"],hide_table_of_contents:!1},prevItem:{title:"Azure RBAC: role assignments and ARM templates",permalink:"/arm-templates-security-role-assignments"},nextItem:{title:"Azure Pipelines Build Info in an ASP.NET React app",permalink:"/surfacing-azure-pipelines-build-info-in-an-aspnet-react-app"}},p={image:n(54072).Z,authorsImageUrls:[void 0]},u=[{value:"Updated: 26/11/2022",id:"updated-26112022",level:2},{value:"Let&#39;s plug it together",id:"lets-plug-it-together",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"If you're deploying an ASP.NET application to Azure App Services / Azure Container Apps or similar, there's a decent chance you'll also be using the fantastic ",(0,a.kt)("a",o({parentName:"p"},{href:"https://serilog.net/"}),"Serilog")," and will want to plug it into Azure's ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/azure-monitor/app/app-insights-overview"}),"Application Insights"),"."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;ASP.NET, Serilog and Application Insights&quot; with ASP.NET, Serilog and Application Insights logos",src:n(54072).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"updated-26112022"}),"Updated: 26/11/2022"),(0,a.kt)("p",null,"This post will show you how it's done, and it'll also build upon the ",(0,a.kt)("a",o({parentName:"p"},{href:"/surfacing-azure-pipelines-build-info-in-an-aspnet-react-app"}),"build info work from our previous post"),". In what way? Great question. Well logs are a tremendous diagnostic tool. If you have logs which display some curious behaviour, and you'd like to replicate that in another environment, you really want to take exactly that version of the codebase out to play. Our last post introduced build info into our application in the form of our ",(0,a.kt)("inlineCode",{parentName:"p"},"AppVersionInfo")," class that looks something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "buildNumber": "20210130.1",\n  "buildId": "123456",\n  "branchName": "main",\n  "commitHash": "7089620222c30c1ad88e4b556c0a7908ddd34a8e"\n}\n')),(0,a.kt)("p",null,"We'd initially exposed an endpoint in our application which surfaced up this information. Now we're going to take that self same information and bake it into our log messages by making use of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/serilog/serilog/wiki/Enrichment"}),"Serilog's enrichment functionality"),". Build info and Serilog's enrichment are the double act your logging has been waiting for."),(0,a.kt)("h2",o({},{id:"lets-plug-it-together"}),"Let's plug it together"),(0,a.kt)("p",null,"We're going to need a number of Serilog dependencies added to our ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<PackageReference Include="Serilog.AspNetCore" Version="3.4.0" />\n<PackageReference Include="Serilog.Enrichers.Environment" Version="2.1.3" />\n<PackageReference Include="Serilog.Enrichers.Thread" Version="3.1.0" />\n<PackageReference Include="Serilog.Sinks.ApplicationInsights" Version="3.1.0" />\n<PackageReference Include="Serilog.Sinks.Async" Version="1.4.0" />\n')),(0,a.kt)("p",null,"The earlier in your application lifetime you get logging wired up, the happier you will be. Earlier, means more information when you're diagnosing issues. So we want to start in our ",(0,a.kt)("inlineCode",{parentName:"p"},"Program.cs"),"; ",(0,a.kt)("inlineCode",{parentName:"p"},"Startup.cs")," would be just ",(0,a.kt)("em",{parentName:"p"},"way")," too late."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public class Program {\n    const string APP_NAME = "MyAmazingApp";\n\n    public static int Main(string[] args) {\n        AppVersionInfo.InitialiseBuildInfoGivenPath(Directory.GetCurrentDirectory());\n        LoggerConfigurationExtensions.SetupLoggerConfiguration(APP_NAME, AppVersionInfo.GetBuildInfo());\n\n        try\n        {\n            Log.Information("Starting web host");\n            CreateHostBuilder(args).Build().Run();\n            return 0;\n        }\n        catch (Exception ex)\n        {\n            Log.Fatal(ex, "Host terminated unexpectedly");\n            return 1;\n        }\n        finally\n        {\n            Log.CloseAndFlush();\n        }\n    }\n\n    public static IHostBuilder CreateHostBuilder(string[] args) =>\n        Host.CreateDefaultBuilder(args)\n            .UseSerilog((hostBuilderContext, services, loggerConfiguration) => {\n                loggerConfiguration.ConfigureBaseLogging(APP_NAME, AppVersionInfo.GetBuildInfo());\n                loggerConfiguration.AddApplicationInsightsLogging(services, hostBuilderContext.Configuration);\n            })\n            .ConfigureWebHostDefaults(webBuilder => {\n                webBuilder\n                    .UseStartup<Startup>();\n            });\n}\n')),(0,a.kt)("p",null,"If you look at the code above you'll see that the first line of code that executes is ",(0,a.kt)("inlineCode",{parentName:"p"},"AppVersionInfo.InitialiseBuildInfoGivenPath"),". This initialises our ",(0,a.kt)("inlineCode",{parentName:"p"},"AppVersionInfo")," so we have meaningful build info to pump into our logs. The next thing we do is to configure Serilog with ",(0,a.kt)("inlineCode",{parentName:"p"},"LoggerConfigurationExtensions.SetupLoggerConfiguration"),". This provides us with a configured logger so we are free to log any issues that take place during startup. (Incidentally, after startup you'll likely inject an ",(0,a.kt)("inlineCode",{parentName:"p"},"ILogger")," into your classes rather than using the static ",(0,a.kt)("inlineCode",{parentName:"p"},"Log")," directly.)"),(0,a.kt)("p",null,"Finally, we call ",(0,a.kt)("inlineCode",{parentName:"p"},"CreateHostBuilder")," which in turn calls ",(0,a.kt)("inlineCode",{parentName:"p"},"UseSerilog")," to plug Serilog into ASP.NET. If you take a look inside the body of ",(0,a.kt)("inlineCode",{parentName:"p"},"UseSerilog")," you'll see we configure the logging of ASP.NET (in the same way we did for Serilog) and we hook into Application Insights as well. There's been a number of references to ",(0,a.kt)("inlineCode",{parentName:"p"},"LoggerConfigurationExtensions"),". Let's take a look at it:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'internal static class LoggerConfigurationExtensions {\n    internal static void SetupLoggerConfiguration(string appName, BuildInfo buildInfo) {\n        Log.Logger = new LoggerConfiguration()\n            .ConfigureBaseLogging(appName, buildInfo)\n            .CreateLogger();\n    }\n\n    internal static LoggerConfiguration ConfigureBaseLogging(\n        this LoggerConfiguration loggerConfiguration,\n        string appName,\n        BuildInfo buildInfo\n    ) {\n        loggerConfiguration\n            .MinimumLevel.Debug()\n            .MinimumLevel.Override("Microsoft", LogEventLevel.Information)\n            // AMAZING COLOURS IN THE CONSOLE!!!!\n            .WriteTo.Async(a => a.Console(theme: AnsiConsoleTheme.Code))\n            .Enrich.FromLogContext()\n            .Enrich.WithMachineName()\n            .Enrich.WithThreadId()\n            // Build information as custom properties\n            .Enrich.WithProperty(nameof(buildInfo.BuildId), buildInfo.BuildId)\n            .Enrich.WithProperty(nameof(buildInfo.BuildNumber), buildInfo.BuildNumber)\n            .Enrich.WithProperty(nameof(buildInfo.BranchName), buildInfo.BranchName)\n            .Enrich.WithProperty(nameof(buildInfo.CommitHash), buildInfo.CommitHash)\n            .Enrich.WithProperty("ApplicationName", appName);\n\n        return loggerConfiguration;\n    }\n\n    internal static LoggerConfiguration AddApplicationInsightsLogging(this LoggerConfiguration loggerConfiguration, IServiceProvider services, IConfiguration configuration)\n    {\n        if (!string.IsNullOrWhiteSpace(configuration.GetValue<string>("APPINSIGHTS_INSTRUMENTATIONKEY")))\n        {\n            loggerConfiguration.WriteTo.ApplicationInsights(\n                services.GetRequiredService<TelemetryConfiguration>(),\n                TelemetryConverter.Traces);\n        }\n\n        return loggerConfiguration;\n    }\n}\n')),(0,a.kt)("p",null,"If we take a look at the ",(0,a.kt)("inlineCode",{parentName:"p"},"ConfigureBaseLogging")," method above, we can see that our logs are being enriched with the build info, property by property. We're also giving ourselves a beautifully coloured console thanks to Serilog's glorious ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/serilog/serilog-sinks-console#themes"}),"theme support"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the console featuring coloured output",src:n(75818).Z,width:"924",height:"128"})),(0,a.kt)("p",null,"Take a moment to admire the salmon pinks. Is it not lovely?"),(0,a.kt)("p",null,"Finally we come to the main act. Plugging in Application Insights is as simple as dropping in ",(0,a.kt)("inlineCode",{parentName:"p"},"loggerConfiguration.WriteTo.ApplicationInsights")," into our configuration. You'll note that this depends upon the existence of an application setting of ",(0,a.kt)("inlineCode",{parentName:"p"},"APPINSIGHTS_INSTRUMENTATIONKEY")," - this is the secret sauce that we need to be in place so we can pipe logs merrily to Application Insights. So you'll need this configuration in place so this works."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of application insights with our output",src:n(45074).Z,width:"806",height:"1068"})),(0,a.kt)("p",null,"As you can see, we now have the likes of ",(0,a.kt)("inlineCode",{parentName:"p"},"BuildNumber"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"CommitHash")," and friends visible on each log. Happy diagnostic days!"),(0,a.kt)("p",null,"I'm indebted to the marvellous ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/MarcelMichau"}),"Marcel Michau")," who showed me how to get the fiddlier parts of how to get Application Insights plugged in the right way. Thanks chap!"))}d.isMDXComponent=!0},90124:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"arm-templates-security-role-assignments",title:"Azure RBAC: role assignments and ARM templates",authors:"johnnyreilly",image:"./with-great-power-comes-great-responsibility.webp",tags:["Azure","ARM templates","role assignments","permissions"],hide_table_of_contents:!1},s=void 0,l={permalink:"/arm-templates-security-role-assignments",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-02-08-arm-templates-security-role-assignments/index.md",source:"@site/blog/2021-02-08-arm-templates-security-role-assignments/index.md",title:"Azure RBAC: role assignments and ARM templates",description:'This post is about Azure\'s role assignments and ARM templates. Role assignments can be thought of as "permissions for Azure".',date:"2021-02-08T00:00:00.000Z",formattedDate:"February 8, 2021",tags:[{label:"Azure",permalink:"/tags/azure"},{label:"ARM templates",permalink:"/tags/arm-templates"},{label:"role assignments",permalink:"/tags/role-assignments"},{label:"permissions",permalink:"/tags/permissions"}],readingTime:6.02,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"arm-templates-security-role-assignments",title:"Azure RBAC: role assignments and ARM templates",authors:"johnnyreilly",image:"./with-great-power-comes-great-responsibility.webp",tags:["Azure","ARM templates","role assignments","permissions"],hide_table_of_contents:!1},prevItem:{title:"Azure App Service, Health checks and zero downtime deployments",permalink:"/azure-app-service-health-checks-and-zero-downtime-deployments"},nextItem:{title:"ASP.NET, Serilog and Application Insights",permalink:"/aspnet-serilog-and-application-insights"}},p={image:n(98941).Z,authorsImageUrls:[void 0]},u=[{value:"Role (up for your) assignments",id:"role-up-for-your-assignments",level:2},{value:"Creating a role assignment",id:"creating-a-role-assignment",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'This post is about Azure\'s role assignments and ARM templates. Role assignments can be thought of as "permissions for Azure".'),(0,a.kt)("p",null,"If you're deploying to Azure, there's a good chance you're using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview"}),"ARM templates")," to do so. Once you've got past \"Hello World\", you'll probably find yourself in a situation when you're deploying multiple types of resource to make your solution. For instance, you may be deploying an ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/app-service/quickstart-arm-template?pivots=platform-linux#review-the-template"}),"App Service")," alongside ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/templates/microsoft.keyvault/vaults"}),"Key Vault")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/templates/microsoft.storage/storageaccounts"}),"Storage"),"."),(0,a.kt)("p",null,"One of the hardest things when it comes to deploying software and having it work, is permissions. Without adequate permissions configured, the most beautiful code can do ",(0,a.kt)("em",{parentName:"p"},"nothing"),". Incidentally, this is a good thing. We're deploying to the web; many people are there, not all good. As a different kind of web-head once said:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"Spider-man saying with great power, comes great responsibility",src:n(98941).Z,width:"269",height:"187"})),(0,a.kt)("p",null,"Azure has great power and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/security/fundamentals/identity-management-best-practices#use-role-based-access-control"}),"suggests you use it wisely"),"."),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Access management for cloud resources is critical for any organization that uses the cloud. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/role-based-access-control/overview"}),"Azure role-based access control (Azure RBAC)")," helps you manage who has access to Azure resources, what they can do with those resources, and what areas they have access to."),(0,a.kt)("p",{parentName:"blockquote"},"Designating groups or individual roles responsible for specific functions in Azure helps avoid confusion that can lead to human and automation errors that create security risks. Restricting access based on the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Need_to_know"}),"need to know")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Principle_of_least_privilege"}),"least privilege")," security principles is imperative for organizations that want to enforce security policies for data access.")),(0,a.kt)("p",null,"This is good advice. With that in mind, how can we ensure that the different resources we're deploying to Azure can talk to one another?"),(0,a.kt)("h2",o({},{id:"role-up-for-your-assignments"}),"Role (up for your) assignments"),(0,a.kt)("p",null,"The answer is roles. There's a number of roles that exist in Azure that can be assigned to users, groups, service principals and managed identities. In our own case we're using managed identity for our resources. What we can do is use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/role-based-access-control/overview#how-azure-rbac-works"}),'"role assignments"')," to give our managed identity access to given resources. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/ArLucaID"}),"Arturo Lucatero")," gives a great short explanation of this:"),(0,a.kt)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/Dzhm-garKBM",frameBorder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowFullScreen:""}),(0,a.kt)("p",null,'Whilst this explanation is delightfully simple, the actual implementation when it comes to ARM templates is a little more involved. Because now it\'s time to talk "magic" GUIDs. Consider the following truncated ARM template, which gives our managed identity (and hence our App Service which uses this identity) access to Key Vault and Storage:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",\n  // ...\n  "variables": {\n    // ...\n    "managedIdentity": "[concat(\'mi-\', parameters(\'applicationName\'), \'-\', parameters(\'environment\'), \'-\', \'001\')]",\n    "appInsightsName": "[concat(\'appi-\', parameters(\'applicationName\'), \'-\', parameters(\'environment\'), \'-\', \'001\')]",\n    "keyVaultName": "[concat(\'kv-\', parameters(\'applicationName\'), \'-\', parameters(\'environment\'), \'-\', \'001\')]",\n    "storageAccountName": "[concat(\'st\', parameters(\'applicationName\'), parameters(\'environment\'), \'001\')]",\n    "storageBlobDataContributor": "[subscriptionResourceId(\'Microsoft.Authorization/roleDefinitions\', \'ba92f5b4-2d11-453d-a403-e96b0029c9fe\')]",\n    "keyVaultSecretsOfficer": "[subscriptionResourceId(\'Microsoft.Authorization/roleDefinitions\', \'b86a8fe4-44ce-4948-aee5-eccb2c155cd7\')]",\n    "keyVaultCryptoOfficer": "[subscriptionResourceId(\'Microsoft.Authorization/roleDefinitions\', \'14b46e9e-c2b7-41b4-b07b-48a6ebf60603\')]",\n    "uniqueRoleGuidKeyVaultSecretsOfficer": "[guid(resourceId(\'Microsoft.KeyVault/vaults\',  variables(\'keyVaultName\')), variables(\'keyVaultSecretsOfficer\'), resourceId(\'Microsoft.KeyVault/vaults\', variables(\'keyVaultName\')))]",\n    "uniqueRoleGuidKeyVaultCryptoOfficer": "[guid(resourceId(\'Microsoft.KeyVault/vaults\',  variables(\'keyVaultName\')), variables(\'keyVaultCryptoOfficer\'), resourceId(\'Microsoft.KeyVault/vaults\', variables(\'keyVaultName\')))]",\n    "uniqueRoleGuidStorageAccount": "[guid(resourceId(\'Microsoft.Storage/storageAccounts\',  variables(\'storageAccountName\')), variables(\'storageBlobDataContributor\'), resourceId(\'Microsoft.Storage/storageAccounts\', variables(\'storageAccountName\')))]"\n  },\n  "resources": [\n    {\n      "type": "Microsoft.ManagedIdentity/userAssignedIdentities",\n      "name": "[variables(\'managedIdentity\')]",\n      "apiVersion": "2018-11-30",\n      "location": "[parameters(\'location\')]"\n    },\n    // ...\n    {\n      "type": "Microsoft.Storage/storageAccounts/providers/roleAssignments",\n      "apiVersion": "2020-04-01-preview",\n      "name": "[concat(variables(\'storageAccountName\'), \'/Microsoft.Authorization/\', variables(\'uniqueRoleGuidStorageAccount\'))]",\n      "dependsOn": [\n        "[resourceId(\'Microsoft.ManagedIdentity/userAssignedIdentities\', variables(\'managedIdentity\'))]"\n      ],\n      "properties": {\n        "roleDefinitionId": "[variables(\'storageBlobDataContributor\')]",\n        "principalId": "[reference(resourceId(\'Microsoft.ManagedIdentity/userAssignedIdentities/\', variables(\'managedIdentity\')), \'2018-11-30\').principalId]",\n        "scope": "[resourceId(\'Microsoft.Storage/storageAccounts\', variables(\'storageAccountName\'))]",\n        "principalType": "ServicePrincipal"\n      }\n    },\n    {\n      "type": "Microsoft.KeyVault/vaults/providers/roleAssignments",\n      "apiVersion": "2018-01-01-preview",\n      "name": "[concat(variables(\'keyVaultName\'), \'/Microsoft.Authorization/\', variables(\'uniqueRoleGuidKeyVaultSecretsOfficer\'))]",\n      "dependsOn": [\n        "[resourceId(\'Microsoft.ManagedIdentity/userAssignedIdentities\', variables(\'managedIdentity\'))]"\n      ],\n      "properties": {\n        "roleDefinitionId": "[variables(\'keyVaultSecretsOfficer\')]",\n        "principalId": "[reference(resourceId(\'Microsoft.ManagedIdentity/userAssignedIdentities/\', variables(\'managedIdentity\')), \'2018-11-30\').principalId]",\n        "scope": "[resourceId(\'Microsoft.KeyVault/vaults\', variables(\'keyVaultName\'))]",\n        "principalType": "ServicePrincipal"\n      }\n    },\n    {\n      "type": "Microsoft.KeyVault/vaults/providers/roleAssignments",\n      "apiVersion": "2018-01-01-preview",\n      "name": "[concat(variables(\'keyVaultName\'), \'/Microsoft.Authorization/\', variables(\'uniqueRoleGuidKeyVaultCryptoOfficer\'))]",\n      "dependsOn": [\n        "[resourceId(\'Microsoft.ManagedIdentity/userAssignedIdentities\', variables(\'managedIdentity\'))]"\n      ],\n      "properties": {\n        "roleDefinitionId": "[variables(\'keyVaultCryptoOfficer\')]",\n        "principalId": "[reference(resourceId(\'Microsoft.ManagedIdentity/userAssignedIdentities/\', variables(\'managedIdentity\')), \'2018-11-30\').principalId]",\n        "scope": "[resourceId(\'Microsoft.KeyVault/vaults\', variables(\'keyVaultName\'))]",\n        "principalType": "ServicePrincipal"\n      }\n    }\n  ]\n}\n')),(0,a.kt)("p",null,"Let's take a look at these three variables:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),"\"storageBlobDataContributor\": \"[subscriptionResourceId('Microsoft.Authorization/roleDefinitions', 'ba92f5b4-2d11-453d-a403-e96b0029c9fe')]\",\n\"keyVaultSecretsOfficer\": \"[subscriptionResourceId('Microsoft.Authorization/roleDefinitions', 'b86a8fe4-44ce-4948-aee5-eccb2c155cd7')]\",\n\"keyVaultCryptoOfficer\": \"[subscriptionResourceId('Microsoft.Authorization/roleDefinitions', '14b46e9e-c2b7-41b4-b07b-48a6ebf60603')]\",\n")),(0,a.kt)("p",null,"The three variables above contain the subscription resource ids for the roles ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles#storage-blob-data-contributor"}),"Storage Blob Data Contributor"),", ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles#key-vault-secrets-officer-preview"}),"Key Vault Secrets Officer")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles#key-vault-crypto-officer-preview"}),"Key Vault Crypto Officer"),'. The first question on your mind is likely: "what is ',(0,a.kt)("inlineCode",{parentName:"p"},"ba92f5b4-2d11-453d-a403-e96b0029c9fe"),' and where does it come from?" Great question! Well, each of these GUIDs represents a built-in role in Azure RBAC. The ',(0,a.kt)("inlineCode",{parentName:"p"},"ba92f5b4-2d11-453d-a403-e96b0029c9fe")," represents the Storage Blob Data Contributor role."),(0,a.kt)("p",null,"How can I look these up? Well, there's two ways; ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles"}),"there's an article which documents them here")," or you could crack open the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://azure.microsoft.com/en-gb/features/cloud-shell/"}),"Cloud Shell")," and look up a role by GUID like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),'Get-AzRoleDefinition | ? {$_.id -eq "ba92f5b4-2d11-453d-a403-e96b0029c9fe" }\n\nName             : Storage Blob Data Contributor\nId               : ba92f5b4-2d11-453d-a403-e96b0029c9fe\nIsCustom         : False\nDescription      : Allows for read, write and delete access to Azure Storage blob containers and data\nActions          : {Microsoft.Storage/storageAccounts/blobServices/containers/delete, Microsoft.Storage/storageAccounts/blobServices/containers/read,\n                   Microsoft.Storage/storageAccounts/blobServices/containers/write, Microsoft.Storage/storageAccounts/blobServices/generateUserDelegationKey/action}\nNotActions       : {}\nDataActions      : {Microsoft.Storage/storageAccounts/blobServices/containers/blobs/delete, Microsoft.Storage/storageAccounts/blobServices/containers/blobs/read,\n                   Microsoft.Storage/storageAccounts/blobServices/containers/blobs/write, Microsoft.Storage/storageAccounts/blobServices/containers/blobs/move/action\u2026}\nNotDataActions   : {}\nAssignableScopes : {/}\n')),(0,a.kt)("p",null,"Or by name like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ps"}),"Get-AzRoleDefinition | ? {$_.name -like \"*Crypto Officer*\" }\n\nName             : Key Vault Crypto Officer\nId               : 14b46e9e-c2b7-41b4-b07b-48a6ebf60603\nIsCustom         : False\nDescription      : Perform any action on the keys of a key vault, except manage permissions. Only works for key vaults that use the 'Azure role-based access control' permission model.\nActions          : {Microsoft.Authorization/*/read, Microsoft.Insights/alertRules/*, Microsoft.Resources/deployments/*, Microsoft.Resources/subscriptions/resourceGroups/read\u2026}\nNotActions       : {}\nDataActions      : {Microsoft.KeyVault/vaults/keys/*}\nNotDataActions   : {}\nAssignableScopes : {/}\n")),(0,a.kt)("p",null,"As you can see, the ",(0,a.kt)("inlineCode",{parentName:"p"},"Actions")," section of the output above (and in even more detail on the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles"}),"linked article"),") provides information about what the different roles can do. So if you're looking to enable one Azure resource to talk to another, you should be able to refer to these to identify a role that you might want to use."),(0,a.kt)("h2",o({},{id:"creating-a-role-assignment"}),"Creating a role assignment"),(0,a.kt)("p",null,"So now we understand how you identify the roles in question, let's take the final leap and look at assigning those roles to our managed identity. For each role assignment, you'll need a ",(0,a.kt)("inlineCode",{parentName:"p"},"roleAssignments")," resource defined that looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "type": "Microsoft.KeyVault/vaults/providers/roleAssignments",\n  "apiVersion": "2018-01-01-preview",\n  "name": "[concat(variables(\'keyVaultName\'), \'/Microsoft.Authorization/\', variables(\'uniqueRoleGuidKeyVaultCryptoOfficer\'))]",\n  "dependsOn": [\n    "[resourceId(\'Microsoft.ManagedIdentity/userAssignedIdentities\', variables(\'managedIdentity\'))]"\n  ],\n  "properties": {\n    "roleDefinitionId": "[variables(\'keyVaultCryptoOfficer\')]",\n    "principalId": "[reference(resourceId(\'Microsoft.ManagedIdentity/userAssignedIdentities/\', variables(\'managedIdentity\')), \'2018-11-30\').principalId]",\n    "scope": "[resourceId(\'Microsoft.KeyVault/vaults\', variables(\'keyVaultName\'))]",\n    "principalType": "ServicePrincipal"\n  }\n}\n')),(0,a.kt)("p",null,"Let's go through the above, significant property by significant property (it's also worth checking the official reference ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/templates/microsoft.authorization/roleassignments"}),"here"),"):"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"type")," ","-"," the type of role assignment we want to create, for a key vault it's ",(0,a.kt)("inlineCode",{parentName:"li"},'"Microsoft.KeyVault/vaults/providers/roleAssignments"'),", for storage it's ",(0,a.kt)("inlineCode",{parentName:"li"},'"Microsoft.Storage/storageAccounts/providers/roleAssignments"'),". The pattern is that it's the resource type, followed by ",(0,a.kt)("inlineCode",{parentName:"li"},'"/providers/roleAssignments"'),"."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"dependsOn")," ","-"," before we can create a role assignment, we need the service principal we desire to permission (in our case a managed identity) to exist"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"properties.roleDefinitionId")," ","-"," the role that we're assigning, provided as an id. So for this example it's the ",(0,a.kt)("inlineCode",{parentName:"li"},"keyVaultCryptoOfficer")," variable, which was earlier defined as ",(0,a.kt)("inlineCode",{parentName:"li"},"[subscriptionResourceId('Microsoft.Authorization/roleDefinitions', 'ba92f5b4-2d11-453d-a403-e96b0029c9fe')]"),". (Note the use of the GUID)"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"properties.principalId")," ","-"," the id of the principal we're adding permissions for. In our case this is a managed identity (a type of service principal)."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"properties.scope")," ","-"," we're modifying another resource; our key vault isn't defined in this ARM template and we want to specify the resource we're granting permissions to."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"properties.principalType")," ","-"," the type of principal that we're creating an assignment for; in our this is ",(0,a.kt)("inlineCode",{parentName:"li"},'"ServicePrincipal"')," ","-"," our managed identity.")),(0,a.kt)("p",null,"There is an alternate approach that you can use where the ",(0,a.kt)("inlineCode",{parentName:"p"},"type")," is ",(0,a.kt)("inlineCode",{parentName:"p"},'"Microsoft.Authorization/roleAssignments"'),". Whilst this also works, it displayed errors in the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://marketplace.visualstudio.com/items?itemName=msazurermtools.azurerm-vscode-tools"}),"Azure tooling for VS Code"),". As such, we've opted not to use that approach in our ARM templates."),(0,a.kt)("p",null,"Many thanks to the awesome ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jmccor99"}),"John McCormick")," who wrangled permissions with me until we bent Azure RBAC to our will."))}d.isMDXComponent=!0},53706:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-app-service-health-checks-and-zero-downtime-deployments",title:"Azure App Service, Health checks and zero downtime deployments",authors:"johnnyreilly",tags:["Azure App Service"],hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-app-service-health-checks-and-zero-downtime-deployments",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-02-11-azure-app-service-health-checks-and-zero-downtime-deployments/index.md",source:"@site/blog/2021-02-11-azure-app-service-health-checks-and-zero-downtime-deployments/index.md",title:"Azure App Service, Health checks and zero downtime deployments",description:"I've been working recently on zero downtime deployments using Azure App Service. They're facilitated by a combination of Health checks and deployment slots. This post will talk about why this is important and how it works.",date:"2021-02-11T00:00:00.000Z",formattedDate:"February 11, 2021",tags:[{label:"Azure App Service",permalink:"/tags/azure-app-service"}],readingTime:7.49,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-app-service-health-checks-and-zero-downtime-deployments",title:"Azure App Service, Health checks and zero downtime deployments",authors:"johnnyreilly",tags:["Azure App Service"],hide_table_of_contents:!1},prevItem:{title:"Making Easy Auth tokens survive releases on Linux Azure App Service",permalink:"/easy-auth-tokens-survive-releases-on-linux-azure-app-service"},nextItem:{title:"Azure RBAC: role assignments and ARM templates",permalink:"/arm-templates-security-role-assignments"}},p={authorsImageUrls:[void 0]},u=[{value:"Why zero downtime deployments?",id:"why-zero-downtime-deployments",level:2},{value:"Manual zero downtime releases with App Services",id:"manual-zero-downtime-releases-with-app-services",level:2},{value:"Rollbacks for bonus points",id:"rollbacks-for-bonus-points",level:2},{value:"Automated zero downtime releases with Health checks",id:"automated-zero-downtime-releases-with-health-checks",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I've been working recently on zero downtime deployments using Azure App Service. They're facilitated by a combination of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/app-service/monitor-instances-health-check"}),"Health checks")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/app-service/deploy-staging-slots"}),"deployment slots"),". This post will talk about why this is important and how it works."),(0,a.kt)("h2",o({},{id:"why-zero-downtime-deployments"}),"Why zero downtime deployments?"),(0,a.kt)("p",null,"Historically (and for many applications, currently) deployment results in downtime. A period of time during the release where an application is not available to users whilst the new version is deployed. There are a number of downsides to releases with downtime:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Your users cannot use your application. This will frustrate them and make them sad."),(0,a.kt)("li",{parentName:"ol"},"Because you're a kind person and you want your users to be happy, you'll optimise to make their lives better. You'll release when the fewest users are accessing your application. It will likely mean you'll end up working late, early or at weekends."),(0,a.kt)("li",{parentName:"ol"},"Again because you want to reduce impact on users, you'll release less often. This means that every release will bring with it a greater collection of changes. This is turn will often result in a large degree of focus on manually testing each release, to reduce the likelihood of bugs ending up in users hands. This is a noble aim, but it drags the teams focus away from shipping.")),(0,a.kt)("p",null,"Put simply: downtime in releases impacts customer happiness and leads to reduced pace for teams. It's a vicious circle."),(0,a.kt)("p",null,"But if we turn it around, what does it look like if releases have ",(0,a.kt)("em",{parentName:"p"},"no")," downtime at all?"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Your users can always use your application. This will please them."),(0,a.kt)("li",{parentName:"ol"},"Your team is now safe to release at any time, day or night. They will likely release more often as a consequence."),(0,a.kt)("li",{parentName:"ol"},"If your team has sufficient automated testing in place, they're now in a position where they can move to ",(0,a.kt)("a",o({parentName:"li"},{href:"https://www.atlassian.com/continuous-delivery/principles/continuous-integration-vs-delivery-vs-deployment"}),"Continuous Deployment"),"."),(0,a.kt)("li",{parentName:"ol"},'Releases become boring. This is good. They "just work\u2122\ufe0f" and so the team can focus instead on building the cool features that are going to make users lives even better.')),(0,a.kt)("h2",o({},{id:"manual-zero-downtime-releases-with-app-services"}),"Manual zero downtime releases with App Services"),(0,a.kt)("p",null,"App Services have the ability to scale out. To ",(0,a.kt)("a",o({parentName:"p"},{href:"https://azure.microsoft.com/en-us/blog/scaling-up-and-scaling-out-in-windows-azure-web-sites/"}),"quote the docs"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"A scale out operation is the equivalent of creating multiple copies of your web site and adding a load balancer to distribute the demand between them. When you scale out ... there is no need to configure load balancing separately since this is already provided by the platform.")),(0,a.kt)("p",null,"As you can see, scaling out works by having multiple instances of your app. Deployment slots are exactly this, but with an extra twist. If you add a deployment slot to your App Service, then you ",(0,a.kt)("strong",{parentName:"p"},"no longer deploy to production"),". Instead you deploy to your staging slot. Your staging slot is accessible in the same way your production slot is accessible. So whilst your users may go to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://my-glorious-app.io"}),"https://my-glorious-app.io"),", your staging slot may live at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://my-glorious-app-stage.azurewebsites.net"}),"https://my-glorious-app-stage.azurewebsites.net")," instead. Because this is accessible, this is testable. You are in a position to test the deployed application before making it generally available."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"diagram of network traffic going to various App Service Deployment Slots",src:n(15402).Z,width:"600",height:"487"})),(0,a.kt)("p",null,'Once you\'re happy that everything looks good, you can "swap slots". What this means, is the version of the app living in the staging slot, gets moved into the production slot. So that which lived at ',(0,a.kt)("a",o({parentName:"p"},{href:"https://my-glorious-app-stage.azurewebsites.net"}),"https://my-glorious-app-stage.azurewebsites.net")," moves to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://my-glorious-app.io"}),"https://my-glorious-app.io"),". For a more details on what that involves ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/app-service/deploy-staging-slots#what-happens-during-a-swap"}),"read this"),". The significant take home is this: there is no downtime. Traffic stops being routed to the old instance and starts being routed to the new one. It's as simple as that."),(0,a.kt)("p",null,"I should mention at this point that there's a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://opensource.com/article/17/5/colorful-deployments"}),"number of zero downtime strategies out there")," and slots can help support a number of these. This includes canary deployments, where a subset of traffic is routed to the new version prior to it being opened out more widely. In our case, we're looking at rolling deployments, where we replace the currently running instances of our application with the new ones; but it's worth being aware that there are other strategies that slots can facilitate."),(0,a.kt)("p",null,"So what does it look like when slots swap? Well, to test that out, we swapped slots on our two App Service instances. We repeatedly CURLed our apps ",(0,a.kt)("a",o({parentName:"p"},{href:"/surfacing-azure-pipelines-build-info-in-an-aspnet-react-app"}),(0,a.kt)("inlineCode",{parentName:"a"},"api/build"))," endpoint that exposes the build information; to get visibility around which version of our app we were routing traffic to. This is what we saw:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'Thu Jan 21 11:51:51 GMT 2021\n{"buildNumber":"20210121.5","buildId":"17992","commitHash":"c2122919df54bfa6a0d20bceb9f06890f822b26e"}\nThu Jan 21 11:51:54 GMT 2021\n{"buildNumber":"20210121.6","buildId":"18015","commitHash":"062ac1488fcf1737fe1dbab0d05c095786218f30"}\nThu Jan 21 11:51:57 GMT 2021\n{"buildNumber":"20210121.5","buildId":"17992","commitHash":"c2122919df54bfa6a0d20bceb9f06890f822b26e"}\nThu Jan 21 11:52:00 GMT 2021\n{"buildNumber":"20210121.6","buildId":"18015","commitHash":"062ac1488fcf1737fe1dbab0d05c095786218f30"}\nThu Jan 21 11:52:03 GMT 2021\n{"buildNumber":"20210121.6","buildId":"18015","commitHash":"062ac1488fcf1737fe1dbab0d05c095786218f30"}\nThu Jan 21 11:52:05 GMT 2021\n{"buildNumber":"20210121.6","buildId":"18015","commitHash":"062ac1488fcf1737fe1dbab0d05c095786218f30"}\nThu Jan 21 11:52:08 GMT 2021\n{"buildNumber":"20210121.5","buildId":"17992","commitHash":"c2122919df54bfa6a0d20bceb9f06890f822b26e"}\nThu Jan 21 11:52:10 GMT 2021\n{"buildNumber":"20210121.6","buildId":"18015","commitHash":"062ac1488fcf1737fe1dbab0d05c095786218f30"}\nThu Jan 21 11:52:12 GMT 2021\n{"buildNumber":"20210121.5","buildId":"17992","commitHash":"c2122919df54bfa6a0d20bceb9f06890f822b26e"}\nThu Jan 21 11:52:15 GMT 2021\n{"buildNumber":"20210121.6","buildId":"18015","commitHash":"062ac1488fcf1737fe1dbab0d05c095786218f30"}\nThu Jan 21 11:52:17 GMT 2021\n{"buildNumber":"20210121.6","buildId":"18015","commitHash":"062ac1488fcf1737fe1dbab0d05c095786218f30"}\n')),(0,a.kt)("p",null,"The first new version of our application showed up in a production slot at 11:51:54, and the last old version showed up at 11:52:12. So it took a total of 15 seconds to complete the transition from hitting only instances of the old application to hitting only instances of the new application. During that 15 seconds either old or new versions of the application would be serving traffic. Significantly, there was always a version of the application returning responses."),(0,a.kt)("p",null,"This is ",(0,a.kt)("em",{parentName:"p"},"very")," exciting! We have zero downtime deployments!"),(0,a.kt)("h2",o({},{id:"rollbacks-for-bonus-points"}),"Rollbacks for bonus points"),(0,a.kt)("p",null,"We now have the new version of the app (",(0,a.kt)("inlineCode",{parentName:"p"},"buildNumber: 20210121.6"),") in the production slot, and the old version of the app (",(0,a.kt)("inlineCode",{parentName:"p"},"buildNumber: 20210121.5"),") in the staging slot."),(0,a.kt)("p",null,"Slots have a tremendous rollback story. If it emerges that there was some uncaught issue in your release and you'd like to revert to the previous version, you can! Just as we swapped just now to move ",(0,a.kt)("inlineCode",{parentName:"p"},"buildNumber: 20210121.6")," from the staging slot to the production slot and ",(0,a.kt)("inlineCode",{parentName:"p"},"buildNumber: 20210121.5")," the other way, we can swap right back and revert our release like so:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"diagram of network traffic going to various App Service Deployment Slots exposing build number",src:n(34010).Z,width:"600",height:"522"})),(0,a.kt)("p",null,"Once again users going to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://my-glorious-app.io"}),"https://my-glorious-app.io")," are hitting ",(0,a.kt)("inlineCode",{parentName:"p"},"buildNumber: 20210121.5"),"."),(0,a.kt)("p",null,"This is also ",(0,a.kt)("em",{parentName:"p"},"very")," exciting! We have zero downtime deployments ",(0,a.kt)("em",{parentName:"p"},"and")," rollbacks!"),(0,a.kt)("h2",o({},{id:"automated-zero-downtime-releases-with-health-checks"}),"Automated zero downtime releases with Health checks"),(0,a.kt)("p",null,"The final piece of the puzzle here automation. You're a sophisticated team, you've put a great deal of energy into automating your tests. You don't want your release process to be manual for this very reason; you trust your test coverage. You want to move to Continuous Deployment."),(0,a.kt)("p",null,"Fortunately, automating swapping slots is a breeze with ",(0,a.kt)("inlineCode",{parentName:"p"},"azure-pipelines.yml"),". Consider the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- job: DeployApp\n        displayName: Deploy app\n        dependsOn:\n        - DeployARMTemplates\n\n        steps:\n        - download: current\n          artifact: webapp\n\n        - task: AzureWebApp@1\n          displayName: 'Deploy Web Application'\n          inputs:\n            azureSubscription: $(serviceConnection)\n            resourceGroupName: $(azureResourceGroup)\n            appName: $(appServiceName)\n            package: $(Pipeline.Workspace)/webapp/**/*.zip\n            slotName: stage\n            deployToSlotOrASE: true\n            deploymentMethod: auto\n\n      - job: SwapSlots\n        displayName: Swap Slots\n        dependsOn:\n        - DeployApp\n\n        steps:\n          - task: AzureAppServiceManage@0\n            displayName: Swap Slots\n            inputs:\n              action: 'Swap Slots'\n              azureSubscription: $(serviceConnection)\n              resourceGroupName: $(azureResourceGroup)\n              webAppName: $(appServiceName)\n              SourceSlot: 'stage'\n")),(0,a.kt)("p",null,"The first job here, deploys our previously built ",(0,a.kt)("inlineCode",{parentName:"p"},"webapp")," to the ",(0,a.kt)("inlineCode",{parentName:"p"},"stage")," slot. The second job swaps the slot."),(0,a.kt)("p",null,"When I first considered this, the question rattling around in the back of my mind was this: how does App Service know when it's safe to swap? What if we swap before our app has fully woken up and started serving responses?"),(0,a.kt)("p",null,"It so happens that using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/app-service/monitor-instances-health-check"}),"Health checks, App Service caters for this beautifully"),'. A health check endpoint is a URL in your application which, when hit, checks the dependencies of your application. "Is the database accessible?" "Are the APIs I depend upon accessible?" The diagram from the docs expresses it very well:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"diagram of traffic hitting the health check endpoint",src:n(75531).Z,width:"400",height:"166"})),(0,a.kt)("p",null,"This approach is very similar to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/"}),"liveness, readiness and startup probes in Kubernetes"),". To make use of Health checks, in our ARM template for our App Service we have configured a ",(0,a.kt)("inlineCode",{parentName:"p"},"healthCheckPath"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"siteConfig": {\n    "linuxFxVersion": "[parameters(\'linuxFxVersion\')]",\n    "alwaysOn": true,\n    "http20Enabled": true,\n    "minTlsVersion": "1.2",\n    "healthCheckPath": "/api/health",\n    //...\n}\n')),(0,a.kt)("p",null,"This tells App Service where to look to check the health. The health check endpoint itself is provided by the ",(0,a.kt)("inlineCode",{parentName:"p"},"MapHealthChecks")," in our ",(0,a.kt)("inlineCode",{parentName:"p"},"Startup.cs")," of our .NET application:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'app.UseEndpoints(endpoints => {\n    endpoints.MapControllerRoute(\n        name: "default",\n        pattern: "{controller}/{action=Index}/{id?}");\n\n    endpoints.MapHealthChecks("/api/health");\n});\n')),(0,a.kt)("p",null,"You read a full list of all the ways App Service uses Health checks ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/app-service/monitor-instances-health-check#what-app-service-does-with-health-checks"}),"here"),". Pertinent for zero downtime deployments is this:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"when scaling up or out, App Service pings the Health check path to ensure new instances are ready.")),(0,a.kt)("p",null,"This is the magic sauce. App Service doesn't route traffic to an instance until it's given the thumbs up that it's ready in the form of passing health checks. This is excellent; it is this that makes automated zero downtime releases a reality."),(0,a.kt)("p",null,"Props to the various Azure teams that have made this possible; I'm very impressed by the way in which the Health checks and slots can be combined together to support some tremendous use cases."))}d.isMDXComponent=!0},90488:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"easy-auth-tokens-survive-releases-on-linux-azure-app-service",title:"Making Easy Auth tokens survive releases on Linux Azure App Service",authors:"johnnyreilly",image:"./easy-auth-zero-downtime-deployment.webp",tags:["Azure","Easy Auth","ASP.NET","authorization"],hide_table_of_contents:!1},s=void 0,l={permalink:"/easy-auth-tokens-survive-releases-on-linux-azure-app-service",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-02-16-easy-auth-tokens-survive-releases-on-linux-azure-app-service/index.md",source:"@site/blog/2021-02-16-easy-auth-tokens-survive-releases-on-linux-azure-app-service/index.md",title:"Making Easy Auth tokens survive releases on Linux Azure App Service",description:'I wrote recently about zero downtime deployments on Azure App Service. Many applications require authentication, and ours is no exception. In our case we\'re using Azure Active Directory facilitated by "Easy Auth" which provides authentication to our App Service.',date:"2021-02-16T00:00:00.000Z",formattedDate:"February 16, 2021",tags:[{label:"Azure",permalink:"/tags/azure"},{label:"Easy Auth",permalink:"/tags/easy-auth"},{label:"ASP.NET",permalink:"/tags/asp-net"},{label:"authorization",permalink:"/tags/authorization"}],readingTime:3.915,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"easy-auth-tokens-survive-releases-on-linux-azure-app-service",title:"Making Easy Auth tokens survive releases on Linux Azure App Service",authors:"johnnyreilly",image:"./easy-auth-zero-downtime-deployment.webp",tags:["Azure","Easy Auth","ASP.NET","authorization"],hide_table_of_contents:!1},prevItem:{title:"Goodbye Client Affinity, Hello Data Protection with Azure",permalink:"/goodbye-client-affinity-hello-data-protection-with-azure"},nextItem:{title:"Azure App Service, Health checks and zero downtime deployments",permalink:"/azure-app-service-health-checks-and-zero-downtime-deployments"}},p={image:n(18676).Z,authorsImageUrls:[void 0]},u=[{value:"SaS-sy ARM Templates",id:"sas-sy-arm-templates",level:2},{value:"What&#39;s actually happening?",id:"whats-actually-happening",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I ",(0,a.kt)("a",o({parentName:"p"},{href:"/azure-app-service-health-checks-and-zero-downtime-deployments"}),"wrote recently about zero downtime deployments on Azure App Service"),". Many applications require authentication, and ours is no exception. In our case we're using Azure Active Directory facilitated by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/app-service/overview-authentication-authorization"}),'"Easy Auth"')," which provides authentication to our App Service."),(0,a.kt)("p",null,"Our app uses a Linux App Service. It's worth knowing that Linux App Services run as a Docker container. As a consequence, Easy Auth works in a slightly different way; effectively as a middleware. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/app-service/overview-authentication-authorization#on-containers"}),"To quote the docs on Easy Auth"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"This module handles several things for your app:"),(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"},"Authenticates users with the specified provider"),(0,a.kt)("li",{parentName:"ul"},"Validates, stores, and refreshes tokens"),(0,a.kt)("li",{parentName:"ul"},"Manages the authenticated session"),(0,a.kt)("li",{parentName:"ul"},"Injects identity information into request headers The module runs separately from your application code and is configured using app settings. No SDKs, specific languages, or changes to your application code are required.")),(0,a.kt)("p",{parentName:"blockquote"},"The authentication and authorization module runs in a separate container, isolated from your application code. Using what's known as the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/architecture/patterns/ambassador"}),"Ambassador")," pattern, it interacts with the incoming traffic to perform similar functionality as on Windows.")),(0,a.kt)("p",null,"However, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://social.msdn.microsoft.com/Forums/en-US/dde551b2-c86d-474b-b0a6-cc66163785a1/restarting-azure-app-service-on-linux-with-azure-active-directory-authentication-resets-authme#b59951ab-623a-4442-a221-80c157387bbe"}),"Microsoft have acknowledged there is a potential bug in Easy Auth support at present"),". When the app service is restarted, the stored tokens are removed, and ",(0,a.kt)("strong",{parentName:"p"},"authentication begins to fail"),". As you might well imagine, authentication similarly starts to fail when a new app service is introduced - as is the case during deployment."),(0,a.kt)("p",null,"This is really significant. You may well have \"zero downtime deployment\", but it doesn't amount to a hill of beans if the moment you've deployed your users find they're effectively logged out. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://social.msdn.microsoft.com/Forums/en-US/dde551b2-c86d-474b-b0a6-cc66163785a1/restarting-azure-app-service-on-linux-with-azure-active-directory-authentication-resets-authme#b59951ab-623a-4442-a221-80c157387bbe"}),"The advice from Microsoft")," is to use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-gb/archive/blogs/jpsanders/azure-app-service-authentication-using-a-blob-storage-for-token-cache"}),"Blob Storage for Token Cache"),":"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/cgillum"}),"Chris Gillum")," said in a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://cgillum.tech/2016/03/07/app-service-token-store/"}),"blog on the topic"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"you can provision an Azure Blob Storage container and configure your web app with a SaS URL (with read/write/list access) pointing to that blob container. This SaS URL can then be saved to the ",(0,a.kt)("inlineCode",{parentName:"p"},"WEBSITE_AUTH_TOKEN_CONTAINER_SASURL")," app setting. When this app setting is present, all tokens will be stored in and fetched from the specified blob container.")),(0,a.kt)("p",null,"To turn that into something visual, what's suggested is this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"diagram of Easy Auth with blog storage",src:n(18676).Z,width:"474",height:"600"})),(0,a.kt)("h2",o({},{id:"sas-sy-arm-templates"}),"SaS-sy ARM Templates"),(0,a.kt)("p",null,"I have the good fortune to work with some very talented people. One of them, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jmccor99"}),"John McCormick")," turned his hand to putting this proposed solution into ",(0,a.kt)("inlineCode",{parentName:"p"},"azure-pipelines.yml")," and ARM template-land. First of all, let's look at our ",(0,a.kt)("inlineCode",{parentName:"p"},"azure-pipelines.yml"),". We add the following, prior to our deployment job:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- job: SASGen\n        displayName: Generate SAS Token\n\n        steps:\n          - task: AzurePowerShell@4\n            name: ObtainSasTokenTask\n            inputs:\n              azureSubscription: $(serviceConnection)\n              ScriptType: inlineScript\n              Inline: |\n                $startTime = Get-Date\n                $expiryTime = $startTime.AddDays(90)\n                $storageAcc = Get-AzStorageAccount -ResourceGroupName $(azureResourceGroup) -Name $(storageAccountName)\n                $ctx = $storageAcc.Context\n                $sas = New-AzStorageContainerSASToken -Context $ctx -Name \"tokens\" -Permission \"rwl\" -Protocol HttpsOnly -StartTime $startTime -ExpiryTime $expiryTime -FullUri\n                Write-Host \"##vso[task.setvariable variable=sasToken;issecret=true;isOutput=true]$sas\"\n              azurePowerShellVersion: 'LatestVersion'\n\n      - job: DeployAppARMTemplates\n        variables:\n          sasToken: $[dependencies.SASGen.outputs['ObtainSasTokenTask.sasToken'] ]\n        displayName: Deploy App ARM Templates\n        dependsOn:\n        - SASGen\n\n        steps:\n          - task: AzureResourceManagerTemplateDeployment@3\n            displayName: Deploy app-service ARM Template\n            inputs:\n              deploymentScope: Resource Group\n              azureResourceManagerConnection: $(serviceConnection)\n              subscriptionId: $(subscriptionId)\n              action: Create Or Update Resource Group\n              resourceGroupName: $(azureResourceGroup)\n              location: $(location)\n              templateLocation: Linked artifact\n              csmFile: 'infra/app-service/azuredeploy.json'\n              csmParametersFile: 'infra/azuredeploy.parameters.json'\n              overrideParameters: >-\n                -sasUrl $(sasToken)\n              deploymentMode: Incremental\n")),(0,a.kt)("p",null,"There's two notable things happening above:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"In the ",(0,a.kt)("inlineCode",{parentName:"li"},"SASGen")," job, a PowerShell script runs that ",(0,a.kt)("a",o({parentName:"li"},{href:"https://docs.microsoft.com/en-us/powershell/module/az.storage/new-azstoragecontainersastoken?view=azps-5.5.0"}),"generates a SaS token URL")," with read, write and list permissions that will last for 90 days. (Incidentally, there is a way to do this via ",(0,a.kt)("a",o({parentName:"li"},{href:"https://stackoverflow.com/a/56127006/761388"}),"ARM templates, and without PowerShell")," ","-"," but alas it didn't seem to work when we experimented with it.)"),(0,a.kt)("li",{parentName:"ol"},"The generated (secret) token URL (",(0,a.kt)("inlineCode",{parentName:"li"},"sasUrl"),") is passed as a parameter to our App Service ARM template. The ARM template sets an appsetting for the app service:")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n    "apiVersion": "2020-09-01",\n    "name": "appsettings",\n    "type": "config",\n    "properties": {\n        "WEBSITE_AUTH_TOKEN_CONTAINER_SASURL": "[parameters(\'sasUrl\')]"\n    }\n},\n')),(0,a.kt)("p",null,"If you google ",(0,a.kt)("inlineCode",{parentName:"p"},"WEBSITE_AUTH_TOKEN_CONTAINER_SASURL")," you will not find a geat deal. Documentation is short. What you will find is ",(0,a.kt)("a",o({parentName:"p"},{href:"http://jsandersblog.azurewebsites.net/2017/08/10/azure-app-service-authentication-using-a-blob-storage-for-token-cache/"}),"Jeff Sanders excellent blog on the topic"),". It is, in terms of content, it has some commonality with this post; except in Jeff's example he's manually implementing the workaround in the Azure Portal."),(0,a.kt)("h2",o({},{id:"whats-actually-happening"}),"What's actually happening?"),(0,a.kt)("p",null,"With this in place, every time someone logs into your app a JSON token is written to the storage like so:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"token in storage account",src:n(44717).Z,width:"600",height:"125"})),(0,a.kt)("p",null,"If you take the trouble to look inside you'll find something like this tucked away:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "encrypted": true,\n  "tokens": {\n    "aad": "herewith_a_very_very_long_encrypted_token"\n  },\n  "version": 1\n}\n')),(0,a.kt)("p",null,"With this in place, you can safely restart your app service and / or deploy a new one, safe in the knowledge that the tokens will live on in the storage account, and that consequently you will not be unauthenticating users."))}d.isMDXComponent=!0},96093:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"goodbye-client-affinity-hello-data-protection-with-azure",title:"Goodbye Client Affinity, Hello Data Protection with Azure",description:"How to use ASP.NET Data Protection to remove the need for sticky sessions with Client Affinity",authors:"johnnyreilly",tags:["Azure","Easy Auth","ASP.NET"],image:"./traffic-to-app-service.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/goodbye-client-affinity-hello-data-protection-with-azure",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-02-27-goodbye-client-affinity-hello-data-protection-with-azure/index.md",source:"@site/blog/2021-02-27-goodbye-client-affinity-hello-data-protection-with-azure/index.md",title:"Goodbye Client Affinity, Hello Data Protection with Azure",description:"How to use ASP.NET Data Protection to remove the need for sticky sessions with Client Affinity",date:"2021-02-27T00:00:00.000Z",formattedDate:"February 27, 2021",tags:[{label:"Azure",permalink:"/tags/azure"},{label:"Easy Auth",permalink:"/tags/easy-auth"},{label:"ASP.NET",permalink:"/tags/asp-net"}],readingTime:3.455,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"goodbye-client-affinity-hello-data-protection-with-azure",title:"Goodbye Client Affinity, Hello Data Protection with Azure",description:"How to use ASP.NET Data Protection to remove the need for sticky sessions with Client Affinity",authors:"johnnyreilly",tags:["Azure","Easy Auth","ASP.NET"],image:"./traffic-to-app-service.png",hide_table_of_contents:!1},prevItem:{title:"NSwag: TypeScript and CSharp client generation based on an API",permalink:"/generate-typescript-and-csharp-clients-with-nswag"},nextItem:{title:"Making Easy Auth tokens survive releases on Linux Azure App Service",permalink:"/easy-auth-tokens-survive-releases-on-linux-azure-app-service"}},p={image:n(42135).Z,authorsImageUrls:[void 0]},u=[{value:"Sharing is caring",id:"sharing-is-caring",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I've written lately about ",(0,a.kt)("a",o({parentName:"p"},{href:"/azure-app-service-health-checks-and-zero-downtime-deployments"}),"zero downtime releases with Azure App Service"),". Zero downtime releases are only successful if your authentication mechanism survives a new deployment. We looked in my last post at ",(0,a.kt)("a",o({parentName:"p"},{href:"/easy-auth-tokens-survive-releases-on-linux-azure-app-service"}),"how to achieve this with Azure's in-built authentication mechanism; Easy Auth"),"."),(0,a.kt)("p",null,"We're now going to look at how the same goal can be achieved if your ASP.NET application is authenticating another way. We achieve this through use of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/aspnet/core/security/data-protection/configuration/overview"}),"ASP.NET Data Protection")," system. Andrew Lock has written ",(0,a.kt)("a",o({parentName:"p"},{href:"https://andrewlock.net/an-introduction-to-the-data-protection-system-in-asp-net-core/"}),"an excellent walkthrough on the topic")," and I encourage you to read it."),(0,a.kt)("p",null,"We're interested in the ASP.NET data-protection system because it encrypts and decrypts sensitive data including the authentication cookie. It's wonderful that the data protection does this, but at the same time it presents a problem. We would like to route traffic to ",(0,a.kt)("em",{parentName:"p"},"multiple")," instances of our application\u2026 So traffic could go to instance 1, instance 2 of our app etc."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"traffic to app service",src:n(42135).Z,width:"600",height:"577"})),(0,a.kt)("p",null,"How can we ensure the different instances of our app can read the authentication cookies regardless of the instance that produced them? How can we ensure that instance 1 can read cookies produced by instance 2 and vice versa? And for that matter, we'd like all instances to be able to read cookies whether they were produced by an instance in a production or staging slot."),(0,a.kt)("p",null,'We\'re aiming to avoid the use of "sticky sessions" and ARRAffinity cookies. These ensure that traffic is continually routed to the same instance. Routing to the same instance explicitly prevents us from stopping routing traffic to an old instance and starting routing to a new one.'),(0,a.kt)("p",null,"With the data protection activated and multiple instances of your app service you immediately face the issue that different instances of the app will be unable to read cookies they did not create. This is the default behaviour of data protection. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/web-farm?view=aspnetcore-5.0#data-protection"}),"To quote the docs:")),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Data Protection relies upon a set of cryptographic keys stored in a key ring. When the Data Protection system is initialized, it applies default settings that store the key ring locally. Under the default configuration, a unique key ring is stored on each node of the web farm. Consequently, each web farm node can't decrypt data that's encrypted by an app on any other node.")),(0,a.kt)("p",null,"The problem here is the data protection keys (the key ring) is being stored locally on each instance. What are the implications of this? Well, For example, instance 2 doesn't have access to the keys instance 1 is using and so can't decrypt instance 1 cookies."),(0,a.kt)("h2",o({},{id:"sharing-is-caring"}),"Sharing is caring"),(0,a.kt)("p",null,"What we need to do is move away from storing keys locally, and to storing it in a ",(0,a.kt)("em",{parentName:"p"},"shared")," place instead. We're going to store data protection keys in Azure Blob Storage and protect the keys with Azure Key Vault:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"persist keys to azure blob",src:n(99166).Z,width:"432",height:"600"})),(0,a.kt)("p",null,"All instances of the application can access the key ring and consequently sharing cookies is enabled. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/aspnet/core/security/data-protection/configuration/overview?view=aspnetcore-5.0#protectkeyswithazurekeyvault"}),"As the documentation attests"),", enabling this is fairly simple. It amounts to adding the following packages to your ASP.NET app:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://www.nuget.org/packages/Azure.Extensions.AspNetCore.DataProtection.Blobs"}),(0,a.kt)("inlineCode",{parentName:"a"},"Azure.Extensions.AspNetCore.DataProtection.Blobs"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://www.nuget.org/packages/Azure.Extensions.AspNetCore.DataProtection.Keys"}),(0,a.kt)("inlineCode",{parentName:"a"},"Azure.Extensions.AspNetCore.DataProtection.Keys")))),(0,a.kt)("p",null,"And adding the following to the ",(0,a.kt)("inlineCode",{parentName:"p"},"ConfigureServices")," in your ASP.NET app:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'services.AddDataProtection().SetApplicationName("OurWebApp")\n        // azure credentials require storage blob contributor role permissions\n        // eg https://my-storage-account.blob.core.windows.net/keys/key\n        .PersistKeysToAzureBlobStorage(new Uri($"https://{Configuration["StorageAccountName"]}.blob.core.windows.net/keys/key"), new DefaultAzureCredential())\n\n        // azure credentials require key vault crypto role permissions\n        // eg https://my-key-vault.vault.azure.net/keys/dataprotection\n        .ProtectKeysWithAzureKeyVault(new Uri($"https://{Configuration["KeyVaultName"]}.vault.azure.net/keys/dataprotection"), new DefaultAzureCredential());\n')),(0,a.kt)("p",null,"In the above example you can see we're passing the name of our Storage account and Key Vault via configuration."),(0,a.kt)("p",null,"There's one more crucial piece of the puzzle here; and it's role assignments, better known as permissions. Your App Service needs to be able to read and write to Azure Key Vault and the Azure Blob Storage. The permissions of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles#storage-blob-data-contributor"}),"Storage Blob Data Contributor")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles#key-vault-crypto-officer-preview"}),"Key Vault Crypto Officer")," are sufficient to enable this. (If you'd like to see what configuring that looks like via ARM templates then ",(0,a.kt)("a",o({parentName:"p"},{href:"/arm-templates-security-role-assignments"}),"check out this post"),".)"),(0,a.kt)("p",null,"With this in place we're able to route traffic to any instance of our application, secure in the knowledge that it will be able to read the cookies. Furthermore, we've enabled zero downtime releases as a direct consequence."))}d.isMDXComponent=!0},27106:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"generate-typescript-and-csharp-clients-with-nswag",title:"NSwag: TypeScript and CSharp client generation based on an API",authors:"johnnyreilly",tags:["NSwag","typescript","C#"],image:"./use-generated-client.gif",hide_table_of_contents:!1},s=void 0,l={permalink:"/generate-typescript-and-csharp-clients-with-nswag",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-03-06-generate-typescript-and-csharp-clients-with-nswag/index.md",source:"@site/blog/2021-03-06-generate-typescript-and-csharp-clients-with-nswag/index.md",title:"NSwag: TypeScript and CSharp client generation based on an API",description:"Generating clients for APIs is a tremendous way to reduce the amount of work you have to do when you're building a project. Why handwrite that code when it can be auto-generated for you quickly and accurately by a tool like NSwag? To quote the docs:",date:"2021-03-06T00:00:00.000Z",formattedDate:"March 6, 2021",tags:[{label:"NSwag",permalink:"/tags/n-swag"},{label:"typescript",permalink:"/tags/typescript"},{label:"C#",permalink:"/tags/c"}],readingTime:8.54,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"generate-typescript-and-csharp-clients-with-nswag",title:"NSwag: TypeScript and CSharp client generation based on an API",authors:"johnnyreilly",tags:["NSwag","typescript","C#"],image:"./use-generated-client.gif",hide_table_of_contents:!1},prevItem:{title:"Managed Identity, Azure SQL and Entity Framework",permalink:"/managed-identity-azure-sql-entity-framework"},nextItem:{title:"Goodbye Client Affinity, Hello Data Protection with Azure",permalink:"/goodbye-client-affinity-hello-data-protection-with-azure"}},p={image:n(47350).Z,authorsImageUrls:[void 0]},u=[{value:"Create an API",id:"create-an-api",level:2},{value:"The client generator project",id:"the-client-generator-project",level:2},{value:"Building a &quot;make a client&quot; script",id:"building-a-make-a-client-script",level:2},{value:"Consume our generated API client",id:"consume-our-generated-api-client",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Generating clients for APIs is a tremendous way to reduce the amount of work you have to do when you're building a project. Why handwrite that code when it can be auto-generated for you quickly and accurately by a tool like ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/RicoSuter/NSwag"}),"NSwag"),"? To quote the docs:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"The NSwag project provides tools to generate OpenAPI specifications from existing ASP.NET Web API controllers and client code from these OpenAPI specifications. The project combines the functionality of Swashbuckle (OpenAPI/Swagger generation) and AutoRest (client generation) in one toolchain.")),(0,a.kt)("p",null,"There's some great posts out there that show you how to generate the clients with NSwag using an ",(0,a.kt)("inlineCode",{parentName:"p"},"nswag.json")," file directly from a .NET project."),(0,a.kt)("p",null,"However, what if you want to use NSwag purely for its client generation capabilities? You may have an API written with another language / platform that exposes a Swagger endpoint, that you simply wish to create a client for. How do you do that? Also, if you want to do some special customisation of the clients you're generating, you may find yourself struggling to configure that in ",(0,a.kt)("inlineCode",{parentName:"p"},"nswag.json"),". In that case, it's possible to hook into NSwag directly to do this with a simple .NET console app."),(0,a.kt)("p",null,"This post will:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Create a .NET API which exposes a Swagger endpoint. (Alternatively, you could use any other Swagger endpoint; ",(0,a.kt)("a",o({parentName:"li"},{href:"https://blog.logrocket.com/documenting-your-express-api-with-swagger/"}),"for example an Express API"),".)"),(0,a.kt)("li",{parentName:"ul"},"Create a .NET console app which can create both TypeScript and CSharp clients from a Swagger endpoint."),(0,a.kt)("li",{parentName:"ul"},"Create a script which, when run, creates a TypeScript client."),(0,a.kt)("li",{parentName:"ul"},"Consume the API using the generated client in a simple TypeScript application.")),(0,a.kt)("p",null,"You will need both ",(0,a.kt)("a",o({parentName:"p"},{href:"https://nodejs.org/en/"}),"Node.js")," and the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://dotnet.microsoft.com/download"}),".NET SDK")," installed."),(0,a.kt)("h2",o({},{id:"create-an-api"}),"Create an API"),(0,a.kt)("p",null,"We'll now create an API which exposes a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://swagger.io/resources/open-api/"}),"Swagger / Open API")," endpoint. Whilst we're doing that we'll create a TypeScript React app which we'll use later on. We'll drop to the command line and enter the following commands which use the .NET SDK, node and the ",(0,a.kt)("inlineCode",{parentName:"p"},"create-react-app")," package:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"mkdir src\ncd src\nnpx create-react-app client-app --template typescript\nmkdir server-app\ncd server-app\ndotnet new api -o API\ncd API\ndotnet add package NSwag.AspNetCore\n")),(0,a.kt)("p",null,"We now have a .NET API with a dependency on NSwag. We'll start to use it by replacing the ",(0,a.kt)("inlineCode",{parentName:"p"},"Startup.cs")," that's been generated with the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using Microsoft.AspNetCore.Builder;\nusing Microsoft.AspNetCore.Hosting;\nusing Microsoft.Extensions.Configuration;\nusing Microsoft.Extensions.DependencyInjection;\nusing Microsoft.Extensions.Hosting;\n\nnamespace API\n{\n    public class Startup\n    {\n        const string ALLOW_DEVELOPMENT_CORS_ORIGINS_POLICY = "AllowDevelopmentSpecificOrigins";\n        const string LOCAL_DEVELOPMENT_URL = "http://localhost:3000";\n\n        public Startup(IConfiguration configuration)\n        {\n            Configuration = configuration;\n        }\n\n        public IConfiguration Configuration { get; }\n\n        // This method gets called by the runtime. Use this method to add services to the container.\n        public void ConfigureServices(IServiceCollection services)\n        {\n\n            services.AddControllers();\n\n            services.AddCors(options => {\n                options.AddPolicy(name: ALLOW_DEVELOPMENT_CORS_ORIGINS_POLICY,\n                    builder => {\n                        builder.WithOrigins(LOCAL_DEVELOPMENT_URL)\n                            .AllowAnyMethod()\n                            .AllowAnyHeader()\n                            .AllowCredentials();\n                    });\n            });\n\n            // Register the Swagger services\n            services.AddSwaggerDocument();\n        }\n\n        // This method gets called by the runtime. Use this method to configure the HTTP request pipeline.\n        public void Configure (IApplicationBuilder app, IWebHostEnvironment env)\n        {\n            if (env.IsDevelopment())\n            {\n                app.UseDeveloperExceptionPage();\n            }\n            else\n            {\n                app.UseExceptionHandler("/Error");\n                app.UseHsts ();\n                app.UseHttpsRedirection();\n            }\n\n            app.UseDefaultFiles();\n            app.UseStaticFiles();\n\n            app.UseRouting();\n\n            app.UseAuthorization();\n\n            // Register the Swagger generator and the Swagger UI middlewares\n            app.UseOpenApi();\n            app.UseSwaggerUi3();\n\n            if (env.IsDevelopment())\n                app.UseCors(ALLOW_DEVELOPMENT_CORS_ORIGINS_POLICY);\n\n            app.UseEndpoints(endpoints =>\n            {\n                endpoints.MapControllers();\n            });\n        }\n    }\n}\n')),(0,a.kt)("p",null,"The significant changes in the above ",(0,a.kt)("inlineCode",{parentName:"p"},"Startup.cs")," are:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Exposing a Swagger endpoint with ",(0,a.kt)("inlineCode",{parentName:"li"},"UseOpenApi")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"UseSwaggerUi3"),". NSwag will automagically create Swagger endpoints in your application for all your controllers. The .NET template ships with a ",(0,a.kt)("inlineCode",{parentName:"li"},"WeatherForecastController"),"."),(0,a.kt)("li",{parentName:"ol"},"Allowing ",(0,a.kt)("a",o({parentName:"li"},{href:"https://docs.microsoft.com/en-us/aspnet/core/security/cors"}),"Cross-Origin Requests (CORS)")," which is useful during development (and will facilitate a demo later).")),(0,a.kt)("p",null,"Back in the root of our project we're going to initialise an npm project. We're going to use this to put in place a number of handy ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.npmjs.com/cli/v6/using-npm/scripts"}),(0,a.kt)("inlineCode",{parentName:"a"},"npm scripts"))," that will make our project easier to work with. So we'll ",(0,a.kt)("inlineCode",{parentName:"p"},"npm init")," and accept all the defaults."),(0,a.kt)("p",null,"Now we're going add some dependencies which our scripts will use: ",(0,a.kt)("inlineCode",{parentName:"p"},"npm install cpx cross-env npm-run-all start-server-and-test")),(0,a.kt)("p",null,"We'll also add ourselves some ",(0,a.kt)("inlineCode",{parentName:"p"},"scripts")," to our ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"scripts": {\n    "postinstall": "npm run install:client-app && npm run install:server-app",\n    "install:client-app": "cd src/client-app && npm install",\n    "install:server-app": "cd src/server-app/API && dotnet restore",\n    "build": "npm run build:client-app && npm run build:server-app",\n    "build:client-app": "cd src/client-app && npm run build",\n    "postbuild:client-app": "cpx \\"src/client-app/build/**/*.*\\" \\"src/server-app/API/wwwroot/\\"",\n    "build:server-app": "cd src/server-app/API && dotnet build --configuration release",\n    "start": "run-p start:client-app start:server-app",\n    "start:client-app": "cd src/client-app && npm start",\n    "start:server-app": "cross-env ASPNETCORE_URLS=http://*:5000 ASPNETCORE_ENVIRONMENT=Development dotnet watch --project src/server-app/API run --no-launch-profile"\n  }\n')),(0,a.kt)("p",null,"Let's walk through what the above scripts provide us with:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Running ",(0,a.kt)("inlineCode",{parentName:"li"},"npm install")," in the root of our project will not only install dependencies for our root ",(0,a.kt)("inlineCode",{parentName:"li"},"package.json"),", thanks to our ",(0,a.kt)("inlineCode",{parentName:"li"},"postinstall"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"install:client-app")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"install:server-app")," scripts it will install the React app and .NET app dependencies as well."),(0,a.kt)("li",{parentName:"ul"},"Running ",(0,a.kt)("inlineCode",{parentName:"li"},"npm run build")," will build our client and server apps."),(0,a.kt)("li",{parentName:"ul"},"Running ",(0,a.kt)("inlineCode",{parentName:"li"},"npm run start")," will start both our React app and our .NET app. Our React app will be started at ",(0,a.kt)("a",o({parentName:"li"},{href:"http://localhost:3000"}),"http://localhost:3000"),". Our .NET app will be started at ",(0,a.kt)("a",o({parentName:"li"},{href:"http://localhost:5000"}),"http://localhost:5000")," (some environment variables are passed to it with ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/kentcdodds/cross-env"}),(0,a.kt)("inlineCode",{parentName:"a"},"cross-env"))," ).")),(0,a.kt)("p",null,"Once ",(0,a.kt)("inlineCode",{parentName:"p"},"npm run start")," has been run, you will find a Swagger endpoint at ",(0,a.kt)("a",o({parentName:"p"},{href:"http://localhost:5000/swagger"}),"http://localhost:5000/swagger"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"swagger screenshot",src:n(73812).Z,width:"600",height:"362"})),(0,a.kt)("h2",o({},{id:"the-client-generator-project"}),"The client generator project"),(0,a.kt)("p",null,"Now we've scaffolded our Swagger-ed API, we want to put together the console app that will generate our typed clients."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"cd src/server-app\ndotnet new console -o APIClientGenerator\ncd APIClientGenerator\ndotnet add package NSwag.CodeGeneration.CSharp\ndotnet add package NSwag.CodeGeneration.TypeScript\ndotnet add package NSwag.Core\n")),(0,a.kt)("p",null,"We now have a console app with dependencies on the code generation portions of NSwag. Now let's change up ",(0,a.kt)("inlineCode",{parentName:"p"},"Program.cs")," to make use of this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.IO;\nusing System.Threading.Tasks;\nusing NJsonSchema;\nusing NJsonSchema.CodeGeneration.TypeScript;\nusing NJsonSchema.Visitors;\nusing NSwag;\nusing NSwag.CodeGeneration.CSharp;\nusing NSwag.CodeGeneration.TypeScript;\n\nnamespace APIClientGenerator\n{\n    class Program\n    {\n        static async Task Main(string[] args)\n        {\n            if (args.Length != 3)\n                throw new ArgumentException("Expecting 3 arguments: URL, generatePath, language");\n\n            var url = args[0];\n            var generatePath = Path.Combine(Directory.GetCurrentDirectory(), args[1]);\n            var language = args[2];\n\n            if (language != "TypeScript" && language != "CSharp")\n                throw new ArgumentException("Invalid language parameter; valid values are TypeScript and CSharp");\n\n            if (language == "TypeScript")\n                await GenerateTypeScriptClient(url, generatePath);\n            else\n                await GenerateCSharpClient(url, generatePath);\n        }\n\n        async static Task GenerateTypeScriptClient(string url, string generatePath) =>\n            await GenerateClient(\n                document: await OpenApiDocument.FromUrlAsync(url),\n                generatePath: generatePath,\n                generateCode: (OpenApiDocument document) =>\n                {\n                    var settings = new TypeScriptClientGeneratorSettings();\n\n                    settings.TypeScriptGeneratorSettings.TypeStyle = TypeScriptTypeStyle.Interface;\n                    settings.TypeScriptGeneratorSettings.TypeScriptVersion = 3.5M;\n                    settings.TypeScriptGeneratorSettings.DateTimeType = TypeScriptDateTimeType.String;\n\n                    var generator = new TypeScriptClientGenerator(document, settings);\n                    var code = generator.GenerateFile();\n\n                    return code;\n                }\n            );\n\n        async static Task GenerateCSharpClient(string url, string generatePath) =>\n            await GenerateClient(\n                document: await OpenApiDocument.FromUrlAsync(url),\n                generatePath: generatePath,\n                generateCode: (OpenApiDocument document) =>\n                {\n                    var settings = new CSharpClientGeneratorSettings\n                    {\n                        UseBaseUrl = false\n                    };\n\n                    var generator = new CSharpClientGenerator(document, settings);\n                    var code = generator.GenerateFile();\n                    return code;\n                }\n            );\n\n        private async static Task GenerateClient(OpenApiDocument document, string generatePath, Func<OpenApiDocument, string> generateCode)\n        {\n            Console.WriteLine($"Generating {generatePath}...");\n\n            var code = generateCode(document);\n\n            await System.IO.File.WriteAllTextAsync(generatePath, code);\n        }\n    }\n}\n')),(0,a.kt)("p",null,"We've created ourselves a simple .NET console application that creates TypeScript and CSharp clients for a given Swagger URL. It expects three arguments:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"url")," ","-"," the url of the ",(0,a.kt)("inlineCode",{parentName:"li"},"swagger.json")," file to generate a client for."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"generatePath")," ","-"," the path where the generated client file should be placed, relative to this project."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"language")," ","-",' the language of the client to generate; valid values are "TypeScript" and "CSharp".')),(0,a.kt)("p",null,"To create a TypeScript client with it then we'd use the following command:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"dotnet run --project src/server-app/APIClientGenerator http://localhost:5000/swagger/v1/swagger.json src/client-app/src/clients.ts TypeScript\n")),(0,a.kt)("p",null,"However, for this to run successfully, we'll first have to ensure the API is running. It would be great if we had a single command we could run that would:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"bring up the API"),(0,a.kt)("li",{parentName:"ul"},"generate a client"),(0,a.kt)("li",{parentName:"ul"},"bring down the API")),(0,a.kt)("p",null,"Let's make that."),(0,a.kt)("h2",o({},{id:"building-a-make-a-client-script"}),'Building a "make a client" script'),(0,a.kt)("p",null,"In the root of the project we're going to add the following ",(0,a.kt)("inlineCode",{parentName:"p"},"scripts"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"generate-client:server-app": "start-server-and-test generate-client:server-app:serve http-get://localhost:5000/swagger/v1/swagger.json generate-client:server-app:generate",\n    "generate-client:server-app:serve": "cross-env ASPNETCORE_URLS=http://*:5000 ASPNETCORE_ENVIRONMENT=Development dotnet run --project src/server-app/API --no-launch-profile",\n    "generate-client:server-app:generate": "dotnet run --project src/server-app/APIClientGenerator http://localhost:5000/swagger/v1/swagger.json src/client-app/src/clients.ts TypeScript",\n')),(0,a.kt)("p",null,"Let's walk through what's happening here. Running ",(0,a.kt)("inlineCode",{parentName:"p"},"npm run generate-client:server-app")," will:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Use the ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/bahmutov/start-server-and-test"}),(0,a.kt)("inlineCode",{parentName:"a"},"start-server-and-test"))," package to spin up our server-app by running the ",(0,a.kt)("inlineCode",{parentName:"li"},"generate-client:server-app:serve")," script."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"start-server-and-test")," waits for the Swagger endpoint to start responding to requests. When it does start responding, ",(0,a.kt)("inlineCode",{parentName:"li"},"start-server-and-test")," runs the ",(0,a.kt)("inlineCode",{parentName:"li"},"generate-client:server-app:generate"),' script which runs our APIClientGenerator console app and provides it with the URL where our swagger can be found, the path of the file to generate and the language of "TypeScript"')),(0,a.kt)("p",null,"If you were wanting to generate a C# client (say if you were writing a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/js-free-frontends-blazor/"}),"Blazor")," app) then you could change the ",(0,a.kt)("inlineCode",{parentName:"p"},"generate-client:server-app:generate")," script as follows:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"generate-client:server-app:generate": "dotnet run --project src/server-app/ApiClientGenerator http://localhost:5000/swagger/v1/swagger.json clients.cs CSharp",\n')),(0,a.kt)("h2",o({},{id:"consume-our-generated-api-client"}),"Consume our generated API client"),(0,a.kt)("p",null,"Let's run the ",(0,a.kt)("inlineCode",{parentName:"p"},"npm run generate-client:server-app")," command. It creates a ",(0,a.kt)("inlineCode",{parentName:"p"},"clients.ts")," file which nestles nicely inside our ",(0,a.kt)("inlineCode",{parentName:"p"},"client-app"),". We're going to exercise that in a moment. First of all, let's enable proxying from our ",(0,a.kt)("inlineCode",{parentName:"p"},"client-app")," to our ",(0,a.kt)("inlineCode",{parentName:"p"},"server-app")," following the instructions in the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://create-react-app.dev/docs/proxying-api-requests-in-development/"}),"Create React App docs")," and adding the following to our ",(0,a.kt)("inlineCode",{parentName:"p"},"client-app/package.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"proxy": "http://localhost:5000"\n')),(0,a.kt)("p",null,"Now let's start our apps with ",(0,a.kt)("inlineCode",{parentName:"p"},"npm run start"),". We'll then replace the contents of ",(0,a.kt)("inlineCode",{parentName:"p"},"App.tsx")," with:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-jsx"}),'import React from "react";\nimport "./App.css";\nimport { WeatherForecast, WeatherForecastClient } from "./clients";\n\nfunction App() {\n  const [weather, setWeather] = React.useState<WeatherForecast[] | null>();\n  React.useEffect(() => {\n    async function loadWeather() {\n      const weatherClient = new WeatherForecastClient(/* baseUrl */ "");\n      const forecast = await weatherClient.get();\n      setWeather(forecast);\n    }\n    loadWeather();\n  }, [setWeather]);\n\n  return (\n    <div className="App">\n      <header className="App-header">\n        {weather ? (\n          <table>\n            <thead>\n              <tr>\n                <th>Date</th>\n                <th>Summary</th>\n                <th>Centigrade</th>\n                <th>Fahrenheit</th>\n              </tr>\n            </thead>\n            <tbody>\n              {weather.map(({ date, summary, temperatureC, temperatureF }) => (\n                <tr key={date}>\n                  <td>{new Date(date).toLocaleDateString()}</td>\n                  <td>{summary}</td>\n                  <td>{temperatureC}</td>\n                  <td>{temperatureF}</td>\n                </tr>\n              ))}\n            </tbody>\n          </table>\n        ) : (\n          <p>Loading weather...</p>\n        )}\n      </header>\n    </div>\n  );\n}\n\nexport default App;\n')),(0,a.kt)("p",null,"Inside the ",(0,a.kt)("inlineCode",{parentName:"p"},"React.useEffect")," above you can see we create a new instance of the auto-generated ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecastClient"),". We then call ",(0,a.kt)("inlineCode",{parentName:"p"},"weatherClient.get()")," which sends the ",(0,a.kt)("inlineCode",{parentName:"p"},"GET")," request to the server to acquire the data and provides it in a strongly typed fashion (",(0,a.kt)("inlineCode",{parentName:"p"},"get()")," returns an array of ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecast"),"). This is then displayed on the page like so:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"load data from server",src:n(47350).Z,width:"600",height:"354"})),(0,a.kt)("p",null,"As you an see we're loading data from the server using our auto-generated client. We're reducing the amount of code we have to write ",(0,a.kt)("em",{parentName:"p"},"and")," we're reducing the likelihood of errors."),(0,a.kt)("p",null,"This post was originally posted on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/generate-typescript-csharp-clients-nswag-api/"}),"LogRocket"),"."),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/generate-typescript-csharp-clients-nswag-api/"})))}d.isMDXComponent=!0},68051:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"managed-identity-azure-sql-entity-framework",title:"Managed Identity, Azure SQL and Entity Framework",authors:"johnnyreilly",tags:["connection string","managed identity","entity framework"],image:"./entity-framework-core-nuget.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/managed-identity-azure-sql-entity-framework",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-03-10-managed-identity-azure-sql-entity-framework/index.md",source:"@site/blog/2021-03-10-managed-identity-azure-sql-entity-framework/index.md",title:"Managed Identity, Azure SQL and Entity Framework",description:"Managed Identity offers a very secure way for applications running in Azure to connect to Azure SQL databases. It's an approach that does not require code changes; merely configuration of connection string and associated resources. Hence it has a good developer experience. Importantly, it allows us to avoid exposing our database to username / password authentication, and hence making it a tougher target for bad actors.",date:"2021-03-10T00:00:00.000Z",formattedDate:"March 10, 2021",tags:[{label:"connection string",permalink:"/tags/connection-string"},{label:"managed identity",permalink:"/tags/managed-identity"},{label:"entity framework",permalink:"/tags/entity-framework"}],readingTime:4.93,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"managed-identity-azure-sql-entity-framework",title:"Managed Identity, Azure SQL and Entity Framework",authors:"johnnyreilly",tags:["connection string","managed identity","entity framework"],image:"./entity-framework-core-nuget.png",hide_table_of_contents:!1},prevItem:{title:"The definitive guide to migrating from Blogger to Docusaurus",permalink:"/definitive-guide-to-migrating-from-blogger-to-docusaurus"},nextItem:{title:"NSwag: TypeScript and CSharp client generation based on an API",permalink:"/generate-typescript-and-csharp-clients-with-nswag"}},p={image:n(43403).Z,authorsImageUrls:[void 0]},u=[{value:"<code>Integrated Security=true</code>",id:"integrated-securitytrue",level:2},{value:"Managed Identity",id:"managed-identity",level:2},{value:"Connection String alone",id:"connection-string-alone",level:2},{value:"Usage with Entity Framework Core 5",id:"usage-with-entity-framework-core-5",level:2},{value:"User Assigned Managed Identity",id:"user-assigned-managed-identity",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Managed Identity offers a very secure way for applications running in Azure to connect to Azure SQL databases. It's an approach that does not require code changes; merely configuration of connection string and associated resources. Hence it has a good developer experience. Importantly, it allows us to avoid exposing our database to username / password authentication, and hence making it a tougher target for bad actors."),(0,a.kt)("p",null,"This post talks us through using managed identity for connecting to Azure SQL."),(0,a.kt)("h2",o({},{id:"integrated-securitytrue"}),(0,a.kt)("inlineCode",{parentName:"h2"},"Integrated Security=true")),(0,a.kt)("p",null,'Everyone is deploying to the cloud. Few are the organisations that view deployment to data centers they manage as the future. This is generally a good thing, however in the excitement of the new, it\'s possible to forget some of the good properties that "on premise" deployment afforded when it came to connectivity and authentication.'),(0,a.kt)("p",null,"I speak of course, of our old friend ",(0,a.kt)("inlineCode",{parentName:"p"},"Integrated Security=true"),". When you seek to connect a web application to a database, you'll typically use some kind of database connection string. And back in the day, it may have looked something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"Data Source=myServer;Initial Catalog=myDB;Integrated Security=true;\n")),(0,a.kt)("p",null,"The above provides a database server, a database and also ",(0,a.kt)("inlineCode",{parentName:"p"},"Integrated Security=true"),". When you see ",(0,a.kt)("inlineCode",{parentName:"p"},"Integrated Security=true"),', what you\'re essentially looking at is an instruction to use the identity that an application is running under (typically called a "service account") as the authentication credential to secure access to the database. Under the covers, this amounts to ',(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/sql/authentication-in-sql-server"}),"Windows Authentication"),"."),(0,a.kt)("p",null,"The significant thing about this approach is that it is more secure than using usernames and passwords in the connection string. If you have to use username and password to authenticate, then you need to persist them somewhere - so you need to make sure that's secure. Also, if someone manages to acquire that username and password, they're free to get access to the database and do malicious things."),(0,a.kt)("p",null,'Bottom line: the less you are sharing authentication credentials, the better your security. Integrated Security is a harder nut to crack than username and password. The thing to note about the above phrase is "Windows Authentication". Web Apps in Azure / AWS etc do not typically use Windows Authentication when it comes to connecting to the database. Connecting with username / password is far more common.'),(0,a.kt)("p",null,"What if there was a way to have the developer experience of ",(0,a.kt)("inlineCode",{parentName:"p"},"Integrated Security=true")," without needing to use Windows Authentication? There is."),(0,a.kt)("h2",o({},{id:"managed-identity"}),"Managed Identity"),(0,a.kt)("p",null,"The docs express the purpose of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/overview"}),"managed identity")," well:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"A common challenge for developers is the management of secrets and credentials to secure communication between different services. On Azure, managed identities eliminate the need for developers having to manage credentials by providing an identity for the Azure resource in Azure AD and using it to obtain Azure Active Directory (Azure AD) tokens")),(0,a.kt)("p",null,"Historically a certain amount of ceremony was required to use managed identity to connect to a database, and could involve augmenting a ",(0,a.kt)("inlineCode",{parentName:"p"},"DbContext")," like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public MyDbContext(DbContextOptions options) : base(options) {\n    var conn = (Microsoft.Data.SqlClient.SqlConnection)Database.GetDbConnection();\n    var credential = new DefaultAzureCredential();\n    var token = credential\n        .GetToken(\n            new Azure.Core.TokenRequestContext(new[] { "https://database.windows.net/.default" })\n        );\n    conn.AccessToken = token.Token;\n}\n')),(0,a.kt)("p",null,"This mechanism works, and has the tremendous upside of no longer requiring credentials be passed in a connection string. However, as you can see this isn't the simplest of setups. And also, what if you don't want to use managed identity when you're developing locally? This approach has baggage and forces us to make code changes."),(0,a.kt)("h2",o({},{id:"connection-string-alone"}),"Connection String alone"),(0,a.kt)("p",null,"The wonderful aspect of the original ",(0,a.kt)("inlineCode",{parentName:"p"},"Integrated Security=true")," approach, was that there were no code changes required; one need only supply the connection string. Just configuration."),(0,a.kt)("p",null,"This is now possible with Azure SQL thanks to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dotnet/SqlClient/pull/730"}),"this PR")," to the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.nuget.org/packages/Microsoft.Data.SqlClient/"}),"Microsoft.Data.SqlClient")," nuget package. (Incidentally, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://devblogs.microsoft.com/dotnet/introducing-the-new-microsoftdatasqlclient/"}),"Microsoft.Data.SqlClient is the successor to System.Data.SqlClient."),")"),(0,a.kt)("p",null,"Support for connection string managed identities ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dotnet/SqlClient/blob/master/release-notes/2.1/2.1.0/index.md#Azure-Active-Directory-Managed-Identity-authentication"}),"shipped with v2.1"),". Connection strings can look slightly different depending on the type of managed identity you're using:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'// For System Assigned Managed Identity\n"Server:{serverURL}; Authentication=Active Directory MSI; Initial Catalog={db};"\n\n// For System Assigned Managed Identity\n"Server:{serverURL}; Authentication=Active Directory Managed Identity; Initial Catalog={db};"\n\n// For User Assigned Managed Identity\n"Server:{serverURL}; Authentication=Active Directory MSI; User Id={ObjectIdOfManagedIdentity}; Initial Catalog={db};"\n\n// For User Assigned Managed Identity\n"Server:{serverURL}; Authentication=Active Directory Managed Identity; User Id={ObjectIdOfManagedIdentity}; Initial Catalog={db};"\n')),(0,a.kt)("p",null,"Regardless of the approach, you can see that none of the connection strings have credentials in them. And that's special."),(0,a.kt)("h2",o({},{id:"usage-with-entity-framework-core-5"}),"Usage with Entity Framework Core 5"),(0,a.kt)("p",null,"If you're using Entity Framework Core, you might be struggling to get this working and encountering strange error messages. In my ASP.NET project I had a dependendency on\n",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.nuget.org/packages/Microsoft.EntityFrameworkCore.SqlServer/5.0.4"}),"Microsoft.EntityFrameworkCore.SqlServer@5"),"."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"Microsoft.EntityFrameworkCore.SqlServer@5 in NuGet",src:n(43403).Z,width:"1516",height:"1120"})),(0,a.kt)("p",null,"If you look close above, you'll see that the package has a dependency on Microsoft.Data.SqlClient, but crucially on 2.0.1 or greater. So if ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet")," has installed a version of Microsoft.Data.SqlClient which is ",(0,a.kt)("em",{parentName:"p"},"less")," than 2.1 then the functionality required will not be installed. The resolution is simple, ensure that the required version is installed:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"dotnet add package Microsoft.Data.SqlClient --version 2.1.2\n")),(0,a.kt)("p",null,"The version which we want to use is 2.1 (or greater) and fortunately that is compatible with Entity Framework Core 5. Incidentally, when Entity Framework Core 6 ships it will no longer be necessary to manually specify this dependency as it already requires ",(0,a.kt)("a",o({parentName:"p"},{href:"mailto:Microsoft.Data.SqlClient@2.1"}),"Microsoft.Data.SqlClient@2.1")," as a minimum."),(0,a.kt)("h2",o({},{id:"user-assigned-managed-identity"}),"User Assigned Managed Identity"),(0,a.kt)("p",null,"If you're using user assigned managed identity, you'll need to supply the object id of your managed identity, which you can find in the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://portal.azure.com/"}),"Azure Portal"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Managed Identity object id",src:n(88439).Z,width:"1250",height:"634"})),(0,a.kt)("p",null,"You can configure this in ARM as well, but cryptically, the object id goes by the nom de plume of ",(0,a.kt)("inlineCode",{parentName:"p"},"principalId")," (thanks to my partner in crime ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jmccor99"}),"John McCormick")," for puzzling that out):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),"\"CONNECTIONSTRINGS__OURDBCONNECTION\": \"[concat('Server=tcp:', parameters('sqlServerName') , '.database.windows.net,1433;Initial Catalog=', parameters('sqlDatabaseName'),';Authentication=Active Directory MSI',';User Id=', reference(resourceId('Microsoft.ManagedIdentity/userAssignedIdentities/', parameters('managedIdentityName')), '2018-11-30').principalId)]\"\n")),(0,a.kt)("p",null,"That's it! With managed identity handling your authentication you can sleep easy, knowing you should be in a better place security wise."))}d.isMDXComponent=!0},57855:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"definitive-guide-to-migrating-from-blogger-to-docusaurus",title:"The definitive guide to migrating from Blogger to Docusaurus",authors:"johnnyreilly",tags:["Blogger","Docusaurus","typescript"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/definitive-guide-to-migrating-from-blogger-to-docusaurus",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-03-15-definitive-guide-to-migrating-from-blogger-to-docusaurus/index.md",source:"@site/blog/2021-03-15-definitive-guide-to-migrating-from-blogger-to-docusaurus/index.md",title:"The definitive guide to migrating from Blogger to Docusaurus",description:"This post documents how to migrate a blog from Blogger to Docusaurus.",date:"2021-03-15T00:00:00.000Z",formattedDate:"March 15, 2021",tags:[{label:"Blogger",permalink:"/tags/blogger"},{label:"Docusaurus",permalink:"/tags/docusaurus"},{label:"typescript",permalink:"/tags/typescript"}],readingTime:13.55,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"definitive-guide-to-migrating-from-blogger-to-docusaurus",title:"The definitive guide to migrating from Blogger to Docusaurus",authors:"johnnyreilly",tags:["Blogger","Docusaurus","typescript"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"RSS update; we moved to Docusaurus",permalink:"/rss-update-we-moved-to-docusaurus"},nextItem:{title:"Managed Identity, Azure SQL and Entity Framework",permalink:"/managed-identity-azure-sql-entity-framework"}},p={image:n(11895).Z,authorsImageUrls:[void 0]},u=[{value:"Updated 5th November 2022",id:"updated-5th-november-2022",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Blog as code",id:"blog-as-code",level:2},{value:"Downloading your Blogger content",id:"downloading-your-blogger-content",level:2},{value:"From HTML in XML to Markdown",id:"from-html-in-xml-to-markdown",level:2},{value:"Bringing it all together",id:"bringing-it-all-together",level:2},{value:"Redirecting from Blogger URLs to Docusaurus URLs",id:"redirecting-from-blogger-urls-to-docusaurus-urls",level:2},{value:"Comments",id:"comments",level:2},{value:"DNS and RSS",id:"dns-and-rss",level:2},{value:"RSS / Atom feeds",id:"rss--atom-feeds",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This post documents how to migrate a blog from Blogger to Docusaurus."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;The definitive guide to migrating from Blogger to Docusaurus&quot; with the Blogger and Docusaurus logos",src:n(11895).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"updated-5th-november-2022"}),"Updated 5th November 2022"),(0,a.kt)("p",null,'This post started out as an investigation into migrating from Blogger to Docusaurus. In the end I very much made the leap, and would recommend doing so to others. I\'ve transformed this post into a "definitive guide" on how to migrate. I intend to maintain this on an ongoing basis for the benefit of the community.'),(0,a.kt)("p",null,'Because I rather like what I originally wrote when I was in "investigation mode", I have largely left it in place. However, there are new sections which have been added in to augment what\'s there.'),(0,a.kt)("h2",o({},{id:"introduction"}),"Introduction"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://v2.docusaurus.io/"}),"Docusaurus")," is, amongst other things, a Markdown powered blogging platform. My blog has lived happily on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.blogger.com/"}),"Blogger")," for the past decade. I'm considering moving, but losing my historic content as part of the move was never an option. This post goes through what it would look like to move from Blogger to Docusaurus ",(0,a.kt)("em",{parentName:"p"},"without")," losing your content."),(0,a.kt)("p",null,"It is imperative that the world never forgets what I was doing with jQuery in 2012."),(0,a.kt)("h2",o({},{id:"blog-as-code"}),"Blog as code"),(0,a.kt)("p",null,'Everything is better when it\'s code. Infrastructure as code. Awesome right? So naturally "blog as code" must be better than just a blog. More seriously, ',(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Markdown"}),"Markdown"),' is a tremendous documentation format. Simple, straightforward and, like Goldilocks, "just right". For a long time I\'ve written everything as Markdown. My years of toil down the Open Source mines have preconditioned me to be very MD-disposed.'),(0,a.kt)("p",null,"I started out writing this blog a long time ago as pure HTML. Not the smoothest of writing formats. At some point I got into the habit of spinning up a new repo in GitHub for a new blogpost, writing it in Markdown and piping it through a variety of tools to convert it into HTML for publication on Blogger. As time passed I felt I'd be a lot happier if I wasn't creating a repo each time. What if I did all my blogging in a single repo and used that as the code that represented my blog?"),(0,a.kt)("p",null,"Just having that thought laid the seeds for what was to follow:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"An investigation into importing my content from Blogger into a GitHub repo"),(0,a.kt)("li",{parentName:"ol"},"An experimental port to Docusaurus")),(0,a.kt)("p",null,"We're going to go this now. First, let's create ourselves a Docusaurus site for our blog:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"npx create-docusaurus@latest blog-website classic\n")),(0,a.kt)("p",null,"This creates a standard Docusaurus site in the ",(0,a.kt)("inlineCode",{parentName:"p"},"blog-website")," directory. In there we'll find a ",(0,a.kt)("inlineCode",{parentName:"p"},"docusaurus.config.js")," file. There's much that can be configured here. It's worth remembering that Docusaurus is a tool for building documentation sites that also happens to feature a blog component. We're going to use it as a blog only. So we'll deactivate the docs component and configure the blog component to be the home page of our site, following the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/docs/blog#blog-only-mode"}),"Docusaurus documentation"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"module.exports = {\n  // ...\n  presets: [\n    [\n      '@docusaurus/preset-classic',\n      /** @type {import('@docusaurus/preset-classic').Options} */\n      ({\n        docs: false, // Deactivate docs\n        blog: {\n          blogTitle: 'I CAN MAKE THIS WORK',\n          blogDescription: 'The blog of johnnyreilly',\n          blogSidebarCount: 5,\n          postsPerPage: 1,\n          path: './blog',\n          routeBasePath: '/', // Make blog the home page\n          showReadingTime: true,\n          editUrl:\n            'https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/',\n        },\n        theme: {\n          customCss: require.resolve('./src/css/custom.css'),\n        },\n      }),\n    ],\n  ],\n  // ...\n};\n")),(0,a.kt)("h2",o({},{id:"downloading-your-blogger-content"}),"Downloading your Blogger content"),(0,a.kt)("p",null,"In order that we can migrate, we must obtain the blog content. This is a mass of HTML that lived inside Blogger's database. (One assumes they have a database; I haven't actually checked.) There's a ",(0,a.kt)("inlineCode",{parentName:"p"},"Back up content")," option inside Blogger's settings to allow this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Download content from Blogger",src:n(13336).Z,width:"650",height:"630"})),(0,a.kt)("p",null,"It provides you with an XML file with a dispiritingly small size. Ten years blogging? You'll get change out of 4Mb it turns out."),(0,a.kt)("h2",o({},{id:"from-html-in-xml-to-markdown"}),"From HTML in XML to Markdown"),(0,a.kt)("p",null,"We now want to take that XML and:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Extract each blog post (and it's associated metadata; title / tags and whatnot)"),(0,a.kt)("li",{parentName:"ul"},"Convert the HTML content of each blog post from HTML to Markdown, and save it as a Markdown file"),(0,a.kt)("li",{parentName:"ul"},"Download the images used in the blogpost so they can be stored in the repo as well")),(0,a.kt)("p",null,"To do this we're going to whip up a smallish TypeScript console app. Let's initialise it with the packages we're going to need:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"mkdir from-blogger-to-docusaurus\ncd from-blogger-to-docusaurus\nnpx typescript --init\nyarn init -y\nyarn add @types/he@^1.1.2 @types/jsdom@^20.0.0 @types/node@^18.11.9 @types/showdown@^2.0.0 axios@^1.1.3 fast-xml-parser@^3.21.1 he@^1.2.0 jsdom@^20.0.2 showdown@^2.1.0 ts-node@^10.9.1 typescript@^4.8.4\n")),(0,a.kt)("p",null,"We're using:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/NaturalIntelligence/fast-xml-parser"}),(0,a.kt)("inlineCode",{parentName:"a"},"fast-xml-parser"))," to parse XML"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/mathiasbynens/he"}),(0,a.kt)("inlineCode",{parentName:"a"},"he")),", ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/jsdom/jsdom"}),(0,a.kt)("inlineCode",{parentName:"a"},"jsdom"))," and ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/showdownjs/showdown"}),(0,a.kt)("inlineCode",{parentName:"a"},"showdown"))," to convert HTML to Markdown"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/axios/axios"}),(0,a.kt)("inlineCode",{parentName:"a"},"axios"))," to download images"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/microsoft/TypeScript"}),(0,a.kt)("inlineCode",{parentName:"a"},"typescript"))," to code in and ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/TypeStrong/ts-node"}),(0,a.kt)("inlineCode",{parentName:"a"},"ts-node"))," to make our TypeScript Node.js console app.")),(0,a.kt)("p",null,"Now we have all the packages we need, it's time to write our script."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import fs from 'fs';\nimport path from 'path';\nimport showdown from 'showdown';\nimport he from 'he';\nimport jsdom from 'jsdom';\nimport axios from 'axios';\nimport fastXmlParser from 'fast-xml-parser';\n\nconst bloggerXmlPath = './blog-03-17-2021.xml';\nconst docusaurusDirectory = '../blog-website';\nconst notMarkdownable: string[] = [];\n\nconst author = 'johnnyreilly';\nconst author_name = 'John Reilly';\nconst author_url = 'https://twitter.com/johnny_reilly';\nconst author_image_url = 'https://blog.johnnyreilly.com/img/profile.jpg';\n\nasync function makePostsFromXML() {\n  const blogDir = path.resolve(docusaurusDirectory, 'blog');\n\n  await deleteExistingFiles(blogDir);\n\n  await makeAuthorsYml(blogDir);\n\n  const posts = await getPosts();\n\n  for (const post of posts) {\n    await makePostIntoMarkDownAndDownloadImages(post);\n  }\n  if (notMarkdownable.length)\n    console.log(\n      'These blog posts could not be turned into MarkDown - go find out why!',\n      notMarkdownable\n    );\n}\n\nasync function deleteExistingFiles(directory: string) {\n  const filesAndFolders = await fs.promises.readdir(directory);\n  for (const file of filesAndFolders) {\n    try {\n      await fs.promises.unlink(path.join(directory, file));\n    } catch (e) {\n      await fs.promises.rm(path.join(directory, file), {\n        recursive: true,\n        force: true,\n      });\n    }\n  }\n}\n\n/**\n * Make an authors.yml file\n *\n * johnnyreilly:\n *   name: John Reilly\n *   url: https://twitter.com/johnny_reilly\n *   image_url: https://blog.johnnyreilly.com/img/profile.jpg\n */\nasync function makeAuthorsYml(directory: string) {\n  const authorsYml = `${author}:\n  name: ${author_name}\n  url: ${author_url}\n  image_url: ${author_image_url}\n`;\n\n  await fs.promises.writeFile(\n    path.join(directory, 'authors.yml'),\n    authorsYml,\n    'utf-8'\n  );\n}\n\nasync function getPosts(): Promise<Post[]> {\n  const xml = await fs.promises.readFile(bloggerXmlPath, 'utf-8');\n\n  const options = {\n    attributeNamePrefix: '@_',\n    attrNodeName: 'attr', //default is 'false'\n    textNodeName: '#text',\n    ignoreAttributes: false,\n    ignoreNameSpace: false,\n    allowBooleanAttributes: true,\n    parseNodeValue: true,\n    parseAttributeValue: true,\n    trimValues: true,\n    cdataTagName: '__cdata', //default is 'false'\n    cdataPositionChar: '\\\\c',\n    parseTrueNumberOnly: false,\n    arrayMode: true, //\"strict\"\n    attrValueProcessor: (val: string, attrName: string) =>\n      he.decode(val, { isAttributeValue: true }), //default is a=>a\n    tagValueProcessor: (val: string, tagName: string) => he.decode(val), //default is a=>a\n  };\n\n  const traversalObj = fastXmlParser.getTraversalObj(xml, options);\n  const blog = fastXmlParser.convertToJson(traversalObj, options);\n\n  const postsRaw = blog.feed[0].entry.filter(\n    (entry: any) =>\n      entry.category.some(\n        (category: any) =>\n          category.attr['@_term'] ===\n          'http://schemas.google.com/blogger/2008/kind#post'\n      ) &&\n      entry.link.some(\n        (link: any) =>\n          link.attr['@_href'] && link.attr['@_type'] === 'text/html'\n      ) &&\n      entry.published < '2021-03-07'\n  );\n\n  const posts: Post[] = postsRaw.map((entry: any) => {\n    return {\n      title: entry.title[0]['#text'],\n      content: entry.content[0]['#text'],\n      published: entry.published,\n      link: entry.link.find(\n        (link: any) =>\n          link.attr['@_href'] && link.attr['@_type'] === 'text/html'\n      )\n        ? entry.link.find(\n            (link: any) =>\n              link.attr['@_href'] && link.attr['@_type'] === 'text/html'\n          ).attr['@_href']\n        : undefined,\n      tags:\n        Array.isArray(entry.category) &&\n        entry.category.some(\n          (category: any) =>\n            category.attr['@_scheme'] === 'http://www.blogger.com/atom/ns#'\n        )\n          ? entry.category\n              .filter(\n                (category: any) =>\n                  category.attr['@_scheme'] ===\n                    'http://www.blogger.com/atom/ns#' &&\n                  category.attr['@_term'] !== 'constructor'\n              ) // 'constructor' will make docusaurus choke\n              .map((category: any) => category.attr['@_term'])\n          : [],\n    };\n  });\n\n  for (const post of posts) {\n    const { content, ...others } = post;\n    console.log(others, content.length);\n    if (!content || !others.title || !others.published)\n      throw new Error('No content');\n  }\n\n  return posts.filter((post) => post.link);\n}\n\nasync function makePostIntoMarkDownAndDownloadImages(post: Post) {\n  const converter = new showdown.Converter({\n    ghCodeBlocks: true,\n  });\n  const linkSections = post.link.split('/');\n  const linkSlug = linkSections[linkSections.length - 1];\n  const blogdirname =\n    post.published.substring(0, 10) + '-' + linkSlug.replace('.html', '');\n\n  const blogdirPath = path.resolve(docusaurusDirectory, 'blog', blogdirname);\n\n  if (!fs.existsSync(blogdirPath)) {\n    fs.mkdirSync(blogdirPath);\n  }\n\n  const contentProcessed = post.content\n    // remove stray <br /> tags\n    .replace(/<br\\s*\\/?>/gi, '\\n')\n    // translate <code class=\"lang-cs\" into <code class=\"language-cs\"> to be showdown friendly\n    .replace(/code class=\"lang-/gi, 'code class=\"language-')\n    // convert \x3c!-- into \x3c!---\n    .replace(/\x3c!--/gi, '\\n\x3c!---\\n')\n    .replace(/--\x3e/gi, '\\n---\x3e\\n');\n  const images: string[] = [];\n  const dom = new jsdom.JSDOM(contentProcessed);\n  let markdown = '';\n  try {\n    markdown = converter\n      .makeMarkdown(contentProcessed, dom.window.document)\n      // bigger titles\n      .replace(/#### /g, '## ')\n\n      // <div style=\"width:100%;height:0;padding-bottom:56%;position:relative;\"><iframe src=\"https://giphy.com/embed/l7JDTHpsXM26k\" width=\"100%\" height=\"100%\" style=\"position:absolute\" frameborder=\"0\" class=\"giphy-embed\" allowfullscreen=\"\"></iframe></div>\n\n      // The mechanism below extracts the underlying iframe\n      .replace(/<div.*(<iframe.*\">).*<\\/div>/g, (replacer) => {\n        const dom = new jsdom.JSDOM(replacer);\n        const iframe = dom?.window?.document?.querySelector('iframe');\n        return iframe?.outerHTML ?? '';\n      })\n\n      // The mechanism below strips class and style attributes from iframes - react hates them\n      .replace(/<iframe.*<\\/iframe>/g, (replacer) => {\n        const dom = new jsdom.JSDOM(replacer);\n        const iframe = dom?.window?.document?.querySelector('iframe');\n        iframe?.removeAttribute('class');\n        iframe?.removeAttribute('style');\n        return iframe?.outerHTML ?? '';\n      })\n\n      // capitalise appropriately\n      .replace(/frameborder/g, 'frameBorder')\n      .replace(/allowfullscreen/g, 'allowFullScreen')\n      .replace(/charset/g, 'charSet')\n\n      // Deals with these:\n      // [![null](<https://4.bp.blogspot.com/-b9-GrL0IXaY/Xmqj4GRhKXI/AAAAAAAAT5s/ZoceUInSY5EWXeCr2LkGV9Zvea8S6-mUgCPcBGAYYCw/s640/hello_world_idb_keyval.png> =640x484)](<https://4.bp.blogspot.com/-b9-GrL0IXaY/Xmqj4GRhKXI/AAAAAAAAT5s/ZoceUInSY5EWXeCr2LkGV9Zvea8S6-mUgCPcBGAYYCw/s1600/hello_world_idb_keyval.png>)We successfully wrote something into IndexedDB, read it back and printed that value to the console. Amazing!\n      .replace(\n        /\\[!\\[null\\]\\(<(.*?)\\].*?>\\)/g,\n        (match) =>\n          `![](${match.slice(match.indexOf('<') + 1, match.indexOf('>'))})\\n\\n`\n      )\n\n      // Blogger tends to put images in HTML that looks like this:\n      // <div class=\"separator\" style=\"clear: both;\"><a href=\"https://1.bp.blogspot.com/-UwrtZigWg78/YDqN82KbjVI/AAAAAAAAZTE/Umezr1MGQicnxMMr5rQHD4xKINg9fasDACLcBGAsYHQ/s783/traffic-to-app-service.png\" style=\"display: block; padding: 1em 0; text-align: center; \"><img alt=\"traffic to app service\" border=\"0\" width=\"600\" data-original-height=\"753\" data-original-width=\"783\" src=\"https://1.bp.blogspot.com/-UwrtZigWg78/YDqN82KbjVI/AAAAAAAAZTE/Umezr1MGQicnxMMr5rQHD4xKINg9fasDACLcBGAsYHQ/s600/traffic-to-app-service.png\"></a></div>\n\n      // The mechanism below extracts the underlying image path and it's alt text\n      .replace(\n        /(<div.*>)*\\w*(<a .*>)*(<img .*\">)(<\\/a>)*.*(<\\/div>)*/g,\n        (replacer) => {\n          const div = new jsdom.JSDOM(replacer);\n          const img = div?.window?.document?.querySelector('img');\n          const alt = img?.getAttribute('alt') ?? '';\n          const src = img?.getAttribute('src') ?? '';\n\n          if (src) images.push(src);\n\n          return `![${alt}](${src})`;\n        }\n      );\n  } catch (e) {\n    console.log(post.link);\n    console.log(e);\n    notMarkdownable.push(post.link);\n    return;\n  }\n\n  for (const url of images) {\n    try {\n      const localUrl = await downloadImage(url, blogdirPath);\n      markdown = markdown.replace(url, localUrl);\n    } catch (e) {\n      console.error(`Failed to download ${url}`);\n    }\n  }\n\n  const content = `---\ntitle: \"${post.title}\"\nauthors: ${author}\ntags: [${post.tags.join(', ')}]\nhide_table_of_contents: false\n---\n${markdown}\n`;\n\n  await fs.promises.writeFile(\n    path.resolve(docusaurusDirectory, 'blog', blogdirPath, 'index.md'),\n    content\n  );\n}\n\nasync function downloadImage(url: string, directory: string) {\n  console.log(`Downloading ${url}`);\n  const pathParts = new URL(url).pathname.split('/');\n  const filename = decodeURIComponent(pathParts[pathParts.length - 1]);\n\n  const pathTo = path.join(directory, filename);\n\n  const writer = fs.createWriteStream(pathTo);\n\n  const response = await axios({\n    url,\n    method: 'GET',\n    responseType: 'stream',\n  });\n\n  response.data.pipe(writer);\n\n  return new Promise<string>((resolve, reject) => {\n    writer.on('finish', () => resolve(filename));\n    writer.on('error', reject);\n  });\n}\n\ninterface Post {\n  title: string;\n  content: string;\n  published: string;\n  link: string;\n  tags: string[];\n}\n\n// do it!\nmakePostsFromXML();\n")),(0,a.kt)("p",null,"To summarise what the script does, it:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"deletes the default blog posts"),(0,a.kt)("li",{parentName:"ul"},"creates a new ",(0,a.kt)("inlineCode",{parentName:"li"},"authors.yml")," file with my details in"),(0,a.kt)("li",{parentName:"ul"},"parses the blog XML into an array of ",(0,a.kt)("inlineCode",{parentName:"li"},"Post"),"s"),(0,a.kt)("li",{parentName:"ul"},"each post is then converted from HTML into Markdown, a Docusaurus header is created and prepended, then the ",(0,a.kt)("inlineCode",{parentName:"li"},"index.md")," file is saved to the ",(0,a.kt)("inlineCode",{parentName:"li"},"blog-website/blog/{POST_NAME}")," directory"),(0,a.kt)("li",{parentName:"ul"},"the images of each post are downloaded with Axios and saved to the ",(0,a.kt)("inlineCode",{parentName:"li"},"blog-website/blog/{POST_NAME}")," directory")),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/tree/main/from-blogger-to-docusaurus"}),"To see the full code, you can find it on the GitHub repository that now represents the blog.")),(0,a.kt)("p",null,"If you're trying to do this yourself, you'll want to change some of the variable values in the script; such as the author details."),(0,a.kt)("h2",o({},{id:"bringing-it-all-together"}),"Bringing it all together"),(0,a.kt)("p",null,"To run the script, we add the following script to the ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'  "scripts": {\n    "start": "ts-node index.ts"\n  },\n')),(0,a.kt)("p",null,"And have ourselves a merry little ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn start")," to kick off the process. In a very short period of time, if you crack open the ",(0,a.kt)("inlineCode",{parentName:"p"},"blogs")," directory of your Docusaurus site you'll see a collection of folders, Markdown files and images. These represent your blog and are ready to power Docusaurus:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Markdown files",src:n(80854).Z,width:"774",height:"723"})),(0,a.kt)("p",null,"I have slightly papered over some details here. For my own case I discovered that I hadn't always written perfect HTML when blogging. I had to go in and fix the HTML in a number of historic blogs and re-download, to get cleanish Markdown."),(0,a.kt)("p",null,'I also learned that a number of my blog\'s images had vanished from Blogger at some point. This makes me all the more convinced that storing your blog in a repo is a good idea. Things should not "go missing".'),(0,a.kt)("p",null,"If we now run ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn start")," in the ",(0,a.kt)("inlineCode",{parentName:"p"},"blog-website")," directory we can see the blog in action:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Blog in Docusaurus",src:n(28240).Z,width:"1404",height:"904"})),(0,a.kt)("p",null,"Congratulations! We're now the proud owners of a Docusaurus blog site based upon our Blogger content."),(0,a.kt)("p",null,"If you've got some curiously named image files you might encounter some minor issues that need fixing up. This should get you 95% the way there though. Docusaurus does a great job of telling you when there's issues."),(0,a.kt)("h2",o({},{id:"redirecting-from-blogger-urls-to-docusaurus-urls"}),"Redirecting from Blogger URLs to Docusaurus URLs"),(0,a.kt)("p",null,"The final step is to redirect from the old Blogger URLs to the new Docusaurus URLs. Blogger URLs look like this: ",(0,a.kt)("inlineCode",{parentName:"p"},"/2019/10/definitely-typed-movie.html"),". On the other hand, Docusaurus URLs look like this: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.johnnyreilly.com/2019/10/08/definitely-typed-movie"}),(0,a.kt)("inlineCode",{parentName:"a"},"/2019/10/08/definitely-typed-movie")),"."),(0,a.kt)("p",null,"I'll want to redirect from the former to the latter. I'll use the ",(0,a.kt)("inlineCode",{parentName:"p"},"@docusaurus/plugin-client-redirects")," plugin to do this. Inside the ",(0,a.kt)("inlineCode",{parentName:"p"},"docusaurus.config.js")," file, I'll add the following to the ",(0,a.kt)("inlineCode",{parentName:"p"},"plugins")," section:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"module.exports = {\n  // ...\n  plugins: [\n    // ...\n    [\n      'client-redirects',\n      /** @type {import('@docusaurus/plugin-client-redirects').Options} */\n      ({\n        createRedirects: function (existingPath) {\n          if (existingPath.match(urlRegex)) {\n            const [, year, month, date, slug] = existingPath.split('/');\n            const oldUrl = `/${year}/${month}/${slug}.html`;\n\n            // eg redirect from /2019/10/definitely-typed-movie.html -> /2019/10/08/definitely-typed-movie\n            console.log(`redirect from ${oldUrl} -> ${existingPath}`);\n\n            return [oldUrl, `/${year}/${month}/${slug}`];\n          }\n        },\n      }),\n    ],\n    // ...\n  ],\n};\n")),(0,a.kt)("p",null,"The function above will be run during the build process for each URL. And consequently a client side redirect will be created to go from the landing URL to the Docusaurus URL. The ",(0,a.kt)("inlineCode",{parentName:"p"},"console.log")," is there to help me see what's going on. I don't actually need it."),(0,a.kt)("p",null,"Having this in place should protect my SEO when the domain switches from Blogger to Docusaurus. Long term I shouldn't need this approach in place."),(0,a.kt)("h2",o({},{id:"comments"}),"Comments"),(0,a.kt)("p",null,"I'd always had comments on my blog. First with Blogger's in-built functionality and then with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://disqus.com/"}),"Disqus"),". One thing that Docusaurus doesn't support by default is comments for blog posts. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/feature-requests/p/comments-in-documents-or-blogs"}),"There's a feature request for it here.")," However, it doesn't exist right now."),(0,a.kt)("p",null,"For a while I considered this a dealbreaker, and wasn't planning to complete the migration. But then I had a discussion with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/JoshuaKGoldberg"}),"Josh Goldberg")," as to the value of comments. Essentially that they are nice, but not essential."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"discussion on Twitter with Josh Goldberg on the topic of the value of comments in blog posts",src:n(37201).Z,width:"1174",height:"1120"})),(0,a.kt)("p",null,"I rather came to agree with the notion that comments were only slightly interesting as I looked back at the comments I'd received on my blog over the years. So I decided to go ahead ",(0,a.kt)("em",{parentName:"p"},"without")," comments. I remain happy with that choice, so thanks Josh!"),(0,a.kt)("p",null,"However, if it's important to you, there are ways to support comments. One example is using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://giscus.app/"}),"Giscus"),"; ",(0,a.kt)("a",o({parentName:"p"},{href:"https://dipakparmar.medium.com/how-to-add-giscus-to-your-docs-site-built-with-docusaurus-d57fa7f8e2f3"}),"here is a guide on how to integrate it"),"."),(0,a.kt)("h2",o({},{id:"dns-and-rss"}),"DNS and RSS"),(0,a.kt)("p",null,"At this point I had a repository that represented my blog. I had a Docusaurus site that represented my blog. When I ran ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn build")," I got a Docusaurus site that looked like my blog. I had a redirect mechanism in place to protect my SEO."),(0,a.kt)("p",null,"I was ready to make the switch."),(0,a.kt)("p",null,"Hosting is a choice. When I initially migrated, I made use of GitHub Pages. I also experimented with Netlify. ",(0,a.kt)("a",o({parentName:"p"},{href:"/migrating-from-github-pages-to-azure-static-web-apps"}),"Finally I moved to using Azure Static Web Apps to make use of preview environments.")," There are many choices out there - you can pick the one that works best for you."),(0,a.kt)("p",null,"Once your site is up, the last stage of the migration is updating your DNS to point to the Docusaurus site. I use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.cloudflare.com/"}),"Cloudflare")," to manage my domain names and so that's where I made the switch."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the DNS settings in Cloudflare",src:n(46683).Z,width:"800",height:"381"})),(0,a.kt)("h2",o({},{id:"rss--atom-feeds"}),"RSS / Atom feeds"),(0,a.kt)("p",null,"If you're like me, you'll want to keep your RSS feed. I didn't want to disrupting people who consumed my RSS feed as I migrated."),(0,a.kt)("p",null,"Happily, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/docs/blog#feed"}),"Docusaurus ships with RSS / Atom in the box"),". Even happier still, most of the feed URLs in Blogger match the same URLs in Docusaurus. There was one exception in the form of the ",(0,a.kt)("inlineCode",{parentName:"p"},"/feeds/posts/default")," feed which is an Atom feed. Docusaurus has an ",(0,a.kt)("inlineCode",{parentName:"p"},"atom.xml")," feed but it's not in the same place."),(0,a.kt)("p",null,"This isn't a significant issue as I can create a page rule in Cloudflare to redirect from the old URL (",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.johnnyreilly.com/feeds/posts/default"}),"https://blog.johnnyreilly.com/feeds/posts/default"),") to the new URL (",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.johnnyreilly.com/atom.xml"}),"https://blog.johnnyreilly.com/atom.xml"),"):"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the page rule in Cloudflare",src:n(14276).Z,width:"1559",height:"889"})),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"I've migrated to Docusaurus and have been happily running there for a while now. I'm very happy with the result."),(0,a.kt)("p",null,"This post is intended to be a community resource that helps folk migrate from Blogger to Docusaurus. If you should find issues with the migration, please do let me know and help make this resource even better."))}d.isMDXComponent=!0},30739:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"rss-update-we-moved-to-docusaurus",title:"RSS update; we moved to Docusaurus",authors:"johnnyreilly",tags:["Blogger","Docusaurus","RSS","Atom"],image:"./rss.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/rss-update-we-moved-to-docusaurus",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-03-17-rss-update-we-moved-to-docusaurus/index.md",source:"@site/blog/2021-03-17-rss-update-we-moved-to-docusaurus/index.md",title:"RSS update; we moved to Docusaurus",description:"My blog lived happily on Blogger for the past decade. It's now built with Docusaurus and hosted on GitHub Pages. To understand the why, read my last post. This post serves purely to share details of feed updates for RSS / Atom subscribers.",date:"2021-03-17T00:00:00.000Z",formattedDate:"March 17, 2021",tags:[{label:"Blogger",permalink:"/tags/blogger"},{label:"Docusaurus",permalink:"/tags/docusaurus"},{label:"RSS",permalink:"/tags/rss"},{label:"Atom",permalink:"/tags/atom"}],readingTime:.56,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"rss-update-we-moved-to-docusaurus",title:"RSS update; we moved to Docusaurus",authors:"johnnyreilly",tags:["Blogger","Docusaurus","RSS","Atom"],image:"./rss.png",hide_table_of_contents:!1},prevItem:{title:"Bicep meet Azure Pipelines",permalink:"/bicep-meet-azure-pipelines"},nextItem:{title:"The definitive guide to migrating from Blogger to Docusaurus",permalink:"/definitive-guide-to-migrating-from-blogger-to-docusaurus"}},p={image:n(53051).Z,authorsImageUrls:[void 0]},u=[],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"My blog lived happily on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://icanmakethiswork.blogspot.com/"}),"Blogger")," for the past decade. It's now built with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://v2.docusaurus.io/"}),"Docusaurus")," and hosted on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://pages.github.com/"}),"GitHub Pages"),". To understand the why, ",(0,a.kt)("a",o({parentName:"p"},{href:"/definitive-guide-to-migrating-from-blogger-to-docusaurus"}),"read my last post"),". This post serves purely to share details of feed updates for RSS / Atom subscribers."),(0,a.kt)("p",null,"The Atom feed at this location no longer exists: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.johnnyreilly.com/feeds/posts/default"}),"https://blog.johnnyreilly.com/feeds/posts/default")),(0,a.kt)("p",null,"The following feeds are new and different:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"RSS - ",(0,a.kt)("a",o({parentName:"li"},{href:"https://blog.johnnyreilly.com/rss.xml"}),"https://blog.johnnyreilly.com/rss.xml")),(0,a.kt)("li",{parentName:"ul"},"Atom - ",(0,a.kt)("a",o({parentName:"li"},{href:"https://blog.johnnyreilly.com/atom.xml"}),"https://blog.johnnyreilly.com/atom.xml"))),(0,a.kt)("p",null,"The new format might mess with any feed reader you have set up. I do apologise for the friction; hopefully it shouldn't cause you too much drama."),(0,a.kt)("p",null,"Finally, all historic links should continue to work with the new site; redirects have been implemented."))}d.isMDXComponent=!0},99994:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"bicep-meet-azure-pipelines",title:"Bicep meet Azure Pipelines",authors:"johnnyreilly",tags:["Bicep","ARM templates","Azure Pipelines","Azure CLI"],image:"./bicep-meet-azure-pipelines.webp",hide_table_of_contents:!1},s=void 0,l={permalink:"/bicep-meet-azure-pipelines",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-03-20-bicep-meet-azure-pipelines/index.md",source:"@site/blog/2021-03-20-bicep-meet-azure-pipelines/index.md",title:"Bicep meet Azure Pipelines",description:"Bicep is a terser and more readable alternative language to ARM templates. Running ARM templates in Azure Pipelines is straightforward. However, there isn't yet a first class experience for running Bicep in Azure Pipelines. This post demonstrates an approach that can be used until a Bicep task is available.",date:"2021-03-20T00:00:00.000Z",formattedDate:"March 20, 2021",tags:[{label:"Bicep",permalink:"/tags/bicep"},{label:"ARM templates",permalink:"/tags/arm-templates"},{label:"Azure Pipelines",permalink:"/tags/azure-pipelines"},{label:"Azure CLI",permalink:"/tags/azure-cli"}],readingTime:4.905,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"bicep-meet-azure-pipelines",title:"Bicep meet Azure Pipelines",authors:"johnnyreilly",tags:["Bicep","ARM templates","Azure Pipelines","Azure CLI"],image:"./bicep-meet-azure-pipelines.webp",hide_table_of_contents:!1},prevItem:{title:"Bicep meet Azure Pipelines 2",permalink:"/bicep-meet-azure-pipelines-2"},nextItem:{title:"RSS update; we moved to Docusaurus",permalink:"/rss-update-we-moved-to-docusaurus"}},p={image:n(81474).Z,authorsImageUrls:[void 0]},u=[{value:"Bicep: mostly ARMless",id:"bicep-mostly-armless",level:2},{value:"App Service with Bicep",id:"app-service-with-bicep",level:2},{value:"Bicep in <code>azure-pipelines.yml</code>",id:"bicep-in-azure-pipelinesyml",level:2},{value:"Update: an even simpler alternative",id:"update-an-even-simpler-alternative",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/bicep"}),"Bicep")," is a terser and more readable alternative language to ARM templates. Running ARM templates in Azure Pipelines is straightforward. However, there isn't yet a first class experience for running Bicep in Azure Pipelines. This post demonstrates an approach that can be used until a Bicep task is available."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"Bicep meet Azure Pipelines",src:n(81474).Z,width:"504",height:"252"})),(0,a.kt)("h2",o({},{id:"bicep-mostly-armless"}),"Bicep: mostly ARMless"),(0,a.kt)("p",null,"If you've been working with Azure and infrastructure as code, you'll likely have encountered ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview"}),"ARM templates"),". They're a domain specific language that lives inside JSON, used to define the infrastructure that is deployed to Azure; App Services, Key Vaults and the like."),(0,a.kt)("p",null,"ARM templates are quite verbose and not the easiest thing to read. This is a consequence of being effectively a language nestled inside another language. Bicep is an alternative language which is far more readable. Bicep transpiles down to ARM templates, in the same way that TypeScript transpiles down to JavaScript."),(0,a.kt)("p",null,"Bicep is quite new, but already it enjoys feature parity with ARM templates (as of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/bicep/releases/tag/v0.3.1"}),"v0.3"),") and ships as part of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/MicrosoftDocs/azure-docs-cli/blob/master/docs-ref-conceptual/release-notes-azure-cli/index.md#arm-1"}),"Azure CLI"),". However, as Bicep is new, it doesn't yet have a dedicated Azure Pipelines task for deployment. This should exist in future, perhaps as soon as the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/bicep/issues/1341"}),"v0.4 release"),". In the meantime there's an alternative way to achieve this which we'll go through."),(0,a.kt)("h2",o({},{id:"app-service-with-bicep"}),"App Service with Bicep"),(0,a.kt)("p",null,"Let's take a simple Bicep file, ",(0,a.kt)("inlineCode",{parentName:"p"},"azuredeploy.bicep"),", which is designed to deploy an App Service resource to Azure. It looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"@description('Tags that our resources need')\nparam tags object = {\n  costCenter: 'todo: replace'\n  environment: 'todo: replace'\n  application: 'todo: replace with app name'\n  description: 'todo: replace'\n  managedBy: 'ARM'\n}\n\n@minLength(2)\n@description('Base name of the resource such as web app name and app service plan')\nparam applicationName string\n\n@description('Location for all resources.')\nparam location string = resourceGroup().location\n\n@description('The SKU of App Service Plan')\nparam sku string\n\nvar appServicePlanName_var = 'plan-${applicationName}-${tags.environment}'\nvar linuxFxVersion = 'DOTNETCORE|5.0'\nvar fullApplicationName_var = 'app-${applicationName}-${uniqueString(applicationName)}'\n\nresource appServicePlanName 'Microsoft.Web/serverfarms@2019-08-01' = {\n  name: appServicePlanName_var\n  location: location\n  sku: {\n    name: sku\n  }\n  kind: 'linux'\n  tags: {\n    CostCenter: tags.costCenter\n    Environment: tags.environment\n    Description: tags.description\n    ManagedBy: tags.managedBy\n  }\n  properties: {\n    reserved: true\n  }\n}\n\nresource fullApplicationName 'Microsoft.Web/sites@2018-11-01' = {\n  name: fullApplicationName_var\n  location: location\n  kind: 'app'\n  tags: {\n    CostCenter: tags.costCenter\n    Environment: tags.environment\n    Description: tags.description\n    ManagedBy: tags.managedBy\n  }\n  properties: {\n    serverFarmId: appServicePlanName.id\n    clientAffinityEnabled: true\n    siteConfig: {\n      appSettings: []\n      linuxFxVersion: linuxFxVersion\n      alwaysOn: false\n      ftpsState: 'Disabled'\n      http20Enabled: true\n      minTlsVersion: '1.2'\n      remoteDebuggingEnabled: false\n    }\n    httpsOnly: true\n  }\n  identity: {\n    type: 'SystemAssigned'\n  }\n}\n\noutput fullApplicationName string = fullApplicationName_var\n")),(0,a.kt)("p",null,"When transpiled down to an ARM template, this Bicep file more than doubles in size:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"azuredeploy.bicep")," - 1782 bytes"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"azuredeploy.json")," - 3863 bytes")),(0,a.kt)("p",null,"This tells you something of the advantage of Bicep. The template comes with an associated ",(0,a.kt)("inlineCode",{parentName:"p"},"azuredeploy.parameters.json")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#",\n  "contentVersion": "1.0.0.0",\n  "parameters": {\n    "tags": {\n      "value": {\n        "costCenter": "8888",\n        "environment": "stg",\n        "application": "hello-azure",\n        "description": "App Service for hello-azure",\n        "managedBy": "ARM"\n      }\n    },\n    "sku": {\n      "value": "B1"\n    }\n  }\n}\n')),(0,a.kt)("p",null,"It's worth remembering that you can use the same parameters files with Bicep that you can use with ARM templates. This is great for minimising friction when it comes to migrating."),(0,a.kt)("h2",o({},{id:"bicep-in-azure-pipelinesyml"}),"Bicep in ",(0,a.kt)("inlineCode",{parentName:"h2"},"azure-pipelines.yml")),(0,a.kt)("p",null,"Now we have our Bicep file, we want to execute it from the context of an Azure Pipeline. If we were working directly with the ARM template we'd likely have something like this in place:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- task: AzureResourceManagerTemplateDeployment@3\n  displayName: 'Deploy Hello Azure ARM'\n  inputs:\n    azureResourceManagerConnection: '$(azureSubscription)'\n    action: Create Or Update Resource Group\n    resourceGroupName: '$(resourceGroupName)'\n    location: 'North Europe'\n    templateLocation: Linked artifact\n    csmFile: 'infra/app-service/azuredeploy.json'\n    csmParametersFile: 'infra/app-service/azuredeploy.parameters.json'\n    deploymentMode: Incremental\n    deploymentOutputs: resourceGroupDeploymentOutputs\n    overrideParameters: -applicationName $(Build.Repository.Name)\n\n- pwsh: |\n    $outputs = ConvertFrom-Json '$(resourceGroupDeploymentOutputs)'\n    foreach ($output in $outputs.PSObject.Properties) {\n        Write-Host \"##vso[task.setvariable variable=RGDO_$($output.Name)]$($output.Value.value)\"\n    }\n  displayName: 'Turn ARM outputs into variables'\n")),(0,a.kt)("p",null,"There's two tasks above. The first is the native task for ARM deployments which takes our ARM template and our parameters and deploys them. The second task takes the output variables from the first task and converts them into Azure Pipeline variables such that they can be referenced later in the pipeline. In this case this variablifies our ",(0,a.kt)("inlineCode",{parentName:"p"},"fullApplicationName")," output."),(0,a.kt)("p",null,"There is, as yet, no ",(0,a.kt)("inlineCode",{parentName:"p"},"BicepTemplateDeployment@1"),". ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/bicep/issues/1341"}),"Though it's coming"),". In the meantime, the marvellous ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/adotfrank"}),"Alex Frankel")," ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/bicep/issues/1341#issuecomment-802010110"}),"advised"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"I'd recommend using the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/azure/devops/pipelines/tasks/deploy/azure-cli?view=azure-devops"}),"Azure CLI task")," to deploy. As long as that task is updated to Az CLI version 2.20 or later, it will automatically install the bicep CLI when calling ",(0,a.kt)("inlineCode",{parentName:"p"},"az deployment group create -f main.bicep"),".")),(0,a.kt)("p",null,"Let's give it a go!"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- task: AzureCLI@2\n  displayName: 'Deploy Hello Azure Bicep'\n  inputs:\n    azureSubscription: '$(azureSubscription)'\n    scriptType: bash\n    scriptLocation: inlineScript\n    inlineScript: |\n      az --version\n\n      echo \"az deployment group create --resource-group '$(resourceGroupName)' --name appservicedeploy\"\n      az deployment group create --resource-group '$(resourceGroupName)' --name appservicedeploy \\\n        --template-file infra/app-service/azuredeploy.bicep \\\n        --parameters infra/app-service/azuredeploy.parameters.json \\\n        --parameters applicationName='$(Build.Repository.Name)'\n\n      echo \"az deployment group show --resource-group '$(resourceGroupName)' --name appservicedeploy\"\n      deploymentoutputs=$(az deployment group show --resource-group '$(resourceGroupName)' --name appservicedeploy \\\n        --query properties.outputs)\n\n      echo 'convert outputs to variables'\n      echo $deploymentoutputs | jq -c '. | to_entries[] | [.key, .value.value]' |\n        while IFS=$\"\\n\" read -r c; do\n          outputname=$(echo \"$c\" | jq -r '.[0]')\n          outputvalue=$(echo \"$c\" | jq -r '.[1]')\n          echo \"setting variable RGDO_$outputname=$outputvalue\"\n          echo \"##vso[task.setvariable variable=RGDO_$outputname]$outputvalue\"\n        done\n")),(0,a.kt)("p",null,"The above is just a single Azure CLI task (as advised). It invokes ",(0,a.kt)("inlineCode",{parentName:"p"},"az deployment group create")," passing the relevant parameters. It then acquires the output properties using ",(0,a.kt)("inlineCode",{parentName:"p"},"az deployment group show"),". Finally it once again converts these outputs to Azure Pipeline variables with some ",(0,a.kt)("a",o({parentName:"p"},{href:"https://stedolan.github.io/jq/"}),(0,a.kt)("inlineCode",{parentName:"a"},"jq"))," smarts."),(0,a.kt)("p",null,"This works right now, and running it results in something like the output below. So if you're excited about Bicep and don't want to wait for 0.4 to start moving on this, then this can get you going. To track the progress of the custom task, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/bicep/issues/1341"}),"keep an eye on this issue"),"."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Bicep in an Azure Pipeline",src:n(79696).Z,width:"1184",height:"1680"})),(0,a.kt)("h2",o({},{id:"update-an-even-simpler-alternative"}),"Update: an even simpler alternative"),(0,a.kt)("p",null,"There is even a simpler way to do this which I discovered subsequent to writing this. ",(0,a.kt)("a",o({parentName:"p"},{href:"/bicep-meet-azure-pipelines-2"}),"Have a read"),"."))}d.isMDXComponent=!0},27319:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"bicep-meet-azure-pipelines-2",title:"Bicep meet Azure Pipelines 2",authors:"johnnyreilly",tags:["Bicep","ARM templates","Azure Pipelines","Azure CLI"],image:"./bicep-meet-azure-pipelines.webp",hide_table_of_contents:!1},s=void 0,l={permalink:"/bicep-meet-azure-pipelines-2",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-03-23-bicep-meet-azure-pipelines-2/index.md",source:"@site/blog/2021-03-23-bicep-meet-azure-pipelines-2/index.md",title:"Bicep meet Azure Pipelines 2",description:"Last time I wrote about how to use the Azure CLI to run Bicep within the context of an Azure Pipeline. The solution was relatively straightforward, and involved using az deployment group create in a task. There's an easier way.",date:"2021-03-23T00:00:00.000Z",formattedDate:"March 23, 2021",tags:[{label:"Bicep",permalink:"/tags/bicep"},{label:"ARM templates",permalink:"/tags/arm-templates"},{label:"Azure Pipelines",permalink:"/tags/azure-pipelines"},{label:"Azure CLI",permalink:"/tags/azure-cli"}],readingTime:1.67,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"bicep-meet-azure-pipelines-2",title:"Bicep meet Azure Pipelines 2",authors:"johnnyreilly",tags:["Bicep","ARM templates","Azure Pipelines","Azure CLI"],image:"./bicep-meet-azure-pipelines.webp",hide_table_of_contents:!1},prevItem:{title:"Hello World Bicep",permalink:"/hello-world-bicep"},nextItem:{title:"Bicep meet Azure Pipelines",permalink:"/bicep-meet-azure-pipelines"}},p={image:n(80029).Z,authorsImageUrls:[void 0]},u=[{value:"The easier way",id:"the-easier-way",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"/bicep-meet-azure-pipelines"}),"Last time")," I wrote about how to use the Azure CLI to run Bicep within the context of an Azure Pipeline. The solution was relatively straightforward, and involved using ",(0,a.kt)("inlineCode",{parentName:"p"},"az deployment group create")," in a task. There's an easier way."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"Bicep meet Azure Pipelines",src:n(80029).Z,width:"504",height:"252"})),(0,a.kt)("h2",o({},{id:"the-easier-way"}),"The easier way"),(0,a.kt)("p",null,"The target reader of the previous post was someone who was already using ",(0,a.kt)("inlineCode",{parentName:"p"},"AzureResourceManagerTemplateDeployment@3")," in an Azure Pipeline to deploy an ARM template. Rather than replacing your existing ",(0,a.kt)("inlineCode",{parentName:"p"},"AzureResourceManagerTemplateDeployment@3")," tasks, all you need do is insert a prior ",(0,a.kt)("inlineCode",{parentName:"p"},"bash")," step that compiles the Bicep to ARM, which your existing template can then process. It looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- bash: az bicep build --file infra/app-service/azuredeploy.bicep\n  displayName: 'Compile Bicep to ARM'\n")),(0,a.kt)("p",null,"This will take your Bicep template of ",(0,a.kt)("inlineCode",{parentName:"p"},"azuredeploy.bicep"),", transpile it into an ARM template named ",(0,a.kt)("inlineCode",{parentName:"p"},"azuredeploy.json")," which a subsequent ",(0,a.kt)("inlineCode",{parentName:"p"},"AzureResourceManagerTemplateDeployment@3")," task can process. Since this is just exercising the Azure CLI, using ",(0,a.kt)("inlineCode",{parentName:"p"},"bash")," is not required; powershell etc would also be fine; it's just required that the Azure CLI is available in a pipeline."),(0,a.kt)("p",null,"In fact this simple task could even be a one-liner if you didn't fancy using the ",(0,a.kt)("inlineCode",{parentName:"p"},"displayName"),". (Though I say keep it; optimising for readability is generally a good shout.) A full pipeline could look like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- bash: az bicep build --file infra/app-service/azuredeploy.bicep\n  displayName: 'Compile Bicep to ARM'\n\n- task: AzureResourceManagerTemplateDeployment@3\n  displayName: 'Deploy Hello Azure ARM'\n  inputs:\n    azureResourceManagerConnection: '$(azureSubscription)'\n    action: Create Or Update Resource Group\n    resourceGroupName: '$(resourceGroupName)'\n    location: 'North Europe'\n    templateLocation: Linked artifact\n    csmFile: 'infra/app-service/azuredeploy.json' # created by bash script\n    csmParametersFile: 'infra/app-service/azuredeploy.parameters.json'\n    deploymentMode: Incremental\n    deploymentOutputs: resourceGroupDeploymentOutputs\n    overrideParameters: -applicationName $(Build.Repository.Name)\n\n- pwsh: |\n    $outputs = ConvertFrom-Json '$(resourceGroupDeploymentOutputs)'\n    foreach ($output in $outputs.PSObject.Properties) {\n        Write-Host \"##vso[task.setvariable variable=RGDO_$($output.Name)]$($output.Value.value)\"\n    }\n  displayName: 'Turn ARM outputs into variables'\n")),(0,a.kt)("p",null,"And when it's run, it may result in something along these lines:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Bicep in an Azure Pipeline",src:n(79530).Z,width:"1916",height:"1132"})),(0,a.kt)("p",null,"So if you want to get using Bicep right now with minimal effort, this an on ramp that could work for you! Props to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/foldr"}),"Jamie McCrindle")," for suggesting this."))}d.isMDXComponent=!0},75890:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"hello-world-bicep",title:"Hello World Bicep",authors:"johnnyreilly",tags:["Bicep","ARM templates"],image:"./hello-world-bicep.webp",hide_table_of_contents:!1},s=void 0,l={permalink:"/hello-world-bicep",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-04-10-hello-world-bicep/index.md",source:"@site/blog/2021-04-10-hello-world-bicep/index.md",title:"Hello World Bicep",description:'Bicep makes Azure Resource Management a great deal simpler than ARM templates. The selling point here is grokkability. This post takes a look at the "Hello World" example recently added to the Bicep repo to appreciate quite what a difference it makes.',date:"2021-04-10T00:00:00.000Z",formattedDate:"April 10, 2021",tags:[{label:"Bicep",permalink:"/tags/bicep"},{label:"ARM templates",permalink:"/tags/arm-templates"}],readingTime:2.68,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"hello-world-bicep",title:"Hello World Bicep",authors:"johnnyreilly",tags:["Bicep","ARM templates"],image:"./hello-world-bicep.webp",hide_table_of_contents:!1},prevItem:{title:"ts-loader goes webpack 5",permalink:"/ts-loader-goes-webpack-5"},nextItem:{title:"Bicep meet Azure Pipelines 2",permalink:"/bicep-meet-azure-pipelines-2"}},p={image:n(60703).Z,authorsImageUrls:[void 0]},u=[{value:"More than configuration",id:"more-than-configuration",level:2},{value:"From terse to verbose",id:"from-terse-to-verbose",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Bicep makes Azure Resource Management a great deal simpler than ARM templates. The selling point here is grokkability. This post takes a look at the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/bicep/pull/2011"}),'"Hello World" example recently added to the Bicep repo')," to appreciate quite what a difference it makes."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"hello world bicep",src:n(60703).Z,width:"255",height:"255"})),(0,a.kt)("h2",o({},{id:"more-than-configuration"}),"More than configuration"),(0,a.kt)("p",null,"The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/bicep/tree/187d4d2047dc83c69695ba79761f552bcb00c319/docs/examples/000/01-hello-world"}),'"Hello World"')," added to the Bicep repo by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/ChristopherGLewis"}),"Chris Lewis")," illustrates the simplest usage of Bicep:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"This bicep file takes a ",(0,a.kt)("inlineCode",{parentName:"p"},"yourName")," parameter and adds that to a ",(0,a.kt)("inlineCode",{parentName:"p"},"hello")," variable and returns the concatenated string as an ARM output.")),(0,a.kt)("p",null,"This is, when you consider it, the very essence of a computer program. Taking an input, doing some computation and providing an output. When I think about ARM templates, (and because Bicep is transpiled into ARM templates I mentally bracket the two together) I tend to think about resources being deployed. I focus on ",(0,a.kt)("em",{parentName:"p"},"configuration"),", not ",(0,a.kt)("em",{parentName:"p"},"computation")),(0,a.kt)("p",null,"This is an imperfect mental model. ARM templates can do so much more than deploy by slinging strings and numbers. Thanks to the wealth of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/template-functions"}),"template functions")," that exist they have much more power. They can do computation."),(0,a.kt)("p",null,"The Hello World example focuses just on computation."),(0,a.kt)("h2",o({},{id:"from-terse-to-verbose"}),"From terse to verbose"),(0,a.kt)("p",null,"The Hello World example is made up of two significant files:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"main.bicep")," - the bicep code"),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"main.json")," - the ARM template compiled from the Bicep file")),(0,a.kt)("p",null,"The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/bicep/blob/187d4d2047dc83c69695ba79761f552bcb00c319/docs/examples/000/01-hello-world/main.bicep"}),(0,a.kt)("inlineCode",{parentName:"a"},"main.bicep"))," file amounts to 3 lines of code (I have omitted the comment line):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param yourName string\nvar hello = 'Hello World! - Hi'\n\noutput helloWorld string = '${hello} ${yourName}'\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"the first line takes the ",(0,a.kt)("em",{parentName:"li"},"input")," of ",(0,a.kt)("inlineCode",{parentName:"li"},"yourName")),(0,a.kt)("li",{parentName:"ul"},"the second line declares a ",(0,a.kt)("inlineCode",{parentName:"li"},"hello")," variable"),(0,a.kt)("li",{parentName:"ul"},"the third line ",(0,a.kt)("em",{parentName:"li"},"computes")," the new value of ",(0,a.kt)("inlineCode",{parentName:"li"},"helloWorld")," based upon ",(0,a.kt)("inlineCode",{parentName:"li"},"hello")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"yourName"),", then passes it as ",(0,a.kt)("em",{parentName:"li"},"output"))),(0,a.kt)("p",null,"Gosh is it ever simple. It's easy to read and it's simple to understand. Even if you don't know Bicep, if you've experience in another language you can likely guess what's happening."),(0,a.kt)("p",null,"Let's compare this with the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/bicep/blob/187d4d2047dc83c69695ba79761f552bcb00c319/docs/examples/000/01-hello-world/main.json"}),(0,a.kt)("inlineCode",{parentName:"a"},"main.json"))," that ",(0,a.kt)("inlineCode",{parentName:"p"},"main.bicep")," is transpiled into:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",\n  "contentVersion": "1.0.0.0",\n  "metadata": {\n    "_generator": {\n      "name": "bicep",\n      "version": "dev",\n      "templateHash": "6989941473549654446"\n    }\n  },\n  "parameters": {\n    "yourName": {\n      "type": "string"\n    }\n  },\n  "functions": [],\n  "variables": {\n    "hello": "Hello World! - Hi"\n  },\n  "resources": [],\n  "outputs": {\n    "helloWorld": {\n      "type": "string",\n      "value": "[format(\'{0} {1}\', variables(\'hello\'), parameters(\'yourName\'))]"\n    }\n  }\n}\n')),(0,a.kt)("p",null,"The above ARM template expresses exactly the same thing as the Bicep alternative. But that 3 lines of logic has become 27 lines of JSON. We've lost something in the transition. Intent is no longer clear. We've gone from something easy to reason about, to something that is hard to reason about. You need to think a lot less to write the Bicep alternative and that's a ",(0,a.kt)("em",{parentName:"p"},"good")," thing."),(0,a.kt)("p",null,"I was chatting to someone recently who expressed it well by saying:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"ARM is the format that the resource providers understand, so really it\u2019s the Azure equivalent of Assembler \u2013 and I don\u2019t know anyone who enjoys coding in Assembler.")),(0,a.kt)("p",null,"This is a great example of the value that Bicep provides. If you'd like to play with the Hello World a little, why not ",(0,a.kt)("a",o({parentName:"p"},{href:"https://aka.ms/bicepdemo#eJzT1w9OzC3ISVXISM3JyVcozy/KSeEqSCxKzFWozC8t8kvMTVUoLinKzEvnKkssgqqyVVD3ADPCQcoVFXQVPDLVubjyS0sKSksgasAyUJ0g9SrVYOFaBZVqmLm16gCvlitr"}),"take it for a spin in the Bicep playground"),"."))}d.isMDXComponent=!0},55797:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"ts-loader-goes-webpack-5",title:"ts-loader goes webpack 5",authors:"johnnyreilly",tags:["webpack","ts-loader","typescript"],image:"./ts-loader-9.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/ts-loader-goes-webpack-5",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-04-20-ts-loader-goes-webpack-5/index.md",source:"@site/blog/2021-04-20-ts-loader-goes-webpack-5/index.md",title:"ts-loader goes webpack 5",description:"ts-loader has just released v9.0.0. This post goes through what this release is all about, and what it took to ship this version. For intrigue, it includes a brief scamper into my mental health along the way. Some upgrades go smoothly - this one had some hiccups. But we'll get into that.",date:"2021-04-20T00:00:00.000Z",formattedDate:"April 20, 2021",tags:[{label:"webpack",permalink:"/tags/webpack"},{label:"ts-loader",permalink:"/tags/ts-loader"},{label:"typescript",permalink:"/tags/typescript"}],readingTime:6.285,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"ts-loader-goes-webpack-5",title:"ts-loader goes webpack 5",authors:"johnnyreilly",tags:["webpack","ts-loader","typescript"],image:"./ts-loader-9.png",hide_table_of_contents:!1},prevItem:{title:"The Service Now API and TypeScript Conditional Types",permalink:"/service-now-api-and-typescript-conditional-types"},nextItem:{title:"Hello World Bicep",permalink:"/hello-world-bicep"}},p={image:n(94045).Z,authorsImageUrls:[void 0]},u=[{value:"One big pull request",id:"one-big-pull-request",level:2},{value:"What&#39;s changed",id:"whats-changed",level:2},{value:"The hole",id:"the-hole",level:2},{value:"&quot;Anybody down there?&quot;",id:"anybody-down-there",level:2},{value:"Release details",id:"release-details",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," has just released ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/releases/tag/v9.0.0"}),"v9.0.0"),". This post goes through what this release is all about, and what it took to ship this version. For intrigue, it includes a brief scamper into my mental health along the way. Some upgrades go smoothly - this one had some hiccups. But we'll get into that."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"hello world bicep",src:n(94045).Z,width:"1376",height:"510"})),(0,a.kt)("h2",o({},{id:"one-big-pull-request"}),"One big pull request"),(0,a.kt)("p",null,"As of v8, ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," supported webpack 4 and webpack 5. However the webpack 5 support was best efforts, and not protected by any automated tests. ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," has two test packs:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"A ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/TypeStrong/ts-loader/tree/main/test/comparison-tests#readme"}),"comparison test pack")," that compares transpilation and webpack compilation output with known outputs."),(0,a.kt)("li",{parentName:"ol"},"An ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/TypeStrong/ts-loader/tree/main/test/execution-tests#readme"}),"execution test pack")," that executes Karma test packs written in TypeScript using ",(0,a.kt)("inlineCode",{parentName:"li"},"ts-loader"),".")),(0,a.kt)("p",null,"The test packs were tightly coupled to webpack 4 (and in the case of the comparison test pack, that's unavoidable). The mission was to port ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," to be built against (and have an automated test pack that ran against) webpack 5."),(0,a.kt)("p",null,"This ended up being a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/1251"}),"very big pull request"),". Work on it started back in February 2021 and we're shipping now in April of 2021. I'd initially expected it would take a couple of days at most. I had underestimated."),(0,a.kt)("p",null,"A number of people collaborated on this PR, either with code, feedback, testing or even just responding to questions. So I'd like to say thank you to:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/JonWallsten"}),"John Wallsten")," - who did a lot of the work swapping ",(0,a.kt)("inlineCode",{parentName:"li"},"ts-loader")," over to webpack 5 APIs"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/appzuka"}),"Nick Excell")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/andrewbranch"}),"Andrew Branch")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/alexander-akait"}),"Alexander Akait")," - who provided webpack 5 expertise and ideas"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/sokra"}),"Tobias Koppers")," - who got me out of a hole - more on that later")),(0,a.kt)("h2",o({},{id:"whats-changed"}),"What's changed"),(0,a.kt)("p",null,"Let's go through what's different in v9. There's two breaking changes:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"The minimum webpack version supported is now webpack 5. This simplifies the codebase, which previously had to if/else the various API registrations based on the version of webpack being used."),(0,a.kt)("li",{parentName:"ul"},"The minimum node version supported is now node 12. ",(0,a.kt)("a",o({parentName:"li"},{href:"https://nodejs.org/en/about/releases/"}),"Node 10 reaches end of life status at the end of April 2021."))),(0,a.kt)("p",null,"An interesting aspect of migrating to building against webpack 5 was dropping the dependency upon ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/@types/webpack"}),(0,a.kt)("inlineCode",{parentName:"a"},"@types/webpack"))," in favour of the types that now ship with webpack 5 itself. This was a mostly great experience; however we discovered some missing pieces."),(0,a.kt)("p",null,"Most notably, the ",(0,a.kt)("inlineCode",{parentName:"p"},"LoaderContext")," ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/webpack/blob/03961f33912ab6735d470b870eacff678735a9ed/lib/NormalModule.js#L424"}),"wasn't strongly typed"),". ",(0,a.kt)("inlineCode",{parentName:"p"},"LoaderContext")," is the value of ",(0,a.kt)("inlineCode",{parentName:"p"},"this")," in the context of a running loader function. So it is probably the most interesting and important type from the perspective of a loader author."),(0,a.kt)("p",null,"Historically we used our own definition which had been adapted from the one in ",(0,a.kt)("inlineCode",{parentName:"p"},"@types/webpack"),". ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/webpack/issues/13162"}),"I've looked into the possibility of a type being exposed in webpack itself.")," However, it turns out, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/webpack/pull/13164#issuecomment-821410359"}),"it's complicated - with the ",(0,a.kt)("inlineCode",{parentName:"a"},"LoaderContext")," type being effectively created across two packages"),". The type is initially created in ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack")," and then augmented later in ",(0,a.kt)("inlineCode",{parentName:"p"},"loader-runner"),", prior to being supplied to loaders. You can read more on that ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/webpack/pull/13164#issuecomment-821410359"}),"here"),"."),(0,a.kt)("p",null,"For now we've opted to stick with keeping ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/1251/commits/acbc71feed91fe14ec065dd9d31081af7a492f47"}),"an interface in ",(0,a.kt)("inlineCode",{parentName:"a"},"ts-loader"))," that models what arrives in the loader when executed. We have freshened it up somewhat, to model the webpack 5 world."),(0,a.kt)("p",null,"Alongside these changes, a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/1251/files#diff-7ae45ad102eab3b6d7e7896acd08c427a9b25b346470d7bc6507b6481575d519"}),"number of dependencies were upgraded"),"."),(0,a.kt)("h2",o({},{id:"the-hole"}),"The hole"),(0,a.kt)("p",null,"By the 19th of February most of the work was done. However, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/1251#issuecomment-781967959"}),"we were experiencing different behaviour between Linux and Windows in our comparison test pack"),"."),(0,a.kt)("p",null,"As far as I was aware, we were doing all the appropriate work to ensure ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," and our test packs worked cross platform. But we were still experiencing problems whenever we ran the test pack on Windows. I'd done no end of tweaking but nothing worked. I couldn't explain it. I couldn't fix it. I was finding that tough to deal with."),(0,a.kt)("p",null,"I really want to be transparent about the warts and all aspect of open source software development. It is like all other types of software development; sometimes things go wrong and it can be tough to work out why. Right then, I was really quite unhappy. Things weren't working code-wise and I was at a loss to say why. This is not something that I dig."),(0,a.kt)("p",null,"I also wasn't sleeping amazingly at this point. It was winter and we'd been in lockdown in the UK for three months; as the COVID-19 pandemic ground relentlessly on. I love my family dearly. I really do. With that said, having my children around whilst I attempted to work was remarkably tough. I love those guys but, woah, was it stressful."),(0,a.kt)("p",null,"I was feeling at a low ebb. And I wasn't sure what to do next. So, feeling tired and pretty fed up, I took a break."),(0,a.kt)("h2",o({},{id:"anybody-down-there"}),'"Anybody down there?"'),(0,a.kt)("p",null,"Time passed. In March ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/alexander-akait"}),"Alexander Akait")," checked in to see how things were going and volunteered to help. He also ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/1251#issuecomment-799531375"}),"suggested what turned out to be the fix"),"; namely replacing usage of ",(0,a.kt)("inlineCode",{parentName:"p"},"'\\'")," with ",(0,a.kt)("inlineCode",{parentName:"p"},"'/'")," in the assets supplied back to webpack. But crucially I implemented this wrong. Observe ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/1251/commits/4bcc5c9623acfd7ffbaf028781a8353b37243804"}),"this commit"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const assetPath = path\n  .relative(compilation.compiler.outputPath, outputFile.name)\n  // According to @alexander-akait we should always '/' https://github.com/TypeStrong/ts-loader/pull/1251#issuecomment-799606985\n  .replace(/\\//g, '/');\n")),(0,a.kt)("p",null,"If you look closely at the ",(0,a.kt)("inlineCode",{parentName:"p"},"replace")," you'll see that I'm globally replacing ",(0,a.kt)("inlineCode",{parentName:"p"},"'/'")," with ",(0,a.kt)("inlineCode",{parentName:"p"},"'/'")," ",(0,a.kt)("em",{parentName:"p"},"rather")," than globally replacing ",(0,a.kt)("inlineCode",{parentName:"p"},"'\\'")," with ",(0,a.kt)("inlineCode",{parentName:"p"},"'/'"),". The wasted time this caused... I could weep."),(0,a.kt)("p",null,"I generally thrashed around for a bit after this. Going in circles, like a six year old swimming wearing one armband. Then ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/1251#issuecomment-805143890"}),"Tobias kindly volunteered to help"),". This much I've learned from a career in software: if talented people offer their assistance, grab it with both hands!"),(0,a.kt)("p",null,'I\'d been trying be as "learn in public" as possible about the issues I was facing on the pull request. The idea being, to surface the problems in a public forum where others can read and advise. And also to attempt a textual kind of ',(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Rubber_duck_debugging"}),"rubber duck debugging"),"."),(0,a.kt)("p",null,"When Tobias pitched in, I wanted to make it as easy as possible for him to help. So I wrote up ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/1251#issuecomment-805181069"}),"a full description of what had changed"),". What the divergent behaviour in test packs looked like. I shared my speculation for what might be causing the issue (I was wrong by the way). Finally I provided a simple way to get up and running with the broken code. The easier I could make it for others to collaborate on this, I figured, the greater the likelihood of an answer. Tobias got to an answer quickly:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"The problem is introduced due to some normalization logic in the test case: see ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/1273"}),"#1273")),(0,a.kt)("p",{parentName:"blockquote"},"While the PR fixes the problem, I think the paths should be normalized earlier in the pipeline to make this normalization code unnecessary. Note that asset names should have only ",(0,a.kt)("inlineCode",{parentName:"p"},"/")," as they are filenames and not paths. Only absolute paths have ",(0,a.kt)("inlineCode",{parentName:"p"},"\\"),".")),(0,a.kt)("p",null,"Tobias had raised a PR which introduced a workaround to resolved things in the test pack. This made me happy. More than that, he also identified that the issue lay in ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," itself. This caused me to look again at the changes I'd made, including my ",(0,a.kt)("inlineCode",{parentName:"p"},"replace")," addition. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/1251#issuecomment-805907212"}),"With fresh eyes, I now realised this was a bug"),", and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/pull/1251/commits/427714e43519289bb5745ca078133d1ace8fc2c1"}),"fixed")," it."),(0,a.kt)("p",null,"I found then that I could revert Tobias' workaround and still have passing tests. Result!"),(0,a.kt)("h2",o({},{id:"release-details"}),"Release details"),(0,a.kt)("p",null,"Now that we've got there; we've shipped. You can get the latest version of ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/ts-loader/v/9.0.0"}),"npm")," and you can find the release details on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader/releases/tag/v9.0.0"}),"GitHub"),"."),(0,a.kt)("p",null,"Thanks everyone - I couldn't have done it without your help. \ud83c\udf3b\u2764\ufe0f"))}d.isMDXComponent=!0},53640:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"service-now-api-and-typescript-conditional-types",title:"The Service Now API and TypeScript Conditional Types",authors:"johnnyreilly",tags:["Service Now","typescript"],image:"./ts-ervice-now.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/service-now-api-and-typescript-conditional-types",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-04-24-service-now-api-and-typescript-conditional-types/index.md",source:"@site/blog/2021-04-24-service-now-api-and-typescript-conditional-types/index.md",title:"The Service Now API and TypeScript Conditional Types",description:"The Service Now REST API is an API which allows you to interact with Service Now. It produces different shaped results based upon the sysparmdisplayvalue query parameter. This post looks at how we can model these API results with TypeScripts conditional types. The aim being to minimise repetition whilst remaining strongly typed. This post is specifically about the Service Now API, but the principles around conditional type usage are generally applicable.",date:"2021-04-24T00:00:00.000Z",formattedDate:"April 24, 2021",tags:[{label:"Service Now",permalink:"/tags/service-now"},{label:"typescript",permalink:"/tags/typescript"}],readingTime:7.755,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"service-now-api-and-typescript-conditional-types",title:"The Service Now API and TypeScript Conditional Types",authors:"johnnyreilly",tags:["Service Now","typescript"],image:"./ts-ervice-now.png",hide_table_of_contents:!1},prevItem:{title:"Blog Archive for Docusaurus",permalink:"/blog-archive-for-docusaurus"},nextItem:{title:"ts-loader goes webpack 5",permalink:"/ts-loader-goes-webpack-5"}},p={image:n(31527).Z,authorsImageUrls:[void 0]},u=[{value:"The power of a query parameter",id:"the-power-of-a-query-parameter",level:2},{value:"Type Definition time",id:"type-definition-time",level:2},{value:"Making a <code>PropertyValue</code> type",id:"making-a-propertyvalue-type",level:2},{value:"Service Now Change Request States",id:"service-now-change-request-states",level:2},{value:"Making a <code>LinkValue</code> type",id:"making-a-linkvalue-type",level:2},{value:"Making our complete type",id:"making-our-complete-type",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.servicenow.com/bundle/paris-application-development/page/build/applications/concept/api-rest.html"}),"Service Now REST API")," is an API which allows you to interact with Service Now. It produces different shaped results based upon the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.servicenow.com/bundle/paris-application-development/page/integrate/inbound-rest/concept/c_TableAPI.html#c_TableAPI__table-GET"}),(0,a.kt)("inlineCode",{parentName:"a"},"sysparm_display_value")," query parameter"),". This post looks at how we can model these API results with TypeScripts conditional types. The aim being to minimise repetition whilst remaining strongly typed. This post is specifically about the Service Now API, but the principles around conditional type usage are generally applicable."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"Service Now and TypeScript",src:n(31527).Z,width:"535",height:"76"})),(0,a.kt)("h2",o({},{id:"the-power-of-a-query-parameter"}),"The power of a query parameter"),(0,a.kt)("p",null,"There is a query parameter which many endpoints in Service Nows Table API support named ",(0,a.kt)("inlineCode",{parentName:"p"},"sysparm_display_value"),". The docs describe it thus:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Data retrieval operation for reference and choice fields.\nBased on this value, retrieves the display value and/or the actual value from the database."),(0,a.kt)("p",{parentName:"blockquote"},"Valid values:"),(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"true"),": Returns the display values for all fields."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"false"),": Returns the actual values from the database."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"all"),": Returns both actual and display value"))),(0,a.kt)("p",null,"Let's see what that looks like when it comes to loading a Change Request. Consider the following curls:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"# sysparm_display_value=all\ncurl \"https://ourcompanyinstance.service-now.com/api/now/table/change_request?sysparm_query=number=CHG0122585&sysparm_limit=1&sysparm_display_value=all\" --request GET --header \"Accept:application/json\" --user 'API_USERNAME':'API_PASSWORD' | jq '.result[0] | { state, sys_id, number, requested_by, reason }'\n\n# sysparm_display_value=true\ncurl \"https://ourcompanyinstance.service-now.com/api/now/table/change_request?sysparm_query=number=CHG0122585&sysparm_limit=1&sysparm_display_value=true\" --request GET --header \"Accept:application/json\" --user 'API_USERNAME':'API_PASSWORD' | jq '.result[0] | { state, sys_id, number, requested_by, reason }'\n\n# sysparm_display_value=false\ncurl \"https://ourcompanyinstance.service-now.com/api/now/table/change_request?sysparm_query=number=CHG0122585&sysparm_limit=1&sysparm_display_value=false\" --request GET --header \"Accept:application/json\" --user 'API_USERNAME':'API_PASSWORD' | jq '.result[0] | { state, sys_id, number, requested_by, reason }'\n")),(0,a.kt)("p",null,"When executed, they each load the same Change Request from Service Now with a different value for ",(0,a.kt)("inlineCode",{parentName:"p"},"sysparm_display_value"),". You'll notice there's some ",(0,a.kt)("a",o({parentName:"p"},{href:"https://stedolan.github.io/jq/"}),(0,a.kt)("inlineCode",{parentName:"a"},"jq"))," in the mix as well. This is because there's a ",(0,a.kt)("em",{parentName:"p"},"lot")," of data in a Change Request. Rather than display everything, we're displaying a subset of fields. The first curl has a ",(0,a.kt)("inlineCode",{parentName:"p"},"sysparm_display_value")," value of ",(0,a.kt)("inlineCode",{parentName:"p"},"all"),", the second ",(0,a.kt)("inlineCode",{parentName:"p"},"false")," and the third ",(0,a.kt)("inlineCode",{parentName:"p"},"true"),". What do the results look like?"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"sysparm_display_value=all"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "state": {\n    "display_value": "Closed",\n    "value": "3"\n  },\n  "sys_id": {\n    "display_value": "4d54d7481b37e010d315cbb5464bcb95",\n    "value": "4d54d7481b37e010d315cbb5464bcb95"\n  },\n  "number": {\n    "display_value": "CHG0122595",\n    "value": "CHG0122595"\n  },\n  "requested_by": {\n    "display_value": "Sally Omer",\n    "link": "https://ourcompanyinstance.service-now.com/api/now/table/sys_user/b15cf3ebdbe11300f196f3651d961999",\n    "value": "b15cf3ebdbe11300f196f3651d961999"\n  },\n  "reason": {\n    "display_value": null,\n    "value": ""\n  }\n}\n')),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"sysparm_display_value=true"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "state": "Closed",\n  "sys_id": "4d54d7481b37e010d315cbb5464bcb95",\n  "number": "CHG0122595",\n  "requested_by": {\n    "display_value": "Sally Omer",\n    "link": "https://ourcompanyinstance.service-now.com/api/now/table/sys_user/b15cf3ebdbe11300f196f3651d961999"\n  },\n  "reason": null\n}\n')),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"sysparm_display_value=false"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "state": "3",\n  "sys_id": "4d54d7481b37e010d315cbb5464bcb95",\n  "number": "CHG0122595",\n  "requested_by": {\n    "link": "https://ourcompanyinstance.service-now.com/api/now/table/sys_user/b15cf3ebdbe11300f196f3651d961999",\n    "value": "b15cf3ebdbe11300f196f3651d961999"\n  },\n  "reason": ""\n}\n')),(0,a.kt)("p",null,"As you can see, we have the same properties being returned each time, but with a different shape. Let's call out some interesting highlights:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"requested_by")," is ",(0,a.kt)("em",{parentName:"li"},"always")," an object which contains ",(0,a.kt)("inlineCode",{parentName:"li"},"link"),". It may also contain ",(0,a.kt)("inlineCode",{parentName:"li"},"value")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"display_value")," depending upon ",(0,a.kt)("inlineCode",{parentName:"li"},"sysparm_display_value")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"state"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"sys_id"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"number")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"reason")," are objects containing ",(0,a.kt)("inlineCode",{parentName:"li"},"value")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"display_value")," when ",(0,a.kt)("inlineCode",{parentName:"li"},"sysparm_display_value")," is ",(0,a.kt)("inlineCode",{parentName:"li"},"all"),". Otherwise, the value of ",(0,a.kt)("inlineCode",{parentName:"li"},"value")," or ",(0,a.kt)("inlineCode",{parentName:"li"},"display_value")," is surfaced up directly; not in an object."),(0,a.kt)("li",{parentName:"ul"},"most values are strings, even if they represent another data type. So ",(0,a.kt)("inlineCode",{parentName:"li"},"state.value")," is always a stringified number. The only exception to this rule is ",(0,a.kt)("inlineCode",{parentName:"li"},"reason.display_value")," which can be ",(0,a.kt)("inlineCode",{parentName:"li"},"null"))),(0,a.kt)("h2",o({},{id:"type-definition-time"}),"Type Definition time"),(0,a.kt)("p",null,"We want to create type definitions for these API results. We could of course create three different results, but that would involve duplication. Boo! It's worth bearing in mind we're looking at a subset of five properties in this example. In reality, there are many, many properties on a Change Request. Whilst this example is for a subset, if we wanted to go on to create the full type definition the duplication would become very impractical."),(0,a.kt)("p",null,"What can we do? Well, if all of the underlying properties were of the same type, we could use a generic and be done. But given the underlying types can vary, that's not going to work. We can achieve this though through using a combination of generics and conditional types."),(0,a.kt)("p",null,"Let's begin by creating a string literal type of the possible values of ",(0,a.kt)("inlineCode",{parentName:"p"},"sysparm_display_value"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export type DisplayValue = 'all' | 'true' | 'false';\n")),(0,a.kt)("h2",o({},{id:"making-a-propertyvalue-type"}),"Making a ",(0,a.kt)("inlineCode",{parentName:"h2"},"PropertyValue")," type"),(0,a.kt)("p",null,"Next we need to create a type that models the object with ",(0,a.kt)("inlineCode",{parentName:"p"},"display_value")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"value")," properties."),(0,a.kt)("admonition",o({},{title:"a type for state, sys_id, number and reason",type:"info"}),(0,a.kt)("ul",{parentName:"admonition"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"state"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"sys_id"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"number")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"reason")," are objects containing ",(0,a.kt)("inlineCode",{parentName:"li"},"value")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"display_value")," when ",(0,a.kt)("inlineCode",{parentName:"li"},"sysparm_display_value")," is ",(0,a.kt)("inlineCode",{parentName:"li"},"'all'"),". Otherwise, the value of ",(0,a.kt)("inlineCode",{parentName:"li"},"value")," or ",(0,a.kt)("inlineCode",{parentName:"li"},"display")," is surfaced up directly; not in an object."),(0,a.kt)("li",{parentName:"ul"},"most values are strings, even if they represent another data type. So ",(0,a.kt)("inlineCode",{parentName:"li"},"state.value")," is always a stringified number. The only exception to this rule is ",(0,a.kt)("inlineCode",{parentName:"li"},"reason.display_value")," which can be ",(0,a.kt)("inlineCode",{parentName:"li"},"null")))),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export interface ValueAndDisplayValue<TValue = string, TDisplayValue = string> {\n  display_value: TDisplayValue;\n  value: TValue;\n}\n")),(0,a.kt)("p",null,"Note that this is a generic property with a default type of ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," for both ",(0,a.kt)("inlineCode",{parentName:"p"},"display_value")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"value"),". Most of the time, ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," is the type in question so it's great that TypeScript allows us to cut down on the amount of syntax we use."),(0,a.kt)("p",null,"Now we're going to create our first conditional type:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export type PropertyValue<\n  TAllTrueFalse extends DisplayValue,\n  TValue = string,\n  TDisplayValue = string\n> = TAllTrueFalse extends 'all'\n  ? ValueAndDisplayValue<TValue, TDisplayValue>\n  : TAllTrueFalse extends 'true'\n  ? TDisplayValue\n  : TValue;\n")),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"PropertyValue")," will either be a ",(0,a.kt)("inlineCode",{parentName:"p"},"ValueAndDisplayValue"),", a ",(0,a.kt)("inlineCode",{parentName:"p"},"TDisplayValue")," or a ",(0,a.kt)("inlineCode",{parentName:"p"},"TValue"),", depending upon whether ",(0,a.kt)("inlineCode",{parentName:"p"},"PropertyValue")," is ",(0,a.kt)("inlineCode",{parentName:"p"},"'all'"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"'true'")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"'false'")," respectively. That's hard to grok. Let's look at an example of each of those cases using the ",(0,a.kt)("inlineCode",{parentName:"p"},"reason")," property, which allows a ",(0,a.kt)("inlineCode",{parentName:"p"},"TValue")," of ",(0,a.kt)("inlineCode",{parentName:"p"},"string")," and a ",(0,a.kt)("inlineCode",{parentName:"p"},"TDisplayValue")," of ",(0,a.kt)("inlineCode",{parentName:"p"},"string | null"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const reasonAll: PropertyValue<'all', string, string | null> = {\n  display_value: null,\n  value: '',\n};\nconst reasonTrue: PropertyValue<'true', string, string | null> = null;\nconst reasonFalse: PropertyValue<'false', string, string | null> = '';\n")),(0,a.kt)("p",null,"Consider the type on the left and the value on the right. We're successfully modelling our ",(0,a.kt)("inlineCode",{parentName:"p"},"PropertyValue"),"s. I've deliberately picked an edge case example to push our conditional type to its limits."),(0,a.kt)("h2",o({},{id:"service-now-change-request-states"}),"Service Now Change Request States"),(0,a.kt)("p",null,"Let's look at another usage. We'll create a type that repesents the possible values of a Change Request's ",(0,a.kt)("inlineCode",{parentName:"p"},"state")," in Service Now. Do take a moment to appreciate these values. Many engineers were lost in the numerous missions to obtain these rare and secret enums. Alas, the Service Now API docs have some significant gaps."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"/** represents the possible Change Request \"State\" values in Service Now */\nexport const STATE = {\n  NEW: '-5',\n  ASSESS: '-4',\n  SENT_FOR_APPROVAL: '-3',\n  SCHEDULED: '-2',\n  APPROVED: '-1',\n  WAITING: '1',\n  IN_PROGRESS: '2',\n  COMPLETE: '3',\n  ERROR: '4',\n  CLOSED: '7',\n} as const;\n\nexport type State = typeof STATE[keyof typeof STATE];\n")),(0,a.kt)("p",null,"By combining ",(0,a.kt)("inlineCode",{parentName:"p"},"State")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"PropertyValue"),", we can strongly type the ",(0,a.kt)("inlineCode",{parentName:"p"},"state")," property of Change Requests. Consider:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const stateAll: PropertyValue<'all', State> = {\n  display_value: 'Closed',\n  value: '3',\n};\nconst stateTrue: PropertyValue<'true', State> = 'Closed';\nconst stateFalse: PropertyValue<'false', State> = '3';\n")),(0,a.kt)("p",null,"With that in place, let's turn our attention to our other natural type that the ",(0,a.kt)("inlineCode",{parentName:"p"},"requested_by")," property demonstrates."),(0,a.kt)("h2",o({},{id:"making-a-linkvalue-type"}),"Making a ",(0,a.kt)("inlineCode",{parentName:"h2"},"LinkValue")," type"),(0,a.kt)("admonition",o({},{title:"a type for requested_by",type:"info"}),(0,a.kt)("p",{parentName:"admonition"},(0,a.kt)("inlineCode",{parentName:"p"},"requested_by")," is ",(0,a.kt)("em",{parentName:"p"},"always")," an object which contains ",(0,a.kt)("inlineCode",{parentName:"p"},"link"),". It may also contain ",(0,a.kt)("inlineCode",{parentName:"p"},"value")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"display_value")," depending upon ",(0,a.kt)("inlineCode",{parentName:"p"},"sysparm_display_value"))),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"interface Link {\n  link: string;\n}\n\n/** when TAllTrueFalse is 'false' */\nexport interface LinkAndValue extends Link {\n  value: string;\n}\n\n/** when TAllTrueFalse is 'true' */\nexport interface LinkAndDisplayValue extends Link {\n  display_value: string;\n}\n\n/** when TAllTrueFalse is 'all' */\nexport interface LinkValueAndDisplayValue\n  extends LinkAndValue,\n    LinkAndDisplayValue {}\n")),(0,a.kt)("p",null,"The three types above model the different scenarios. Now we need a conditional type to make use of them:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export type LinkValue<TAllTrueFalse extends DisplayValue> =\n  TAllTrueFalse extends 'all'\n    ? LinkValueAndDisplayValue\n    : TAllTrueFalse extends 'true'\n    ? LinkAndDisplayValue\n    : LinkAndValue;\n")),(0,a.kt)("p",null,"This is hopefully simpler to read than the ",(0,a.kt)("inlineCode",{parentName:"p"},"PropertyValue")," type, and if you look at the examples below you can see what usage looks like:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const requested_byAll: LinkValue<'all'> = {\n  display_value: 'Sally Omer',\n  link: 'https://ourcompanyinstance.service-now.com/api/now/table/sys_user/b15cf3ebdbe11300f196f3651d961999',\n  value: 'b15cf3ebdbe11300f196f3651d961999',\n};\nconst requested_byTrue: LinkValue<'true'> = {\n  display_value: 'Sally Omer',\n  link: 'https://ourcompanyinstance.service-now.com/api/now/table/sys_user/b15cf3ebdbe11300f196f3651d961999',\n};\nconst requested_byFalse: LinkValue<'false'> = {\n  link: 'https://ourcompanyinstance.service-now.com/api/now/table/sys_user/b15cf3ebdbe11300f196f3651d961999',\n  value: 'b15cf3ebdbe11300f196f3651d961999',\n};\n")),(0,a.kt)("h2",o({},{id:"making-our-complete-type"}),"Making our complete type"),(0,a.kt)("p",null,"With these primitives in place, we can now build ourself a (cut-down) type that models a Change Request:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export interface ServiceNowChangeRequest<TAllTrueFalse extends DisplayValue> {\n  state: PropertyValue<TAllTrueFalse, State>;\n  sys_id: PropertyValue<TAllTrueFalse>;\n  number: PropertyValue<TAllTrueFalse>;\n  requested_by: LinkValue<TAllTrueFalse>;\n  reason: PropertyValue<TAllTrueFalse, string, string | null>;\n  // there are *way* more properties in reality\n}\n")),(0,a.kt)("p",null,"This is a generic type which will accept ",(0,a.kt)("inlineCode",{parentName:"p"},"'all'"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"'true'")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"'false'")," and will use that type to drive the type of the properties ",(0,a.kt)("em",{parentName:"p"},"inside")," the object. And now we have successfully typed our Service Now Change Request, thanks to TypeScript's conditional types."),(0,a.kt)("p",null,"To test it out, let's take the JSON responses we got back from our curls at the start, and see if we can make ",(0,a.kt)("inlineCode",{parentName:"p"},"ServiceNowChangeRequest"),"s with them."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const changeRequestFalse: ServiceNowChangeRequest<'false'> = {\n  state: '3',\n  sys_id: '4d54d7481b37e010d315cbb5464bcb95',\n  number: 'CHG0122595',\n  requested_by: {\n    link: 'https://ourcompanyinstance.service-now.com/api/now/table/sys_user/b15cf3ebdbe11300f196f3651d961999',\n    value: 'b15cf3ebdbe11300f196f3651d961999',\n  },\n  reason: '',\n};\n\nconst changeRequestTrue: ServiceNowChangeRequest<'true'> = {\n  state: 'Closed',\n  sys_id: '4d54d7481b37e010d315cbb5464bcb95',\n  number: 'CHG0122595',\n  requested_by: {\n    display_value: 'Sally Omer',\n    link: 'https://ourcompanyinstance.service-now.com/api/now/table/sys_user/b15cf3ebdbe11300f196f3651d961999',\n  },\n  reason: null,\n};\n\nconst changeRequestAll: ServiceNowChangeRequest<'all'> = {\n  state: {\n    display_value: 'Closed',\n    value: '3',\n  },\n  sys_id: {\n    display_value: '4d54d7481b37e010d315cbb5464bcb95',\n    value: '4d54d7481b37e010d315cbb5464bcb95',\n  },\n  number: {\n    display_value: 'CHG0122595',\n    value: 'CHG0122595',\n  },\n  requested_by: {\n    display_value: 'Sally Omer',\n    link: 'https://ourcompanyinstance.service-now.com/api/now/table/sys_user/b15cf3ebdbe11300f196f3651d961999',\n    value: 'b15cf3ebdbe11300f196f3651d961999',\n  },\n  reason: {\n    display_value: null,\n    value: '',\n  },\n};\n")),(0,a.kt)("p",null,"We can! Do take a look at this in the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/play?#code/KYDwDg9gTgLgBDAnmYcAiBLAzmANgQ0QDV9cBXVAXjgHJTca4AfWmKCxlmgM1K2BoBuAFDDQkWHAwA7GMCi8AxqhLlgAQWkATTDgLFSFADwAVVRTjUsbGQHMANHBO68hc1TjWodgHxwA3sJwwXBa2K6IAPoAbobAAFxOLvruIiFwsWqJZnEiAL6i4tDwSChwAApQECiwBmpGQSEm6ri4JuzAAGJ8qKBy2ljo4Slx9o3BOWqWnjbSDuNJw25x0152wn7Uza3tFN24-HB9wAO09DQLAPxw7po6S3XGkxSOzg-uPgvZLW0d+4fHU40NgcK6LPTLNRfJypUSKCDSaxwKDAfBYBE-RKVaryJDuIx0Vo0RxrOYk2a2ZhwaRkVqbAILABEYQhUUyFEZiRprTG6UZ7OAnLgjMZwgK8MR8BRaIRuwSFSqNTxcQJIIE5O8ZJmmspLG5uHp+pEEqR0vR0n+8uxSsewAJvAO6u1dg1dip+vpNCEogA9AAqP3I4BgFH8WSDGAAC1QkCwWAwACNcKgAMKR-BzVAAJWAAEcKEjGQBlGD4OSMjJxQYyOBF+TRDDKOAAOQgAHc4H6fWJwMU4Cb4EXmiYAKLTQLpZsjgDqiRoAFoAKzEhbqItFkfrufzgAsK-SG+bJkinQA8lnIupyuUs6eiOoADLbgDM+5CRZTAAkR2gAKoPn9twAJjfYIrxvO9ANoecAEZQLgad1AASRMJDmwAcTnODeRCNDIgg9Cs03Is5xAnDghTU8AFlygA0c51fci4BHLNbyzOc9yYlMH1PDc0DnAB2Fc8jgNF+wRawRB7CQSmQVASzLDxSmACBuFrYcRwAbQAa2ARBVIQOSDKHdRRwAXSkgcZkUzEFRxWp8UJBhHAUuR6QnEJmQeGI4iFRkU1wCB+C0RkmP5XzEkZZ9RTyY0JPgaxFLlLFFVxW1VQ6Yla1LNzpn8wLgsZOLJWsuRLRS+zlXqHgeiy1zgHpKKitEGQ5AUfAmwfGRtIZdJcG6xJSVsfJfQDOA22jaQnB+OVLSkQYasdRgu2kvtWvkJRUC66RtLudwjhAfotEGbaeo84IBUGikRuEf1Awmk5pp2P4enm1hMs7bsikkdb2s67q7mSSELEBY64FO3qQhZCIfKyZ05huu7xsmp7fj2V7sDOIlPtWn7ZA2jqtu625tCB20DqOk6Ae0dxHFOwH3hWfwClx2SylO-FtjRrpXtBwYyY+aYudm3nDpOMGnIudJrg5uIGdZdxoWFl7HQp8WFrVKWQhl6n7gVuJoXpmncjheKg3zYBrGALRIgTRBbNl6rzncplof0WGOUiloMFrCAAFt5FCpl+p2vzIxgGAwCweIfR9GRoktuRFES2w7AAOn4KAG2UedpHbNP4T9n18DADAfTztsfVLJNgB9LBECwSIyEzn0ExgxdFG4Z9gATLQE2AGCYOfAAGYfuBggBOAA2Lup8XGCtGnyeJ-wIO+QFPy247rue77geh9H8fp9n+fF6n5fV7FYrTTzAs5Btu3kvB4mVWBTKXb5N3CA9wUvf632A5QDXp5EO2kw4RyjjHOO0gE5W2TqWVOcwM71kbMAXO+dC7F1LuXdsVd8A1zrg3JuLct6d27r3fug8R5j0njPZ8c8F5LwnivGKwgrIogtlbB+iByrPx2o5B0-AaAfxAd1cBkdo6x3jonYA8D8CINsMgrOqD0FtgLv7LBZcK54IIfXRuzd5Ct3bmQ3elCD40OPvQ0+TCWFhQ3pFUhO8KH72oUfOhDCz4XxilJb68BfqbVrCg5QrY2xpgzLYYAOZOEwFMDNFWAIxanAFnEPw51SpWlSg5FUyt0aOhcjlBqaQQh6MiBgLQFUbSczibk-gPginBBpH7fuUAKlpSqc9GphSFgcLvtbW2iBEiOyeNUnmjo6ndNROaVpWT6g5NGfwV0WohrulpAaG6VlFDpkzFEu+vC6zKOCe2MJ2zb6J3tLVERjJErlkitFHCVyiFlL8juLQi4XkCR3AADhggmZ8AlgDDxgsPLQz5jEJgTG8qeO4EyKATJ8xcwDGSNOaX5L86FAVASAoueFiKekyO4UKNJjJQHiMgVImBMi5EKKUdnNBFd1FFxLlo3B1dkyEP0SQ4xTi95UMPrQk+jDz7MNXnYiKwpHHkJ5eYtxArPHCtFMEPI9yzQIj8t402JVNnhMiac6wT99m0pCcciJOyzlvw4Jc65v9hQBSCtbRFJSnmRReW8rQHzvm-P+YC4FoKO7gshdC2FOL7nIsDpFNFGKsXBsaIyPFXD+mEtdt5exwpvYAMDmFElkVw4SKgdIuBKd06Z1paohlmicGV1ZbXEpBioBGO3pKsxrj+VWMFV4xoSqY0qukEKfUYoNVIi1Sc6JtkDWoKNVsk1uqYmS3pMIDyVyCmJs-smsV+U7UhVFWoPy0UO33MdSFRIRKv5sjXS695Xyfl-IBUCkFYKIU7ihTCuFCKt2e2FOet1l7PU3p9fegNz6cV7pjaGoBR6k2sh-qiz86KYKYuxa+pkKb-IwcjQhhVcBO3BFjdOvpdtl2eRPVBv+Psiz+wzcHMR2aIGSOgbApOhakHFpUfSzBTKK06LZTWzlDbTEuL5ZYjxNiRVIbXRKvjvKLHuOsUKlhwHsPdoI9hojKb9RvutSKDtYogA"}),"TypeScript playground"),"."))}d.isMDXComponent=!0},59778:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"blog-archive-for-docusaurus",title:"Blog Archive for Docusaurus",authors:"johnnyreilly",tags:["Docusaurus","webpack"],image:"./docusaurus-blog-archive.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/blog-archive-for-docusaurus",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-05-01-blog-archive-for-docusaurus/index.md",source:"@site/blog/2021-05-01-blog-archive-for-docusaurus/index.md",title:"Blog Archive for Docusaurus",description:'Docusaurus doesn\'t ship with "blog archive" functionality. By which I mean, something that allows you to look at an overview of your historic blog posts. It turns out it is fairly straightforward to implement your own. This post does just that.',date:"2021-05-01T00:00:00.000Z",formattedDate:"May 1, 2021",tags:[{label:"Docusaurus",permalink:"/tags/docusaurus"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:5.395,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"blog-archive-for-docusaurus",title:"Blog Archive for Docusaurus",authors:"johnnyreilly",tags:["Docusaurus","webpack"],image:"./docusaurus-blog-archive.png",hide_table_of_contents:!1},prevItem:{title:"Create a Pipeline with the Azure DevOps API",permalink:"/create-pipeline-with-azure-devops-api"},nextItem:{title:"The Service Now API and TypeScript Conditional Types",permalink:"/service-now-api-and-typescript-conditional-types"}},p={image:n(72567).Z,authorsImageUrls:[void 0]},u=[{value:"Updated 2021-09-01",id:"updated-2021-09-01",level:2},{value:"Blogger&#39;s blog archive",id:"bloggers-blog-archive",level:2},{value:"Handrolling a Docusaurus blog archive",id:"handrolling-a-docusaurus-blog-archive",level:2},{value:"Obtaining the blog data",id:"obtaining-the-blog-data",level:2},{value:"Presenting it",id:"presenting-it",level:2},{value:"Bringing it all together",id:"bringing-it-all-together",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'Docusaurus doesn\'t ship with "blog archive" functionality. By which I mean, something that allows you to look at an overview of your historic blog posts. It turns out it is fairly straightforward to implement your own. This post does just that.'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"Docusaurus blog archive",src:n(72567).Z,width:"3014",height:"1226"})),(0,a.kt)("h2",o({},{id:"updated-2021-09-01"}),"Updated 2021-09-01"),(0,a.kt)("p",null,"As of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/releases/tag/v2.0.0-beta.6"}),"v2.0.0-beta.6"),", Docusauras ",(0,a.kt)("em",{parentName:"p"},"does")," ship with blog archive functionality that lives at the ",(0,a.kt)("inlineCode",{parentName:"p"},"archive")," route. This is down to the work of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/gabrielcsapo"}),"Gabriel Csapo")," in ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/pull/5428"}),"this PR"),"."),(0,a.kt)("p",null,"If you'd like to know how to build your own, read on... But you may not need to!"),(0,a.kt)("h2",o({},{id:"bloggers-blog-archive"}),"Blogger's blog archive"),(0,a.kt)("p",null,"I recently went through the exercise of ",(0,a.kt)("a",o({parentName:"p"},{href:"/definitive-guide-to-migrating-from-blogger-to-docusaurus"}),"migrating my blog from Blogger to Docusaurus"),". I found that ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/"}),"Docusaurus")," was a tremendous platform upon which to build a blog, but it was missing a feature from Blogger that I valued highly; the blog archive:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Blogger blog archive",src:n(84011).Z,width:"283",height:"545"})),(0,a.kt)("p",null,"The blog archive is a way by which you can browse through your historic blog posts. A place where you can see all that you've written and when. I find this very helpful. I didn't really want to make the jump without having something like that around."),(0,a.kt)("h2",o({},{id:"handrolling-a-docusaurus-blog-archive"}),"Handrolling a Docusaurus blog archive"),(0,a.kt)("p",null,"Let's create our own blog archive in the land of the Docusaurus."),(0,a.kt)("p",null,"We'll create a new page under the ",(0,a.kt)("inlineCode",{parentName:"p"},"pages")," directory called ",(0,a.kt)("inlineCode",{parentName:"p"},"blog-archive.js")," and we'll add a link to it in our ",(0,a.kt)("inlineCode",{parentName:"p"},"docusaurus.config.js"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'    navbar: {\n      // ...\n      items: [\n        // ...\n        { to: "blog-archive", label: "Blog Archive", position: "left" },\n        // ...\n      ],\n    },\n')),(0,a.kt)("h2",o({},{id:"obtaining-the-blog-data"}),"Obtaining the blog data"),(0,a.kt)("p",null,"This page will be powered by webpack's ",(0,a.kt)("a",o({parentName:"p"},{href:"https://webpack.js.org/guides/dependency-management/#requirecontext"}),(0,a.kt)("inlineCode",{parentName:"a"},"require.context"))," function. ",(0,a.kt)("inlineCode",{parentName:"p"},"require.context")," allows us to use webpack to obtain all of the blog modules:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"require.context('../../blog', false, //index.md/);\n")),(0,a.kt)("p",null,"The code snippet above looks in the ",(0,a.kt)("inlineCode",{parentName:"p"},"blog")," directory for files / modules ending with the suffix ",(0,a.kt)("inlineCode",{parentName:"p"},'"/index.md"'),". Each one of these represents a blog post. The function returns a ",(0,a.kt)("inlineCode",{parentName:"p"},"context")," object, which contains all of the data about these modules."),(0,a.kt)("p",null,"By reducing over that data we can construct an array of objects called ",(0,a.kt)("inlineCode",{parentName:"p"},"allPosts")," that could drive a blog archive screen. Let's do this below, and we'll use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/docs/handbook/jsdoc-supported-types.html"}),"TypeScripts JSDoc support")," to type our JavaScript:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),'/**\n * @typedef {Object} BlogPost - creates a new type named \'BlogPost\'\n * @property {string} date - eg "2021-04-24T00:00:00.000Z"\n * @property {string} formattedDate - eg "April 24, 2021"\n * @property {string} title - eg "The Service Now API and TypeScript Conditional Types"\n * @property {string} permalink - eg "/2021/04/24/service-now-api-and-typescript-conditional-types"\n */\n\n/** @type {BlogPost[]} */\nconst allPosts = ((ctx) => {\n  /** @type {string[]} */\n  const blogpostNames = ctx.keys();\n\n  return blogpostNames.reduce(\n    (blogposts, blogpostName, i) => {\n      const module = ctx(blogpostName);\n      const { date, formattedDate, title, permalink } = module.metadata;\n      return [\n        ...blogposts,\n        {\n          date,\n          formattedDate,\n          title,\n          permalink,\n        },\n      ];\n    },\n    /** @type {string[]}>} */ []\n  );\n})(require.context(\'../../blog\', true, /index.md/));\n')),(0,a.kt)("p",null,"Observe the ",(0,a.kt)("inlineCode",{parentName:"p"},"metadata")," property in the screenshot below:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"require.context",src:n(77347).Z,width:"2824",height:"1182"})),(0,a.kt)("p",null,"This gives us a flavour of the data available in the modules and shows how we pull out the bits that we need; ",(0,a.kt)("inlineCode",{parentName:"p"},"date"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"formattedDate"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"title")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"permalink"),"."),(0,a.kt)("h2",o({},{id:"presenting-it"}),"Presenting it"),(0,a.kt)("p",null,"Now we have our data in the form of ",(0,a.kt)("inlineCode",{parentName:"p"},"allPosts"),", let's display it. We'd like to break it up into posts by year, which we can do by reducing and looking at the ",(0,a.kt)("inlineCode",{parentName:"p"},"date")," property which is an ISO-8601 style date string taking a format that begins ",(0,a.kt)("inlineCode",{parentName:"p"},"yyyy-mm-dd"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"const postsByYear = allPosts.reduceRight((posts, post) => {\n  const year = post.date.split('-')[0];\n  const yearPosts = posts.get(year) || [];\n  return posts.set(year, [post, ...yearPosts]);\n}, /** @type {Map<string, BlogPost[]>} */ new Map());\n\nconst yearsOfPosts = Array.from(postsByYear, ([year, posts]) => ({\n  year,\n  posts,\n}));\n")),(0,a.kt)("p",null,"Now we're ready to blast it onto the screen. We'll create two components:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Year")," - which is a list of the posts for a given year and"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"BlogArchive")," - which is the overall page and maps over ",(0,a.kt)("inlineCode",{parentName:"li"},"yearsOfPosts")," to render ",(0,a.kt)("inlineCode",{parentName:"li"},"Year"),"s")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),'function Year(\n  /** @type {{ year: string; posts: BlogPost[]; }} */ { year, posts }\n) {\n  return (\n    <div className={clsx(\'col col--4\', styles.feature)}>\n      <h3>{year}</h3>\n      <ul>\n        {posts.map((post) => (\n          <li key={post.date}>\n            <Link to={post.permalink}>\n              {post.formattedDate} - {post.title}\n            </Link>\n          </li>\n        ))}\n      </ul>\n    </div>\n  );\n}\n\nfunction BlogArchive() {\n  return (\n    <Layout title="Blog Archive">\n      <header className={clsx(\'hero hero--primary\', styles.heroBanner)}>\n        <div className="container">\n          <h1 className="hero__title">Blog Archive</h1>\n          <p className="hero__subtitle">Historic posts</p>\n        </div>\n      </header>\n      <main>\n        {yearsOfPosts && yearsOfPosts.length > 0 && (\n          <section className={styles.features}>\n            <div className="container">\n              <div className="row">\n                {yearsOfPosts.map((props, idx) => (\n                  <Year key={idx} {...props} />\n                ))}\n              </div>\n            </div>\n          </section>\n        )}\n      </main>\n    </Layout>\n  );\n}\n')),(0,a.kt)("h2",o({},{id:"bringing-it-all-together"}),"Bringing it all together"),(0,a.kt)("p",null,"We're finished! We have a delightful looking blog archive plumbed into our blog:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"Docusaurus blog archive",src:n(72567).Z,width:"3014",height:"1226"})),(0,a.kt)("p",null,"It is possible that a blog archive may become natively available in Docusaurus in future. If you're interested in this, you can track ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/issues/4431"}),"this issue"),"."),(0,a.kt)("p",null,"Here's the final code - which you can see ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.johnnyreilly.com/blog-archive"}),"powering this screen"),". And you can see the code that backs it ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/blob/main/blog-website/src/pages/blog-archive.js"}),"here"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"import React from 'react';\nimport clsx from 'clsx';\nimport Layout from '@theme/Layout';\nimport Link from '@docusaurus/Link';\nimport styles from './styles.module.css';\n\n/**\n * @typedef {Object} BlogPost - creates a new type named 'BlogPost'\n * @property {string} date - eg \"2021-04-24T00:00:00.000Z\"\n * @property {string} formattedDate - eg \"April 24, 2021\"\n * @property {string} title - eg \"The Service Now API and TypeScript Conditional Types\"\n * @property {string} permalink - eg \"/2021/04/24/service-now-api-and-typescript-conditional-types\"\n */\n\n/** @type {BlogPost[]} */\nconst allPosts = ((ctx) => {\n  /** @type {string[]} */\n  const blogpostNames = ctx.keys();\n\n  return blogpostNames.reduce(\n    (blogposts, blogpostName, i) => {\n      const module = ctx(blogpostName);\n      const { date, formattedDate, title, permalink } = module.metadata;\n      return [\n        ...blogposts,\n        {\n          date,\n          formattedDate,\n          title,\n          permalink,\n        },\n      ];\n    },\n    /** @type {BlogPost[]}>} */ []\n  );\n  // @ts-ignore\n})(require.context('../../blog', true, /index.md/));\n\nconst postsByYear = allPosts.reduceRight((posts, post) => {\n  const year = post.date.split('-')[0];\n  const yearPosts = posts.get(year) || [];\n  return posts.set(year, [post, ...yearPosts]);\n}, /** @type {Map<string, BlogPost[]>} */ new Map());\n\nconst yearsOfPosts = Array.from(postsByYear, ([year, posts]) => ({\n  year,\n  posts,\n}));\n\nfunction Year(\n  /** @type {{ year: string; posts: BlogPost[]; }} */ { year, posts }\n) {\n  return (\n    <div className={clsx('col col--4', styles.feature)}>\n      <h3>{year}</h3>\n      <ul>\n        {posts.map((post) => (\n          <li key={post.date}>\n            <Link to={post.permalink}>\n              {post.formattedDate} - {post.title}\n            </Link>\n          </li>\n        ))}\n      </ul>\n    </div>\n  );\n}\n\nfunction BlogArchive() {\n  return (\n    <Layout title=\"Blog Archive\">\n      <header className={clsx('hero hero--primary', styles.heroBanner)}>\n        <div className=\"container\">\n          <h1 className=\"hero__title\">Blog Archive</h1>\n          <p className=\"hero__subtitle\">Historic posts</p>\n        </div>\n      </header>\n      <main>\n        {yearsOfPosts && yearsOfPosts.length > 0 && (\n          <section className={styles.features}>\n            <div className=\"container\">\n              <div className=\"row\">\n                {yearsOfPosts.map((props, idx) => (\n                  <Year key={idx} {...props} />\n                ))}\n              </div>\n            </div>\n          </section>\n        )}\n      </main>\n    </Layout>\n  );\n}\n\nexport default BlogArchive;\n")))}d.isMDXComponent=!0},57941:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"create-pipeline-with-azure-devops-api",title:"Create a Pipeline with the Azure DevOps API",authors:"johnnyreilly",tags:["Azure Pipelines","azure devops api"],image:"./new-pipeline.webp",hide_table_of_contents:!1},s=void 0,l={permalink:"/create-pipeline-with-azure-devops-api",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-05-08-create-pipeline-with-azure-devops-api/index.md",source:"@site/blog/2021-05-08-create-pipeline-with-azure-devops-api/index.md",title:"Create a Pipeline with the Azure DevOps API",description:"Creating an Azure Pipeline using the Azure DevOps REST API is possible, but badly documented. This post goes through how to do this.",date:"2021-05-08T00:00:00.000Z",formattedDate:"May 8, 2021",tags:[{label:"Azure Pipelines",permalink:"/tags/azure-pipelines"},{label:"azure devops api",permalink:"/tags/azure-devops-api"}],readingTime:1.75,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"create-pipeline-with-azure-devops-api",title:"Create a Pipeline with the Azure DevOps API",authors:"johnnyreilly",tags:["Azure Pipelines","azure devops api"],image:"./new-pipeline.webp",hide_table_of_contents:!1},prevItem:{title:"Azurite and Table Storage in a dev container",permalink:"/azurite-and-table-storage-dev-container"},nextItem:{title:"Blog Archive for Docusaurus",permalink:"/blog-archive-for-docusaurus"}},p={image:n(52960).Z,authorsImageUrls:[void 0]},u=[{value:"curling a pipeline",id:"curling-a-pipeline",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Creating an Azure Pipeline using the Azure DevOps REST API is possible, but badly documented. This post goes through how to do this."),(0,a.kt)("h2",o({},{id:"curling-a-pipeline"}),"curling a pipeline"),(0,a.kt)("p",null,"The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/rest/api/azure/devops/pipelines/pipelines/create?view=azure-devops-rest-6.1"}),"documentation")," for creating an Azure Pipeline using the Azure DevOps API is somewhat lacking. However it isn't actually too hard, you just need the recipe."),(0,a.kt)("p",null,"Here's a curl to make you a pipeline:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"curl  --user '':'PERSONAL_ACCESS_TOKEN' --header \"Content-Type: application/json\" --header \"Accept:application/json\" https://dev.azure.com/organisation-name/sandbox/_apis/pipelines?api-version=6.1-preview.1 -d @makepipeline.json\n")),(0,a.kt)("p",null,"Looking at the above there's two things you need:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"A personal access token. You can make one of those here: ",(0,a.kt)("a",o({parentName:"li"},{href:"https://dev.azure.com/organisation-name/_usersSettings/tokens"}),"https://dev.azure.com/organisation-name/_usersSettings/tokens")," (where ",(0,a.kt)("inlineCode",{parentName:"li"},"organisation-name")," is the name of your organisation)"),(0,a.kt)("li",{parentName:"ol"},"A ",(0,a.kt)("inlineCode",{parentName:"li"},"makepipeline.json")," file, which contains the details of the pipeline you want to create:")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "folder": null,\n  "name": "pipeline-made-by-api",\n  "configuration": {\n    "type": "yaml",\n    "path": "/azure-pipelines.yml",\n    "repository": {\n      "id": "guid-of-repo-id",\n      "name": "my-repo",\n      "type": "azureReposGit"\n    }\n  }\n}\n')),(0,a.kt)("p",null,"Let's talk through the significant properties above:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"folder")," - can be ",(0,a.kt)("inlineCode",{parentName:"li"},"null")," if you'd like the pipeline to be created in the root of Pipelines; otherwise provide the folder name. Incidentally a ",(0,a.kt)("inlineCode",{parentName:"li"},"null")," will be translated into a value of ",(0,a.kt)("inlineCode",{parentName:"li"},"\\\\")," which appears to be the magic value which represents the root."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"name")," - your pipeline needs a name"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"path")," - this is the path to the yaml pipelines file in the repo. Note we're creating the pipeline itself here; what's actually in the pipeline sits in that file."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"repository.id")," - this is the guid that represents the repo you're creating the pipeline for. You can find this out by going to your equivalent ",(0,a.kt)("a",o({parentName:"li"},{href:"https://dev.azure.com/organisation-name/project-name/_settings/repositories"}),"https://dev.azure.com/organisation-name/project-name/_settings/repositories")," (substituting in appropriate values) and looking up your repository there."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"repository.name")," - the name of your repo")),(0,a.kt)("p",null,"When you execute your curl you should be returned some JSON along these lines:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "_links": {\n    "self": {\n      "href": "https://dev.azure.com/organisation-name/2184049d-8bc4-484a-91e6-00fca6b5b19f/_apis/pipelines/975?revision=1"\n    },\n    "web": {\n      "href": "https://dev.azure.com/organisation-name/2184049d-8bc4-484a-91e6-00fca6b5b19f/_build/definition?definitionId=975"\n    }\n  },\n  "configuration": {\n    "path": "/azure-pipelines.yml",\n    "repository": {\n      "id": "9a72560d-1622-4016-93dd-32ac85b96d03",\n      "type": "azureReposGit"\n    },\n    "type": "yaml"\n  },\n  "url": "https://dev.azure.com/organisation-name/2184049d-8bc4-484a-91e6-00fca6b5b19f/_apis/pipelines/975?revision=1",\n  "id": 975,\n  "revision": 1,\n  "name": "pipeline-made-by-api",\n  "folder": "\\\\"\n}\n')),(0,a.kt)("p",null,"And inside Azure DevOps you'll now have a shiny new pipeline:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"The new pipeline",src:n(52960).Z,width:"1824",height:"720"})))}d.isMDXComponent=!0},77207:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azurite-and-table-storage-dev-container",title:"Azurite and Table Storage in a dev container",authors:"johnnyreilly",tags:["VS Code","devcontainer","Docker"],image:"./dev-container-start.gif",hide_table_of_contents:!1},s=void 0,l={permalink:"/azurite-and-table-storage-dev-container",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-05-15-azurite-and-table-storage-dev-container/index.md",source:"@site/blog/2021-05-15-azurite-and-table-storage-dev-container/index.md",title:"Azurite and Table Storage in a dev container",description:'It\'s great to be able to develop locally without needing a "real" database to connect to. Azurite is an Azure Storage emulator which exists to support just that. This post demonstrates how to run Azurite v3 in a dev container, such that you can access the Table Storage API, which is currently in preview.',date:"2021-05-15T00:00:00.000Z",formattedDate:"May 15, 2021",tags:[{label:"VS Code",permalink:"/tags/vs-code"},{label:"devcontainer",permalink:"/tags/devcontainer"},{label:"Docker",permalink:"/tags/docker"}],readingTime:6.51,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azurite-and-table-storage-dev-container",title:"Azurite and Table Storage in a dev container",authors:"johnnyreilly",tags:["VS Code","devcontainer","Docker"],image:"./dev-container-start.gif",hide_table_of_contents:!1},prevItem:{title:"Azure Functions and .NET 5: Query params, Dependency Injection, Bicep & Build",permalink:"/azure-functions-dotnet-5-query-params-di-bicep"},nextItem:{title:"Create a Pipeline with the Azure DevOps API",permalink:"/create-pipeline-with-azure-devops-api"}},p={image:n(84213).Z,authorsImageUrls:[void 0]},u=[{value:"Azurite in VS Code",id:"azurite-in-vs-code",level:2},{value:"Make a function app",id:"make-a-function-app",level:2},{value:"Can we swap out Azurite for The Real Thing\u2122\ufe0f?",id:"can-we-swap-out-azurite-for-the-real-thing\ufe0f",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'It\'s great to be able to develop locally without needing a "real" database to connect to. ',(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/Azurite"}),"Azurite")," is an Azure Storage emulator which exists to support just that. This post demonstrates how to run Azurite v3 in a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://code.visualstudio.com/docs/remote/containers"}),"dev container"),", such that you can access the Table Storage API, which is currently in preview."),(0,a.kt)("h2",o({},{id:"azurite-in-vs-code"}),"Azurite in VS Code"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/Azurite/releases/tag/v3.12.0"}),"Azurite v3.12.0")," recently shipped, and with it came:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Preview of Table Service in npm package and docker image. (Visual Studio Code extension doesn't support Table Service in this release)")),(0,a.kt)("p",null,"You'll note that whilst there's a VS Code extension for Azurite, it doesn't have support for the Table Service yet. However, we do have it available in the form of a Docker image. So whilst we may not be able to directly use the Table APIs of Azurite in VS Code, what we could do instead is use a dev container."),(0,a.kt)("p",null,"We'll start by making ourselves a new directory and open VS Code in that location:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"mkdir azurite-devcontainer\ncode azurite-devcontainer\n")),(0,a.kt)("p",null,"We're going to initialise a dev container there for function apps based upon ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/vscode-dev-containers/tree/master/containers/azure-functions-dotnetcore-3.1"}),"the example Azure Functions & C# - .NET Core 3.1 container"),". We'll use it later to test our Azurite connectivity. To do that let's create ourselves a ",(0,a.kt)("inlineCode",{parentName:"p"},".devcontainer")," directory:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"mkdir .devcontainer\n")),(0,a.kt)("p",null,"And inside there we'll add a ",(0,a.kt)("inlineCode",{parentName:"p"},"devcontainer.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'// For format details, see https://aka.ms/devcontainer.json. For config options, see the README at:\n// https://github.com/microsoft/vscode-dev-containers/tree/v0.177.0/containers/azure-functions-dotnetcore-3.1\n{\n  "name": "Azurite and Azure Functions & C# - .NET Core 3.1",\n  "dockerComposeFile": "docker-compose.yml",\n  "service": "app",\n  "workspaceFolder": "/workspace",\n  "forwardPorts": [7071],\n\n  // Set *default* container specific settings.json values on container create.\n  "settings": {\n    "terminal.integrated.defaultProfile.linux": "/bin/bash"\n  },\n\n  // Add the IDs of extensions you want installed when the container is created.\n  "extensions": [\n    "ms-azuretools.vscode-azurefunctions",\n    "ms-dotnettools.csharp"\n  ],\n\n  // Use \'postCreateCommand\' to run commands after the container is created.\n  // "postCreateCommand": "dotnet restore",\n\n  // Comment out connect as root instead. More info: https://aka.ms/vscode-remote/containers/non-root.\n  "remoteUser": "vscode"\n}\n')),(0,a.kt)("p",null,"As we can see, we're referencing a ",(0,a.kt)("inlineCode",{parentName:"p"},"docker-compose.yml")," file; let's add that:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"version: '3'\n\nservices:\n  app:\n    build:\n      context: .\n      dockerfile: Dockerfile\n      args:\n        # On Linux, you may need to update USER_UID and USER_GID below if not your local UID is not 1000.\n        USER_UID: 10000\n        USER_GID: 10000\n\n    init: true\n    volumes:\n      - ..:/workspace:cached\n\n    # Overrides default command so things don't shut down after the process ends.\n    command: sleep infinity\n\n    # Uncomment the next line to use a non-root user for all processes.\n    user: vscode\n\n  # run azurite and expose the relevant ports\n  azurite:\n    image: ./'mcr.microsoft.com/azure-storage/azurite'\n    ports:\n      - '10000:10000'\n      - '10001:10001'\n      - '10002:10002'\n")),(0,a.kt)("p",null,"It consists of two services; ",(0,a.kt)("inlineCode",{parentName:"p"},"app")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"azurite"),". ",(0,a.kt)("inlineCode",{parentName:"p"},"azurite")," is the Docker image of Azurite, which exposes the Azurite ports so ",(0,a.kt)("inlineCode",{parentName:"p"},"app")," can access it. Note the name of ",(0,a.kt)("inlineCode",{parentName:"p"},"azurite"),"; that will turn out to be significant later. We're actually only going to use the Table Storage port of ",(0,a.kt)("inlineCode",{parentName:"p"},"10002"),", but this would allow us to use Blobs and Queues also. The ",(0,a.kt)("inlineCode",{parentName:"p"},"azurite")," service is effectively going to be executing this command for us when it runs:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"docker run -p 10000:10000 -p 10001:10001 -p 10002:10002 mcr.microsoft.com/azure-storage/azurite\n")),(0,a.kt)("p",null,"Now let's look at ",(0,a.kt)("inlineCode",{parentName:"p"},"app"),". This is our Azure Functions container. It references a ",(0,a.kt)("inlineCode",{parentName:"p"},"Dockerfile")," which we need to add:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-dockerfile"}),"# Find the Dockerfile for mcr.microsoft.com/azure-functions/dotnet:3.0-dotnet3-core-tools at this URL\n# https://github.com/Azure/azure-functions-docker/blob/master/host/3.0/buster/amd64/dotnet/dotnet-core-tools.Dockerfile\nFROM mcr.microsoft.com/azure-functions/dotnet:3.0-dotnet3-core-tools\n")),(0,a.kt)("p",null,"We now have ourselves a dev container! VS Code should prompt us to reopen inside the container:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"The dev container starting",src:n(84213).Z,width:"2282",height:"1342"})),(0,a.kt)("h2",o({},{id:"make-a-function-app"}),"Make a function app"),(0,a.kt)("p",null,"Now we're inside our container, we're going to make ourselves a function app that will use Azurite. Let's fire up the terminal in VS Code and create a function app containing a simple HTTP function:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"mkdir src\ncd src\nfunc init TableStorage --dotnet\ncd TableStorage\n")),(0,a.kt)("p",null,"We need to add a package for the APIs which interact with Table Storage:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"dotnet restore\ndotnet add package Microsoft.Azure.Cosmos.Table --version 1.0.8\n")),(0,a.kt)("p",null,"The name is somewhat misleading, as it's both for Cosmos ",(0,a.kt)("em",{parentName:"p"},"and")," for Table Storage. Famously, naming things is hard \ud83d\ude09."),(0,a.kt)("p",null,"Our mission is to be able to write and read from Azurite Table Storage. We need something to read and write that we care about. I like to visit ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.kew.org/kew-gardens"}),"Kew Gardens")," and so let's imagine ourselves a system which tracks visitors to Kew."),(0,a.kt)("p",null,"We're going to add a class called ",(0,a.kt)("inlineCode",{parentName:"p"},"KewGardensVisit"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing Microsoft.Azure.Cosmos.Table;\n\nnamespace TableStorage\n{\n    public class KewGardenVisit : TableEntity\n    {\n        public KewGardenVisit() {}\n        public KewGardenVisit(DateTime arrivedAt, string memberId)\n        {\n            PartitionKey = arrivedAt.ToString("yyyy-MM-dd", System.Globalization.CultureInfo.InvariantCulture);\n            RowKey = memberId;\n\n            ArrivedAt = arrivedAt;\n        }\n\n        public DateTime ArrivedAt { get; set; }\n    }\n}\n')),(0,a.kt)("p",null,"Now we have our entity, let's add a class called ",(0,a.kt)("inlineCode",{parentName:"p"},"HelloAzuriteTableStorage")," which will contain functions which interact with the storage:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Linq;\nusing System.Threading.Tasks;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Azure.WebJobs;\nusing Microsoft.Azure.WebJobs.Extensions.Http;\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.Extensions.Logging;\nusing Microsoft.Azure.Cosmos.Table;\n\nnamespace TableStorage\n{\n    public static class HelloAzuriteTableStorage\n    {\n        // Note how we\'re addressing our azurite service\n        const string AZURITE_TABLESTORAGE_CONNECTIONSTRING =\n            "DefaultEndpointsProtocol=http;" +\n            "AccountName=devstoreaccount1;" +\n            "AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;" +\n            "BlobEndpoint=http://azurite:10000/devstoreaccount1;" +\n            "QueueEndpoint=http://azurite:10001/devstoreaccount1;" +\n            "TableEndpoint=http://azurite:10002/devstoreaccount1;";\n        const string TABLE_NAME = "KewGardenVisits";\n\n        [FunctionName("SaveVisit")]\n        public static async Task<IActionResult> RunSaveVisit(\n            [HttpTrigger(AuthorizationLevel.Anonymous, "get", "post", Route = null)] HttpRequest req,\n            ILogger log)\n        {\n            try\n            {\n                var table = await GetTable(log);\n\n                // Create the InsertOrReplace table operation\n                var insertOrMergeOperation = TableOperation.InsertOrMerge(new KewGardenVisit(\n                    arrivedAt: DateTime.UtcNow,\n                    memberId: "JR123456743921"\n                ));\n\n                // Execute the operation.\n                TableResult result = await table.ExecuteAsync(insertOrMergeOperation);\n                KewGardenVisit savedTelemetry = result.Result as KewGardenVisit;\n\n                if (result.RequestCharge.HasValue)\n                    log.LogInformation("Request Charge of InsertOrMerge Operation: " + result.RequestCharge);\n\n                return new OkObjectResult(savedTelemetry);\n\n            }\n            catch (Exception e)\n            {\n                log.LogError(e, "Problem saving");\n            }\n\n            return new BadRequestObjectResult("There was an issue");\n        }\n\n        [FunctionName("GetTodaysVisits")]\n        public static async Task<IActionResult> RunGetTodaysVisits(\n            [HttpTrigger(AuthorizationLevel.Anonymous, "get", Route = null)] HttpRequest req,\n            ILogger log)\n        {\n            try\n            {\n                var table = await GetTable(log);\n\n                var snowOnTheAdoTelemetries = table.CreateQuery<KewGardenVisit>()\n                    .Where(x => x.PartitionKey == DateTime.UtcNow.ToString("yyyy-MM-dd", System.Globalization.CultureInfo.InvariantCulture))\n                    .ToArray();\n\n                return new OkObjectResult(snowOnTheAdoTelemetries);\n\n            }\n            catch (Exception e)\n            {\n                log.LogError(e, "Problem loading");\n                return new BadRequestObjectResult("There was an issue");\n            }\n        }\n\n        private static async Task<CloudTable> GetTable(ILogger log)\n        {\n            // Construct a new TableClient using a TableSharedKeyCredential.\n            var storageAccount = CloudStorageAccount.Parse(AZURITE_TABLESTORAGE_CONNECTIONSTRING); ;\n\n            // Create a table client for interacting with the table service\n            CloudTableClient tableClient = storageAccount.CreateCloudTableClient(new TableClientConfiguration());\n\n            // Create a table client for interacting with the table service\n            CloudTable table = tableClient.GetTableReference(TABLE_NAME);\n            if (await table.CreateIfNotExistsAsync())\n                log.LogInformation("Created Table named: {0}", TABLE_NAME);\n            else\n                log.LogInformation("Table {0} already exists", TABLE_NAME);\n\n            return table;\n        }\n    }\n}\n')),(0,a.kt)("p",null,"There's a couple of things to draw attention to here:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"AZURITE_TABLESTORAGE_CONNECTIONSTRING")," - this mega string is based upon the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/Azurite#connection-strings"}),"Azurite connection string docs"),". The account name and key are the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/Azurite#default-storage-account"}),"Azurite default storage accounts"),". You'll note we target ",(0,a.kt)("inlineCode",{parentName:"p"},"TableEndpoint=http://azurite:10002/devstoreaccount1"),". The ",(0,a.kt)("inlineCode",{parentName:"p"},"azurite")," here is replacing the standard ",(0,a.kt)("inlineCode",{parentName:"p"},"127.0.0.1")," where Azurite typically listens. This ",(0,a.kt)("inlineCode",{parentName:"p"},"azurite")," name comes from the name of our service in the ",(0,a.kt)("inlineCode",{parentName:"p"},"docker-compose.yml")," file.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"We're creating two functions ",(0,a.kt)("inlineCode",{parentName:"p"},"SaveVisit")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"GetTodaysVisits"),". ",(0,a.kt)("inlineCode",{parentName:"p"},"SaveVisit")," creates an entry in our storage to represent someone's visit. It's a hardcoded value representing me, and we're exposing a write operation at a ",(0,a.kt)("inlineCode",{parentName:"p"},"GET")," endpoint which is not very RESTful. But this is a demo and Roy Fielding would forgive us. ",(0,a.kt)("inlineCode",{parentName:"p"},"GetTodaysVisits")," allows us to read back the visits that have happened today."))),(0,a.kt)("p",null,"Let's see if it works by entering ",(0,a.kt)("inlineCode",{parentName:"p"},"func start")," and browsing to ",(0,a.kt)("inlineCode",{parentName:"p"},"http://localhost:7071/api/savevisit")),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"a screenshot of the response from the savevisits endpoint",src:n(82785).Z,width:"1110",height:"472"})),(0,a.kt)("p",null,"Looking good. Now let's see if we can query them at ",(0,a.kt)("inlineCode",{parentName:"p"},"http://localhost:7071/api/gettodaysvisits"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"a screenshot of the response from the gettodaysvisits endpoint",src:n(38637).Z,width:"1110",height:"472"})),(0,a.kt)("p",null,"Disco."),(0,a.kt)("h2",o({},{id:"can-we-swap-out-azurite-for-the-real-thing\ufe0f"}),"Can we swap out Azurite for The Real Thing\u2122\ufe0f?"),(0,a.kt)("p",null,"You may be thinking ",(0,a.kt)("em",{parentName:"p"},'"This is great! But in the end I need to write to Azure Table Storage itself; not Azurite."')),(0,a.kt)("p",null,"That's a fair point. Fortunately, it's only the connection string that determines where you read and write to. It would be fairly easy to dependency inject the appropriate connection string, or indeed a service that is connected to the storage you wish to target. If you want to make that happen, you can."))}d.isMDXComponent=!0},86725:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-functions-dotnet-5-query-params-di-bicep",title:"Azure Functions and .NET 5: Query params, Dependency Injection, Bicep & Build",authors:"johnnyreilly",tags:["Azure Functions",".NET","Bicep"],image:"./title-image.png",description:"The upgrade of Azure Functions from .NET Core 3.1 to .NET 5 is significant. This post shows part of the upgrade: Query params, Dependency Injection, Bicep & Build",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-functions-dotnet-5-query-params-di-bicep",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-06-11-azure-functions-dotnet-5-query-params-di-bicep/index.md",source:"@site/blog/2021-06-11-azure-functions-dotnet-5-query-params-di-bicep/index.md",title:"Azure Functions and .NET 5: Query params, Dependency Injection, Bicep & Build",description:"The upgrade of Azure Functions from .NET Core 3.1 to .NET 5 is significant. This post shows part of the upgrade: Query params, Dependency Injection, Bicep & Build",date:"2021-06-11T00:00:00.000Z",formattedDate:"June 11, 2021",tags:[{label:"Azure Functions",permalink:"/tags/azure-functions"},{label:".NET",permalink:"/tags/net"},{label:"Bicep",permalink:"/tags/bicep"}],readingTime:3.385,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-functions-dotnet-5-query-params-di-bicep",title:"Azure Functions and .NET 5: Query params, Dependency Injection, Bicep & Build",authors:"johnnyreilly",tags:["Azure Functions",".NET","Bicep"],image:"./title-image.png",description:"The upgrade of Azure Functions from .NET Core 3.1 to .NET 5 is significant. This post shows part of the upgrade: Query params, Dependency Injection, Bicep & Build",hide_table_of_contents:!1},prevItem:{title:"React 18 and TypeScript",permalink:"/react-18-and-typescript"},nextItem:{title:"Azurite and Table Storage in a dev container",permalink:"/azurite-and-table-storage-dev-container"}},p={image:n(28061).Z,authorsImageUrls:[void 0]},u=[{value:"Query params",id:"query-params",level:2},{value:"Dependency Injection, local development and Azure Application Settings",id:"dependency-injection-local-development-and-azure-application-settings",level:2},{value:"Bicep",id:"bicep",level:2},{value:"Building .NET 5 functions",id:"building-net-5-functions",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The upgrade of Azure Functions from .NET Core 3.1 to .NET 5 is significant. There's an excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"https://codetraveler.io/2021/05/28/creating-azure-functions-using-net-5/"}),"guide")," for the general steps required to perform the upgrade. However there's a number of (unrelated) items which are not covered by that post:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Query params"),(0,a.kt)("li",{parentName:"ul"},"Dependency Injection"),(0,a.kt)("li",{parentName:"ul"},"Bicep"),(0,a.kt)("li",{parentName:"ul"},"Build")),(0,a.kt)("p",null,"This post will show how to tackle these."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image showing name of post and the Azure Functions logo",src:n(28061).Z,width:"1347",height:"431"})),(0,a.kt)("h2",o({},{id:"query-params"}),"Query params"),(0,a.kt)("p",null,"As part of the move to .NET 5 functions, we say goodbye to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.http.httprequest?view=aspnetcore-5.0"}),(0,a.kt)("inlineCode",{parentName:"a"},"HttpRequest"))," and hello to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.functions.worker.http.httprequestdata?view=azure-dotnet"}),(0,a.kt)("inlineCode",{parentName:"a"},"HttpRequestData")),". Now ",(0,a.kt)("inlineCode",{parentName:"p"},"HttpRequest")," had a useful ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.http.httprequest.query?view=aspnetcore-5.0#Microsoft_AspNetCore_Http_HttpRequest_Query"}),(0,a.kt)("inlineCode",{parentName:"a"},"Query"))," property which allowed for the simple extraction of query parameters like so."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'var from = req.Query["from"]\n')),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"HttpRequestData")," has no such property. However, it's straightforward to make our own. It's simply a matter of using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/api/system.web.httputility.parsequerystring?view=net-5.0"}),(0,a.kt)("inlineCode",{parentName:"a"},"System.Web.HttpUtility.ParseQueryString"))," on ",(0,a.kt)("inlineCode",{parentName:"p"},"req.Url.Query")," and using that:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'var query = System.Web.HttpUtility.ParseQueryString(req.Url.Query);\nvar from = query["from"]\n')),(0,a.kt)("h2",o({},{id:"dependency-injection-local-development-and-azure-application-settings"}),"Dependency Injection, local development and Azure Application Settings"),(0,a.kt)("p",null,"Dependency Injection is a much more familiar shape in .NET 5 if you're familiar with .NET Core web apps. Once again we have a ",(0,a.kt)("inlineCode",{parentName:"p"},"Program.cs")," file. To get the configuration built in such a way to support both local development and when deployed to Azure, there's a few things to do. When deployed to Azure you'll likely want to read from Azure Application Settings:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Azure Application Settings",src:n(27809).Z,width:"3014",height:"1364"})),(0,a.kt)("p",null,"To tackle both of these, you'll want to use ",(0,a.kt)("inlineCode",{parentName:"p"},"AddJsonFile")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"AddEnvironmentVariables")," in ",(0,a.kt)("inlineCode",{parentName:"p"},"ConfigureAppConfiguration"),". A final ",(0,a.kt)("inlineCode",{parentName:"p"},"Program.cs")," might look something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Threading.Tasks;\nusing Microsoft.Extensions.Configuration;\nusing Microsoft.Extensions.DependencyInjection;\nusing Microsoft.Extensions.Hosting;\n\nnamespace MyApp\n{\n    public class Program\n    {\n        public static Task Main(string[] args)\n        {\n            var host = new HostBuilder()\n                .ConfigureAppConfiguration(configurationBuilder =>\n                    configurationBuilder\n                        .AddCommandLine(args)\n                        // below is for local development\n                        .AddJsonFile("local.settings.json", optional: true, reloadOnChange: true)\n                        // below is what you need to read Application Settings in Azure\n                        .AddEnvironmentVariables()\n                )\n                .ConfigureFunctionsWorkerDefaults()\n                .ConfigureServices(services =>\n                {\n                    services.AddLogging();\n                    services.AddHttpClient();\n                })\n                .Build();\n\n            return host.RunAsync();\n        }\n    }\n}\n')),(0,a.kt)("p",null,"With this approach in place, when the application runs, it should construct a configuration driven by all the providers required to run our application."),(0,a.kt)("h2",o({},{id:"bicep"}),"Bicep"),(0,a.kt)("p",null,"When it comes to deploying to Azure via ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/bicep"}),"Bicep"),", there's some small tweaks required:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"appSettings.FUNCTIONS_WORKER_RUNTIME")," becomes ",(0,a.kt)("inlineCode",{parentName:"li"},"dotnet-isolated")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"linuxFxVersion")," becomes ",(0,a.kt)("inlineCode",{parentName:"li"},"DOTNET-ISOLATED|5.0"))),(0,a.kt)("p",null,"Applied to the resource itself the diff looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),"resource functionAppName_resource 'Microsoft.Web/sites@2018-11-01' = {\n  name: functionAppName\n  location: location\n  tags: tags_var\n  kind: 'functionapp,linux'\n  identity: {\n    type: 'SystemAssigned'\n  }\n  properties: {\n    serverFarmId: appServicePlanName_resource.id\n    siteConfig: {\n      http20Enabled: true\n      remoteDebuggingEnabled: false\n      minTlsVersion: '1.2'\n      appSettings: [\n        {\n          name: 'FUNCTIONS_EXTENSION_VERSION'\n          value: '~3'\n        }\n        {\n          name: 'FUNCTIONS_WORKER_RUNTIME'\n-          value: 'dotnet'\n+          value: 'dotnet-isolated'\n        }\n        {\n          name: 'AzureWebJobsStorage'\n          value: 'DefaultEndpointsProtocol=https;AccountName=${storageAccountName};AccountKey=${listKeys(resourceId('Microsoft.Storage/storageAccounts', storageAccountName), '2019-06-01').keys[0].value};EndpointSuffix=${environment().suffixes.storage}'\n        }\n      ]\n      connectionStrings: [\n        {\n          name: 'TableStorageConnectionString'\n          connectionString: 'DefaultEndpointsProtocol=https;AccountName=${storageAccountName};AccountKey=${listKeys(resourceId('Microsoft.Storage/storageAccounts', storageAccountName), '2019-06-01').keys[0].value};EndpointSuffix=${environment().suffixes.storage}'\n        }\n      ]\n-      linuxFxVersion: 'DOTNETCORE|LTS'\n+      linuxFxVersion: 'DOTNET-ISOLATED|5.0'\n      ftpsState: 'Disabled'\n      managedServiceIdentityId: 1\n    }\n    clientAffinityEnabled: false\n    httpsOnly: true\n  }\n}\n")),(0,a.kt)("h2",o({},{id:"building-net-5-functions"}),"Building .NET 5 functions"),(0,a.kt)("p",null,"Before signing off, there's one more thing to slip in. When attempting to build .NET 5 Azure Functions with the .NET SDK ",(0,a.kt)("em",{parentName:"p"},"alone"),", you'll encounter this error:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"The framework 'Microsoft.NETCore.App', version '3.1.0' was not found.\n")),(0,a.kt)("p",null,"Docs on this seem to be pretty short. The closest I came to docs was ",(0,a.kt)("a",o({parentName:"p"},{href:"https://stackoverflow.com/questions/66938752/net-5-the-framework-microsoft-netcore-app-version-3-1-0-was-not-found/66938753#66938753"}),"this comment on Stack Overflow"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"To build .NET 5 functions, the .NET Core 3 SDK is required. So this must be installed alongside the 5.0.x sdk.")),(0,a.kt)("p",null,"So with Azure Pipelines you might have have something that looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"stages:\n  - stage: build\n    displayName: build\n    pool:\n      vmImage: 'ubuntu-latest'\n    jobs:\n      - job: BuildAndTest\n        displayName: 'Build and Test'\n        steps:\n          # we need .NET Core SDK 3.1 too!\n          - task: UseDotNet@2\n            displayName: 'Install .NET Core SDK 3.1'\n            inputs:\n              packageType: 'sdk'\n              version: 3.1.x\n\n          - task: UseDotNet@2\n            displayName: 'Install .NET SDK 5.0'\n            inputs:\n              packageType: 'sdk'\n              version: 5.0.x\n\n          - task: DotNetCoreCLI@2\n            displayName: 'function app test'\n            inputs:\n              command: test\n\n          - task: DotNetCoreCLI@2\n            displayName: 'function app build'\n            inputs:\n              command: build\n              arguments: '--configuration Release --output $(Build.ArtifactStagingDirectory)/MyApp'\n\n          - task: DotNetCoreCLI@2\n            displayName: 'function app publish'\n            inputs:\n              command: publish\n              arguments: '--configuration Release --output $(Build.ArtifactStagingDirectory)/MyApp /p:SourceRevisionId=$(Build.SourceVersion)'\n              publishWebProjects: false\n              modifyOutputPath: false\n              zipAfterPublish: true\n\n          - publish: $(Build.ArtifactStagingDirectory)/MyApp\n            artifact: functionapp\n")),(0,a.kt)("p",null,"Have fun building .NET 5 functions!"))}d.isMDXComponent=!0},989:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"react-18-and-typescript",title:"React 18 and TypeScript",authors:"johnnyreilly",tags:["React","typescript","React 18"],image:"./createNode-error.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/react-18-and-typescript",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-06-30-react-18-and-typescript/index.md",source:"@site/blog/2021-06-30-react-18-and-typescript/index.md",title:"React 18 and TypeScript",description:'React 18 alpha has been released; but can we use it with TypeScript? The answer is "yes", but you need to do a couple of things to make that happen. This post will show you what to do.',date:"2021-06-30T00:00:00.000Z",formattedDate:"June 30, 2021",tags:[{label:"React",permalink:"/tags/react"},{label:"typescript",permalink:"/tags/typescript"},{label:"React 18",permalink:"/tags/react-18"}],readingTime:3.44,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"react-18-and-typescript",title:"React 18 and TypeScript",authors:"johnnyreilly",tags:["React","typescript","React 18"],image:"./createNode-error.png",hide_table_of_contents:!1},prevItem:{title:"C# 9 in-process Azure Functions",permalink:"/c-sharp-9-azure-functions-in-process"},nextItem:{title:"Azure Functions and .NET 5: Query params, Dependency Injection, Bicep & Build",permalink:"/azure-functions-dotnet-5-query-params-di-bicep"}},p={image:n(8314).Z,authorsImageUrls:[void 0]},u=[{value:"Creating a React App with TypeScript",id:"creating-a-react-app-with-typescript",level:2},{value:"Using the new APIs",id:"using-the-new-apis",level:2},{value:"Telling TypeScript about the new APIs",id:"telling-typescript-about-the-new-apis",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://reactjs.org/blog/2021/06/08/the-plan-for-react-18.html"}),"React 18 alpha has been released"),'; but can we use it with TypeScript? The answer is "yes", but you need to do a couple of things to make that happen. This post will show you what to do.'),(0,a.kt)("h2",o({},{id:"creating-a-react-app-with-typescript"}),"Creating a React App with TypeScript"),(0,a.kt)("p",null,"Let's create ourselves a vanilla React TypeScript app with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://create-react-app.dev/"}),"Create React App"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"yarn create react-app my-app --template typescript\n")),(0,a.kt)("p",null,"Now let's upgrade the version of React to ",(0,a.kt)("inlineCode",{parentName:"p"},"@next"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"yarn add react@next react-dom@next\n")),(0,a.kt)("p",null,"Which will leave you with entries in the ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," which use React 18. It will likely look something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'    "react": "^18.0.0-alpha-e6be2d531",\n    "react-dom": "^18.0.0-alpha-e6be2d531",\n')),(0,a.kt)("p",null,"If we run ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn start")," we'll find ourselves running a React 18 app. Exciting!"),(0,a.kt)("h2",o({},{id:"using-the-new-apis"}),"Using the new APIs"),(0,a.kt)("p",null,"So let's try using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/reactwg/react-18/discussions/5"}),(0,a.kt)("inlineCode",{parentName:"a"},"ReactDOM.createRoot"))," API. It's this API that opts our application into using new features of React 18. We'll open up ",(0,a.kt)("inlineCode",{parentName:"p"},"index.tsx")," and make this change:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),"-ReactDOM.render(\n-  <React.StrictMode>\n-    <App />\n-  </React.StrictMode>,\n-  document.getElementById('root')\n-);\n+const root = ReactDOM.createRoot(document.getElementById('root'));\n+\n+root.render(\n+  <React.StrictMode>\n+    <App />\n+  </React.StrictMode>\n+);\n")),(0,a.kt)("p",null,"If we were running JavaScript alone, this would work. However, because we're using TypeScript as well, we're now confronted with an error:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("inlineCode",{parentName:"p"},"Property 'createRoot' does not exist on type 'typeof import(\"/code/my-app/node_modules/@types/react-dom/index\")'. TS2339"))),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"a screenshot of the Property &#39;createRoot&#39; does not exist error",src:n(8314).Z,width:"2076",height:"584"})),(0,a.kt)("p",null,"This is the TypeScript compiler complaining that it doesn't know anything about ",(0,a.kt)("inlineCode",{parentName:"p"},"ReactDOM.createRoot"),". This is because the type definitions that are currently in place in our application don't have that API defined."),(0,a.kt)("p",null,"Let's upgrade our type definitions:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"yarn add @types/react @types/react-dom\n")),(0,a.kt)("p",null,"We might reasonably hope that everything should work now. Alas it does not. The same error is presenting. TypeScript is not happy."),(0,a.kt)("h2",o({},{id:"telling-typescript-about-the-new-apis"}),"Telling TypeScript about the new APIs"),(0,a.kt)("p",null,"If we take a look at the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped/pull/53685"}),"PR that added support for the APIs"),", we'll find some tips. If you look at one of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped/blob/a07e9cfb005682fb6be0a2e85113eac131c3006f/types/react/next.d.ts"}),(0,a.kt)("inlineCode",{parentName:"a"},"next.d.ts"))," you'll find this info, courtesy of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/sebsilbermann"}),"Sebastian Silbermann"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),'/**\n * These are types for things that are present in the upcoming React 18 release.\n *\n * Once React 18 is released they can just be moved to the main index file.\n *\n * To load the types declared here in an actual project, there are three ways. The easiest one,\n * if your `tsconfig.json` already has a `"types"` array in the `"compilerOptions"` section,\n * is to add `"react/next"` to the `"types"` array.\n *\n * Alternatively, a specific import syntax can to be used from a typescript file.\n * This module does not exist in reality, which is why the {} is important:\n *\n * ```ts\n * import {} from \'react/next\'\n * ```\n *\n * It is also possible to include it through a triple-slash reference:\n *\n * ```ts\n * /// <reference types="react/next" />\n * ```\n *\n * Either the import or the reference only needs to appear once, anywhere in the project.\n */\n')),(0,a.kt)("p",null,"Let's try the first item on the list. We'll edit our ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," and add a new entry to the ",(0,a.kt)("inlineCode",{parentName:"p"},'"compilerOptions"')," section:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'    "types": ["react/next", "react-dom/next"]\n')),(0,a.kt)("p",null,"If we restart our build with ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn start")," we're now presented with a ",(0,a.kt)("em",{parentName:"p"},"different")," error:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("inlineCode",{parentName:"p"},"Argument of type 'HTMLElement | null' is not assignable to parameter of type 'Element | Document | DocumentFragment | Comment'. Type 'null' is not assignable to type 'Element | Document | DocumentFragment | Comment'. TS2345"))),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"a screenshot of the null is not assignable error",src:n(78908).Z,width:"2076",height:"584"})),(0,a.kt)("p",null,"Now this is actually nothing to do with issues with our new React type definitions. They are fine. This is TypeScript saying \"it's not guaranteed that ",(0,a.kt)("inlineCode",{parentName:"p"},"document.getElementById('root')")," returns something that is not ",(0,a.kt)("inlineCode",{parentName:"p"},"null"),"... since we're in ",(0,a.kt)("inlineCode",{parentName:"p"},"strictNullChecks")," mode you need to be sure ",(0,a.kt)("inlineCode",{parentName:"p"},"root"),' is not null".'),(0,a.kt)("p",null,"We'll deal with that by testing we do have an element in play before invoking ",(0,a.kt)("inlineCode",{parentName:"p"},"ReactDOM.createRoot"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),"-const root = ReactDOM.createRoot(document.getElementById('root'));\n+const rootElement = document.getElementById('root');\n+if (!rootElement) throw new Error('Failed to find the root element');\n+const root = ReactDOM.createRoot(rootElement);\n")),(0,a.kt)("p",null,"Now that change is made, we have a working React 18 application, using TypeScript. Enjoy!"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/how-to-use-typescript-with-react-18-alpha/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/how-to-use-typescript-with-react-18-alpha/"})))}d.isMDXComponent=!0},10575:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"c-sharp-9-azure-functions-in-process",title:"C# 9 in-process Azure Functions",authors:"johnnyreilly",tags:["C#","Azure Functions",".NET"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/c-sharp-9-azure-functions-in-process",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-07-01-c-sharp-9-azure-functions-in-process/index.md",source:"@site/blog/2021-07-01-c-sharp-9-azure-functions-in-process/index.md",title:"C# 9 in-process Azure Functions",description:"C# 9 has some amazing features. Azure Functions are have two modes: isolated and in-process. Whilst isolated supports .NET 5 (and hence C# 9), in-process supports .NET Core 3.1 (C# 8). This post shows how we can use C# 9 with in-process Azure Functions running on .NET Core 3.1.",date:"2021-07-01T00:00:00.000Z",formattedDate:"July 1, 2021",tags:[{label:"C#",permalink:"/tags/c"},{label:"Azure Functions",permalink:"/tags/azure-functions"},{label:".NET",permalink:"/tags/net"}],readingTime:4.57,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"c-sharp-9-azure-functions-in-process",title:"C# 9 in-process Azure Functions",authors:"johnnyreilly",tags:["C#","Azure Functions",".NET"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"Output connection strings and keys from Azure Bicep",permalink:"/output-connection-strings-and-keys-from-azure-bicep"},nextItem:{title:"React 18 and TypeScript",permalink:"/react-18-and-typescript"}},p={image:n(63830).Z,authorsImageUrls:[void 0]},u=[{value:"Azure Functions: in-process and isolated",id:"azure-functions-in-process-and-isolated",level:2},{value:"Setting up a C# 8 project",id:"setting-up-a-c-8-project",level:2},{value:"What does it take to get to C# 9?",id:"what-does-it-take-to-get-to-c-9",level:2},{value:"Adding C# 9 to the in-process function",id:"adding-c-9-to-the-in-process-function",level:2},{value:"Making a C# 9 program",id:"making-a-c-9-program",level:2},{value:"Best before...",id:"best-before",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"C# 9 has some amazing features. Azure Functions are have two modes: isolated and in-process. Whilst isolated supports .NET 5 (and hence C# 9), in-process supports .NET Core 3.1 (C# 8). This post shows how we can use C# 9 with in-process Azure Functions running on .NET Core 3.1."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image showing name of post and the Azure Functions logo",src:n(63830).Z,width:"880",height:"412"})),(0,a.kt)("h2",o({},{id:"azure-functions-in-process-and-isolated"}),"Azure Functions: in-process and isolated"),(0,a.kt)("p",null,'Historically .NET Azure Functions have been in-process. This changed with .NET 5 where a new model was introduced named "isolated". ',(0,a.kt)("a",o({parentName:"p"},{href:"https://techcommunity.microsoft.com/t5/apps-on-azure/net-on-azure-functions-roadmap/ba-p/2197916"}),"To quote from the roadmap"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Running in an isolated process decouples .NET functions from the Azure Functions host\u2014allowing us to more easily support new .NET versions and address pain points associated with sharing a single process.")),(0,a.kt)("p",null,"However, the initial launch of isolated functions ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/azure-functions/dotnet-isolated-process-guide#differences-with-net-class-library-functions"}),"does not have the full level of functionality enjoyed by in-process functions"),". This will happen, according the roadmap:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Long term, our vision is to have full feature parity out of process, bringing many of the features that are currently exclusive to the in-process model to the isolated model. We plan to begin delivering improvements to the isolated model after the .NET 6 general availability release.")),(0,a.kt)("p",null,"In the future, in-process functions will be retired in favour of isolated functions. However, it will be .NET 7 (scheduled to ship in November 2022) before that takes place:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"the Azure Functions roadmap image illustrating the future of .NET functions taken from https://techcommunity.microsoft.com/t5/apps-on-azure/net-on-azure-functions-roadmap/ba-p/2197916",src:n(49167).Z,width:"998",height:"340"})),(0,a.kt)("p",null,"As the image taken from the roadmap shows, when .NET 5 shipped, it did not support in-process Azure Functions. When .NET 6 ships in November, it should."),(0,a.kt)("p",null,"In the meantime, we would like to use C# 9."),(0,a.kt)("h2",o({},{id:"setting-up-a-c-8-project"}),"Setting up a C# 8 project"),(0,a.kt)("p",null,"We're have the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/azure-functions/functions-run-local"}),"Azure Functions Core Tools")," installed, so let's create a new function project:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),'func new --worker-runtime dotnet --template "Http Trigger" --name "HelloRecord"\n')),(0,a.kt)("p",null,"The above command scaffolds out a .NET Core 3.1 Azure function project which contains a single Azure function. The ",(0,a.kt)("inlineCode",{parentName:"p"},"--worker-runtime dotnet")," parameter is what causes an in-process .NET Core 3.1 function being created. You should have a ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj")," file that looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<Project Sdk="Microsoft.NET.Sdk">\n  <PropertyGroup>\n    <TargetFramework>netcoreapp3.1</TargetFramework>\n    <AzureFunctionsVersion>v3</AzureFunctionsVersion>\n  </PropertyGroup>\n  <ItemGroup>\n    <PackageReference Include="Microsoft.NET.Sdk.Functions" Version="3.0.11" />\n  </ItemGroup>\n  <ItemGroup>\n    <None Update="host.json">\n      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n    </None>\n    <None Update="local.settings.json">\n      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n      <CopyToPublishDirectory>Never</CopyToPublishDirectory>\n    </None>\n  </ItemGroup>\n</Project>\n')),(0,a.kt)("p",null,"We're running with C# 8 and .NET Core 3.1 at this point. What does it take to get us to C# 9?"),(0,a.kt)("h2",o({},{id:"what-does-it-take-to-get-to-c-9"}),"What does it take to get to C# 9?"),(0,a.kt)("p",null,"There's a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.reddit.com/r/csharp/comments/kiplz8/can_i_use_c90_with_aspnet_core_31/"}),"great post on Reddit addressing using C# 9 with .NET Core 3.1 which says:")),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"You can use ",(0,a.kt)("inlineCode",{parentName:"p"},"<LangVersion>9.0</LangVersion>"),", and VS even includes support for suggesting a language upgrade."),(0,a.kt)("p",{parentName:"blockquote"},"However, there are three categories of features in C#:"),(0,a.kt)("ol",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"features that are entirely part of the compiler. Those will work.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"features that require BCL additions. Since you're on the older BCL, those will need to be backported. For example, to use init; and record, you can use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/manuelroemer/IsExternalInit"}),"https://github.com/manuelroemer/IsExternalInit"),".")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"features that require runtime additions. Those cannot be added at all. For example, default interface members in C# 8, and covariant return types in C# 9.")))),(0,a.kt)("p",null,"Of the above, 1 and 2 add a tremendous amount of value. The features of 3 are great, but more niche. Speaking personally, I care a great deal about ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/csharp/whats-new/csharp-9#record-types"}),"Record types"),". So let's apply this."),(0,a.kt)("h2",o({},{id:"adding-c-9-to-the-in-process-function"}),"Adding C# 9 to the in-process function"),(0,a.kt)("p",null,"To get C# into the mix, we want to make two changes:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"add a ",(0,a.kt)("inlineCode",{parentName:"li"},"<LangVersion>9.0</LangVersion>")," to the ",(0,a.kt)("inlineCode",{parentName:"li"},"<PropertyGroup>")," element of our ",(0,a.kt)("inlineCode",{parentName:"li"},".csproj")," file"),(0,a.kt)("li",{parentName:"ul"},"add a package reference to the ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/manuelroemer/IsExternalInit"}),(0,a.kt)("inlineCode",{parentName:"a"},"IsExternalInit")))),(0,a.kt)("p",null,"The applied changes look like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),'<Project Sdk="Microsoft.NET.Sdk">\n  <PropertyGroup>\n    <TargetFramework>netcoreapp3.1</TargetFramework>\n+    <LangVersion>9.0</LangVersion>\n    <AzureFunctionsVersion>v3</AzureFunctionsVersion>\n  </PropertyGroup>\n  <ItemGroup>\n    <PackageReference Include="Microsoft.NET.Sdk.Functions" Version="3.0.11" />\n+    <PackageReference Include="IsExternalInit" Version="1.0.1" PrivateAssets="all" />\n  </ItemGroup>\n  <ItemGroup>\n    <None Update="host.json">\n      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n    </None>\n    <None Update="local.settings.json">\n      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n      <CopyToPublishDirectory>Never</CopyToPublishDirectory>\n    </None>\n  </ItemGroup>\n</Project>\n')),(0,a.kt)("p",null,"If we used ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet add package IsExternalInit"),", we might be using a different syntax in the ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj"),". Be not afeard - that won't affect usage."),(0,a.kt)("h2",o({},{id:"making-a-c-9-program"}),"Making a C# 9 program"),(0,a.kt)("p",null,"Now we can theoretically use C# 9.... Let's use C# 9. We'll tweak our ",(0,a.kt)("inlineCode",{parentName:"p"},"HelloRecord.cs")," file, add in a simple ",(0,a.kt)("inlineCode",{parentName:"p"},"record")," named ",(0,a.kt)("inlineCode",{parentName:"p"},"MessageRecord")," and tweak the ",(0,a.kt)("inlineCode",{parentName:"p"},"Run")," method to use it:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.IO;\nusing System.Threading.Tasks;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Azure.WebJobs;\nusing Microsoft.Azure.WebJobs.Extensions.Http;\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.Extensions.Logging;\nusing Newtonsoft.Json;\n\nnamespace tmp\n{\n    public record MessageRecord(string message);\n\n    public static class HelloRecord\n    {\n        [FunctionName("HelloRecord")]\n        public static async Task<IActionResult> Run(\n            [HttpTrigger(AuthorizationLevel.Function, "get", "post", Route = null)] HttpRequest req,\n            ILogger log)\n        {\n            log.LogInformation("C# HTTP trigger function processed a request.");\n\n            string name = req.Query["name"];\n\n            string requestBody = await new StreamReader(req.Body).ReadToEndAsync();\n            dynamic data = JsonConvert.DeserializeObject(requestBody);\n            name = name ?? data?.name;\n\n            var responseMessage = new MessageRecord(string.IsNullOrEmpty(name)\n                ? "This HTTP triggered function executed successfully. Pass a name in the query string or in the request body for a personalized response."\n                : $"Hello, {name}. This HTTP triggered function executed successfully.");\n\n            return new OkObjectResult(responseMessage);\n        }\n    }\n}\n')),(0,a.kt)("p",null,"If we kick off our function with ",(0,a.kt)("inlineCode",{parentName:"p"},"func start"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the output of the HelloRecord function",src:n(52716).Z,width:"2082",height:"282"})),(0,a.kt)("p",null,"We can see we can compile, and output is as we might expect and hope. Likewise if we try and debug in VS Code, we can:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the output of the HelloRecord function",src:n(60062).Z,width:"2672",height:"1148"})),(0,a.kt)("h2",o({},{id:"best-before"}),"Best before..."),(0,a.kt)("p",null,"So, we've now a way to use C# 9 (or most of it) with in-process .NET Core 3.1 apps. This should serve until .NET 6 ships in November 2021 and we're able to use C# 9 by default."))}d.isMDXComponent=!0},46710:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"output-connection-strings-and-keys-from-azure-bicep",title:"Output connection strings and keys from Azure Bicep",authors:"johnnyreilly",tags:["Bicep","Azure","connection string"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/output-connection-strings-and-keys-from-azure-bicep",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-07-07-output-connection-strings-and-keys-from-azure-bicep/index.md",source:"@site/blog/2021-07-07-output-connection-strings-and-keys-from-azure-bicep/index.md",title:"Output connection strings and keys from Azure Bicep",description:"If we're provisioning resources in Azure with Bicep, we may have a need to acquire the connection strings and keys of our newly deployed infrastructure. For example, the connection strings of an event hub or the access keys of a storage account. Perhaps we'd like to use them to run an end-to-end test, perhaps we'd like to store these secrets somewhere for later consumption. This post shows how to do that using Bicep and the listKeys helper. Optionally it shows how we could consume this in Azure Pipelines.",date:"2021-07-07T00:00:00.000Z",formattedDate:"July 7, 2021",tags:[{label:"Bicep",permalink:"/tags/bicep"},{label:"Azure",permalink:"/tags/azure"},{label:"connection string",permalink:"/tags/connection-string"}],readingTime:6.14,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"output-connection-strings-and-keys-from-azure-bicep",title:"Output connection strings and keys from Azure Bicep",authors:"johnnyreilly",tags:["Bicep","Azure","connection string"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"webpack? esbuild? Why not both?",permalink:"/webpack-esbuild-why-not-both"},nextItem:{title:"C# 9 in-process Azure Functions",permalink:"/c-sharp-9-azure-functions-in-process"}},p={image:n(47088).Z,authorsImageUrls:[void 0]},u=[{value:"Event Hub connection string",id:"event-hub-connection-string",level:2},{value:"Storage Account connection string",id:"storage-account-connection-string",level:2},{value:"From Bicep to Azure Pipelines",id:"from-bicep-to-azure-pipelines",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"If we're provisioning resources in Azure with Bicep, we may have a need to acquire the connection strings and keys of our newly deployed infrastructure. For example, the connection strings of an event hub or the access keys of a storage account. Perhaps we'd like to use them to run an end-to-end test, perhaps we'd like to store these secrets somewhere for later consumption. This post shows how to do that using Bicep and the ",(0,a.kt)("inlineCode",{parentName:"p"},"listKeys")," helper. Optionally it shows how we could consume this in Azure Pipelines."),(0,a.kt)("p",null,"Please note that exporting keys / connection strings etc from Bicep / ARM templates is generally considered to be a less secure approach. This is because these values will be visible inside the deployments section of the Azure Portal. Anyone who has access to this will be able to see them. An alternative approach would be permissioning our pipeline to access the resources directly. You can read about that approach ",(0,a.kt)("a",o({parentName:"p"},{href:"/permissioning-azure-pipelines-bicep-role-assignments"}),"here"),"."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"image which contains the blog title",src:n(47088).Z,width:"750",height:"250"})),(0,a.kt)("h2",o({},{id:"event-hub-connection-string"}),"Event Hub connection string"),(0,a.kt)("p",null,"First of all, let's provision an Azure Event Hub. This involves deploying an event hub namespace, an event hub in that namespace and an authorization rule. The following Bicep will do this for us:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"// Create an event hub namespace\n\nvar eventHubNamespaceName = 'evhns-demo'\n\nresource eventHubNamespace 'Microsoft.EventHub/namespaces@2021-01-01-preview' = {\n  name: eventHubNamespaceName\n  location: resourceGroup().location\n  sku: {\n    name: 'Standard'\n    tier: 'Standard'\n    capacity: 1\n  }\n  properties: {\n    zoneRedundant: true\n  }\n}\n\n// Create an event hub inside the namespace\n\nvar eventHubName = 'evh-demo'\n\nresource eventHubNamespaceName_eventHubName 'Microsoft.EventHub/namespaces/eventhubs@2021-01-01-preview' = {\n  parent: eventHubNamespace\n  name: eventHubName\n  properties: {\n    messageRetentionInDays: 7\n    partitionCount: 1\n  }\n}\n\n// Grant Listen and Send on our event hub\n\nresource eventHubNamespaceName_eventHubName_ListenSend 'Microsoft.EventHub/namespaces/eventhubs/authorizationRules@2021-01-01-preview' = {\n  parent: eventHubNamespaceName_eventHubName\n  name: 'ListenSend'\n  properties: {\n    rights: [\n      'Listen'\n      'Send'\n    ]\n  }\n  dependsOn: [\n    eventHubNamespace\n  ]\n}\n")),(0,a.kt)("p",null,"When this is deployed to Azure, it will result in creating something like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of event hub connection strings in the Azure Portal",src:n(10362).Z,width:"2358",height:"1460"})),(0,a.kt)("p",null,"As we can see, there are connection strings available which can be used to access the event hub. How do we get a connection string that we can play with? It's easily achieved by appending the following to our Bicep:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"// Determine our connection string\n\nvar eventHubNamespaceConnectionString = listKeys(eventHubNamespaceName_eventHubName_ListenSend.id, eventHubNamespaceName_eventHubName_ListenSend.apiVersion).primaryConnectionString\n\n// Output our variables\n\noutput eventHubNamespaceConnectionString string = eventHubNamespaceConnectionString\noutput eventHubName string = eventHubName\n")),(0,a.kt)("p",null,"What we're doing here is using the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/azure-resource-manager/bicep/bicep-functions-resource#list"}),(0,a.kt)("inlineCode",{parentName:"a"},"listKeys"))," helper on our authorization rule and retrieving the handy ",(0,a.kt)("inlineCode",{parentName:"p"},"primaryConnectionString"),", which is then exposed as an output variable."),(0,a.kt)("h2",o({},{id:"storage-account-connection-string"}),"Storage Account connection string"),(0,a.kt)("p",null,"We'd like to obtain a connection string for a storage account also. Let's put together a Bicep file that creates a storage account and a container therein. (Incidentally, it's fairly common to have a storage account provisioned alongside an event hub to facilitate reading from an event hub.)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"// Create a storage account\n\nvar storageAccountName = 'stdemo'\n\nresource eventHubNamespaceName_storageAccount 'Microsoft.Storage/storageAccounts@2021-02-01' = {\n  name: storageAccountName\n  location: resourceGroup().location\n  sku: {\n    name: 'Standard_LRS'\n    tier: 'Standard'\n  }\n  kind: 'StorageV2'\n  properties: {\n    networkAcls: {\n      bypass: 'AzureServices'\n      defaultAction: 'Allow'\n    }\n    accessTier: 'Hot'\n    allowBlobPublicAccess: false\n    minimumTlsVersion: 'TLS1_2'\n    allowSharedKeyAccess: true\n  }\n}\n\n// create a container inside that storage account\n\nvar blobContainerName = 'test-container'\n\nresource storageAccountName_default_containerName 'Microsoft.Storage/storageAccounts/blobServices/containers@2021-02-01' = {\n  name: '${storageAccountName}/default/${blobContainerName}'\n  dependsOn: [\n    eventHubNamespaceName_storageAccount\n  ]\n}\n")),(0,a.kt)("p",null,"When this is deployed to Azure, it will result in creating something like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of storage account access keys in the Azure Portal",src:n(10108).Z,width:"2358",height:"1460"})),(0,a.kt)("p",null,"Again we can see, there are connection strings available in the Azure Portal, which can be used to access the storage account. However, things aren't quite as simple as previously; in that there doesn't seem to be a way to directly acquire a connection string. What we can do, is acquire a key; and construct ourselves a connection string with that. Here's how:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"// Determine our connection string\n\nvar blobStorageConnectionString = 'DefaultEndpointsProtocol=https;AccountName=${eventHubNamespaceName_storageAccount.name};EndpointSuffix=${environment().suffixes.storage};AccountKey=${listKeys(eventHubNamespaceName_storageAccount.id, eventHubNamespaceName_storageAccount.apiVersion).keys[0].value}'\n\n// Output our variable\n\noutput blobStorageConnectionString string = blobStorageConnectionString\noutput blobContainerName string = blobContainerName\n")),(0,a.kt)("p",null,"If you just wanted to know how to acquire connection strings from Bicep then you can stop now; we're done! But if you're curious on how the Bicep might connect to ",(0,a.kt)("del",{parentName:"p"},"the shoulder")," Azure Pipelines... Read on."),(0,a.kt)("h2",o({},{id:"from-bicep-to-azure-pipelines"}),"From Bicep to Azure Pipelines"),(0,a.kt)("p",null,"If we put together our snippets above into a single Bicep file it would look like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"// Create an event hub namespace\n\nvar eventHubNamespaceName = 'evhns-demo'\n\nresource eventHubNamespace 'Microsoft.EventHub/namespaces@2021-01-01-preview' = {\n  name: eventHubNamespaceName\n  location: resourceGroup().location\n  sku: {\n    name: 'Standard'\n    tier: 'Standard'\n    capacity: 1\n  }\n  properties: {\n    zoneRedundant: true\n  }\n}\n\n// Create an event hub inside the namespace\n\nvar eventHubName = 'evh-demo'\n\nresource eventHubNamespaceName_eventHubName 'Microsoft.EventHub/namespaces/eventhubs@2021-01-01-preview' = {\n  parent: eventHubNamespace\n  name: eventHubName\n  properties: {\n    messageRetentionInDays: 7\n    partitionCount: 1\n  }\n}\n\n// Grant Listen and Send on our event hub\n\nresource eventHubNamespaceName_eventHubName_ListenSend 'Microsoft.EventHub/namespaces/eventhubs/authorizationRules@2021-01-01-preview' = {\n  parent: eventHubNamespaceName_eventHubName\n  name: 'ListenSend'\n  properties: {\n    rights: [\n      'Listen'\n      'Send'\n    ]\n  }\n  dependsOn: [\n    eventHubNamespace\n  ]\n}\n\n// Create a storage account\n\nvar storageAccountName = 'stdemo'\n\nresource eventHubNamespaceName_storageAccount 'Microsoft.Storage/storageAccounts@2021-02-01' = {\n  name: storageAccountName\n  location: resourceGroup().location\n  sku: {\n    name: 'Standard_LRS'\n    tier: 'Standard'\n  }\n  kind: 'StorageV2'\n  properties: {\n    networkAcls: {\n      bypass: 'AzureServices'\n      defaultAction: 'Allow'\n    }\n    accessTier: 'Hot'\n    allowBlobPublicAccess: false\n    minimumTlsVersion: 'TLS1_2'\n    allowSharedKeyAccess: true\n  }\n}\n\n// create a container inside that storage account\n\nvar blobContainerName = 'test-container'\n\nresource storageAccountName_default_containerName 'Microsoft.Storage/storageAccounts/blobServices/containers@2021-02-01' = {\n  name: '${storageAccountName}/default/${blobContainerName}'\n  dependsOn: [\n    eventHubNamespaceName_storageAccount\n  ]\n}\n\n// Determine our connection strings\n\nvar blobStorageConnectionString       = 'DefaultEndpointsProtocol=https;AccountName=${eventHubNamespaceName_storageAccount.name};EndpointSuffix=${environment().suffixes.storage};AccountKey=${listKeys(eventHubNamespaceName_storageAccount.id, eventHubNamespaceName_storageAccount.apiVersion).keys[0].value}'\nvar eventHubNamespaceConnectionString = listKeys(eventHubNamespaceName_eventHubName_ListenSend.id, eventHubNamespaceName_eventHubName_ListenSend.apiVersion).primaryConnectionString\n\n// Output our variables\n\noutput blobStorageConnectionString string = blobStorageConnectionString\noutput blobContainerName string = blobContainerName\noutput eventHubNamespaceConnectionString string = eventHubNamespaceConnectionString\noutput eventHubName string = eventHubName\n")),(0,a.kt)("p",null,"This might be consumed in an Azure Pipeline that looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- bash: az bicep build --file infra/our-test-app/main.bicep\n  displayName: 'Compile Bicep to ARM'\n\n- task: AzureResourceManagerTemplateDeployment@3\n  name: DeploySharedInfra\n  displayName: Deploy Shared ARM Template\n  inputs:\n    deploymentScope: Resource Group\n    azureResourceManagerConnection: ${{ parameters.serviceConnection }}\n    subscriptionId: $(subscriptionId)\n    action: Create Or Update Resource Group\n    resourceGroupName: $(azureResourceGroup)\n    location: $(location)\n    templateLocation: Linked artifact\n    csmFile: 'infra/our-test-app/main.json' # created by bash script\n    deploymentMode: Incremental\n    deploymentOutputs: deployOutputs\n\n- task: PowerShell@2\n  name: 'SetOutputVariables'\n  displayName: 'Set Output Variables'\n  inputs:\n    targetType: inline\n    script: |\n      $armOutputObj = '$(deployOutputs)' | ConvertFrom-Json\n      $armOutputObj.PSObject.Properties | ForEach-Object {\n        $keyname = $_.Name\n        $value = $_.Value.value\n\n        # Creates a standard pipeline variable\n        Write-Output \"##vso[task.setvariable variable=$keyName;]$value\"\n\n        # Creates an output variable\n        Write-Output \"##vso[task.setvariable variable=$keyName;issecret=true;isOutput=true]$value\"\n\n        # Display keys in pipeline\n        Write-Output \"output variable: $keyName\"\n      }\n    pwsh: true\n")),(0,a.kt)("p",null,"Above we can see:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"the Bicep get compiled to ARM"),(0,a.kt)("li",{parentName:"ul"},"the ARM is deployed to Azure, with ",(0,a.kt)("inlineCode",{parentName:"li"},"deploymentOutputs")," being passed out at the end"),(0,a.kt)("li",{parentName:"ul"},"the outputs are turned into secret output variables inside the pipeline (the names of which are printed to the console)")),(0,a.kt)("p",null,"With the above in place, we now have all of our variables in place; ",(0,a.kt)("inlineCode",{parentName:"p"},"blobStorageConnectionString"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"blobContainerName"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"eventHubNamespaceConnectionString")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"eventHubName"),". These could now be consumed in whatever way is useful. Consider the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- task: UseDotNet@2\n  displayName: 'Install .NET Core SDK 3.1.x'\n  inputs:\n    packageType: 'sdk'\n    version: 3.1.x\n\n- task: DotNetCoreCLI@2\n  displayName: 'dotnet run eventhub test'\n  inputs:\n    command: 'run'\n    arguments: 'eventhub test --eventHubNamespaceConnectionString \"$(eventHubNamespaceConnectionString)\" --eventHubName \"$(eventHubName)\" --blobStorageConnectionString \"$(blobStorageConnectionString)\" --blobContainerName \"$(blobContainerName)\"'\n    workingDirectory: '$(Build.SourcesDirectory)/OurTestApp'\n")),(0,a.kt)("p",null,"Here we run a .NET application and pass it our connection strings. Please note, there's nothing .NET specific about what we're doing above - it could be any kind of application, bash script or similar that consumes our connection strings. The significant thing is that we can acquire connection strings in an automated fashion, for use in whichever manner pleases us."))}d.isMDXComponent=!0},16381:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"webpack-esbuild-why-not-both",title:"webpack? esbuild? Why not both?",authors:"johnnyreilly",tags:["webpack","esbuild","ts-loader","babel-loader"],image:"./webpack-esbuild-why-not-both.webp",hide_table_of_contents:!1},s=void 0,l={permalink:"/webpack-esbuild-why-not-both",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-07-11-webpack-esbuild-why-not-both/index.md",source:"@site/blog/2021-07-11-webpack-esbuild-why-not-both/index.md",title:"webpack? esbuild? Why not both?",description:"Builds can be made faster using tools like esbuild. However, if you're invested in webpack but would still like to take advantage of speedier builds, there is a way. This post takes us through using esbuild alongside webpack using esbuild-loader.",date:"2021-07-11T00:00:00.000Z",formattedDate:"July 11, 2021",tags:[{label:"webpack",permalink:"/tags/webpack"},{label:"esbuild",permalink:"/tags/esbuild"},{label:"ts-loader",permalink:"/tags/ts-loader"},{label:"babel-loader",permalink:"/tags/babel-loader"}],readingTime:7.09,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"webpack-esbuild-why-not-both",title:"webpack? esbuild? Why not both?",authors:"johnnyreilly",tags:["webpack","esbuild","ts-loader","babel-loader"],image:"./webpack-esbuild-why-not-both.webp",hide_table_of_contents:!1},prevItem:{title:"Directory.Build.props: C# 9 for all your projects",permalink:"/directory-build-props-c-sharp-9-for-all"},nextItem:{title:"Output connection strings and keys from Azure Bicep",permalink:"/output-connection-strings-and-keys-from-azure-bicep"}},p={image:n(87690).Z,authorsImageUrls:[void 0]},u=[{value:"Web development",id:"web-development",level:2},{value:"Migrating an existing project to esbuild",id:"migrating-an-existing-project-to-esbuild",level:2},{value:"Creating a baseline application",id:"creating-a-baseline-application",level:2},{value:"CRACO",id:"craco",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Builds can be made faster using tools like ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/evanw/esbuild"}),"esbuild"),". However, if you're invested in ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/webpack"}),"webpack")," but would still like to take advantage of speedier builds, there is a way. This post takes us through using esbuild alongside webpack using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/privatenumber/esbuild-loader"}),"esbuild-loader"),"."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"A screenshot of the &quot;why not both&quot; meme adapted to include webpack and esbuild",src:n(87690).Z,width:"1200",height:"800"})),(0,a.kt)("h2",o({},{id:"web-development"}),"Web development"),(0,a.kt)("p",null,"With apologies to those suffering from JavaScript fatigue, once again the world of web development is evolving. It's long been common practice to run your JavaScript and TypeScript through some kind of Node.js based build tool, like webpack or rollup.js. These tools are written in the same language they compile to; JavaScript (or TypeScript). The new kids on the blog are tools like ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/evanw/esbuild"}),"esbuild"),", ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/vitejs/vite"}),"Vite")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/swc-project/swc"}),"swc"),". The significant difference between these and their predecessors is that they are written in languages like Go and Rust. Go and Rust enjoy far greater performance than JavaScript. This translates into significantly faster builds. If you'd like to read about esbuild directly there's a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/fast-javascript-bundling-with-esbuild/"}),"great post")," about it."),(0,a.kt)("p",null,"These new tools are transformative and represent a likely future of build tooling for the web. In the long term, the likes of esbuild, Vite and friends may well come to displace the current standard build tools. So the webpacks, the rollups and so on."),(0,a.kt)("p",null,"However, that\u2019s the long term. There\u2019s a lot of projects out there that are already heavily invested in their current build tooling. Mostly webpack. Migrating to a new build tool is no small piece of work. New projects might start with Vite, but existing ones are less likely to be ported. There\u2019s a reason webpack is so popular. It does a lot of things very well indeed. It's battle tested on large projects; it's mature and it handles many use cases."),(0,a.kt)("p",null,"So if you\u2019re a team that wants to have faster builds, but doesn\u2019t have the time to go through a big migration... Is there anything you can do? Yes. There\u2019s a middle ground to be explored. There\u2019s a relatively new project named ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/privatenumber/esbuild-loader"}),"esbuild-loader")," developed by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/privatenumbr"}),"hiroki osame"),". It's a webpack loader built on top of esbuild. It allows users to swap out ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"babel-loader")," with itself, and massively improve build speeds."),(0,a.kt)("p",null,"To declare an interest here, I'm the primary maintainer of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/ts-loader"}),"ts-loader"),"; a popular TypeScript loader that is commonly used with webpack. However, I feel strongly that the important thing here is developer productivity. As Node.js-based projects, ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"babel-loader")," will never be able to compete with ",(0,a.kt)("inlineCode",{parentName:"p"},"esbuild-loader")," in the same way. As a language, Go really, uh, goes!"),(0,a.kt)("p",null,"Whilst esbuild may not work for all use cases, it will for the majority. As such ",(0,a.kt)("inlineCode",{parentName:"p"},"esbuild-loader")," represents a middle ground; and an early way to get access to the increased build speed that esbuild offers ",(0,a.kt)("em",{parentName:"p"},"without")," saying goodbye to webpack. This post will look at using ",(0,a.kt)("inlineCode",{parentName:"p"},"esbuild-loader")," in your webpack setup."),(0,a.kt)("h2",o({},{id:"migrating-an-existing-project-to-esbuild"}),"Migrating an existing project to esbuild"),(0,a.kt)("p",null,"It's very straightforward to migrate a project which uses either ",(0,a.kt)("inlineCode",{parentName:"p"},"babel-loader")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader")," to ",(0,a.kt)("inlineCode",{parentName:"p"},"esbuild-loader"),". You install the dependency:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"npm i -D esbuild-loader\n")),(0,a.kt)("p",null,"Then if we are currently using ",(0,a.kt)("inlineCode",{parentName:"p"},"babel-loader"),", we make this change to our ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),"  module.exports = {\n    module: {\n      rules: [\n-       {\n-         test: /\\.js$/,\n-         use: 'babel-loader',\n-       },\n+       {\n+         test: /\\.js$/,\n+         loader: 'esbuild-loader',\n+         options: {\n+           loader: 'jsx',  // Remove this if you're not using JSX\n+           target: 'es2015'  // Syntax to compile to (see options below for possible values)\n+         }\n+       },\n\n        ...\n      ],\n    },\n  }\n")),(0,a.kt)("p",null,"Or if we're using ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-loader"),", we make this change to our ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack.config.js"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),"  module.exports = {\n    module: {\n      rules: [\n-       {\n-         test: /\\.tsx?$/,\n-         use: 'ts-loader'\n-       },\n+       {\n+         test: /\\.tsx?$/,\n+         loader: 'esbuild-loader',\n+         options: {\n+           loader: 'tsx',  // Or 'ts' if you don't need tsx\n+           target: 'es2015'\n+         }\n+       },\n\n        ...\n      ]\n    },\n  }\n")),(0,a.kt)("h2",o({},{id:"creating-a-baseline-application"}),"Creating a baseline application"),(0,a.kt)("p",null,"Let's try ",(0,a.kt)("inlineCode",{parentName:"p"},"esbuild-loader")," out in practice. We're going to create a new React application using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://create-react-app.dev/"}),"Create React App"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"npx create-react-app my-app --template typescript\n")),(0,a.kt)("p",null,"This will scaffold out a new React application using TypeScript in the ",(0,a.kt)("inlineCode",{parentName:"p"},"my-app")," directory. It's worth knowing that Create React App uses ",(0,a.kt)("inlineCode",{parentName:"p"},"babel-loader")," behind the scenes."),(0,a.kt)("p",null,"CRA also uses the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/TypeStrong/fork-ts-checker-webpack-plugin"}),"fork-ts-checker-webpack-plugin")," to provide TypeScript type checking. This is very useful, as esbuild ",(0,a.kt)("em",{parentName:"p"},"just")," does transpilation and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://esbuild.github.io/faq/#upcoming-roadmap"}),"does not intend to provide type checking support"),". So it's tremendous we still have that plugin in place as otherwise we would lose type checking."),(0,a.kt)("p",null,"So we can understand the advantage of moving to esbuild, we first need a baseline to understand what performance looks like with babel-loader. We'll run ",(0,a.kt)("inlineCode",{parentName:"p"},"time npm run build")," to execute a build of our simple app:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A screenshot of the completed build for Create React App",src:n(19960).Z,width:"987",height:"699"})),(0,a.kt)("p",null,"Our complete build, TypeScript type checking, transpilation, minification and so on, all took 22.08 seconds. The question now is, what will happen if we drop esbuild into the mix?"),(0,a.kt)("h2",o({},{id:"craco"}),"CRACO"),(0,a.kt)("p",null,"One way to customise a Create React App build is by running ",(0,a.kt)("inlineCode",{parentName:"p"},"npm run eject")," and then customising the code that CRA pumps out. Doing so is fine, but it means you can't keep track with CRA's evolution. An alternative is to use a tool like ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/gsoft-inc/craco"}),"CRACO")," which allows us to tweak configuration in place. It describes itself this way:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("em",{parentName:"p"},"C"),"reate ",(0,a.kt)("em",{parentName:"p"},"R"),"eact ",(0,a.kt)("em",{parentName:"p"},"A"),"pp ",(0,a.kt)("em",{parentName:"p"},"C"),"onfiguration ",(0,a.kt)("em",{parentName:"p"},"O"),"verride is an easy and comprehensible configuration layer for create-react-app.")),(0,a.kt)("p",null,"We're going to use CRACO, so we'll add ",(0,a.kt)("inlineCode",{parentName:"p"},"esbuild-loader")," and CRACO as dependencies:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"npm install @craco/craco esbuild-loader --save-dev\n")),(0,a.kt)("p",null,"Then we'll swap over our various ",(0,a.kt)("inlineCode",{parentName:"p"},"scripts")," in our ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," to use ",(0,a.kt)("inlineCode",{parentName:"p"},"CRACO"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"start": "craco start",\n"build": "craco build",\n"test": "craco test",\n')),(0,a.kt)("p",null,"Our app now uses CRACO, but we haven't yet configured it. So we'll add a ",(0,a.kt)("inlineCode",{parentName:"p"},"craco.config.js")," file to the root of our project. This is where we swap out ",(0,a.kt)("inlineCode",{parentName:"p"},"babel-loader")," for ",(0,a.kt)("inlineCode",{parentName:"p"},"esbuild-loader"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const {\n  addAfterLoader,\n  removeLoaders,\n  loaderByName,\n  getLoaders,\n  throwUnexpectedConfigError,\n} = require('@craco/craco');\nconst { ESBuildMinifyPlugin } = require('esbuild-loader');\n\nconst throwError = (message) =>\n  throwUnexpectedConfigError({\n    packageName: 'craco',\n    githubRepo: 'gsoft-inc/craco',\n    message,\n    githubIssueQuery: 'webpack',\n  });\n\nmodule.exports = {\n  webpack: {\n    configure: (webpackConfig, { paths }) => {\n      const { hasFoundAny, matches } = getLoaders(\n        webpackConfig,\n        loaderByName('babel-loader')\n      );\n      if (!hasFoundAny) throwError('failed to find babel-loader');\n\n      console.log('removing babel-loader');\n      const { hasRemovedAny, removedCount } = removeLoaders(\n        webpackConfig,\n        loaderByName('babel-loader')\n      );\n      if (!hasRemovedAny) throwError('no babel-loader to remove');\n      if (removedCount !== 2)\n        throwError('had expected to remove 2 babel loader instances');\n\n      console.log('adding esbuild-loader');\n\n      const tsLoader = {\n        test: /\\.(js|mjs|jsx|ts|tsx)$/,\n        include: paths.appSrc,\n        loader: require.resolve('esbuild-loader'),\n        options: {\n          loader: 'tsx',\n          target: 'es2015',\n        },\n      };\n\n      const { isAdded: tsLoaderIsAdded } = addAfterLoader(\n        webpackConfig,\n        loaderByName('url-loader'),\n        tsLoader\n      );\n      if (!tsLoaderIsAdded) throwError('failed to add esbuild-loader');\n      console.log('added esbuild-loader');\n\n      console.log('adding non-application JS babel-loader back');\n      const { isAdded: babelLoaderIsAdded } = addAfterLoader(\n        webpackConfig,\n        loaderByName('esbuild-loader'),\n        matches[1].loader // babel-loader\n      );\n      if (!babelLoaderIsAdded)\n        throwError('failed to add back babel-loader for non-application JS');\n      console.log('added non-application JS babel-loader back');\n\n      console.log('replacing TerserPlugin with ESBuildMinifyPlugin');\n      webpackConfig.optimization.minimizer = [\n        new ESBuildMinifyPlugin({\n          target: 'es2015',\n        }),\n      ];\n\n      return webpackConfig;\n    },\n  },\n};\n")),(0,a.kt)("p",null,"So what's happening here? The script looks for ",(0,a.kt)("inlineCode",{parentName:"p"},"babel-loader")," usages in the default Create React App config. There will be two; one for TypeScript / JavaScript application code (we want to replace this) and one for non application JavaScript code. It's not too clear what non application JavaScript code there is or can be, so we'll leave it in place; it may be important. Significantly, the code we care about is the application code."),(0,a.kt)("p",null,"You cannot remove a ",(0,a.kt)("em",{parentName:"p"},"single")," loader using ",(0,a.kt)("inlineCode",{parentName:"p"},"CRACO"),", so instead we'll remove both and we'll add back the non application JavaScript ",(0,a.kt)("inlineCode",{parentName:"p"},"babel-loader"),". We'll also add ",(0,a.kt)("inlineCode",{parentName:"p"},"esbuild-loader")," with the ",(0,a.kt)("inlineCode",{parentName:"p"},"{ loader: 'tsx', target: 'es2015' }")," option set (to ensure we can process JSX/TSX)."),(0,a.kt)("p",null,"Finally we'll swap out using Terser for JavaScript minification for esbuild as well."),(0,a.kt)("p",null,"Our migration is complete. The next time we build we'll have Create React App running using ",(0,a.kt)("inlineCode",{parentName:"p"},"esbuild-loader")," ",(0,a.kt)("em",{parentName:"p"},"without")," having ejected. Once again we'll run ",(0,a.kt)("inlineCode",{parentName:"p"},"time npm run build")," to execute a build of our simple app and determine how long it takes:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A screenshot of the completed build for Create React App with esbuild",src:n(19895).Z,width:"953",height:"694"})),(0,a.kt)("p",null,"Our complete build, TypeScript type checking, transpilation, minification and so on, all took 13.85 seconds. By migrating to ",(0,a.kt)("inlineCode",{parentName:"p"},"esbuild-loader")," we've reduced our overall compilation time by approximately one third; this is a tremendous improvement!"),(0,a.kt)("p",null,"As your codebase scales and your application grows, compilation time can skyrocket also. With ",(0,a.kt)("inlineCode",{parentName:"p"},"esbuild-loader")," you should get ongoing benefits to your build time."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/webpack-or-esbuild-why-not-both/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/webpack-or-esbuild-why-not-both/"})))}d.isMDXComponent=!0},71560:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"directory-build-props-c-sharp-9-for-all",title:"Directory.Build.props: C# 9 for all your projects",authors:"johnnyreilly",tags:["Directory.Build.props","C#",".NET"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/directory-build-props-c-sharp-9-for-all",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-07-14-directory-build-props-c-sharp-9-for-all/index.md",source:"@site/blog/2021-07-14-directory-build-props-c-sharp-9-for-all/index.md",title:"Directory.Build.props: C# 9 for all your projects",description:".NET Core can make use of C# 9 by making some changes to your .csproj files. There is a way to opt all projects in a solution into this behaviour in a single place, through using a Directory.Build.props file and / or a Directory.Build.targets file. Here's how to do it.",date:"2021-07-14T00:00:00.000Z",formattedDate:"July 14, 2021",tags:[{label:"Directory.Build.props",permalink:"/tags/directory-build-props"},{label:"C#",permalink:"/tags/c"},{label:".NET",permalink:"/tags/net"}],readingTime:1.94,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"directory-build-props-c-sharp-9-for-all",title:"Directory.Build.props: C# 9 for all your projects",authors:"johnnyreilly",tags:["Directory.Build.props","C#",".NET"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"TypeScript, abstract classes, and constructors",permalink:"/typescript-abstract-classes-and-constructors"},nextItem:{title:"webpack? esbuild? Why not both?",permalink:"/webpack-esbuild-why-not-both"}},p={image:n(32172).Z,authorsImageUrls:[void 0]},u=[{value:"&quot;have you the good news about <code>Directory.Build.props</code>&quot;?",id:"have-you-the-good-news-about-directorybuildprops",level:2},{value:"<code>Directory.Build.props</code>: C# 9 for all",id:"directorybuildprops-c-9-for-all",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,".NET Core can make use of C# 9 by making some changes to your ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj")," files. There is a way to opt all projects in a solution into this behaviour in a ",(0,a.kt)("em",{parentName:"p"},"single")," place, through using a ",(0,a.kt)("inlineCode",{parentName:"p"},"Directory.Build.props")," file and / or a ",(0,a.kt)("inlineCode",{parentName:"p"},"Directory.Build.targets")," file. Here's how to do it."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image showing name of post and the C# logo",src:n(32172).Z,width:"1366",height:"548"})),(0,a.kt)("h2",o({},{id:"have-you-the-good-news-about-directorybuildprops"}),'"have you the good news about ',(0,a.kt)("inlineCode",{parentName:"h2"},"Directory.Build.props"),'"?'),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"/c-sharp-9-azure-functions-in-process"}),"I wrote recently about using C# 9 with in-process Azure Functions.")," What that amounted to, was using C# 9 with .NET Core."),(0,a.kt)("p",null,"One of the best things about blogging, is all that you get to learn along the way. After I put up that post, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/danielearwicker"}),"Daniel Earwicker")," was kind enough to send this message:"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/danielearwicker/status/1412678642203828226"}),(0,a.kt)("img",{loading:"lazy",alt:"title image showing name of post and the C# logo",src:n(2898).Z,width:"1200",height:"950"}))),(0,a.kt)("p",null,"I was intrigued that Daniel was able to configure all the projects in a solution to use the same approach using some strange incantations named ",(0,a.kt)("inlineCode",{parentName:"p"},"Directory.Build.props")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"Directory.Build.targets"),". ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/visualstudio/msbuild/customize-your-build?view=vs-2019#directorybuildprops-and-directorybuildtargets"}),"Microsoft describes them thusly"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Prior to MSBuild version 15, if you wanted to provide a new, custom property to projects in your solution, you had to manually add a reference to that property to every project file in the solution. Or, you had to define the property in a ",(0,a.kt)("inlineCode",{parentName:"p"},".props")," file and then explicitly import the ",(0,a.kt)("inlineCode",{parentName:"p"},".props")," file in every project in the solution, among other things."),(0,a.kt)("p",{parentName:"blockquote"},"However, now you can add a new property to every project in one step by defining it in a single file called ",(0,a.kt)("inlineCode",{parentName:"p"},"Directory.Build.props")," in the root folder that contains your source.")),(0,a.kt)("p",null,"Let's see if we can put it to use."),(0,a.kt)("h2",o({},{id:"directorybuildprops-c-9-for-all"}),(0,a.kt)("inlineCode",{parentName:"h2"},"Directory.Build.props"),": C# 9 for all"),(0,a.kt)("p",null,"So, rather than us updating each of our ",(0,a.kt)("inlineCode",{parentName:"p"},".csproj")," files, we should be able to create a ",(0,a.kt)("inlineCode",{parentName:"p"},"Directory.Build.props")," file to sit alongside our ",(0,a.kt)("inlineCode",{parentName:"p"},".sln")," file in the root of our source code. We'll add this into the file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<Project>\n <PropertyGroup>\n    \x3c!-- use C# 9 --\x3e\n    <LangVersion>9.0</LangVersion>\n </PropertyGroup>\n <ItemGroup>\n    \x3c!-- allows some C# 9 support with .NET Core 3.1 https://github.com/manuelroemer/IsExternalInit --\x3e\n    <PackageReference Include="IsExternalInit" Version="1.0.1">\n      <IncludeAssets>runtime; build; native; contentfiles; analyzers; buildtransitive</IncludeAssets>\n      <PrivateAssets>all</PrivateAssets>\n    </PackageReference>\n  </ItemGroup>\n</Project>\n')),(0,a.kt)("p",null,"Now we're free to add projects into the solution, which will ",(0,a.kt)("em",{parentName:"p"},"already")," support C# 9 without us taking any further steps. It's as simple as that! Thanks to Daniel for sharing this super handy tip. \u2764\ufe0f\ud83c\udf3b"))}d.isMDXComponent=!0},14425:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-abstract-classes-and-constructors",title:"TypeScript, abstract classes, and constructors",authors:"johnnyreilly",tags:["typescript"],image:"./vs-code-abstract-screenshot.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-abstract-classes-and-constructors",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-08-01-typescript-abstract-classes-and-constructors/index.md",source:"@site/blog/2021-08-01-typescript-abstract-classes-and-constructors/index.md",title:"TypeScript, abstract classes, and constructors",description:"TypeScript has the ability to define classes as abstract. This means they cannot be instantiated directly, only non-abstract subclasses can be. Let's take a look at what this means when it comes to constructor usage.",date:"2021-08-01T00:00:00.000Z",formattedDate:"August 1, 2021",tags:[{label:"typescript",permalink:"/tags/typescript"}],readingTime:4.7,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-abstract-classes-and-constructors",title:"TypeScript, abstract classes, and constructors",authors:"johnnyreilly",tags:["typescript"],image:"./vs-code-abstract-screenshot.png",hide_table_of_contents:!1},prevItem:{title:"TypeScript 4.4 and more readable code",permalink:"/typescript-4-4-more-readable-code"},nextItem:{title:"Directory.Build.props: C# 9 for all your projects",permalink:"/directory-build-props-c-sharp-9-for-all"}},p={image:n(10489).Z,authorsImageUrls:[void 0]},u=[{value:"Making a scratchpad",id:"making-a-scratchpad",level:2},{value:"Making an abstract class",id:"making-an-abstract-class",level:2},{value:"Taking our abstract class for a spin",id:"taking-our-abstract-class-for-a-spin",level:2},{value:"Subclassing without a new constructor",id:"subclassing-without-a-new-constructor",level:2},{value:"Subclassing with a new constructor",id:"subclassing-with-a-new-constructor",level:2},{value:"Wrapping it up",id:"wrapping-it-up",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"TypeScript has the ability to define classes as abstract. This means they cannot be instantiated directly, only non-abstract subclasses can be. Let's take a look at what this means when it comes to constructor usage."),(0,a.kt)("h2",o({},{id:"making-a-scratchpad"}),"Making a scratchpad"),(0,a.kt)("p",null,"In order that we can dig into this, let's create ourselves a scratchpad project to work with. We're going to create a node project and install TypeScript as a dependency."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"mkdir ts-abstract-constructors\ncd ts-abstract-constructors\nnpm init --yes\nnpm install typescript @types/node --save-dev\n")),(0,a.kt)("p",null,"We now have a ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," file set up. We need to initialise a TypeScript project as well:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"npx tsc --init\n")),(0,a.kt)("p",null,"This will give us a ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," file that will drive configuration of TypeScript. By default TypeScript transpiles to an older version of JavaScript that predates classes. So we'll update the config to target a newer version of the language that does include them:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'    "target": "es2020",\n    "lib": ["es2020"],\n')),(0,a.kt)("p",null,"Let's create ourselves a TypeScript file called ",(0,a.kt)("inlineCode",{parentName:"p"},"index.ts"),". The name is not significant; we just need a file to develop in."),(0,a.kt)("p",null,"Finally we'll add a script to our ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," that compiles our TypeScript to JavaScript, and then runs the JS with node:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"start": "tsc --project \\".\\" && node index.js"\n')),(0,a.kt)("h2",o({},{id:"making-an-abstract-class"}),"Making an abstract class"),(0,a.kt)("p",null,"Now we're ready. Let's add an abstract class with a constructor to our ",(0,a.kt)("inlineCode",{parentName:"p"},"index.ts")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"abstract class ViewModel {\n  id: string;\n\n  constructor(id: string) {\n    this.id = id;\n  }\n}\n")),(0,a.kt)("p",null,"Consider the ",(0,a.kt)("inlineCode",{parentName:"p"},"ViewModel")," class above. Let's say we're building some kind of CRUD app, we'll have different views. Each of those views will have a corresponding viewmodel which is a subclass of the ",(0,a.kt)("inlineCode",{parentName:"p"},"ViewModel")," abstract class. The ",(0,a.kt)("inlineCode",{parentName:"p"},"ViewModel")," class has a mandatory ",(0,a.kt)("inlineCode",{parentName:"p"},"id")," parameter in the constructor. This is to ensure that every viewmodel has an ",(0,a.kt)("inlineCode",{parentName:"p"},"id")," value. If this were a real app, ",(0,a.kt)("inlineCode",{parentName:"p"},"id")," would likely be the value with which an entity was looked up in some kind of database."),(0,a.kt)("p",null,"Importantly, all subclasses of ",(0,a.kt)("inlineCode",{parentName:"p"},"ViewModel")," should either:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"not implement a constructor at all, leaving the base class constructor to become the default constructor of the subclass ",(0,a.kt)("em",{parentName:"p"},"or"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"implement their own constructor which invokes the ",(0,a.kt)("inlineCode",{parentName:"p"},"ViewModel")," base class constructor."))),(0,a.kt)("h2",o({},{id:"taking-our-abstract-class-for-a-spin"}),"Taking our abstract class for a spin"),(0,a.kt)("p",null,"Now we have it, let's see what we can do with our abstract class. First of all, can we instantiate our abstract class? We shouldn't be able to do this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"const viewModel = new ViewModel('my-id');\n\nconsole.log(`the id is: ${viewModel.id}`);\n")),(0,a.kt)("p",null,"And sure enough, running ",(0,a.kt)("inlineCode",{parentName:"p"},"npm start")," results in the following error (which is also being reported by our editor; VS Code)."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"index.ts:9:19 - error TS2511: Cannot create an instance of an abstract class.\n\nconst viewModel = new ViewModel('my-id');\n")),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"Screenshot of &quot;Cannot create an instance of an abstract class.&quot; error in VS Code",src:n(10489).Z,width:"1197",height:"417"})),(0,a.kt)("p",null,"Tremendous. However, it's worth remembering that ",(0,a.kt)("inlineCode",{parentName:"p"},"abstract")," is a TypeScript concept. When we compile our TS, although it's throwing a compilation error, it still transpiles an ",(0,a.kt)("inlineCode",{parentName:"p"},"index.js")," file that looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"'use strict';\nclass ViewModel {\n  constructor(id) {\n    this.id = id;\n  }\n}\nconst viewModel = new ViewModel('my-id');\nconsole.log(`the id is: ${viewModel.id}`);\n")),(0,a.kt)("p",null,"As we can see, there's no mention of ",(0,a.kt)("inlineCode",{parentName:"p"},"abstract"),"; it's just a straightforward ",(0,a.kt)("inlineCode",{parentName:"p"},"class"),". In fact, if we directly execute the file with ",(0,a.kt)("inlineCode",{parentName:"p"},"node index.js")," we can see an output of:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"the id is: my-id\n")),(0,a.kt)("p",null,"So the transpiled code is valid JavaScript even if the source code isn't valid TypeScript. This all reminds us that ",(0,a.kt)("inlineCode",{parentName:"p"},"abstract")," is a TypeScript construct."),(0,a.kt)("h2",o({},{id:"subclassing-without-a-new-constructor"}),"Subclassing without a new constructor"),(0,a.kt)("p",null,"Let's now create our first subclass of ",(0,a.kt)("inlineCode",{parentName:"p"},"ViewModel")," and attempt to instantiate it:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"class NoNewConstructorViewModel extends ViewModel {}\n\n// error TS2554: Expected 1 arguments, but got 0.\nconst viewModel1 = new NoNewConstructorViewModel();\n\nconst viewModel2 = new NoNewConstructorViewModel('my-id');\n")),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of &quot;error TS2554: Expected 1 arguments, but got 0.&quot; error in VS Code",src:n(57773).Z,width:"1476",height:"613"})),(0,a.kt)("p",null,"As the TypeScript compiler tells us, the second of these instantiations is legitimate as it relies upon the constructor from the base class as we'd hope. The first is not as there is no parameterless constructor."),(0,a.kt)("h2",o({},{id:"subclassing-with-a-new-constructor"}),"Subclassing with a new constructor"),(0,a.kt)("p",null,"Having done that, let's try subclassing and implementing a new constructor which has two parameters (to differentiate from the constructor we're overriding):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"class NewConstructorViewModel extends ViewModel {\n  data: string;\n  constructor(id: string, data: string) {\n    super(id);\n    this.data = data;\n  }\n}\n\n// error TS2554: Expected 2 arguments, but got 0.\nconst viewModel3 = new NewConstructorViewModel();\n\n// error TS2554: Expected 2 arguments, but got 1.\nconst viewModel4 = new NewConstructorViewModel('my-id');\n\nconst viewModel5 = new NewConstructorViewModel('my-id', 'important info');\n")),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of &quot;error TS2554: Expected 1 arguments, but got 1.&quot; error in VS Code",src:n(3597).Z,width:"1633",height:"897"})),(0,a.kt)("p",null,"Again, only one of the attempted instantiations is legitimate. ",(0,a.kt)("inlineCode",{parentName:"p"},"viewModel3")," is not as there is no parameterless constructor. ",(0,a.kt)("inlineCode",{parentName:"p"},"viewModel4")," is not as we have overridden the base class constructor with our new one that has two parameters. Hence ",(0,a.kt)("inlineCode",{parentName:"p"},"viewModel5"),' is our "Goldilocks" instantiation; it\'s just right!'),(0,a.kt)("p",null,"It's also worth noting that we're calling ",(0,a.kt)("inlineCode",{parentName:"p"},"super")," in the ",(0,a.kt)("inlineCode",{parentName:"p"},"NewConstructorViewModel")," constructor. This invokes the constructor of the ",(0,a.kt)("inlineCode",{parentName:"p"},"ViewModel"),' base (or "super") class. TypeScript enforces that we pass the appropriate arguments (in our case a single ',(0,a.kt)("inlineCode",{parentName:"p"},"string"),")."),(0,a.kt)("h2",o({},{id:"wrapping-it-up"}),"Wrapping it up"),(0,a.kt)("p",null,"We've seen that TypeScript ensures correct usage of constructors when we have an abstract class. Importantly, all subclasses of abstract classes either:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"do not implement a constructor at all, leaving the base class constructor (the abstract constructor) to become the default constructor of the subclass ",(0,a.kt)("em",{parentName:"p"},"or"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},'implement their own constructor which invokes the base (or "super") class constructor with the correct arguments.'))),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/typescript-abstract-classes-and-constructors/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/typescript-abstract-classes-and-constructors/"})))}d.isMDXComponent=!0},79844:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-4-4-more-readable-code",title:"TypeScript 4.4 and more readable code",authors:"johnnyreilly",tags:["typescript"],image:"./reactions-on-github.webp",hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-4-4-more-readable-code",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-08-14-typescript-4-4-more-readable-code/index.md",source:"@site/blog/2021-08-14-typescript-4-4-more-readable-code/index.md",title:"TypeScript 4.4 and more readable code",description:'An exciting feature is shipping with TypeScript 4.4. It has the name "Control Flow Analysis of Aliased Conditions" which is quite a mouthful. This post unpacks what this feature is, and demonstrates the contribution it makes to improving the readability of code.',date:"2021-08-14T00:00:00.000Z",formattedDate:"August 14, 2021",tags:[{label:"typescript",permalink:"/tags/typescript"}],readingTime:4.1,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-4-4-more-readable-code",title:"TypeScript 4.4 and more readable code",authors:"johnnyreilly",tags:["typescript"],image:"./reactions-on-github.webp",hide_table_of_contents:!1},prevItem:{title:"Publish Azure Static Web Apps with Bicep and Azure DevOps",permalink:"/bicep-azure-static-web-apps-azure-devops"},nextItem:{title:"TypeScript, abstract classes, and constructors",permalink:"/typescript-abstract-classes-and-constructors"}},p={image:n(92688).Z,authorsImageUrls:[void 0]},u=[{value:"Updated 30th September 2021",id:"updated-30th-september-2021",level:2},{value:"Indirect type narrowing via <code>const</code>",id:"indirect-type-narrowing-via-const",level:2},{value:"The code we would like to write",id:"the-code-we-would-like-to-write",level:2},{value:"Read more",id:"read-more",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"An exciting feature is shipping with TypeScript 4.4. It has the name ",(0,a.kt)("a",o({parentName:"p"},{href:"https://devblogs.microsoft.com/typescript/announcing-typescript-4-4-beta/#cfa-aliased-conditions"}),'"Control Flow Analysis of Aliased Conditions"')," which is quite a mouthful. This post unpacks what this feature is, and demonstrates the contribution it makes to improving the readability of code."),(0,a.kt)("h2",o({},{id:"updated-30th-september-2021"}),"Updated 30th September 2021"),(0,a.kt)("p",null,"This blog evolved to become a talk:"),(0,a.kt)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/LxZx3ycrxI0",title:"YouTube video player",frameBorder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowFullScreen:!0}),(0,a.kt)("h2",o({},{id:"indirect-type-narrowing-via-const"}),"Indirect type narrowing via ",(0,a.kt)("inlineCode",{parentName:"h2"},"const")),(0,a.kt)("p",null,'On June 24th 2021, an issue on the TypeScript GitHub repository with the title "Indirect type narrowing via ',(0,a.kt)("inlineCode",{parentName:"p"},"const"),'" was closed by ',(0,a.kt)("a",o({parentName:"p"},{href:"https://www.twitter.com/ahejlsberg"}),"Anders Hejlsberg"),". The issue had been open since 2016 and it was closed as it was covered by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/TypeScript/pull/44730"}),"a pull request addressing control flow analysis of aliased conditional expressions and discriminants"),"."),(0,a.kt)("p",null,"It's fair to say that the TypeScript community was very excited about this, both judging from reactions on the issue:"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/TypeScript/issues/12184#issuecomment-867928408"}),(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"Screenshot of reactions on GitHub",src:n(92688).Z,width:"1998",height:"2018"}))),(0,a.kt)("p",null,"And also the general delight on Twitter:"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://www.twitter.com/johnny_reilly/status/1408162514504933378"}),(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of reactions on Twitter",src:n(96731).Z,width:"1161",height:"1584"}))),(0,a.kt)("p",null,"What Zeh said is a great explanation of the significance of this feature:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Lack of type narrowing with consts made me repeat code, or avoid helpfully namef consts, too many times")),(0,a.kt)("p",null,"With this feature we're going to have the possibility of more readable code, and less repetition. That's amazing!"),(0,a.kt)("h2",o({},{id:"the-code-we-would-like-to-write"}),"The code we would like to write"),(0,a.kt)("p",null,"Rather than starting with an explanation of what this new language feature is, let's instead start from the position of writing some code and seeing what's possible with TypeScript 4.4 that we couldn't tackle previously."),(0,a.kt)("p",null,"Here's a simple function that adds all the parameters it receives and returns the total. It's a tolerant function and will allow people to supply numbers in the form of strings as well; so it would successfully process ",(0,a.kt)("inlineCode",{parentName:"p"},"'2'")," as it would ",(0,a.kt)("inlineCode",{parentName:"p"},"2"),". This is, of course, a slightly contrived example, but should be useful for demonstrating the new feature."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"function add(...thingsToAdd: (string | number)[]): number {\n  let total = 0;\n  for (const thingToAdd of thingsToAdd) {\n    if (typeof thingToAdd === 'string') {\n      total += Number(thingToAdd);\n    } else {\n      total += thingToAdd;\n    }\n  }\n  return total;\n}\n\nconsole.log(add(1, '7', '3', 9));\n")),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/play?ts=4.3.5#code/GYVwdgxgLglg9mABAQwCaoBQDodQBYxgDmAzgCpwCC6AXIhiVAE6FGIA+iYIAtgEYBTJgEoA2gF1hdbvyGIA3gChEKxABsBURFDhRkaxAF5EABgDcy1cDhN6EBI20FiFaqkRxgT1uSrphCpaqqjBeGFAAngAOAp7eLn7uhsmIAOSMLMSpAUrBeao6egYA1MYAcryCTOHORK7+FvkqAL6IAmokAoFNeYX6iKXxdYmNTc1BiOPBTJogTEh9ahbjivZgJHAaWGpwRBhomACMADRpAOypp6kAzJeIAJzCwkA"}),"Try it out in the TypeScript playground.")),(0,a.kt)("p",null,"If we look at this function, whilst it works, it's not super expressive. The ",(0,a.kt)("inlineCode",{parentName:"p"},"typeof thingToAdd === 'string'")," performs two purposes:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"It narrows the type from ",(0,a.kt)("inlineCode",{parentName:"li"},"string | number")," to ",(0,a.kt)("inlineCode",{parentName:"li"},"string")),(0,a.kt)("li",{parentName:"ol"},"It branches the logic, such that the ",(0,a.kt)("inlineCode",{parentName:"li"},"string")," can be coerced into a ",(0,a.kt)("inlineCode",{parentName:"li"},"number")," and added to the total.")),(0,a.kt)("p",null,"You can infer this from reading the code. However, what if we were to re-write it to capture intent? Let's try creating a ",(0,a.kt)("inlineCode",{parentName:"p"},"shouldCoerceToNumber")," constant which expresses the action we need to take:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"function add(...thingsToAdd: (string | number)[]): number {\n  let total = 0;\n  for (const thingToAdd of thingsToAdd) {\n    const shouldCoerceToNumber = typeof thingToAdd === 'string';\n    if (shouldCoerceToNumber) {\n      total += Number(thingToAdd);\n    } else {\n      total += thingToAdd;\n    }\n  }\n  return total;\n}\n\nconsole.log(add(1, '7', '3', 9));\n")),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/play?ts=4.3.5#code/GYVwdgxgLglg9mABAQwCaoBQDodQBYxgDmAzgCpwCC6AXIhiVAE6FGIA+iYIAtgEYBTJgEoA2gF1hdbvyGIA3gChEKxABsBURFDhRkaxAF5EABgDcy1cDhN6EBI20FiFaqkRxgT1uSrphCpaqqvZgjiR4cCBqqADCcEIQAhQAcryCtsZQAJ4ADgKe3i5+7oZliADkjCzEFRbBwTBeDJHRcQlMSanpQgFKDQPauvqIANTGabJMGPisrv71gwC+iAJqJAKBgw06egbjRUTzqIsDS0GI58FMmiBMSLv6FueKoSRwGlhqcEQYaJgARgANJUAOwVEEVADMEMQAE5hMIgA"}),"Try it out in the TypeScript playground.")),(0,a.kt)("p",null,"This is valid code; however TypeScript 4.3 is choking with an error:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the TypeScript playground running TypeScript 4.3 and throwing an error on our new code",src:n(86243).Z,width:"1716",height:"869"})),(0,a.kt)("p",null,"The error being surfaced is:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("inlineCode",{parentName:"p"},"Operator '+=' cannot be applied to types 'number' and 'string | number'.(2365)"))),(0,a.kt)("p",null,"What's happening here, is TypeScript ",(0,a.kt)("em",{parentName:"p"},"does not remember")," that ",(0,a.kt)("inlineCode",{parentName:"p"},"shouldCoerceToNumber")," represents a type narrowing of ",(0,a.kt)("inlineCode",{parentName:"p"},"thingToAdd")," from ",(0,a.kt)("inlineCode",{parentName:"p"},"string | number")," to ",(0,a.kt)("inlineCode",{parentName:"p"},"string"),". So the type of ",(0,a.kt)("inlineCode",{parentName:"p"},"thingToAdd")," remains unchanged from ",(0,a.kt)("inlineCode",{parentName:"p"},"string | number")," when we write code that depends upon it."),(0,a.kt)("p",null,"This has terrible consequences. It means we can't write this more expressive code that we're interested in, and would be better for maintainers of our codebase. And this is what TypeScript 4.4, with our new feature, unlocks. Let's change the playground to use TypeScript 4.4 instead:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the TypeScript playground running TypeScript 4.4 and working with our new code - it shows the `thingToAdd` variable has been narrowed to a `string`",src:n(71276).Z,width:"1324",height:"858"})),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/play?ts=4.4.0-beta#code/GYVwdgxgLglg9mABAQwCaoBQDodQBYxgDmAzgCpwCC6AXIhiVAE6FGIA+iYIAtgEYBTJgEoA2gF1hdbvyGIA3gChEKxABsBURFDhRkaxAF5EABgDcy1cDhN6EBI20FiFaqkRxgT1uSrphCpaqqvZgjiR4cCBqqADCcEIQAhQAcryCtsZQAJ4ADgKe3i5+7oZliADkjCzEFRbBwTBeDJHRcQlMSanpQgFKDQPauvqIANTGabJMGPisrv71gwC+iAJqJAKBgw06egbjRUTzqIsDS0GI58FMmiBMSLv6FueKoSRwGlhqcEQYaJgARgANJUAOwVEEVADMEMQAE5hMIgA"}),"Try it out in the TypeScript playground.")),(0,a.kt)("p",null,"Delightfully, we no longer have errors now we've made the switch. And as the screenshot shows, the ",(0,a.kt)("inlineCode",{parentName:"p"},"thingToAdd")," variable has been narrowed to a ",(0,a.kt)("inlineCode",{parentName:"p"},"string"),". This is because Control Flow Analysis of Aliased Conditions is now in play."),(0,a.kt)("p",null,"So we're now writing more expressive code, and TypeScript is willing us on our way."),(0,a.kt)("h2",o({},{id:"read-more"}),"Read more"),(0,a.kt)("p",null,"This feature is a tremendous addition to the TypeScript language. It should have a significant long-term positive impact on how people write code with TypeScript."),(0,a.kt)("p",null,"To read more, do check out the excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"https://devblogs.microsoft.com/typescript/announcing-typescript-4-4-beta/#cfa-aliased-conditions"}),"TypeScript 4.4 beta release notes"),". There's also some other exciting feature shipping with this release as well. Thanks very much to the TypeScript team for once again improving the language, and making a real contribution to people being able to write readable code."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/typescript-4-4-and-more-readable-code/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/typescript-4-4-and-more-readable-code/"})))}d.isMDXComponent=!0},81635:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"bicep-azure-static-web-apps-azure-devops",title:"Publish Azure Static Web Apps with Bicep and Azure DevOps",authors:"johnnyreilly",tags:["Azure Static Web Apps","Bicep","azure devops","Azure Pipelines"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/bicep-azure-static-web-apps-azure-devops",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-08-15-bicep-azure-static-web-apps-azure-devops/index.md",source:"@site/blog/2021-08-15-bicep-azure-static-web-apps-azure-devops/index.md",title:"Publish Azure Static Web Apps with Bicep and Azure DevOps",description:'This post demonstrates how to deploy Azure Static Web Apps using Bicep and Azure DevOps. It includes a few workarounds for the "Provider is invalid. Cannot change the Provider. Please detach your static site first if you wish to use to another deployment provider." issue.',date:"2021-08-15T00:00:00.000Z",formattedDate:"August 15, 2021",tags:[{label:"Azure Static Web Apps",permalink:"/tags/azure-static-web-apps"},{label:"Bicep",permalink:"/tags/bicep"},{label:"azure devops",permalink:"/tags/azure-devops"},{label:"Azure Pipelines",permalink:"/tags/azure-pipelines"}],readingTime:4.395,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"bicep-azure-static-web-apps-azure-devops",title:"Publish Azure Static Web Apps with Bicep and Azure DevOps",authors:"johnnyreilly",tags:["Azure Static Web Apps","Bicep","azure devops","Azure Pipelines"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"Bicep: syntax highlighting with PrismJS (and Docusaurus)",permalink:"/bicep-syntax-highlighting-with-prismjs"},nextItem:{title:"TypeScript 4.4 and more readable code",permalink:"/typescript-4-4-more-readable-code"}},p={image:n(82116).Z,authorsImageUrls:[void 0]},u=[{value:"Bicep template",id:"bicep-template",level:2},{value:"Static Web App",id:"static-web-app",level:2},{value:"Azure Pipeline",id:"azure-pipeline",level:2},{value:"<code>Provider is invalid</code> workaround 2",id:"provider-is-invalid-workaround-2",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This post demonstrates how to deploy ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/static-web-apps/overview"}),"Azure Static Web Apps")," using Bicep and Azure DevOps. It includes a few workarounds for the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/static-web-apps/issues/516"}),'"Provider is invalid. Cannot change the Provider. Please detach your static site first if you wish to use to another deployment provider." issue'),"."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Publish Azure Static Web Apps with Bicep and Azure DevOps&quot; and some Azure logos",src:n(82116).Z,width:"1522",height:"644"})),(0,a.kt)("h2",o({},{id:"bicep-template"}),"Bicep template"),(0,a.kt)("p",null,"The first thing we're going to do is create a folder where our Bicep file for deploying our Azure Static Web App will live:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"mkdir infra/static-web-app -p\n")),(0,a.kt)("p",null,"Then we'll create a ",(0,a.kt)("inlineCode",{parentName:"p"},"main.bicep")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param repositoryUrl string\nparam repositoryBranch string\n\nparam location string = 'westeurope'\nparam skuName string = 'Free'\nparam skuTier string = 'Free'\n\nparam appName string\n\nresource staticWebApp 'Microsoft.Web/staticSites@2020-12-01' = {\n  name: appName\n  location: location\n  sku: {\n    name: skuName\n    tier: skuTier\n  }\n  properties: {\n    // The provider, repositoryUrl and branch fields are required for successive deployments to succeed\n    // for more details see: https://github.com/Azure/static-web-apps/issues/516\n    provider: 'DevOps'\n    repositoryUrl: repositoryUrl\n    branch: repositoryBranch\n    buildProperties: {\n      skipGithubActionWorkflowGeneration: true\n    }\n  }\n}\n\noutput deployment_token string = listSecrets(staticWebApp.id, staticWebApp.apiVersion).properties.apiKey\n")),(0,a.kt)("p",null,"There's some things to draw attention to in the code above:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"The ",(0,a.kt)("inlineCode",{parentName:"li"},"provider"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"repositoryUrl")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"branch")," fields are required for successive deployments to succeed. In our case we're deploying via Azure DevOps and so our provider is ",(0,a.kt)("inlineCode",{parentName:"li"},"'DevOps'"),". For more details, ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/Azure/static-web-apps/issues/516"}),"look at this issue"),"."),(0,a.kt)("li",{parentName:"ol"},"We're creating a ",(0,a.kt)("inlineCode",{parentName:"li"},"deployment_token")," which we'll need in order that we can deploy into the Azure Static Web App resource.")),(0,a.kt)("h2",o({},{id:"static-web-app"}),"Static Web App"),(0,a.kt)("p",null,"In order that we can test out Azure Static Web Apps, what we need is a static web app. You could use pretty much anything here; we're going to use Docusaurus. We'll execute this single command:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"npx @docusaurus/init@latest init static-web-app classic\n")),(0,a.kt)("p",null,"Which will scaffold a Docusaurus site in a folder named ",(0,a.kt)("inlineCode",{parentName:"p"},"static-web-app"),". We don't need to change it any further; let's just see if we can deploy it."),(0,a.kt)("h2",o({},{id:"azure-pipeline"}),"Azure Pipeline"),(0,a.kt)("p",null,"We're going to add an ",(0,a.kt)("inlineCode",{parentName:"p"},"azure-pipelines.yml")," file which Azure DevOps can use to power a pipeline:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"trigger:\n  - main\n\npool:\n  vmImage: ubuntu-latest\n\nsteps:\n  - checkout: self\n    submodules: true\n\n  - bash: az bicep build --file infra/static-web-app/main.bicep\n    displayName: 'Compile Bicep to ARM'\n\n  - task: AzureResourceManagerTemplateDeployment@3\n    name: DeployStaticWebAppInfra\n    displayName: Deploy Static Web App infra\n    inputs:\n      deploymentScope: Resource Group\n      azureResourceManagerConnection: $(serviceConnection)\n      subscriptionId: $(subscriptionId)\n      action: Create Or Update Resource Group\n      resourceGroupName: $(azureResourceGroup)\n      location: $(location)\n      templateLocation: Linked artifact\n      csmFile: 'infra/static-web-app/main.json' # created by bash script\n      overrideParameters: >-\n        -repositoryUrl $(repo)\n        -repositoryBranch $(Build.SourceBranchName)\n        -appName $(staticWebAppName)\n      deploymentMode: Incremental\n      deploymentOutputs: deploymentOutputs\n\n  - task: PowerShell@2\n    name: 'SetDeploymentOutputVariables'\n    displayName: 'Set Deployment Output Variables'\n    inputs:\n      targetType: inline\n      script: |\n        $armOutputObj = '$(deploymentOutputs)' | ConvertFrom-Json\n        $armOutputObj.PSObject.Properties | ForEach-Object {\n          $keyname = $_.Name\n          $value = $_.Value.value\n\n          # Creates a standard pipeline variable\n          Write-Output \"##vso[task.setvariable variable=$keyName;issecret=true]$value\"\n\n          # Display keys in pipeline\n          Write-Output \"output variable: $keyName\"\n        }\n      pwsh: true\n\n  - task: AzureStaticWebApp@0\n    name: DeployStaticWebApp\n    displayName: Deploy Static Web App\n    inputs:\n      app_location: 'static-web-app'\n      # api_location: 'api' # we don't have an API\n      output_location: 'build'\n      azure_static_web_apps_api_token: $(deployment_token) # captured from deploymentOutputs\n")),(0,a.kt)("p",null,"When the pipeline is run, it does the following:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Compiles our Bicep into an ARM template"),(0,a.kt)("li",{parentName:"ol"},"Deploys the compiled ARM template to Azure"),(0,a.kt)("li",{parentName:"ol"},"Captures the deployment outputs (essentially the ",(0,a.kt)("inlineCode",{parentName:"li"},"deployment_token"),") and converts them into variables to use in the pipeline"),(0,a.kt)("li",{parentName:"ol"},"Deploys our Static Web App using the ",(0,a.kt)("inlineCode",{parentName:"li"},"deployment_token"))),(0,a.kt)("p",null,"The pipeline depends upon a number of variables:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"azureResourceGroup")," - the name of your resource group in Azure where the app will be deployed"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"location")," - where your app is deployed, eg ",(0,a.kt)("inlineCode",{parentName:"li"},"northeurope")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"repo")," - the URL of your repository in Azure DevOps, eg ",(0,a.kt)("a",o({parentName:"li"},{href:"https://dev.azure.com/johnnyreilly/_git/azure-static-web-apps"}),"https://dev.azure.com/johnnyreilly/_git/azure-static-web-apps")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"serviceConnection")," - the name of your AzureRM service connection in Azure DevOps"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"staticWebAppName")," - the name of your static web app, eg ",(0,a.kt)("inlineCode",{parentName:"li"},"azure-static-web-apps-johnnyreilly")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"subscriptionId")," - your Azure subscription id from the ",(0,a.kt)("a",o({parentName:"li"},{href:"https://portal.azure.com"}),"Azure Portal"))),(0,a.kt)("p",null,"A successful pipeline looks something like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of successfully running Azure Pipeline",src:n(70563).Z,width:"2090",height:"1648"})),(0,a.kt)("p",null,"What you might notice is that the ",(0,a.kt)("inlineCode",{parentName:"p"},"AzureStaticWebApp")," is itself installing and building our application. This is handled by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/Oryx"}),"Microsoft Oryx"),". The upshot of this is that we don't need to manually run ",(0,a.kt)("inlineCode",{parentName:"p"},"npm install")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"npm build")," ourselves; the ",(0,a.kt)("inlineCode",{parentName:"p"},"AzureStaticWebApp")," task will take care of it for us."),(0,a.kt)("p",null,"Finally, let's see if we've deployed something successfully..."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of deployed Azure Static Web App",src:n(92051).Z,width:"1856",height:"1482"})),(0,a.kt)("p",null,"We have! It's worth noting that you'll likely want to give your Azure Static Web App a lovelier URL, and perhaps even put it behind Azure Front Door as well."),(0,a.kt)("h2",o({},{id:"provider-is-invalid-workaround-2"}),(0,a.kt)("inlineCode",{parentName:"h2"},"Provider is invalid")," workaround 2"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://www.linkedin.com/in/shaneneff/"}),"Shane Neff")," was attempting to follow the instructions in this post and encountered issues. He shared his struggles with me as he encountered the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/static-web-apps/issues/516"}),'"Provider is invalid. Cannot change the Provider. Please detach your static site first if you wish to use to another deployment provider." issue'),"."),(0,a.kt)("p",null,"He was good enough to share his solution as well, which is inserting this task at the start of the pipeline (before the ",(0,a.kt)("inlineCode",{parentName:"p"},"az bicep build")," step):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- task: AzureCLI@2\n  inputs:\n    azureSubscription: '<name of your service connection>'\n    scriptType: 'bash'\n    scriptLocation: 'inlineScript'\n    inlineScript: 'az staticwebapp disconnect -n <name of your app>'\n")),(0,a.kt)("p",null,"I haven't had the problems that Shane has had myself, but I wanted to share his fix for the people out there who almost certainly are bumping on this."))}d.isMDXComponent=!0},40391:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"bicep-syntax-highlighting-with-prismjs",title:"Bicep: syntax highlighting with PrismJS (and Docusaurus)",authors:"johnnyreilly",tags:["Bicep","PrismJS"],image:"./bicep-syntax-highlighting-with-prismjs.webp",hide_table_of_contents:!1},s=void 0,l={permalink:"/bicep-syntax-highlighting-with-prismjs",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-08-19-bicep-syntax-highlighting-with-prismjs/index.md",source:"@site/blog/2021-08-19-bicep-syntax-highlighting-with-prismjs/index.md",title:"Bicep: syntax highlighting with PrismJS (and Docusaurus)",description:"Bicep is an amazing language, it's also very new. If you want to write attractive code snippets about Bicep, you can by using PrismJS (and Docusaurus). This post shows you how.",date:"2021-08-19T00:00:00.000Z",formattedDate:"August 19, 2021",tags:[{label:"Bicep",permalink:"/tags/bicep"},{label:"PrismJS",permalink:"/tags/prism-js"}],readingTime:2.215,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"bicep-syntax-highlighting-with-prismjs",title:"Bicep: syntax highlighting with PrismJS (and Docusaurus)",authors:"johnnyreilly",tags:["Bicep","PrismJS"],image:"./bicep-syntax-highlighting-with-prismjs.webp",hide_table_of_contents:!1},prevItem:{title:"Google APIs: authentication with TypeScript",permalink:"/google-apis-authentication-with-typescript"},nextItem:{title:"Publish Azure Static Web Apps with Bicep and Azure DevOps",permalink:"/bicep-azure-static-web-apps-azure-devops"}},p={image:n(33377).Z,authorsImageUrls:[void 0]},u=[{value:"Syntax highlighting",id:"syntax-highlighting",level:2},{value:"Docusaurus meet Bicep",id:"docusaurus-meet-bicep",level:2},{value:"Early adoption workaround",id:"early-adoption-workaround",level:2},{value:"What does it look like?",id:"what-does-it-look-like",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Bicep is an amazing language, it's also very new. If you want to write attractive code snippets about Bicep, you can by using PrismJS (and Docusaurus). This post shows you how."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Publish Azure Static Web Apps with Bicep and Azure DevOps&quot; and some Azure logos",src:n(33377).Z,width:"700",height:"500"})),(0,a.kt)("h2",o({},{id:"syntax-highlighting"}),"Syntax highlighting"),(0,a.kt)("p",null,"I've been writing blog posts about Bicep for a little while. I was frustrated that the code snippets were entirely unhighlighted. I'm keen my posts are as readable as possible, and so I ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/PrismJS/prism/pull/3027"}),"looked into adding support to PrismJS")," which is what ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/"}),"Docusaurus")," uses to power syntax highlighting."),(0,a.kt)("p",null,"Whilst my regex fu is amateur at best, happily ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/RunDevelopment"}),"Michael Schmidt")," of the PrismJS family is considerably better. He took the support I added and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/PrismJS/prism/pull/3028"}),"made it much better"),"."),(0,a.kt)("h2",o({},{id:"docusaurus-meet-bicep"}),"Docusaurus meet Bicep"),(0,a.kt)("p",null,"If you have any code snippets that start with three backticks and the word ",(0,a.kt)("inlineCode",{parentName:"p"},"bicep"),"..."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"```bicep\n// code goes here...\n")),(0,a.kt)("p",null,"... then ideally you'd like to see some syntax highlighting in your post. Since Bicep isn't \"in the box\" for Docusaurus you need to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/docs/next/markdown-features/code-blocks#supported-languages"}),"explicitly opt into support like so:")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),'    prism: {\n      additionalLanguages: ["powershell", "csharp", "docker", "bicep"],\n    },\n')),(0,a.kt)("p",null,"Above you can see a snippet from my own ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/blob/b2df93efb72adc32d9f45de4f727e890e59a4919/blog-website/docusaurus.config.js#L185"}),(0,a.kt)("inlineCode",{parentName:"a"},"docusaurus.config.js"))," which adds Bicep, alongside the other additional languages I use."),(0,a.kt)("p",null,"With this in place, you would typically get all the syntax highlighting support you need."),(0,a.kt)("h2",o({},{id:"early-adoption-workaround"}),"Early adoption workaround"),(0,a.kt)("p",null,"I'm writing this post before the latest version of PrismJS has shipped. As such, Bicep support isn't available by default yet. But if you're an early adopter, you can get support right now. The secret is adding a ",(0,a.kt)("inlineCode",{parentName:"p"},"resolutions")," section to your ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," which points to the GitHub Repo ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/PrismJS/prism"}),"where Prism lives"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'  "resolutions": {\n    "prismjs": "PrismJS/prism"\n  },\n')),(0,a.kt)("p",null,"This will mean that Yarn (if you're using Docusaurus you're probably using Yarn) pulls ",(0,a.kt)("inlineCode",{parentName:"p"},"prismjs")," directly from GitHub, as demonstrated by the ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn.lock")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'prismjs@PrismJS/prism, prismjs@^1.23.0:\n  version "1.24.1"\n  resolved "https://codeload.github.com/PrismJS/prism/tar.gz/59f449d33dc9fd19302f21aad95fc0b5028ac830"\n')),(0,a.kt)("h2",o({},{id:"what-does-it-look-like"}),"What does it look like?"),(0,a.kt)("p",null,"Finally, let's see if works. Here's a Bicep code snippet that I borrowed from ",(0,a.kt)("a",o({parentName:"p"},{href:"/bicep-syntax-highlighting-with-prismjs"}),"an earlier post"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param repositoryUrl string\nparam repositoryBranch string\n\nparam location string = 'westeurope'\nparam skuName string = 'Free'\nparam skuTier string = 'Free'\n\nparam appName string\n\nresource staticWebApp 'Microsoft.Web/staticSites@2020-12-01' = {\n  name: appName\n  location: location\n  tags: tagsObj\n  sku: {\n    name: skuName\n    tier: skuTier\n  }\n  properties: {\n    // The provider, repositoryUrl and branch fields are required for successive deployments to succeed\n    // for more details see: https://github.com/Azure/static-web-apps/issues/516\n    provider: 'DevOps'\n    repositoryUrl: repositoryUrl\n    branch: repositoryBranch\n    buildProperties: {\n      skipGithubActionWorkflowGeneration: true\n    }\n  }\n}\n\noutput deployment_token string = listSecrets(staticWebApp.id, staticWebApp.apiVersion).properties.apiKey\n")),(0,a.kt)("p",null,"As you can see, it's delightfully highlighted by PrismJS. Enjoy!"))}d.isMDXComponent=!0},98089:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"google-apis-authentication-with-typescript",title:"Google APIs: authentication with TypeScript",authors:"johnnyreilly",tags:["Google APIs","typescript"],image:"./app-registration.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/google-apis-authentication-with-typescript",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-09-10-google-apis-authentication-with-typescript/index.md",source:"@site/blog/2021-09-10-google-apis-authentication-with-typescript/index.md",title:"Google APIs: authentication with TypeScript",description:"Google has a wealth of APIs which we can interact with. At the time of writing, there's more than two hundred available; including YouTube, Google Calendar and GMail (alongside many others). To integrate with these APIs, it's necessary to authenticate and then use that credential with the API. This post will take you through how to do just that using TypeScript. It will also demonstrate how to use one of those APIs: the Google Calendar API.",date:"2021-09-10T00:00:00.000Z",formattedDate:"September 10, 2021",tags:[{label:"Google APIs",permalink:"/tags/google-ap-is"},{label:"typescript",permalink:"/tags/typescript"}],readingTime:8.74,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"google-apis-authentication-with-typescript",title:"Google APIs: authentication with TypeScript",authors:"johnnyreilly",tags:["Google APIs","typescript"],image:"./app-registration.png",hide_table_of_contents:!1},prevItem:{title:"Permissioning Azure Pipelines with Bicep and Azure RBAC Role Assignments",permalink:"/permissioning-azure-pipelines-bicep-role-assignments"},nextItem:{title:"Bicep: syntax highlighting with PrismJS (and Docusaurus)",permalink:"/bicep-syntax-highlighting-with-prismjs"}},p={image:n(53254).Z,authorsImageUrls:[void 0]},u=[{value:"Creating an OAuth 2.0 Client ID on the Google Cloud Platform",id:"creating-an-oauth-20-client-id-on-the-google-cloud-platform",level:2},{value:"Acquiring a refresh token",id:"acquiring-a-refresh-token",level:2},{value:"Accessing the Google Calendar API",id:"accessing-the-google-calendar-api",level:2},{value:"Today the Google Calendar API, tomorrow the (Google API) world!",id:"today-the-google-calendar-api-tomorrow-the-google-api-world",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Google has a wealth of APIs which we can interact with. At the time of writing, there's more than two hundred available; including YouTube, Google Calendar and GMail (alongside many others). To integrate with these APIs, it's necessary to authenticate and then use that credential with the API. This post will take you through how to do just that using TypeScript. It will also demonstrate how to use one of those APIs: the Google Calendar API."),(0,a.kt)("h2",o({},{id:"creating-an-oauth-20-client-id-on-the-google-cloud-platform"}),"Creating an OAuth 2.0 Client ID on the Google Cloud Platform"),(0,a.kt)("p",null,"The first thing we need to do is go to the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://console.cloud.google.com/projectcreate"}),"Google Cloud Platform to create a project"),". The name of the project doesn't matter particularly; although it can be helpful to name the project to align with the API you're intending to consume. That's what we'll do here as we plan to integrate with the Google Calendar API:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"Screenshot of the Create Project screen in the Google Cloud Platform",src:n(81712).Z,width:"1445",height:"900"})),(0,a.kt)("p",null,"The project is the container in which the OAuth 2.0 Client ID will be housed. Now we've created the project, let's go to the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://console.cloud.google.com/apis/credentials"}),"credentials screen")," and create an OAuth Client ID using the Create Credentials dropdown:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the Create Credentials dropdown in the Google Cloud Platform",src:n(20395).Z,width:"3030",height:"1205"})),(0,a.kt)("p",null,"You'll likely have to create an OAuth consent screen before you can create the OAuth Client ID. Going through the journey of doing that feels a little daunting as many questions have to be answered. This is because the consent screen can be used for a variety of purposes beyond the API authentication we're looking at today."),(0,a.kt)("p",null,'When challenged, you can generally accept the defaults and proceed. The user type you\'ll require will be "External":'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the OAuth consent screen in the Google Cloud Platform",src:n(22143).Z,width:"1873",height:"1132"})),(0,a.kt)("p",null,"You'll also be required to create an app registration - all that's really required here is a name (which can be anything) and your email address:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the OAuth consent screen in the Google Cloud Platform",src:n(53254).Z,width:"1911",height:"1204"})),(0,a.kt)("p",null,"You don't need to worry about scopes. You can either plan to publish the app, or alternately set yourself up to be a test user - you'll need to do one of these in order that you can authenticate with the app. Continuing to the end of the journey should provide you with the OAuth consent screen which you need in order that you may then create the OAuth Client ID."),(0,a.kt)("p",null,'Creating the OAuth Client ID is slightly confusing as the "Application type" required is "TVs and Limited Input devices".'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the create OAuth Client ID screen in the Google Cloud Platform",src:n(39189).Z,width:"1782",height:"940"})),(0,a.kt)("p",null,"We're using this type of application as we want to acquire a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://oauth.net/2/grant-types/refresh-token/"}),"refresh token")," which we'll be able to use in future to aquire access tokens which will be used to access the Google APIs."),(0,a.kt)("p",null,"Once it's created, you'll be able to download the Client ID from the Google Cloud Platform:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the create OAuth Client ID screen in the Google Cloud Platform",src:n(62e3).Z,width:"2476",height:"221"})),(0,a.kt)("p",null,"When you download it, it should look something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "installed": {\n    "client_id": "CLIENT_ID",\n    "project_id": "PROJECT_ID",\n    "auth_uri": "https://accounts.google.com/o/oauth2/auth",\n    "token_uri": "https://oauth2.googleapis.com/token",\n    "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",\n    "client_secret": "CLIENT_SECRET",\n    "redirect_uris": ["urn:ietf:wg:oauth:2.0:oob", "http://localhost"]\n  }\n}\n')),(0,a.kt)("p",null,"You'll need the ",(0,a.kt)("inlineCode",{parentName:"p"},"client_id"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"client_secret")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"redirect_uris")," - but keep them in a safe place and don't commit ",(0,a.kt)("inlineCode",{parentName:"p"},"client_id")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"client_secret")," to source control!"),(0,a.kt)("h2",o({},{id:"acquiring-a-refresh-token"}),"Acquiring a refresh token"),(0,a.kt)("p",null,"Now we've got our ",(0,a.kt)("inlineCode",{parentName:"p"},"client_id")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"client_secret"),", we're ready to write a simple node command line application which we can use to obtain a refresh token. This is actually a multi-stage process that will end up looking like this:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Provide the Google authentication provider with the ",(0,a.kt)("inlineCode",{parentName:"li"},"client_id")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"client_secret"),", in return it will provide an authentication URL."),(0,a.kt)("li",{parentName:"ul"},"Open the authentication URL in the browser and grant consent, the provider will hand over a code."),(0,a.kt)("li",{parentName:"ul"},"Provide the Google authentication provider with the ",(0,a.kt)("inlineCode",{parentName:"li"},"client_id"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"client_secret")," and the code, it will acquire and provide users with a refresh token.")),(0,a.kt)("p",null,"Let's start coding. We'll initialise a TypeScript Node project like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"mkdir src\ncd src\nnpm init -y\nnpm install googleapis ts-node typescript yargs @types/yargs @types/node\nnpx tsc --init\n")),(0,a.kt)("p",null,"We've added a number of dependencies that will allow us to write a TypeScript Node command line application. We've also added a dependency to the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/googleapis"}),(0,a.kt)("inlineCode",{parentName:"a"},"googleapis"))," package which describes itself as:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Node.js client library for using Google APIs. Support for authorization and authentication with OAuth 2.0, API Keys and JWT tokens is included.")),(0,a.kt)("p",null,"We're going to make use of the OAuth 2.0 part. We'll start our journey by creating a file called ",(0,a.kt)("inlineCode",{parentName:"p"},"google-api-auth.ts"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { getArgs, makeOAuth2Client } from './shared';\n\nasync function getToken() {\n  const { clientId, clientSecret, code } = await getArgs();\n  const oauth2Client = makeOAuth2Client({ clientId, clientSecret });\n\n  if (code) await getRefreshToken(code);\n  else getAuthUrl();\n\n  async function getAuthUrl() {\n    const url = oauth2Client.generateAuthUrl({\n      // 'online' (default) or 'offline' (gets refresh_token)\n      access_type: 'offline',\n\n      // scopes are documented here: https://developers.google.com/identity/protocols/oauth2/scopes#calendar\n      scope: [\n        'https://www.googleapis.com/auth/calendar',\n        'https://www.googleapis.com/auth/calendar.events',\n      ],\n    });\n\n    console.log(`Go to this URL to acquire a refresh token:\\n\\n${url}\\n`);\n  }\n\n  async function getRefreshToken(code: string) {\n    const token = await oauth2Client.getToken(code);\n    console.log(token);\n  }\n}\n\ngetToken();\n")),(0,a.kt)("p",null,"And a common file named ",(0,a.kt)("inlineCode",{parentName:"p"},"shared.ts")," which ",(0,a.kt)("inlineCode",{parentName:"p"},"google-api-auth.ts")," imports and which we'll re-use later:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { google } from 'googleapis';\nimport yargs from 'yargs/yargs';\nconst { hideBin } = require('yargs/helpers');\n\nexport async function getArgs() {\n  const argv = await Promise.resolve(yargs(hideBin(process.argv)).argv);\n\n  const clientId = argv['clientId'] as string;\n  const clientSecret = argv['clientSecret'] as string;\n\n  const code = argv.code as string | undefined;\n  const refreshToken = argv.refreshToken as string | undefined;\n  const test = argv.test as boolean;\n\n  if (!clientId) throw new Error('No clientId ');\n  console.log('We have a clientId');\n\n  if (!clientSecret) throw new Error('No clientSecret');\n  console.log('We have a clientSecret');\n\n  if (code) console.log('We have a code');\n  if (refreshToken) console.log('We have a refreshToken');\n\n  return { code, clientId, clientSecret, refreshToken, test };\n}\n\nexport function makeOAuth2Client({\n  clientId,\n  clientSecret,\n}: {\n  clientId: string;\n  clientSecret: string;\n}) {\n  return new google.auth.OAuth2(\n    /* YOUR_CLIENT_ID */ clientId,\n    /* YOUR_CLIENT_SECRET */ clientSecret,\n    /* YOUR_REDIRECT_URL */ 'urn:ietf:wg:oauth:2.0:oob'\n  );\n}\n")),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"getToken")," function above does these things:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"If given a ",(0,a.kt)("inlineCode",{parentName:"li"},"client_id")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"client_secret")," it will obtain an authentication URL."),(0,a.kt)("li",{parentName:"ol"},"If given a ",(0,a.kt)("inlineCode",{parentName:"li"},"client_id"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"client_secret")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"code")," it will obtain a refresh token (scoped to access the Google Calendar API).")),(0,a.kt)("p",null,"We'll add an entry to our ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," which will allow us to run our console app:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'    "google-api-auth": "ts-node google-api-auth.ts"\n')),(0,a.kt)("p",null,"Now we're ready to acquire the refresh token. We'll run the following command (substituting in the appropriate values):"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"npm run google-api-auth -- --clientId CLIENT_ID --clientSecret CLIENT_SECRET")),(0,a.kt)("p",null,"Click on the URL that is generated in the console, it should open up a consent screen in the browser which looks like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the consent screen",src:n(81531).Z,width:"915",height:"1534"})),(0,a.kt)("p",null,"Authenticate and grant consent and you should get a code:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the generated code",src:n(12715).Z,width:"1012",height:"1020"})),(0,a.kt)("p",null,"Then (quickly) paste the acquired code into the following command:"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"npm run google-api-auth -- --clientId CLIENT_ID --clientSecret CLIENT_SECRET --code THISISTHECODE")),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"refresh_token")," (alongside much else) will be printed to the console. Grab it and put it somewhere secure. Again, no storing in source control!"),(0,a.kt)("p",null,"It's worth taking a moment to reflect on what we've done. We've acquired a refresh token which involved a certain amount of human interaction. We've had to run a console command, do some work in a browser and run another commmand. You wouldn't want to do this repeatedly because it involves human interaction. Intentionally it cannot be automated. However, once you've acquired the refresh token, you can use it repeatedly until it expires (which may be never or at least years in the future). So once you have the refresh token, and you've stored it securely, you have what you need to be able to automate an API interaction."),(0,a.kt)("h2",o({},{id:"accessing-the-google-calendar-api"}),"Accessing the Google Calendar API"),(0,a.kt)("p",null,"Let's test out our refresh token by attempting to access the Google Calendar API. We'll create a ",(0,a.kt)("inlineCode",{parentName:"p"},"calendar.ts")," file"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { google } from 'googleapis';\nimport { getArgs, makeOAuth2Client } from './shared';\n\nasync function makeCalendarClient() {\n  const { clientId, clientSecret, refreshToken } = await getArgs();\n  const oauth2Client = makeOAuth2Client({ clientId, clientSecret });\n  oauth2Client.setCredentials({\n    refresh_token: refreshToken,\n  });\n\n  const calendarClient = google.calendar({\n    version: 'v3',\n    auth: oauth2Client,\n  });\n  return calendarClient;\n}\n\nasync function getCalendar() {\n  const calendarClient = await makeCalendarClient();\n\n  const { data: calendars, status } = await calendarClient.calendarList.list();\n\n  if (status === 200) {\n    console.log('calendars', calendars);\n  } else {\n    console.log('there was an issue...', status);\n  }\n}\n\ngetCalendar();\n")),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"getCalendar")," function above uses the ",(0,a.kt)("inlineCode",{parentName:"p"},"client_id"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"client_secret")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"refresh_token")," to access the Google Calendar API and retrieve the list of calendars."),(0,a.kt)("p",null,"We'll add an entry to our ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," which will allow us to run this function:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'    "calendar": "ts-node calendar.ts",\n')),(0,a.kt)("p",null,"Now we're ready to test ",(0,a.kt)("inlineCode",{parentName:"p"},"calendar.ts"),". We'll run the following command (substituting in the appropriate values):"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"npm run calendar -- --clientId CLIENT_ID --clientSecret CLIENT_SECRET --refreshToken REFRESH_TOKEN")),(0,a.kt)("p",null,"When we run for the first time, we may encounter a self explanatory message which tells us that we need enable the calendar API for our application:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"(node:31563) UnhandledPromiseRejectionWarning: Error: Google Calendar API has not been used in project 77777777777777 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/calendar-json.googleapis.com/overview?project=77777777777777 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\n")),(0,a.kt)("p",null,"Once enabled, we can run successfully for the first time. Consequently we should see something like this showing up in the console:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of calendars list response in the console",src:n(66320).Z,width:"1094",height:"586"})),(0,a.kt)("p",null,"This demonstrates that we're successfully integrating with a Google API using our refresh token."),(0,a.kt)("h2",o({},{id:"today-the-google-calendar-api-tomorrow-the-google-api-world"}),"Today the Google Calendar API, tomorrow the (Google API) world!"),(0,a.kt)("p",null,"What we've demonstrated here is integrating with the Google Calendar API. However, that is not the limit of what we can do. As we discussed earlier, Google has more than two hundred APIs we can interact with, and the key to that interaction is following the same steps for authentication that this post outlines."),(0,a.kt)("p",null,"Let's imagine that we want to integrate with the YouTube API or the GMail API. We'd be able to follow the steps in this post, using different ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/identity/protocols/oauth2/scopes#calendar"}),"scopes for the refresh token appropriate to the API"),", and build an integration against that API. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/apis-explorer"}),"Take a look at the available APIs")," here."),(0,a.kt)("p",null,"The approach outlined by this post is the key to integrating with a multitude of Google APIs. Happy integrating!"),(0,a.kt)("p",null,"The idea of this was sparked by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://martinfowler.com/articles/command-line-google.html"}),"Martin Fowler's post")," on the topic which comes from a Ruby angle."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/how-to-authenticate-access-google-apis-using-oauth-2-0/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/how-to-authenticate-access-google-apis-using-oauth-2-0/"})))}d.isMDXComponent=!0},71502:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"permissioning-azure-pipelines-bicep-role-assignments",title:"Permissioning Azure Pipelines with Bicep and Azure RBAC Role Assignments",authors:"johnnyreilly",tags:["Role Assignments","Bicep","azure devops","Azure Pipelines"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/permissioning-azure-pipelines-bicep-role-assignments",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-09-12-permissioning-azure-pipelines-bicep-role-assignments/index.md",source:"@site/blog/2021-09-12-permissioning-azure-pipelines-bicep-role-assignments/index.md",title:"Permissioning Azure Pipelines with Bicep and Azure RBAC Role Assignments",description:"How can we deploy resources to Azure, and then run an integration test through them in the context of an Azure Pipeline? This post will show how to do this by permissioning our Azure Pipeline to access these resources using Azure RBAC role assignments. It will also demonstrate a dotnet test that runs in the context of the pipeline and makes use of those role assignments.",date:"2021-09-12T00:00:00.000Z",formattedDate:"September 12, 2021",tags:[{label:"Role Assignments",permalink:"/tags/role-assignments"},{label:"Bicep",permalink:"/tags/bicep"},{label:"azure devops",permalink:"/tags/azure-devops"},{label:"Azure Pipelines",permalink:"/tags/azure-pipelines"}],readingTime:8.72,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"permissioning-azure-pipelines-bicep-role-assignments",title:"Permissioning Azure Pipelines with Bicep and Azure RBAC Role Assignments",authors:"johnnyreilly",tags:["Role Assignments","Bicep","azure devops","Azure Pipelines"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"Structured data, SEO and React",permalink:"/structured-data-seo-and-react"},nextItem:{title:"Google APIs: authentication with TypeScript",permalink:"/google-apis-authentication-with-typescript"}},p={image:n(55513).Z,authorsImageUrls:[void 0]},u=[{value:"Add Event Hubs to your subscription",id:"add-event-hubs-to-your-subscription",level:2},{value:"Permission our service connection / service principal",id:"permission-our-service-connection--service-principal",level:2},{value:"Event Hub and Role Assignment with Bicep",id:"event-hub-and-role-assignment-with-bicep",level:2},{value:"Our test",id:"our-test",level:2},{value:"Azure Pipeline",id:"azure-pipeline",level:2},{value:"Running the pipeline",id:"running-the-pipeline",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"How can we deploy resources to Azure, and then run an integration test through them in the context of an Azure Pipeline? This post will show how to do this by permissioning our Azure Pipeline to access these resources using Azure RBAC role assignments. It will also demonstrate a dotnet test that runs in the context of the pipeline and makes use of those role assignments."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Permissioning Azure Pipelines with Bicep and Role Assignments&quot; and some Azure logos",src:n(55513).Z,width:"800",height:"800"})),(0,a.kt)("p",null,"We're following this approach as an alternative to ",(0,a.kt)("a",o({parentName:"p"},{href:"/output-connection-strings-and-keys-from-azure-bicep"}),"exporting connection strings"),", as these can be viewed in the Azure Portal; which may be an security issue if you have many people who are able to access the portal and view deployment outputs."),(0,a.kt)("p",null,"We're going to demonstrate this approach using Event Hubs. It's worth calling out that this is a generally useful approach which can be applied to any Azure resources that support Azure RBAC Role Assignments. So wherever in this post you read \"Event Hubs\", imagine substituting other Azure resources you're working with."),(0,a.kt)("p",null,"The post will do the following:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Add Event Hubs to our Azure subscription"),(0,a.kt)("li",{parentName:"ul"},"Permission our service connection / service principal"),(0,a.kt)("li",{parentName:"ul"},"Deploy to Azure with Bicep"),(0,a.kt)("li",{parentName:"ul"},"Write an integration test"),(0,a.kt)("li",{parentName:"ul"},"Write a pipeline to bring it all together")),(0,a.kt)("h2",o({},{id:"add-event-hubs-to-your-subscription"}),"Add Event Hubs to your subscription"),(0,a.kt)("p",null,"First of all, we may need to add Event Hubs to our Azure subscription."),(0,a.kt)("p",null,"Without this in place, we may encounter errors of the type:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"##","[error]","MissingSubscriptionRegistration: The subscription is not registered to use namespace 'Microsoft.EventHub'. See ",(0,a.kt)("a",o({parentName:"p"},{href:"https://aka.ms/rps-not-found"}),"https://aka.ms/rps-not-found")," for how to register subscriptions.")),(0,a.kt)("p",null,'We do this by going to "Resource Providers" in the ',(0,a.kt)("a",o({parentName:"p"},{href:"https://portal.azure.com"}),"Azure Portal")," and registering the resources you need. Lots are registered by default, but not all."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the Azure Portal, subscriptions -&gt; resource providers section, showing that Event Hubs have been registered",src:n(88630).Z,width:"3152",height:"1682"})),(0,a.kt)("h2",o({},{id:"permission-our-service-connection--service-principal"}),"Permission our service connection / service principal"),(0,a.kt)("p",null,"In order that we can run pipelines related to Azure, we mostly need to have an Azure Resource Manager service connection set up in Azure DevOps. Once that exists, we also need to give it a role assignment to allow it to create role assignments of its own when pipelines are running."),(0,a.kt)("p",null,"Without this in place, we may encounter errors of the type:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"##","[error]","The template deployment failed with error: 'Authorization failed for template resource '{GUID-THE-FIRST}' of type 'Microsoft.Authorization/roleAssignments'. The client '{GUID-THE-SECOND}' with object id '{GUID-THE-SECOND}' does not have permission to perform action 'Microsoft.Authorization/roleAssignments/write' at scope '/subscriptions/","*","*","*","/resourceGroups/johnnyreilly/providers/Microsoft.EventHub/namespaces/evhns-demo/providers/Microsoft.Authorization/roleAssignments/{GUID-THE-FIRST}'.'.")),(0,a.kt)("p",null,'Essentially, we want to be able to run pipelines that say "hey Azure, we want to give permissions to our service connection". We are doing this ',(0,a.kt)("em",{parentName:"p"},"with")," the self same service connection, so (chicken and egg) we first need to give it permission to give those commands in future. This is a little confusing; but let's role with it. (Pun most definitely intended. \ud83d\ude09)"),(0,a.kt)("p",null,"To grant that permission / add that role assignment, we go to the service connection in Azure Devops:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the service connection in Azure DevOps",src:n(69862).Z,width:"914",height:"560"})),(0,a.kt)("p",null,"We can see there's two links here; first we'll click on \"Manage Service Principal\", which will take us to the service principal in the Azure Portal:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the service principal in the Azure Portal",src:n(64664).Z,width:"1954",height:"740"})),(0,a.kt)("p",null,'Take note of the display name of the service principal; we\'ll need that as we click on the "Manage service connection roles" link, which will take us to the resource groups IAM page in the Azure Portal:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the resource groups IAM page in the Azure Portal",src:n(72653).Z,width:"3020",height:"1308"})),(0,a.kt)("p",null,'Here we can click on "Add role assignment", select "Owner":'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the add role assignment IAM page in the Azure Portal",src:n(85098).Z,width:"3020",height:"722"})),(0,a.kt)("p",null,"Then when selecting members we should be able to look up the service principal to assign it:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the add role assignment select member IAM page in the Azure Portal",src:n(37001).Z,width:"3584",height:"724"})),(0,a.kt)("p",null,"We now have a service connection which we should be able to use for granting permissions / role assignments, which is what we need."),(0,a.kt)("h2",o({},{id:"event-hub-and-role-assignment-with-bicep"}),"Event Hub and Role Assignment with Bicep"),(0,a.kt)("p",null,"Next we want a Bicep file that will, when run, provision an Event Hub and a role assignment which will allow our Azure Pipeline (via its service connection) to interact with it."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"@description('Name of the eventhub namespace')\nparam eventHubNamespaceName string\n\n@description('Name of the eventhub name')\nparam eventHubName string\n\n@description('The service principal')\nparam principalId string\n\n// Create an Event Hub namespace\nresource eventHubNamespace 'Microsoft.EventHub/namespaces@2021-01-01-preview' = {\n  name: eventHubNamespaceName\n  location: resourceGroup().location\n  sku: {\n    name: 'Standard'\n    tier: 'Standard'\n    capacity: 1\n  }\n  properties: {\n    zoneRedundant: true\n  }\n}\n\n// Create an Event Hub inside the namespace\nresource eventHub 'Microsoft.EventHub/namespaces/eventhubs@2021-01-01-preview' = {\n  parent: eventHubNamespace\n  name: eventHubName\n  properties: {\n    messageRetentionInDays: 7\n    partitionCount: 1\n  }\n}\n\n// give Azure Pipelines Service Principal permissions against the Event Hub\n\nvar roleDefinitionAzureEventHubsDataOwner = subscriptionResourceId('Microsoft.Authorization/roleDefinitions', 'f526a384-b230-433a-b45c-95f59c4a2dec')\n\nresource integrationTestEventHubReceiverNamespaceRoleAssignment 'Microsoft.Authorization/roleAssignments@2018-01-01-preview' = {\n  name: guid(principalId, eventHub.id, roleDefinitionAzureEventHubsDataOwner)\n  scope: eventHubNamespace\n  properties: {\n    roleDefinitionId: roleDefinitionAzureEventHubsDataOwner\n    principalId: principalId\n  }\n}\n")),(0,a.kt)("p",null,"Do note that our bicep template takes the service principal id as a parameter. We're going to supply this later from our Azure Pipeline."),(0,a.kt)("h2",o({},{id:"our-test"}),"Our test"),(0,a.kt)("p",null,"We're now going to write a dotnet integration test which will make use of the infrastructure deployed by our Bicep template. Let's create a new test project:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"mkdir src\ncd src\ndotnet new xunit -o IntegrationTests\ncd IntegrationTests\ndotnet add package Azure.Identity\ndotnet add package Azure.Messaging.EventHubs\ndotnet add package FluentAssertions\ndotnet add package Microsoft.Extensions.Configuration.EnvironmentVariables\n")),(0,a.kt)("p",null,"We'll create a test file called ",(0,a.kt)("inlineCode",{parentName:"p"},"EventHubTest.cs")," with these contents:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing System.Threading;\nusing System.Threading.Tasks;\nusing Azure.Identity;\nusing Azure.Messaging.EventHubs;\nusing Azure.Messaging.EventHubs.Consumer;\nusing Azure.Messaging.EventHubs.Producer;\nusing FluentAssertions;\nusing Microsoft.Extensions.Configuration;\nusing Newtonsoft.Json;\nusing Xunit;\nusing Xunit.Abstractions;\n\nnamespace IntegrationTests\n{\n    public record EchoMessage(string Id, string Message, DateTime Timestamp);\n\n    public class EventHubTest\n    {\n        private readonly ITestOutputHelper _output;\n\n        public EventHubTest(ITestOutputHelper output)\n        {\n            _output = output;\n        }\n\n        [Fact]\n        public async Task Can_post_message_to_event_hub_and_read_it_back()\n        {\n            // ARRANGE\n            var configuration = new ConfigurationBuilder()\n                .AddEnvironmentVariables()\n                .Build();\n\n            // populated by variables specified in the Azure Pipeline\n            var eventhubNamespaceName = configuration["EVENTHUBNAMESPACENAME"];\n            eventhubNamespaceName.Should().NotBeNull();\n            var eventhubName = configuration["EVENTHUBNAME"];\n            eventhubName.Should().NotBeNull();\n            var tenantId = configuration["TENANTID"];\n            tenantId.Should().NotBeNull();\n\n            // populated as a consequence of the addSpnToEnvironment in the azure-pipelines.yml\n            var servicePrincipalId = configuration["SERVICEPRINCIPALID"];\n            servicePrincipalId.Should().NotBeNull();\n            var servicePrincipalKey = configuration["SERVICEPRINCIPALKEY"];\n            servicePrincipalKey.Should().NotBeNull();\n\n            var fullyQualifiedNamespace = $"{eventhubNamespaceName}.servicebus.windows.net";\n\n            var clientCredential = new ClientSecretCredential(tenantId, servicePrincipalId, servicePrincipalKey);\n            var eventHubClient = new EventHubProducerClient(\n                fullyQualifiedNamespace: fullyQualifiedNamespace,\n                eventHubName: eventhubName,\n                credential: clientCredential\n            );\n            var ourGuid = Guid.NewGuid().ToString();\n            var now = DateTime.UtcNow;\n            var sentEchoMessage = new EchoMessage(Id: ourGuid, Message: $"Test message", Timestamp: now);\n            var sentEventData = new EventData(\n                Encoding.UTF8.GetBytes(JsonConvert.SerializeObject(sentEchoMessage))\n            );\n\n            // ACT\n            await eventHubClient.SendAsync(new List<EventData> { sentEventData }, CancellationToken.None);\n\n            var eventHubConsumerClient = new EventHubConsumerClient(\n                consumerGroup: EventHubConsumerClient.DefaultConsumerGroupName,\n                fullyQualifiedNamespace: fullyQualifiedNamespace,\n                eventHubName: eventhubName,\n                credential: clientCredential\n            );\n\n            List<PartitionEvent> partitionEvents = new();\n            await foreach (var partitionEvent in eventHubConsumerClient.ReadEventsAsync(new ReadEventOptions\n            {\n                MaximumWaitTime = TimeSpan.FromSeconds(10)\n            }))\n            {\n                if (partitionEvent.Data == null) break;\n                _output.WriteLine(Encoding.UTF8.GetString(partitionEvent.Data.EventBody.ToArray()));\n                partitionEvents.Add(partitionEvent);\n            }\n\n            // ASSERT\n            partitionEvents.Count.Should().BeGreaterOrEqualTo(1);\n            var firstOne = partitionEvents.FirstOrDefault(evnt =>\n              ExtractTypeFromEventBody<EchoMessage>(evnt, _output)?.Id == ourGuid\n            );\n            var receivedEchoMessage = ExtractTypeFromEventBody<EchoMessage>(firstOne, _output);\n            receivedEchoMessage.Should().BeEquivalentTo(sentEchoMessage, because: "the event body should be the same one posted to the message queue");\n        }\n\n        private static T ExtractTypeFromEventBody<T>(PartitionEvent evnt, ITestOutputHelper _output)\n        {\n            try\n            {\n                return JsonConvert.DeserializeObject<T>(Encoding.UTF8.GetString(evnt.Data.EventBody.ToArray()));\n            }\n            catch (JsonException)\n            {\n                _output.WriteLine("[" + Encoding.UTF8.GetString(evnt.Data.EventBody.ToArray()) + "] is probably not JSON");\n                return default(T);\n            }\n        }\n    }\n}\n')),(0,a.kt)("p",null,"Let's talk through what happens in the test above:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"We read in Event Hub connection configuration for the test from environment variables. (These will be supplied by an Azure Pipeline that we will create shortly.)"),(0,a.kt)("li",{parentName:"ol"},"We post a message to the Event Hub."),(0,a.kt)("li",{parentName:"ol"},"We read a message back from the Event Hub."),(0,a.kt)("li",{parentName:"ol"},"We confirm that the message we read back matches the one we posted.")),(0,a.kt)("p",null,"Now that we have our test, we want to be able to execute it. For that we need an Azure Pipeline!"),(0,a.kt)("h2",o({},{id:"azure-pipeline"}),"Azure Pipeline"),(0,a.kt)("p",null,"We're going to add an ",(0,a.kt)("inlineCode",{parentName:"p"},"azure-pipelines.yml")," file which Azure DevOps can use to power a pipeline:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"variables:\n  - name: eventHubNamespaceName\n    value: evhns-demo\n  - name: eventHubName\n    value: evh-demo\n\npool:\n  vmImage: ubuntu-latest\n\nsteps:\n  - task: AzureCLI@2\n    displayName: Get Service Principal Id\n    inputs:\n      azureSubscription: $(serviceConnection)\n      scriptType: bash\n      scriptLocation: inlineScript\n      addSpnToEnvironment: true\n      inlineScript: |\n        PRINCIPAL_ID=$(az ad sp show --id $servicePrincipalId --query objectId -o tsv)\n        echo \"##vso[task.setvariable variable=PIPELINE_PRINCIPAL_ID;]$PRINCIPAL_ID\"\n\n  - bash: az bicep build --file infra/main.bicep\n    displayName: 'Compile Bicep to ARM'\n\n  - task: AzureResourceManagerTemplateDeployment@3\n    name: DeployEventHubInfra\n    displayName: Deploy Event Hub infra\n    inputs:\n      deploymentScope: Resource Group\n      azureResourceManagerConnection: $(serviceConnection)\n      subscriptionId: $(subscriptionId)\n      action: Create Or Update Resource Group\n      resourceGroupName: $(azureResourceGroup)\n      location: $(location)\n      templateLocation: Linked artifact\n      csmFile: 'infra/main.json' # created by bash script\n      overrideParameters: >-\n        -eventHubNamespaceName $(eventHubNamespaceName)\n        -eventHubName $(eventHubName)\n        -principalId $(PIPELINE_PRINCIPAL_ID)\n      deploymentMode: Incremental\n\n  - task: UseDotNet@2\n    displayName: 'Install .NET SDK 5.0.x'\n    inputs:\n      packageType: 'sdk'\n      version: 5.0.x\n\n  - task: AzureCLI@2\n    displayName: dotnet integration test\n    inputs:\n      azureSubscription: $(serviceConnection)\n      scriptType: pscore\n      scriptLocation: inlineScript\n      addSpnToEnvironment: true # allows access to service principal details in script\n      inlineScript: |\n        cd $(Build.SourcesDirectory)/src/IntegrationTests\n        dotnet test\n")),(0,a.kt)("p",null,"When the pipeline is run, it does the following:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Gets the service principal id from the service connection."),(0,a.kt)("li",{parentName:"ol"},"Compiles our Bicep into an ARM template"),(0,a.kt)("li",{parentName:"ol"},"Deploys the compiled ARM template to Azure"),(0,a.kt)("li",{parentName:"ol"},"Installs the dotnet SDK"),(0,a.kt)("li",{parentName:"ol"},"Uses the ",(0,a.kt)("a",o({parentName:"li"},{href:"https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/deploy/azure-cli?view=azure-devops"}),"Azure CLI task")," which allows us to access service principal details in the pipeline to run our dotnet test.")),(0,a.kt)("p",null,"We'll create a pipeline in Azure DevOps pointing to this file, and we'll also create the variables that it depends upon:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"azureResourceGroup")," - the name of your resource group in Azure where the app will be deployed"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"location")," - where your app is deployed, eg ",(0,a.kt)("inlineCode",{parentName:"li"},"northeurope")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"serviceConnection")," - the name of your AzureRM service connection in Azure DevOps"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"subscriptionId")," - your Azure subscription id from the ",(0,a.kt)("a",o({parentName:"li"},{href:"https://portal.azure.com"}),"Azure Portal")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"tenantId")," - the Azure tenant id from the ",(0,a.kt)("a",o({parentName:"li"},{href:"https://portal.azure.com"}),"Azure Portal"))),(0,a.kt)("h2",o({},{id:"running-the-pipeline"}),"Running the pipeline"),(0,a.kt)("p",null,"Now we're ready to run our pipeline:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of pipeline running successfully",src:n(64967).Z,width:"2796",height:"1848"})),(0,a.kt)("p",null,"Here we can see that the pipeline runs and the test passes. That means we've successfully provisioned the Event Hub and permissioned our pipeline to be able to access it using Azure RBAC role assignments. We then wrote a test which used the pipeline credentials to interact with the Event Hub. To see the repo that demostrates this, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://dev.azure.com/johnnyreilly/blog-demos/_git/permissioning-azure-pipelines-bicep-role-assignments"}),"look here"),"."),(0,a.kt)("p",null,"Just to reiterate: we've demonstrated this approach using Event Hubs. This is a generally useful approach which can be applied to any Azure resources that support Azure RBAC Role Assignments."),(0,a.kt)("p",null,"Thanks to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/foldr"}),"Jamie McCrindle")," for helping out with permissioning the service connection / service principal. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://foldr.uk/rotating-azure-credentials-in-github-with-terraform"}),"His post on rotating ",(0,a.kt)("inlineCode",{parentName:"a"},"AZURE_CREDENTIALS")," in GitHub with Terraform")," provides useful background for those who would like to do similar permissioning using Terraform."))}d.isMDXComponent=!0},90187:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"structured-data-seo-and-react",title:"Structured data, SEO and React",authors:"johnnyreilly",tags:["Structured Data","SEO","React"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/structured-data-seo-and-react",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-10-15-structured-data-seo-and-react/index.md",source:"@site/blog/2021-10-15-structured-data-seo-and-react/index.md",title:"Structured data, SEO and React",description:"People being able to discover your website when they search is important. This post is about how you can add structured data to a site. Adding structured data will help search engines like Google understand your content, and get it in front of more eyeballs. We'll illustrate this by making a simple React app which incorporates structured data.",date:"2021-10-15T00:00:00.000Z",formattedDate:"October 15, 2021",tags:[{label:"Structured Data",permalink:"/tags/structured-data"},{label:"SEO",permalink:"/tags/seo"},{label:"React",permalink:"/tags/react"}],readingTime:6.1,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"structured-data-seo-and-react",title:"Structured data, SEO and React",authors:"johnnyreilly",tags:["Structured Data","SEO","React"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"Docusaurus, meta tags and Google Discover",permalink:"/docusaurus-meta-tags-and-google-discover"},nextItem:{title:"Permissioning Azure Pipelines with Bicep and Azure RBAC Role Assignments",permalink:"/permissioning-azure-pipelines-bicep-role-assignments"}},p={image:n(53008).Z,authorsImageUrls:[void 0]},u=[{value:"Updated 5th January 2023",id:"updated-5th-january-2023",level:2},{value:"What is structured data?",id:"what-is-structured-data",level:2},{value:"Structured data in action",id:"structured-data-in-action",level:2},{value:"Adding structured data to a website",id:"adding-structured-data-to-a-website",level:2},{value:"Using the Rich Results Test",id:"using-the-rich-results-test",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"People being able to discover your website when they search is important. This post is about how you can add structured data to a site. Adding structured data will help search engines like Google understand your content, and get it in front of more eyeballs. We'll illustrate this by making a simple React app which incorporates structured data."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Structured data, SEO and React&quot; with a screenshot of the rich results tool in the background",src:n(53008).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"updated-5th-january-2023"}),"Updated 5th January 2023"),(0,a.kt)("p",null,"This blog evolved to become a talk:"),(0,a.kt)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/zi1CHB-eVck?start=282",title:"YouTube video player",frameBorder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowFullScreen:!0}),(0,a.kt)("p",null,"If you'd like to read about the related topic of ",(0,a.kt)("a",o({parentName:"p"},{href:"/docusaurus-blogs-adding-breadcrumb-structured-data"}),"adding breadcrumb Structured Data to a Docusaurus app, I've another post covering that"),"."),(0,a.kt)("h2",o({},{id:"what-is-structured-data"}),"What is structured data?"),(0,a.kt)("p",null,'Google, DuckDuckGo and others are proficient at understanding the content of websites. However, scraping HTML is not a highly reliable way to categorise content. HTML is about presentation and it can have all manner of different structures. To make the life of search engines easier, there\'s a standardized format known as "structured data" which can be embedded within a page. That standardized format allows you to explicitly declare the type of content the page contains.'),(0,a.kt)("p",null,"So let's say you've written an article, you can reliably state in a language that Google understands \"this page is an article, it has this title, this description and image and was published on this date\". There are hundreds of types of structured data available, and you can read about all of them in depth at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://schema.org/"}),"https://schema.org/")," which is maintained by representatives of the search engine community."),(0,a.kt)("p",null,"It's worth knowing that whilst there are many types of structured data available to choose from, there are definitely more popular options and those that are more niche. So ",(0,a.kt)("a",o({parentName:"p"},{href:"https://schema.org/Article"}),"Article")," is likely to be used a great deal more than, perhaps, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://schema.org/MolecularEntity"}),"MolecularEntity"),"."),(0,a.kt)("p",null,"As well as there being different types of structured data, there also a variety of formats which can be used to provide it; these include ",(0,a.kt)("a",o({parentName:"p"},{href:"http://json-ld.org/"}),"JSON-LD"),", ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.w3.org/TR/microdata/"}),"Microdata")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://rdfa.info/"}),"RDFa"),". Google explicitly prefer JSON-LD and so that's what we'll focus on. JSON-LD is effectively a rending of a piece of JSON inside a ",(0,a.kt)("inlineCode",{parentName:"p"},"script")," tag with the custom type of ",(0,a.kt)("inlineCode",{parentName:"p"},"application/ld+json"),". For example:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<script type="application/ld+json">\n  {\n    "@context": "https://schema.org/",\n    "@type": "Recipe",\n    "name": "Chocolate Brownie",\n    "author": {\n      "@type": "Person",\n      "name": "John Reilly"\n    },\n    "datePublished": "2014-09-01",\n    "description": "The most amazing chocolate brownie recipe",\n    "prepTime": "PT60M"\n  }\n<\/script>\n')),(0,a.kt)("h2",o({},{id:"structured-data-in-action"}),"Structured data in action"),(0,a.kt)("p",null,"Whilst structured data is helpful for search engines in general, it can also make a difference to the way your content is rendered ",(0,a.kt)("em",{parentName:"p"},"inside"),' search results. For instance, let\'s search for "best brownie recipe" in Google and see what shows up:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of google search results for &quot;best brownie recipe&quot; including a rich text results set at the top of the list showing recipes from various sources",src:n(53415).Z,width:"1788",height:"1111"})),(0,a.kt)("p",null,"When you look at the screenshot above, you'll notice that at the top of the list (before the main search results) there's a carousel which shows various brownie recipe links, with dedicated pictures, titles and descriptions. Where did this come from? The answer, unsurprisingly, is structured data."),(0,a.kt)("p",null,"If we click on the first link, we're taken to the recipe in question. Looking at the HTML of that page we find a number of JSON-LD sections:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of JSON-LD sections in the BBC Good Food website",src:n(32440).Z,width:"2415",height:"897"})),(0,a.kt)("p",null,"If we grab the content of one JSON-LD section and paste it into the devtools console, it becomes much easier to read:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of JSON-LD section transformed into a JavaScript Object Literal",src:n(7896).Z,width:"3000",height:"839"})),(0,a.kt)("p",null,"If we look at the ",(0,a.kt)("inlineCode",{parentName:"p"},"@type")," property we can see it's a ",(0,a.kt)("inlineCode",{parentName:"p"},'"Recipe"'),". This means it's an example of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://schema.org/Recipe"}),"https://schema.org/Recipe")," schema. If we look further at the ",(0,a.kt)("inlineCode",{parentName:"p"},"headline")," property, it reads ",(0,a.kt)("inlineCode",{parentName:"p"},'"Best ever chocolate brownies recipe"'),". That matches up with headline that was displayed in the search results."),(0,a.kt)("p",null,"Now we have a sense of what the various search engines are using as they categorise the page, and we understand exactly what is powering the carousel in the Google search results."),(0,a.kt)("p",null,'Incidentally, there\'s a special name for this "carousel"; it is a "rich result". A rich result is a search result singled out for special treatment when it is displayed. Google provide a ',(0,a.kt)("a",o({parentName:"p"},{href:"https://search.google.com/test/rich-results"}),"Rich Results Test tool")," which allows you to validate if a site provides structured data which is eligible to be featured in rich results. We'll make use of this later."),(0,a.kt)("h2",o({},{id:"adding-structured-data-to-a-website"}),"Adding structured data to a website"),(0,a.kt)("p",null,"Now we'll make ourselves a React app and add structured data to it. In the console we'll execute the following command:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"npx create-react-app my-app\n")),(0,a.kt)("p",null,"We now have a simple React app which consists of a single page. Let's replace the content of the existing ",(0,a.kt)("inlineCode",{parentName:"p"},"App.js")," file with this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-jsx"}),"//@ts-check\nimport './App.css';\n\nfunction App() {\n  // https://schema.org/Article\n  const articleStructuredData = {\n    '@context': 'https://schema.org',\n    '@type': 'Article',\n    headline: 'Structured data for you',\n    description: 'This is an article that demonstrates structured data.',\n    image: 'https://upload.wikimedia.org/wikipedia/commons/4/40/JSON-LD.svg',\n    datePublished: new Date('2021-09-04T09:25:01.340Z').toISOString(),\n    author: {\n      '@type': 'Person',\n      name: 'John Reilly',\n      url: 'https://twitter.com/johnny_reilly',\n    },\n  };\n\n  return (\n    <div className=\"App\">\n      <script type=\"application/ld+json\">\n        {JSON.stringify(articleStructuredData)}\n      <\/script>\n\n      <h1>{articleStructuredData.headline}</h1>\n      <h3>\n        by{' '}\n        <a href={articleStructuredData.author.url}>\n          {articleStructuredData.author.name}\n        </a>{' '}\n        on {articleStructuredData.datePublished}\n      </h3>\n\n      <img\n        style={{ width: '5em' }}\n        alt=\"https://json-ld.org/ - Website content released under a Creative Commons CC0 Public Domain Dedication except where an alternate is specified., CC0, via Wikimedia Commons\"\n        src={articleStructuredData.image}\n      />\n\n      <p>{articleStructuredData.description}</p>\n\n      <p>Take a look at the source of this page and find the JSON-LD!</p>\n    </div>\n  );\n}\n\nexport default App;\n")),(0,a.kt)("p",null,"If we look at the code above, we can see we're creating a JavaScript object literal named ",(0,a.kt)("inlineCode",{parentName:"p"},"articleStructuredData")," which contains the data of an ",(0,a.kt)("a",o({parentName:"p"},{href:"https://schema.org/Article"}),"https://schema.org/Article"),". ",(0,a.kt)("inlineCode",{parentName:"p"},"articleStructuredData")," is then used to do two things:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"to contribute to the content of the page"),(0,a.kt)("li",{parentName:"ol"},"to render a JSON-LD script tag: ",(0,a.kt)("inlineCode",{parentName:"li"},'<script type="application/ld+json">')," which is populated by calling ",(0,a.kt)("inlineCode",{parentName:"li"},"JSON.stringify(articleStructuredData)"))),(0,a.kt)("p",null,"When we run our site locally with ",(0,a.kt)("inlineCode",{parentName:"p"},"npm start")," we see a simple article site that looks like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of article page",src:n(18608).Z,width:"1091",height:"618"})),(0,a.kt)("p",null,"Now let's see if it supports structured data in the way we hope."),(0,a.kt)("h2",o({},{id:"using-the-rich-results-test"}),"Using the Rich Results Test"),(0,a.kt)("p",null,"If we go to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://search.google.com/test/rich-results"}),"https://search.google.com/test/rich-results")," we find the Rich Results Test tool. There's two ways you can test; providing a URL or providing code. In our case we don't have a public facing URL and so we're going to use the HTML that React is rendering."),(0,a.kt)("p",null,"In devtools we'll use the \"copy outerHTML\" feature to grab the HTML, then we'll paste it into Rich Results:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of rich results tool in code view",src:n(61889).Z,width:"1862",height:"1457"})),(0,a.kt)("p",null,'We hit the "TEST CODE" button and we see results that look like this:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the results of testing our site using the rich results tool",src:n(86373).Z,width:"3018",height:"1529"})),(0,a.kt)("p",null,"So we've been successful in building a website that renders structured data. More than that, we're doing it in a way that we know Google will recognise and can use to render rich results in search. That's a really useful way to drive traffic to our website."),(0,a.kt)("p",null,"This post has illustrated what it looks like to create an ",(0,a.kt)("inlineCode",{parentName:"p"},"Article"),". Google has some ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/search/docs/advanced/structured-data/search-gallery"}),"great resources")," on other types that it supports and prioritises for rich results which should help you build the structured data you need for your particular content."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/react-structured-data-and-seo/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/react-structured-data-and-seo/"})))}d.isMDXComponent=!0},90029:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"docusaurus-meta-tags-and-google-discover",title:"Docusaurus, meta tags and Google Discover",authors:"johnnyreilly",tags:["Docusaurus"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/docusaurus-meta-tags-and-google-discover",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-10-18-docusaurus-meta-tags-and-google-discover/index.md",source:"@site/blog/2021-10-18-docusaurus-meta-tags-and-google-discover/index.md",title:"Docusaurus, meta tags and Google Discover",description:"Google Discover is a way that people can find your content. To make your content more attractive, Google encourage using high quality images which are enabled by setting the max-image-preview:large meta tag. This post shows you how to achieve that with Docusaurus.",date:"2021-10-18T00:00:00.000Z",formattedDate:"October 18, 2021",tags:[{label:"Docusaurus",permalink:"/tags/docusaurus"}],readingTime:2.675,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"docusaurus-meta-tags-and-google-discover",title:"Docusaurus, meta tags and Google Discover",authors:"johnnyreilly",tags:["Docusaurus"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"NSwag generated C# client: Open API property name clashes and decimal types rather than double",permalink:"/nswag-generated-c-sharp-client-property-name-clash"},nextItem:{title:"Structured data, SEO and React",permalink:"/structured-data-seo-and-react"}},p={image:n(96879).Z,authorsImageUrls:[void 0]},u=[{value:"Google Discover",id:"google-discover",level:2},{value:"Docusaurus let&#39;s get meta",id:"docusaurus-lets-get-meta",level:2},{value:"Meta meta",id:"meta-meta",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Google Discover is a way that people can find your content. To make your content more attractive, Google encourage using high quality images which are enabled by setting the ",(0,a.kt)("inlineCode",{parentName:"p"},"max-image-preview:large")," meta tag. This post shows you how to achieve that with Docusaurus."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Docusaurus, meta tags and Google Discover&quot; with a Docusaurus logo and the Google Discover phone photo taken from https://developers.google.com/search/docs/advanced/mobile/google-discover",src:n(96879).Z,width:"2400",height:"1710"})),(0,a.kt)("h2",o({},{id:"google-discover"}),"Google Discover"),(0,a.kt)("p",null,"I'm an Android user. Google Discover will present articles to me in various places on my phone. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/search/docs/advanced/mobile/google-discover"}),"According to the docs"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"With Discover, you can get updates for your interests, like your favorite sports team or news site, without searching for them. You can choose the types of updates you want to see in Discover in the Google app or when you\u2019re browsing the web on your phone.")),(0,a.kt)("p",null,'It turns out that my own content is showing up in Discover. I (ahem) discovered this by looking at the Google search console and noticing a "Discover" tab:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the Google search console featuring a &quot;discover&quot; image",src:n(70135).Z,width:"2064",height:"1202"})),(0,a.kt)("p",null,"As I read up about Discover I noticed this:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"To increase the likelihood of your content appearing in Discover, we recommend the following:\n..."),(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"},"Include compelling, high-quality images in your content, especially large images that are more likely to generate visits from Discover. Large images need to be at least 1200 px wide and enabled by the ",(0,a.kt)("inlineCode",{parentName:"li"},"max-image-preview:large")," setting..."))),(0,a.kt)("p",null,"I was already trying to include images with my blog posts as described... But ",(0,a.kt)("inlineCode",{parentName:"p"},"max-image-preview:large")," was news to me. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/search/docs/advanced/robots/robots_meta_tag#max-image-preview"}),"Reading up further"),' revealed that the "setting" was simply a meta tag to be added to the HTML that looked like this:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<meta name="robots" content="max-image-preview:standard" />\n')),(0,a.kt)("p",null,"Incidentally, applying this setting will affect all forms of search results. So not just Discover, but Google web search, Google Images and Assistant as well. The result of having this meta tag will be that bigger images are displayed in search results, which should make the content more attractive."),(0,a.kt)("h2",o({},{id:"docusaurus-lets-get-meta"}),"Docusaurus let's get meta"),(0,a.kt)("p",null,"Now we understand what we want (an extra meta tag on all our pages), how do we apply this to Docusaurus?"),(0,a.kt)("p",null,"Well, it's remarkably simple. There's an optional ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/docs/api/themes/configuration#metadata"}),(0,a.kt)("inlineCode",{parentName:"a"},"metadata"))," property in ",(0,a.kt)("inlineCode",{parentName:"p"},"docusaurus.config.js"),". This property allows you to configure additional html metadata (and override existing ones). The property is an array of ",(0,a.kt)("inlineCode",{parentName:"p"},"Metadata"),", each entry of which will be directly passed to the ",(0,a.kt)("inlineCode",{parentName:"p"},"<meta />")," tag."),(0,a.kt)("p",null,"So in our case we'd want to pass an object with ",(0,a.kt)("inlineCode",{parentName:"p"},"name: 'robots'")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"content: 'max-image-preview:large'")," to render our desired meta tag. Which looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"/** @type {import('@docusaurus/types').DocusaurusConfig} */\nmodule.exports = {\n  //...\n  themeConfig: {\n    // <meta name=\"robots\" content=\"max-image-preview:large\">\n    metadata: [{ name: 'robots', content: 'max-image-preview:large' }],\n    //...\n  },\n  //...\n};\n")),(0,a.kt)("p",null,"With that in place, we find our expected ",(0,a.kt)("inlineCode",{parentName:"p"},"meta")," tag is now part of our rendered HTML:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the &lt;meta name=&quot;robots&quot; content=&quot;max-image-preview:large&quot;&gt; tag taken from Chrome Devtools",src:n(66792).Z,width:"1546",height:"418"})),(0,a.kt)("h2",o({},{id:"meta-meta"}),"Meta meta"),(0,a.kt)("p",null,"We should now have a more Google Discover-friendly website which is tremendous!"),(0,a.kt)("p",null,"Before signing off, here's a fun fact: the PR that published this blog post is the ",(0,a.kt)("em",{parentName:"p"},"same")," PR that added ",(0,a.kt)("inlineCode",{parentName:"p"},"max-image-preview:standard")," to my blog. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/pull/114"}),"Peep it here")," - meta in so many ways \ud83d\ude09"))}d.isMDXComponent=!0},18661:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"nswag-generated-c-sharp-client-property-name-clash",title:"NSwag generated C# client: Open API property name clashes and decimal types rather than double",authors:"johnnyreilly",tags:["NSwag","C#"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/nswag-generated-c-sharp-client-property-name-clash",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-10-31-nswag-generated-c-sharp-client-property-name-clash/index.md",source:"@site/blog/2021-10-31-nswag-generated-c-sharp-client-property-name-clash/index.md",title:"NSwag generated C# client: Open API property name clashes and decimal types rather than double",description:"NSwag is a great tool for generating client libraries in C# and TypeScript from Open API / Swagger definitions. You can face issues where Open API property names collide due to the nature of the C# language, and when you want to use decimal for your floating point numeric type over double. This post demonstrates how to get over both issues.",date:"2021-10-31T00:00:00.000Z",formattedDate:"October 31, 2021",tags:[{label:"NSwag",permalink:"/tags/n-swag"},{label:"C#",permalink:"/tags/c"}],readingTime:10.58,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"nswag-generated-c-sharp-client-property-name-clash",title:"NSwag generated C# client: Open API property name clashes and decimal types rather than double",authors:"johnnyreilly",tags:["NSwag","C#"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"Azure standard availability tests with Bicep",permalink:"/azure-standard-tests-with-bicep"},nextItem:{title:"Docusaurus, meta tags and Google Discover",permalink:"/docusaurus-meta-tags-and-google-discover"}},p={image:n(56910).Z,authorsImageUrls:[void 0]},u=[{value:"Make a C# Client Generator",id:"make-a-c-client-generator",level:2},{value:"When properties collide",id:"when-properties-collide",level:2},{value:"Use <code>decimal</code> not <code>double</code> for floating point numbers",id:"use-decimal-not-double-for-floating-point-numbers",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"NSwag is a great tool for generating client libraries in C# and TypeScript from Open API / Swagger definitions. You can face issues where Open API property names collide due to the nature of the C# language, and when you want to use ",(0,a.kt)("inlineCode",{parentName:"p"},"decimal")," for your floating point numeric type over ",(0,a.kt)("inlineCode",{parentName:"p"},"double"),". This post demonstrates how to get over both issues."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;NSwag generated C# client: Open API property name clashes and decimal types rather than double&quot; with a C# logo and Open API logos",src:n(56910).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"make-a-c-client-generator"}),"Make a C# Client Generator"),(0,a.kt)("p",null,"Let's get a console app set up that will allow us to generate a C# client using an Open API file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-sh"}),"dotnet new console -o NSwag\ncd NSwag\ndotnet add package NSwag.CodeGeneration.CSharp\n")),(0,a.kt)("p",null,"We'll also add a ",(0,a.kt)("inlineCode",{parentName:"p"},"petstore-simple.json")," file to our project which we'll borrow from ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/OAI/OpenAPI-Specification/blob/main/examples/v2.0/json/petstore-simple.json"}),"https://github.com/OAI/OpenAPI-Specification/blob/main/examples/v2.0/json/petstore-simple.json")," (home of the Open API specification):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "swagger": "2.0",\n  "info": {\n    "version": "1.0.0",\n    "title": "Swagger Petstore",\n    "description": "A sample API that uses a petstore as an example to demonstrate features in the swagger-2.0 specification",\n    "termsOfService": "http://swagger.io/terms/",\n    "contact": {\n      "name": "Swagger API Team"\n    },\n    "license": {\n      "name": "MIT"\n    }\n  },\n  "host": "petstore.swagger.io",\n  "basePath": "/api",\n  "schemes": ["http"],\n  "consumes": ["application/json"],\n  "produces": ["application/json"],\n  "paths": {\n    "/pets": {\n      "get": {\n        "description": "Returns all pets from the system that the user has access to",\n        "operationId": "findPets",\n        "produces": [\n          "application/json",\n          "application/xml",\n          "text/xml",\n          "text/html"\n        ],\n        "parameters": [\n          {\n            "name": "tags",\n            "in": "query",\n            "description": "tags to filter by",\n            "required": false,\n            "type": "array",\n            "items": {\n              "type": "string"\n            },\n            "collectionFormat": "csv"\n          },\n          {\n            "name": "limit",\n            "in": "query",\n            "description": "maximum number of results to return",\n            "required": false,\n            "type": "integer",\n            "format": "int32"\n          }\n        ],\n        "responses": {\n          "200": {\n            "description": "pet response",\n            "schema": {\n              "type": "array",\n              "items": {\n                "$ref": "#/definitions/Pet"\n              }\n            }\n          },\n          "default": {\n            "description": "unexpected error",\n            "schema": {\n              "$ref": "#/definitions/ErrorModel"\n            }\n          }\n        }\n      },\n      "post": {\n        "description": "Creates a new pet in the store.  Duplicates are allowed",\n        "operationId": "addPet",\n        "produces": ["application/json"],\n        "parameters": [\n          {\n            "name": "pet",\n            "in": "body",\n            "description": "Pet to add to the store",\n            "required": true,\n            "schema": {\n              "$ref": "#/definitions/NewPet"\n            }\n          }\n        ],\n        "responses": {\n          "200": {\n            "description": "pet response",\n            "schema": {\n              "$ref": "#/definitions/Pet"\n            }\n          },\n          "default": {\n            "description": "unexpected error",\n            "schema": {\n              "$ref": "#/definitions/ErrorModel"\n            }\n          }\n        }\n      }\n    },\n    "/pets/{id}": {\n      "get": {\n        "description": "Returns a user based on a single ID, if the user does not have access to the pet",\n        "operationId": "findPetById",\n        "produces": [\n          "application/json",\n          "application/xml",\n          "text/xml",\n          "text/html"\n        ],\n        "parameters": [\n          {\n            "name": "id",\n            "in": "path",\n            "description": "ID of pet to fetch",\n            "required": true,\n            "type": "integer",\n            "format": "int64"\n          }\n        ],\n        "responses": {\n          "200": {\n            "description": "pet response",\n            "schema": {\n              "$ref": "#/definitions/Pet"\n            }\n          },\n          "default": {\n            "description": "unexpected error",\n            "schema": {\n              "$ref": "#/definitions/ErrorModel"\n            }\n          }\n        }\n      },\n      "delete": {\n        "description": "deletes a single pet based on the ID supplied",\n        "operationId": "deletePet",\n        "parameters": [\n          {\n            "name": "id",\n            "in": "path",\n            "description": "ID of pet to delete",\n            "required": true,\n            "type": "integer",\n            "format": "int64"\n          }\n        ],\n        "responses": {\n          "204": {\n            "description": "pet deleted"\n          },\n          "default": {\n            "description": "unexpected error",\n            "schema": {\n              "$ref": "#/definitions/ErrorModel"\n            }\n          }\n        }\n      }\n    }\n  },\n  "definitions": {\n    "Pet": {\n      "type": "object",\n      "allOf": [\n        {\n          "$ref": "#/definitions/NewPet"\n        },\n        {\n          "required": ["id"],\n          "properties": {\n            "id": {\n              "type": "integer",\n              "format": "int64"\n            }\n          }\n        }\n      ]\n    },\n    "NewPet": {\n      "type": "object",\n      "required": ["name"],\n      "properties": {\n        "name": {\n          "type": "string"\n        },\n        "tag": {\n          "type": "string"\n        }\n      }\n    },\n    "ErrorModel": {\n      "type": "object",\n      "required": ["code", "message"],\n      "properties": {\n        "code": {\n          "type": "integer",\n          "format": "int32"\n        },\n        "message": {\n          "type": "string"\n        }\n      }\n    }\n  }\n}\n')),(0,a.kt)("p",null,"We'll tweak our ",(0,a.kt)("inlineCode",{parentName:"p"},"NSwag.csproj")," file to ensure that the ",(0,a.kt)("inlineCode",{parentName:"p"},"json")," file is included in our build output:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<Project Sdk="Microsoft.NET.Sdk">\n  \x3c!-- ... ---\x3e\n  <ItemGroup>\n    <Content Include="**\\*.json">\n      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n    </Content>\n  </ItemGroup>\n</Project>\n')),(0,a.kt)("p",null,"This will give us a console app with a reference to NSwag. Now we'll flesh out the ",(0,a.kt)("inlineCode",{parentName:"p"},"Program.cs")," file thusly:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.IO;\nusing System.Reflection;\nusing System.Threading.Tasks;\nusing NJsonSchema;\nusing NJsonSchema.Visitors;\nusing NSwag.CodeGeneration.CSharp;\n\nnamespace NSwag {\n    class Program {\n        static async Task Main(string[] args) {\n            Console.WriteLine("Generating client...");\n            await ClientGenerator.GenerateCSharpClient();\n            Console.WriteLine("Generated client.");\n        }\n    }\n\n    public static class ClientGenerator {\n\n        public async static Task GenerateCSharpClient() =>\n            GenerateClient(\n                // https://github.com/OAI/OpenAPI-Specification/blob/main/examples/v2.0/json/petstore-simple.json\n                document: await GetDocumentFromFile("petstore-simple.json"),\n                generatedLocation: "GeneratedClient.cs",\n                generateCode: (OpenApiDocument document) => {\n                    var settings = new CSharpClientGeneratorSettings();\n\n                    var generator = new CSharpClientGenerator(document, settings);\n                    var code = generator.GenerateFile();\n                    return code;\n                }\n            );\n\n        private static void GenerateClient(OpenApiDocument document, string generatedLocation, Func<OpenApiDocument, string> generateCode) {\n            var root = Path.GetDirectoryName(Assembly.GetEntryAssembly().Location);\n            var location = Path.GetFullPath(Path.Join(root, @"../../../", generatedLocation));\n\n            Console.WriteLine($"Generating {location}...");\n\n            var code = generateCode(document);\n\n            System.IO.File.WriteAllText(location, code);\n        }\n\n        private static async Task<OpenApiDocument> GetDocumentFromFile(string swaggerJsonFilePath) {\n            var root = Path.GetDirectoryName(Assembly.GetEntryAssembly().Location);\n            var swaggerJson = await File.ReadAllTextAsync(Path.GetFullPath(Path.Join(root, swaggerJsonFilePath)));\n            var document = await OpenApiDocument.FromJsonAsync(swaggerJson);\n\n            return document;\n        }\n    }\n}\n')),(0,a.kt)("p",null,"If we perform a ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet run")," we now pump out a ",(0,a.kt)("inlineCode",{parentName:"p"},"GeneratedClient.cs")," file which is a C# client library for the pet store. Fabulous."),(0,a.kt)("p",null,"So far so dandy. We're taking an Open API ",(0,a.kt)("inlineCode",{parentName:"p"},"json")," file and generating a C# client library from it."),(0,a.kt)("h2",o({},{id:"when-properties-collide"}),"When properties collide"),(0,a.kt)("p",null,"It's time to break things. We're presently generating a ",(0,a.kt)("inlineCode",{parentName:"p"},"Pet")," class that looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[System.CodeDom.Compiler.GeneratedCode("NJsonSchema", "10.5.2.0 (Newtonsoft.Json v13.0.0.0)")]\npublic partial class Pet : NewPet\n{\n    [Newtonsoft.Json.JsonProperty("id", Required = Newtonsoft.Json.Required.Always)]\n    public long Id { get; set; }\n}\n')),(0,a.kt)("p",null,"We're going to take our ",(0,a.kt)("inlineCode",{parentName:"p"},"Pet")," definition in the ",(0,a.kt)("inlineCode",{parentName:"p"},"petstore-simple.json")," file, and add a new ",(0,a.kt)("inlineCode",{parentName:"p"},"@id")," property alongside the ",(0,a.kt)("inlineCode",{parentName:"p"},"id")," property:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"Pet": {\n    "type": "object",\n    "allOf": [\n        {\n            "$ref": "#/definitions/NewPet"\n        },\n        {\n            "required": [\n                "id"\n            ],\n            "properties": {\n                "id": {\n                    "type": "integer",\n                    "format": "int64"\n                },\n                "@id": {\n                    "type": "integer",\n                    "format": "int64"\n                }\n            }\n        }\n    ]\n},\n')),(0,a.kt)("p",null,"For why? Whilst this may seem esoteric, this is a scenario that can present. It's not unknown to encounter properties which are identical, save for an ",(0,a.kt)("inlineCode",{parentName:"p"},"@")," prefix. This is often the case for meta-properties."),(0,a.kt)("p",null,"What do we get if we run our generator over that?"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[System.CodeDom.Compiler.GeneratedCode("NJsonSchema", "10.5.2.0 (Newtonsoft.Json v13.0.0.0)")]\npublic partial class Pet : NewPet\n{\n    [Newtonsoft.Json.JsonProperty("id", Required = Newtonsoft.Json.Required.Always)]\n    public long Id { get; set; }\n\n    [Newtonsoft.Json.JsonProperty("@id", Required = Newtonsoft.Json.Required.Always)]\n    public long Id { get; set; }\n}\n')),(0,a.kt)("p",null,"We get code that doesn't compile. You can't have two properties in a C# class with the same name. You also cannot have ",(0,a.kt)("inlineCode",{parentName:"p"},"@")," as a character in a C# property or variable name. To quote the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/tokens/verbatim"}),"docs"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"The @ special character serves as a verbatim identifier.")),(0,a.kt)("p",null,"It so happens that, by default, NSwag purges ",(0,a.kt)("inlineCode",{parentName:"p"},"@")," characters from property names. If there isn't another property which is named the same save for an ",(0,a.kt)("inlineCode",{parentName:"p"},"@")," prefix, this is a fine strategy. If there is, as for us now, you're toast."),(0,a.kt)("p",null,"There's a workaround. We'll create a new ",(0,a.kt)("inlineCode",{parentName:"p"},"HandleAtCSharpPropertyNameGenerator")," class:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'/// <summary>\n/// Replace characters which will not comply with C# syntax with something that will\n/// </summary>\npublic class HandleAtCSharpPropertyNameGenerator : NJsonSchema.CodeGeneration.IPropertyNameGenerator {\n    /// <summary>Generates the property name.</summary>\n    /// <param name="property">The property.</param>\n    /// <returns>The new name.</returns>\n    public virtual string Generate(JsonSchemaProperty property) =>\n        ConversionUtilities.ConvertToUpperCamelCase(property.Name\n            .Replace("\\"", string.Empty)\n            .Replace("@", "__") // make "@" => "__", so "@type" => "__type"\n            .Replace("?", string.Empty)\n            .Replace("$", string.Empty)\n            .Replace("[", string.Empty)\n            .Replace("]", string.Empty)\n            .Replace("(", "_")\n            .Replace(")", string.Empty)\n            .Replace(".", "-")\n            .Replace("=", "-")\n            .Replace("+", "plus"), true)\n            .Replace("*", "Star")\n            .Replace(":", "_")\n            .Replace("-", "_")\n            .Replace("#", "_");\n}\n')),(0,a.kt)("p",null,"This is a replacement for the ",(0,a.kt)("inlineCode",{parentName:"p"},"CSharpPropertyNameGenerator")," that NSwag ships with. Rather than purging the ",(0,a.kt)("inlineCode",{parentName:"p"},"@")," character, it replaces usage with a double underscore: ",(0,a.kt)("inlineCode",{parentName:"p"},"__"),"."),(0,a.kt)("p",null,"We'll make use of our new ",(0,a.kt)("inlineCode",{parentName:"p"},"PropertyNameGenerator"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public async static Task GenerateCSharpClient() =>\n    GenerateClient(\n        // https://github.com/OAI/OpenAPI-Specification/blob/main/examples/v2.0/json/petstore-simple.json\n        document: await GetDocumentFromFile("petstore-simple.json"),\n        generatedLocation: "GeneratedClient.cs",\n        generateCode: (OpenApiDocument document) => {\n            var settings = new CSharpClientGeneratorSettings {\n                CSharpGeneratorSettings = {\n                    PropertyNameGenerator = new HandleAtCSharpPropertyNameGenerator() // @ shouldn\'t cause us problems\n                }\n            };\n\n            var generator = new CSharpClientGenerator(document, settings);\n            var code = generator.GenerateFile();\n            return code;\n        }\n    );\n')),(0,a.kt)("p",null,"With this in place, when we ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet run")," we create a class that looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[System.CodeDom.Compiler.GeneratedCode("NJsonSchema", "10.5.2.0 (Newtonsoft.Json v13.0.0.0)")]\npublic partial class Pet : NewPet\n{\n    [Newtonsoft.Json.JsonProperty("id", Required = Newtonsoft.Json.Required.Always)]\n    public long Id { get; set; }\n\n    [Newtonsoft.Json.JsonProperty("@id", Required = Newtonsoft.Json.Required.Always)]\n    public long __id { get; set; }\n}\n')),(0,a.kt)("p",null,"So the newly generated property name is ",(0,a.kt)("inlineCode",{parentName:"p"},"__id")," rather than the clashing ",(0,a.kt)("inlineCode",{parentName:"p"},"Id"),". Rather wonderfully, this works. It resolves the issue we faced. We've chosen to use ",(0,a.kt)("inlineCode",{parentName:"p"},"__")," as our prefix - we could choose something else if that worked better for us."),(0,a.kt)("p",null,"Knowing that this hook exists is super useful."),(0,a.kt)("h2",o({},{id:"use-decimal-not-double-for-floating-point-numbers"}),"Use ",(0,a.kt)("inlineCode",{parentName:"h2"},"decimal")," not ",(0,a.kt)("inlineCode",{parentName:"h2"},"double")," for floating point numbers"),(0,a.kt)("p",null,"Another common problem with generated C# clients is the number type used to represent floating point numbers. The default for C# is ",(0,a.kt)("inlineCode",{parentName:"p"},"double"),"."),(0,a.kt)("p",null,"This is a reasonable choice when you consider the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://swagger.io/docs/specification/data-models/data-types/#numbers"}),"official format")," for highly precise floating point numbers is ",(0,a.kt)("inlineCode",{parentName:"p"},"double"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"OpenAPI has two numeric types, ",(0,a.kt)("inlineCode",{parentName:"p"},"number")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"integer"),", where ",(0,a.kt)("inlineCode",{parentName:"p"},"number")," includes both integer and floating-point numbers. An optional ",(0,a.kt)("inlineCode",{parentName:"p"},"format")," keyword serves as a hint for the tools to use a specific numeric type:"),(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("inlineCode",{parentName:"p"},"float")," - Floating-point numbers.\n",(0,a.kt)("inlineCode",{parentName:"p"},"double")," - Floating-point numbers with double precision.")),(0,a.kt)("p",null,"Let's tweak our pet definition to reflect this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"Pet": {\n    "type": "object",\n    "allOf": [\n        {\n            "$ref": "#/definitions/NewPet"\n        },\n        {\n            "required": [\n                "id"\n            ],\n            "properties": {\n                "id": {\n                    "type": "number",\n                    "format": "double"\n                },\n                "@id": {\n                    "type": "number",\n                    "format": "double"\n                }\n            }\n        }\n    ]\n},\n')),(0,a.kt)("p",null,"With this in place, when we ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet run")," we create a class that looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[System.CodeDom.Compiler.GeneratedCode("NJsonSchema", "10.5.2.0 (Newtonsoft.Json v13.0.0.0)")]\npublic partial class Pet : NewPet\n{\n    [Newtonsoft.Json.JsonProperty("id", Required = Newtonsoft.Json.Required.Always)]\n    public double Id { get; set; }\n\n    [Newtonsoft.Json.JsonProperty("@id", Required = Newtonsoft.Json.Required.Always)]\n    public double __id { get; set; }\n}\n')),(0,a.kt)("p",null,"C# developers may well rather work with a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/api/system.decimal?view=net-5.0"}),(0,a.kt)("inlineCode",{parentName:"a"},"decimal")),' type which can handle "financial calculations that require large numbers of significant integral and fractional digits and no round-off errors".'),(0,a.kt)("p",null,"There is a way to switch from using ",(0,a.kt)("inlineCode",{parentName:"p"},"double")," to ",(0,a.kt)("inlineCode",{parentName:"p"},"decimal")," in your generated clients. I've been using the approach for some years, and I suspect I first adapted it from ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/RicoSuter/NSwag/issues/1814#issuecomment-448752684"}),"a comment on GitHub"),"."),(0,a.kt)("p",null,"It uses the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.m.wikipedia.org/wiki/Visitor_pattern"}),"visitor pattern")," and looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"/// <summary>\n/// By default the C# decimal number type used is double; this makes it decimal\n/// </summary>\npublic class DoubleToDecimalVisitor : JsonSchemaVisitorBase {\n    protected override JsonSchema VisitSchema(JsonSchema schema, string path, string typeNameHint) {\n        if (schema.Type == JsonObjectType.Number)\n            schema.Format = JsonFormatStrings.Decimal;\n\n        return schema;\n    }\n}\n")),(0,a.kt)("p",null,"The code above, when invoked upon our ",(0,a.kt)("inlineCode",{parentName:"p"},"OpenApiDocument"),", changes the format of all number types to be ",(0,a.kt)("inlineCode",{parentName:"p"},"decimal"),". Which results in code along these lines:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[System.CodeDom.Compiler.GeneratedCode("NJsonSchema", "10.5.2.0 (Newtonsoft.Json v13.0.0.0)")]\npublic partial class Pet : NewPet\n{\n    [Newtonsoft.Json.JsonProperty("id", Required = Newtonsoft.Json.Required.Always)]\n    public decimal Id { get; set; }\n\n    [Newtonsoft.Json.JsonProperty("@id", Required = Newtonsoft.Json.Required.Always)]\n    public decimal __id { get; set; }\n}\n')),(0,a.kt)("p",null,"If we take all the code, and put it together, we end up with this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.IO;\nusing System.Reflection;\nusing System.Threading.Tasks;\nusing NJsonSchema;\nusing NJsonSchema.Visitors;\nusing NSwag.CodeGeneration.CSharp;\n\nnamespace NSwag {\n    class Program {\n        static async Task Main(string[] args) {\n            Console.WriteLine("Generating client...");\n            await ClientGenerator.GenerateCSharpClient();\n            Console.WriteLine("Generated client.");\n        }\n    }\n\n    public static class ClientGenerator {\n\n        public async static Task GenerateCSharpClient() =>\n            GenerateClient(\n                // https://github.com/OAI/OpenAPI-Specification/blob/main/examples/v2.0/json/petstore-simple.json\n                document: await GetDocumentFromFile("petstore-simple.json"),\n                generatedLocation: "GeneratedClient.cs",\n                generateCode: (OpenApiDocument document) => {\n                    new DoubleToDecimalVisitor().Visit(document); // we want decimals not doubles\n\n                    var settings = new CSharpClientGeneratorSettings {\n                        CSharpGeneratorSettings = {\n                            PropertyNameGenerator = new HandleAtCSharpPropertyNameGenerator() // @ shouldn\'t cause us problems\n                        }\n                    };\n\n                    var generator = new CSharpClientGenerator(document, settings);\n                    var code = generator.GenerateFile();\n                    return code;\n                }\n            );\n\n        private static void GenerateClient(OpenApiDocument document, string generatedLocation, Func<OpenApiDocument, string> generateCode) {\n            var root = Path.GetDirectoryName(Assembly.GetEntryAssembly().Location);\n            var location = Path.GetFullPath(Path.Join(root, @"../../../", generatedLocation));\n\n            Console.WriteLine($"Generating {location}...");\n\n            var code = generateCode(document);\n\n            System.IO.File.WriteAllText(location, code);\n        }\n\n        private static async Task<OpenApiDocument> GetDocumentFromFile(string swaggerJsonFilePath) {\n            var root = Path.GetDirectoryName(Assembly.GetEntryAssembly().Location);\n            var swaggerJson = await File.ReadAllTextAsync(Path.GetFullPath(Path.Join(root, swaggerJsonFilePath)));\n            var document = await OpenApiDocument.FromJsonAsync(swaggerJson);\n\n            return document;\n        }\n    }\n\n    /// <summary>\n    /// By default the C# decimal number type used is double; this makes it decimal\n    /// </summary>\n    public class DoubleToDecimalVisitor : JsonSchemaVisitorBase {\n        protected override JsonSchema VisitSchema(JsonSchema schema, string path, string typeNameHint) {\n            if (schema.Type == JsonObjectType.Number)\n                schema.Format = JsonFormatStrings.Decimal;\n\n            return schema;\n        }\n    }\n\n    /// <summary>\n    /// Replace characters which will not comply with C# syntax with something that will\n    /// </summary>\n    public class HandleAtCSharpPropertyNameGenerator : NJsonSchema.CodeGeneration.IPropertyNameGenerator {\n        /// <summary>Generates the property name.</summary>\n        /// <param name="property">The property.</param>\n        /// <returns>The new name.</returns>\n        public virtual string Generate(JsonSchemaProperty property) =>\n            ConversionUtilities.ConvertToUpperCamelCase(property.Name\n                .Replace("\\"", string.Empty)\n                .Replace("@", "__") // make "@" => "__", so "@type" => "__type"\n                .Replace("?", string.Empty)\n                .Replace("$", string.Empty)\n                .Replace("[", string.Empty)\n                .Replace("]", string.Empty)\n                .Replace("(", "_")\n                .Replace(")", string.Empty)\n                .Replace(".", "-")\n                .Replace("=", "-")\n                .Replace("+", "plus"), true)\n                .Replace("*", "Star")\n                .Replace(":", "_")\n                .Replace("-", "_")\n                .Replace("#", "_");\n    }\n}\n')),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"This post takes the tremendous NSwag, and demonstrates a mechanism for using it to create C# clients from an Open API / Swagger documents which:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"can handle property names with an ",(0,a.kt)("inlineCode",{parentName:"li"},"@")," prefix which might collide with the same property without the prefix"),(0,a.kt)("li",{parentName:"ul"},"use ",(0,a.kt)("inlineCode",{parentName:"li"},"decimal")," as the preferred number type for floating point numbers")))}d.isMDXComponent=!0},62037:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-standard-tests-with-bicep",title:"Azure standard availability tests with Bicep",authors:"johnnyreilly",tags:["Azure","Bicep"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-standard-tests-with-bicep",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-11-18-azure-standard-tests-with-bicep/index.md",source:"@site/blog/2021-11-18-azure-standard-tests-with-bicep/index.md",title:"Azure standard availability tests with Bicep",description:"Azure standard tests are a tremendous way to monitor the uptime of your services in Azure. Sometimes also called availability tests, web tests and ping tests, this post goes through how to deploy one using Bicep. It also looks at some of the gotchas that you may encounter as you're setting it up.",date:"2021-11-18T00:00:00.000Z",formattedDate:"November 18, 2021",tags:[{label:"Azure",permalink:"/tags/azure"},{label:"Bicep",permalink:"/tags/bicep"}],readingTime:5.75,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-standard-tests-with-bicep",title:"Azure standard availability tests with Bicep",authors:"johnnyreilly",tags:["Azure","Bicep"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"TypeScript vs JSDoc JavaScript",permalink:"/typescript-vs-jsdoc-javascript"},nextItem:{title:"NSwag generated C# client: Open API property name clashes and decimal types rather than double",permalink:"/nswag-generated-c-sharp-client-property-name-clash"}},p={image:n(58406).Z,authorsImageUrls:[void 0]},u=[{value:"What are standard tests?",id:"what-are-standard-tests",level:2},{value:"Standard test Bicep",id:"standard-test-bicep",level:2},{value:"Locations / populations",id:"locations--populations",level:3},{value:"The <code>hidden-link</code> tag",id:"the-hidden-link-tag",level:3},{value:"App insights and standard tests share a resource group",id:"app-insights-and-standard-tests-share-a-resource-group",level:3},{value:"Using <code>standard-test.bicep</code>",id:"using-standard-testbicep",level:2},{value:"Azure Pipelines test",id:"azure-pipelines-test",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Azure standard tests are a tremendous way to monitor the uptime of your services in Azure. Sometimes also called availability tests, web tests and ping tests, this post goes through how to deploy one using Bicep. It also looks at some of the gotchas that you may encounter as you're setting it up."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Azure standard availability tests with Bicep&quot; with a Bicep logo and Azure logos",src:n(58406).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"what-are-standard-tests"}),"What are standard tests?"),(0,a.kt)("p",null,"To quote the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/azure-monitor/app/availability-standard-tests"}),"docs"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Standard tests are a single request test that is similar to the URL ping test but more advanced. In addition to validating whether an endpoint is responding and measuring the performance, Standard tests also includes SSL certificate validity, proactive lifetime check, HTTP request verb (for example GET,HEAD,POST, etc.), custom headers, and custom data associated with your HTTP request.")),(0,a.kt)("p",null,"So we can use these to:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"send requests to a URL"),(0,a.kt)("li",{parentName:"ul"},"from a variety of geographic locations"),(0,a.kt)("li",{parentName:"ul"},"and determine if it is responding with a 200 status code")),(0,a.kt)("p",null,"The URL may be one of our own service URLs, but it could be checking any kind of URL. It's web specific, not Azure specific."),(0,a.kt)("h2",o({},{id:"standard-test-bicep"}),"Standard test Bicep"),(0,a.kt)("p",null,"Now we're going to write a Bicep module that provisions a standard test named ",(0,a.kt)("inlineCode",{parentName:"p"},"standard-test.bicep"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"@description('Tags that our resources need')\nparam tags object\n\n@description('The resource id of the app insights which the webtest will reference')\nparam appInsightsResourceId string\n\n@description('The name of the webtest to create')\nparam standardTestName string\n\n@description('URL to test')\nparam urlToTest string\n\n@description('Interval in seconds between test runs for this WebTest. Default value is 300.')\nparam frequency int = 300\n\n@description('Seconds until this WebTest will timeout and fail. Default value is 30.')\nparam timeout int = 30\n\n// useful reference:\n// https://docs.microsoft.com/en-us/azure/azure-monitor/app/monitor-web-app-availability#azure\n@allowed([\n  'emea-au-syd-edge' // Australia\u202fEast\n  'latam-br-gru-edge' // Brazil South\n  'us-fl-mia-edge' // Central US\n  'apac-hk-hkn-azr' // East Asia\n  'us-va-ash-azr' // East US\n  'emea-ch-zrh-edge' // France South (Formerly France Central)\n  'emea-fr-pra-edge' // France Central\n  'apac-jp-kaw-edge' // Japan East\n  'emea-gb-db3-azr' // North Europe\n  'us-il-ch1-azr' // North Central US\n  'us-tx-sn1-azr' // South Central US\n  'apac-sg-sin-azr' // Southeast Asia\n  'emea-se-sto-edge' // UK West\n  'emea-nl-ams-azr' // West Europe\n  'us-ca-sjc-azr' // West US\n  'emea-ru-msa-edge' // UK South\n])\n@description('The populations (locations) for the test')\nparam testPopulations array = [\n  'emea-se-sto-edge' // UK West\n  'emea-ru-msa-edge' // UK South\n  'emea-gb-db3-azr' // North Europe\n  'us-va-ash-azr' // East US\n  'apac-sg-sin-azr' // Southeast Asia\n]\n\nvar tagsWithHiddenLink = union({\n  'hidden-link:${appInsightsResourceId}': 'Resource'\n}, tags)\n\nresource standardWebTest 'Microsoft.Insights/webtests@2018-05-01-preview' = {\n  name: standardTestName\n  location: resourceGroup().location\n  tags: tagsWithHiddenLink\n  kind: 'ping'\n  properties: {\n    SyntheticMonitorId: urlToTest\n    Name: urlToTest\n    Description: null\n    Enabled: true\n    Frequency: frequency\n    Timeout: timeout\n    Kind: 'standard'\n    RetryEnabled: true\n    Locations: [for testPopulation in testPopulations: {\n      Id: testPopulation\n    }]\n    Configuration: null\n    Request: {\n      RequestUrl: urlToTest\n      Headers: null\n      HttpVerb: 'GET'\n      RequestBody: null\n      ParseDependentRequests: false\n      FollowRedirects: null\n    }\n    ValidationRules: {\n      ExpectedHttpStatusCode: 200\n      IgnoreHttpsStatusCode: false\n      ContentValidation: null\n      SSLCheck: true\n      SSLCertRemainingLifetimeCheck: 7\n    }\n  }\n}\n\noutput standardWebTestName string = standardWebTest.name\noutput standardWebTestId string = standardWebTest.id\n")),(0,a.kt)("h3",o({},{id:"locations--populations"}),"Locations / populations"),(0,a.kt)("p",null,"You'll note that a parameter to the Bicep module is ",(0,a.kt)("inlineCode",{parentName:"p"},"testPopulations"),". These are the geographical places where requests will be sent from. You'll note we have a default value of five populations, but these could be any of the (presently) sixteen valid values. If you were wondering where those are sourced from, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/azure-monitor/app/availability-standard-tests#location-population-tags"}),"here is the link to the Azure docs"),"."),(0,a.kt)("h3",o({},{id:"the-hidden-link-tag"}),"The ",(0,a.kt)("inlineCode",{parentName:"h3"},"hidden-link")," tag"),(0,a.kt)("p",null,"Another significant call out should go to the ",(0,a.kt)("inlineCode",{parentName:"p"},"hidden-link")," tag. The ",(0,a.kt)("inlineCode",{parentName:"p"},"hidden-link"),' tag is a mandatory tag that connects the test (known in Azure as a "webtest") to an app insights instance.'),(0,a.kt)("p",null,"If you do not provide a ",(0,a.kt)("inlineCode",{parentName:"p"},"hidden-link")," tag, or if you try to specify a resource group other than the app insights resource group, Azure will fail to deploy your test and you may find yourself presented with an error like this in the deployments section of the Azure Portal."),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Resource should exist in the same resource group as the linked component")),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the Azure Portal Deployments section saying &quot;Resource should exist in the same resource group as the linked component&quot;",src:n(44013).Z,width:"1102",height:"241"})),(0,a.kt)("p",null,"In our module we set both the ",(0,a.kt)("inlineCode",{parentName:"p"},"hidden-link")," tag as well as the tags that have been supplied via the ",(0,a.kt)("inlineCode",{parentName:"p"},"tags")," parameter."),(0,a.kt)("h3",o({},{id:"app-insights-and-standard-tests-share-a-resource-group"}),"App insights and standard tests share a resource group"),(0,a.kt)("p",null,"Another thing that can cause issues is the deployment of your app insights resource. It's not unusual to spin up Azure resources on demand, for a given branch of your source code. Those resources will be named in relation to the branch and will depend upon one another. I've never managed to successfully create an app insights resource, and reference it from a standard test within the same Bicep file. It appears to be necessary to separate the two actions, such that Azure recognises the existence of the app insights resource when the standard test is deployed."),(0,a.kt)("p",null,"If you are working with long-lived app insights it won't be an issue for you, but if you aren't it's worth being aware of."),(0,a.kt)("h2",o({},{id:"using-standard-testbicep"}),"Using ",(0,a.kt)("inlineCode",{parentName:"h2"},"standard-test.bicep")),(0,a.kt)("p",null,"Our Bicep module can be invoked from another Bicep module named ",(0,a.kt)("inlineCode",{parentName:"p"},"ping-them.bicep")," like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"@description('Tags that our resources need')\nparam tags object\n\n@description('The name of the app insights')\nparam appInsightsName string\n\n@description('An object where the keys are the name of the web test and the values are the URL eg {\"my-standard-test\": \"https://status.azure.com/en-gb/status\"} ')\nparam standardTests object\n\nvar appInsightsResourceId = resourceId('Microsoft.Insights/components', appInsightsName)\n\nmodule standardTestsToCreate 'standard-test.bicep' = [for standardTest in items(standardTests): {\n  name: standardTest.key\n  params: {\n    tags: tags\n    appInsightsResourceId: appInsightsResourceId\n    standardTestName: standardTest.key\n    urlToTest: standardTest.value\n  }\n}]\n")),(0,a.kt)("p",null,"As you can see, this module itself takes a number of parameters, and will typically be invoked from some kind of continuous integration mechanism such as Azure Pipelines or GitHub Actions."),(0,a.kt)("p",null,"This module is written in the expectation that multiple URLs will need to be pinged, and so it has a parameter named ",(0,a.kt)("inlineCode",{parentName:"p"},"standardTests")," which is effectively a dictionary of key-value pairs, where the key is the name of the standard test, and the value is the URL to test."),(0,a.kt)("p",null,"The module makes use of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/azure-resource-manager/bicep/bicep-functions-array#items"}),(0,a.kt)("inlineCode",{parentName:"a"},"items"))," array helper in Bicep to convert the object into an array that can be iterated over."),(0,a.kt)("h2",o({},{id:"azure-pipelines-test"}),"Azure Pipelines test"),(0,a.kt)("p",null,"We're going to use Azure Pipelines to test this out. Here's an ",(0,a.kt)("inlineCode",{parentName:"p"},"azure-pipelines.yml")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),'trigger:\n  - main\n\npool:\n  vmImage: ubuntu-latest\n\nsteps:\n  - checkout: self\n    submodules: true\n\n  - bash: az bicep build --file ping-them.bicep\n    displayName: \'Compile Bicep to ARM\'\n\n  - task: AzureResourceManagerTemplateDeployment@3\n    name: DeploySharedWebTests\n    displayName: Deploy Shared Web Tests\n    inputs:\n      deploymentScope: Resource Group\n      azureResourceManagerConnection: ${{ variables.serviceConnection }}\n      subscriptionId: $(subscriptionId)\n      action: Create Or Update Resource Group\n      resourceGroupName: $(resourceGroup)\n      location: $(location)\n      templateLocation: Linked artifact\n      csmFile: \'ping-them.json\' # created by bash script\n      overrideParameters: >-\n        -tags {"owner": "@johnny_reilly", "branch": "$(Build.SourceBranchName)"}\n        -appInsightsName $(appInsightsName)\n        -standardTests {"my-standard-test": "https://status.azure.com/en-gb/status"}\n      deploymentMode: Incremental\n')),(0,a.kt)("p",null,"When run, it invokes our ",(0,a.kt)("inlineCode",{parentName:"p"},"ping-them.bicep")," module, passing two URLs to test."),(0,a.kt)("p",null,'When executed, you end up with a delightful "availability test" (which is your standard test) in Azure:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of an Availability test in the Azure Portal",src:n(87550).Z,width:"3016",height:"1310"})))}d.isMDXComponent=!0},29820:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-vs-jsdoc-javascript",title:"TypeScript vs JSDoc JavaScript",authors:"johnnyreilly",tags:["javascript","typescript","JSDoc"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-vs-jsdoc-javascript",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-11-22-typescript-vs-jsdoc-javascript/index.md",source:"@site/blog/2021-11-22-typescript-vs-jsdoc-javascript/index.md",title:"TypeScript vs JSDoc JavaScript",description:"There's a debate to be had about whether using JavaScript or TypeScript leads to better outcomes when building a project. The introduction of using JSDoc annotations to type a JavaScript codebase introduces a new dynamic to this discussion. This post will investigate what that looks like, and come to an (opinionated) conclusion.",date:"2021-11-22T00:00:00.000Z",formattedDate:"November 22, 2021",tags:[{label:"javascript",permalink:"/tags/javascript"},{label:"typescript",permalink:"/tags/typescript"},{label:"JSDoc",permalink:"/tags/js-doc"}],readingTime:5.315,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-vs-jsdoc-javascript",title:"TypeScript vs JSDoc JavaScript",authors:"johnnyreilly",tags:["javascript","typescript","JSDoc"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"Azure Static Web App Deploy Previews with Azure DevOps",permalink:"/azure-static-web-app-deploy-previews-with-azure-devops"},nextItem:{title:"Azure standard availability tests with Bicep",permalink:"/azure-standard-tests-with-bicep"}},p={image:n(32775).Z,authorsImageUrls:[void 0]},u=[{value:"Updated 6th December 2021",id:"updated-6th-december-2021",level:2},{value:"What is JSDoc JavaScript?",id:"what-is-jsdoc-javascript",level:2},{value:"Why use JSDoc JavaScript?",id:"why-use-jsdoc-javascript",level:2},{value:"Why use TypeScript?",id:"why-use-typescript",level:2},{value:"It&#39;s your choice!",id:"its-your-choice",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"There's a debate to be had about whether using JavaScript or TypeScript leads to better outcomes when building a project. The introduction of using JSDoc annotations to type a JavaScript codebase introduces a new dynamic to this discussion. This post will investigate what that looks like, and come to an (opinionated) conclusion."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;JSDoc JavaScript vs TypeScript&quot; with a JavaScript logo and TypeScript logo",src:n(32775).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"updated-6th-december-2021"}),"Updated 6th December 2021"),(0,a.kt)("p",null,"This blog evolved to become a talk:"),(0,a.kt)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/5MZoAcheyE4?start=240",title:"YouTube video player",frameBorder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowFullScreen:!0}),(0,a.kt)("p",null,"If you'd talked to me in 2018, I would have solidly recommended using TypeScript, and steering away from JavaScript. The rationale is simple: I'm exceedingly convinced of the value that static typing provides in terms of productivity / avoiding bugs in production. I appreciate this can be a contentious issue, but that is my settled opinion on the subject. Other opinions are available."),(0,a.kt)("p",null,"TypeScript has long had a good static typing story. JavaScript is dynamically typed and so historically has not. Thanks to TypeScript support for JSDoc, JavaScript can now be statically type checked."),(0,a.kt)("h2",o({},{id:"what-is-jsdoc-javascript"}),"What is JSDoc JavaScript?"),(0,a.kt)("p",null,"JSDoc itself actually dates way back to 1999. According to the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.wikipedia.org/wiki/JSDoc"}),"Wikipedia entry"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"JSDoc is a markup language used to annotate JavaScript source code files. Using comments containing JSDoc, programmers can add documentation describing the application programming interface of the code they're creating.")),(0,a.kt)("p",null,"The TypeScript team have taken JSDoc support and run with it. You can now use a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/docs/handbook/jsdoc-supported-types.html"}),"variant of JSDoc annotations")," to provide type information in JavaScript files."),(0,a.kt)("p",null,"What does this look like? Well, to take a simple example, a TypeScript statement like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"let myString: string;\n")),(0,a.kt)("p",null,"Could become the equivalent JavaScript statement with a JSDoc annotation:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"/** @type {string} */\nlet myString;\n")),(0,a.kt)("p",null,"This is type enhanced JavaScript which the TypeScript compiler can understand and type check."),(0,a.kt)("h2",o({},{id:"why-use-jsdoc-javascript"}),"Why use JSDoc JavaScript?"),(0,a.kt)("p",null,"Why would you use JSDoc JavaScript instead of TypeScript? Well there's a number of possible use cases."),(0,a.kt)("p",null,"Perhaps you're writing simple node scripts and you'd like a little type safety to avoid mistakes. Or perhaps you want to dip your project's toe in the waters of static type checking but without fully committing. JSDoc allows for that. Or perhaps your team simply prefers not having a compile step."),(0,a.kt)("p",null,"That, in fact, was the rationale of the webpack team. A little bit of history: webpack has always been a JavaScript codebase. As the codebase grew and grew, there was often discussion about using static typing. However, having a compilation step wasn't desired."),(0,a.kt)("p",null,"TypeScript had been quietly adding support for type checking JavaScript with the assistance of JSDoc for some time. Initial support arrived with the ",(0,a.kt)("inlineCode",{parentName:"p"},"--checkJs")," compiler option in ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/docs/handbook/release-notes/typescript-2-3.html#errors-in-js-files-with---checkjs"}),"TypeScript 2.3"),"."),(0,a.kt)("p",null,"A community member by the name of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/mohsen____"}),"Mohsen Azimi")," experimentally started out using this approach to type check the webpack codebase. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/webpack/pull/6862"}),"His PR")," ended up being a test case that helped improve the type checking of JavaScript by TypeScript. TypeScript v2.9 shipped with a whole host of JSDoc improvements as a consequence of the webpack work. Being such a widely used project this also helped popularise the approach of using JSDoc to type check JavaScript codebases. It demonstrated that this approach could work on a significantly sized codebase."),(0,a.kt)("p",null,"These days, JSDoc type checking with TypeScript is extremely powerful. Whilst not quite on par with TypeScript (not all TypeScript syntax is supported in JSDoc) the gap in functionality is pretty small."),(0,a.kt)("p",null,"It's a completely legitimate choice to build a JavaScript codebase with all the benefits of static typing."),(0,a.kt)("h2",o({},{id:"why-use-typescript"}),"Why use TypeScript?"),(0,a.kt)("p",null,"So if you were starting a project today, and you'd decided you wanted to make use of static typing, how do you choose? TypeScript or JavaScript with JSDoc?"),(0,a.kt)("p",null,"Well, unless you've a compelling need to avoid a compilation step, I'm going to suggest that TypeScript may be the better choice for a number of reasons."),(0,a.kt)("p",null,"Firstly, the tooling support for using TypeScript directly is better than that for JSDoc JavaScript. At the time of writing, things like refactoring tools etc in your editor work more effectively with TypeScript than with JSDoc JavaScript. (Although these are improving as time goes by.)"),(0,a.kt)("p",null,'Secondly, working with JSDoc is distinctly "noisier". It requires far more keystrokes to achieve the same level of type safety. Consider the following TypeScript:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"function stringsStringStrings(\n  p1: string,\n  p2?: string,\n  p3?: string,\n  p4 = 'test'\n): string {\n  // ...\n}\n")),(0,a.kt)("p",null,"As compared to the equivalent JSDoc JavaScript:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),'/**\n * @param {string}  p1\n * @param {string=} p2\n * @param {string} [p3]\n * @param {string} [p4="test"]\n * @return {string}\n */\nfunction stringsStringStrings(p1, p2, p3, p4) {\n  // ...\n}\n')),(0,a.kt)("p",null,"It may be my own familiarity with TypeScript speaking, but I find that the TypeScript is easier to read and comprehend as compared to the JSDoc JavaScript alternative. The fact that all JSDoc annotations live in comments, rather than directly in syntax, makes it harder to follow. (It certainly doesn't help that many VS Code themes present comments in a very faint colour.)"),(0,a.kt)("p",null,"My final reason for favouring TypeScript comes down to falling into the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.codinghorror.com/falling-into-the-pit-of-success/"}),'"pit of success"'),". You're cutting ",(0,a.kt)("em",{parentName:"p"},"against")," the grain when it comes to static typing and JavaScript. You can have it, but you have to work that bit harder to ensure that you have statically typed code. On the other hand, you're cutting ",(0,a.kt)("em",{parentName:"p"},"with")," the grain when it comes to static typing and TypeScript. You have to work hard to opt out of static typing. The TypeScript defaults tend towards static typing, whilst the JavaScript defaults tend away."),(0,a.kt)("p",null,"As someone who very much favours static typing, you can imagine how this is compelling to me!"),(0,a.kt)("h2",o({},{id:"its-your-choice"}),"It's your choice!"),(0,a.kt)("p",null,"So in a way, I don't feel super strongly whether people use JavaScript or TypeScript. But having static typing will likely be a benefit to new projects. Bottom line, I'm keen that people fall into the \"pit of success\", so my recommendation for a new project would be TypeScript."),(0,a.kt)("p",null,"I really like JSDoc myself, and will often use it on small projects. It's a fantastic addition to TypeScript's capabilities. For bigger projects, I'll likely go with TypeScript from the get go. But really, this is a choice - and either is great."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/typescript-vs-jsdoc-javascript/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/typescript-vs-jsdoc-javascript/"})))}d.isMDXComponent=!0},62979:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-static-web-app-deploy-previews-with-azure-devops",title:"Azure Static Web App Deploy Previews with Azure DevOps",authors:"johnnyreilly",tags:["Azure Static Web Apps","azure devops","Netlify deploy previews"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-static-web-app-deploy-previews-with-azure-devops",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-12-05-azure-static-web-app-deploy-previews-with-azure-devops/index.md",source:"@site/blog/2021-12-05-azure-static-web-app-deploy-previews-with-azure-devops/index.md",title:"Azure Static Web App Deploy Previews with Azure DevOps",description:"I love Netlify deploy previews. This post implements a pull request deployment preview mechanism for Azure Static Web Apps in the context of Azure DevOps which is very much inspired by the Netlify offering.",date:"2021-12-05T00:00:00.000Z",formattedDate:"December 5, 2021",tags:[{label:"Azure Static Web Apps",permalink:"/tags/azure-static-web-apps"},{label:"azure devops",permalink:"/tags/azure-devops"},{label:"Netlify deploy previews",permalink:"/tags/netlify-deploy-previews"}],readingTime:10.82,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-static-web-app-deploy-previews-with-azure-devops",title:"Azure Static Web App Deploy Previews with Azure DevOps",authors:"johnnyreilly",tags:["Azure Static Web Apps","azure devops","Netlify deploy previews"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"Open Graph: a guide to sharable social media previews",permalink:"/open-graph-sharing-previews-guide"},nextItem:{title:"TypeScript vs JSDoc JavaScript",permalink:"/typescript-vs-jsdoc-javascript"}},p={image:n(54797).Z,authorsImageUrls:[void 0]},u=[{value:"Getting <code>defaultHostName</code> from Static Web Apps",id:"getting-defaulthostname-from-static-web-apps",level:2},{value:"Azure Pipelines tweaks",id:"azure-pipelines-tweaks",level:2},{value:"Updating the PR with a preview URL",id:"updating-the-pr-with-a-preview-url",level:2},{value:"Permissions",id:"permissions",level:2},{value:"Enjoy! (and keep Azure tidy)",id:"enjoy-and-keep-azure-tidy",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I love ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.netlify.com/products/deploy-previews/"}),"Netlify deploy previews"),". This post implements a pull request deployment preview mechanism for Azure Static Web Apps in the context of Azure DevOps which is very much inspired by the Netlify offering."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Azure Static Web App Deploy Previews with Azure DevOps&quot; with a Azure, Bicep and Azure DevOps logos",src:n(54797).Z,width:"1600",height:"900"})),(0,a.kt)("p",null,"Having a build of your latest pull request which is deployed and clickable from the PR itself is a wonderful developer experience. It reduces friction for testing out changes by allowing you to see the impact from within the PR itself. No checking to see if an environment is free with the rest of the team, then manually running a pipeline and waiting whilst a deployment happens. No. It's all there without you having to lift a finger. I use Netlify deploy previews on my blog and have become accustomed to the delight that is this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of a Netlify deploy preview on my latest blog post",src:n(47200).Z,width:"1840",height:"464"})),(0,a.kt)("p",null,'I love this and I wanted to implement the "browse the preview" mechanism in Azure DevOps as well, using Azure Static Web Apps. This blog post contains two things:'),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"A pull request deployment environment mechanism using Azure and Azure Pipelines with Bicep."),(0,a.kt)("li",{parentName:"ol"},'A mechanism for updating a pull request in Azure DevOps with a link to the deployment environment (the "browse the preview")')),(0,a.kt)("p",null,"It's worth bearing in mind that there's a very similar feature to what we're going to build for ",(0,a.kt)("strong",{parentName:"p"},"1."),' in SWAs now called "staging environments" that is presently only available on GitHub and not Azure DevOps:'),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/answers/questions/574288/creating-environments-for-azure-static-web-app.html"}),(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Anthony Chu at Microsoft saying &quot;Unfortunately environments is not yet available for Azure DevOps.&quot;",src:n(52736).Z,width:"2602",height:"1150"}))),(0,a.kt)("p",null,"It's possible that in future the deployment environment aspect of this blog post may be rendered redundant by staging environments landing in Azure DevOps. However, the second part, which updates a PR in ADO with a link is probably generally useful. And it may be the case that the approach of provisioning an environment on demand and extracting a URL could be reworked to work with App Service and similar too."),(0,a.kt)("p",null,"I wrote about using ",(0,a.kt)("a",o({parentName:"p"},{href:"/bicep-azure-static-web-apps-azure-devops"}),"SWAs with Azure DevOps earlier this year"),". This blog post will take the form of a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://dev.azure.com/johnnyreilly/azure-static-web-apps/_git/azure-static-web-apps/pullrequest/3"}),"pull request on the code written in that post"),". ",(0,a.kt)("a",o({parentName:"p"},{href:"https://dev.azure.com/johnnyreilly/azure-static-web-apps/_git/azure-static-web-apps?version=GThand-rolled-deploy-previews"}),"The finished code for this blog post can be found here"),"."),(0,a.kt)("h2",o({},{id:"getting-defaulthostname-from-static-web-apps"}),"Getting ",(0,a.kt)("inlineCode",{parentName:"h2"},"defaultHostName")," from Static Web Apps"),(0,a.kt)("p",null,"The first thing we're going to do is take the Bicep from that post and tweak it to the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param appName string\nparam repositoryUrl string\nparam repositoryBranch string\n\nparam skuName string = 'Free'\nparam skuTier string = 'Free'\n\nresource staticWebApp 'Microsoft.Web/staticSites@2021-02-01' = {\n  name: repositoryBranch == 'main' ? appName : '${appName}-${repositoryBranch}'\n  location: resourceGroup().location\n  sku: {\n    name: skuName\n    tier: skuTier\n  }\n  properties: {\n    // The provider, repositoryUrl and branch fields are required for successive deployments to succeed\n    // for more details see: https://github.com/Azure/static-web-apps/issues/516\n    provider: 'DevOps'\n    repositoryUrl: repositoryUrl\n    branch: repositoryBranch\n    buildProperties: {\n      skipGithubActionWorkflowGeneration: true\n    }\n  }\n}\n\noutput staticWebAppDefaultHostName string = staticWebApp.properties.defaultHostname // eg gentle-bush-0db02ce03.azurestaticapps.net\noutput staticWebAppId string = staticWebApp.id\noutput staticWebAppName string = staticWebApp.name\n")),(0,a.kt)("p",null,"There's some changes in here. First of all we're using a newer version of the ",(0,a.kt)("inlineCode",{parentName:"p"},"staticSites")," resource in Azure. You'll also see that we name the resource conditionally now. If we're on the ",(0,a.kt)("inlineCode",{parentName:"p"},"main")," branch we name it as we did before with ",(0,a.kt)("inlineCode",{parentName:"p"},"appName"),". But if we aren't then we suffix the ",(0,a.kt)("inlineCode",{parentName:"p"},"name")," with the ",(0,a.kt)("inlineCode",{parentName:"p"},"repositoryBranch"),". It's worth knowing that ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/resource-abbreviations#compute-and-web"}),"there are restrictions and conventions for Azure resource naming"),". If you have a branch name that is just alphanumerics and hyphens you'll be fine."),(0,a.kt)("p",null,"You'll see the output of the Bicep file has changed. Previously we were outputting the ",(0,a.kt)("inlineCode",{parentName:"p"},"apiKey")," that we used for deployment. This isn't the securest of approaches as, by having this as a deployment output, this data can be accessed by people who share access with your Azure portal. So we're going to use a different (and more secure) approach to acquire this in our pipeline later."),(0,a.kt)("p",null,"More significantly, we are now outputting the ",(0,a.kt)("inlineCode",{parentName:"p"},"staticWebAppDefaultHostName")," of our newly provisioned SWA. This is the location where people will be able to view the deployment preview. Since we want to pump that into our pull request description, so people can click on the link, we are going to need this. We're also pumping out the ",(0,a.kt)("inlineCode",{parentName:"p"},"staticWebAppId")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"staticWebAppName"),". We'll use the ",(0,a.kt)("inlineCode",{parentName:"p"},"staticWebAppName")," to acquire the ",(0,a.kt)("inlineCode",{parentName:"p"},"apiKey")," in our pipeline."),(0,a.kt)("h2",o({},{id:"azure-pipelines-tweaks"}),"Azure Pipelines tweaks"),(0,a.kt)("p",null,"Now to the pipeline. After the deployment, our updated pipeline is going to acquire the ",(0,a.kt)("inlineCode",{parentName:"p"},"apiKey")," for deployment like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- task: AzureCLI@2\n  displayName: 'Acquire API key for deployment'\n  inputs:\n    azureSubscription: $(serviceConnection)\n    scriptType: bash\n    scriptLocation: inlineScript\n    inlineScript: |\n      APIKEY=$(az staticwebapp secrets list --name $(staticWebAppName) | jq -r '.properties.apiKey')\n      echo \"##vso[task.setvariable variable=apiKey;issecret=true]$APIKEY\"\n")),(0,a.kt)("p",null,"The above uses the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/deploy/azure-cli?view=azure-devops"}),"Azure CLI task")," to acquire the ",(0,a.kt)("inlineCode",{parentName:"p"},"apiKey"),". It uses ",(0,a.kt)("a",o({parentName:"p"},{href:"https://stedolan.github.io/jq/"}),"jq")," to pull out the required property from the JSON and writes it as a secret variable in the pipeline to be used in the deployment."),(0,a.kt)("p",null,"At the end of the pipeline, if we're not on the ",(0,a.kt)("inlineCode",{parentName:"p"},"main")," branch, the the pipeline is going to run a custom script that will update the PR with the preview URL:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- task: Npm@1\n  displayName: 'Pull request preview install'\n  condition: and(succeeded(), ne(variables.isMain, 'true'))\n  inputs:\n    command: 'install'\n    workingDir: pull-request-preview\n\n- task: Npm@1\n  displayName: 'Pull request preview'\n  condition: and(succeeded(), ne(variables.isMain, 'true'))\n  inputs:\n    command: 'custom'\n    customCommand: 'run pull-request-preview -- --sat \"$(System.AccessToken)\" --project \"$(System.TeamProject)\" --repository \"$(Build.Repository.Name)\" --systemCollectionUri \"$(System.CollectionUri)\" --pullRequestId $(System.PullRequest.PullRequestId) --previewUrl \"https://$(staticWebAppDefaultHostName)\"'\n    workingDir: pull-request-preview\n")),(0,a.kt)("p",null,"We haven't written that script yet; we will in a moment."),(0,a.kt)("p",null,"The complete ",(0,a.kt)("inlineCode",{parentName:"p"},"azure-piplines.yml")," is below, and you'll notice we've moved all variables save for the ",(0,a.kt)("inlineCode",{parentName:"p"},"subscriptionId")," into the ",(0,a.kt)("inlineCode",{parentName:"p"},"azure-pipelines.yml")," and we're using a ",(0,a.kt)("inlineCode",{parentName:"p"},"westeurope")," location / resource group as at present ",(0,a.kt)("inlineCode",{parentName:"p"},"staticSites")," is not available everywhere:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"pool:\n  vmImage: ubuntu-latest\n\nvariables:\n  # subscriptionId is a variable defined on the pipeline itself\n  - name: appName\n    value: 'our-static-web-app'\n  - name: location\n    value: 'westeurope' #\xa0at time of writing static sites are available in limited locations such as westeurope\n  - name: serviceConnection\n    value: 'azureRMWestEurope'\n  - name: azureResourceGroup # this resource group lives in westeurope\n    value: 'johnnyreilly'\n\nsteps:\n  - checkout: self\n    submodules: true\n\n  - bash: az bicep build --file infra/static-web-app/main.bicep\n    displayName: 'Compile Bicep to ARM'\n\n  - task: AzureResourceManagerTemplateDeployment@3\n    name: DeployStaticWebAppInfra\n    displayName: Deploy Static Web App infra\n    inputs:\n      deploymentScope: Resource Group\n      azureResourceManagerConnection: $(serviceConnection)\n      subscriptionId: $(subscriptionId)\n      action: Create Or Update Resource Group\n      resourceGroupName: $(azureResourceGroup)\n      location: $(location)\n      templateLocation: Linked artifact\n      csmFile: 'infra/static-web-app/main.json' # created by bash script\n      overrideParameters: >-\n        -repositoryUrl $(Build.Repository.Uri)\n        -repositoryBranch $(Build.SourceBranchName)\n        -appName $(appName)\n      deploymentMode: Incremental\n      deploymentOutputs: deploymentOutputs\n\n  - task: PowerShell@2\n    name: 'SetDeploymentOutputVariables'\n    displayName: 'Set Deployment Output Variables'\n    inputs:\n      targetType: inline\n      script: |\n        $armOutputObj = '$(deploymentOutputs)' | ConvertFrom-Json\n        $armOutputObj.PSObject.Properties | ForEach-Object {\n          $keyname = $_.Name\n          $value = $_.Value.value\n\n          # Creates a standard pipeline variable\n          Write-Output \"##vso[task.setvariable variable=$keyName;]$value\"\n\n          # Display keys and values in pipeline\n          Write-Output \"output variable: $keyName $value\"\n        }\n      pwsh: true\n\n  - task: AzureCLI@2\n    displayName: 'Acquire API key for deployment'\n    inputs:\n      azureSubscription: $(serviceConnection)\n      scriptType: bash\n      scriptLocation: inlineScript\n      inlineScript: |\n        APIKEY=$(az staticwebapp secrets list --name $(staticWebAppName) | jq -r '.properties.apiKey')\n        echo \"##vso[task.setvariable variable=apiKey;issecret=true]$APIKEY\"\n\n  - task: AzureStaticWebApp@0\n    name: DeployStaticWebApp\n    displayName: Deploy Static Web App\n    inputs:\n      app_location: 'static-web-app'\n      # api_location: 'api'\n      output_location: 'build'\n      azure_static_web_apps_api_token: $(apiKey)\n\n  - task: Npm@1\n    displayName: 'Pull request preview install'\n    condition: and(succeeded(), ne(variables.isMain, 'true'))\n    inputs:\n      command: 'install'\n      workingDir: pull-request-preview\n\n  - task: Npm@1\n    displayName: 'Pull request preview'\n    condition: and(succeeded(), ne(variables.isMain, 'true'))\n    inputs:\n      command: 'custom'\n      customCommand: 'run pull-request-preview -- --sat \"$(System.AccessToken)\" --project \"$(System.TeamProject)\" --repository \"$(Build.Repository.Name)\" --systemCollectionUri \"$(System.CollectionUri)\" --pullRequestId $(System.PullRequest.PullRequestId) --previewUrl \"https://$(staticWebAppDefaultHostName)\"'\n      workingDir: pull-request-preview\n")),(0,a.kt)("h2",o({},{id:"updating-the-pr-with-a-preview-url"}),"Updating the PR with a preview URL"),(0,a.kt)("p",null,"We want to be able to update our pull request with our deploy URL. To make that happen, we're going to whiz up a little node app using TypeScript, ts-node and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/azure-devops-node-api"}),"the azure-devops-node-api package"),"."),(0,a.kt)("p",null,"Let's create our app:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"mkdir pull-request-preview\ncd pull-request-preview\nnpm init --yes\nnpm install @types/node @types/yargs ts-node typescript azure-devops-node-api yargs --save\n")),(0,a.kt)("p",null,"We'll update our newly created ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," file with a ",(0,a.kt)("inlineCode",{parentName:"p"},"pull-request-preview")," script which will be the entry point."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'  "scripts": {\n    "pull-request-preview": "ts-node ./index.ts"\n  },\n')),(0,a.kt)("p",null,"We'll add a ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," file that looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "compilerOptions": {\n    "target": "ES2015",\n    "module": "CommonJS",\n    "strict": true,\n    "esModuleInterop": true,\n    "moduleResolution": "node"\n  }\n}\n')),(0,a.kt)("p",null,"Finally we'll add our script in a new ",(0,a.kt)("inlineCode",{parentName:"p"},"index.ts")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"#!/usr/bin/env node\nimport yargs from 'yargs/yargs';\nimport * as nodeApi from 'azure-devops-node-api';\nimport { IGitApi } from 'azure-devops-node-api/GitApi';\nimport { PullRequestStatus } from 'azure-devops-node-api/interfaces/GitInterfaces';\n\nconst parser = yargs(process.argv.slice(2)).options({\n  pat: { type: 'string', default: '' },\n  sat: { type: 'string', default: '' },\n  systemCollectionUri: { type: 'string', demandOption: true },\n  project: { type: 'string', demandOption: true },\n  repository: { type: 'string', demandOption: true },\n  pullRequestId: { type: 'number' },\n  previewUrl: { type: 'string', demandOption: true },\n});\n\n(async () => {\n  await run(await parser.argv);\n})();\n\nasync function run({\n  pat,\n  sat,\n  project,\n  repository,\n  systemCollectionUri,\n  pullRequestId,\n  previewUrl,\n}: {\n  pat: string;\n  sat: string;\n  systemCollectionUri: string;\n  project: string;\n  repository: string;\n  pullRequestId: number | undefined;\n  previewUrl: string;\n}) {\n  const config: Config = { project, repository };\n  const gitApi = await getGitApi({ pat, sat, systemCollectionUri });\n\n  if (!pullRequestId)\n    console.log(\n      'No pull request id supplied, so will look up latest active PR'\n    );\n\n  const pullRequestIdToUpdate =\n    pullRequestId || (await getActivePullRequestId({ gitApi, config }));\n  if (!pullRequestIdToUpdate) {\n    console.log('No pull request found');\n    return;\n  }\n\n  console.log(\n    `Updating ${systemCollectionUri}/${project}/_git/${repository}/pullrequest/${pullRequestIdToUpdate} with a preview URL of ${previewUrl}`\n  );\n\n  const pullRequest = await getPullRequest({\n    gitApi,\n    config,\n    pullRequestId: pullRequestIdToUpdate,\n  });\n\n  await updatePullRequestDescription({\n    gitApi,\n    config,\n    pullRequestId: pullRequestIdToUpdate,\n    description: makePreviewDescriptionMarkdown(\n      pullRequest.description!,\n      previewUrl\n    ),\n  });\n\n  console.log(\n    `Updated pull request description a preview URL of ${previewUrl}`\n  );\n}\n\ninterface Config {\n  project: string;\n  repository: string;\n}\n\nasync function getGitApi({\n  sat,\n  pat,\n  systemCollectionUri,\n}: {\n  pat: string;\n  sat: string;\n  systemCollectionUri: string;\n}) {\n  const authHandler = pat\n    ? nodeApi.getPersonalAccessTokenHandler(\n        pat,\n        /** allowCrossOriginAuthentication */ true\n      )\n    : nodeApi.getHandlerFromToken(\n        sat,\n        /** allowCrossOriginAuthentication */ true\n      );\n\n  const webApi = new nodeApi.WebApi(systemCollectionUri, authHandler);\n  const gitApi = await webApi.getGitApi();\n\n  return gitApi;\n}\n\nasync function getActivePullRequestId({\n  gitApi,\n  config,\n}: {\n  gitApi: IGitApi;\n  config: Config;\n}) {\n  const topActivePullRequest = await gitApi.getPullRequests(\n    config.repository, // repository.id!,\n    { status: PullRequestStatus.Active },\n    config.project,\n    undefined,\n    /** skip */ 0,\n    /** top */ 1\n  );\n\n  return topActivePullRequest.length > 0\n    ? topActivePullRequest[0].pullRequestId\n    : undefined;\n}\n\nasync function getPullRequest({\n  gitApi,\n  config,\n  pullRequestId,\n}: {\n  gitApi: IGitApi;\n  config: Config;\n  pullRequestId: number;\n}) {\n  const pullRequest = await gitApi.getPullRequest(\n    config.repository, // repository.id!,\n    pullRequestId,\n    config.project,\n    undefined,\n    /** skip */ 0,\n    /** top */ 1,\n    /** includeCommits */ false,\n    /** includeWorkItemRefs */ false\n  );\n  return pullRequest;\n}\n\nasync function updatePullRequestDescription({\n  gitApi,\n  config,\n  pullRequestId,\n  description,\n}: {\n  gitApi: IGitApi;\n  config: Config;\n  pullRequestId: number;\n  description: string;\n}) {\n  // To do an update with the API you must provide a new object with only the properties you are updating\n  const updatePullRequest = {\n    description,\n  };\n  await gitApi.updatePullRequest(\n    updatePullRequest,\n    config.repository,\n    pullRequestId,\n    config.project\n  );\n}\n\nfunction makePreviewDescriptionMarkdown(desc: string, previewUrl: string) {\n  const previewRegex = /(> -*\\n> # Preview:\\n.*\\n>.*\\n> -*\\n)/;\n\n  const makePreview = (previewUrl: string) => `> ---\n> # Preview:\n> ${previewUrl}\n> \n> ---\n`;\n\n  const alreadyHasPreview = desc.match(previewRegex);\n  return alreadyHasPreview\n    ? desc.replace(previewRegex, makePreview(previewUrl))\n    : makePreview(previewUrl) + desc;\n}\n")),(0,a.kt)("p",null,"The above code does two things:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Looks up the pull request, using the details supplied from the pipeline. It's worth noting that the ",(0,a.kt)("inlineCode",{parentName:"li"},"System.PullRequest.PullRequestId")," variable is ",(0,a.kt)("a",o({parentName:"li"},{href:"https://docs.microsoft.com/en-us/azure/devops/pipelines/build/variables?view=azure-devops&tabs=yaml"}),"initialized only if the build ran because of a Git PR affected by a branch policy"),". If you don't have that set up, the script falls back to using the latest active pull request. This is generally useful when you're getting set up in the first place; you won't want to rely on this behaviour."),(0,a.kt)("li",{parentName:"ol"},'Updates the pull request description with a prefix piece of markdown that provides the link to the preview URL. This is our "browse the preview":\n',(0,a.kt)("img",{loading:"lazy",alt:"screenshot of rendered markdown with the preview link",src:n(72207).Z,width:"848",height:"268"}))),(0,a.kt)("p",null,"This script could be refactored into a dedicated Azure Pipelines custom task."),(0,a.kt)("h2",o({},{id:"permissions"}),"Permissions"),(0,a.kt)("p",null,"The first time you run this you may encounter a permissions error of the form:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"Error: TF401027: You need the Git 'PullRequestContribute' permission to perform this action.\n")),(0,a.kt)("p",null,'To remedy this you need to give your build service the relevant permissions to update a pull request. You can do that by going to the security settings of your repo and setting "Contribute to pull requests" to "Allow" for your build service:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of &quot;Contribute to pull requests&quot; permission in Azure DevOps Git security being set to &quot;Allow&quot; ",src:n(51498).Z,width:"3566",height:"1744"})),(0,a.kt)("h2",o({},{id:"enjoy-and-keep-azure-tidy"}),"Enjoy! (and keep Azure tidy)"),(0,a.kt)("p",null,"When the pipeline is now run you can see that a deployment preview link is now updated onto the PR description:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of deployment preview on PR",src:n(95234).Z,width:"3566",height:"1046"})),(0,a.kt)("p",null,"This will happen whenever a PR is raised which is tremendous."),(0,a.kt)("p",null,"A thing to remember, is that there's nothing in this post that tears down the temporary deployment after the pull request has been merged. It will hang around. We happen to be using free resources in this post, but if we weren't there would be cost implications. Either way, you'll want to clean up unused environments as a matter of course. And I'd advise automating that."),(0,a.kt)("p",null,"So be tidy and cost aware with this approach."))}d.isMDXComponent=!0},94516:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"open-graph-sharing-previews-guide",title:"Open Graph: a guide to sharable social media previews",authors:"johnnyreilly",tags:["Open Graph"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/open-graph-sharing-previews-guide",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-12-12-open-graph-sharing-previews-guide/index.md",source:"@site/blog/2021-12-12-open-graph-sharing-previews-guide/index.md",title:"Open Graph: a guide to sharable social media previews",description:"The Open Graph protocol has become the standard mechanism for sharing rich content on the web. This post looks at what implementing Open Graph tags for sharable previews (often called social media previews) looks like, the tools you can use and also examines the different platform rendering issue.",date:"2021-12-12T00:00:00.000Z",formattedDate:"December 12, 2021",tags:[{label:"Open Graph",permalink:"/tags/open-graph"}],readingTime:7.76,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"open-graph-sharing-previews-guide",title:"Open Graph: a guide to sharable social media previews",authors:"johnnyreilly",tags:["Open Graph"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"Azure Container Apps, Bicep and GitHub Actions",permalink:"/azure-container-apps-bicep-and-github-actions"},nextItem:{title:"Azure Static Web App Deploy Previews with Azure DevOps",permalink:"/azure-static-web-app-deploy-previews-with-azure-devops"}},p={image:n(7092).Z,authorsImageUrls:[void 0]},u=[{value:"Updated: 26 November 2022",id:"updated-26-november-2022",level:2},{value:"Open Graph protocol and sharing",id:"open-graph-protocol-and-sharing",level:2},{value:"Open Graph meta tags",id:"open-graph-meta-tags",level:2},{value:"Tools for testing sharing",id:"tools-for-testing-sharing",level:2},{value:"Sharable preview rendering: not yet standard",id:"sharable-preview-rendering-not-yet-standard",level:2},{value:"<code>og:image</code> type: PNG, JPEG or WebP? What&#39;s best?",id:"ogimage-type-png-jpeg-or-webp-whats-best",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The Open Graph protocol has become the standard mechanism for sharing rich content on the web. This post looks at what implementing Open Graph tags for sharable previews (often called social media previews) looks like, the tools you can use and also examines the different platform rendering issue."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Open Graph: a guide to sharable social media previews&quot; with the open graph logo and screenshots of twitter shared cards",src:n(7092).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"updated-26-november-2022"}),"Updated: 26 November 2022"),(0,a.kt)("p",null,"I've updated this post to advise on image types to favour."),(0,a.kt)("h2",o({},{id:"open-graph-protocol-and-sharing"}),"Open Graph protocol and sharing"),(0,a.kt)("p",null,"You may have noticed, that when you share a URL, the platform on which you're sharing may display a kind of \"preview\" of the link. Here's an example of sharing a link to a blog on Twitter:"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/johnny_reilly/status/1454092877722800131"}),(0,a.kt)("img",{loading:"lazy",alt:"screenshot of tweet demonstrating sharing",src:n(6981).Z,width:"1197",height:"1392"}))),(0,a.kt)("p",null,'Sharing a link has automagically generated a preview "card" at the bottom of the tweet. It contains an image, it has the title of the blog and it has a description of the post as well.'),(0,a.kt)("p",null,"This looks pretty fabulous and it gives the reader of that tweet some fairly rich information about what might be in that post. It potentially saves readers a click if it's obvious that the post isn't particularly interesting to them. Conversely, it makes it more likely that the reader will click if it does seem intriguing. Sharing previews are an asset."),(0,a.kt)("p",null,"Twitter made this card using a combination of Open Graph metatags (and some custom tags) which my blog surfaces."),(0,a.kt)("h2",o({},{id:"open-graph-meta-tags"}),"Open Graph meta tags"),(0,a.kt)("p",null,"The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://ogp.me/"}),"Open Graph protocol")," came out of Facebook and it describes itself thusly:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"The Open Graph protocol enables any web page to become a rich object in a social graph. For instance, this is used on Facebook to allow any web page to have the same functionality as any other object on Facebook.")),(0,a.kt)("p",null,"What Open Graph is all about, is meta tags. Adding meta tags to an HTML page to explicitly define pieces of standardised information. Now there's many purposes for this, and we're interested in just one: sharing."),(0,a.kt)("p",null,"Now that we understand what sharing previews give us, let's understand how they work. The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://ogp.me/#metadata"}),"Open Graph")," website has a great walkthrough of the minimum requirement for Open Graph:"),(0,a.kt)("blockquote",null,(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"og:title"),' - The title of your object as it should appear within the graph, e.g., "The Rock".'),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"og:type"),' - The type of your object, e.g., "video.movie". Depending on the type you specify, other properties may also be required.'),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"og:image")," - An image URL which should represent your object within the graph."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"og:url"),' - The canonical URL of your object that will be used as its permanent ID in the graph, e.g., "',(0,a.kt)("a",o({parentName:"li"},{href:"https://www.imdb.com/title/tt0117500/%22"}),'https://www.imdb.com/title/tt0117500/"'),".")),(0,a.kt)("p",{parentName:"blockquote"},"As an example, the following is the Open Graph protocol markup for The Rock on IMDB:"),(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<html prefix="og: https://ogp.me/ns#">\n  <head>\n    <title>The Rock (1996)</title>\n    <meta property="og:title" content="The Rock" />\n    <meta property="og:type" content="video.movie" />\n    <meta property="og:url" content="https://www.imdb.com/title/tt0117500/" />\n    <meta\n      property="og:image"\n      content="https://ia.media-imdb.com/images/rock.jpg"\n    />\n    ...\n  </head>\n  ...\n</html>\n'))),(0,a.kt)("p",null,"Sharing previews have very similar, but crucially slightly different, requirements. Five tags are required to generate a sharable preview:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"og:title")," - The title of your page"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"og:description")," - A description of the content of that page"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"og:image")," - An image URL which should appear in the social media share."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"og:url")," - The canonical URL of your web page."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"twitter:card")," - A ",(0,a.kt)("a",o({parentName:"li"},{href:"https://developer.twitter.com/en/docs/twitter-for-websites/cards/guides/getting-started#started"}),"custom tag which is only required by Twitter")," indicating the type of share, be it ",(0,a.kt)("inlineCode",{parentName:"li"},'"summary"'),", ",(0,a.kt)("inlineCode",{parentName:"li"},'"summary_large_image"'),", ",(0,a.kt)("inlineCode",{parentName:"li"},'"app"'),", or ",(0,a.kt)("inlineCode",{parentName:"li"},'"player"'),". Probably ",(0,a.kt)("inlineCode",{parentName:"li"},'"summary"')," or ",(0,a.kt)("inlineCode",{parentName:"li"},'"summary_large_image"')," for most use cases.")),(0,a.kt)("p",null,"If we implement these, then our page will offer sharable previews."),(0,a.kt)("p",null,"With this understanding in place; we can take a look at what it would look like to add sharable previews to a website. We'll make ourselves a React website with:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"npx react-static create\n")),(0,a.kt)("p",null,"When prompted, name the site ",(0,a.kt)("inlineCode",{parentName:"p"},"demo")," and select the ",(0,a.kt)("inlineCode",{parentName:"p"},"blank")," template."),(0,a.kt)("p",null,"Please note, nothing that we're doing here is React specific; it's applicable to all websites regardless of the technology they're built with; this is just a straightforward way to demo a website."),(0,a.kt)("p",null,"We're using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/react-static/react-static"}),(0,a.kt)("inlineCode",{parentName:"a"},"react-static"))," for this demo because it is a static site generator. This is significant because, as a general rule, many platforms that support sharing, do not crawl dynamically generated meta tags. By this we mean, tags generated by JavaScript at runtime. Rather, these tags must be baked into the HTML that is served up, so a static site generator like ",(0,a.kt)("inlineCode",{parentName:"p"},"react-static")," fits the brief well as it takes care of this."),(0,a.kt)("p",null,"We're going to replace the ",(0,a.kt)("inlineCode",{parentName:"p"},"App.js")," that is scaffolded out with our own ",(0,a.kt)("inlineCode",{parentName:"p"},"App.js"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-jsx"}),'import * as React from \'react\';\nimport { Head } from \'react-static\';\nimport \'./app.css\';\n\nfunction App() {\n  const openGraphData = {\n    title: \'Open Graph: a guide to sharing previews\',\n    description:\n      \'This page features the Open Graph protocol markup for sharing previews.\',\n    url: \'https://johnnyreilly.github.io/open-graph-sharing-previews/\',\n    image:\n      \'https://upload.wikimedia.org/wikipedia/commons/7/72/Open_Graph_protocol_logo.png\',\n  };\n  return (\n    <div className="App">\n      <Head>\n        <meta property="og:title" content={openGraphData.title} />\n        <meta property="og:description" content={openGraphData.description} />\n        <meta property="og:url" content={openGraphData.url} />\n        <meta property="og:image" content={openGraphData.image} />\n        <meta name="twitter:card" content="summary" />\n      </Head>\n      <h1>{openGraphData.title}</h1>\n      <img src={openGraphData.image} alt="The Open Graph protocol logo" />\n      <h2>Share it and see!</h2>\n    </div>\n  );\n}\n\nexport default App;\n')),(0,a.kt)("p",null,"The code above renders the required meta tags for sharing previews. When we build and deploy this we can see they show up like so:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of demo with devtools open illustrating the meta tags",src:n(74018).Z,width:"2355",height:"1325"})),(0,a.kt)("h2",o({},{id:"tools-for-testing-sharing"}),"Tools for testing sharing"),(0,a.kt)("p",null,"Now we have a demo, it would be tremendous to be able to test it out. There's various official tools to test your URLs:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://cards-dev.twitter.com/validator"}),"Twitter")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://developers.facebook.com/tools/debug/"}),"Facebook")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://www.linkedin.com/post-inspector/inspect/"}),"LinkedIn"))),(0,a.kt)("p",null,'There\'s also a number of unoffical "aggregator" tools that attempt to render the appearance of your social previews across multiple platforms to save you going to each tool in turn:'),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://www.opengraph.xyz/"}),"https://www.opengraph.xyz/")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://metatags.io/"}),"https://metatags.io/")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://socialsharepreview.com/"}),"https://socialsharepreview.com/"))),(0,a.kt)("p",null,"Let's test out the Twitter validator:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of testing out our site using the twitter validator",src:n(1437).Z,width:"2005",height:"1077"})),(0,a.kt)("p",null,"Terrific! We have sharable previews enabled for the site we've made."),(0,a.kt)("h2",o({},{id:"sharable-preview-rendering-not-yet-standard"}),"Sharable preview rendering: not yet standard"),(0,a.kt)("p",null,"Now we have a sense of what sharing previews look like, what powers them and how to implement them. So far we've looked just at Twitter for examples of sharing previews. However, support for Open Graph sharing previews is widespread. Examples of other places where you can use them include: Facebook, Polywork, Slack, Teams, Linked In, Outlook.com, Discord... The list is now very long indeed."),(0,a.kt)("p",null,"However, each platform implements sharing previews according to their own standard. What does mean? Well, a link shared on Twitter will look different to one shared on Outlook.com. For example:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of an email being sent in outlook with a share preview card to the same blog showing the untruncated title",src:n(33244).Z,width:"1631",height:"483"})),(0,a.kt)("p",null,"Above I'm sharing a link to a blog post. The image is to the left, the title and description is to the right. Now let's look at the same link shared on Twitter:"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/AzureWeekly/status/1436733027489652743"}),(0,a.kt)("img",{loading:"lazy",alt:"screenshot of a tweet where the image in the share preview card has been cropped making the title unreadable",src:n(19131).Z,width:"1204",height:"1337"}))),(0,a.kt)("p",null,"Here the image is above the title and the description. More distressingly, the image has been cropped which renders the title slightly unreadable."),(0,a.kt)("p",null,"So whilst the mechanism for sharing is roughly standardised, the rendering is not. It's not dissimilar to the web in the year 2000. Back then, a single piece of HTML could be rendered in many different ways, depending upon the browser. The same statement is true now for Open Graph sharing. Sharing can look very different depending upon the platform which is displaying the preview. The only way to avoid this at present is to thoroughly on all the platforms where we want to share links; ensuring the sharable previews look acceptable."),(0,a.kt)("h2",o({},{id:"ogimage-type-png-jpeg-or-webp-whats-best"}),(0,a.kt)("inlineCode",{parentName:"h2"},"og:image")," type: PNG, JPEG or WebP? What's best?"),(0,a.kt)("p",null,"Let's think about the type of image we reference in the ",(0,a.kt)("inlineCode",{parentName:"p"},"og:image")," tag for a moment. This is the image that will be displayed in the sharing preview:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<meta property="og:image" content="https://ia.media-imdb.com/images/rock.jpg" />\n')),(0,a.kt)("p",null,"We can use any image format we like. However, there are some considerations to bear in mind. Whilst you might imagine that the image format is not important, it is. This is because not all platforms support all image formats. Whilst say Twitter and Facebook support PNG, JPEG and WebP, other platforms do not. For example, Teams does not support WebP. So if we want to share a link on Teams, we likely want to use a JPEG or PNG image."),(0,a.kt)("p",null,"I should tell you that I learned this the hard way, deciding to use WebP for most of the images on my blog, including the Open Graph image. I was then surprised to find that the images were not displaying in Teams. I had to go back and change the Open Graph images back to PNG. Don't be me."),(0,a.kt)("p",null,'Incidentally, the world could use a "caniuse" for Open Graph sharing previews. I\'d love to see one.'),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"In this post we've understood what sharable previews are, how to add them to a website, how to test them and some of the rough edges to be aware of."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/open-graph-sharable-social-media-previews/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/open-graph-sharable-social-media-previews/"})))}d.isMDXComponent=!0},5544:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-container-apps-bicep-and-github-actions",title:"Azure Container Apps, Bicep and GitHub Actions",authors:"johnnyreilly",tags:["Azure Container Apps","Bicep","GitHub Actions"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-container-apps-bicep-and-github-actions",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-12-19-azure-container-apps-bicep-and-github-actions/index.md",source:"@site/blog/2021-12-19-azure-container-apps-bicep-and-github-actions/index.md",title:"Azure Container Apps, Bicep and GitHub Actions",description:"Azure Container Apps are an exciting way to deploy containers to Azure. This post shows how to deploy the infrastructure for an Azure Container App to Azure using Bicep and GitHub Actions. The Azure Container App documentation features quickstarts for deploying your first container app using both the Azure Portal and the Azure CLI. These are great, but there's a gap if you prefer to deploy using Bicep and you'd like to get your CI/CD setup right from the beginning. This post aims to fill that gap.",date:"2021-12-19T00:00:00.000Z",formattedDate:"December 19, 2021",tags:[{label:"Azure Container Apps",permalink:"/tags/azure-container-apps"},{label:"Bicep",permalink:"/tags/bicep"},{label:"GitHub Actions",permalink:"/tags/git-hub-actions"}],readingTime:3.725,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-container-apps-bicep-and-github-actions",title:"Azure Container Apps, Bicep and GitHub Actions",authors:"johnnyreilly",tags:["Azure Container Apps","Bicep","GitHub Actions"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"Azure Container Apps: build and deploy with Bicep and GitHub Actions",permalink:"/azure-container-apps-build-and-deploy-with-bicep-and-github-actions"},nextItem:{title:"Open Graph: a guide to sharable social media previews",permalink:"/open-graph-sharing-previews-guide"}},p={image:n(79984).Z,authorsImageUrls:[void 0]},u=[{value:"Updated 02/05/2022",id:"updated-02052022",level:2},{value:"Bicep",id:"bicep",level:2},{value:"Setting up a resource group",id:"setting-up-a-resource-group",level:2},{value:"Deploying with the Azure CLI",id:"deploying-with-the-azure-cli",level:2},{value:"Deploying with GitHub Actions",id:"deploying-with-github-actions",level:2},{value:"Running it",id:"running-it",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Azure Container Apps are an exciting way to deploy containers to Azure. This post shows how to deploy the infrastructure for an Azure Container App to Azure using Bicep and GitHub Actions. The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/container-apps/"}),"Azure Container App documentation")," features quickstarts for deploying your first container app using both the Azure Portal and the Azure CLI. These are great, but there's a gap if you prefer to deploy using Bicep and you'd like to get your CI/CD setup right from the beginning. This post aims to fill that gap."),(0,a.kt)("p",null,"If you're interested in building your own containers as well, it's worth looking at ",(0,a.kt)("a",o({parentName:"p"},{href:"/azure-container-apps-build-and-deploy-with-bicep-and-github-actions"}),"this follow up post"),"."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Azure Container Apps, Bicep and GitHub Actions&quot; with the Bicep, Azure Container Apps and GitHub Actions logos",src:n(79984).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"updated-02052022"}),"Updated 02/05/2022"),(0,a.kt)("p",null,"This post has been updated to reflect the migration of Azure Container Apps from the Microsoft.Web namespace to the Microsoft.App namespace in March 2022. See: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/azure-container-apps/issues/109"}),"https://github.com/microsoft/azure-container-apps/issues/109")),(0,a.kt)("h2",o({},{id:"bicep"}),"Bicep"),(0,a.kt)("p",null,"Let's begin with the Bicep required to deploy an Azure Container App."),(0,a.kt)("p",null,"In our new repository we'll create an ",(0,a.kt)("inlineCode",{parentName:"p"},"infra")," directory, into which we'll place a ",(0,a.kt)("inlineCode",{parentName:"p"},"main.bicep")," file which will contain our Bicep template."),(0,a.kt)("p",null,"I've pared this down to the simplest Bicep template that I can; it only requires a name parameter:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param name string\nparam secrets array = []\n\nvar location = resourceGroup().location\nvar environmentName = 'Production'\nvar workspaceName = '${name}-log-analytics'\n\nresource workspace 'Microsoft.OperationalInsights/workspaces@2021-12-01-preview' = {\n  name: workspaceName\n  location: location\n  properties: {\n    sku: {\n      name: 'PerGB2018'\n    }\n    retentionInDays: 30\n    workspaceCapping: {}\n  }\n}\n\nresource environment 'Microsoft.App/managedEnvironments@2022-01-01-preview' = {\n  name: environmentName\n  location: location\n  properties: {\n    appLogsConfiguration: {\n      destination: 'log-analytics'\n      logAnalyticsConfiguration: {\n        customerId: workspace.properties.customerId\n        sharedKey: listKeys(workspace.id, workspace.apiVersion).primarySharedKey\n      }\n    }\n  }\n}\n\nresource containerApp 'Microsoft.App/containerApps@2022-01-01-preview' = {\n  name: name\n  kind: 'containerapps'\n  location: location\n  properties: {\n    managedEnvironmentId: environment.id\n    configuration: {\n      secrets: secrets\n      registries: []\n      ingress: {\n        'external':true\n        'targetPort':80\n      }\n    }\n    template: {\n      containers: [\n        {\n          'name':'simple-hello-world-container'\n          'image':'mcr.microsoft.com/azuredocs/containerapps-helloworld:latest'\n          'command':[]\n          'resources':{\n            'cpu':'.25'\n            'memory':'.5Gi'\n          }\n        }\n      ]\n    }\n  }\n}\n")),(0,a.kt)("p",null,"Some things to note from the template:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"We're deploying three resources; a container app, a kube environment and an operational insights."),(0,a.kt)("li",{parentName:"ul"},"Just like the official quickstarts we're going to use the ",(0,a.kt)("inlineCode",{parentName:"li"},"containerapps-helloworld")," image.")),(0,a.kt)("h2",o({},{id:"setting-up-a-resource-group"}),"Setting up a resource group"),(0,a.kt)("p",null,"In order that you can deploy your Bicep, we're going to need a resource group to send it to. Right now, Azure Container Apps aren't available everywhere. So we're going to create ourselves a resource group in North Europe which does support ACAs:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"az group create -g rg-aca -l northeurope\n")),(0,a.kt)("h2",o({},{id:"deploying-with-the-azure-cli"}),"Deploying with the Azure CLI"),(0,a.kt)("p",null,"With this resource group in place, we could simply deploy using the Azure CLI like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"az deployment group create \\\n  --resource-group rg-aca \\\n  --template-file ./infra/main.bicep \\\n  --parameters \\\n    name='container-app'\n")),(0,a.kt)("h2",o({},{id:"deploying-with-github-actions"}),"Deploying with GitHub Actions"),(0,a.kt)("p",null,"However, we're aiming to set up a GitHub Action to do this for us. We'll create a ",(0,a.kt)("inlineCode",{parentName:"p"},".github/workflows/deploy.yaml")," file in our repository:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),"name: Deploy\non:\n  push:\n    branches: [main]\n  workflow_dispatch:\n\nenv:\n  RESOURCE_GROUP: rg-aca\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n\n      - name: Azure Login\n        uses: azure/login@v1\n        with:\n          creds: ${{ secrets.AZURE_CREDENTIALS }}\n\n      - name: Deploy bicep\n        uses: azure/CLI@v1\n        with:\n          inlineScript: |\n            az deployment group create \\\n              --resource-group ${{ env.RESOURCE_GROUP }} \\\n              --template-file ./infra/main.bicep \\\n              --parameters \\\n                name='container-app'\n")),(0,a.kt)("p",null,"The above GitHub action is very simple. It:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Logs into Azure using some ",(0,a.kt)("inlineCode",{parentName:"li"},"AZURE_CREDENTIALS")," we'll set up in a moment."),(0,a.kt)("li",{parentName:"ol"},"Invokes the Azure CLI to deploy our Bicep template.")),(0,a.kt)("p",null,"Let's create that ",(0,a.kt)("inlineCode",{parentName:"p"},"AZURE_CREDENTIALS")," secret in GitHub:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of `AZURE_CREDENTIALS` secret in the GitHub website that we need to create",src:n(62767).Z,width:"1540",height:"235"})),(0,a.kt)("p",null,"We'll use the Azure CLI once more:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),'az ad sp create-for-rbac --name "myApp" --role contributor \\\n    --scopes /subscriptions/{subscription-id}/resourceGroups/{resource-group} \\\n    --sdk-auth\n')),(0,a.kt)("p",null,"Remember to replace the ",(0,a.kt)("inlineCode",{parentName:"p"},"{subscription-id}")," with your subscription id and ",(0,a.kt)("inlineCode",{parentName:"p"},"{resource-group}")," with the name of your resource group (",(0,a.kt)("inlineCode",{parentName:"p"},"rg-aca")," if you're following along). This command will pump out a lump of JSON that looks something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "clientId": "a-client-id",\n  "clientSecret": "a-client-secret",\n  "subscriptionId": "a-subscription-id",\n  "tenantId": "a-tenant-id",\n  "activeDirectoryEndpointUrl": "https://login.microsoftonline.com",\n  "resourceManagerEndpointUrl": "https://management.azure.com/",\n  "activeDirectoryGraphResourceId": "https://graph.windows.net/",\n  "sqlManagementEndpointUrl": "https://management.core.windows.net:8443/",\n  "galleryEndpointUrl": "https://gallery.azure.com/",\n  "managementEndpointUrl": "https://management.core.windows.net/"\n}\n')),(0,a.kt)("p",null,"Take this and save it as the ",(0,a.kt)("inlineCode",{parentName:"p"},"AZURE_CREDENTIALS")," secret in Azure."),(0,a.kt)("h2",o({},{id:"running-it"}),"Running it"),(0,a.kt)("p",null,"When the GitHub Action has been run you'll find that Azure Container App is now showing up inside the Azure Portal:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the Azure Container App in the Azure Portal",src:n(11719).Z,width:"1400",height:"541"})),(0,a.kt)("p",null,"You'll see a URL is displayed, when you go that URL you'll find the hello world image is running!"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the running Azure Container App",src:n(52713).Z,width:"2227",height:"953"})))}d.isMDXComponent=!0},75259:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-container-apps-build-and-deploy-with-bicep-and-github-actions",title:"Azure Container Apps: build and deploy with Bicep and GitHub Actions",authors:"johnnyreilly",tags:["Azure Container Apps","Bicep","GitHub Actions","GitHub container registry"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-container-apps-build-and-deploy-with-bicep-and-github-actions",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-12-27-azure-container-apps-build-and-deploy-with-bicep-and-github-actions/index.md",source:"@site/blog/2021-12-27-azure-container-apps-build-and-deploy-with-bicep-and-github-actions/index.md",title:"Azure Container Apps: build and deploy with Bicep and GitHub Actions",description:"This post shows how to build and deploy a simple web application to Azure Container Apps using Bicep and GitHub Actions. This includes the configuration and deployment of secrets.",date:"2021-12-27T00:00:00.000Z",formattedDate:"December 27, 2021",tags:[{label:"Azure Container Apps",permalink:"/tags/azure-container-apps"},{label:"Bicep",permalink:"/tags/bicep"},{label:"GitHub Actions",permalink:"/tags/git-hub-actions"},{label:"GitHub container registry",permalink:"/tags/git-hub-container-registry"}],readingTime:13.495,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-container-apps-build-and-deploy-with-bicep-and-github-actions",title:"Azure Container Apps: build and deploy with Bicep and GitHub Actions",authors:"johnnyreilly",tags:["Azure Container Apps","Bicep","GitHub Actions","GitHub container registry"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"Query deployment outputs with the Azure CLI",permalink:"/azure-cli-show-query-output-properties"},nextItem:{title:"Azure Container Apps, Bicep and GitHub Actions",permalink:"/azure-container-apps-bicep-and-github-actions"}},p={image:n(31702).Z,authorsImageUrls:[void 0]},u=[{value:"Updated 02/05/2022",id:"updated-02052022",level:2},{value:"The containerised convent",id:"the-containerised-convent",level:2},{value:"Bicep",id:"bicep",level:2},{value:"The node container app",id:"the-node-container-app",level:3},{value:"Accessing the GitHub Container Registry",id:"accessing-the-github-container-registry",level:3},{value:"Secrets / Configuration",id:"secrets--configuration",level:3},{value:"Setting up a resource group",id:"setting-up-a-resource-group",level:2},{value:"Secrets for GitHub Actions",id:"secrets-for-github-actions",level:2},{value:"<code>AZURE_CREDENTIALS</code> - GitHub logging into Azure",id:"azure_credentials---github-logging-into-azure",level:3},{value:"<code>PACKAGES_TOKEN</code> - Azure accessing the GitHub container registry",id:"packages_token---azure-accessing-the-github-container-registry",level:3},{value:"Secrets for the app",id:"secrets-for-the-app",level:3},{value:"Deploying with GitHub Actions",id:"deploying-with-github-actions",level:2},{value:"<code>build</code> - building our image",id:"build---building-our-image",level:3},{value:"<code>deploy</code> - shipping our image to Azure",id:"deploy---shipping-our-image-to-azure",level:3},{value:"Running it",id:"running-it",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This post shows how to build and deploy a simple web application to Azure Container Apps using Bicep and GitHub Actions. This includes the configuration and deployment of secrets."),(0,a.kt)("p",null,"This post follows on from the ",(0,a.kt)("a",o({parentName:"p"},{href:"/azure-container-apps-bicep-and-github-actions"}),"previous post"),' which deployed infrastructure and a "hello world" container, this time introducing the building of an image and storing it in the ',(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry"}),"GitHub container registry")," so it can be deployed."),(0,a.kt)("p",null,"If you'd like to learn more about using dapr with Azure Container Apps then you might want to read ",(0,a.kt)("a",o({parentName:"p"},{href:"/azure-container-apps-dapr-bicep-github-actions-debug-devcontainer"}),"this post"),"."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Azure Container Apps: build and deploy with Bicep and GitHub Actions&quot; with the Bicep, Azure Container Apps and GitHub Actions logos",src:n(31702).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"updated-02052022"}),"Updated 02/05/2022"),(0,a.kt)("p",null,"This post has been updated to reflect the migration of Azure Container Apps from the Microsoft.Web namespace to the Microsoft.App namespace in March 2022. See: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/azure-container-apps/issues/109"}),"https://github.com/microsoft/azure-container-apps/issues/109")),(0,a.kt)("h2",o({},{id:"the-containerised-convent"}),"The containerised convent"),(0,a.kt)("p",null,"I learn the most about a technology when I'm using it to build something. It so happens that I have an aunt that's a nun, and long ago she persuaded me to build her convent a website. I'm a good nephew and I complied. Since that time I've been merrily overengineering it for fun and non-profit."),(0,a.kt)("p",null,"My aunts website is a pretty vanilla node app. Significantly it is already containerised and runs on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://azure.microsoft.com/en-gb/services/app-service/containers/"}),"Azure App Service Web App for Containers"),". Given it lives in the context of a container, this makes it a great candidate for porting to Azure Container Apps."),(0,a.kt)("p",null,"So that's what we'll do in this post. But where I'm building and deploying my aunt's container, you could equally be substituting your own; with some minimal changes."),(0,a.kt)("h2",o({},{id:"bicep"}),"Bicep"),(0,a.kt)("p",null,"Let's begin with the Bicep required to deploy our Azure Container App."),(0,a.kt)("p",null,"In our repository we'll create an ",(0,a.kt)("inlineCode",{parentName:"p"},"infra")," directory, into which we'll place a ",(0,a.kt)("inlineCode",{parentName:"p"},"main.bicep")," file which will contain our Bicep template:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param nodeImage string\nparam nodePort int\nparam nodeIsExternalIngress bool\n\nparam containerRegistry string\nparam containerRegistryUsername string\n@secure()\nparam containerRegistryPassword string\n\nparam tags object\n\n@secure()\nparam APPSETTINGS_API_KEY string\nparam APPSETTINGS_DOMAIN string\nparam APPSETTINGS_FROM_EMAIL string\nparam APPSETTINGS_RECIPIENT_EMAIL string\n\nvar location = resourceGroup().location\nvar environmentName = 'env-${uniqueString(resourceGroup().id)}'\nvar minReplicas = 0\n\nvar nodeServiceAppName = 'node-app'\nvar workspaceName = '${nodeServiceAppName}-log-analytics'\nvar appInsightsName = '${nodeServiceAppName}-app-insights'\n\nvar containerRegistryPasswordRef = 'container-registry-password'\nvar mailgunApiKeyRef = 'mailgun-api-key'\n\nresource workspace 'Microsoft.OperationalInsights/workspaces@2021-12-01-preview' = {\n  name: workspaceName\n  location: location\n  tags: tags\n  properties: {\n    sku: {\n      name: 'PerGB2018'\n    }\n    retentionInDays: 30\n    workspaceCapping: {}\n  }\n}\n\nresource appInsights 'Microsoft.Insights/components@2020-02-02' = {\n  name: appInsightsName\n  location: location\n  tags: tags\n  kind: 'web'\n  properties: {\n    Application_Type: 'web'\n    Flow_Type: 'Bluefield'\n  }\n}\n\nresource environment 'Microsoft.App/managedEnvironments@2022-01-01-preview' = {\n  name: environmentName\n  location: location\n  tags: tags\n  properties: {\n    appLogsConfiguration: {\n      destination: 'log-analytics'\n      logAnalyticsConfiguration: {\n        customerId: workspace.properties.customerId\n        sharedKey: listKeys(workspace.id, workspace.apiVersion).primarySharedKey\n      }\n    }\n    containerAppsConfiguration: {\n      daprAIInstrumentationKey: appInsights.properties.InstrumentationKey\n    }\n  }\n}\n\nresource containerApp 'Microsoft.App/containerApps@2022-01-01-preview' = {\n  name: nodeServiceAppName\n  kind: 'containerapps'\n  tags: tags\n  location: location\n  properties: {\n    managedEnvironmentId: environment.id\n    configuration: {\n      secrets: [\n        {\n          name: containerRegistryPasswordRef\n          value: containerRegistryPassword\n        }\n        {\n          name: mailgunApiKeyRef\n          value: APPSETTINGS_API_KEY\n        }\n      ]\n      registries: [\n        {\n          server: containerRegistry\n          username: containerRegistryUsername\n          passwordSecretRef: containerRegistryPasswordRef\n        }\n      ]\n      ingress: {\n        'external': nodeIsExternalIngress\n        'targetPort': nodePort\n      }\n    }\n    template: {\n      containers: [\n        {\n          image: nodeImage\n          name: nodeServiceAppName\n          transport: 'auto'\n          env: [\n            {\n              name: 'APPSETTINGS_API_KEY'\n              secretref: mailgunApiKeyRef\n            }\n            {\n              name: 'APPSETTINGS_DOMAIN'\n              value: APPSETTINGS_DOMAIN\n            }\n            {\n              name: 'APPSETTINGS_FROM_EMAIL'\n              value: APPSETTINGS_FROM_EMAIL\n            }\n            {\n              name: 'APPSETTINGS_RECIPIENT_EMAIL'\n              value: APPSETTINGS_RECIPIENT_EMAIL\n            }\n          ]\n        }\n      ]\n      scale: {\n        minReplicas: minReplicas\n      }\n    }\n  }\n}\n")),(0,a.kt)("p",null,"Let's talk through this template. The environment, workspace and app insights resources are fairly self explanatory. The ",(0,a.kt)("inlineCode",{parentName:"p"},"containerApp")," resource is where the action is. We'll drill into that resource and the parameters used to configure it."),(0,a.kt)("h3",o({},{id:"the-node-container-app"}),"The node container app"),(0,a.kt)("p",null,"We're going to create a single container app for our node web application. This is configured with these parameters:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param nodeImage string\nparam nodePort int\nparam nodeIsExternalIngress bool\n")),(0,a.kt)("p",null,"The above parameters relate to the node application that represents the website. The ",(0,a.kt)("inlineCode",{parentName:"p"},"nodeImage")," is the container image which should be deployed to a container app. The ",(0,a.kt)("inlineCode",{parentName:"p"},"nodePort")," is the port from the app which should be exposed (",(0,a.kt)("inlineCode",{parentName:"p"},"3000")," in our case). ",(0,a.kt)("inlineCode",{parentName:"p"},"nodeIsExternalIngress")," is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/container-apps/ingress?tabs=bash#configuration"}),"whether the container should be accessible on the internet"),". (Always ",(0,a.kt)("inlineCode",{parentName:"p"},"true")," incidentally.)"),(0,a.kt)("p",null,"When these parameters are applied to the ",(0,a.kt)("inlineCode",{parentName:"p"},"containerApp")," resource, it looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"var nodeServiceAppName = 'node-app'\n\nresource containerApp 'Microsoft.App/containerApps@2022-01-01-preview' = {\n  // ...\n  properties: {\n      // ...\n      ingress: {\n        'external': nodeIsExternalIngress\n        'targetPort': nodePort\n      }\n    }\n    template: {\n      containers: [\n        {\n          image: nodeImage\n          name: nodeServiceAppName\n          // ...\n        }\n      ]\n      // ...\n    }\n  }\n}\n")),(0,a.kt)("h3",o({},{id:"accessing-the-github-container-registry"}),"Accessing the GitHub Container Registry"),(0,a.kt)("p",null,"Given that we've told Bicep to deploy an ",(0,a.kt)("inlineCode",{parentName:"p"},"image"),", we're going to need to tell it what registry it can use to acquire that image. Our template takes these parameters:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param containerRegistry string\nparam containerRegistryUsername string\n@secure()\nparam containerRegistryPassword string\n\nparam tags object\n")),(0,a.kt)("p",null,"With the exception of the ",(0,a.kt)("inlineCode",{parentName:"p"},"tags")," object which is metadata to apply to resources, these parameters are related to the container registry where our images will be stored. GitHub's in our case. Remember, what we deploy to Azure Container Apps are container images. To get something running in an ACA, it first has to reside in a container registry. There's a multitude of container registries out there and we're using the one directly available in GitHub. As an alternative, we could use an ",(0,a.kt)("a",o({parentName:"p"},{href:"https://azure.microsoft.com/en-us/services/container-registry/"}),"Azure Container Registry"),", or ",(0,a.kt)("a",o({parentName:"p"},{href:"https://hub.docker.com/"}),"Docker Hub")," - or something else entirely."),(0,a.kt)("p",null,"Do note the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/azure-resource-manager/bicep/parameters#secure-parameters"}),(0,a.kt)("inlineCode",{parentName:"a"},"@secure()"))," decorator. This marks the ",(0,a.kt)("inlineCode",{parentName:"p"},"containerRegistryPassword")," parameter as secure. The value for a secure parameter isn't saved to the deployment history and isn't logged. Typically you'll want to mark secrets with the ",(0,a.kt)("inlineCode",{parentName:"p"},"@secure()")," decorator for this very reason."),(0,a.kt)("p",null,"We use the parameters to configure the ",(0,a.kt)("inlineCode",{parentName:"p"},"registries")," property of our container app. This tells the ACA where it can go to collect the image it needs. You can also see our first usage of secrets here. We declare the ",(0,a.kt)("inlineCode",{parentName:"p"},"containerRegistryPassword")," as a secret which is stored against the ref ",(0,a.kt)("inlineCode",{parentName:"p"},"'container-registry-password'"),"; captured as the variable ",(0,a.kt)("inlineCode",{parentName:"p"},"containerRegistryPasswordRef"),". That variable is then referenced in the ",(0,a.kt)("inlineCode",{parentName:"p"},"passwordSecretRef")," property - thus telling ACA where it can find the password."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"var containerRegistryPasswordRef = 'container-registry-password'\n\nresource containerApp 'Microsoft.App/containerApps@2022-01-01-preview' = {\n  // ...\n  properties: {\n    // ...\n    configuration: {\n      secrets: [\n        {\n          name: containerRegistryPasswordRef\n          value: containerRegistryPassword\n        }\n        // ...\n      ]\n      registries: [\n        {\n          server: containerRegistry\n          username: containerRegistryUsername\n          passwordSecretRef: containerRegistryPasswordRef\n        }\n      ]\n      // ...\n    }\n    // ...\n  }\n}\n")),(0,a.kt)("h3",o({},{id:"secrets--configuration"}),"Secrets / Configuration"),(0,a.kt)("p",null,"The final collection of parameters are unrelated to the infrastructure of deployment, rather they are the things required to configure our running application:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"@secure()\nparam APPSETTINGS_API_KEY string\nparam APPSETTINGS_DOMAIN string\nparam APPSETTINGS_FROM_EMAIL string\nparam APPSETTINGS_RECIPIENT_EMAIL string\n")),(0,a.kt)("p",null,"Again we've got a secret marked with ",(0,a.kt)("inlineCode",{parentName:"p"},"@secure()")," in the form of our ",(0,a.kt)("inlineCode",{parentName:"p"},"APPSETTINGS_API_KEY"),". Just as we did with ",(0,a.kt)("inlineCode",{parentName:"p"},"containerRegistryPassword"),", we declare ",(0,a.kt)("inlineCode",{parentName:"p"},"APPSETTINGS_API_KEY")," to be a secret, which is stored against the ref ",(0,a.kt)("inlineCode",{parentName:"p"},"'mailgun-api-key'"),"; captured as the variable ",(0,a.kt)("inlineCode",{parentName:"p"},"mailgunApiKeyRef"),"."),(0,a.kt)("p",null,"All of our configuration is exposed to the running application through environment variables. By and large this is achieved through the mechanism of key / value pairs (well technically ",(0,a.kt)("inlineCode",{parentName:"p"},"name")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"value"),") with a slight variation for secrets. Similar to the ",(0,a.kt)("inlineCode",{parentName:"p"},"passwordSecretRef")," mechanism we used for the registry password, we use a ",(0,a.kt)("inlineCode",{parentName:"p"},"secretref")," in place of ",(0,a.kt)("inlineCode",{parentName:"p"},"value")," when passing a secret, and the value will be the ref that was set up in the ",(0,a.kt)("inlineCode",{parentName:"p"},"secrets")," section; ",(0,a.kt)("inlineCode",{parentName:"p"},"mailgunApiKeyRef")," in this case."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"var mailgunApiKeyRef = 'mailgun-api-key'\n\nresource containerApp 'Microsoft.App/containerApps@2022-01-01-preview' = {\n  // ...\n  properties: {\n    // ...\n    configuration: {\n      secrets: [\n        // ...\n        {\n          name: mailgunApiKeyRef\n          value: APPSETTINGS_API_KEY\n        }\n      ]\n      // ...\n    }\n    template: {\n      containers: [\n        {\n          // ...\n          env: [\n            {\n              name: 'APPSETTINGS_API_KEY'\n              secretref: mailgunApiKeyRef\n            }\n            {\n              name: 'APPSETTINGS_DOMAIN'\n              value: APPSETTINGS_DOMAIN\n            }\n            {\n              name: 'APPSETTINGS_FROM_EMAIL'\n              value: APPSETTINGS_FROM_EMAIL\n            }\n            {\n              name: 'APPSETTINGS_RECIPIENT_EMAIL'\n              value: APPSETTINGS_RECIPIENT_EMAIL\n            }\n          ]\n        }\n      ]\n      // ...\n    }\n  }\n}\n")),(0,a.kt)("h2",o({},{id:"setting-up-a-resource-group"}),"Setting up a resource group"),(0,a.kt)("p",null,"With our Bicep in place, we're going to need a resource group to send it to. Right now, Azure Container Apps aren't available everywhere. So we're going to create ourselves a resource group in North Europe which does support ACAs:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"az group create -g rg-aca -l northeurope\n")),(0,a.kt)("h2",o({},{id:"secrets-for-github-actions"}),"Secrets for GitHub Actions"),(0,a.kt)("p",null,"We're aiming to set up a GitHub Action to handle our deployment. This will depend upon a number of secrets:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the secrets in the GitHub website that we need to create",src:n(7262).Z,width:"1544",height:"842"})),(0,a.kt)("p",null,"We'll need to create each of these secrets."),(0,a.kt)("h3",o({},{id:"azure_credentials---github-logging-into-azure"}),(0,a.kt)("inlineCode",{parentName:"h3"},"AZURE_CREDENTIALS")," - GitHub logging into Azure"),(0,a.kt)("p",null,"So GitHub Actions can interact with Azure on our behalf, we need to provide it with some credentials. We'll use the Azure CLI to create these:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),'az ad sp create-for-rbac --name "myApp" --role contributor \\\n    --scopes /subscriptions/{subscription-id}/resourceGroups/{resource-group} \\\n    --sdk-auth\n')),(0,a.kt)("p",null,"Remember to replace the ",(0,a.kt)("inlineCode",{parentName:"p"},"{subscription-id}")," with your subscription id and ",(0,a.kt)("inlineCode",{parentName:"p"},"{resource-group}")," with the name of your resource group (",(0,a.kt)("inlineCode",{parentName:"p"},"rg-aca")," if you're following along). This command will pump out a lump of JSON that looks something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "clientId": "a-client-id",\n  "clientSecret": "a-client-secret",\n  "subscriptionId": "a-subscription-id",\n  "tenantId": "a-tenant-id",\n  "activeDirectoryEndpointUrl": "https://login.microsoftonline.com",\n  "resourceManagerEndpointUrl": "https://management.azure.com/",\n  "activeDirectoryGraphResourceId": "https://graph.windows.net/",\n  "sqlManagementEndpointUrl": "https://management.core.windows.net:8443/",\n  "galleryEndpointUrl": "https://gallery.azure.com/",\n  "managementEndpointUrl": "https://management.core.windows.net/"\n}\n')),(0,a.kt)("p",null,"Take this and save it as the ",(0,a.kt)("inlineCode",{parentName:"p"},"AZURE_CREDENTIALS")," secret in Azure."),(0,a.kt)("h3",o({},{id:"packages_token---azure-accessing-the-github-container-registry"}),(0,a.kt)("inlineCode",{parentName:"h3"},"PACKAGES_TOKEN")," - Azure accessing the GitHub container registry"),(0,a.kt)("p",null,"We also need a secret for accessing packages from Azure. We're going to be publishing packages to the GitHub container registry. Azure is going to need to be able to access this when we're deploying. ACA deployment works by telling Azure where to look for an image and providing any necessary credentials to do the acquisition. To facilitate this we'll set up a ",(0,a.kt)("inlineCode",{parentName:"p"},"PACKAGES_TOKEN")," secret. This is a GitHub personal access token with the ",(0,a.kt)("inlineCode",{parentName:"p"},"read:packages")," scope. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token"}),"Follow the instructions here to create the token.")),(0,a.kt)("h3",o({},{id:"secrets-for-the-app"}),"Secrets for the app"),(0,a.kt)("p",null,"Alongside these infrastructure / deployment related secrets, we'll need ones to configure the app at runtime:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"APPSETTINGS_API_KEY")," - an API key for Mailgun which will be used to send emails"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"APPSETTINGS_DOMAIN")," - the domain for the email eg ",(0,a.kt)("inlineCode",{parentName:"li"},"mg.poorclaresarundel.org")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"APPSETTINGS_FROM_EMAIL")," - who automated emails should come from eg ",(0,a.kt)("inlineCode",{parentName:"li"},"noreply@mg.poorclaresarundel.org")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"APPSETTINGS_RECIPIENT_EMAIL")," - the email address emails should be sent to")),(0,a.kt)("p",null,"Strictly speaking, only the API key is a secret. But to simplify this post we'll configure all of these as secrets in GitHub."),(0,a.kt)("h2",o({},{id:"deploying-with-github-actions"}),"Deploying with GitHub Actions"),(0,a.kt)("p",null,"With our secrets configured, we're now well placed to write our GitHub Action. We'll create a ",(0,a.kt)("inlineCode",{parentName:"p"},".github/workflows/deploy.yaml")," file in our repository and populate it thusly:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),'# yaml-language-server: $schema=./build.yaml\nname: Build and Deploy\non:\n  # Trigger the workflow on push or pull request,\n  # but only for the main branch\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n    # Publish semver tags as releases.\n    tags: [\'v*.*.*\']\n  workflow_dispatch:\n\nenv:\n  RESOURCE_GROUP: rg-aca\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        services:\n          [{ \'imageName\': \'node-service\', \'directory\': \'./node-service\' }]\n    permissions:\n      contents: read\n      packages: write\n    outputs:\n      containerImage-node: ${{ steps.image-tag.outputs.image-node-service }}\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n\n      # Login against a Docker registry except on PR\n      # https://github.com/docker/login-action\n      - name: Log into registry ${{ env.REGISTRY }}\n        if: github.event_name != \'pull_request\'\n        uses: docker/login-action@v1\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      # Extract metadata (tags, labels) for Docker\n      # https://github.com/docker/metadata-action\n      - name: Extract Docker metadata\n        id: meta\n        uses: docker/metadata-action@v3\n        with:\n          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/${{ matrix.services.imageName }}\n          tags: |\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n            type=semver,pattern={{major}}\n            type=ref,event=branch\n            type=sha\n\n      # Build and push Docker image with Buildx (don\'t push on PR)\n      # https://github.com/docker/build-push-action\n      - name: Build and push Docker image\n        uses: docker/build-push-action@v2\n        with:\n          context: ${{ matrix.services.directory }}\n          push: ${{ github.event_name != \'pull_request\' }}\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n\n      - name: Output image tag\n        id: image-tag\n        run: echo "::set-output name=image-${{ matrix.services.imageName }}::${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/${{ matrix.services.imageName }}:sha-$(git rev-parse --short HEAD)" | tr \'[:upper:]\' \'[:lower:]\'\n\n  deploy:\n    runs-on: ubuntu-latest\n    needs: [build]\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n\n      - name: Azure Login\n        uses: azure/login@v1\n        with:\n          creds: ${{ secrets.AZURE_CREDENTIALS }}\n\n      - name: Deploy bicep\n        uses: azure/CLI@v1\n        if: github.event_name != \'pull_request\'\n        with:\n          inlineScript: |\n            tags=\'{"owner":"johnnyreilly", "email":"johnny_reilly@hotmail.com"}\'\n            az deployment group create \\\n              --resource-group ${{ env.RESOURCE_GROUP }} \\\n              --template-file ./infra/main.bicep \\\n              --parameters \\\n                  nodeImage=\'${{ needs.build.outputs.containerImage-node }}\' \\\n                  nodePort=3000 \\\n                  nodeIsExternalIngress=true \\\n                  containerRegistry=${{ env.REGISTRY }} \\\n                  containerRegistryUsername=${{ github.actor }} \\\n                  containerRegistryPassword=${{ secrets.PACKAGES_TOKEN }} \\\n                  tags="$tags" \\\n                  APPSETTINGS_API_KEY="${{ secrets.APPSETTINGS_API_KEY }}" \\\n                  APPSETTINGS_DOMAIN="${{ secrets.APPSETTINGS_DOMAIN }}" \\\n                  APPSETTINGS_FROM_EMAIL="${{ secrets.APPSETTINGS_FROM_EMAIL }}" \\\n                  APPSETTINGS_RECIPIENT_EMAIL="${{ secrets.APPSETTINGS_RECIPIENT_EMAIL }}"\n\n      - name: What-if bicep\n        uses: azure/CLI@v1\n        if: github.event_name == \'pull_request\'\n        with:\n          inlineScript: |\n            tags=\'{"owner":"johnnyreilly", "email":"johnny_reilly@hotmail.com"}\'\n            az deployment group what-if \\\n              --resource-group ${{ env.RESOURCE_GROUP }} \\\n              --template-file ./infra/main.bicep \\\n              --parameters \\\n                  nodeImage=\'${{ needs.build.outputs.containerImage-node }}\' \\\n                  nodePort=3000 \\\n                  nodeIsExternalIngress=true \\\n                  containerRegistry=${{ env.REGISTRY }} \\\n                  containerRegistryUsername=${{ github.actor }} \\\n                  containerRegistryPassword=${{ secrets.PACKAGES_TOKEN }} \\\n                  tags="$tags" \\\n                  APPSETTINGS_API_KEY="${{ secrets.APPSETTINGS_API_KEY }}" \\\n                  APPSETTINGS_DOMAIN="${{ secrets.APPSETTINGS_DOMAIN }}" \\\n                  APPSETTINGS_FROM_EMAIL="${{ secrets.APPSETTINGS_FROM_EMAIL }}" \\\n                  APPSETTINGS_RECIPIENT_EMAIL="${{ secrets.APPSETTINGS_RECIPIENT_EMAIL }}"\n')),(0,a.kt)("p",null,"There's a lot in this workflow. Let's dig into the ",(0,a.kt)("inlineCode",{parentName:"p"},"build")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"deploy")," jobs to see what's happening."),(0,a.kt)("h3",o({},{id:"build---building-our-image"}),(0,a.kt)("inlineCode",{parentName:"h3"},"build")," - building our image"),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"build")," job is all about building our container images and pushing then to the GitHub registry. It's heavily inspired by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/jeffhollan"}),"Jeff Hollan"),"'s ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure-Samples/container-apps-store-api-microservice"}),"Azure sample app GHA"),". When we look at the ",(0,a.kt)("inlineCode",{parentName:"p"},"strategy")," we can see a ",(0,a.kt)("inlineCode",{parentName:"p"},"matrix")," of ",(0,a.kt)("inlineCode",{parentName:"p"},"services")," consisting of a single service; our node app:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),"strategy:\n  matrix:\n    services: [{ 'imageName': 'node-service', 'directory': './node-service' }]\n")),(0,a.kt)("p",null,"This is a matrix because a typical use case of an Azure Container App will be multi-container, so we're starting generic from the beginning. The ",(0,a.kt)("inlineCode",{parentName:"p"},"outputs")," pumps out the details of our ",(0,a.kt)("inlineCode",{parentName:"p"},"containerImage-node")," image to be used later:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),"outputs:\n  containerImage-node: ${{ steps.image-tag.outputs.image-node-service }}\n")),(0,a.kt)("p",null,"With that understanding in place, let's examine what each of the steps in the ",(0,a.kt)("inlineCode",{parentName:"p"},"build")," job does"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Log into registry")," - logs into the GitHub container registry"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Extract Docker metadata")," - acquire tags which will be used for versioning"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Build and push Docker image")," - build the docker image and if this is not a PR: tag, label and push it to the registry"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Output image tag")," - write out the image tag for usage in deployment")),(0,a.kt)("h3",o({},{id:"deploy---shipping-our-image-to-azure"}),(0,a.kt)("inlineCode",{parentName:"h3"},"deploy")," - shipping our image to Azure"),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"deploy")," job does two possible things with our Bicep template; ",(0,a.kt)("inlineCode",{parentName:"p"},"main.bicep"),"."),(0,a.kt)("p",null,"In the case of a pull request, it runs the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/cli/azure/deployment/group?view=azure-cli-latest#az_deployment_group_what_if"}),(0,a.kt)("inlineCode",{parentName:"a"},"az deployment group what-if"))," - this allows us to see what the effect would be of applying a PR to our infrastructure."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),'- name: What-if bicep\n  uses: azure/CLI@v1\n  if: github.event_name == \'pull_request\'\n  with:\n    inlineScript: |\n      tags=\'{"owner":"johnnyreilly", "email":"johnny_reilly@hotmail.com"}\'\n      az deployment group what-if \\\n        --resource-group ${{ env.RESOURCE_GROUP }} \\\n        --template-file ./infra/main.bicep \\\n        --parameters \\\n            nodeImage=\'${{ needs.build.outputs.containerImage-node }}\' \\\n            nodePort=3000 \\\n            nodeIsExternalIngress=true \\\n            containerRegistry=${{ env.REGISTRY }} \\\n            containerRegistryUsername=${{ github.actor }} \\\n            containerRegistryPassword=${{ secrets.PACKAGES_TOKEN }} \\\n            tags="$tags" \\\n            APPSETTINGS_API_KEY="${{ secrets.APPSETTINGS_API_KEY }}" \\\n            APPSETTINGS_DOMAIN="${{ secrets.APPSETTINGS_DOMAIN }}" \\\n            APPSETTINGS_FROM_EMAIL="${{ secrets.APPSETTINGS_FROM_EMAIL }}" \\\n            APPSETTINGS_RECIPIENT_EMAIL="${{ secrets.APPSETTINGS_RECIPIENT_EMAIL }}"\n')),(0,a.kt)("p",null,"When it's not a pull request, it runs the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/cli/azure/deployment/group?view=azure-cli-latest#az_deployment_group_create"}),(0,a.kt)("inlineCode",{parentName:"a"},"az deployment group create"))," command which performs a deployment of our ",(0,a.kt)("inlineCode",{parentName:"p"},"main.bicep")," file."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),'- name: Deploy bicep\n  uses: azure/CLI@v1\n  if: github.event_name != \'pull_request\'\n  with:\n    inlineScript: |\n      tags=\'{"owner":"johnnyreilly", "email":"johnny_reilly@hotmail.com"}\'\n      az deployment group create \\\n        --resource-group ${{ env.RESOURCE_GROUP }} \\\n        --template-file ./infra/main.bicep \\\n        --parameters \\\n            nodeImage=\'${{ needs.build.outputs.containerImage-node }}\' \\\n            nodePort=3000 \\\n            nodeIsExternalIngress=true \\\n            containerRegistry=${{ env.REGISTRY }} \\\n            containerRegistryUsername=${{ github.actor }} \\\n            containerRegistryPassword=${{ secrets.PACKAGES_TOKEN }} \\\n            tags="$tags" \\\n            APPSETTINGS_API_KEY="${{ secrets.APPSETTINGS_API_KEY }}" \\\n            APPSETTINGS_DOMAIN="${{ secrets.APPSETTINGS_DOMAIN }}" \\\n            APPSETTINGS_FROM_EMAIL="${{ secrets.APPSETTINGS_FROM_EMAIL }}" \\\n            APPSETTINGS_RECIPIENT_EMAIL="${{ secrets.APPSETTINGS_RECIPIENT_EMAIL }}"\n')),(0,a.kt)("p",null,"In either case we pass the same set of parameters:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),'nodeImage=\'${{ needs.build.outputs.containerImage-node }}\' \\\nnodePort=3000 \\\nnodeIsExternalIngress=true \\\ncontainerRegistry=${{ env.REGISTRY }} \\\ncontainerRegistryUsername=${{ github.actor }} \\\ncontainerRegistryPassword=${{ secrets.PACKAGES_TOKEN }} \\\ntags="$tags" \\\nAPPSETTINGS_API_KEY="${{ secrets.APPSETTINGS_API_KEY }}" \\\nAPPSETTINGS_DOMAIN="${{ secrets.APPSETTINGS_DOMAIN }}" \\\nAPPSETTINGS_FROM_EMAIL="${{ secrets.APPSETTINGS_FROM_EMAIL }}" \\\nAPPSETTINGS_RECIPIENT_EMAIL="${{ secrets.APPSETTINGS_RECIPIENT_EMAIL }}"\n')),(0,a.kt)("p",null,"These are either:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"secrets we set up earlier"),(0,a.kt)("li",{parentName:"ul"},"environment variables declared at the start of the script or"),(0,a.kt)("li",{parentName:"ul"},"outputs from the build step - this is where we acquire our node image")),(0,a.kt)("h2",o({},{id:"running-it"}),"Running it"),(0,a.kt)("p",null,"When the GitHub Action has been run you'll find that Azure Container App is now showing up inside the Azure Portal in your resource group, alongside the other resources:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the Azure Container App&#39;s resource group in the Azure Portal",src:n(19774).Z,width:"2507",height:"420"})),(0,a.kt)("p",null,"And when we take a closer look at the container app, we find a URL we can navigate to:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the Azure Container App in the Azure Portal revealing it&#39;s URL",src:n(37300).Z,width:"1404",height:"388"})),(0,a.kt)("p",null,"Congratulations! You've built and deployed a simple web app to Azure Container Apps with Bicep and GitHub Actions and secrets."))}d.isMDXComponent=!0},9929:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-cli-show-query-output-properties",title:"Query deployment outputs with the Azure CLI",authors:"johnnyreilly",tags:["azure cli","GitHub Actions"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-cli-show-query-output-properties",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-12-28-azure-cli-show-query-output-properties/index.md",source:"@site/blog/2021-12-28-azure-cli-show-query-output-properties/index.md",title:"Query deployment outputs with the Azure CLI",description:"It's often desirable to query the outputs of deployments to Azure. This post demonstrates how to do this using the Azure CLI, bash and jq. It also shows how to generically convert deployment outputs to GitHub Action job outputs.",date:"2021-12-28T00:00:00.000Z",formattedDate:"December 28, 2021",tags:[{label:"azure cli",permalink:"/tags/azure-cli"},{label:"GitHub Actions",permalink:"/tags/git-hub-actions"}],readingTime:2.575,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-cli-show-query-output-properties",title:"Query deployment outputs with the Azure CLI",authors:"johnnyreilly",tags:["azure cli","GitHub Actions"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"Preload fonts with Docusaurus (updated 03/11/2022)",permalink:"/preload-fonts-with-docusaurus"},nextItem:{title:"Azure Container Apps: build and deploy with Bicep and GitHub Actions",permalink:"/azure-container-apps-build-and-deploy-with-bicep-and-github-actions"}},p={image:n(2393).Z,authorsImageUrls:[void 0]},u=[{value:"Deployment outputs",id:"deployment-outputs",level:2},{value:"Acquire all outputs",id:"acquire-all-outputs",level:2},{value:"Acquire an individual output",id:"acquire-an-individual-output",level:2},{value:"Convert deployment outputs to GitHub Action job outputs",id:"convert-deployment-outputs-to-github-action-job-outputs",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"It's often desirable to query the outputs of deployments to Azure. This post demonstrates how to do this using the Azure CLI, bash and jq. It also shows how to generically convert deployment outputs to GitHub Action job outputs."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Query deployment outputs with the Azure CLI&quot; with the Azure logo and the Azure Cloud Shell in the background",src:n(2393).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"deployment-outputs"}),"Deployment outputs"),(0,a.kt)("p",null,"When we deploy something to Azure, we frequently have outputs which we want to use. Let's consider the canonical case, whereby a website is created and we want to use the URL of where it has been deployed. We can see these values in the Azure Portal:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"a screenshot of the Azure portal demostrating deployment outputs, there is a single output of &quot;nodeUrl&quot;",src:n(79665).Z,width:"1253",height:"320"})),(0,a.kt)("p",null,"The above deployment has a single output of ",(0,a.kt)("inlineCode",{parentName:"p"},"nodeUrl"),". Rather than logging into the portal to acquire this value, how can we do so using the Azure CLI and bash?"),(0,a.kt)("h2",o({},{id:"acquire-all-outputs"}),"Acquire all outputs"),(0,a.kt)("p",null,"The way to acquire outputs from the Azure CLI is using the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/cli/azure/group/deployment?view=azure-cli-latest#az_group_deployment_show"}),(0,a.kt)("inlineCode",{parentName:"a"},"az group deployment show"))," command:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"az deployment group show \\\n  -g <resource-group-name> \\\n  -n <deployment-name> \\\n  --query properties.outputs\n")),(0,a.kt)("p",null,"Running the above will produce a piece of JSON that contains all our outputs. In our case, we have a single deployment output: ",(0,a.kt)("inlineCode",{parentName:"p"},"nodeUrl"),". So our JSON looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "nodeUrl": {\n    "type": "String",\n    "value": "some.url.northeurope.azurecontainerapps.io"\n  }\n}\n')),(0,a.kt)("h2",o({},{id:"acquire-an-individual-output"}),"Acquire an individual output"),(0,a.kt)("p",null,"To acquire an individual output, you can provide a targeted ",(0,a.kt)("inlineCode",{parentName:"p"},"--query")," to pull out the value you care about. However, there's a slight issue:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),'john@Azure:~$ NODE_URL=$(az deployment group show -g rg-aca -n our-deployment --query properties.outputs.nodeUrl.value)\njohn@Azure:~$ echo $NODE_URL\n"some.url.northeurope.azurecontainerapps.io"\n')),(0,a.kt)("p",null,"The value we capture in the ",(0,a.kt)("inlineCode",{parentName:"p"},"NODE_URL")," variable above is surrounded by quotes. These will probably get in the way when we're scripting something with this. Rather than purging them with bash, I tend to use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://stedolan.github.io/jq/manual/"}),(0,a.kt)("inlineCode",{parentName:"a"},"jq"),"'s ",(0,a.kt)("inlineCode",{parentName:"a"},"--raw-output / -r")," option")," to grab the raw string."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"john@Azure:~$ NODE_URL=$(az deployment group show -g rg-aca -n our-deployment --query properties.outputs | jq -r '.nodeUrl.value')\njohn@Azure:~$ echo $NODE_URL\nsome.url.northeurope.azurecontainerapps.io\n")),(0,a.kt)("p",null,"Perfect!"),(0,a.kt)("p",null,"There's another approach you could use which ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/alexandair/status/1476554234543890437"}),"Aleksandar Nikoli\u0107 shared"),", which means jq needn't be used at all; using the ",(0,a.kt)("inlineCode",{parentName:"p"},"tsv")," output formatter:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"john@Azure:~$ NODE_URL=$(az deployment group show -g rg-aca -n our-deployment --query properties.outputs.nodeUrl.value -o tsv)\njohn@Azure:~$ echo $NODE_URL\nsome.url.northeurope.azurecontainerapps.io\n")),(0,a.kt)("h2",o({},{id:"convert-deployment-outputs-to-github-action-job-outputs"}),"Convert deployment outputs to GitHub Action job outputs"),(0,a.kt)("p",null,"Before wrapping up, here's one more useful script, if you find yourself automating in the context of GitHub Actions. It's often useful to take the deployment outputs, and convert them into GHA job outputs that can be used in other jobs."),(0,a.kt)("p",null,"With JSON and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://stedolan.github.io/jq/"}),"jq")," in hand, it's possible to expose these like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),'DEPLOYMENT_OUTPUTS=$(az deployment group show \\\n  --resource-group ${{ env.RESOURCE_GROUP }} \\\n  --name $DEPLOYMENT_NAME \\\n  --query properties.outputs)\n\necho \'convert deployment outputs to outputs\'\necho $DEPLOYMENT_OUTPUTS | jq -c \'. | to_entries[] | [.key, .value.value]\' |\n  while IFS=$"\\n" read -r c; do\n    OUTPUT_NAME=$(echo "$c" | jq -r \'.[0]\')\n    OUTPUT_VALUE=$(echo "$c" | jq -r \'.[1]\')\n    echo "setting output $OUTPUT_NAME=$OUTPUT_VALUE"\n    echo "::set-output name=$OUTPUT_NAME::$OUTPUT_VALUE"\n  done\n')))}d.isMDXComponent=!0},35044:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"preload-fonts-with-docusaurus",title:"Preload fonts with Docusaurus (updated 03/11/2022)",authors:"johnnyreilly",tags:["Docusaurus","webpack"],image:"./title-image.png",hide_table_of_contents:!1},s=void 0,l={permalink:"/preload-fonts-with-docusaurus",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2021-12-29-preload-fonts-with-docusaurus/index.md",source:"@site/blog/2021-12-29-preload-fonts-with-docusaurus/index.md",title:"Preload fonts with Docusaurus (updated 03/11/2022)",description:"When we're using custom fonts in our websites, it's good practice to preload the fonts to minimise the flash of unstyled text. This post shows how to achieve this with Docusaurus.",date:"2021-12-29T00:00:00.000Z",formattedDate:"December 29, 2021",tags:[{label:"Docusaurus",permalink:"/tags/docusaurus"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:4.305,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"preload-fonts-with-docusaurus",title:"Preload fonts with Docusaurus (updated 03/11/2022)",authors:"johnnyreilly",tags:["Docusaurus","webpack"],image:"./title-image.png",hide_table_of_contents:!1},prevItem:{title:"Azure Container Apps: dapr, devcontainer, debug and deploy",permalink:"/azure-container-apps-dapr-bicep-github-actions-debug-devcontainer"},nextItem:{title:"Query deployment outputs with the Azure CLI",permalink:"/azure-cli-show-query-output-properties"}},p={image:n(51659).Z,authorsImageUrls:[void 0]},u=[{value:"Preload web fonts with Docusaurus",id:"preload-web-fonts-with-docusaurus",level:2},{value:"Making a plugin",id:"making-a-plugin",level:2},{value:"Using the <code>headTags</code> API",id:"using-the-headtags-api",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"When we're using custom fonts in our websites, it's good practice to preload the fonts to minimise the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://css-tricks.com/fout-foit-foft/"}),"flash of unstyled text"),". This post shows how to achieve this with Docusaurus."),(0,a.kt)("p",null,"It does so by building a Docusaurus plugin which makes use of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/sn-satyendra"}),"Satyendra Singh"),"'s excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/sn-satyendra/webpack-font-preload-plugin"}),(0,a.kt)("inlineCode",{parentName:"a"},"webpack-font-preload-plugin")),"."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Updated 03/11/2022:")," Subsequently this post demonstrates how to achieve font preloading directly, by using the the ",(0,a.kt)("inlineCode",{parentName:"p"},"headTags")," API."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Preload fonts with Docusaurus&quot; in a ridiculous font with the Docusaurus logo and a screenshot of a preload link HTML element",src:n(51659).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"preload-web-fonts-with-docusaurus"}),"Preload web fonts with Docusaurus"),(0,a.kt)("p",null,"To quote the docs of the ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack-font-preload-plugin"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/HTML/Preloading_content"}),"preload")," value of the ",(0,a.kt)("inlineCode",{parentName:"p"},"<link>")," element's ",(0,a.kt)("inlineCode",{parentName:"p"},"rel")," attribute lets you declare fetch requests in the HTML's ",(0,a.kt)("inlineCode",{parentName:"p"},"<head>"),", specifying resources that your page will need very soon, which you want to start loading early in the page lifecycle, before browsers' main rendering machinery kicks in. This ensures they are available earlier and are less likely to block the page's render, improving performance."),(0,a.kt)("p",{parentName:"blockquote"},"This plugin specifically targets fonts used with the application which are bundled using webpack. The plugin would add ",(0,a.kt)("inlineCode",{parentName:"p"},"<link>")," tags in the begining of ",(0,a.kt)("inlineCode",{parentName:"p"},"<head>")," of your html:"),(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<link rel="preload" href="/font1.woff" as="font" crossorigin />\n<link rel="preload" href="/font2.woff" as="font" crossorigin />\n'))),(0,a.kt)("p",null,"If you want to learn more about preloading web fonts, it's also worth ",(0,a.kt)("a",o({parentName:"p"},{href:"https://web.dev/codelab-preload-web-fonts/"}),"reading this excellent article"),"."),(0,a.kt)("p",null,"The blog you're reading is built with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/"}),"Docusaurus"),". Our mission: for the HTML our Docusaurus build pumps out to feature preload ",(0,a.kt)("inlineCode",{parentName:"p"},"link")," elements. Something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<link\n  rel="preload"\n  href="/assets/fonts/Poppins-Regular-8081832fc5cfbf634aa664a9eff0350e.ttf"\n  as="font"\n  crossorigin=""\n/>\n')),(0,a.kt)("p",null,"This ",(0,a.kt)("inlineCode",{parentName:"p"},"link")," element has the ",(0,a.kt)("inlineCode",{parentName:"p"},'rel="preload"')," attribute set, which triggers font preloading."),(0,a.kt)("p",null,"But the thing to take from the above text is that the filename features a hash in the name. This demonstrates that the font is being pumped through the Docusaurus build, which is powered by webpack. So we need some webpack whispering to get font preloading going."),(0,a.kt)("h2",o({},{id:"making-a-plugin"}),"Making a plugin"),(0,a.kt)("p",null,"We're going to make a minimal ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/docs/using-plugins#creating-plugins"}),"Docusaurus plugin")," using ",(0,a.kt)("inlineCode",{parentName:"p"},"webpack-font-preload-plugin"),". Let's add it to our project:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"yarn add webpack-font-preload-plugin\n")),(0,a.kt)("p",null,"Now in the ",(0,a.kt)("inlineCode",{parentName:"p"},"docusaurus.config.js")," we can create our minimal plugin:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const FontPreloadPlugin = require('webpack-font-preload-plugin');\n\n//...\n/** @type {import('@docusaurus/types').Config} */\nconst config = {\n  //...\n  plugins: [\n    function preloadFontPlugin(_context, _options) {\n      return {\n        name: 'preload-font-plugin',\n        configureWebpack(_config, _isServer) {\n          return {\n            plugins: [new FontPreloadPlugin()],\n          };\n        },\n      };\n    },\n    // ...\n  ],\n  //...\n};\n")),(0,a.kt)("p",null,"It's a super simple plugin, it does nothing more than ",(0,a.kt)("inlineCode",{parentName:"p"},"new")," up an instance of the webpack plugin, inside the context of the ",(0,a.kt)("inlineCode",{parentName:"p"},"configureWebpack")," method. That's all that's required."),(0,a.kt)("p",null,"With this in place we're now seeing the ",(0,a.kt)("inlineCode",{parentName:"p"},'<link rel="preload" ... />')," elements being included in the HTML pumped out of our Docusaurus build. This means we have font preloading working:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the Chrome devtools featuring link rel=&quot;preload&quot; elements",src:n(6935).Z,width:"1243",height:"65"})),(0,a.kt)("p",null,"Huzzah!"),(0,a.kt)("h2",o({},{id:"using-the-headtags-api"}),"Using the ",(0,a.kt)("inlineCode",{parentName:"h2"},"headTags")," API"),(0,a.kt)("p",null,"If you're using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/blog/releases/2.2#config-headtags"}),"Docusaurus 2.2 or greater")," you can use the new ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/docs/api/docusaurus-config#headTags"}),(0,a.kt)("inlineCode",{parentName:"a"},"headTags")," API")," and bypass using an extra dependency entirely."),(0,a.kt)("p",null,"To make this work, we need to ensure that our fonts live in the ",(0,a.kt)("inlineCode",{parentName:"p"},"static")," directory which is reliably addressable - not hashed by webpack. We can then use the ",(0,a.kt)("inlineCode",{parentName:"p"},"headTags")," API to add the ",(0,a.kt)("inlineCode",{parentName:"p"},"link")," elements to the ",(0,a.kt)("inlineCode",{parentName:"p"},"head")," of the HTML:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"module.exports = {\n  // ...\n  headTags: [\n    // the entry below will make this tag: <link rel=\"preload\" href=\"/fonts/Poppins-Regular.ttf\" as=\"font\" type=\"font/ttf\" crossorigin=\"anonymous\">\n    {\n      tagName: 'link',\n      attributes: {\n        rel: 'preload',\n        href: '/fonts/Poppins-Regular.ttf',\n        as: 'font',\n        type: 'font/ttf',\n        crossorigin: 'anonymous',\n      },\n    },\n    // the entry below will make this tag: <link rel=\"preload\" href=\"/fonts/Poppins-Bold.ttf\" as=\"font\" type=\"font/ttf\" crossorigin=\"anonymous\">\n    {\n      tagName: 'link',\n      attributes: {\n        rel: 'preload',\n        href: '/fonts/Poppins-Bold.ttf',\n        as: 'font',\n        type: 'font/ttf',\n        crossorigin: 'anonymous',\n      },\n    },\n  ],\n  // ...\n};\n")),(0,a.kt)("p",null,"In our ",(0,a.kt)("inlineCode",{parentName:"p"},"custom.css")," we need to add the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-css"}),"@font-face {\n  font-family: 'Poppins';\n  src: url('https://blog.johnnyreilly.com/fonts/Poppins-Regular.ttf');\n  font-weight: 400;\n  font-style: normal;\n  font-display: swap;\n}\n\n@font-face {\n  font-family: 'Poppins';\n  src: url('https://blog.johnnyreilly.com/fonts/Poppins-Bold.ttf');\n  font-weight: 700;\n  font-style: normal;\n  font-display: swap;\n}\n")),(0,a.kt)("p",null,"Note that the urls are fully qualified to prevent webpack from trying to bundle them. Another bonus of using the ",(0,a.kt)("inlineCode",{parentName:"p"},"static")," folder is that we can apply long term caching. I'm using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://azure.microsoft.com/en-us/products/app-service/static/"}),"Azure Static Web Apps")," to run my site and so I'm achieving this with the following in ",(0,a.kt)("inlineCode",{parentName:"p"},"staticwebapp.config.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "trailingSlash": "auto",\n  "routes": [\n    {\n      "route": "/img/*",\n      "headers": {\n        "cache-control": "must-revalidate, max-age=15770000"\n      }\n    },\n    {\n      "route": "/fonts/*",\n      "headers": {\n        "cache-control": "must-revalidate, max-age=15770000"\n      }\n    }\n  ],\n  "globalHeaders": {\n    "content-security-policy": "default-src https: \'unsafe-eval\' \'unsafe-inline\'; object-src \'none\'; script-src \'self\' https://www.googleanalytics.com https://www.google-analytics.com https://www.googleoptimize.com https://www.googletagmanager.com \'unsafe-inline\'; img-src \'self\' data: https: https://blog.johnnyreilly.com https://thankful-sky-0bfc7e803-320.westeurope.1.azurestaticapps.net https://www.google-analytics.com https://www.googletagmanager.com",\n    "X-Clacks-Overhead": "GNU Terry Pratchett",\n    "Access-Control-Allow-Origin": "*"\n  }\n}\n')),(0,a.kt)("p",null,"Things to note from the above:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Access-Control-Allow-Origin")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"Vary")," are in place to allow my staging sites to access the fonts from the production site. Without this, the fonts won't load in the staging site."),(0,a.kt)("li",{parentName:"ul"},"The ",(0,a.kt)("inlineCode",{parentName:"li"},"img")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"fonts")," directories sit under the ",(0,a.kt)("inlineCode",{parentName:"li"},"static")," directory. For those directories we're going to use ",(0,a.kt)("inlineCode",{parentName:"li"},"cache-control")," set to 6 months for the fonts and static images. They rarely change and so this is an appropriate strategy.")),(0,a.kt)("p",null,"This blog post was migrated to the ",(0,a.kt)("inlineCode",{parentName:"p"},"headTags")," API approach with the release of Docusaurus 2.2.0. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/pull/321"}),"You can see the PR here"),"."))}d.isMDXComponent=!0},66830:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-container-apps-dapr-bicep-github-actions-debug-devcontainer",title:"Azure Container Apps: dapr, devcontainer, debug and deploy",authors:"johnnyreilly",tags:["Azure Container Apps","Bicep","GitHub Actions","devcontainer"],image:"./title-image.png",description:"Build and deploy two Azure Container Apps using Bicep and GitHub Actions, communicate using dapr, build, run and debug in VS Code using a devcontainer.",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-container-apps-dapr-bicep-github-actions-debug-devcontainer",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-01-22-azure-container-apps-dapr-bicep-github-actions-debug-devcontainer/index.md",source:"@site/blog/2022-01-22-azure-container-apps-dapr-bicep-github-actions-debug-devcontainer/index.md",title:"Azure Container Apps: dapr, devcontainer, debug and deploy",description:"Build and deploy two Azure Container Apps using Bicep and GitHub Actions, communicate using dapr, build, run and debug in VS Code using a devcontainer.",date:"2022-01-22T00:00:00.000Z",formattedDate:"January 22, 2022",tags:[{label:"Azure Container Apps",permalink:"/tags/azure-container-apps"},{label:"Bicep",permalink:"/tags/bicep"},{label:"GitHub Actions",permalink:"/tags/git-hub-actions"},{label:"devcontainer",permalink:"/tags/devcontainer"}],readingTime:21.6,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-container-apps-dapr-bicep-github-actions-debug-devcontainer",title:"Azure Container Apps: dapr, devcontainer, debug and deploy",authors:"johnnyreilly",tags:["Azure Container Apps","Bicep","GitHub Actions","devcontainer"],image:"./title-image.png",description:"Build and deploy two Azure Container Apps using Bicep and GitHub Actions, communicate using dapr, build, run and debug in VS Code using a devcontainer.",hide_table_of_contents:!1},prevItem:{title:"Migrating from GitHub Pages to Azure Static Web Apps",permalink:"/migrating-from-github-pages-to-azure-static-web-apps"},nextItem:{title:"Preload fonts with Docusaurus (updated 03/11/2022)",permalink:"/preload-fonts-with-docusaurus"}},p={image:n(565).Z,authorsImageUrls:[void 0]},u=[{value:"Updated 02/05/2022",id:"updated-02052022",level:2},{value:"What we&#39;re going to build",id:"what-were-going-to-build",level:2},{value:"Setting up our devcontainer",id:"setting-up-our-devcontainer",level:2},{value:"Create a dotnet service",id:"create-a-dotnet-service",level:2},{value:"Create a Node.js service (with Koa)",id:"create-a-nodejs-service-with-koa",level:2},{value:"Debugging dapr in VS Code",id:"debugging-dapr-in-vs-code",level:2},{value:"Containerising our services with Docker",id:"containerising-our-services-with-docker",level:2},{value:"Deploying to Azure",id:"deploying-to-azure",level:2},{value:"Setting up a resource group",id:"setting-up-a-resource-group",level:2},{value:"Secrets for GitHub Actions",id:"secrets-for-github-actions",level:2},{value:"<code>AZURE_CREDENTIALS</code> - GitHub logging into Azure",id:"azure_credentials---github-logging-into-azure",level:3},{value:"<code>PACKAGES_TOKEN</code> - Azure accessing the GitHub container registry",id:"packages_token---azure-accessing-the-github-container-registry",level:3},{value:"Deploying with GitHub Actions",id:"deploying-with-github-actions",level:2},{value:"<code>build</code> - building our image",id:"build---building-our-image",level:3},{value:"<code>deploy</code> - shipping our image to Azure",id:"deploy---shipping-our-image-to-azure",level:3},{value:"Running it",id:"running-it",level:2},{value:"<code>The subscription &#39;***&#39; cannot have more than 2 environments.</code>",id:"the-subscription--cannot-have-more-than-2-environments",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This post shows how to build and deploy two Azure Container Apps using Bicep and GitHub Actions. These apps will communicate using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.dapr.io/"}),"dapr"),", be built in ",(0,a.kt)("a",o({parentName:"p"},{href:"https://code.visualstudio.com/docs/remote/containers"}),"VS Code using a devcontainer"),". It will be possible to debug in VS Code and run with ",(0,a.kt)("inlineCode",{parentName:"p"},"docker-compose"),"."),(0,a.kt)("p",null,"This follows on from the ",(0,a.kt)("a",o({parentName:"p"},{href:"/azure-container-apps-build-and-deploy-with-bicep-and-github-actions"}),"previous post")," which built and deployed a simple web application to Azure Container Apps using Bicep and GitHub Actions using the GitHub container registry."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Azure Container Apps dapr, devcontainer, debug and deploy&quot;  with the dapr, Bicep, Azure Container Apps and GitHub Actions logos",src:n(565).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"updated-02052022"}),"Updated 02/05/2022"),(0,a.kt)("p",null,"This post has been updated to reflect the migration of Azure Container Apps from the Microsoft.Web namespace to the Microsoft.App namespace in March 2022. See: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/azure-container-apps/issues/109"}),"https://github.com/microsoft/azure-container-apps/issues/109")),(0,a.kt)("h2",o({},{id:"what-were-going-to-build"}),"What we're going to build"),(0,a.kt)("p",null,"As an engineer, I'm productive when:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Integrating different services together is a turnkey experience and"),(0,a.kt)("li",{parentName:"ul"},"I'm able to easily debug my code")),(0,a.kt)("p",null,"I've found that using dapr and VS Code I'm able to achieve both of these goals. I can build an application made up of multiple services, compose them together using dapr and deploy them to Azure Container Apps with relative ease."),(0,a.kt)("p",null,"In this post we're going to build an example of that from scratch, with a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://koajs.com/"}),"koa/node.js")," (built with TypeScript) front end that will communicate with a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://dotnet.microsoft.com/en-us/"}),"dotnet")," service via dapr."),(0,a.kt)("p",null,"All the work done in this post can be found in the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/dapr-devcontainer-debug-and-deploy/tree/v1.0.0"}),(0,a.kt)("inlineCode",{parentName:"a"},"dapr-devcontainer-debug-and-deploy"))," repo. As a note, if you're interested in this topic it's also worth looking at the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure-Samples/container-apps-store-api-microservice"}),(0,a.kt)("inlineCode",{parentName:"a"},"Azure-Samples/container-apps-store-api-microservice"))," repo."),(0,a.kt)("h2",o({},{id:"setting-up-our-devcontainer"}),"Setting up our devcontainer"),(0,a.kt)("p",null,"The first thing we'll do is set up our devcontainer. We're going to use a tweaked version of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/vscode-dev-containers/tree/main/containers/docker-in-docker"}),"docker-in-docker")," image from the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/vscode-dev-containers"}),"vscode-dev-containers")," repo."),(0,a.kt)("p",null,"In the root of our project we'll create a ",(0,a.kt)("inlineCode",{parentName:"p"},".devcontainer")," folder, and within that a ",(0,a.kt)("inlineCode",{parentName:"p"},"library-scripts")," folder. There's a number of communal scripts from the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/vscode-dev-containers"}),(0,a.kt)("inlineCode",{parentName:"a"},"vscode-dev-containers"))," repo which we're going to lift and shift into in our ",(0,a.kt)("inlineCode",{parentName:"p"},"library-scripts")," folder:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/microsoft/vscode-dev-containers/blob/d93de4632781372d4b4da1699e27ae3a2404c96c/script-library/docker-in-docker-debian.sh"}),"docker-in-docker-debian.sh")," - for installing Docker in Docker"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/microsoft/vscode-dev-containers/blob/d93de4632781372d4b4da1699e27ae3a2404c96c/script-library/azcli-debian.sh"}),"azcli-debian.sh")," - for installing the Azure CLI")),(0,a.kt)("p",null,"In the ",(0,a.kt)("inlineCode",{parentName:"p"},".devcontainer")," folder we want to create a ",(0,a.kt)("inlineCode",{parentName:"p"},"Dockerfile"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-docker"}),'# [Choice] .NET version: 6.0, 5.0, 3.1, 2.1\nARG VARIANT=3.1\nFROM mcr.microsoft.com/vscode/devcontainers/dotnet:0-${VARIANT}\nRUN su vscode -c "umask 0002 && dotnet tool install -g Microsoft.Tye --version \\"0.10.0-alpha.21420.1\\" 2>&1"\n\n# [Choice] Node.js version: none, lts/*, 16, 14, 12, 10\nARG NODE_VERSION="14"\nRUN if [ "${NODE_VERSION}" != "none" ]; then su vscode -c "umask 0002 && . /usr/local/share/nvm/nvm.sh && nvm install ${NODE_VERSION} 2>&1"; fi\n\n# [Option] Install Azure CLI\nARG INSTALL_AZURE_CLI="false"\nCOPY library-scripts/azcli-debian.sh /tmp/library-scripts/\nRUN if [ "$INSTALL_AZURE_CLI" = "true" ]; then bash /tmp/library-scripts/azcli-debian.sh; fi \\\n    && apt-get clean -y && rm -rf /var/lib/apt/lists/* /tmp/library-scripts \\\n    && az bicep install\n\n# [Option] Enable non-root Docker access in container\nARG ENABLE_NONROOT_DOCKER="true"\n# [Option] Use the OSS Moby CLI instead of the licensed Docker CLI\nARG USE_MOBY="true"\n# [Option] Engine/CLI Version\nARG DOCKER_VERSION="latest"\n\n# Enable new "BUILDKIT" mode for Docker CLI\nENV DOCKER_BUILDKIT=1\n\nARG USERNAME=vscode\n\n# Install needed packages and setup non-root user. Use a separate RUN statement to add your\n# own dependencies. A user of "automatic" attempts to reuse an user ID if one already exists.\nCOPY library-scripts/docker-in-docker-debian.sh /tmp/library-scripts/\nRUN apt-get update \\\n    && apt-get install python3-pip -y \\\n# Use Docker script from script library to set things up\n    && /bin/bash /tmp/library-scripts/docker-in-docker-debian.sh "${ENABLE_NONROOT_DOCKER}" "${USERNAME}" "${USE_MOBY}" "${DOCKER_VERSION}"\n\n# Install Dapr\nRUN wget -q https://raw.githubusercontent.com/dapr/cli/master/install/install.sh -O - | /bin/bash \\\n    # Clean up\n    && apt-get autoremove -y && apt-get clean -y && rm -rf /var/lib/apt/lists/* /tmp/library-scripts/\n\n# Add daprd to the path for the VS Code Dapr extension.\nENV PATH="${PATH}:/home/${USERNAME}/.dapr/bin"\n\n# Install Tye\nENV PATH=/home/${USERNAME}/.dotnet/tools:$PATH\n\nVOLUME [ "/var/lib/docker" ]\n\n# Setting the ENTRYPOINT to docker-init.sh will configure non-root access\n# to the Docker socket. The script will also execute CMD as needed.\nENTRYPOINT [ "/usr/local/share/docker-init.sh" ]\nCMD [ "sleep", "infinity" ]\n\n# [Optional] Uncomment this section to install additional OS packages.\n# RUN apt-get update && export DEBIAN_FRONTEND=noninteractive \\\n#     && apt-get -y install --no-install-recommends <your-package-list-here>\n')),(0,a.kt)("p",null,"The above is a loose riff on the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/vscode-dev-containers/blob/main/containers/docker-in-docker/.devcontainer/Dockerfile"}),"docker-in-docker Dockerfile"),", lovingly mixed with the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure-Samples/container-apps-store-api-microservice/blob/main/.devcontainer/Dockerfile"}),"Azure-Samples container-apps Dockerfile"),"."),(0,a.kt)("p",null,"It installs the following:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Dot Net"),(0,a.kt)("li",{parentName:"ul"},"Node.js"),(0,a.kt)("li",{parentName:"ul"},"the Azure CLI"),(0,a.kt)("li",{parentName:"ul"},"Docker"),(0,a.kt)("li",{parentName:"ul"},"Bicep"),(0,a.kt)("li",{parentName:"ul"},"Dapr")),(0,a.kt)("p",null,"Now we have our ",(0,a.kt)("inlineCode",{parentName:"p"},"Dockerfile"),", we need a ",(0,a.kt)("inlineCode",{parentName:"p"},"devcontainer.json")," to go with it:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'// For format details, see https://aka.ms/devcontainer.json. For config options, see the README at:\n// https://github.com/microsoft/vscode-dev-containers/tree/v0.205.0/containers/dapr-dotnet\n{\n  "name": "dapr",\n  "build": {\n    "dockerfile": "Dockerfile",\n    "args": {\n      // Update \'VARIANT\' to pick a .NET Core version: 3.1, 5.0, 6.0\n      "VARIANT": "6.0",\n      // Options\n      "NODE_VERSION": "lts/*",\n      "INSTALL_AZURE_CLI": "true"\n    }\n  },\n  "runArgs": ["--init", "--privileged"],\n  "mounts": ["source=dind-var-lib-docker,target=/var/lib/docker,type=volume"],\n  "overrideCommand": false,\n\n  // Use this environment variable if you need to bind mount your local source code into a new container.\n  "remoteEnv": {\n    "LOCAL_WORKSPACE_FOLDER": "${localWorkspaceFolder}",\n    "PATH": "/home/vscode/.dapr/bin/:/home/vscode/.dotnet/tools:$PATH${containerEnv:PATH}"\n  },\n\n  // Set *default* container specific settings.json values on container create.\n  "settings": {},\n\n  // Add the IDs of extensions you want installed when the container is created.\n  "extensions": [\n    "ms-azuretools.vscode-dapr",\n    "ms-azuretools.vscode-docker",\n    "ms-dotnettools.csharp",\n    "ms-vscode.azurecli",\n    "ms-azuretools.vscode-bicep"\n  ],\n\n  // Use \'forwardPorts\' to make a list of ports inside the container available locally.\n  // "forwardPorts": [],\n\n  // Ensure Dapr is running on opening the container\n  "postCreateCommand": "dapr uninstall --all && dapr init",\n\n  // Comment out connect as root instead. More info: https://aka.ms/vscode-remote/containers/non-root.\n  "remoteUser": "vscode",\n  "features": {\n    "azure-cli": "latest"\n  }\n}\n')),(0,a.kt)("p",null,"The above will:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"install Node 16 / dotnet 6 and the latest Azure CLI"),(0,a.kt)("li",{parentName:"ul"},"install a number of VS Code extensions related to dapr / Docker / Bicep / Azure / C#"),(0,a.kt)("li",{parentName:"ul"},"install dapr when the container starts")),(0,a.kt)("p",null,"We're ready! Reopen your repo in a container (it will take a while first time out) and you'll be ready to go."),(0,a.kt)("h2",o({},{id:"create-a-dotnet-service"}),"Create a dotnet service"),(0,a.kt)("p",null,"Now we're going to create a dotnet service. The aim of this post is not to build a specific application, but rather to demonstrate how simple service to service communication is with dapr. So we'll use the web api template that ships with dotnet 6. That arrives with a fake weather API included, so we'll name our service accordingly:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"dotnet new webapi -o WeatherService\n")),(0,a.kt)("p",null,"Inside the created ",(0,a.kt)("inlineCode",{parentName:"p"},"Program.cs"),", find the following line and delete it:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"app.UseHttpsRedirection();\n")),(0,a.kt)("p",null,"HTTPS is important, however Azure Container Apps are going to tackle that for us."),(0,a.kt)("h2",o({},{id:"create-a-nodejs-service-with-koa"}),"Create a Node.js service (with Koa)"),(0,a.kt)("p",null,"Creating our dotnet service was very simple. We're now going to create a web app with Node.js and Koa that calls our dotnet service. This will be a little more complicated - but still surprisingly simple thanks to the great API choices of dapr."),(0,a.kt)("p",null,"Let's make that service:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"mkdir WebService\ncd WebService\nnpm init -y\nnpm install koa axios --save\nnpm install @types/koa @types/node @types/axios typescript --save-dev\n")),(0,a.kt)("p",null,"We're installing the following:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://koajs.com/"}),"koa")," - the web framework we're going to use"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://axios-http.com/"}),"axios")," - to make calls to our dotnet service via HTTP / dapr"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://www.typescriptlang.org/"}),"TypeScript")," and associated type definitions, so we can take advantage of static typing. Admittedly since we're building a minimal example this is not super beneficial; but TS makes me happy and I'd certainly want static typing in place if going beyond a simple example. Start as you mean to go on.")),(0,a.kt)("p",null,"We'll create a ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "compilerOptions": {\n    "esModuleInterop": true,\n    "module": "commonjs",\n    "target": "es2017",\n    "noImplicitAny": true,\n    "outDir": "./dist",\n    "strict": true,\n    "sourceMap": true\n  }\n}\n')),(0,a.kt)("p",null,"We'll update the ",(0,a.kt)("inlineCode",{parentName:"p"},"scripts")," section of our ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'  "scripts": {\n    "build": "tsc",\n    "start": "node dist/index.js"\n  },\n')),(0,a.kt)("p",null,"So we can build and start our web app. Now let's write it!"),(0,a.kt)("p",null,"We're going to create an ",(0,a.kt)("inlineCode",{parentName:"p"},"index.ts")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import Koa from 'koa';\nimport axios from 'axios';\n\n// How we connect to the dotnet service with dapr\nconst daprSidecarBaseUrl = `http://localhost:${\n  process.env.DAPR_HTTP_PORT || 3501\n}`;\n// app id header for service discovery\nconst weatherServiceAppIdHeaders = {\n  'dapr-app-id': process.env.WEATHER_SERVICE_NAME || 'dotnet-app',\n};\n\nconst app = new Koa();\n\napp.use(async (ctx) => {\n  try {\n    const data = await axios.get<WeatherForecast[]>(\n      `${daprSidecarBaseUrl}/weatherForecast`,\n      {\n        headers: weatherServiceAppIdHeaders,\n      }\n    );\n\n    ctx.body = `And the weather today will be ${data.data[0].summary}`;\n  } catch (exc) {\n    console.error('Problem calling weather service', exc);\n    ctx.body = 'Something went wrong!';\n  }\n});\n\nconst portNumber = 3000;\napp.listen(portNumber);\nconsole.log(`listening on port ${portNumber}`);\n\ninterface WeatherForecast {\n  date: string;\n  temperatureC: number;\n  temperatureF: number;\n  summary: string;\n}\n")),(0,a.kt)("p",null,"The above code is fairly simple but is achieving quite a lot. It:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"uses various environment variables to construct the URLs / headers which allow connecting to the dapr sidecar running alongside the app, and consequently to the weather service through the dapr sidecar running alongside the weather service. We're going to set up the environment variables which this code relies upon later."),(0,a.kt)("li",{parentName:"ul"},"spins up a web server with koa on port 3000"),(0,a.kt)("li",{parentName:"ul"},"that web server, when sent an HTTP request, will call the ",(0,a.kt)("inlineCode",{parentName:"li"},"weatherForecast")," endpoint of the dotnet app. It will grab what comes back, take the first entry in there and surface that up as the weather forecast."),(0,a.kt)("li",{parentName:"ul"},"We're also defining a ",(0,a.kt)("inlineCode",{parentName:"li"},"WeatherForecast")," interface to represent the type of the data that comes back from the dotnet service")),(0,a.kt)("p",null,"It's worth dwelling for a moment on the simplicity that dapr is affording us here. We're able to make HTTP requests to our dotnet service just like they were any other service running locally. What's actually happening is illustrated by the diagram below:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"a diagram showing traffic going from the web service to the weather service and back again via dapr",src:n(4187).Z,width:"672",height:"403"})),(0,a.kt)("p",null,"We're making HTTP requests from the web service, which look like they're going directly to the weather service. But in actual fact, they're being routed through dapr sidecars until they reach their destination. Why is this fantastic? Well there's two things we aren't having to think about here:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"certificates"),(0,a.kt)("li",{parentName:"ul"},"inter-service authentication")),(0,a.kt)("p",null,"Both of these can be complex and burn a large amount of engineering time. Because we're using dapr it's not a problem we have to solve. Isn't that great?"),(0,a.kt)("h2",o({},{id:"debugging-dapr-in-vs-code"}),"Debugging dapr in VS Code"),(0,a.kt)("p",null,"We want to be able to debug this code. We can achieve that in VS Code by setting a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://code.visualstudio.com/docs/editor/debugging#_launchjson-attributes"}),(0,a.kt)("inlineCode",{parentName:"a"},"launch.json"))," and a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://code.visualstudio.com/docs/editor/tasks"}),(0,a.kt)("inlineCode",{parentName:"a"},"tasks.json"))," file."),(0,a.kt)("p",null,"First of all we'll create a ",(0,a.kt)("inlineCode",{parentName:"p"},"launch.json")," file in the ",(0,a.kt)("inlineCode",{parentName:"p"},".vscode")," folder of our repo:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  // Use IntelliSense to learn about possible attributes.\n  // Hover to view descriptions of existing attributes.\n  // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387\n  "version": "0.2.0",\n  "compounds": [\n    {\n      "name": "All Container Apps",\n      "configurations": ["WeatherService", "WebService"],\n      "presentation": {\n        "hidden": false,\n        "group": "Containers",\n        "order": 1\n      }\n    }\n  ],\n  "configurations": [\n    {\n      "name": "WeatherService",\n      "type": "coreclr",\n      "request": "launch",\n      "preLaunchTask": "daprd-debug-dotnet",\n      "postDebugTask": "daprd-down-dotnet",\n      "program": "${workspaceFolder}/WeatherService/bin/Debug/net6.0/WeatherService.dll",\n      "args": [],\n      "cwd": "${workspaceFolder}/WeatherService",\n      "stopAtEntry": false,\n      "env": {\n        "DOTNET_ENVIRONMENT": "Development",\n        "DOTNET_URLS": "http://localhost:5000",\n        "DAPR_HTTP_PORT": "3500",\n        "DAPR_GRPC_PORT": "50000",\n        "DAPR_METRICS_PORT": "9090"\n      }\n    },\n\n    {\n      "name": "WebService",\n      "type": "node",\n      "request": "launch",\n      "preLaunchTask": "daprd-debug-node",\n      "postDebugTask": "daprd-down-node",\n      "program": "${workspaceFolder}/WebService/index.ts",\n      "cwd": "${workspaceFolder}/WebService",\n      "env": {\n        "NODE_ENV": "development",\n        "PORT": "3000",\n        "DAPR_HTTP_PORT": "3501",\n        "DAPR_GRPC_PORT": "50001",\n        "DAPR_METRICS_PORT": "9091",\n        "WEATHER_SERVICE_NAME": "dotnet-app"\n      },\n      "protocol": "inspector",\n      "outFiles": ["${workspaceFolder}/WebService/dist/**/*.js"],\n      "serverReadyAction": {\n        "action": "openExternally"\n      }\n    }\n  ]\n}\n')),(0,a.kt)("p",null,"The things to note about this are:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},'we create a Node.js ("WebService") and a dotnet ("WeatherService") configuration. These are referenced by the ',(0,a.kt)("inlineCode",{parentName:"li"},"All Container Apps")," compound. Kicking off that will start both the Node.js and the dotnet apps."),(0,a.kt)("li",{parentName:"ul"},"The Node.js app runs a ",(0,a.kt)("inlineCode",{parentName:"li"},"daprd-debug-node")," task prior to launch and a ",(0,a.kt)("inlineCode",{parentName:"li"},"daprd-down-node")," task when debugging completes. Comparable tasks are run by the dotnet container - we'll look at these in a moment."),(0,a.kt)("li",{parentName:"ul"},"Various environment variables are configured, most of which control the behaviour of dapr. When we're debugging locally we'll be using some non-typical ports to accomodate multiple dapr sidecars being in play at the same time. Note also the ",(0,a.kt)("inlineCode",{parentName:"li"},'"WEATHER_SERVICE_NAME": "dotnet-app"')," - it's this that allows the WebService to communicate with the WeatherService - ",(0,a.kt)("inlineCode",{parentName:"li"},"dotnet-app")," is the ",(0,a.kt)("inlineCode",{parentName:"li"},"appId")," used to identify a service with dapr. We'll see that as we configure our ",(0,a.kt)("inlineCode",{parentName:"li"},"tasks.json"),".")),(0,a.kt)("p",null,"Here's the ",(0,a.kt)("inlineCode",{parentName:"p"},"tasks.json")," we must make:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  // See https://go.microsoft.com/fwlink/?LinkId=733558\n  // for the documentation about the tasks.json format\n  "version": "2.0.0",\n  "tasks": [\n    {\n      "label": "dotnet-build",\n      "command": "dotnet",\n      "type": "process",\n      "args": [\n        "build",\n        "${workspaceFolder}/WeatherService/WeatherService.csproj",\n        "/property:GenerateFullPaths=true",\n        "/consoleloggerparameters:NoSummary"\n      ],\n      "problemMatcher": "$msCompile"\n    },\n    {\n      "label": "daprd-debug-dotnet",\n      "appId": "dotnet-app",\n      "appPort": 5000,\n      "httpPort": 3500,\n      "grpcPort": 50000,\n      "metricsPort": 9090,\n      "type": "daprd",\n      "dependsOn": ["dotnet-build"]\n    },\n    {\n      "label": "daprd-down-dotnet",\n      "appId": "dotnet-app",\n      "type": "daprd-down"\n    },\n\n    {\n      "label": "npm-install",\n      "type": "shell",\n      "command": "npm install",\n      "options": {\n        "cwd": "${workspaceFolder}/WebService"\n      }\n    },\n    {\n      "label": "webservice-build",\n      "type": "typescript",\n      "tsconfig": "WebService/tsconfig.json",\n      "problemMatcher": ["$tsc"],\n      "group": {\n        "kind": "build",\n        "isDefault": true\n      },\n      "dependsOn": ["npm-install"]\n    },\n    {\n      "label": "daprd-debug-node",\n      "appId": "node-app",\n      "appPort": 3000,\n      "httpPort": 3501,\n      "grpcPort": 50001,\n      "metricsPort": 9091,\n      "type": "daprd",\n      "dependsOn": ["webservice-build"]\n    },\n    {\n      "label": "daprd-down-node",\n      "appId": "node-app",\n      "type": "daprd-down"\n    }\n  ]\n}\n')),(0,a.kt)("p",null,"There's two sets of tasks here; one for the WeatherService and one for the WebService. You'll see some commonalities here. For each service there's a ",(0,a.kt)("inlineCode",{parentName:"p"},"daprd")," task that depends upon the relevant service being built and passes the various ports for the dapr sidecar to run on that runs just before debugging kicks off. To go with that, there's a ",(0,a.kt)("inlineCode",{parentName:"p"},"daprd-down")," task for each service that runs when debugging finishes and shuts down dapr."),(0,a.kt)("p",null,"We're now ready to debug our app. Let's hit F5."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of debugging the index.ts file in VS Code",src:n(35541).Z,width:"2680",height:"1080"})),(0,a.kt)("p",null,"And if we look at our browser:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of browsing Firefox at http://localhost:3000 and seeing &quot;And the weather today will be Freezing&quot; in the output",src:n(50702).Z,width:"764",height:"160"})),(0,a.kt)("p",null,"It works! We're running a Node.js WebService which, when called, is communicating with our dotnet WeatherService and surfacing up the results. Brilliant!"),(0,a.kt)("h2",o({},{id:"containerising-our-services-with-docker"}),"Containerising our services with Docker"),(0,a.kt)("p",null,"Before we can deploy each of our services, they need to be containerised."),(0,a.kt)("p",null,"First let's add a ",(0,a.kt)("inlineCode",{parentName:"p"},"Dockerfile")," to the ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherService")," folder:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-docker"}),'FROM mcr.microsoft.com/dotnet/sdk:6.0 as build\nWORKDIR /app\nCOPY . .\nRUN dotnet restore\nRUN dotnet publish -o /app/publish\n\nFROM mcr.microsoft.com/dotnet/aspnet:6.0 as runtime\nWORKDIR /app\nCOPY --from=build /app/publish /app\n\nENV DOTNET_ENVIRONMENT=Production\nENV ASPNETCORE_URLS=\'http://+:5000\'\nEXPOSE 5000\nENTRYPOINT [ "dotnet", "/app/WeatherService.dll" ]\n')),(0,a.kt)("p",null,"Then we'll add a ",(0,a.kt)("inlineCode",{parentName:"p"},"Dockerfile")," to the ",(0,a.kt)("inlineCode",{parentName:"p"},"WebService")," folder:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-docker"}),'FROM node:16 AS build\nWORKDIR /app\nCOPY package.json ./\nCOPY package-lock.json ./\nRUN npm install\n\nCOPY . .\nRUN npm run build\n\nFROM node:16 AS runtime\nWORKDIR /app\nCOPY --from=build /app/dist /app\nCOPY --from=build /app/package.json /app\nCOPY --from=build /app/package-lock.json /app\nRUN npm install\n\nENV NODE_ENV production\nEXPOSE 3000\nENTRYPOINT [ "node", "/app/index.js" ]\n')),(0,a.kt)("p",null,"Likely these ",(0,a.kt)("inlineCode",{parentName:"p"},"Dockerfile"),"s could be optimised further; but we're not focussed on that just now. What we have now are two simple ",(0,a.kt)("inlineCode",{parentName:"p"},"Dockerfile"),"s that will give us images we can run. Given that one depends on the other it makes sense to bring them together with a ",(0,a.kt)("inlineCode",{parentName:"p"},"docker-compose.yml")," file which we'll place in the root of the repo:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"version: '3.4'\n\nservices:\n  weatherservice:\n    image: ${REGISTRY:-weatherservice}:${TAG:-latest}\n    build:\n      context: ./WeatherService\n      dockerfile: Dockerfile\n    ports:\n      - '50000:50000' # Dapr instances communicate over gRPC so we need to expose the gRPC port\n    environment:\n      DOTNET_ENVIRONMENT: 'Development'\n      ASPNETCORE_URLS: 'http://+:5000'\n      DAPR_HTTP_PORT: 3500\n      DAPR_GRPC_PORT: 50000\n      DAPR_METRICS_PORT: 9090\n\n  weatherservice-dapr:\n    image: 'daprio/daprd:latest'\n    command:\n      [\n        './daprd',\n        '-app-id',\n        'dotnet-app',\n        '-app-port',\n        '5000',\n        '-dapr-http-port',\n        '3500',\n        '-placement-host-address',\n        'placement:50006',\n      ]\n    network_mode: 'service:weatherservice'\n    depends_on:\n      - weatherservice\n\n  webservice:\n    image: ${REGISTRY:-webservice}:${TAG:-latest}\n    ports:\n      - '3000:3000' # The web front end port\n      - '50001:50001' # Dapr instances communicate over gRPC so we need to expose the gRPC port\n    build:\n      context: ./WebService\n      dockerfile: Dockerfile\n    environment:\n      NODE_ENV: 'development'\n      PORT: '3000'\n      DAPR_HTTP_PORT: 3501\n      DAPR_GRPC_PORT: 50001\n      DAPR_METRICS_PORT: 9091\n      WEATHER_SERVICE_NAME: 'dotnet-app'\n\n  webservice-dapr:\n    image: 'daprio/daprd:latest'\n    command: [\n        './daprd',\n        '-app-id',\n        'node-app',\n        '-app-port',\n        '3000',\n        '-dapr-http-port',\n        '3501',\n        '-placement-host-address',\n        'placement:50006', # Dapr's placement service can be reach via the docker DNS entry\n      ]\n    network_mode: 'service:webservice'\n    depends_on:\n      - webservice\n\n  dapr-placement:\n    image: 'daprio/dapr:latest'\n    command: ['./placement', '-port', '50006']\n    ports:\n      - '50006:50006'\n")),(0,a.kt)("p",null,"With this in place we can run ",(0,a.kt)("inlineCode",{parentName:"p"},"docker-compose up")," and bring up our application locally."),(0,a.kt)("p",null,"And now we have docker images built, we can look at deploying them."),(0,a.kt)("h2",o({},{id:"deploying-to-azure"}),"Deploying to Azure"),(0,a.kt)("p",null,"At this point we have pretty much everything we need in terms of application code and the ability to build and debug it. Now we'd like to deploy it to Azure."),(0,a.kt)("p",null,"Let's begin with the Bicep required to deploy our Azure Container Apps."),(0,a.kt)("p",null,"In our repository we'll create an ",(0,a.kt)("inlineCode",{parentName:"p"},"infra")," directory, into which we'll place a ",(0,a.kt)("inlineCode",{parentName:"p"},"main.bicep")," file which will contain our Bicep template:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param branchName string\n\nparam webServiceImage string\nparam webServicePort int\nparam webServiceIsExternalIngress bool\n\nparam weatherServiceImage string\nparam weatherServicePort int\nparam weatherServiceIsExternalIngress bool\n\nparam containerRegistry string\nparam containerRegistryUsername string\n@secure()\nparam containerRegistryPassword string\n\nparam tags object\n\nparam location string = resourceGroup().location\n\nvar minReplicas = 0\nvar maxReplicas = 1\n\nvar branch = toLower(last(split(branchName, '/')))\n\nvar environmentName = 'shared-env'\nvar workspaceName = '${branch}-log-analytics'\nvar appInsightsName = '${branch}-app-insights'\nvar webServiceContainerAppName = '${branch}-web'\nvar weatherServiceContainerAppName = '${branch}-weather'\n\nvar containerRegistryPasswordRef = 'container-registry-password'\n\nresource workspace 'Microsoft.OperationalInsights/workspaces@2021-12-01-preview' = {\n  name: workspaceName\n  location: location\n  tags: tags\n  properties: {\n    sku: {\n      name: 'PerGB2018'\n    }\n    retentionInDays: 30\n    workspaceCapping: {}\n  }\n}\n\nresource appInsights 'Microsoft.Insights/components@2020-02-02' = {\n  name: appInsightsName\n  location: location\n  tags: tags\n  kind: 'web'\n  properties: {\n    Application_Type: 'web'\n    Flow_Type: 'Bluefield'\n  }\n}\n\nresource environment 'Microsoft.App/managedEnvironments@2022-01-01-preview' = {\n  name: environmentName\n  location: location\n  tags: tags\n  properties: {\n    daprAIInstrumentationKey: appInsights.properties.InstrumentationKey\n    appLogsConfiguration: {\n      destination: 'log-analytics'\n      logAnalyticsConfiguration: {\n        customerId: workspace.properties.customerId\n        sharedKey: listKeys(workspace.id, workspace.apiVersion).primarySharedKey\n      }\n    }\n  }\n}\n\nresource weatherServiceContainerApp 'Microsoft.App/containerApps@2022-01-01-preview' = {\n  name: weatherServiceContainerAppName\n  kind: 'containerapps'\n  tags: tags\n  location: location\n  properties: {\n    managedEnvironmentId: environment.id\n    configuration: {\n      dapr: {\n        enabled: true\n        appPort: weatherServicePort\n        appId: weatherServiceContainerAppName\n      }\n      secrets: [\n        {\n          name: containerRegistryPasswordRef\n          value: containerRegistryPassword\n        }\n      ]\n      registries: [\n        {\n          server: containerRegistry\n          username: containerRegistryUsername\n          passwordSecretRef: containerRegistryPasswordRef\n        }\n      ]\n      ingress: {\n        external: weatherServiceIsExternalIngress\n        targetPort: weatherServicePort\n      }\n    }\n    template: {\n      containers: [\n        {\n          image: weatherServiceImage\n          name: weatherServiceContainerAppName\n          transport: 'auto'\n        }\n      ]\n      scale: {\n        minReplicas: minReplicas\n        maxReplicas: maxReplicas\n      }\n    }\n  }\n}\n\nresource webServiceContainerApp 'Microsoft.App/containerApps@2022-01-01-preview' = {\n  name: webServiceContainerAppName\n  kind: 'containerapps'\n  tags: tags\n  location: location\n  properties: {\n    managedEnvironmentId: environment.id\n    configuration: {\n      dapr: {\n        enabled: true\n        appPort: webServicePort\n        appId: webServiceContainerAppName\n      }\n      secrets: [\n        {\n          name: containerRegistryPasswordRef\n          value: containerRegistryPassword\n        }\n      ]\n      registries: [\n        {\n          server: containerRegistry\n          username: containerRegistryUsername\n          passwordSecretRef: containerRegistryPasswordRef\n        }\n      ]\n      ingress: {\n        external: webServiceIsExternalIngress\n        targetPort: webServicePort\n      }\n    }\n    template: {\n      containers: [\n        {\n          image: webServiceImage\n          name: webServiceContainerAppName\n          transport: 'auto'\n          env: [\n            {\n              name: 'WEATHER_SERVICE_NAME'\n              value: weatherServiceContainerAppName\n            }\n          ]\n        }\n      ]\n      scale: {\n        minReplicas: minReplicas\n        maxReplicas: maxReplicas\n      }\n    }\n  }\n}\n\noutput webServiceUrl string = webServiceContainerApp.properties.latestRevisionFqdn\n")),(0,a.kt)("p",null,"This will deploy two container apps - one for our ",(0,a.kt)("inlineCode",{parentName:"p"},"WebService")," and one for our ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherService"),". Alongside that we've resources for logging and environments."),(0,a.kt)("h2",o({},{id:"setting-up-a-resource-group"}),"Setting up a resource group"),(0,a.kt)("p",null,"With our Bicep in place, we're going to need a resource group to send it to. Right now, Azure Container Apps aren't available everywhere. So we're going to create ourselves a resource group in North Europe which does support ACAs:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"az group create -g rg-aca -l northeurope\n")),(0,a.kt)("h2",o({},{id:"secrets-for-github-actions"}),"Secrets for GitHub Actions"),(0,a.kt)("p",null,"We're aiming to set up a GitHub Action to handle our deployment. This will depend upon a number of secrets:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the secrets in the GitHub website that we need to create",src:n(7175).Z,width:"1544",height:"250"})),(0,a.kt)("p",null,"We'll need to create each of these secrets."),(0,a.kt)("h3",o({},{id:"azure_credentials---github-logging-into-azure"}),(0,a.kt)("inlineCode",{parentName:"h3"},"AZURE_CREDENTIALS")," - GitHub logging into Azure"),(0,a.kt)("p",null,"So GitHub Actions can interact with Azure on our behalf, we need to provide it with some credentials. We'll use the Azure CLI to create these:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),'az ad sp create-for-rbac --name "myApp" --role contributor \\\n    --scopes /subscriptions/{subscription-id}/resourceGroups/{resource-group} \\\n    --sdk-auth\n')),(0,a.kt)("p",null,"Remember to replace the ",(0,a.kt)("inlineCode",{parentName:"p"},"{subscription-id}")," with your subscription id and ",(0,a.kt)("inlineCode",{parentName:"p"},"{resource-group}")," with the name of your resource group (",(0,a.kt)("inlineCode",{parentName:"p"},"rg-aca")," if you're following along). This command will pump out a lump of JSON that looks something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "clientId": "a-client-id",\n  "clientSecret": "a-client-secret",\n  "subscriptionId": "a-subscription-id",\n  "tenantId": "a-tenant-id",\n  "activeDirectoryEndpointUrl": "https://login.microsoftonline.com",\n  "resourceManagerEndpointUrl": "https://management.azure.com/",\n  "activeDirectoryGraphResourceId": "https://graph.windows.net/",\n  "sqlManagementEndpointUrl": "https://management.core.windows.net:8443/",\n  "galleryEndpointUrl": "https://gallery.azure.com/",\n  "managementEndpointUrl": "https://management.core.windows.net/"\n}\n')),(0,a.kt)("p",null,"Take this and save it as the ",(0,a.kt)("inlineCode",{parentName:"p"},"AZURE_CREDENTIALS")," secret in Azure."),(0,a.kt)("h3",o({},{id:"packages_token---azure-accessing-the-github-container-registry"}),(0,a.kt)("inlineCode",{parentName:"h3"},"PACKAGES_TOKEN")," - Azure accessing the GitHub container registry"),(0,a.kt)("p",null,"We also need a secret for accessing packages from Azure. We're going to be publishing packages to the GitHub container registry. Azure is going to need to be able to access this when we're deploying. ACA deployment works by telling Azure where to look for an image and providing any necessary credentials to do the acquisition. To facilitate this we'll set up a ",(0,a.kt)("inlineCode",{parentName:"p"},"PACKAGES_TOKEN")," secret. This is a GitHub personal access token with the ",(0,a.kt)("inlineCode",{parentName:"p"},"read:packages")," scope. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token"}),"Follow the instructions here to create the token.")),(0,a.kt)("h2",o({},{id:"deploying-with-github-actions"}),"Deploying with GitHub Actions"),(0,a.kt)("p",null,"With our secrets configured, we're now well placed to write our GitHub Action. We'll create a ",(0,a.kt)("inlineCode",{parentName:"p"},".github/workflows/build-and-deploy.yaml")," file in our repository and populate it thusly:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),"# yaml-language-server: $schema=./build.yaml\nname: Build and Deploy\non:\n  # Trigger the workflow on push or pull request,\n  # but only for the main branch\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n    # Publish semver tags as releases.\n    tags: ['v*.*.*']\n  workflow_dispatch:\n\nenv:\n  RESOURCE_GROUP: rg-aca\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        services:\n          [\n            { 'imageName': 'node-service', 'directory': './WebService' },\n            { 'imageName': 'dotnet-service', 'directory': './WeatherService' },\n          ]\n    permissions:\n      contents: read\n      packages: write\n    outputs:\n      image-node: ${{ steps.image-tag.outputs.image-node-service }}\n      image-dotnet: ${{ steps.image-tag.outputs.image-dotnet-service }}\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n\n      # Login against a Docker registry except on PR\n      # https://github.com/docker/login-action\n      - name: Log into registry ${{ env.REGISTRY }}\n        if: github.event_name != 'pull_request'\n        uses: docker/login-action@v1\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      # Extract metadata (tags, labels) for Docker\n      # https://github.com/docker/metadata-action\n      - name: Extract Docker metadata\n        id: meta\n        uses: docker/metadata-action@v3\n        with:\n          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/${{ matrix.services.imageName }}\n          tags: |\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n            type=semver,pattern={{major}}\n            type=ref,event=branch\n            type=sha\n\n      # Build and push Docker image with Buildx (don't push on PR)\n      # https://github.com/docker/build-push-action\n      - name: Build and push Docker image\n        uses: docker/build-push-action@v2\n        with:\n          context: ${{ matrix.services.directory }}\n          push: ${{ github.event_name != 'pull_request' }}\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n\n      - name: Output image tag\n        id: image-tag\n        run: echo \"::set-output name=image-${{ matrix.services.imageName }}::${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/${{ matrix.services.imageName }}:sha-$(git rev-parse --short HEAD)\" | tr '[:upper:]' '[:lower:]'\n\n  deploy:\n    runs-on: ubuntu-latest\n    needs: [build]\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n\n      - name: Azure Login\n        uses: azure/login@v1\n        with:\n          creds: ${{ secrets.AZURE_CREDENTIALS }}\n\n      - name: Deploy bicep\n        uses: azure/CLI@v1\n        if: github.event_name != 'pull_request'\n        with:\n          inlineScript: |\n            REF_SHA='${{ github.ref }}.${{ github.sha }}'\n            DEPLOYMENT_NAME=\"${REF_SHA////-}\"\n            echo \"DEPLOYMENT_NAME=$DEPLOYMENT_NAME\"\n\n            TAGS='{\"owner\":\"johnnyreilly\", \"email\":\"johnny_reilly@hotmail.com\"}'\n            az deployment group create \\\n              --resource-group ${{ env.RESOURCE_GROUP }} \\\n              --name \"$DEPLOYMENT_NAME\" \\\n              --template-file ./infra/main.bicep \\\n              --parameters \\\n                  branchName='${{ github.event.number == 0 && 'main' ||  format('pr-{0}', github.event.number) }}' \\\n                  webServiceImage='${{ needs.build.outputs.image-node }}' \\\n                  webServicePort=3000 \\\n                  webServiceIsExternalIngress=true \\\n                  weatherServiceImage='${{ needs.build.outputs.image-dotnet }}' \\\n                  weatherServicePort=5000 \\\n                  weatherServiceIsExternalIngress=false \\\n                  containerRegistry=${{ env.REGISTRY }} \\\n                  containerRegistryUsername=${{ github.actor }} \\\n                  containerRegistryPassword=${{ secrets.PACKAGES_TOKEN }} \\\n                  tags=\"$TAGS\"\n")),(0,a.kt)("p",null,"There's a lot in this workflow. Let's dig into the ",(0,a.kt)("inlineCode",{parentName:"p"},"build")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"deploy")," jobs to see what's happening."),(0,a.kt)("h3",o({},{id:"build---building-our-image"}),(0,a.kt)("inlineCode",{parentName:"h3"},"build")," - building our image"),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"build")," job is all about building our container images and pushing then to the GitHub registry. It's heavily inspired by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/jeffhollan"}),"Jeff Hollan"),"'s ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure-Samples/container-apps-store-api-microservice"}),"Azure sample app GHA"),". When we look at the ",(0,a.kt)("inlineCode",{parentName:"p"},"strategy")," we can see a ",(0,a.kt)("inlineCode",{parentName:"p"},"matrix")," of ",(0,a.kt)("inlineCode",{parentName:"p"},"services")," consisting of two services; our node app and our dotnet app:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),"strategy:\n  matrix:\n    services:\n      [\n        { 'imageName': 'node-service', 'directory': './WebService' },\n        { 'imageName': 'dotnet-service', 'directory': './WeatherService' },\n      ]\n")),(0,a.kt)("p",null,"This is a matrix because a typical use case of an Azure Container Apps will be multi-container - just as this is. The ",(0,a.kt)("inlineCode",{parentName:"p"},"outputs")," pumps out the details of our ",(0,a.kt)("inlineCode",{parentName:"p"},"image-node")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"image-dotnet")," images to be used later:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),"outputs:\n  image-node: ${{ steps.image-tag.outputs.image-node-service }}\n  image-dotnet: ${{ steps.image-tag.outputs.image-dotnet-service }}\n")),(0,a.kt)("p",null,"With that understanding in place, let's examine what each of the steps in the ",(0,a.kt)("inlineCode",{parentName:"p"},"build")," job does"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Log into registry")," - logs into the GitHub container registry"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Extract Docker metadata")," - acquire tags which will be used for versioning"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Build and push Docker image")," - build the docker image and if this is not a PR: tag, label and push it to the registry"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Output image tag")," - write out the image tag for usage in deployment")),(0,a.kt)("h3",o({},{id:"deploy---shipping-our-image-to-azure"}),(0,a.kt)("inlineCode",{parentName:"h3"},"deploy")," - shipping our image to Azure"),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"deploy")," job runs the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/cli/azure/deployment/group?view=azure-cli-latest#az_deployment_group_create"}),(0,a.kt)("inlineCode",{parentName:"a"},"az deployment group create"))," command which performs a deployment of our ",(0,a.kt)("inlineCode",{parentName:"p"},"main.bicep")," file."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),"- name: Deploy bicep\n  uses: azure/CLI@v1\n  if: github.event_name != 'pull_request'\n  with:\n    inlineScript: |\n      REF_SHA='${{ github.ref }}.${{ github.sha }}'\n      DEPLOYMENT_NAME=\"${REF_SHA////-}\"\n      echo \"DEPLOYMENT_NAME=$DEPLOYMENT_NAME\"\n\n      TAGS='{\"owner\":\"johnnyreilly\", \"email\":\"johnny_reilly@hotmail.com\"}'\n      az deployment group create \\\n        --resource-group ${{ env.RESOURCE_GROUP }} \\\n        --name \"$DEPLOYMENT_NAME\" \\\n        --template-file ./infra/main.bicep \\\n        --parameters \\\n            branchName='${{ github.event.number == 0 && 'main' ||  format('pr-{0}', github.event.number) }}' \\\n            webServiceImage='${{ needs.build.outputs.image-node }}' \\\n            webServicePort=3000 \\\n            webServiceIsExternalIngress=true \\\n            weatherServiceImage='${{ needs.build.outputs.image-dotnet }}' \\\n            weatherServicePort=5000 \\\n            weatherServiceIsExternalIngress=false \\\n            containerRegistry=${{ env.REGISTRY }} \\\n            containerRegistryUsername=${{ github.actor }} \\\n            containerRegistryPassword=${{ secrets.PACKAGES_TOKEN }} \\\n            tags=\"$TAGS\"\n")),(0,a.kt)("p",null,"In either case we pass the same set of parameters:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"branchName='${{ github.event.number == 0 && 'main' ||  format('pr-{0}', github.event.number) }}' \\\nwebServiceImage='${{ needs.build.outputs.image-node }}' \\\nwebServicePort=3000 \\\nwebServiceIsExternalIngress=true \\\nweatherServiceImage='${{ needs.build.outputs.image-dotnet }}' \\\nweatherServicePort=5000 \\\nweatherServiceIsExternalIngress=true \\\ncontainerRegistry=${{ env.REGISTRY }} \\\ncontainerRegistryUsername=${{ github.actor }} \\\ncontainerRegistryPassword=${{ secrets.PACKAGES_TOKEN }} \\\ntags=\"$tags\"\n")),(0,a.kt)("p",null,"These are either:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"secrets we set up earlier"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://docs.github.com/en/actions/learn-github-actions/contexts"}),"special github variables")),(0,a.kt)("li",{parentName:"ul"},"environment variables declared at the start of the script or"),(0,a.kt)("li",{parentName:"ul"},"outputs from the build step - this is where we acquire our node and dotnet images")),(0,a.kt)("h2",o({},{id:"running-it"}),"Running it"),(0,a.kt)("p",null,"When the GitHub Action has been run you'll find that Azure Container Apps are now showing up inside the Azure Portal in your resource group, alongside the other resources:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the Azure Container App&#39;s resource group in the Azure Portal",src:n(42643).Z,width:"2635",height:"1142"})),(0,a.kt)("p",null,"If we take a look at our web ACA we'll see"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the web Azure Container App&#39;s in the Azure Portal",src:n(52684).Z,width:"1064",height:"612"})),(0,a.kt)("p",null,"And when we take a closer look at the container app, we find a URL we can navigate to:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the Azure Container App in the Azure Portal revealing it&#39;s URL",src:n(23770).Z,width:"900",height:"332"})),(0,a.kt)("p",null,"Congratulations! You've built and deployed a simple web app to Azure Container Apps with Bicep and GitHub Actions and secrets."),(0,a.kt)("h2",o({},{id:"the-subscription--cannot-have-more-than-2-environments"}),(0,a.kt)("inlineCode",{parentName:"h2"},"The subscription '***' cannot have more than 2 environments.")),(0,a.kt)("p",null,"Before signing off, it's probably worth sharing this gotcha. If you've been playing with Azure Container Apps you may have already deployed an \"environment\" (",(0,a.kt)("inlineCode",{parentName:"p"},"Microsoft.Web/kubeEnvironments"),"). It's fairly common to have a limit of one environment per subscription, which is what this message is saying. So either delete other environments, share the one you have or arrange to raise the limit on your subscription."))}d.isMDXComponent=!0},38171:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"migrating-from-github-pages-to-azure-static-web-apps",title:"Migrating from GitHub Pages to Azure Static Web Apps",authors:"johnnyreilly",tags:["Azure Static Web Apps","Bicep","GitHub Actions","github pages"],image:"./title-image.png",description:"You can use Bicep and GitHub Actions to build and deploy to a static website on Azure Static Web Apps. This post demonstrates how.",hide_table_of_contents:!1},s=void 0,l={permalink:"/migrating-from-github-pages-to-azure-static-web-apps",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-02-01-migrating-from-github-pages-to-azure-static-web-apps/index.md",source:"@site/blog/2022-02-01-migrating-from-github-pages-to-azure-static-web-apps/index.md",title:"Migrating from GitHub Pages to Azure Static Web Apps",description:"You can use Bicep and GitHub Actions to build and deploy to a static website on Azure Static Web Apps. This post demonstrates how.",date:"2022-02-01T00:00:00.000Z",formattedDate:"February 1, 2022",tags:[{label:"Azure Static Web Apps",permalink:"/tags/azure-static-web-apps"},{label:"Bicep",permalink:"/tags/bicep"},{label:"GitHub Actions",permalink:"/tags/git-hub-actions"},{label:"github pages",permalink:"/tags/github-pages"}],readingTime:7.915,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"migrating-from-github-pages-to-azure-static-web-apps",title:"Migrating from GitHub Pages to Azure Static Web Apps",authors:"johnnyreilly",tags:["Azure Static Web Apps","Bicep","GitHub Actions","github pages"],image:"./title-image.png",description:"You can use Bicep and GitHub Actions to build and deploy to a static website on Azure Static Web Apps. This post demonstrates how.",hide_table_of_contents:!1},prevItem:{title:"Lazy loading images with Docusaurus",permalink:"/lazy-loading-images-with-docusaurus"},nextItem:{title:"Azure Container Apps: dapr, devcontainer, debug and deploy",permalink:"/azure-container-apps-dapr-bicep-github-actions-debug-devcontainer"}},p={image:n(36285).Z,authorsImageUrls:[void 0]},u=[{value:"Why migrate?",id:"why-migrate",level:2},{value:"Bicep",id:"bicep",level:2},{value:"Setting up a resource group",id:"setting-up-a-resource-group",level:2},{value:"Secrets for GitHub Actions",id:"secrets-for-github-actions",level:2},{value:"<code>AZURE_CREDENTIALS</code> - GitHub logging into Azure",id:"azure_credentials---github-logging-into-azure",level:3},{value:"<code>WORKFLOW_TOKEN</code> - Azure accessing the GitHub container registry",id:"workflow_token---azure-accessing-the-github-container-registry",level:3},{value:"Deploying with GitHub Actions",id:"deploying-with-github-actions",level:2},{value:"DNS and custom domains",id:"dns-and-custom-domains",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"You can use Bicep and GitHub Actions to build and deploy to a static website on Azure Static Web Apps. This post demonstrates how."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Migrating from GitHub Pages to Azure Static Web Apps&quot; with GitHub and Azure Static Web Apps logos",src:n(36285).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"why-migrate"}),"Why migrate?"),(0,a.kt)("p",null,"This blog has been hosted on GitHub Pages for some time. It also makes use of Netlify for deployment previews. These are both great, but it's always niggled that there's two mechanisms in play; each separately configured. It's time to simplify."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://azure.microsoft.com/en-us/services/app-service/static/"}),"Azure Static Web Apps"),' supports both hosting static websites and deployment previews (known as "staging environments"). So we\'re going to migrate across to use Static Web Apps in place of both of GitHub Pages and Netlify. I\'m choosing to use Bicep to do this as I tend towards using infrastructure as code. If you wanted to roll with a more "point and click" approach in the Azure Portal, you could do that too. Simply ignore the Bicep related portions of the post.'),(0,a.kt)("h2",o({},{id:"bicep"}),"Bicep"),(0,a.kt)("p",null,"The first thing we're going to need is a Bicep template to deploy our SWA. In our GitHub repo we're going to add a ",(0,a.kt)("inlineCode",{parentName:"p"},"infra")," folder, and in there we'll create a ",(0,a.kt)("inlineCode",{parentName:"p"},"main.bicep")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param location string\nparam branch string\nparam name string\nparam tags object\n@secure()\nparam repositoryToken string\nparam customDomainName string\n\nresource staticWebApp 'Microsoft.Web/staticSites@2021-02-01' = {\n  name: name\n  location: location\n  tags: tags\n  sku: {\n    name: 'Free'\n    tier: 'Free'\n  }\n  properties: {\n    repositoryUrl: 'https://github.com/johnnyreilly/blog.johnnyreilly.com'\n    repositoryToken: repositoryToken\n    branch: branch\n    provider: 'GitHub'\n    stagingEnvironmentPolicy: 'Enabled'\n    allowConfigFileUpdates: true\n    buildProperties:{\n      skipGithubActionWorkflowGeneration: true\n    }\n  }\n}\n\n// resource customDomain 'Microsoft.Web/staticSites/customDomains@2021-02-01' = {\n//   parent: staticWebApp\n//   name: customDomainName\n//   properties: {}\n// }\n\noutput staticWebAppDefaultHostName string = staticWebApp.properties.defaultHostname // eg gentle-bush-0db02ce03.azurestaticapps.net\noutput staticWebAppId string = staticWebApp.id\noutput staticWebAppName string = staticWebApp.name\n")),(0,a.kt)("p",null,"Most of the Bicep template above is self-explanatory. There's a few things to highlight:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"We're using the \"Free\" SKU which means we don't have to pay to run our website."),(0,a.kt)("li",{parentName:"ul"},"We need to provide a ",(0,a.kt)("inlineCode",{parentName:"li"},"repositoryToken")," - this is a little surprising as you'll see later in the template that we supply the ",(0,a.kt)("inlineCode",{parentName:"li"},"skipGithubActionWorkflowGeneration: true")," which means we're ",(0,a.kt)("em",{parentName:"li"},"not")," requiring our SWA to interact with GitHub on our behalf - but it seems that there's a requirement for a GitHub token anyway. We'll roll with it."),(0,a.kt)("li",{parentName:"ul"},"We're enabling deployment previews / staging environments with ",(0,a.kt)("inlineCode",{parentName:"li"},"stagingEnvironmentPolicy: 'Enabled'")),(0,a.kt)("li",{parentName:"ul"},"The ",(0,a.kt)("inlineCode",{parentName:"li"},"branch")," is always set to ",(0,a.kt)("inlineCode",{parentName:"li"},"main")," - we have to let Azure know this so it knows which branch is the primary branch and hence which other ones will have staging environments."),(0,a.kt)("li",{parentName:"ul"},"It also includes a section for the custom domain which is commented out - we'll uncomment that later once we've set up our custom domain / DNS.")),(0,a.kt)("h2",o({},{id:"setting-up-a-resource-group"}),"Setting up a resource group"),(0,a.kt)("p",null,"With our Bicep in place, we're going to need a resource group to send it to. We're going to create ourselves a resource group in West Europe:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"az group create -g rg-blog-johnnyreilly-com -l westeurope\n")),(0,a.kt)("h2",o({},{id:"secrets-for-github-actions"}),"Secrets for GitHub Actions"),(0,a.kt)("p",null,"We're aiming to set up a GitHub Action to handle our deployment which depends upon some secrets."),(0,a.kt)("h3",o({},{id:"azure_credentials---github-logging-into-azure"}),(0,a.kt)("inlineCode",{parentName:"h3"},"AZURE_CREDENTIALS")," - GitHub logging into Azure"),(0,a.kt)("p",null,"First a ",(0,a.kt)("inlineCode",{parentName:"p"},"AZURE_CREDENTIALS")," secret that facilitates GitHub logging into Azure. We'll use the Azure CLI to create this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),'az ad sp create-for-rbac --name "myApp" --role contributor \\\n    --scopes /subscriptions/{subscription-id}/resourceGroups/{resource-group} \\\n    --sdk-auth\n')),(0,a.kt)("p",null,"Remember to replace the ",(0,a.kt)("inlineCode",{parentName:"p"},"{subscription-id}")," with your subscription id and ",(0,a.kt)("inlineCode",{parentName:"p"},"{resource-group}")," with the name of your resource group (",(0,a.kt)("inlineCode",{parentName:"p"},"rg-blog-johnnyreilly-com")," if you're following along). This command will pump out a lump of JSON that looks something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "clientId": "a-client-id",\n  "clientSecret": "a-client-secret",\n  "subscriptionId": "a-subscription-id",\n  "tenantId": "a-tenant-id",\n  "activeDirectoryEndpointUrl": "https://login.microsoftonline.com",\n  "resourceManagerEndpointUrl": "https://management.azure.com/",\n  "activeDirectoryGraphResourceId": "https://graph.windows.net/",\n  "sqlManagementEndpointUrl": "https://management.core.windows.net:8443/",\n  "galleryEndpointUrl": "https://gallery.azure.com/",\n  "managementEndpointUrl": "https://management.core.windows.net/"\n}\n')),(0,a.kt)("p",null,"Take this and save it as the ",(0,a.kt)("inlineCode",{parentName:"p"},"AZURE_CREDENTIALS")," secret in GitHub."),(0,a.kt)("h3",o({},{id:"workflow_token---azure-accessing-the-github-container-registry"}),(0,a.kt)("inlineCode",{parentName:"h3"},"WORKFLOW_TOKEN")," - Azure accessing the GitHub container registry"),(0,a.kt)("p",null,"We also need a secret for updating workflows from Azure. Azure Static Web Apps can update your workflow - they need access to do this when we're deploying. To facilitate this we'll set up a ",(0,a.kt)("inlineCode",{parentName:"p"},"WORKFLOW_TOKEN")," secret. This is a GitHub personal access token with the ",(0,a.kt)("inlineCode",{parentName:"p"},"workflow")," scope. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token"}),"Follow the instructions here to create the token.")),(0,a.kt)("p",null,"Ironically, we're not planning to use this functionality, but the validation for the Bicep template will fail if it isn't supplied."),(0,a.kt)("h2",o({},{id:"deploying-with-github-actions"}),"Deploying with GitHub Actions"),(0,a.kt)("p",null,"With our secrets configured, we're now well placed to update our GitHub Action. We'll tweak the content of ",(0,a.kt)("inlineCode",{parentName:"p"},".github/workflows/build-and-deploy.yaml")," file in our repository to the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),"name: Build and Deploy\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    types: [opened, synchronize, reopened, closed]\n    branches:\n      - main\n\nenv:\n  RESOURCE_GROUP: rg-blog-johnnyreilly-com\n  LOCATION: westeurope\n  STATICWEBAPPNAME: blog.johnnyreilly.com\n  TAGS: '{\"owner\":\"johnnyreilly\", \"email\":\"johnny_reilly@hotmail.com\"}'\n\njobs:\n  build_and_deploy_swa_job:\n    if: github.event_name == 'push' || (github.event_name == 'pull_request' && github.event.action != 'closed')\n    runs-on: ubuntu-latest\n    name: Build and deploy\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: true\n\n      - name: Azure Login\n        uses: azure/login@v1\n        with:\n          creds: ${{ secrets.AZURE_CREDENTIALS }}\n\n      - name: Set Deployment Name\n        id: deployment_name\n        run: |\n          REF_SHA='${{ github.ref }}.${{ github.sha }}'\n          DEPLOYMENT_NAME=\"${REF_SHA////-}\"\n          echo \"::set-output name=DEPLOYMENT_NAME::$DEPLOYMENT_NAME\"\n\n      - name: Static Web App - change details\n        id: static_web_app_what_if\n        if: github.event_name == 'pull_request'\n        uses: azure/CLI@v1\n        with:\n          inlineScript: |\n            az deployment group what-if \\\n              --resource-group ${{ env.RESOURCE_GROUP }} \\\n              --name \"${{ steps.deployment_name.outputs.DEPLOYMENT_NAME }}\" \\\n              --template-file ./infra/main.bicep \\\n              --parameters \\\n                  branch='main' \\\n                  location='${{ env.LOCATION }}' \\\n                  name='${{ env.STATICWEBAPPNAME }}' \\\n                  tags='${{ env.TAGS }}' \\\n                  repositoryToken='${{ secrets.WORKFLOW_TOKEN }}' \\\n                  customDomainName='${{ env.STATICWEBAPPNAME }}'\n\n      - name: Static Web App - deploy infra\n        id: static_web_app_deploy\n        if: github.event_name != 'pull_request'\n        uses: azure/CLI@v1\n        with:\n          inlineScript: |\n            az deployment group create \\\n              --resource-group ${{ env.RESOURCE_GROUP }} \\\n              --name \"${{ steps.deployment_name.outputs.DEPLOYMENT_NAME }}\" \\\n              --template-file ./infra/main.bicep \\\n              --parameters \\\n                  branch='main' \\\n                  location='${{ env.LOCATION }}' \\\n                  name='${{ env.STATICWEBAPPNAME }}' \\\n                  tags='${{ env.TAGS }}' \\\n                  repositoryToken='${{ secrets.WORKFLOW_TOKEN }}' \\\n                  customDomainName='${{ env.STATICWEBAPPNAME }}'\n\n      - name: Static Web App - get API key for deployment\n        id: static_web_app_apikey\n        uses: azure/CLI@v1\n        with:\n          inlineScript: |\n            APIKEY=$(az staticwebapp secrets list --name '${{ env.STATICWEBAPPNAME }}' | jq -r '.properties.apiKey')\n            echo \"::set-output name=APIKEY::$APIKEY\"\n\n      - name: Static Web App - build and deploy\n        id: static_web_app_build_and_deploy\n        uses: Azure/static-web-apps-deploy@v1\n        with:\n          azure_static_web_apps_api_token: ${{ steps.static_web_app_apikey.outputs.APIKEY }}\n          repo_token: ${{ secrets.GITHUB_TOKEN }} # Used for Github integrations (i.e. PR comments)\n          action: 'upload'\n          ###### Repository/Build Configurations - These values can be configured to match your app requirements. ######\n          # For more information regarding Static Web App workflow configurations, please visit: https://aka.ms/swaworkflowconfig\n          app_location: '/blog-website' # App source code path\n          api_location: '' # Api source code path - optional\n          output_location: 'build' # Built app content directory - optional\n          ###### End of Repository/Build Configurations ######\n\n      - name: Static Web App - get preview URL\n        id: static_web_app_preview_url\n        uses: azure/CLI@v1\n        with:\n          inlineScript: |\n            DEFAULTHOSTNAME=$(az staticwebapp show -n '${{ env.STATICWEBAPPNAME }}' | jq -r '.defaultHostname')\n            echo $DEFAULTHOSTNAME\n\n            PREVIEW_URL=\"https://${DEFAULTHOSTNAME/.[1-9]./-${{github.event.pull_request.number }}.${{ env.LOCATION }}.1.}\"\n            echo $PREVIEW_URL\n\n            echo \"::set-output name=PREVIEW_URL::$PREVIEW_URL\"\n\n    outputs:\n      preview-url: ${{steps.static_web_app_preview_url.outputs.PREVIEW_URL}}\n\n  close_pull_request_job:\n    if: github.event_name == 'pull_request' && github.event.action == 'closed'\n    runs-on: ubuntu-latest\n    name: Cleanup Pull Request staging environment\n    steps:\n      - name: Azure Login\n        uses: azure/login@v1\n        with:\n          creds: ${{ secrets.AZURE_CREDENTIALS }}\n\n      - name: Get API key for deployment\n        id: apikey\n        uses: azure/CLI@v1\n        with:\n          inlineScript: |\n            APIKEY=$(az staticwebapp secrets list --name '${{ env.STATICWEBAPPNAME }}' | jq -r '.properties.apiKey')\n            echo \"::set-output name=APIKEY::$APIKEY\"\n\n      - name: Close Pull Request\n        id: closepullrequest\n        uses: Azure/static-web-apps-deploy@v1\n        with:\n          azure_static_web_apps_api_token: ${{ steps.apikey.outputs.APIKEY }}\n          action: 'close'\n")),(0,a.kt)("p",null,"The above workflow does the following:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"For main branch deployments it releases our static web app making use of Bicep. For pull requests it tells us if there's any changes that the current PR would make to our SWA as a consequence."),(0,a.kt)("li",{parentName:"ul"},"It acquires an API Key from Azure which can then be used to perform a deployment."),(0,a.kt)("li",{parentName:"ul"},"It deploys ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/Azure/static-web-apps-deploy"}),"using the dedicated GitHub Action for SWAs")),(0,a.kt)("li",{parentName:"ul"},"It calculates the preview URL for a given pull request (it isn't used as yet, but could be)"),(0,a.kt)("li",{parentName:"ul"},"When a pull request is closed it triggers the GitHub Action to clean up the preview environment.")),(0,a.kt)("h2",o({},{id:"dns-and-custom-domains"}),"DNS and custom domains"),(0,a.kt)("p",null,"Once our GitHub Action has run for the first time on the main branch, we'll be deploying to Azure Static Web Apps."),(0,a.kt)("p",null,"Once we've started deploying there, we want to get our custom domain set up to point to it. To do this, we're going to fire up the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://portal.azure.com"}),"Azure Portal")," and go to add a custom domain:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the Azure Portal Add Custom Domain screen",src:n(20876).Z,width:"3041",height:"747"})),(0,a.kt)("p",null,"We're going to add a TXT record for my blog. Azure generates a code for us:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the Azure Portal Add Custom Domain screen",src:n(78380).Z,width:"1146",height:"1106"})),(0,a.kt)("p",null,"We need to take that code and go a register it with our DNS provider. In my case that's Cloudflare, so we can go there and add it:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Cloudflare",src:n(50088).Z,width:"1411",height:"420"})),(0,a.kt)("p",null,"After a while (I think about twenty minutes in my case), this lead to the domain name being validated:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the Azure Portal Add Custom Domain screen with domain validated",src:n(33499).Z,width:"1151",height:"1092"})),(0,a.kt)("p",null,"Now that we have a custom domain set up in Azure, we want to uncomment the ",(0,a.kt)("inlineCode",{parentName:"p"},"resource customDomain")," portion of the Bicep template now as well:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"resource customDomain 'Microsoft.Web/staticSites/customDomains@2021-02-01' = {\n  parent: staticWebApp\n  name: customDomainName\n  properties: {}\n}\n")),(0,a.kt)("p",null,"This will mean that subsequent deployments to Azure do ",(0,a.kt)("em",{parentName:"p"},"not")," wipe out our newly configured domain name."),(0,a.kt)("p",null,"We're now ready to start pointing our DNS to the Static Web Apps instance. We jump back across to Cloudflare and we amend the CNAME record that currently points to johnnyreilly.github.io, and switch it to point to the auto-generated domain in Azure:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Cloudflare with the CNAME record set",src:n(39318).Z,width:"2078",height:"497"})),(0,a.kt)("p",null,"And just like that, we're hosted on Static Web Apps!"))}d.isMDXComponent=!0},32313:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"lazy-loading-images-with-docusaurus",title:"Lazy loading images with Docusaurus",authors:"johnnyreilly",tags:["Docusaurus","rehype plugin"],image:"./title-image.png",description:"Docusaurus websites can implement native lazy-loading of images, you can by writing a Rehype plugin.",hide_table_of_contents:!1},s=void 0,l={permalink:"/lazy-loading-images-with-docusaurus",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-02-02-lazy-loading-images-with-docusaurus/index.md",source:"@site/blog/2022-02-02-lazy-loading-images-with-docusaurus/index.md",title:"Lazy loading images with Docusaurus",description:"Docusaurus websites can implement native lazy-loading of images, you can by writing a Rehype plugin.",date:"2022-02-02T00:00:00.000Z",formattedDate:"February 2, 2022",tags:[{label:"Docusaurus",permalink:"/tags/docusaurus"},{label:"rehype plugin",permalink:"/tags/rehype-plugin"}],readingTime:2.955,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"lazy-loading-images-with-docusaurus",title:"Lazy loading images with Docusaurus",authors:"johnnyreilly",tags:["Docusaurus","rehype plugin"],image:"./title-image.png",description:"Docusaurus websites can implement native lazy-loading of images, you can by writing a Rehype plugin.",hide_table_of_contents:!1},prevItem:{title:"Azure Static Web Apps - a Netlify alternative",permalink:"/azure-static-web-apps-a-netlify-alternative"},nextItem:{title:"Migrating from GitHub Pages to Azure Static Web Apps",permalink:"/migrating-from-github-pages-to-azure-static-web-apps"}},p={image:n(66308).Z,authorsImageUrls:[void 0]},u=[{value:"Updated 26/02/2022",id:"updated-26022022",level:2},{value:"Lazy loading images",id:"lazy-loading-images",level:2},{value:"Docusaurus",id:"docusaurus",level:2},{value:"Rehype plugin",id:"rehype-plugin",level:2},{value:"What&#39;s the result?",id:"whats-the-result",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"If you'd like to improve the performance of a Docusaurus website by implementing native lazy-loading of images, you can. This post shows you how you too can have ",(0,a.kt)("inlineCode",{parentName:"p"},'<img loading="lazy" ')," on your images by writing a Rehype plugin."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Lazy loading images with Docusaurus&quot; with a Docusaurus logo and an image that reads `&lt;img loading=&quot;lazy&quot; `",src:n(66308).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"updated-26022022"}),"Updated 26/02/2022"),(0,a.kt)("p",null,"You don't need this anymore. As of Docusaurus ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/releases/tag/v2.0.0-beta.16"}),"v2.0.0-beta.16")," Docusaurus lazy loads markdown images by default. You can see the commit where it was added ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/pull/6598"}),"here"),". Isn't that wonderful?"),(0,a.kt)("p",null,"\u2705cumulative no of network requests for Docusaurus sites will go \ud83d\udc47\n\u2705perceived performance will go \u261d\ufe0f\n\u2705hosting costs will go \ud83d\udc47"),(0,a.kt)("h2",o({},{id:"lazy-loading-images"}),"Lazy loading images"),(0,a.kt)("p",null,"Native browser lazy loading for images is a relatively recent innovation. To read more on the topic, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://web.dev/browser-level-image-lazy-loading/"}),"do look at this post"),". The TL;DR is this though: by adding the ",(0,a.kt)("inlineCode",{parentName:"p"},'loading="lazy"')," attribute to an ",(0,a.kt)("inlineCode",{parentName:"p"},"img")," element, modern browsers will delay loading the image until it is needed. This provides better performance to your users: when it comes to loading, less is more."),(0,a.kt)("h2",o({},{id:"docusaurus"}),"Docusaurus"),(0,a.kt)("p",null,"If you're using Docusaurus then you're likely writing Markdown. I am. This blog is written using Markdown, and converted, using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/docs/next/markdown-features/plugins"}),"MDX plugins")," into JSX. This handles images as well as we can ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/blob/6ec0db4722cbf988fd5280a4442223637c2de8d7/packages/docusaurus-mdx-loader/src/remark/transformImage/index.ts#L79"}),"see here"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"jsxNode.value = `<img ${alt}src={${src}}${title}${width}${height} />`;\n")),(0,a.kt)("p",null,"The crucial thing to note about the above, is the lack of the ",(0,a.kt)("inlineCode",{parentName:"p"},'loading="lazy"')," attribute. Can we add that somehow? Yes we can!"),(0,a.kt)("h2",o({},{id:"rehype-plugin"}),"Rehype plugin"),(0,a.kt)("p",null,"To do this, we're going to write our own mini ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/rehypejs"}),"rehype plugin")," that will take the HTML being pumped out of Docusaurus and add the ",(0,a.kt)("inlineCode",{parentName:"p"},'loading="lazy"')," attribute."),(0,a.kt)("p",null,"Alongside our ",(0,a.kt)("inlineCode",{parentName:"p"},"docusaurus.config.js")," we're going to create a ",(0,a.kt)("inlineCode",{parentName:"p"},"image-lazy-remark-plugin.js")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const visit = require('unist-util-visit');\n\n/** @type {import('unified').Plugin<[], import('hast').Root>} */\nfunction lazyLoadImagesPlugin() {\n  return (tree) => {\n    visit(tree, ['element', 'jsx'], (node) => {\n      if (node.type === 'element' && node.tagName === 'img') {\n        // handles nodes like this:\n\n        // {\n        //   type: 'element',\n        //   tagName: 'img',\n        //   properties: {\n        //     src: 'https://some.website.com/cat.gif',\n        //     alt: null\n        //   },\n        //   ...\n        // }\n\n        node.properties.loading = 'lazy';\n      } else if (node.type === 'jsx' && node.value.includes('<img ')) {\n        // handles nodes like this:\n\n        // {\n        //   type: 'jsx',\n        //   value: '<img src={require(\"!/workspaces/blog.johnnyreilly.com/blog-website/node_modules/url-loader/dist/cjs.js?limit=10000&name=assets/images/[name]-[hash].[ext]&fallback=/workspaces/blog.johnnyreilly.com/blog-website/node_modules/file-loader/dist/cjs.js!./bower-with-the-long-paths.png\").default} width=\"640\" height=\"497\" />'\n        // }\n\n        node.value = node.value.replace(/<img /g, '<img loading=\"lazy\" ');\n      }\n    });\n  };\n}\n\nmodule.exports = lazyLoadImagesPlugin;\n")),(0,a.kt)("p",null,"As the code above suggests, it looks for ",(0,a.kt)("inlineCode",{parentName:"p"},"img")," elements, whether they be in HTML or JSX, and adds in the ",(0,a.kt)("inlineCode",{parentName:"p"},'loading="lazy"')," attribute."),(0,a.kt)("p",null,"To apply this to our blog, we simply tweak the ",(0,a.kt)("inlineCode",{parentName:"p"},"docusaurus.config.js")," file to make use of our plugin:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const imageLazyRemarkPlugin = require('./image-lazy-remark-plugin');\n\n// ...\n\n/** @type {import('@docusaurus/types').Config} */\nconst config = {\n  // ...\n\n  presets: [\n    [\n      '@docusaurus/preset-classic',\n      /** @type {import('@docusaurus/preset-classic').Options} */\n      ({\n        // ...\n        blog: {\n          // ...\n          rehypePlugins: [imageLazyRemarkPlugin],\n        },\n        // ...\n      }),\n    ],\n  ],\n  // ...\n};\n")),(0,a.kt)("h2",o({},{id:"whats-the-result"}),"What's the result?"),(0,a.kt)("p",null,"With this in place, next time we run a build, we can see the attribute being applied to our image elements:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of an img element with the loading=&quot;lazy&quot; attribute set",src:n(97854).Z,width:"2042",height:"90"})),(0,a.kt)("p",null,"Consequently, when we fire up devtools we can see that only the images onscreen are being loaded. In the example below we're ",(0,a.kt)("em",{parentName:"p"},"not")," seeing five other images being loaded because they're offscreen and haven't been scrolled to as yet:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of chrome devtools showing only two images being loaded - the ones that are on the screen",src:n(97386).Z,width:"2541",height:"789"})),(0,a.kt)("p",null,"Amazing! It works! It's possible that this could land directly in Docusaurus one day. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/feature-requests/p/lazy-loading-images-in-blog-posts-by-default"}),"Go here to follow the discussion on this.")))}d.isMDXComponent=!0},59159:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-static-web-apps-a-netlify-alternative",title:"Azure Static Web Apps - a Netlify alternative",authors:"johnnyreilly",tags:["Azure Static Web Apps","GitHub Actions","Docusaurus"],description:"Azure Static Web Apps are a new offering from Microsoft. This post looks at what they are and how they compare to Netlify.",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-static-web-apps-a-netlify-alternative",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-02-08-azure-static-web-apps-a-netlify-alternative/index.md",source:"@site/blog/2022-02-08-azure-static-web-apps-a-netlify-alternative/index.md",title:"Azure Static Web Apps - a Netlify alternative",description:"Azure Static Web Apps are a new offering from Microsoft. This post looks at what they are and how they compare to Netlify.",date:"2022-02-08T00:00:00.000Z",formattedDate:"February 8, 2022",tags:[{label:"Azure Static Web Apps",permalink:"/tags/azure-static-web-apps"},{label:"GitHub Actions",permalink:"/tags/git-hub-actions"},{label:"Docusaurus",permalink:"/tags/docusaurus"}],readingTime:7.685,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-static-web-apps-a-netlify-alternative",title:"Azure Static Web Apps - a Netlify alternative",authors:"johnnyreilly",tags:["Azure Static Web Apps","GitHub Actions","Docusaurus"],description:"Azure Static Web Apps are a new offering from Microsoft. This post looks at what they are and how they compare to Netlify.",hide_table_of_contents:!1},prevItem:{title:"Swashbuckle & inheritance: Give. Me. The. Types",permalink:"/swashbuckle-inheritance-multiple-return-types"},nextItem:{title:"Lazy loading images with Docusaurus",permalink:"/lazy-loading-images-with-docusaurus"}},p={authorsImageUrls:[void 0]},u=[{value:"Jamstack and Azure Static Web Apps",id:"jamstack-and-azure-static-web-apps",level:2},{value:"Create our application",id:"create-our-application",level:2},{value:"Creating a Static Web App in Azure",id:"creating-a-static-web-app-in-azure",level:2},{value:"Authentication",id:"authentication",level:2},{value:"Staging Environments",id:"staging-environments",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Jamstack sites have taken the world by storm. There's currently fierce competition between offerings like ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/netlify-vs-cloudflare-pages/"}),"Netlify and Cloudflare"),". A new player in this space is Azure Static Web Apps. This post will look at what working with SWAs is like and will demonstrate deploying one using GitHub Actions."),(0,a.kt)("h2",o({},{id:"jamstack-and-azure-static-web-apps"}),"Jamstack and Azure Static Web Apps"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://en.m.wikipedia.org/wiki/Jamstack"}),"Jamstack")," stands for JavaScript, API and Markup In Jamstack websites, the application logic typically resides on the client side. Typically these clients are built as ",(0,a.kt)("a",o({parentName:"p"},{href:"https://en.m.wikipedia.org/wiki/Single-page_application"}),"single-page applications")," and often have HTML files statically generated for every possible path to support search engine optimization."),(0,a.kt)("p",null,"Azure Static Web Apps were released for general use in ",(0,a.kt)("a",o({parentName:"p"},{href:"https://azure.microsoft.com/en-us/updates/azure-static-web-apps-is-now-generally-available/"}),"May 2021")," and offer features including:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Globally distributed content for production apps"),(0,a.kt)("li",{parentName:"ul"},"Auto-provisioned preview environments"),(0,a.kt)("li",{parentName:"ul"},"Custom domain configuration and free SSL certificates"),(0,a.kt)("li",{parentName:"ul"},"Built-in access to a variety of authentication providers"),(0,a.kt)("li",{parentName:"ul"},"Route-based authorization"),(0,a.kt)("li",{parentName:"ul"},"Custom routing"),(0,a.kt)("li",{parentName:"ul"},"Integration with serverless APIs powered by Azure Functions"),(0,a.kt)("li",{parentName:"ul"},"A custom Visual Studio Code developer extension")),(0,a.kt)("p",null,"Significantly, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://azure.microsoft.com/en-gb/pricing/details/app-service/static/"}),"these features are available to use for free"),". With Netlify there is also a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.netlify.com/pricing/"}),"free tier"),", however it's quite easy to exceed the build limits of the free tier and land yourself with an unexpected bill. By combining Azure Static Web Apps with GitHub Actions we can build comparable experiences and save ourselves money!"),(0,a.kt)("p",null,"So let's build ourselves a simple SWA and deploy it with GitHub Actions."),(0,a.kt)("h2",o({},{id:"create-our-application"}),"Create our application"),(0,a.kt)("p",null,"Inside the root of our repository we're going to create a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/"}),"Docusaurus site"),". Docusaurus is a good example of a static site, the kind of which is a natural fit for Jamstack. We could equally use something else like ",(0,a.kt)("a",o({parentName:"p"},{href:"https://gohugo.io/"}),"Hugo")," for instance."),(0,a.kt)("p",null,"At the command line we'll enter:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"npx create-docusaurus@latest website classic\n")),(0,a.kt)("p",null,"And Docusaurus will create a new site in the ",(0,a.kt)("inlineCode",{parentName:"p"},"website")," directory. Let's commit and push this and turn our attention to Azure."),(0,a.kt)("h2",o({},{id:"creating-a-static-web-app-in-azure"}),"Creating a Static Web App in Azure"),(0,a.kt)("p",null,"There's a number of ways to create a Static Web App in Azure. It's possible to use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.johnnyreilly.com/2021/08/15/bicep-azure-static-web-apps-azure-devops#bicep-template"}),"infrastructure as code with a language like Bicep"),". But for this post let's use the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://portal.azure.com"}),"Azure Portal")," instead. If you don't have an account already, you can set one up for free very quickly."),(0,a.kt)("p",null,'Once you\'ve logged in, click "Create a resource" and look up Static Web App:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"Screenshot of the Azure Portal, &quot;Create a resource&quot; Azure Static Web Apps section",src:n(7733).Z,width:"1073",height:"640"})),(0,a.kt)("p",null,'Click on "Create" and you\'ll be take to the creation dialog:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the Azure Portal, &quot;Create a resource&quot; Azure Static Web Apps dialog",src:n(198).Z,width:"1213",height:"1404"})),(0,a.kt)("p",null,'You\'ll need to create a resource group for your SWA to live in, give the app a name, the "Free" plan and a deployment source of GitHub.'),(0,a.kt)("p",null,'Click on the "Sign in with GitHub" button and authorize Azure to access your GitHub account for Static Web Apps.'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the Azure Portal, &quot;Create a resource&quot; Azure Static Web Apps dialog - repository settings",src:n(59943).Z,width:"1201",height:"1018"})),(0,a.kt)("p",null,"At this point Azure will query GitHub on your behalf and look up the organisations and repositories you have access to. Select the repository that you'd like to deploy to your Static Web App and select the branch you'd like to deploy."),(0,a.kt)("p",null,'You also need to provide Azure with some build details that help it understand how your app is built. We\'ll provide a preset of "Custom". We\'ll set the "App location" (the root of our front end app) to be ',(0,a.kt)("inlineCode",{parentName:"p"},'"/website"')," to tally up with the application we just created. We'll leave \"Api location\" blank and we'll set the output location to be ",(0,a.kt)("inlineCode",{parentName:"p"},'"build"')," - this is the directory under ",(0,a.kt)("inlineCode",{parentName:"p"},"website")," where Docusaurus will create our site."),(0,a.kt)("p",null,'Finally click "Review + create" and then "Create".'),(0,a.kt)("p",null,"Azure will now:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Create an Azure Static Web app resource in Azure"),(0,a.kt)("li",{parentName:"ul"},"Update your repository to add a GitHub Actions workflow to deploy your static web app"),(0,a.kt)("li",{parentName:"ul"},"Kick off a first run of the GitHub Actions workflow to deploy your SWA.")),(0,a.kt)("p",null,"Pretty amazing, right?"),(0,a.kt)("p",null,"When you look at the resource in Azure it will look something like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the Azure Portal, your Azure Static Web Apps resource",src:n(6962).Z,width:"1422",height:"657"})),(0,a.kt)("p",null,"If you click on the GitHub Action runs you'll be presented with your GitHub Action:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the GitHub Action",src:n(3689).Z,width:"1420",height:"1079"})),(0,a.kt)("p",null,"And when that finishes running you'll be able to see your deployed Static Web App by clicking on the URL in the Azure Portal:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of your Static Web App running in a browser",src:n(46230).Z,width:"1511",height:"676"})),(0,a.kt)("p",null,"We've gone from having nothing, to having a brand new website in Azure, shipped via continous deployment in GitHub Actions in a matter of minutes. This is low friction and high value!"),(0,a.kt)("h2",o({},{id:"authentication"}),"Authentication"),(0,a.kt)("p",null,"Now we've done our initial deployment, let's take it a stage further and add authentication."),(0,a.kt)("p",null,"One of the awesome features of Static Web Apps is the fact that ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/static-web-apps/authentication-authorization?tabs=invitations#login"}),"authentication is available straight out of the box"),". We can pick from GitHub, Azure Active Directory and Twitter as identity providers. Let's roll with GitHub and amend our ",(0,a.kt)("inlineCode",{parentName:"p"},"website/src/pages/index.js")," to support authentication:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-jsx"}),"import React, { useState, useEffect } from 'react';\nimport clsx from 'clsx';\nimport Layout from '@theme/Layout';\nimport useDocusaurusContext from '@docusaurus/useDocusaurusContext';\nimport styles from './index.module.css';\n\n/**\n * @typedef {object} UserInfo\n * @prop {\"github\"} identityProvider\n * @prop {string} userId\n * @prop {string} userDetails\n * @prop {string[]} userRoles\n */\n\n/**\n * @return {UserInfo | null}\n */\nfunction useUserInfo() {\n  const [userInfo, setUserInfo] = useState(null);\n\n  useEffect(() => {\n    async function getUserInfo() {\n      const response = await fetch('/.auth/me');\n      const payload = await response.json();\n      const { clientPrincipal } = payload;\n      return clientPrincipal;\n    }\n\n    getUserInfo().then((ui) => setUserInfo(ui));\n  }, []);\n\n  return userInfo;\n}\n\nexport default function Home() {\n  const { siteConfig } = useDocusaurusContext();\n  const userInfo = useUserInfo();\n\n  return (\n    <Layout\n      title={`Hello from ${siteConfig.title}`}\n      description=\"Description will go into a meta tag in <head />\"\n    >\n      <header className={clsx('hero hero--primary', styles.heroBanner)}>\n        <div className=\"container\">\n          <h1 className=\"hero__title\">{siteConfig.title}</h1>\n          <p className=\"hero__subtitle\">{siteConfig.tagline}</p>\n          <div className={styles.buttons}>\n            {userInfo ? (\n              <p>Hello {userInfo.userDetails}</p>\n            ) : (\n              <a\n                className=\"button button--secondary button--lg\"\n                href=\"/.auth/login/github\"\n              >\n                Click here to login\n              </a>\n            )}\n          </div>\n        </div>\n      </header>\n    </Layout>\n  );\n}\n")),(0,a.kt)("p",null,"The above code does the following:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Implements a React hook named ",(0,a.kt)("inlineCode",{parentName:"li"},"useUserInfo")," which calls the ",(0,a.kt)("inlineCode",{parentName:"li"},"/.auth/me")," endpoint of your SWA. This returns ",(0,a.kt)("inlineCode",{parentName:"li"},"null")," when not authenticated, and the ",(0,a.kt)("inlineCode",{parentName:"li"},"UserInfo")," when authenticated."),(0,a.kt)("li",{parentName:"ul"},"For users who are not authenticated, display a link button which takes people to ",(0,a.kt)("inlineCode",{parentName:"li"},"/.auth/login/github"),", thus triggering the GitHub authentication flow."),(0,a.kt)("li",{parentName:"ul"},"For users who are authenticated, display the users ",(0,a.kt)("inlineCode",{parentName:"li"},"userDetails"),"; the GitHub username.")),(0,a.kt)("p",null,"Let's commit and push this and (when our build has finished running) browse to our Static Web App once again:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of Static Web App now featuring a login button",src:n(11402).Z,width:"1940",height:"734"})),(0,a.kt)("p",null,"If we click to login, we're taken through the GitHub authentication flow:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of Static Web App now featuring a login button",src:n(97578).Z,width:"1023",height:"1070"})),(0,a.kt)("p",null,"Once you've authorised and granted consent you'll be redirected to your app and see that you're logged in:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of Static Web App showing I&#39;m logged in",src:n(63073).Z,width:"1937",height:"740"})),(0,a.kt)("p",null,"If we pop open the devtools of Chrome we'll see what comes back from the ",(0,a.kt)("inlineCode",{parentName:"p"},"/.auth/me")," endpoint:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of Chrome devtools displaying a JSON structure",src:n(51594).Z,width:"1611",height:"328"})),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "clientPrincipal": {\n    "identityProvider": "github",\n    "userId": "1f5b4b7de7d445e29dd6188bcc7ee052",\n    "userDetails": "johnnyreilly",\n    "userRoles": ["anonymous", "authenticated"]\n  }\n}\n')),(0,a.kt)("p",null,"We've now implemented and demonstrated authentication with Azure Static Web Apps with very little effort on our behalf. This is tremendous!"),(0,a.kt)("h2",o({},{id:"staging-environments"}),"Staging Environments"),(0,a.kt)("p",null,"Finally, let's look at a super cool feature that Static Web Apps provides by default. If you take a look at the Environments tab of your SWA you'll see this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the Azure Portal, your Azure Static Web Apps resource - featuring the phrase &quot;Open pull requests against the linked repository to create a staging environment.&quot;",src:n(22276).Z,width:"2900",height:"976"})),(0,a.kt)("blockquote",null,(0,a.kt)("h2",o({parentName:"blockquote"},{id:"staging"}),"Staging"),(0,a.kt)("p",{parentName:"blockquote"},"Open pull requests against the linked repository to create a staging environment.")),(0,a.kt)("p",null,"Let's try that out! We'll create a new branch:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"git checkout -b feat/show-me-staging\n")),(0,a.kt)("p",null,"In our ",(0,a.kt)("inlineCode",{parentName:"p"},"index.js")," we'll add an arbitrary piece of text:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-jsx"}),"<p>I'm a staging environment!</p>\n")),(0,a.kt)("p",null,"Then we'll commit and push our branch to GitHub and create a pull request. This triggers our GitHub Action to run once again. But this time, rather than publishing over our existing Static Web App, it's going to spin up a brand new one with our changes in. Not only that, it's going to put a link for us in our GitHub pull request so we can browse straight to it:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the pull request in GitHub including a comment from the GitHub Actions bot which says: &quot;Azure Static Web Apps: Your stage site is ready! Visit it here: https://ambitious-island-05069ea10-2.centralus.azurestaticapps.net&quot;",src:n(3735).Z,width:"2097",height:"1170"})),(0,a.kt)("p",null,"This is the equivalent of Netlify Deploy Previews, implemented with Azure Static Web Apps and GitHub Actions. Given the allowances for GitHub Actions currently sit at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.github.com/en/billing/managing-billing-for-github-actions/about-billing-for-github-actions"}),"2,000 free minutes per month")," as compared with Netlify's ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.netlify.com/pricing/"}),"300 free minutes per month"),", you're less likely to receive a bill for using Static Web Apps."),(0,a.kt)("p",null,"This staging environment will last only until the pull request is closed. At that point the environment is torn down by the GitHub Action."),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"In this post we've deployed a website to a Static Web App using GitHub Actions and implemented authentication. We've also demonstrated Azure's equivalent of Netlify's deploy previews; staging environments."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/azure-static-web-apps-netlify-alternative/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/azure-static-web-apps-netlify-alternative/"})))}d.isMDXComponent=!0},79408:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"swashbuckle-inheritance-multiple-return-types",title:"Swashbuckle & inheritance: Give. Me. The. Types",authors:"johnnyreilly",tags:["Swashbuckle",".NET"],image:"./title-image.png",description:"For API endpoints that return multiple types, you can use inheritance with Swashbuckle to get create a Swagger / Open API definition; here is how.",hide_table_of_contents:!1},s=void 0,l={permalink:"/swashbuckle-inheritance-multiple-return-types",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-03-06-swashbuckle-inheritance-multiple-return-types/index.md",source:"@site/blog/2022-03-06-swashbuckle-inheritance-multiple-return-types/index.md",title:"Swashbuckle & inheritance: Give. Me. The. Types",description:"For API endpoints that return multiple types, you can use inheritance with Swashbuckle to get create a Swagger / Open API definition; here is how.",date:"2022-03-06T00:00:00.000Z",formattedDate:"March 6, 2022",tags:[{label:"Swashbuckle",permalink:"/tags/swashbuckle"},{label:".NET",permalink:"/tags/net"}],readingTime:5.56,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"swashbuckle-inheritance-multiple-return-types",title:"Swashbuckle & inheritance: Give. Me. The. Types",authors:"johnnyreilly",tags:["Swashbuckle",".NET"],image:"./title-image.png",description:"For API endpoints that return multiple types, you can use inheritance with Swashbuckle to get create a Swagger / Open API definition; here is how.",hide_table_of_contents:!1},prevItem:{title:"Lighthouse meet GitHub Actions",permalink:"/lighthouse-meet-github-actions"},nextItem:{title:"Azure Static Web Apps - a Netlify alternative",permalink:"/azure-static-web-apps-a-netlify-alternative"}},p={image:n(19251).Z,authorsImageUrls:[void 0]},u=[{value:"Making a simple API",id:"making-a-simple-api",level:2},{value:"Multiple return types",id:"multiple-return-types",level:2},{value:"Serving up subtypes",id:"serving-up-subtypes",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"For API endpoints that return multiple types, you can use inheritance with Swashbuckle to get create a Swagger / Open API definition featuring the variety of available types. Serving all these types is not the default behaviour. This post shows you how to opt in."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Swashbuckle and inheritance: Give. Me. The. Types&quot; with Sid Swashbuckle the Pirate and Open API logos",src:n(19251).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"making-a-simple-api"}),"Making a simple API"),(0,a.kt)("p",null,"The first thing we're going to need is an API, which we'll build with the .NET 6 SDK:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"dotnet new webapi\ndotnet add package Swashbuckle.AspNetCore\n")),(0,a.kt)("p",null,"When we run this with ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet run")," we find Swashbuckle living at http://localhost:5000/swagger/index.html defining our web api that serves up a WeatherForecast:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of swagger UI including `WeatherForecast`",src:n(81410).Z,width:"1289",height:"1232"})),(0,a.kt)("p",null,"If we look at the ",(0,a.kt)("inlineCode",{parentName:"p"},"swagger.json")," created at our ",(0,a.kt)("inlineCode",{parentName:"p"},"http://localhost:5000/swagger/v1/swagger.json")," endpoint we see the following definition:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "openapi": "3.0.1",\n  "info": {\n    "title": "SwashbuckleInheritance",\n    "version": "1.0"\n  },\n  "paths": {\n    "/WeatherForecast": {\n      "get": {\n        "tags": ["WeatherForecast"],\n        "operationId": "GetWeatherForecast",\n        "responses": {\n          "200": {\n            "description": "Success",\n            "content": {\n              "text/plain": {\n                "schema": {\n                  "type": "array",\n                  "items": {\n                    "$ref": "#/components/schemas/WeatherForecast"\n                  }\n                }\n              },\n              "application/json": {\n                "schema": {\n                  "type": "array",\n                  "items": {\n                    "$ref": "#/components/schemas/WeatherForecast"\n                  }\n                }\n              },\n              "text/json": {\n                "schema": {\n                  "type": "array",\n                  "items": {\n                    "$ref": "#/components/schemas/WeatherForecast"\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  },\n  "components": {\n    "schemas": {\n      "WeatherForecast": {\n        "type": "object",\n        "properties": {\n          "date": {\n            "type": "string",\n            "format": "date-time"\n          },\n          "temperatureC": {\n            "type": "integer",\n            "format": "int32"\n          },\n          "temperatureF": {\n            "type": "integer",\n            "format": "int32",\n            "readOnly": true\n          },\n          "summary": {\n            "type": "string",\n            "nullable": true\n          }\n        },\n        "additionalProperties": false\n      }\n    }\n  }\n}\n')),(0,a.kt)("p",null,"Only a single return type is defined: ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecast"),"."),(0,a.kt)("h2",o({},{id:"multiple-return-types"}),"Multiple return types"),(0,a.kt)("p",null,"Now we've got our simple API, let's evolve it to serve up multiple types. We're going to do this by updating our ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecast.cs")," as follows:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public class WeatherForecast\n{\n    public DateTime Date { get; set; }\n\n    public int TemperatureC { get; set; }\n\n    public int TemperatureF => 32 + (int)(TemperatureC / 0.5556);\n\n    public string? Summary { get; set; }\n}\n\npublic class WeatherForecastWithLocation : WeatherForecast\n{\n    public string? Location { get; set; }\n}\n")),(0,a.kt)("p",null,"We now have both a ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecast")," and a ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecastWithLocation")," that inherits from ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecast")," and adds in a ",(0,a.kt)("inlineCode",{parentName:"p"},"Location")," property."),(0,a.kt)("p",null,"We'll also update the ",(0,a.kt)("inlineCode",{parentName:"p"},"GetWeatherForecast")," endpoint to surface both these types:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[HttpGet(Name = "GetWeatherForecast")]\npublic IEnumerable<WeatherForecast> Get() =>\n    DateTime.Now.Minute < 30\n        ? Enumerable.Range(1, 5).Select(index => new WeatherForecast\n        {\n            Date = DateTime.Now.AddDays(index),\n            TemperatureC = Random.Shared.Next(-20, 55),\n            Summary = Summaries[Random.Shared.Next(Summaries.Length)]\n        })\n        : Enumerable.Range(1, 5).Select(index => new WeatherForecastWithLocation\n        {\n            Date = DateTime.Now.AddDays(index),\n            TemperatureC = Random.Shared.Next(-20, 55),\n            Summary = Summaries[Random.Shared.Next(Summaries.Length)],\n            Location = "London"\n        })\n        .ToArray();\n')),(0,a.kt)("p",null,"We've amended the endpoint to return ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecast"),"s for the first thirty minutes of each hour, and ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecastWithLocation"),"s for the second thirty minutes. This is plainly a contrived example, but it demonstrates what it looks like to have an API endpoint with multiple return types."),(0,a.kt)("p",null,"Incidentally, the reason we're able to achieve this without the compiler shouting at us is because our endpoint is saying it returns a ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecast")," and that is the base type of ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecastWithLocation")," as well."),(0,a.kt)("p",null,"To prove that it works, we wait for half past the hour and enter:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"curl -X 'GET' 'http://localhost:5000/WeatherForecast'\n")),(0,a.kt)("p",null,"We see back JSON that includes the ",(0,a.kt)("inlineCode",{parentName:"p"},"Location")," property. Huzzah!"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'[\n  {\n    "location": "London",\n    "date": "2022-03-07T08:51:02.0932353+00:00",\n    "temperatureC": -4,\n    "temperatureF": 25,\n    "summary": "Bracing"\n  },\n  {\n    "location": "London",\n    "date": "2022-03-08T08:51:02.0938418+00:00",\n    "temperatureC": -5,\n    "temperatureF": 24,\n    "summary": "Balmy"\n  },\n  {\n    "location": "London",\n    "date": "2022-03-09T08:51:02.0938513+00:00",\n    "temperatureC": 51,\n    "temperatureF": 123,\n    "summary": "Warm"\n  },\n  {\n    "location": "London",\n    "date": "2022-03-10T08:51:02.0938518+00:00",\n    "temperatureC": 35,\n    "temperatureF": 94,\n    "summary": "Warm"\n  },\n  {\n    "location": "London",\n    "date": "2022-03-11T08:51:02.0938537+00:00",\n    "temperatureC": 2,\n    "temperatureF": 35,\n    "summary": "Cool"\n  }\n]\n')),(0,a.kt)("p",null,"Whilst we've got behaviour that handles multiple return types, what we don't have is Swagger / Open API that represents that. Despite our tweaks, our Swagger / Open API definition remains unchanged."),(0,a.kt)("h2",o({},{id:"serving-up-subtypes"}),"Serving up subtypes"),(0,a.kt)("p",null,"In a perfect world, C# would have support for discriminated unions, and we'd be using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://swagger.io/docs/specification/data-models/oneof-anyof-allof-not/"}),(0,a.kt)("inlineCode",{parentName:"a"},"oneOf"))," to represent the multiple types being surfaced. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dotnet/csharplang/issues/113"}),"The day may come where C# supports discriminated unions"),", but until that time we'll be achieving this behaviour with inheritance. We do this by having an endpoint that surfaces up a base type, and all our possible return types must either subclass that base type, or be that base type."),(0,a.kt)("p",null,"To be clearer: we want our served up Swagger / Open API definition to serve up the definitions of our subclasses. It needs to shout about ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecastWithLocation")," in the same way it shouts about ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecast"),"."),(0,a.kt)("p",null,"It turns out that this is eminently achievable with Swashbuckle, but you do need to know where to look. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/domaindrivendev/Swashbuckle.AspNetCore#describing-discriminators"}),"Look here"),"."),(0,a.kt)("p",null,"To apply this tweak to our own ",(0,a.kt)("inlineCode",{parentName:"p"},"Program.cs")," we simply update the ",(0,a.kt)("inlineCode",{parentName:"p"},"AddSwaggerGen")," as follows:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"builder.Services.AddSwaggerGen(swaggerGenOptions =>\n{\n    swaggerGenOptions.UseAllOfForInheritance();\n    swaggerGenOptions.UseOneOfForPolymorphism();\n\n    swaggerGenOptions.SelectSubTypesUsing(baseType =>\n        typeof(Program).Assembly.GetTypes().Where(type => type.IsSubclassOf(baseType))\n    );\n});\n")),(0,a.kt)("p",null,"There's three things we're doing here:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"With ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/domaindrivendev/Swashbuckle.AspNetCore#enabling-inheritance"}),(0,a.kt)("inlineCode",{parentName:"a"},"UseAllOfForInheritance"))," we're enabling inheritance - this allows us to maintain the inheritance hierarchy in any generated client models."),(0,a.kt)("li",{parentName:"ol"},"With ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/domaindrivendev/Swashbuckle.AspNetCore#enabling-polymorphism"}),(0,a.kt)("inlineCode",{parentName:"a"},"UseOneOfForPolymorphism"))," we're listing the possible subtypes for an action that accepts/returns base types."),(0,a.kt)("li",{parentName:"ol"},"With ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/domaindrivendev/Swashbuckle.AspNetCore#detecting-subtypes"}),(0,a.kt)("inlineCode",{parentName:"a"},"SelectSubTypesUsing"))," we're pointing Swashbuckle at the type hierarchies it exposes in the generated Swagger.")),(0,a.kt)("p",null,"Then next time we ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet run")," we see that we're serving up both ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecast")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecastWithLocation"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of swagger UI including `WeatherForecast` and `WeatherForecastWithLocation`",src:n(45752).Z,width:"1282",height:"1184"})),(0,a.kt)("p",null,"We can also see this directly in the ",(0,a.kt)("inlineCode",{parentName:"p"},"swagger.json")," created at our ",(0,a.kt)("inlineCode",{parentName:"p"},"http://localhost:5000/swagger/v1/swagger.json")," endpoint:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "openapi": "3.0.1",\n  "info": {\n    "title": "SwashbuckleInheritance",\n    "version": "1.0"\n  },\n  "paths": {\n    "/WeatherForecast": {\n      "get": {\n        "tags": ["WeatherForecast"],\n        "operationId": "GetWeatherForecast",\n        "responses": {\n          "200": {\n            "description": "Success",\n            "content": {\n              "text/plain": {\n                "schema": {\n                  "type": "array",\n                  "items": {\n                    "oneOf": [\n                      {\n                        "$ref": "#/components/schemas/WeatherForecast"\n                      },\n                      {\n                        "$ref": "#/components/schemas/WeatherForecastWithLocation"\n                      }\n                    ]\n                  }\n                }\n              },\n              "application/json": {\n                "schema": {\n                  "type": "array",\n                  "items": {\n                    "oneOf": [\n                      {\n                        "$ref": "#/components/schemas/WeatherForecast"\n                      },\n                      {\n                        "$ref": "#/components/schemas/WeatherForecastWithLocation"\n                      }\n                    ]\n                  }\n                }\n              },\n              "text/json": {\n                "schema": {\n                  "type": "array",\n                  "items": {\n                    "oneOf": [\n                      {\n                        "$ref": "#/components/schemas/WeatherForecast"\n                      },\n                      {\n                        "$ref": "#/components/schemas/WeatherForecastWithLocation"\n                      }\n                    ]\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  },\n  "components": {\n    "schemas": {\n      "WeatherForecast": {\n        "type": "object",\n        "properties": {\n          "date": {\n            "type": "string",\n            "format": "date-time"\n          },\n          "temperatureC": {\n            "type": "integer",\n            "format": "int32"\n          },\n          "temperatureF": {\n            "type": "integer",\n            "format": "int32",\n            "readOnly": true\n          },\n          "summary": {\n            "type": "string",\n            "nullable": true\n          }\n        },\n        "additionalProperties": false\n      },\n      "WeatherForecastWithLocation": {\n        "type": "object",\n        "allOf": [\n          {\n            "$ref": "#/components/schemas/WeatherForecast"\n          }\n        ],\n        "properties": {\n          "location": {\n            "type": "string",\n            "nullable": true\n          }\n        },\n        "additionalProperties": false\n      }\n    }\n  }\n}\n')),(0,a.kt)("p",null,"There's two things to note about the new definition:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"The ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecastWithLocation")," type is included in the ",(0,a.kt)("inlineCode",{parentName:"p"},"schemas"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"The return type has widened to include ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecastWithLocation")," as well using ",(0,a.kt)("inlineCode",{parentName:"p"},"oneOf")),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'"oneOf": [\n    {\n        "$ref": "#/components/schemas/WeatherForecast"\n    },\n    {\n        "$ref": "#/components/schemas/WeatherForecastWithLocation"\n    }\n]\n')))),(0,a.kt)("p",null,"Success!"))}d.isMDXComponent=!0},31345:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"lighthouse-meet-github-actions",title:"Lighthouse meet GitHub Actions",authors:"johnnyreilly",tags:["Azure Static Web Apps","GitHub Actions","Docusaurus"],image:"./title-image.png",description:"This post illustrates how to integrate Lighthouse into a GitHub Actions workflow for an Azure Static Web App.",hide_table_of_contents:!1},s=void 0,l={permalink:"/lighthouse-meet-github-actions",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-03-20-lighthouse-meet-github-actions/index.md",source:"@site/blog/2022-03-20-lighthouse-meet-github-actions/index.md",title:"Lighthouse meet GitHub Actions",description:"This post illustrates how to integrate Lighthouse into a GitHub Actions workflow for an Azure Static Web App.",date:"2022-03-20T00:00:00.000Z",formattedDate:"March 20, 2022",tags:[{label:"Azure Static Web Apps",permalink:"/tags/azure-static-web-apps"},{label:"GitHub Actions",permalink:"/tags/git-hub-actions"},{label:"Docusaurus",permalink:"/tags/docusaurus"}],readingTime:11.765,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"lighthouse-meet-github-actions",title:"Lighthouse meet GitHub Actions",authors:"johnnyreilly",tags:["Azure Static Web Apps","GitHub Actions","Docusaurus"],image:"./title-image.png",description:"This post illustrates how to integrate Lighthouse into a GitHub Actions workflow for an Azure Static Web App.",hide_table_of_contents:!1},prevItem:{title:"Azure DevOps: consume a private artifact feed",permalink:"/azure-devops-consume-private-nuget-artifact-feed"},nextItem:{title:"Swashbuckle & inheritance: Give. Me. The. Types",permalink:"/swashbuckle-inheritance-multiple-return-types"}},p={image:n(48203).Z,authorsImageUrls:[void 0]},u=[{value:"What we&#39;ll do",id:"what-well-do",level:2},{value:"Create our application",id:"create-our-application",level:2},{value:"Creating a Static Web App in Azure",id:"creating-a-static-web-app-in-azure",level:2},{value:"Preparing to plug in Lighthouse",id:"preparing-to-plug-in-lighthouse",level:2},{value:"Custom domain",id:"custom-domain",level:3},{value:"Location",id:"location",level:3},{value:"Plugging in Lighthouse",id:"plugging-in-lighthouse",level:2},{value:"Static Web App - get preview URL",id:"static-web-app---get-preview-url",level:3},{value:"Static Web App - wait for preview",id:"static-web-app---wait-for-preview",level:3},{value:"Audit URLs using Lighthouse",id:"audit-urls-using-lighthouse",level:3},{value:"Format lighthouse score",id:"format-lighthouse-score",level:3},{value:"Add Lighthouse stats as comment",id:"add-lighthouse-stats-as-comment",level:3},{value:"Putting it all together",id:"putting-it-all-together",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Lighthouse is a tremendous tool for auditing the performance and usability of websites. Rather than having to perform these audits manually, it's helpful to be able to plug it into your CI pipeline. This post illustrates how to integrate Lighthouse into a GitHub Actions workflow for an Azure Static Web App, and report findings directly in pull requests that are raised."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Lighthouse meet GitHub Actions&quot; with the Lighthouse logo and a screenshot of the results in a GitHub comment`",src:n(48203).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"what-well-do"}),"What we'll do"),(0,a.kt)("p",null,"This post isn't a walkthrough of how to use Lighthouse effectively. There is already ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/lighthouse-and-how-to-use-it-more-effectively/"}),"great guidance out there on this topic"),"."),(0,a.kt)("p",null,"Instead, we're going build a simple web application, in the context of a GitHub repo. We'll wire it up to deploy via GitHub Actions to Azure Static Web Apps. Static Web Apps is a free hosting option for static websites and it comes with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/static-web-apps/review-publish-pull-requests"}),"staging environments")," or deployment previews built in. This feature deploys a fully functional version of a site each time a pull request is raised, built upon the changes implemented in that pull request."),(0,a.kt)("p",null,"The staging environment is a perfect place to implement our Lighthouse checks. If a pull request impacts usability or performance, seeing those details in the context of our pull request is exactly where we'd like to learn this. This kind of check gives us the opportunity to ensure we only merge when we're happy that the changes do not negatively impact our Lighthouse scores."),(0,a.kt)("p",null,"In this post we'll start from the point of an empty GitHub repo and build up from there."),(0,a.kt)("h2",o({},{id:"create-our-application"}),"Create our application"),(0,a.kt)("p",null,"Inside the root of our repository we're going to create a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/"}),"Docusaurus site"),". Docusaurus is a good example of a static site, the kind of which is a natural fit for Jamstack. We could equally use something else like ",(0,a.kt)("a",o({parentName:"p"},{href:"https://gohugo.io/"}),"Hugo")," for instance."),(0,a.kt)("p",null,"At the command line we'll enter:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"npx create-docusaurus@latest website classic\n")),(0,a.kt)("p",null,"And Docusaurus will create a new site in the ",(0,a.kt)("inlineCode",{parentName:"p"},"website")," directory. Let's commit and push this and turn our attention to Azure."),(0,a.kt)("h2",o({},{id:"creating-a-static-web-app-in-azure"}),"Creating a Static Web App in Azure"),(0,a.kt)("p",null,"There's a number of ways to create a Static Web App in Azure. It's possible to use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.johnnyreilly.com/2021/08/15/bicep-azure-static-web-apps-azure-devops#bicep-template"}),"infrastructure as code with a language like Bicep"),". But for this post let's use the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://portal.azure.com"}),"Azure Portal")," instead. If you don't have an account already, you can set one up for free very quickly."),(0,a.kt)("p",null,'Once you\'ve logged in, click "Create a resource" and look up Static Web App:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the Azure Portal, &quot;Create a resource&quot; Azure Static Web Apps section",src:n(14748).Z,width:"1073",height:"640"})),(0,a.kt)("p",null,'Click on "Create" and you\'ll be take to the creation dialog:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the Azure Portal, &quot;Create a resource&quot; Azure Static Web Apps dialog",src:n(40494).Z,width:"1218",height:"1429"})),(0,a.kt)("p",null,'You\'ll need to create a resource group for your SWA to live in, give the app a name, the "Free" plan and a deployment source of GitHub.'),(0,a.kt)("p",null,'Click on the "Sign in with GitHub" button and authorize Azure to access your GitHub account for Static Web Apps.'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the Azure Portal, &quot;Create a resource&quot; Azure Static Web Apps dialog - repository settings",src:n(97541).Z,width:"1182",height:"1425"})),(0,a.kt)("p",null,"At this point Azure will query GitHub on your behalf and look up the organisations and repositories you have access to. Select the repository that you'd like to deploy to your Static Web App and select the branch you'd like to deploy."),(0,a.kt)("p",null,'You also need to provide Azure with some build details that help it understand how your app is built. We\'ll provide a preset of "Custom". We\'ll set the "App location" (the root of our front end app) to be ',(0,a.kt)("inlineCode",{parentName:"p"},'"/website"')," to tally up with the application we just created. We'll leave \"Api location\" blank and we'll set the output location to be ",(0,a.kt)("inlineCode",{parentName:"p"},'"build"')," - this is the directory under ",(0,a.kt)("inlineCode",{parentName:"p"},"website")," where Docusaurus will create our site."),(0,a.kt)("p",null,'Finally click "Review + create" and then "Create".'),(0,a.kt)("p",null,"Azure will now:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Create an Azure Static Web app resource in Azure"),(0,a.kt)("li",{parentName:"ul"},"Update your repository to add a GitHub Actions workflow to deploy your static web app"),(0,a.kt)("li",{parentName:"ul"},"Kick off a first run of the GitHub Actions workflow to deploy your SWA.")),(0,a.kt)("p",null,"Pretty amazing, right?"),(0,a.kt)("p",null,"When you look at the resource in Azure it will look something like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the Azure Portal, your Azure Static Web Apps resource",src:n(6723).Z,width:"1426",height:"715"})),(0,a.kt)("p",null,"If you click on the GitHub Action runs you'll be presented with your GitHub Action:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the GitHub Action",src:n(2858).Z,width:"1433",height:"1097"})),(0,a.kt)("p",null,"And when that finishes running you'll be able to see your deployed Static Web App by clicking on the URL in the Azure Portal:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of your Static Web App running in a browser",src:n(38666).Z,width:"1573",height:"1140"})),(0,a.kt)("p",null,"We now have:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"a GitHub repo"),(0,a.kt)("li",{parentName:"ul"},"which contains a simple web application"),(0,a.kt)("li",{parentName:"ul"},"and a GitHub Actions workflow which:",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"deploys to an Azure Static Web App"),(0,a.kt)("li",{parentName:"ul"},"spins up a staging environment for pull requests")))),(0,a.kt)("h2",o({},{id:"preparing-to-plug-in-lighthouse"}),"Preparing to plug in Lighthouse"),(0,a.kt)("p",null,"With this groundwork in place we're ready to add Lighthouse into the mix. If you look in the ",(0,a.kt)("inlineCode",{parentName:"p"},"/.github/workflows")," folder of your repo, you'll find a workflow file with contents along these lines:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"name: Azure Static Web Apps CI/CD\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    types: [opened, synchronize, reopened, closed]\n    branches:\n      - main\n\njobs:\n  build_and_deploy_job:\n    if: github.event_name == 'push' || (github.event_name == 'pull_request' && github.event.action != 'closed')\n    runs-on: ubuntu-latest\n    name: Build and Deploy Job\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: true\n\n      - name: Build And Deploy\n        id: builddeploy\n        uses: Azure/static-web-apps-deploy@v1\n        with:\n          azure_static_web_apps_api_token: ${{ secrets.AZURE_STATIC_WEB_APPS_API_TOKEN_AGREEABLE_ROCK_039A51810 }}\n          repo_token: ${{ secrets.GITHUB_TOKEN }} # Used for Github integrations (i.e. PR comments)\n          action: 'upload'\n          ###### Repository/Build Configurations - These values can be configured to match your app requirements. ######\n          # For more information regarding Static Web App workflow configurations, please visit: https://aka.ms/swaworkflowconfig\n          app_location: '/website' # App source code path\n          api_location: '' # Api source code path - optional\n          output_location: 'build' # Built app content directory - optional\n          ###### End of Repository/Build Configurations ######\n\n  close_pull_request_job:\n    if: github.event_name == 'pull_request' && github.event.action == 'closed'\n    runs-on: ubuntu-latest\n    name: Close Pull Request Job\n    steps:\n      - name: Close Pull Request\n        id: closepullrequest\n        uses: Azure/static-web-apps-deploy@v1\n        with:\n          azure_static_web_apps_api_token: ${{ secrets.AZURE_STATIC_WEB_APPS_API_TOKEN_AGREEABLE_ROCK_039A51810 }}\n          action: 'close'\n")),(0,a.kt)("p",null,"This was created for us when we set up our SWA in Azure. We're now going to update the contents to add some Lighthouse jobs."),(0,a.kt)("p",null,"Before we do that, we need to acquire two things:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"the custom domain of our static web app"),(0,a.kt)("li",{parentName:"ol"},"the location of the resource group where the SWA resides")),(0,a.kt)("p",null,"These two pieces of information are required such that we can determine the URL of our staging environments."),(0,a.kt)("h3",o({},{id:"custom-domain"}),"Custom domain"),(0,a.kt)("p",null,'We acquire the custom domain of our static web app in the "Custom Domains" screen of the Azure Portal:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the custom domain screen in the Azure Portal",src:n(69271).Z,width:"2043",height:"589"})),(0,a.kt)("p",null,"The custom domain is the auto-generated custom domain - it's highlighted in the screenshot above. For the SWA we're building here the custom domain is ",(0,a.kt)("inlineCode",{parentName:"p"},"agreeable-rock-039a51810.1.azurestaticapps.net"),"."),(0,a.kt)("h3",o({},{id:"location"}),"Location"),(0,a.kt)("p",null,'We acquire the location by looking at the resource group in the Azure Portal. For the SWA we\'ve been building the location is "Central US". However, rather than the "display name" variant of the location, what we want is the "code" which will be used in the URL. You can see what this is by clicking on the "JSON view" in the Azure Portal:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the resource group JSON view with location highlighted",src:n(18611).Z,width:"2505",height:"598"})),(0,a.kt)("p",null,"As the screenshot above demonstrates, the code we need is ",(0,a.kt)("inlineCode",{parentName:"p"},"centralus"),"."),(0,a.kt)("h2",o({},{id:"plugging-in-lighthouse"}),"Plugging in Lighthouse"),(0,a.kt)("p",null,"We now have all we need to plug in Lighthouse. Let's create a branch:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"git checkout -b lighthouse\n")),(0,a.kt)("p",null,'We\'re going to add a new "Lighthouse report" job to our GitHub Actions workflow file:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"env:\n  RESOURCE_GROUP: rg-blog-johnnyreilly-com\n  LOCATION: westeurope\n  STATICWEBAPPNAME: blog.johnnyreilly.com\n\nlighthouse_report_job:\n  name: Lighthouse report\n  if: github.event_name == 'pull_request' && github.event.action != 'closed'\n  runs-on: ubuntu-latest\n  steps:\n    - uses: actions/checkout@v2\n\n    # Auth between GitHub and Azure is handled by https://github.com/jongio/github-azure-oidc\n    # https://github.com/Azure/login#sample-workflow-that-uses-azure-login-action-using-oidc-to-run-az-cli-linux\n    # other login options are possible too\n    - name: AZ CLI login \ud83d\udd11\n      uses: azure/login@v1\n      with:\n        client-id: ${{ secrets.AZURE_CLIENT_ID }}\n        tenant-id: ${{ secrets.AZURE_TENANT_ID }}\n        subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\n\n    - name: Static Web App - get preview URL\n      id: static_web_app_preview_url\n      uses: azure/CLI@v1\n      with:\n        inlineScript: |\n          DEFAULTHOSTNAME=$(az staticwebapp show -n '${{ env.STATICWEBAPPNAME }}' | jq -r '.defaultHostname')\n\n          PREVIEW_URL=\"https://${DEFAULTHOSTNAME/.[1-9]./-${{github.event.pull_request.number }}.${{ env.LOCATION }}.1.}\"\n\n          echo \"PREVIEW_URL=$PREVIEW_URL\" >> $GITHUB_OUTPUT\n\n    - name: Static Web App - wait for preview\n      id: static_web_app_wait_for_preview\n      uses: nev7n/wait_for_response@v1\n      with:\n        url: '${{ steps.static_web_app_preview_url.outputs.PREVIEW_URL }}'\n        responseCode: 200\n        timeout: 600000\n        interval: 1000\n\n    - name: Audit URLs using Lighthouse\n      id: lighthouse_audit\n      uses: treosh/lighthouse-ci-action@v8\n      with:\n        urls: |\n          ${{ steps.static_web_app_preview_url.outputs.PREVIEW_URL }}\n        configPath: ./.github/workflows/lighthousesrc.json\n        uploadArtifacts: true\n        temporaryPublicStorage: true\n        runs: 5\n\n    - name: Format lighthouse score\n      id: format_lighthouse_score\n      uses: actions/github-script@v5\n      with:\n        script: |\n          const lighthouseCommentMaker = require('./.github/workflows/lighthouseCommentMaker.js');\n\n          const lighthouseOutputs = {\n            manifest: ${{ steps.lighthouse_audit.outputs.manifest }},\n            links: ${{ steps.lighthouse_audit.outputs.links }}\n          };\n\n          const comment = lighthouseCommentMaker({ lighthouseOutputs });\n          core.setOutput(\"comment\", comment);\n\n    - name: Add Lighthouse stats as comment\n      id: comment_to_pr\n      uses: marocchino/sticky-pull-request-comment@v2.0.0\n      with:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        number: ${{ github.event.pull_request.number }}\n        header: lighthouse\n        message: ${{ steps.format_lighthouse_score.outputs.comment }}\n")),(0,a.kt)("p",null,"There's a number of things happening in this workflow. Let's walk through them."),(0,a.kt)("h3",o({},{id:"static-web-app---get-preview-url"}),"Static Web App - get preview URL"),(0,a.kt)("p",null,"Here we acquire the preview URL of our static web app using:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"the default host name of the static web app"),(0,a.kt)("li",{parentName:"ul"},"the location"),(0,a.kt)("li",{parentName:"ul"},"the pull request number eg 123")),(0,a.kt)("p",null,"Given a default host name of ",(0,a.kt)("inlineCode",{parentName:"p"},"agreeable-rock-039a51810"),", a location of ",(0,a.kt)("inlineCode",{parentName:"p"},"centralus")," and a pull request number of ",(0,a.kt)("inlineCode",{parentName:"p"},"123"),", the preview url would be ",(0,a.kt)("inlineCode",{parentName:"p"},"agreeable-rock-039a51810-123.centralus.1.azurestaticapps.net"),". Using a little bash magic we create an output variable named ",(0,a.kt)("inlineCode",{parentName:"p"},"PREVIEW_URL")," containing that value. We'll re-use it later in the workflow."),(0,a.kt)("h3",o({},{id:"static-web-app---wait-for-preview"}),"Static Web App - wait for preview"),(0,a.kt)("p",null,"We don't want to run our test until the static web app is up and running. To cater for this we're going to pull in the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/nev7n/wait_for_response"}),(0,a.kt)("inlineCode",{parentName:"a"},"wait_for_response"))," GitHub Action. This polls until a website returns a ",(0,a.kt)("inlineCode",{parentName:"p"},"200"),", we're going to point it at our SWA."),(0,a.kt)("h3",o({},{id:"audit-urls-using-lighthouse"}),"Audit URLs using Lighthouse"),(0,a.kt)("p",null,"The big moment has arrived! We're going to plug Lighthouse into our workflow using the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/treosh/lighthouse-ci-action"}),(0,a.kt)("inlineCode",{parentName:"a"},"lighthouse-ci-action"))," GitHub Action."),(0,a.kt)("p",null,"We provide a ",(0,a.kt)("inlineCode",{parentName:"p"},"configPath: ./.github/workflows/lighthousesrc.json")," which points to file that configures our Lighthouse configuration. We'll create that file as well and populate it with this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "ci": {\n    "collect": {\n      "settings": {\n        "configPath": "./.github/workflows/lighthouse-config.js"\n      }\n    }\n  }\n}\n')),(0,a.kt)("p",null,"This in turn hands off the specific configuration to a ",(0,a.kt)("inlineCode",{parentName:"p"},"lighthouse-config.js")," file that we also need to create:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"// see https://github.com/GoogleChrome/lighthouse/blob/master/docs/configuration.md\nmodule.exports = {\n  extends: 'lighthouse:default',\n  settings: {\n    // audits can be found here:\n    // https://github.com/GoogleChrome/lighthouse/blob/eba2a4d19c5786dc37e993858ff4b663181f81e5/lighthouse-core/config/default-config.js#L174\n    skipAudits: [\n      'canonical', // for staging sites this will always be incorrect\n      'maskable-icon',\n      'valid-source-maps',\n      'unsized-images',\n      'offline-start-url',\n    ],\n  },\n};\n")),(0,a.kt)("p",null,"The configuration above can be amended based upon the various links in the comments. Generally it's a good idea to roll with the defaults; however skipping the ",(0,a.kt)("inlineCode",{parentName:"p"},"canonical")," audit is sensible as it will reliably be incorrect for staging sites."),(0,a.kt)("p",null,"Along side the Lighthouse configuration, there's config for the GitHub Action itself:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"uploadArtifacts: true")," - will save results as an action artifacts"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"temporaryPublicStorage: true")," - will upload lighthouse report to the temporary storage"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"runs: 5")," - will run Lighthouse 5 times to get more reliable performance results")),(0,a.kt)("h3",o({},{id:"format-lighthouse-score"}),"Format lighthouse score"),(0,a.kt)("p",null,"We've run Lighthouse at this point. What we want to do next is take the results of the run and build up some text that we can add to our pull request as a comment."),(0,a.kt)("p",null,"For this we're going to use the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/actions/github-script"}),(0,a.kt)("inlineCode",{parentName:"a"},"github-script"))," GitHub Action, grab the outputs of the previous step and call out to a ",(0,a.kt)("inlineCode",{parentName:"p"},"lighthouseCommentMaker.js")," file we're going to write to make the comment we'd like to publish to our PR:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"// @ts-check\n\n/**\n * @typedef {Object} Summary\n * @prop {number} performance\n * @prop {number} accessibility\n * @prop {number} best-practices\n * @prop {number} seo\n * @prop {number} pwa\n */\n\n/**\n * @typedef {Object} Manifest\n * @prop {string} url\n * @prop {boolean} isRepresentativeRun\n * @prop {string} htmlPath\n * @prop {string} jsonPath\n * @prop {Summary} summary\n */\n\n/**\n * @typedef {Object} LighthouseOutputs\n * @prop {Record<string, string>} links\n * @prop {Manifest[]} manifest\n */\n\nconst formatScore = (/** @type { number } */ score) => Math.round(score * 100);\nconst emojiScore = (/** @type { number } */ score) =>\n  score >= 0.9 ? '\ud83d\udfe2' : score >= 0.5 ? '\ud83d\udfe0' : '\ud83d\udd34';\n\nconst scoreRow = (\n  /** @type { string } */ label,\n  /** @type { number } */ score\n) => `| ${emojiScore(score)} ${label} | ${formatScore(score)} |`;\n\n/**\n * @param {LighthouseOutputs} lighthouseOutputs\n */\nfunction makeComment(lighthouseOutputs) {\n  const { summary } = lighthouseOutputs.manifest[0];\n  const [[testedUrl, reportUrl]] = Object.entries(lighthouseOutputs.links);\n\n  const comment = `## \u26a1\ufe0f\ud83c\udfe0 Lighthouse report\n\nWe ran Lighthouse against the changes and produced this [report](${reportUrl}). Here's the summary:\n\n| Category | Score |\n| -------- | ----- |\n${scoreRow('Performance', summary.performance)}\n${scoreRow('Accessibility', summary.accessibility)}\n${scoreRow('Best practices', summary['best-practices'])}\n${scoreRow('SEO', summary.seo)}\n${scoreRow('PWA', summary.pwa)}\n\n*Lighthouse ran against [${testedUrl}](${testedUrl})*\n`;\n\n  return comment;\n}\n\nmodule.exports = ({ lighthouseOutputs }) => {\n  return makeComment(lighthouseOutputs);\n};\n")),(0,a.kt)("p",null,"The above code takes the Lighthouse outputs and creates some Markdown to represent the results. It uses some nice emoji as well. Wonderfully, we're entirely free to customise this as much as we'd like; it's just code! All that matters is that a string is pumped out at the end."),(0,a.kt)("h3",o({},{id:"add-lighthouse-stats-as-comment"}),"Add Lighthouse stats as comment"),(0,a.kt)("p",null,"Finally we're ready to add the comment to the PR. We'll do this using the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/marocchino/sticky-pull-request-comment"}),(0,a.kt)("inlineCode",{parentName:"a"},"sticky-pull-request-comment"))," GitHub Action. We pass in the comment we've just made in the previous step, as well as some other parameters, and this will write the comment to the PR."),(0,a.kt)("h2",o({},{id:"putting-it-all-together"}),"Putting it all together"),(0,a.kt)("p",null,"When we commit our changes and raise a pull request, we see our GitHub Action run, and then once it has we see a Lighthouse report being attached to our pull request:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of GitHub pull request showing the Lighthouse results as a comment",src:n(56693).Z,width:"1857",height:"1082"})),(0,a.kt)("p",null,"Note you can also click on a link in the comment to go directly to the full report."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Lighthouse report",src:n(9227).Z,width:"3008",height:"1441"})),(0,a.kt)("p",null,"Now, with each PR that is raised, any regressions in performance can be observed and resolved ",(0,a.kt)("em",{parentName:"p"},"before")," they make get in front of customer's eyes!"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/lighthouse-meets-github-actions-use-lighthouse-ci/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/lighthouse-meets-github-actions-use-lighthouse-ci/"})))}d.isMDXComponent=!0},32673:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-devops-consume-private-nuget-artifact-feed",title:"Azure DevOps: consume a private artifact feed",authors:"johnnyreilly",tags:["azure devops","NuGet","Azure Artifacts",".NET"],image:"./title-image.png",description:"To build applications both locally and in an Azure Pipeline using Private Azure Artifact feeds with Azure DevOps, follow these steps.",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-devops-consume-private-nuget-artifact-feed",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-03-30-azure-devops-consume-private-nuget-artifact-feed/index.md",source:"@site/blog/2022-03-30-azure-devops-consume-private-nuget-artifact-feed/index.md",title:"Azure DevOps: consume a private artifact feed",description:"To build applications both locally and in an Azure Pipeline using Private Azure Artifact feeds with Azure DevOps, follow these steps.",date:"2022-03-30T00:00:00.000Z",formattedDate:"March 30, 2022",tags:[{label:"azure devops",permalink:"/tags/azure-devops"},{label:"NuGet",permalink:"/tags/nu-get"},{label:"Azure Artifacts",permalink:"/tags/azure-artifacts"},{label:".NET",permalink:"/tags/net"}],readingTime:3.395,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-devops-consume-private-nuget-artifact-feed",title:"Azure DevOps: consume a private artifact feed",authors:"johnnyreilly",tags:["azure devops","NuGet","Azure Artifacts",".NET"],image:"./title-image.png",description:"To build applications both locally and in an Azure Pipeline using Private Azure Artifact feeds with Azure DevOps, follow these steps.",hide_table_of_contents:!1},prevItem:{title:"ESLint your C# in VS Code with Roslyn Analyzers",permalink:"/eslint-your-csharp-in-vs-code-with-roslyn-analyzers"},nextItem:{title:"Lighthouse meet GitHub Actions",permalink:"/lighthouse-meet-github-actions"}},p={image:n(84814).Z,authorsImageUrls:[void 0]},u=[{value:"Make a <code>nuget.config</code>",id:"make-a-nugetconfig",level:2},{value:"Consuming a private feed locally with the Azure Artifacts Credential Provider",id:"consuming-a-private-feed-locally-with-the-azure-artifacts-credential-provider",level:2},{value:"Consuming a private feed in Azure Pipelines",id:"consuming-a-private-feed-in-azure-pipelines",level:2},{value:"The publish gotcha",id:"the-publish-gotcha",level:2},{value:"Summing up",id:"summing-up",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Private Azure Artifact feeds in in Azure DevOps can be used to serve NuGet packages. To build applications both locally and in an Azure Pipeline using those packages, there are a few steps to follow which this post will demonstrate."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Azure DevOps: consume a private artifact feed&quot; with the Azure DevOps and Azure Pipelines logos`",src:n(84814).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"make-a-nugetconfig"}),"Make a ",(0,a.kt)("inlineCode",{parentName:"h2"},"nuget.config")),(0,a.kt)("p",null,"To consume a private feed, you'll likely want to create a ",(0,a.kt)("inlineCode",{parentName:"p"},"nuget.config")," file in the root of your repo. Here you list the package sources you want to consume, typically the NuGet official package source ",(0,a.kt)("em",{parentName:"p"},"as well")," as your private feed. See the example below:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<?xml version="1.0" encoding="utf-8"?>\n  <configuration>\n    <packageSources>\n      <add key="NuGet official package source" value="https://api.nuget.org/v3/index.json" />\n      <add key="my-nuget-packages" value="https://pkgs.dev.azure.com/my-org/_packaging/my-nuget-packages/nuget/v3/index.json" />\n    </packageSources>\n  </configuration>\n')),(0,a.kt)("h2",o({},{id:"consuming-a-private-feed-locally-with-the-azure-artifacts-credential-provider"}),"Consuming a private feed locally with the Azure Artifacts Credential Provider"),(0,a.kt)("p",null,"With our ",(0,a.kt)("inlineCode",{parentName:"p"},"nuget.config")," in place, can we build locally? Yes, once we've authenticated. If you're using Rider or Visual Studio, these may take care of this for you. However, if you're using VS Code you might need to do something else."),(0,a.kt)("p",null,"If you experience 401's when you run ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet restore")," like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"error : Unable to load the service index for source https://pkgs.dev.azure.com/my-org/_packaging/not-there/nuget/v3/index.json. [/dev.azure.com/project/repo/src/App.csproj]\nerror : Response status code does not indicate success: 401\n")),(0,a.kt)("p",null,"Then it's probably a sign you need to install the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/artifacts-credprovider"}),"Azure Artifacts Credential Provider"),". With that you should be able to restore nuget packages. See instructions ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Microsoft/artifacts-credprovider#setup"}),"here"),"."),(0,a.kt)("p",null,"On Linux and Mac this is as simple as running ",(0,a.kt)("inlineCode",{parentName:"p"},'sh -c "$(curl -fsSL https://aka.ms/install-artifacts-credprovider.sh)"')," in your terminal."),(0,a.kt)("p",null,"Subsequently, running ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet restore --interactive")," should trigger an authentication flow in the terminal, and subject to successful authentication, restore packages from the private feed."),(0,a.kt)("h2",o({},{id:"consuming-a-private-feed-in-azure-pipelines"}),"Consuming a private feed in Azure Pipelines"),(0,a.kt)("p",null,"You will need to authenticate within your pipeline before you can acquire your private feed packages. This is as simple as this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- task: NuGetAuthenticate@0\n")),(0,a.kt)("p",null,"Before building / publishing or running tests, you must first explicitly ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet restore")," and provide the path to the ",(0,a.kt)("inlineCode",{parentName:"p"},"nuget.config"),". You can do this with the dedicated ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/build/dotnet-core-cli"}),".NET Core CLI task")," task like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- task: DotNetCoreCLI@2\n  displayName: 'dotnet restore'\n  inputs:\n    command: 'restore'\n    projects: 'src/App/App.csproj'\n    nugetConfigPath: '../../nuget.config'\n    feedsToUse: config\n")),(0,a.kt)("h2",o({},{id:"the-publish-gotcha"}),"The publish gotcha"),(0,a.kt)("p",null,"On occasion, it can happen that Azure Pipelines doesn't seem to be happy running a publish task with private feeds. Consider, a task like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- task: DotNetCoreCLI@2\n  displayName: 'dotnet publish'\n  inputs:\n    command: publish\n    arguments: '--configuration Release --output $(Build.ArtifactStagingDirectory)/${{parameters.artifactName}} /p:SourceRevisionId=$(Build.SourceVersion)'\n    zipAfterPublish: true\n    publishWebProjects: false\n    workingDirectory: src/App\n")),(0,a.kt)("p",null,"This can result in non-actionable errors like this:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("inlineCode",{parentName:"p"},"##[error]Error: There was an error when attempting to execute the process '/opt/hostedtoolcache/dotnet/dotnet'. This may indicate the process failed to start. Error: spawn /opt/hostedtoolcache/dotnet/dotnet ENOENT"))),(0,a.kt)("p",null,"A workaround in this situation is to invoke .NET through a bash script directly like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),'- bash: |\n    cd src/App\n    dotnet --list-sdks\n    echo ""\n    echo "**************"\n    echo "dotnet restore --configfile ../../nuget.config"\n    dotnet restore --configfile ../../nuget.config\n    echo ""\n    echo "**************"\n    echo "dotnet build --configuration Release --no-restore"\n    dotnet build --configuration Release\n    echo ""\n    echo "**************"\n    echo "dotnet publish --configuration Release --no-restore --output $(Build.ArtifactStagingDirectory)/App /p:SourceRevisionId=$(Build.SourceVersion)"\n    dotnet publish --configuration Release --no-restore --output $(Build.ArtifactStagingDirectory)/App /p:SourceRevisionId=$(Build.SourceVersion)\n  displayName: \'dotnet publish\'\n\n- task: ArchiveFiles@2\n  displayName: \'Create $(Build.ArtifactStagingDirectory)/App.zip\'\n  inputs:\n    rootFolderOrFile: \'$(Build.ArtifactStagingDirectory)/App\'\n    includeRootFolder: false\n    archiveFile: \'$(Build.ArtifactStagingDirectory)/App.zip\'\n')),(0,a.kt)("p",null,"And note that after publishing we use the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/utility/archive-files"}),"Archive Files task")," to zip up the output of our publishing."),(0,a.kt)("p",null,"You may be tempted to use the zip command line utility to make your zip. Do not do this. I did this. I learned, through no small amount of suffering, that there is a problem with this. Whilst you can make a zip this way that will be consumed happily by Mac and OSX, when it comes to being deployed to Azure (even if you're deploying to Linux within Azure) via zip deploy it will not work. I can't tell you why, just that it won't. So use the dedicated task."),(0,a.kt)("h2",o({},{id:"summing-up"}),"Summing up"),(0,a.kt)("p",null,"And that's it; with these approaches in place you should be able to build applications consuming privage NuGet feeds with ease."))}d.isMDXComponent=!0},73155:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"eslint-your-csharp-in-vs-code-with-roslyn-analyzers",title:"ESLint your C# in VS Code with Roslyn Analyzers",authors:"johnnyreilly",tags:["Roslyn Analyzers","C#","VS Code","Lint","ESLint"],image:"./title-image.png",description:"ESLint provides linting for TypeScript and JavaScript in VS Code. A similar experience is available for C# in VS Code through Roslyn Analyzers.",hide_table_of_contents:!1},s=void 0,l={permalink:"/eslint-your-csharp-in-vs-code-with-roslyn-analyzers",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-04-06-eslint-your-csharp-in-vs-code-with-roslyn-analyzers/index.md",source:"@site/blog/2022-04-06-eslint-your-csharp-in-vs-code-with-roslyn-analyzers/index.md",title:"ESLint your C# in VS Code with Roslyn Analyzers",description:"ESLint provides linting for TypeScript and JavaScript in VS Code. A similar experience is available for C# in VS Code through Roslyn Analyzers.",date:"2022-04-06T00:00:00.000Z",formattedDate:"April 6, 2022",tags:[{label:"Roslyn Analyzers",permalink:"/tags/roslyn-analyzers"},{label:"C#",permalink:"/tags/c"},{label:"VS Code",permalink:"/tags/vs-code"},{label:"Lint",permalink:"/tags/lint"},{label:"ESLint",permalink:"/tags/es-lint"}],readingTime:10.34,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"eslint-your-csharp-in-vs-code-with-roslyn-analyzers",title:"ESLint your C# in VS Code with Roslyn Analyzers",authors:"johnnyreilly",tags:["Roslyn Analyzers","C#","VS Code","Lint","ESLint"],image:"./title-image.png",description:"ESLint provides linting for TypeScript and JavaScript in VS Code. A similar experience is available for C# in VS Code through Roslyn Analyzers.",hide_table_of_contents:!1},prevItem:{title:"Type annotations: strong types, weakly held",permalink:"/type-annotations-strong-types-weakly-held"},nextItem:{title:"Azure DevOps: consume a private artifact feed",permalink:"/azure-devops-consume-private-nuget-artifact-feed"}},p={image:n(47452).Z,authorsImageUrls:[void 0]},u=[{value:"Linting and C#",id:"linting-and-c",level:2},{value:"Roslyn Analyzers",id:"roslyn-analyzers",level:2},{value:"&quot;Analyse <code>this</code>&quot;",id:"analyse-this",level:2},{value:"Now fail my build!",id:"now-fail-my-build",level:2},{value:"Categories",id:"categories",level:2},{value:"Opt out of rules",id:"opt-out-of-rules",level:2},{value:"Dial up information to warning",id:"dial-up-information-to-warning",level:2},{value:"Deactivate linting partially",id:"deactivate-linting-partially",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"ESLint provides a great linting experience for TypeScript and JavaScript in VS Code. The suggestions, fixes and ignore options make creating clean code a joy. A similar experience is available for C# in VS Code through Roslyn Analyzers - this post tells us more."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;ESLint your C# in VS Code with Roslyn Analyzers&quot; with the C# and VS Code logos`",src:n(47452).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"linting-and-c"}),"Linting and C#"),(0,a.kt)("p",null,"JavaScript and TypeScript benefit from a tremendous tooling ecosystem which allows us to simply format and lint our codebases as we're editing. Similar tooling exists for C#. ",(0,a.kt)("a",o({parentName:"p"},{href:"/prettier-your-csharp-with-dotnet-format-and-lint-staged"}),"Previously I wrote about using ",(0,a.kt)("inlineCode",{parentName:"a"},"dotnet-format")," to have a Prettier-like experience for formatting our C#"),". If that last post focussed on formatting C#; looking through the lens of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://prettier.io/"}),"Prettier"),", this post focusses on linting; looking through the lens of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://eslint.org/"}),"ESLint"),"."),(0,a.kt)("h2",o({},{id:"roslyn-analyzers"}),"Roslyn Analyzers"),(0,a.kt)("p",null,"There's often overlap between linting and formatting tooling; and so it goes with C# as well. Linting and formatting in the .NET space make use of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dotnet/roslyn-analyzers"}),"Roslyn Analyzers"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Roslyn analyzers analyze your code for style, quality and maintainability, design and other issues. The documentation for Roslyn Analyzers can be found at docs.microsoft.com/dotnet/fundamentals/code-analysis/overview.")),(0,a.kt)("p",null,"To learn more about them, it's worth reading ",(0,a.kt)("a",o({parentName:"p"},{href:"https://endjin.com/blog/2022/01/raising-coding-standard-dotnet-analyzers"}),"the excellent piece on the topic")," by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/idg10"}),"Ian Griffiths"),"."),(0,a.kt)("h2",o({},{id:"analyse-this"}),'"Analyse ',(0,a.kt)("inlineCode",{parentName:"h2"},"this"),'"'),(0,a.kt)("p",null,"In order that we can see what the linting experience is like in VS Code, we're going to need a project to work on. We have the .NET 6 SDK installed, so we'll create ourselves a project:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"dotnet new webapi -o AnalyseThis\n")),(0,a.kt)("p",null,"We have the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.csharp"}),"C# extension")," installed already, but we're getting no feedback on the code. Maybe it's already beautiful?"),(0,a.kt)("p",null,"Or maybe not. We're going to need an ",(0,a.kt)("inlineCode",{parentName:"p"},".editorconfig")," file to control all the code style settings. You can create this directly using the ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet")," CLI like so;"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"dotnet new editorconfig\n")),(0,a.kt)("p",null,"Once this runs, it creates a file with all of the settings in with their default values. Alongside that, we need to wake VS Code up to our brave new world by setting the following in our ",(0,a.kt)("inlineCode",{parentName:"p"},"settings.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "omnisharp.enableRoslynAnalyzers": true,\n  "omnisharp.enableEditorConfigSupport": true\n}\n')),(0,a.kt)("p",null,"Or alternatively, use the GUI in VS Code to set these settings directly:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the VS Code settings screen",src:n(36803).Z,width:"1908",height:"769"})),(0,a.kt)("p",null,"It's then a good idea to turn OmniSharp off and on again, so it picks up these changes:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the VS Code &quot;restart OmniSharp&quot;",src:n(28144).Z,width:"1203",height:"126"})),(0,a.kt)("p",null,"Then, excitingly, we start to see code analysis, or linting, messages in the problems pane of VS Code:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of a first linting message and the code to which it applies",src:n(59541).Z,width:"2422",height:"552"})),(0,a.kt)("p",null,"It's possible to use the ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet-format")," command to surface this information:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"dotnet format style -v detailed --severity info --verify-no-changes\n  The dotnet runtime version is '6.0.2'.\n  Formatting code files in workspace '/workspaces/AnalyseThis.csproj'.\n    Determining projects to restore...\n  All projects are up-to-date for restore.\n  Project AnalyseThis is using configuration from '/workspaces/.editorconfig'.\n  Project AnalyseThis is using configuration from '/workspaces/obj/Debug/net6.0/AnalyseThis.GeneratedMSBuildEditorConfig.editorconfig'.\n  Project AnalyseThis is using configuration from '/usr/share/dotnet/sdk/6.0.200/Sdks/Microsoft.NET.Sdk/analyzers/build/config/analysislevel_6_default.editorconfig'.\n  Running 45 analyzers on AnalyseThis.\n/workspaces/Controllers/WeatherForecastController.cs(14,57): info IDE0052: Private member 'WeatherForecastController._logger' can be removed as the value assigned to it is never read [/workspaces/AnalyseThis.csproj]\n  Formatted code file '/workspaces/Controllers/WeatherForecastController.cs'.\n  Formatted 1 of 6 files.\n  Format complete in 7993ms.\n")),(0,a.kt)("p",null,"Note the ",(0,a.kt)("inlineCode",{parentName:"p"},"IDE0052: Private member 'WeatherForecastController._logger' can be removed as the value assigned to it is never read")," message above."),(0,a.kt)("h2",o({},{id:"now-fail-my-build"}),"Now fail my build!"),(0,a.kt)("p",null,"This is all very exciting - we've a world of extra linting at our fingertips! But what's a touch disappointing, is that the above information isn't surfaced in my build. What if as a team we commit to a particular code style? If I can't enforce that in the build, it's likely not going to happen."),(0,a.kt)("p",null,"So what do I do? Well, the information is out there on how to do this, but it's easy to miss. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/fundamentals/code-analysis/overview#enable-on-build"}),"You can find the details here"),". We update our ",(0,a.kt)("inlineCode",{parentName:"p"},"AnalyseThis.csproj")," to include an ",(0,a.kt)("inlineCode",{parentName:"p"},"EnforceCodeStyleInBuild")," setting like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),"  <PropertyGroup>\n    <TargetFramework>net6.0</TargetFramework>\n    <Nullable>enable</Nullable>\n    <ImplicitUsings>enable</ImplicitUsings>\n\n    <EnforceCodeStyleInBuild>true</EnforceCodeStyleInBuild>\n  </PropertyGroup>\n")),(0,a.kt)("p",null,"We're going to replace our exhaustive ",(0,a.kt)("inlineCode",{parentName:"p"},".editorconfig")," file with a much simpler one:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ini"}),"# Remove the line below if you want to inherit .editorconfig settings from higher directories\nroot = true\n\n[*.cs]\n# Default severity for analyzer diagnostics with category 'Style' (escalated to build warnings)\ndotnet_analyzer_diagnostic.category-Style.severity = warning\n")),(0,a.kt)("p",null,"Do you see what we did here? We told our build to treat ",(0,a.kt)("inlineCode",{parentName:"p"},"Style")," diagnostics (lints) as warnings. Once OmniSharp picks this up, more linting messages start to appear in the problems pane of VS Code:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of more linting messages",src:n(83825).Z,width:"2261",height:"517"})),(0,a.kt)("p",null,"And what's more, if we attempt to build, guess what?"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"dotnet build\nMicrosoft (R) Build Engine version 17.1.0+ae57d105c for .NET\nCopyright (C) Microsoft Corporation. All rights reserved.\n\n  Determining projects to restore...\n  All projects are up-to-date for restore.\n/workspaces/AnalyseThis/Controllers/WeatherForecastController.cs(3,1): warning IDE0160: Convert to block scoped namespace [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/WeatherForecast.cs(1,1): warning IDE0160: Convert to block scoped namespace [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Program.cs(1,1): warning IDE0008: Use explicit type instead of 'var' [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Program.cs(10,1): warning IDE0008: Use explicit type instead of 'var' [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Program.cs(15,5): warning IDE0058: Expression value is never used [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Program.cs(16,5): warning IDE0058: Expression value is never used [/workspaces/AnalyseThis/AnalyseThis.csproj]\n  AnalyseThis -> /workspaces/AnalyseThis/bin/Debug/net6.0/AnalyseThis.dll\n\nBuild succeeded.\n\n/workspaces/AnalyseThis/Controllers/WeatherForecastController.cs(3,1): warning IDE0160: Convert to block scoped namespace [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/WeatherForecast.cs(1,1): warning IDE0160: Convert to block scoped namespace [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Program.cs(1,1): warning IDE0008: Use explicit type instead of 'var' [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Program.cs(10,1): warning IDE0008: Use explicit type instead of 'var' [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Program.cs(15,5): warning IDE0058: Expression value is never used [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Program.cs(16,5): warning IDE0058: Expression value is never used [/workspaces/AnalyseThis/AnalyseThis.csproj]\n    6 Warning(s)\n    0 Error(s)\n\nTime Elapsed 00:00:06.53\n")),(0,a.kt)("p",null,"That's right! The same messages from the problems pane are now surfaced in our build as warnings. And we can kick it up a notch too; let's make them errors:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ini"}),"# Remove the line below if you want to inherit .editorconfig settings from higher directories\nroot = true\n\n[*.cs]\n# Default severity for analyzer diagnostics with category 'Style' (escalated to build errors)\ndotnet_analyzer_diagnostic.category-Style.severity = error\n")),(0,a.kt)("p",null,"Once OmniSharp catches up we see our warnings transform into errors:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of a more linting messages",src:n(73717).Z,width:"2264",height:"510"})),(0,a.kt)("p",null,"And if we build..."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"dotnet build\nMicrosoft (R) Build Engine version 17.1.0+ae57d105c for .NET\nCopyright (C) Microsoft Corporation. All rights reserved.\n\n  Determining projects to restore...\n  All projects are up-to-date for restore.\n/workspaces/AnalyseThis/WeatherForecast.cs(1,1): error IDE0160: Convert to block scoped namespace [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Controllers/WeatherForecastController.cs(3,1): error IDE0160: Convert to block scoped namespace [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Program.cs(1,1): error IDE0008: Use explicit type instead of 'var' [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Program.cs(10,1): error IDE0008: Use explicit type instead of 'var' [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Program.cs(15,5): error IDE0058: Expression value is never used [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Program.cs(16,5): error IDE0058: Expression value is never used [/workspaces/AnalyseThis/AnalyseThis.csproj]\n\nBuild FAILED.\n\n/workspaces/AnalyseThis/WeatherForecast.cs(1,1): error IDE0160: Convert to block scoped namespace [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Controllers/WeatherForecastController.cs(3,1): error IDE0160: Convert to block scoped namespace [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Program.cs(1,1): error IDE0008: Use explicit type instead of 'var' [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Program.cs(10,1): error IDE0008: Use explicit type instead of 'var' [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Program.cs(15,5): error IDE0058: Expression value is never used [/workspaces/AnalyseThis/AnalyseThis.csproj]\n/workspaces/AnalyseThis/Program.cs(16,5): error IDE0058: Expression value is never used [/workspaces/AnalyseThis/AnalyseThis.csproj]\n    0 Warning(s)\n    6 Error(s)\n\nTime Elapsed 00:00:04.22\n")),(0,a.kt)("p",null,"Yes! Our style diagnostics are now failing the build. This is terrific!"),(0,a.kt)("h2",o({},{id:"categories"}),"Categories"),(0,a.kt)("p",null,"It's worth pausing a second and considering the category upgrade we did here:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ini"}),"dotnet_analyzer_diagnostic.category-Style.severity = error\n")),(0,a.kt)("p",null,"There's a number of different categories that encapsulate groups of rules, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/fundamentals/code-analysis/categories"}),"they're documented here"),". Taken from there you can see the wealth of different categories that exist:"),(0,a.kt)("table",null,(0,a.kt)("thead",{parentName:"table"},(0,a.kt)("tr",{parentName:"thead"},(0,a.kt)("th",o({parentName:"tr"},{align:null}),"Category"),(0,a.kt)("th",o({parentName:"tr"},{align:null}),"Description"),(0,a.kt)("th",o({parentName:"tr"},{align:null}),"EditorConfig value"))),(0,a.kt)("tbody",{parentName:"table"},(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Design rules"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Design rules support adherence to the .NET Framework Design Guidelines."),(0,a.kt)("td",o({parentName:"tr"},{align:null}),(0,a.kt)("inlineCode",{parentName:"td"},"dotnet_analyzer_diagnostic.category-Design.severity"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Documentation rules"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Documentation rules support writing well-documented libraries through the correct use of XML documentation comments for externally visible APIs."),(0,a.kt)("td",o({parentName:"tr"},{align:null}),(0,a.kt)("inlineCode",{parentName:"td"},"dotnet_analyzer_diagnostic.category-Documentation.severity"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Globalization rules"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Globalization rules support world-ready libraries and applications."),(0,a.kt)("td",o({parentName:"tr"},{align:null}),(0,a.kt)("inlineCode",{parentName:"td"},"dotnet_analyzer_diagnostic.category-Globalization.severity"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Portability and interoperability rules"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Portability rules support portability across different platforms. Interoperability rules support interaction with COM clients."),(0,a.kt)("td",o({parentName:"tr"},{align:null}),(0,a.kt)("inlineCode",{parentName:"td"},"dotnet_analyzer_diagnostic.category-Interoperability.severity"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Maintainability rules"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Maintainability rules support library and application maintenance."),(0,a.kt)("td",o({parentName:"tr"},{align:null}),(0,a.kt)("inlineCode",{parentName:"td"},"dotnet_analyzer_diagnostic.category-Maintainability.severity"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Naming rules"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Naming rules support adherence to the naming conventions of the .NET design guidelines."),(0,a.kt)("td",o({parentName:"tr"},{align:null}),(0,a.kt)("inlineCode",{parentName:"td"},"dotnet_analyzer_diagnostic.category-Naming.severity"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Performance rules"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Performance rules support high-performance libraries and applications."),(0,a.kt)("td",o({parentName:"tr"},{align:null}),(0,a.kt)("inlineCode",{parentName:"td"},"dotnet_analyzer_diagnostic.category-Performance.severity"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"SingleFile rules"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Single-file rules support single-file applications."),(0,a.kt)("td",o({parentName:"tr"},{align:null}),(0,a.kt)("inlineCode",{parentName:"td"},"dotnet_analyzer_diagnostic.category-SingleFile.severity"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Reliability rules"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Reliability rules support library and application reliability, such as correct memory and thread usage."),(0,a.kt)("td",o({parentName:"tr"},{align:null}),(0,a.kt)("inlineCode",{parentName:"td"},"dotnet_analyzer_diagnostic.category-Reliability.severity"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Security rules"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Security rules support safer libraries and applications. These rules help prevent security flaws in your program."),(0,a.kt)("td",o({parentName:"tr"},{align:null}),(0,a.kt)("inlineCode",{parentName:"td"},"dotnet_analyzer_diagnostic.category-Security.severity"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Style rules"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),'Style rules support consistent code style in your codebase. These rules start with the "IDE" prefix.'),(0,a.kt)("td",o({parentName:"tr"},{align:null}),(0,a.kt)("inlineCode",{parentName:"td"},"dotnet_analyzer_diagnostic.category-Style.severity"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Usage rules"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),"Usage rules support proper usage of .NET."),(0,a.kt)("td",o({parentName:"tr"},{align:null}),(0,a.kt)("inlineCode",{parentName:"td"},"dotnet_analyzer_diagnostic.category-Usage.severity"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",o({parentName:"tr"},{align:null}),"N/A"),(0,a.kt)("td",o({parentName:"tr"},{align:null}),'You can use this EditorConfig value to enable the following rules: IDE0051, IDE0064, IDE0076. While these rules start with "IDE", they are not technically part of the ',(0,a.kt)("inlineCode",{parentName:"td"},"Style")," category."),(0,a.kt)("td",o({parentName:"tr"},{align:null}),(0,a.kt)("inlineCode",{parentName:"td"},"dotnet_analyzer_diagnostic.category-CodeQuality.severity"))))),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"IDE0052")," information we saw when we used ",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet format")," earlier is technically part of the ",(0,a.kt)("inlineCode",{parentName:"p"},"CodeQuality")," category. If we wanted to, we we could dial that up that category to an error like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ini"}),"# Default severity for analyzer diagnostics with category 'CodeQuality' (escalated to build errors)\ndotnet_analyzer_diagnostic.category-CodeQuality.severity = error\n")),(0,a.kt)("h2",o({},{id:"opt-out-of-rules"}),"Opt out of rules"),(0,a.kt)("p",null,"As it turns out, I disagree with the complaints I'm getting on the codebase right now, so I'd like to dial those down to ignore. To do that globally, you simply put configuration in the ",(0,a.kt)("inlineCode",{parentName:"p"},".editorconfig")," to reflect that:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ini"}),"# Remove the line below if you want to inherit .editorconfig settings from higher directories\nroot = true\n\n[*.cs]\n# Default severity for analyzer diagnostics with category 'Style' (escalated to build warnings)\ndotnet_analyzer_diagnostic.category-Style.severity = error\n\ndotnet_diagnostic.IDE0008.severity = none\ndotnet_diagnostic.IDE0058.severity = none\ndotnet_diagnostic.IDE0160.severity = none\n")),(0,a.kt)("p",null,"What we're doing here is saying \"upgrade all ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/fundamentals/code-analysis/style-rules/"}),"style rules")," to be errors, but ",(0,a.kt)("inlineCode",{parentName:"p"},"IDE0008"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"IDE0058")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"IDE0160")," (which are style rules) - ignore those; don't tell me about them\"."),(0,a.kt)("p",null,"Now I'm not going to be bothered by those errors in future. Great."),(0,a.kt)("h2",o({},{id:"dial-up-information-to-warning"}),"Dial up information to warning"),(0,a.kt)("p",null,"If we look again at our problems pane in VS Code, we can see there's an entry there. It's not an error, it's not a warning. It's information:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of a first linting message and the code to which it applies",src:n(59541).Z,width:"2422",height:"552"})),(0,a.kt)("p",null,"Let's say we want to take that and dial it up to be a warning, such that it surfaces in the build too. We can with a simple addition to our ",(0,a.kt)("inlineCode",{parentName:"p"},".editorconfig"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ini"}),"# Remove the line below if you want to inherit .editorconfig settings from higher directories\nroot = true\n\n[*.cs]\n# Default severity for analyzer diagnostics with category 'Style' (escalated to build warnings)\ndotnet_analyzer_diagnostic.category-Style.severity = error\n\ndotnet_diagnostic.IDE0008.severity = none\ndotnet_diagnostic.IDE0058.severity = none\ndotnet_diagnostic.IDE0160.severity = none\n\n# Roslyn analzer surfaces this as information - we'll dial it up to a warning\ndotnet_diagnostic.IDE0052.severity = warning\n")),(0,a.kt)("p",null,"Once OmniSharp notices:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of our information now a warning",src:n(67646).Z,width:"2276",height:"157"})),(0,a.kt)("p",null,"And if we run the build, there it is!"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"dotnet build\nMicrosoft (R) Build Engine version 17.1.0+ae57d105c for .NET\nCopyright (C) Microsoft Corporation. All rights reserved.\n\n  Determining projects to restore...\n  All projects are up-to-date for restore.\n/workspaces/AnalyseThis/Controllers/WeatherForecastController.cs(14,57): warning IDE0052: Private member 'WeatherForecastController._logger' can be removed as the value assigned to it is never read [/workspaces/AnalyseThis/AnalyseThis.csproj]\n  AnalyseThis -> /workspaces/AnalyseThis/bin/Debug/net6.0/AnalyseThis.dll\n\nBuild succeeded.\n\n/workspaces/AnalyseThis/Controllers/WeatherForecastController.cs(14,57): warning IDE0052: Private member 'WeatherForecastController._logger' can be removed as the value assigned to it is never read [/workspaces/AnalyseThis/AnalyseThis.csproj]\n    1 Warning(s)\n    0 Error(s)\n\nTime Elapsed 00:00:02.21\n")),(0,a.kt)("h2",o({},{id:"deactivate-linting-partially"}),"Deactivate linting partially"),(0,a.kt)("p",null,"Let's say we want to ignore that one warning. We'd like the equivalent functionality to ",(0,a.kt)("inlineCode",{parentName:"p"},"// eslint-disable-next-line"),". That doesn't exist alas. However, what does is the equivalent to this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"/* eslint-disable */\n\nalert('foo');\n\n/* eslint-enable */\n")),(0,a.kt)("p",null,"In our case what we'd do is this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"#pragma warning disable\n    private readonly ILogger<WeatherForecastController> _logger;\n#pragma warning restore\n")),(0,a.kt)("p",null,"Or to be more specific:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"#pragma warning disable IDE0052\n    private readonly ILogger<WeatherForecastController> _logger;\n#pragma warning restore IDE0052\n")),(0,a.kt)("p",null,"And now we can opt out of that rule in this specific place - whilst maintaining it more generally."),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"There's powerful linting tools in C#, hopefully this guide has made it easier for you to surface them, control them and apply them both to VS Code and to your build."),(0,a.kt)("p",null,"Thanks to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/JoeyRobichaud"}),"Joey Robichaud"),", ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/timheuer"}),"Tim Heuer")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/YoussefV1313"}),"Youssef Victor")," for some excellent pointers that fed into the writing of this post. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/dotnet/roslyn/issues/60620"}),"You can see the help they provided here"),"."))}d.isMDXComponent=!0},76187:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"type-annotations-strong-types-weakly-held",title:"Type annotations: strong types, weakly held",authors:"johnnyreilly",tags:["JSDoc","ECMAScript","typescript"],image:"./title-image.png",description:"Type annotations is a proposal which would allow for the inclusion of types in JavaScript code. Here is a description of the proposal and some thoughts.",hide_table_of_contents:!1},s=void 0,l={permalink:"/type-annotations-strong-types-weakly-held",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-04-16-type-annotations-strong-types-weakly-held/index.md",source:"@site/blog/2022-04-16-type-annotations-strong-types-weakly-held/index.md",title:"Type annotations: strong types, weakly held",description:"Type annotations is a proposal which would allow for the inclusion of types in JavaScript code. Here is a description of the proposal and some thoughts.",date:"2022-04-16T00:00:00.000Z",formattedDate:"April 16, 2022",tags:[{label:"JSDoc",permalink:"/tags/js-doc"},{label:"ECMAScript",permalink:"/tags/ecma-script"},{label:"typescript",permalink:"/tags/typescript"}],readingTime:8.645,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"type-annotations-strong-types-weakly-held",title:"Type annotations: strong types, weakly held",authors:"johnnyreilly",tags:["JSDoc","ECMAScript","typescript"],image:"./title-image.png",description:"Type annotations is a proposal which would allow for the inclusion of types in JavaScript code. Here is a description of the proposal and some thoughts.",hide_table_of_contents:!1},prevItem:{title:"Upgrading to React 18 with TypeScript",permalink:"/upgrading-to-react-18-typescript"},nextItem:{title:"ESLint your C# in VS Code with Roslyn Analyzers",permalink:"/eslint-your-csharp-in-vs-code-with-roslyn-analyzers"}},p={image:n(55485).Z,authorsImageUrls:[void 0]},u=[{value:"What is the proposal?",id:"what-is-the-proposal",level:2},{value:"What isn&#39;t it?",id:"what-isnt-it",level:2},{value:"Why do this at all?",id:"why-do-this-at-all",level:2},{value:"&quot;It&#39;s the JSDoc I always wanted!&quot;",id:"its-the-jsdoc-i-always-wanted",level:2},{value:"Controversy and Compromise",id:"controversy-and-compromise",level:2},{value:"Generic invocations and TypeScript",id:"generic-invocations-and-typescript",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Recently, a new ECMAScript proposal called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/tc39/proposal-type-annotations"}),'"Type Annotations"')," (originally named ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/giltayar/proposal-types-as-comments"}),'"Types as Comments"'),") was revealed. The purpose is to allow type annotations to be valid JavaScript syntax. Albeit syntax that is ignored by JavaScript engines. The proposal is being worked on by Gil Tayar, Daniel Rosenwasser, Romulo Cintra, Rob Palmer, and others. Many of these people are from TypeScript community - however this proposal intentionally does not exist to benefit TypeScript alone."),(0,a.kt)("p",null,"It's a contentious topic. As a regular (and longtime) TypeScript user, here's a description of the proposal and some thoughts."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Type annotations: strong types, weakly held&quot; with the JavaScript logo",src:n(55485).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"what-is-the-proposal"}),"What is the proposal?"),(0,a.kt)("p",null,"Types annotations is a proposal which would allow for the inclusion of types in JavaScript code. Consider the following piece of TypeScript:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const theAnswer: number = 42;\n")),(0,a.kt)("p",null,"At present, this is not valid JavaScript. If you try and run the above in a JavaScript engine you'll get an error. Types are not part of JavaScript syntax."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of `const theAnswer: number = 42;` entered into the Chrome devtools and responding with an error that says `Uncaught SyntaxError: Missing initializer in const declaration`",src:n(38889).Z,width:"1542",height:"140"})),(0,a.kt)("p",null,"Interestingly, it's already possible to store types within JavaScript through a standard known as JSDoc. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/typescript-vs-jsdoc-javascript/"}),"I've written about how TypeScript and JSDoc connect before."),", essentially the thing to note is that JSDoc amounts to storing type declarations in the context of JavaScript comments."),(0,a.kt)("p",null,"It's already possible to write our code sample in valid JavaScript expressing the types within JSDoc. It looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"/** @type {number} */\nconst theAnswer = 42;\n")),(0,a.kt)("p",null,"This works, but it took two lines of code instead of one. The proposal allows for types to be directly expressed; not written as comments. So rather than writing the JSDoc equivalent, imagine if JavaScript was happy with the following instead:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const theAnswer: number = 42;\n")),(0,a.kt)("p",null,"That's what the proposal amounts to."),(0,a.kt)("h2",o({},{id:"what-isnt-it"}),"What isn't it?"),(0,a.kt)("p",null,"Now that we understand what the proposal is, let's consider what it isn't."),(0,a.kt)("p",null,"Types annotations isn't an endorsement of a particular type system. Furthermore, it is not type checking in the browser or type checking in Node.js."),(0,a.kt)("p",null,"Let's consider each of these. There's a number of languages which allow us to type check JavaScript. TypeScript, Flow, Hegel and others all play in this space. They are all similar, but different. They have different syntax and they do different things."),(0,a.kt)("p",null,'What they have in common, is the space where types live in their syntax or grammar. The proposal essentially says "hey we might have different approaches to describing types, but we agree about where the types ought to live - let\'s standardise that".'),(0,a.kt)("p",null,'This is why the original proposal name of "types as comments" is instructive; these types would be ignored by JavaScript runtimes. The fact they would be ignored is an indication that no existing type system would be "anointed" by this proposal.'),(0,a.kt)("p",null,"Consider the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const theAnswer: gibberish = 42;\n")),(0,a.kt)("p",null,"This is neither TypeScript or Flow. Both would complain about the above. JavaScript, if this proposal were adopted, would be entirely untroubled."),(0,a.kt)("p",null,"To reiterate: the proposal is not an endorsement of any given type system and it follows that there is no runtime type checking being introduced to JavaScript."),(0,a.kt)("h2",o({},{id:"why-do-this-at-all"}),"Why do this at all?"),(0,a.kt)("p",null,"It's worth taking a look at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://devblogs.microsoft.com/typescript/a-proposal-for-type-syntax-in-javascript/"}),"Daniel Rosenwasser"),"'s post where he announces the proposal. Daniel is part of the TypeScript team and one of champions of this proposal, along with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/robpalmer2"}),"Rob Palmer")," at Bloomberg and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/romulocintra"}),"Romulo Cintra")," at Igalia."),(0,a.kt)("p",null,"He says:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Today, you can create a .js file in your editor and start sprinkling in types in the form of JSDoc comments."),(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"/**\n * @param a {number}\n * @param b {number}\n */\nfunction add(a, b) {\n  return a + b;\n}\n")),(0,a.kt)("p",{parentName:"blockquote"},"Because these are just comments, they don\u2019t change how your code runs at all \u2013 they\u2019re just a form of documentation, but TypeScript uses them to give you a better JavaScript editing experience ... This feature makes it incredibly convenient to get some of the TypeScript experience without a build step, and you can use it for small scripts, basic web pages, server code in Node.js, etc."),(0,a.kt)("p",{parentName:"blockquote"},"Still, you\u2019ll notice that this is a little verbose \u2013 we love how lightweight the inner-loop is for writing JavaScript, but we\u2019re missing how convenient TypeScript makes it to just write types."),(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("em",{parentName:"p"},"So what if we had both?")),(0,a.kt)("p",{parentName:"blockquote"},"What if we could have something like TypeScript syntax which was totally ignored \u2013 sort of like comments \u2013 in JavaScript."),(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"function add(a: number, b: number) {\n  return a + b;\n}\n"))),(0,a.kt)("p",null,"What I take from this, is that JavaScript with types annotations, would be a more developer friendly JSDoc."),(0,a.kt)("h2",o({},{id:"its-the-jsdoc-i-always-wanted"}),'"It\'s the JSDoc I always wanted!"'),(0,a.kt)("p",null,"This idea really resonates with me. I'm a longtime user of JSDoc. Let me articulate why I find it useful."),(0,a.kt)("p",null,"What I wanted, way back before TypeScript existed, was JavaScript with static typing. TypeScript ",(0,a.kt)("em",{parentName:"p"},"mostly")," is that. At least in the way I choose to use it."),(0,a.kt)("p",null,"I don't use ",(0,a.kt)("inlineCode",{parentName:"p"},"enum"),"s, ",(0,a.kt)("inlineCode",{parentName:"p"},"namespace"),"s, ",(0,a.kt)("inlineCode",{parentName:"p"},"decorator"),"s etc. This is significant as each of those features steps has an emit aspect; using one of these will require transpilation to create special JavaScript to represent a custom TypeScript implemented feature. All other TypeScript features are ",(0,a.kt)("em",{parentName:"p"},"erased")," by transpilation; there's no execution characteristics."),(0,a.kt)("p",null,"So by subsetting the features of TypeScript, we can choose to use only those features that do not have an emit aspect. By making that choice, it's possible to use just JavaScript, if we're willing to commit to using JSDoc syntax within JavaScript ",(0,a.kt)("em",{parentName:"p"},"instead")," of TypeScript. There's many in the community who are doing this on sizeable projects like ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/webpack/webpack"}),"webpack")," already. We don't lose type checking, we don't lose refactoring possibilities thanks to editors like VS Code."),(0,a.kt)("p",null,"JSDoc is great, but it's undeniably more verbose than writing TypeScript. If types annotations was to be adopted, we'd able to write TypeScript in our JavaScript files. We'd be able to use TypeScript to type check that ",(0,a.kt)("strong",{parentName:"p"},"if we wanted to"),". But we wouldn't need to transpile our code prior to running. We could run our source code directly. Brilliant!"),(0,a.kt)("h2",o({},{id:"controversy-and-compromise"}),"Controversy and Compromise"),(0,a.kt)("p",null,'Up until now, as we\'ve looked at the proposal, the story has been one of JavaScript becoming "types tolerant". And as a consequence, the syntax of Flow / TypeScript / Hegel et al would in future being considered valid JavaScript.'),(0,a.kt)("p",null,"This paints a picture of JavaScript, a dynamic language, being changed to accomodate the sensibilities of those who favour static typing. If you should glance at the discussions on Hacker News and in the issues of the proposal it's clear there's a very vocal section of JavaScript developers who consider this proposal to be thoroughly unwanted."),(0,a.kt)("p",null,"Whilst it's unlikely that the most fervent dynamic language advocate will change their mind, it's worth considering the nuance of this proposal. In actual fact, the proposal is a two way street; to comply with types becoming JavaScript native, languages like TypeScript would likely make changes to accomodate."),(0,a.kt)("h2",o({},{id:"generic-invocations-and-typescript"}),"Generic invocations and TypeScript"),(0,a.kt)("p",null,"There's a few cases which apply, the one that seems most significant is that of generic invocation. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/giltayar/proposal-types-as-comments#generic-invocations"}),"To quote the proposal"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"One can explicitly specify the type arguments of a generic function invocation or generic class instantiation ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/docs/handbook/2/functions.html#specifying-type-arguments"}),"in TypeScript"),"."),(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"// TypeScript\nadd<number>(4, 5);\nnew Point<bigint>(4n, 5n);\n")),(0,a.kt)("p",{parentName:"blockquote"},"The above syntax is already valid JavaScript that users may rely on, so we cannot use this syntax as-is.")),(0,a.kt)("p",null,"So if this proposal was to land, writing today's style TypeScript in JavaScript would ",(0,a.kt)("em",{parentName:"p"},"not")," work in the case of generic invocations."),(0,a.kt)("p",null,"If we read on in the proposal it says;"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"We expect some form of new syntax that could be used to resolve this ambiguity.\nNo specific solution is proposed at this point of time, but one example option is to use a syntactic prefix such as ",(0,a.kt)("inlineCode",{parentName:"p"},"::")),(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"// Types as Comments - example syntax solution\nadd::<number>(4, 5)\nnew Point::<bigint>(4n, 5n)\n")),(0,a.kt)("p",{parentName:"blockquote"},"These type arguments (",(0,a.kt)("inlineCode",{parentName:"p"},"::<type>"),") would be ignored by the JavaScript runtime.\nIt would be reasonable for this non-ambiguous syntax to be adopted in TypeScript as well.")),(0,a.kt)("p",null,"This last sentence is significant. Let's read it again:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"It would be reasonable for this non-ambiguous syntax to be adopted in TypeScript as well")),(0,a.kt)("p",null,"Whilst not being an absolute commitment, this certainly suggests that TypeScript would be willing to change its own syntax to align with something that was standardised as typed JavaScript."),(0,a.kt)("p",null,"Speaking personally, I don't love the proposed new syntax; but I understand the rationale. Certainly a new generic invocation syntax is something I could come to terms with. It's good of the TypeScript team to be open to the idea of making changes to the language to align with the proposal. This is not zero cost to them. This demonstrates that to allow this proposal to land, there will be compromises on many sides. It's likely that Flow will be similarly affected also."),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"When you see the various discussions on this topic online, it's clear there are many strong feelings. The proposal hasn't even reached stage 1 (of the potential 4 stages required for adoption). This may be a feature that doesn't make it. Or perhaps takes a long time to land on a mutually agreed design."),(0,a.kt)("p",null,"Speaking personally I'm hopeful that this does end up being part of the language. Not only do I like running raw JS, I see the benefits of being able to onboard people from JavaScript to TypeScript by allowing types to live directly in JavaScript."),(0,a.kt)("p",null,"It's said that prediction is very difficult, especially if it's about the future. So it is hard to know for sure what the long term effects on the language and the ecosystem of this proposal might be. It would certainly lower the barrier to entry for using static typing with JavaScript, and as consequence, would likely lead to greater adoption and hence less bugs in userland. Time will tell."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/types-as-comments-strong-types-weakly-held/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/types-as-comments-strong-types-weakly-held/"})))}d.isMDXComponent=!0},547:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"upgrading-to-react-18-typescript",title:"Upgrading to React 18 with TypeScript",authors:"johnnyreilly",tags:["React","typescript","Definitely Typed"],image:"./title-image.png",description:"The upgrade of the React type definitions to support React 18 involved some significant breaking changes. This post the upgrade path.",hide_table_of_contents:!1},s=void 0,l={permalink:"/upgrading-to-react-18-typescript",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-05-01-upgrading-to-react-18-typescript/index.md",source:"@site/blog/2022-05-01-upgrading-to-react-18-typescript/index.md",title:"Upgrading to React 18 with TypeScript",description:"The upgrade of the React type definitions to support React 18 involved some significant breaking changes. This post the upgrade path.",date:"2022-05-01T00:00:00.000Z",formattedDate:"May 1, 2022",tags:[{label:"React",permalink:"/tags/react"},{label:"typescript",permalink:"/tags/typescript"},{label:"Definitely Typed",permalink:"/tags/definitely-typed"}],readingTime:5.91,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"upgrading-to-react-18-typescript",title:"Upgrading to React 18 with TypeScript",authors:"johnnyreilly",tags:["React","typescript","Definitely Typed"],image:"./title-image.png",description:"The upgrade of the React type definitions to support React 18 involved some significant breaking changes. This post the upgrade path.",hide_table_of_contents:!1},prevItem:{title:"Azure Static Web Apps: named preview environments with Azure DevOps",permalink:"/static-web-apps-azure-devops-named-preview-environments"},nextItem:{title:"Type annotations: strong types, weakly held",permalink:"/type-annotations-strong-types-weakly-held"}},p={image:n(51871).Z,authorsImageUrls:[void 0]},u=[{value:"React 18 and Definitely Typed",id:"react-18-and-definitely-typed",level:2},{value:"Definitely Typed and semantic versioning",id:"definitely-typed-and-semantic-versioning",level:2},{value:"React 18 - breaking type changes",id:"react-18---breaking-type-changes",level:2},{value:"Upgrading",id:"upgrading",level:2},{value:"Wrapping up",id:"wrapping-up",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The upgrade of the React type definitions to support React 18 involved some significant breaking changes. This post digs into that and examines what the upgrade path looks like."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Upgrading to React 18 with TypeScript&quot; with the React, TypeScript and Definitely Typed logos`",src:n(51871).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"react-18-and-definitely-typed"}),"React 18 and Definitely Typed"),(0,a.kt)("p",null,"After a significant period of time in alpha / beta, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://reactjs.org/blog/2022/03/29/react-v18.html"}),"React 18 shipped on March 29th 2022"),". Since the first alpha was released, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/how-to-use-typescript-with-react-18-alpha/"}),"support has been available in TypeScript"),". This has been made possible through the type definitions at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped"}),"Definitely Typed"),", the repository for high quality TypeScript type definitions. It's particularly down to the fine work of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/sebsilbermann"}),"Sebastian Silbermann")," who has put a lot of work into the React 18 definitions."),(0,a.kt)("p",null,"Now that React 18 has shipped, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped/pull/56210"}),"the type definitions for React 18 were updated in Sebastian's pull request"),". Many projects have been, and will be, broken by this change. This post will look at what that breakage can look like and how to resolve it."),(0,a.kt)("p",null,"Before we do that, let's first consider the problem of Definitely Typed and ",(0,a.kt)("a",o({parentName:"p"},{href:"http://semver.org/"}),"semantic versioning"),"."),(0,a.kt)("h2",o({},{id:"definitely-typed-and-semantic-versioning"}),"Definitely Typed and semantic versioning"),(0,a.kt)("p",null,"People are used to the idea of semantic versioning in the software they consume. They expect a major version bump to indicate breaking changes. This is exactly what React has just done by incrementing from v17 to v18."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Definitely Typed does not support semantic versioning.")),(0,a.kt)("p",null,"This is not out of spite. This is because DT intentionally publishes type definitions to npm, under the scope of ",(0,a.kt)("inlineCode",{parentName:"p"},"@types"),". So, for example, the type definitions of React are published to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/@types/react"}),(0,a.kt)("inlineCode",{parentName:"a"},"@types/react")),"."),(0,a.kt)("p",null,"It's important to be aware that npm is built on top of semantic versioning. To make consumption of type definitions easier, the versioning of a type definition package will seek to emulate the versioning of the npm package it supports. So for ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/react"}),(0,a.kt)("inlineCode",{parentName:"a"},"react"))," ",(0,a.kt)("inlineCode",{parentName:"p"},"18.0.0"),", the corresponding type definition would be ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/@types/react"}),(0,a.kt)("inlineCode",{parentName:"a"},"@types/react")),"'s ",(0,a.kt)("inlineCode",{parentName:"p"},"18.0.0"),"."),(0,a.kt)("p",null,"If there's a breaking change to the ",(0,a.kt)("inlineCode",{parentName:"p"},"@types/react")," type definition (or any other for that matter) then the new version published will not increment the major or minor version numbers. The increment will be applied to the patch number alone. This is done to maintain the simpler consumption model of types through npm."),(0,a.kt)("h2",o({},{id:"react-18---breaking-type-changes"}),"React 18 - breaking type changes"),(0,a.kt)("p",null,"All that said, for very widely used type definitions, it's not unusual to at least make an effort towards minimising breaking changes where that is possible."),(0,a.kt)("p",null,"As an aside, it's interesting to know that the Definitely Typed automation tooling splits type definitions into three categories: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/dt-mergebot/blob/5485345b210a4baf8e63376a930554bf2b7dd311/src/basic.ts#L11-L14"}),'"Well-liked by everyone", "Popular" and "Critical"'),". Thanks ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/atcb/status/1438559981838626817"}),"Andrew Branch for sharing that"),'! React, being very widely used, is considered "Critical".'),(0,a.kt)("p",null,"When Sebastian submitted ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped/pull/56210"}),"a pull request to upgrade the TypeScript React type definitions"),", the opportunity was taken to make breaking changes. These were not all directly related to React 18. Many were fixing long standing issues with the React type definitions."),(0,a.kt)("p",null,"Sebastian's write up on the PR is excellent and I'd encourage you to read it. Here is a summary of the breaking changes:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Removal of implicit children"),(0,a.kt)("li",{parentName:"ol"},"Remove ",(0,a.kt)("inlineCode",{parentName:"li"},"{}")," from ",(0,a.kt)("inlineCode",{parentName:"li"},"ReactFragment")," (related to 1.)"),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"this.context")," becomes ",(0,a.kt)("inlineCode",{parentName:"li"},"unknown")),(0,a.kt)("li",{parentName:"ol"},"Using ",(0,a.kt)("inlineCode",{parentName:"li"},"noImplicitAny")," now enforces a type is supplied with ",(0,a.kt)("inlineCode",{parentName:"li"},"useCallback")),(0,a.kt)("li",{parentName:"ol"},"Remove deprecated types to align with official React ones")),(0,a.kt)("p",null,"Of the above, the removal of implicit children is the most breaking of the changes and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://solverfox.dev/writing/no-implicit-children"}),"Sebastian wrote a blog post to explain the rationale"),". He was also good enough to write a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/eps1lon/types-react-codemod"}),"codemod to help"),"."),(0,a.kt)("p",null,"With that in mind, let's go upgrade a codebase to React 18!"),(0,a.kt)("h2",o({},{id:"upgrading"}),"Upgrading"),(0,a.kt)("p",null,"To demonstrate what upgrading looks like, I'm going to upgrade my aunt's website. It's a fairly simple site, and the pull request for the upgrade ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/poor-clares-arundel-koa/pull/69"}),"can be found here"),"."),(0,a.kt)("p",null,"The first thing to do is upgrade React itself in the ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),'-    "react": "^17.0.0",\n-    "react-dom": "^17.0.0",\n+    "react": "^18.0.0",\n+    "react-dom": "^18.0.0",\n')),(0,a.kt)("p",null,"Next we'll upgrade our type definitions:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),'-    "@types/react": "^17.0.0",\n-    "@types/react-dom": "^17.0.0",\n+    "@types/react": "^18.0.0",\n+    "@types/react-dom": "^18.0.0",\n')),(0,a.kt)("p",null,"When you install your dependencies, do check your lock file (",(0,a.kt)("inlineCode",{parentName:"p"},"yarn.lock")," / ",(0,a.kt)("inlineCode",{parentName:"p"},"package-lock.json")," etc). It's important that you only have ",(0,a.kt)("inlineCode",{parentName:"p"},"@types/react")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"@types/react-dom")," packages which are version 18+ listed."),(0,a.kt)("p",null,"Now that your install has completed, we start to see the following error message:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Property 'children' does not exist on type 'LoadingProps'.ts(2339)")),(0,a.kt)("p",null,"... In the following code:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"interface LoadingProps {\n  // you'll note there's no `children` prop here - this is what's prompting the error message\n  noHeader?: boolean;\n}\n\n// if props.noHeader is false then this component returns just the icon and a message\n// if props.noHeader is true then this component returns the same but wrapped in an h1\nconst Loading: React.FunctionComponent<LoadingProps> = (props) =>\n  props.noHeader ? (\n    <>\n      <FontAwesomeIcon icon={faSnowflake} spin /> Loading {props.children} ...\n    </>\n  ) : (\n    <h1 className=\"loader\">\n      <FontAwesomeIcon icon={faSnowflake} spin /> Loading {props.children} ...\n    </h1>\n  );\n")),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the above code snippet with &quot;Property &#39;children&#39; does not exist on type &#39;LoadingProps&#39;.ts(2339)&quot; displayed over the `props.children`",src:n(12330).Z,width:"1832",height:"651"})),(0,a.kt)("p",null,'What we\'re seeing here is the "removal of implicit children" in action. Before we did the upgrade, all ',(0,a.kt)("inlineCode",{parentName:"p"},"React.Component")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"React.FunctionComponent"),"s had a ",(0,a.kt)("inlineCode",{parentName:"p"},"children")," property in place which allowed React users to use this without declaring it. This is no longer the case. If you have a component with ",(0,a.kt)("inlineCode",{parentName:"p"},"children")," you have to explicitly declare them."),(0,a.kt)("p",null,"In my case, I could fix the issue by adding a ",(0,a.kt)("inlineCode",{parentName:"p"},"children")," property directly:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"interface LoadingProps {\n  noHeader?: boolean;\n  children: string;\n}\n")),(0,a.kt)("p",null,"But why write code when you can get someone else to write it on your behalf?"),(0,a.kt)("p",null,"Let's make use of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/eps1lon/types-react-codemod"}),"Sebastian's codemod")," instead. To do that we simply enter the following command:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"npx types-react-codemod preset-18 ./src\n")),(0,a.kt)("p",null,"When it runs you should find yourself with a prompt which says something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"? Pick transforms to apply (Press <space> to select, <a> to toggle all, <i> to invert selection, and <enter> to proceed)\n\u276f\u25c9 context-any\n \u25c9 deprecated-react-type\n \u25c9 deprecated-sfc-element\n \u25c9 deprecated-sfc\n \u25c9 deprecated-stateless-component\n \u25c9 implicit-children\n \u25c9 useCallback-implicit-any\n")),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the terminal prompt above",src:n(85885).Z,width:"1960",height:"290"})),(0,a.kt)("p",null,"I'm going to select ",(0,a.kt)("inlineCode",{parentName:"p"},"a")," and let the codemod run. For my own project, 37 files are updated. It's the same modification for all files. In each case, a components props are wrapped by ",(0,a.kt)("inlineCode",{parentName:"p"},"React.PropsWithChildren"),". Let's look at what that looks like for our ",(0,a.kt)("inlineCode",{parentName:"p"},"Loading")," component:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),"-const Loading: React.FunctionComponent<LoadingProps> = (props) =>\n+const Loading: React.FunctionComponent<React.PropsWithChildren<LoadingProps>> = (props) =>\n")),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"PropsWithChildren")," is very simple; it just adds ",(0,a.kt)("inlineCode",{parentName:"p"},"children")," back, like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"type PropsWithChildren<P> = P & { children?: ReactNode | undefined };\n")),(0,a.kt)("p",null,"This resolves the compilation issues we were having earlier; no type issues are reported anymore."),(0,a.kt)("h2",o({},{id:"wrapping-up"}),"Wrapping up"),(0,a.kt)("p",null,"We now understand how the breaking type changes came to present with React 18, and we know how to upgrade our codebase using the handy codemod. Thanks ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/sebsilbermann"}),"Sebastian Silbermann")," for not only putting this work into getting the type definitions in the best state they could be, and making it easier for the community to upgrade."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/upgrading-react-18-typescript/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/upgrading-react-18-typescript/"})))}d.isMDXComponent=!0},63298:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"static-web-apps-azure-devops-named-preview-environments",title:"Azure Static Web Apps: named preview environments with Azure DevOps",authors:"johnnyreilly",tags:["Azure Static Web Apps","azure devops"],image:"./title-image.png",description:'Azure Static Web Apps have just released a new feature for Azure DevOps users called "named preview environments". Let us have a look',hide_table_of_contents:!1},s=void 0,l={permalink:"/static-web-apps-azure-devops-named-preview-environments",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-05-07-static-web-apps-azure-devops-named-preview-environments/index.md",source:"@site/blog/2022-05-07-static-web-apps-azure-devops-named-preview-environments/index.md",title:"Azure Static Web Apps: named preview environments with Azure DevOps",description:'Azure Static Web Apps have just released a new feature for Azure DevOps users called "named preview environments". Let us have a look',date:"2022-05-07T00:00:00.000Z",formattedDate:"May 7, 2022",tags:[{label:"Azure Static Web Apps",permalink:"/tags/azure-static-web-apps"},{label:"azure devops",permalink:"/tags/azure-devops"}],readingTime:5.135,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"static-web-apps-azure-devops-named-preview-environments",title:"Azure Static Web Apps: named preview environments with Azure DevOps",authors:"johnnyreilly",tags:["Azure Static Web Apps","azure devops"],image:"./title-image.png",description:'Azure Static Web Apps have just released a new feature for Azure DevOps users called "named preview environments". Let us have a look',hide_table_of_contents:!1},prevItem:{title:"Azure Static Web Apps: Node.js 16 / 18 and Oryx",permalink:"/azure-static-web-apps-node-16-oryx"},nextItem:{title:"Upgrading to React 18 with TypeScript",permalink:"/upgrading-to-react-18-typescript"}},p={image:n(88461).Z,authorsImageUrls:[void 0]},u=[{value:"What are named preview environments?",id:"what-are-named-preview-environments",level:2},{value:"Deploy Static Web App with Bicep",id:"deploy-static-web-app-with-bicep",level:2},{value:"Azure Pipelines",id:"azure-pipelines",level:2},{value:"Creating a site",id:"creating-a-site",level:2},{value:"Testing the preview",id:"testing-the-preview",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'Azure Static Web Apps have just released a new feature for Azure DevOps users called "named preview environments". They allow users to deploy changes to an environment, prior to merging.'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Azure Static Web App Deploy Previews with Azure DevOps&quot; with a Azure, Bicep and Azure DevOps logos",src:n(88461).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"what-are-named-preview-environments"}),"What are named preview environments?"),(0,a.kt)("p",null,"The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-gb/azure/static-web-apps/named-environments?tabs=azure-devops"}),"announcement")," describes them like so:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"You can configure your site to deploy every change to a named environment. This preview deployment is published at a stable URL that includes the environment name. For example, if the environment is named ",(0,a.kt)("inlineCode",{parentName:"p"},"release"),", then the preview is available at a location like ",(0,a.kt)("inlineCode",{parentName:"p"},"<DEFAULT_HOST_NAME>-release.<LOCATION>.azurestaticapps.net"),".")),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"/azure-static-web-app-deploy-previews-with-azure-devops"}),"I'd previously written about how to hand roll preview environments with Azure DevOps using Bicep"),". But now there's dedicated functionality that covers this, let's see if we can test it out."),(0,a.kt)("h2",o({},{id:"deploy-static-web-app-with-bicep"}),"Deploy Static Web App with Bicep"),(0,a.kt)("p",null,"We'll start with an empty repo in Azure DevOps and we'll create the Bicep template for deploying a Static Web App to Azure:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param appName string\nparam repositoryUrl string\nparam repositoryBranch string\n\nparam location string = resourceGroup().location\nparam skuName string = 'Free'\nparam skuTier string = 'Free'\n\nresource staticWebApp 'Microsoft.Web/staticSites@2021-03-01' = {\n  name: appName\n  location: location\n  sku: {\n    name: skuName\n    tier: skuTier\n  }\n  properties: {\n    // The provider, repositoryUrl and branch fields are required for successive deployments to succeed\n    // for more details see: https://github.com/Azure/static-web-apps/issues/516\n    provider: 'DevOps'\n    repositoryUrl: repositoryUrl\n    branch: repositoryBranch\n    buildProperties: {\n      skipGithubActionWorkflowGeneration: true\n    }\n  }\n}\n\noutput staticWebAppDefaultHostName string = staticWebApp.properties.defaultHostname // eg gentle-bush-0db02ce03.azurestaticapps.net\noutput staticWebAppId string = staticWebApp.id\noutput staticWebAppName string = staticWebApp.name\n")),(0,a.kt)("p",null,"The above deploys a Static Web App configured for Azure DevOps."),(0,a.kt)("p",null,"We are now outputting the ",(0,a.kt)("inlineCode",{parentName:"p"},"defaultHostname"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"id")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"name")," of our newly provisioned SWA. Doing this allows us to do build things in the pipeline around our SWA should we choose to."),(0,a.kt)("h2",o({},{id:"azure-pipelines"}),"Azure Pipelines"),(0,a.kt)("p",null,"We're going to need an Azure Pipeline for this. We'll create an ",(0,a.kt)("inlineCode",{parentName:"p"},"azure-pipelines.yml")," file in the root of our repo:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"trigger:\n  - '*'\n\npool:\n  vmImage: ubuntu-latest\n\nvariables:\n  # subscriptionId is a variable defined on the pipeline itself\n  - name: appName\n    value: 'our-static-web-app'\n  - name: location\n    value: 'westeurope' #\xa0at time of writing static sites are available in limited locations such as westeurope\n  - name: serviceConnection\n    value: 'azure-resource-manager-rg-static-web-apps' # Azure Resource Manager Service Connection created in Azure DevOps with permission against the rg-static-web-apps resource group in Azure\n  - name: azureResourceGroup # this resource group lives in westeurope\n    value: 'rg-static-web-apps'\n  - name: isMain\n    value: $[eq(variables['Build.SourceBranch'], 'refs/heads/main')] # runtime expression\n\nsteps:\n  - checkout: self\n    submodules: true\n\n  - bash: az bicep build --file infra/static-web-app/main.bicep\n    displayName: 'Compile Bicep to ARM'\n\n  - task: AzureResourceManagerTemplateDeployment@3\n    name: DeployStaticWebAppInfra\n    displayName: Deploy Static Web App infra\n    inputs:\n      deploymentScope: Resource Group\n      azureResourceManagerConnection: $(serviceConnection)\n      subscriptionId: $(subscriptionId)\n      action: Create Or Update Resource Group\n      resourceGroupName: $(azureResourceGroup)\n      location: $(location)\n      templateLocation: Linked artifact\n      csmFile: 'infra/static-web-app/main.json' # created by bash script\n      overrideParameters: >-\n        -repositoryUrl $(Build.Repository.Uri)\n        -repositoryBranch $(Build.SourceBranchName)\n        -appName $(appName)\n      deploymentMode: Incremental\n      deploymentOutputs: deploymentOutputs\n\n  - task: PowerShell@2\n    name: 'SetDeploymentOutputVariables'\n    displayName: 'Set Deployment Output Variables'\n    inputs:\n      targetType: inline\n      script: |\n        $armOutputObj = '$(deploymentOutputs)' | ConvertFrom-Json\n        $armOutputObj.PSObject.Properties | ForEach-Object {\n          $keyname = $_.Name\n          $value = $_.Value.value\n\n          # Creates a standard pipeline variable\n          Write-Output \"##vso[task.setvariable variable=$keyName;]$value\"\n\n          # Display keys and values in pipeline\n          Write-Output \"output variable: $keyName $value\"\n        }\n      pwsh: true\n\n  - task: AzureCLI@2\n    displayName: 'Acquire API key for deployment'\n    inputs:\n      azureSubscription: $(serviceConnection)\n      scriptType: bash\n      scriptLocation: inlineScript\n      inlineScript: |\n        APIKEY=$(az staticwebapp secrets list --name $(staticWebAppName) | jq -r '.properties.apiKey')\n        echo \"##vso[task.setvariable variable=apiKey;issecret=true]$APIKEY\"\n\n  - task: AzureStaticWebApp@0\n    name: DeployStaticWebApp\n    displayName: Deploy Static Web App\n    condition: and(succeeded(), eq(variables.isMain, 'true'))\n    inputs:\n      app_location: 'static-web-app'\n      # api_location: 'api'\n      output_location: 'build'\n      azure_static_web_apps_api_token: $(apiKey)\n\n  - task: AzureStaticWebApp@0\n    name: DeployStaticWebAppPreview\n    displayName: Deploy Static Web App to named preview environment\n    condition: and(succeeded(), ne(variables.isMain, 'true'))\n    inputs:\n      app_location: 'static-web-app'\n      # api_location: 'api'\n      output_location: 'build'\n      azure_static_web_apps_api_token: $(apiKey)\n      deployment_environment: 'pullrequest'\n")),(0,a.kt)("p",null,"There's two significant parts to the above pipeline. First the trigger, which ensures we run the pipeline on each change:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"trigger:\n  - '*' # this means we'll trigger on each change\n")),(0,a.kt)("p",null,"Next the two ",(0,a.kt)("inlineCode",{parentName:"p"},"AzureStaticWebApp@0")," tasks:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- task: AzureStaticWebApp@0\n  name: DeployStaticWebApp\n  displayName: Deploy Static Web App\n  condition: and(succeeded(), eq(variables.isMain, 'true'))\n  inputs:\n    app_location: 'static-web-app'\n    # api_location: 'api'\n    output_location: 'build'\n    azure_static_web_apps_api_token: $(apiKey)\n\n- task: AzureStaticWebApp@0\n  name: DeployStaticWebAppPreview\n  displayName: Deploy Static Web App to named preview environment\n  condition: and(succeeded(), ne(variables.isMain, 'true'))\n  inputs:\n    app_location: 'static-web-app'\n    # api_location: 'api'\n    output_location: 'build'\n    azure_static_web_apps_api_token: $(apiKey)\n    deployment_environment: 'pullrequest'\n")),(0,a.kt)("p",null,"Depending upon whether we're using the ",(0,a.kt)("inlineCode",{parentName:"p"},"main")," branch or not, we either use or do not use the ",(0,a.kt)("inlineCode",{parentName:"p"},"deployment_environment")," property. When it is not the ",(0,a.kt)("inlineCode",{parentName:"p"},"main")," branch we supply the ",(0,a.kt)("inlineCode",{parentName:"p"},"deployment_environment")," property with a value of ",(0,a.kt)("inlineCode",{parentName:"p"},"'pullrequest'"),". This is the name of our preview environment; and the value will be used in the URL we end up with. In my own experiments it seems that using hyphens in the name can be problematic - so I would advise avoiding this."),(0,a.kt)("h2",o({},{id:"creating-a-site"}),"Creating a site"),(0,a.kt)("p",null,"So we can test this out, we need a static web app to deploy. We'll spin up a simple Docusaurus site:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"npx create-docusaurus@latest static-web-app classic\n")),(0,a.kt)("p",null,"Upon the initial commit of our main branch we end up with a website, once the pipeline has run:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Azure Pipelines, including the phrase &quot;Visit your site at: https://zealous-beach-05119b203.1.azurestaticapps.net&quot;",src:n(21041).Z,width:"2467",height:"1307"})),(0,a.kt)("p",null,"Note the URL:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Docusaurus site deployed to Azure Static Web Apps",src:n(81648).Z,width:"1552",height:"1100"})),(0,a.kt)("h2",o({},{id:"testing-the-preview"}),"Testing the preview"),(0,a.kt)("p",null,"Now our main site is deployed, let's test out the preview environment. We'll create a new branch:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"git checkout -b test-preview\n")),(0,a.kt)("p",null,"And we'll update the ",(0,a.kt)("inlineCode",{parentName:"p"},"pages.index.js"),' file to include this message: "Hello from preview environment!". Once we commit and push our changes, we see the pipeline run:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Azure Pipelines, including the phrase &quot;Visit your site at: https://zealous-beach-05119b203-pullrequest.westeurope.1.azurestaticapps.net&quot;",src:n(20161).Z,width:"2457",height:"1291"})),(0,a.kt)("p",null,"Note that this time we are deploying to our preview environment instead."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Docusaurus site deployed to Azure Static Web Apps",src:n(39517).Z,width:"1558",height:"1102"})),(0,a.kt)("p",null,'As we can see, this preview is showing our "Hello from preview environment!" changes as well; whilst the main environment is unchanged.'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"animated GIF demonstrating both environments with different content",src:n(9413).Z,width:"1584",height:"1224"})),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"Azure DevOps now has support for named preview environments for Azure Static Web Apps; a powerful addition to the product."),(0,a.kt)("p",null,"You can see further discussion of this feature on the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/static-web-apps/issues/510#issuecomment-1116307462"}),"Azure/static-web-apps repo"),"."))}d.isMDXComponent=!0},83928:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-static-web-apps-node-16-oryx",title:"Azure Static Web Apps: Node.js 16 / 18 and Oryx",authors:"johnnyreilly",tags:["Azure Static Web Apps","GitHub Actions","Docusaurus","Node.js","Oryx"],image:"./title-image.png",description:"Azure Static Web Apps presently fixes to Node.js 14 when building. If you require a different version of Node to build, here is how.",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-static-web-apps-node-16-oryx",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-05-28-azure-static-web-apps-node-16-oryx/index.md",source:"@site/blog/2022-05-28-azure-static-web-apps-node-16-oryx/index.md",title:"Azure Static Web Apps: Node.js 16 / 18 and Oryx",description:"Azure Static Web Apps presently fixes to Node.js 14 when building. If you require a different version of Node to build, here is how.",date:"2022-05-28T00:00:00.000Z",formattedDate:"May 28, 2022",tags:[{label:"Azure Static Web Apps",permalink:"/tags/azure-static-web-apps"},{label:"GitHub Actions",permalink:"/tags/git-hub-actions"},{label:"Docusaurus",permalink:"/tags/docusaurus"},{label:"Node.js",permalink:"/tags/node-js"},{label:"Oryx",permalink:"/tags/oryx"}],readingTime:2.065,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-static-web-apps-node-16-oryx",title:"Azure Static Web Apps: Node.js 16 / 18 and Oryx",authors:"johnnyreilly",tags:["Azure Static Web Apps","GitHub Actions","Docusaurus","Node.js","Oryx"],image:"./title-image.png",description:"Azure Static Web Apps presently fixes to Node.js 14 when building. If you require a different version of Node to build, here is how.",hide_table_of_contents:!1},prevItem:{title:"TypeScript 4.7 and ECMAScript Module Support",permalink:"/typescript-4-7-and-ecmascript-module-support"},nextItem:{title:"Azure Static Web Apps: named preview environments with Azure DevOps",permalink:"/static-web-apps-azure-devops-named-preview-environments"}},p={image:n(90764).Z,authorsImageUrls:[void 0]},u=[{value:"The engine &quot;node&quot; is incompatible",id:"the-engine-node-is-incompatible",level:2},{value:"Solution 1: <code>engines</code> to the rescue!",id:"solution-1-engines-to-the-rescue",level:2},{value:"Solution 2: Environment variables for the win!",id:"solution-2-environment-variables-for-the-win",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Azure Static Web Apps presently fixes to Node.js 14 when building. If you require a different version of Node to build, this can be a problem. This post outlines a workaround."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Azure Static Web Apps: Node.js 16 and Oryx&quot; with Azure and Node.js logos",src:n(90764).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"the-engine-node-is-incompatible"}),'The engine "node" is incompatible'),(0,a.kt)("p",null,"As I was upgrading this blog to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/releases/tag/v2.0.0-beta.21"}),"Docusaurus v2.0.0-beta.21")," I noticed this error in my build:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),'error @docusaurus/core@2.0.0-beta.21: The engine "node" is incompatible with this module. Expected version ">=16.14". Got "14.19.1"\nerror Found incompatible module.\n\n\n---End of Oryx build logs---\nOryx has failed to build the solution.\n')),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/Oryx"}),"Oryx"),", which performs the build for Static Web Apps, is fixed to Node 14 for the default LTS version (for now, this will definitely change sometime in 2023). You can check for the constant ",(0,a.kt)("inlineCode",{parentName:"p"},"NodeLtsVersion")," ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/Oryx/blob/main/src/BuildScriptGenerator/Node/NodeConstants.cs"}),"here")," to check which version of Node Oryx is using as the ",(0,a.kt)("inlineCode",{parentName:"p"},"DEFAULT_NODE_VERSION"),". To override this default, can either use an ",(0,a.kt)("inlineCode",{parentName:"p"},"engines")," setting in ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json"),", or use an environment setting in the The GitHub Action."),(0,a.kt)("h2",o({},{id:"solution-1-engines-to-the-rescue"}),"Solution 1: ",(0,a.kt)("inlineCode",{parentName:"h2"},"engines")," to the rescue!"),(0,a.kt)("p",null,"You can specify the node version you require in your ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," with the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.npmjs.com/cli/v7/configuring-npm/package-json#engines"}),(0,a.kt)("inlineCode",{parentName:"a"},"engines"))," property. This means you can do something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'  "engines": {\n    "node": ">=16"\n  }\n')),(0,a.kt)("p",null,"And have the version of Node.js you require installed by Oryx."),(0,a.kt)("p",null,"Thanks to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/cormacpayne"}),"Cormac McCarthy")," for his ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/static-web-apps/issues/694#issuecomment-1137492562"}),"comment")," which lead me to try this approach out."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/pull/228"}),"You can see the PR where I made this change for my blog here.")),(0,a.kt)("h2",o({},{id:"solution-2-environment-variables-for-the-win"}),"Solution 2: Environment variables for the win!"),(0,a.kt)("p",null,"You can change the version for the build step using an environnment variable. This is documented in the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://learn.microsoft.com/en-us/azure/developer/javascript/how-to/with-web-app/static-web-app-with-swa-cli/create-static-web-app"}),"Microsoft Docs")),(0,a.kt)("p",null,"Modify the workflow file, from the ",(0,a.kt)("inlineCode",{parentName:"p"},"./github/workflows")," directory. Just add these last two lines:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),"     - name: Build And Deploy\n        id: builddeploy\n        uses: Azure/static-web-apps-deploy@v1\n        with:\n          azure_static_web_apps_api_token: ${{ secrets.AZURE_STATIC_WEB_APPS_API_TOKEN_SAMPLE }}\n          repo_token: ${{ secrets.GITHUB_TOKEN }} # Used for Github integrations (i.e. PR comments)\n          action: 'upload'\n          app_location: '/' # App source code path\n          api_location: 'api' # Api source code path - optional\n          output_location: 'public' # Built app content directory - optional\n        env:  # Put a node version on the following line\n          NODE_VERSION: 18.12.0\n")),(0,a.kt)("p",null,"You can use a specific node version (18.12.0 or 16.18.0) or a major node version (18 or 16). The latter approach installs the latest minor version."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Note:")," The Oryx image is updated quarterly. You can get a list of the supported node versions ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/Oryx/blob/main/doc/supportedPlatformVersions.md"}),"here"),"."),(0,a.kt)("p",null,"Thanks to Eric C\xf4t\xe9 from ",(0,a.kt)("a",o({parentName:"p"},{href:"https://reactAcademy.live"}),"React Academy")," for the information."))}d.isMDXComponent=!0},43037:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-4-7-and-ecmascript-module-support",title:"TypeScript 4.7 and ECMAScript Module Support",authors:"johnnyreilly",tags:["typescript","ECMAScript Modules"],image:"./title-image.png",description:"As part of the TypeScript 4.7 release comes a major upgrade to ECMAScript Module Support for Node.js. This post takes a look at what that means.",hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-4-7-and-ecmascript-module-support",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-06-07-typescript-4-7-and-ecmascript-module-support/index.md",source:"@site/blog/2022-06-07-typescript-4-7-and-ecmascript-module-support/index.md",title:"TypeScript 4.7 and ECMAScript Module Support",description:"As part of the TypeScript 4.7 release comes a major upgrade to ECMAScript Module Support for Node.js. This post takes a look at what that means.",date:"2022-06-07T00:00:00.000Z",formattedDate:"June 7, 2022",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"ECMAScript Modules",permalink:"/tags/ecma-script-modules"}],readingTime:6.1,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-4-7-and-ecmascript-module-support",title:"TypeScript 4.7 and ECMAScript Module Support",authors:"johnnyreilly",tags:["typescript","ECMAScript Modules"],image:"./title-image.png",description:"As part of the TypeScript 4.7 release comes a major upgrade to ECMAScript Module Support for Node.js. This post takes a look at what that means.",hide_table_of_contents:!1},prevItem:{title:"Azure Container Apps: dapr pubsub",permalink:"/azure-container-apps-pubsub"},nextItem:{title:"Azure Static Web Apps: Node.js 16 / 18 and Oryx",permalink:"/azure-static-web-apps-node-16-oryx"}},p={image:n(62289).Z,authorsImageUrls:[void 0]},u=[{value:"A short history of ECMAScript modules",id:"a-short-history-of-ecmascript-modules",level:2},{value:"TypeScript support",id:"typescript-support",level:2},{value:"Making a module",id:"making-a-module",level:2},{value:"Adding TypeScript 4.7",id:"adding-typescript-47",level:2},{value:"Writing TypeScript ECMAScript modules",id:"writing-typescript-ecmascript-modules",level:2},{value:"ECMAScript and CommonJS side by side",id:"ecmascript-and-commonjs-side-by-side",level:2},{value:"What files are emitted?",id:"what-files-are-emitted",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"As part of the TypeScript 4.7 release comes a major upgrade to ECMAScript Module Support for Node.js. This post takes a look at what that means."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Upgrading to React 18 with TypeScript&quot; with the React, TypeScript and Definitely Typed logos`",src:n(62289).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"a-short-history-of-ecmascript-modules"}),"A short history of ECMAScript modules"),(0,a.kt)("p",null,'When ES6 shipped back in 2015, with it came the concept of modules for JavaScript. Back then it was known as "ES6 modules". These days they are called ECMAScript modules.'),(0,a.kt)("p",null,"Whilst writing code using ECMAScript module semantics came quickly for front end, for the back end (which is generally Node.js) that has not the case. There's a number of reasons for this:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"There was already an established module system used in Node.js called ",(0,a.kt)("a",o({parentName:"li"},{href:"https://en.wikipedia.org/wiki/CommonJS"}),"CommonJS")),(0,a.kt)("li",{parentName:"ol"},"Node.js itself did not initially offer support for ECMAScript modules; in large part because of the problems associated with being able to support CommonJS ",(0,a.kt)("em",{parentName:"li"},"as well")," as ECMAScript modules.")),(0,a.kt)("p",null,"However, with the release Node.js 14 support for ECMAScript modules (AKA \"ESM\") landed. If you're interested in the details of that module support then it's worth ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/es-modules-in-node-today/"}),"reading this post on ECMAScript modules"),"."),(0,a.kt)("h2",o({},{id:"typescript-support"}),"TypeScript support"),(0,a.kt)("p",null,"The TypeScript team have been experimenting with ways to offer support for ECMAScript modules from a Node.js perspective, and with TypeScript 4.7 support is being released."),(0,a.kt)("p",null,"In this post we'll test drive that support by attempting to build a simple module in TypeScript using the new ECMAScript modules support. As we do this, we'll discuss what it looks like to author ECMAScript modules for Node.js in TypeScript."),(0,a.kt)("p",null,"Let's go!"),(0,a.kt)("h2",o({},{id:"making-a-module"}),"Making a module"),(0,a.kt)("p",null,"We're going to make a module named ",(0,a.kt)("inlineCode",{parentName:"p"},"greeter")," - let's initialise it:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"mkdir greeter\ncd greeter\nnpm init --yes\n")),(0,a.kt)("p",null,"We now have a ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," that looks something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "name": "greeter",\n  "version": "1.0.0",\n  "description": "",\n  "main": "index.js",\n  "scripts": {\n    "test": "echo \\"Error: no test specified\\" && exit 1"\n  },\n  "keywords": [],\n  "author": "",\n  "license": "ISC"\n}\n')),(0,a.kt)("p",null,"Node.js supports a new setting in ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," called ",(0,a.kt)("inlineCode",{parentName:"p"},"type"),". ",(0,a.kt)("a",o({parentName:"p"},{href:"https://nodejs.org/api/packages.html#type"}),'This can be set to either "module" or "commonjs"'),". To quote the docs:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Files ending with ",(0,a.kt)("inlineCode",{parentName:"p"},".js")," are loaded as ES modules when the nearest parent package.json file contains a top-level field ",(0,a.kt)("inlineCode",{parentName:"p"},'"type"')," with a value of ",(0,a.kt)("inlineCode",{parentName:"p"},'"module"'),".")),(0,a.kt)("p",null,"With that in mind, we'll add a ",(0,a.kt)("inlineCode",{parentName:"p"},'"type": "module"')," to our ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json"),"."),(0,a.kt)("p",null,"We're now ECMAScript module support compliant, let's start adding some TypeScript."),(0,a.kt)("h2",o({},{id:"adding-typescript-47"}),"Adding TypeScript 4.7"),(0,a.kt)("p",null,"In order that we can make use of TypeScript ECMAScript modules support we're going to install TypeScript 4.7 (currently in beta):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"npm install typescript@4.7.0-beta --save\n")),(0,a.kt)("p",null,"With this in place we'll initialise a TypeScript project:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"npx tsc --init\n")),(0,a.kt)("p",null,"This will create a ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," file which contains many options. We will tweak the ",(0,a.kt)("inlineCode",{parentName:"p"},"module")," option to be ",(0,a.kt)("inlineCode",{parentName:"p"},"nodenext")," to opt into ECMAScript module support:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "compilerOptions": {\n    // ...\n    "module": "nodenext" /* Specify what module code is generated. */,\n    "outDir": "./lib" /* Specify an output folder for all emitted files. */,\n    "declaration": true /* Generate .d.ts files from TypeScript and JavaScript files in your project. */\n\n    // ...\n  }\n}\n')),(0,a.kt)("p",null,"We've also set the ",(0,a.kt)("inlineCode",{parentName:"p"},"outDir")," option, such that compiled JavaScript will go into that directory, and the ",(0,a.kt)("inlineCode",{parentName:"p"},"declaration")," option such that ",(0,a.kt)("inlineCode",{parentName:"p"},".d.ts")," files will be generated. We'll also update the ",(0,a.kt)("inlineCode",{parentName:"p"},'"scripts"')," section of our ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," to include ",(0,a.kt)("inlineCode",{parentName:"p"},"build")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"start")," scripts:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'  "scripts": {\n    "build": "tsc",\n    "start": "node lib/index.js"\n  },\n')),(0,a.kt)("h2",o({},{id:"writing-typescript-ecmascript-modules"}),"Writing TypeScript ECMAScript modules"),(0,a.kt)("p",null,"With all that set up, we're ready to write some TypeScript ECMAScript modules. First we'll write a ",(0,a.kt)("inlineCode",{parentName:"p"},"greetings.ts")," module:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export function helloWorld(): string {\n  return 'hello world!';\n}\n")),(0,a.kt)("p",null,"There is nothing new or surprising about this; it's just a module exporting a single function named ",(0,a.kt)("inlineCode",{parentName:"p"},"helloWorld"),". It becomes more interesting as we write our ",(0,a.kt)("inlineCode",{parentName:"p"},"index.ts")," module:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { helloWorld } from './greetings.js';\n\nconst greeting = helloWorld();\n\nconsole.log(greeting);\n")),(0,a.kt)("p",null,"The code above imports our ",(0,a.kt)("inlineCode",{parentName:"p"},"helloWorld")," function and then executes it; writing the output to the console. Not particularly noteworthy. However, the way we import is. We are importing from ",(0,a.kt)("inlineCode",{parentName:"p"},"'./greetings.js'"),". In the past we would have written:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { helloWorld } from './greetings';\n")),(0,a.kt)("p",null,"Now we write:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { helloWorld } from './greetings.js';\n")),(0,a.kt)("p",null,"This can feel slightly odd and unnatural because we have no ",(0,a.kt)("inlineCode",{parentName:"p"},"greetings.js")," in our codebase; only ",(0,a.kt)("inlineCode",{parentName:"p"},"greetings.ts"),". The imports we're writing, reflect the code that will end up being executed; once our TypeScript has been compiled to JavaScript. In ES modules relative import paths need to use extensions."),(0,a.kt)("p",null,"The easiest way to demonstrate that this is legitimate, is to run the code:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"npm run build && npm start\n")),(0,a.kt)("p",null,"Which results in:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"> greeter@1.0.0 build\n> tsc\n\n\n> greeter@1.0.0 start\n> node lib/index.js\n\nhello world!\n")),(0,a.kt)("p",null,"So it works!"),(0,a.kt)("h2",o({},{id:"ecmascript-and-commonjs-side-by-side"}),"ECMAScript and CommonJS side by side"),(0,a.kt)("p",null,"Part of ECMAScript module support is the ability to specify the module type of a file based on the file suffix. If you use ",(0,a.kt)("inlineCode",{parentName:"p"},".mjs"),", you're explicitly saying a file is an ECMAScript module. If you use ",(0,a.kt)("inlineCode",{parentName:"p"},".cjs"),", you're explicitly saying a file is an CommonJS module. If you're authoring with TypeScript you'd use ",(0,a.kt)("inlineCode",{parentName:"p"},"mts")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"cts")," respectively and they'd be transpiled to ",(0,a.kt)("inlineCode",{parentName:"p"},"mjs")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"cjs"),"."),(0,a.kt)("p",null,"Happily Node.js allows ES modules to import CommonJS modules as if they were ES modules with a default export; which is good news for interop. Let's test that out by writing a ",(0,a.kt)("inlineCode",{parentName:"p"},"oldGreetings.cts")," module:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export function helloOldWorld(): string {\n  return 'hello old world!';\n}\n")),(0,a.kt)("p",null,"Exactly the same syntax as before. We'll adjust our ",(0,a.kt)("inlineCode",{parentName:"p"},"index.ts")," to consume this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { helloWorld } from './greetings.js';\nimport { helloOldWorld } from './oldGreetings.cjs';\n\nconsole.log(helloWorld());\nconsole.log(helloOldWorld());\n")),(0,a.kt)("p",null,"Note that we're importing from ",(0,a.kt)("inlineCode",{parentName:"p"},"'./oldGreetings.cjs'"),". We'll see if it works:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"npm run build && npm start\n")),(0,a.kt)("p",null,"Which results in:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"> greeter@1.0.0 build\n> tsc\n\n\n> greeter@1.0.0 start\n> node lib/index.js\n\nhello world!\nhello old world!\n")),(0,a.kt)("p",null,"It does work!"),(0,a.kt)("h2",o({},{id:"what-files-are-emitted"}),"What files are emitted?"),(0,a.kt)("p",null,"Before we close out, it might be interesting to look at what TypeScript is doing when we run our ",(0,a.kt)("inlineCode",{parentName:"p"},"npm run build"),". It transpiles our TypeScript into JavaScript in our ",(0,a.kt)("inlineCode",{parentName:"p"},"lib")," directory:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A screenshot of VS Code showing the files in the lib directory",src:n(76198).Z,width:"331",height:"314"})),(0,a.kt)("p",null,"Note the ",(0,a.kt)("inlineCode",{parentName:"p"},"greetings.ts")," file has resulted in ",(0,a.kt)("inlineCode",{parentName:"p"},"greetings.js")," and a ",(0,a.kt)("inlineCode",{parentName:"p"},"greetings.d.ts")," files. Whereas ",(0,a.kt)("inlineCode",{parentName:"p"},"oldGreetings.cts")," has resulted in ",(0,a.kt)("inlineCode",{parentName:"p"},"oldGreetings.cjs")," and a ",(0,a.kt)("inlineCode",{parentName:"p"},"oldGreetings.d.cts")," files; reflecting the different module types represented."),(0,a.kt)("p",null,"It's also interesting to look at the difference in the emitted JavaScript. When you consider how similar the source files were. If you look at ",(0,a.kt)("inlineCode",{parentName:"p"},"greetings.js"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"export function helloWorld() {\n  return 'hello world!';\n}\n")),(0,a.kt)("p",null,"This is the same code as ",(0,a.kt)("inlineCode",{parentName:"p"},"greetings.ts")," but with types stripped. However, if we look at ",(0,a.kt)("inlineCode",{parentName:"p"},"oldGreetings.cjs")," we see this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"'use strict';\nObject.defineProperty(exports, '__esModule', { value: true });\nexports.helloOldWorld = void 0;\nfunction helloOldWorld() {\n  return 'hello old world!';\n}\nexports.helloOldWorld = helloOldWorld;\n")),(0,a.kt)("p",null,"In the middle the same code as ",(0,a.kt)("inlineCode",{parentName:"p"},"oldGreetings.cts")," but with types stripped, but around that boilerplate code that TypeScript is emitting for us to aid in interop."),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"We've seen what TypeScript support for ECMAScript modules looks like, and how to set up a module to embrace it."),(0,a.kt)("p",null,"If you'd like to read up further on the topic, the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://devblogs.microsoft.com/typescript/announcing-typescript-4-7-beta/#esm-nodejs"}),"TypeScript 4.7 beta release notes")," are an excellent resource."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/typescript-4-7-ecmascript-module-support/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/typescript-4-7-ecmascript-module-support/"})))}d.isMDXComponent=!0},83054:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-container-apps-pubsub",title:"Azure Container Apps: dapr pubsub",authors:"johnnyreilly",tags:["Azure Container Apps","dapr","Bicep","GitHub Actions","GitHub container registry","devcontainer","debug"],image:"./title-image.png",description:"This post shows how to build and deploy two Azure Container Apps using Bicep and GitHub Actions which communicate using daprs pubsub building block.",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-container-apps-pubsub",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-06-21-azure-container-apps-pubsub/index.md",source:"@site/blog/2022-06-21-azure-container-apps-pubsub/index.md",title:"Azure Container Apps: dapr pubsub",description:"This post shows how to build and deploy two Azure Container Apps using Bicep and GitHub Actions which communicate using daprs pubsub building block.",date:"2022-06-21T00:00:00.000Z",formattedDate:"June 21, 2022",tags:[{label:"Azure Container Apps",permalink:"/tags/azure-container-apps"},{label:"dapr",permalink:"/tags/dapr"},{label:"Bicep",permalink:"/tags/bicep"},{label:"GitHub Actions",permalink:"/tags/git-hub-actions"},{label:"GitHub container registry",permalink:"/tags/git-hub-container-registry"},{label:"devcontainer",permalink:"/tags/devcontainer"},{label:"debug",permalink:"/tags/debug"}],readingTime:20.725,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-container-apps-pubsub",title:"Azure Container Apps: dapr pubsub",authors:"johnnyreilly",tags:["Azure Container Apps","dapr","Bicep","GitHub Actions","GitHub container registry","devcontainer","debug"],image:"./title-image.png",description:"This post shows how to build and deploy two Azure Container Apps using Bicep and GitHub Actions which communicate using daprs pubsub building block.",hide_table_of_contents:!1},prevItem:{title:"Azure Static Web Apps: Failed to deploy the Azure Functions",permalink:"/static-web-apps-failed-to-deploy-the-azure-functions"},nextItem:{title:"TypeScript 4.7 and ECMAScript Module Support",permalink:"/typescript-4-7-and-ecmascript-module-support"}},p={image:n(48150).Z,authorsImageUrls:[void 0]},u=[{value:"You got mail: service invocation",id:"you-got-mail-service-invocation",level:2},{value:".NET meet mailgun",id:"net-meet-mailgun",level:3},{value:"Webservice gets a form",id:"webservice-gets-a-form",level:3},{value:"Secrets in Bicep",id:"secrets-in-bicep",level:3},{value:"You got mail: pubsub!",id:"you-got-mail-pubsub",level:2},{value:"Publishing with dapr-client",id:"publishing-with-dapr-client",level:3},{value:"Subscribing",id:"subscribing",level:3},{value:"Components",id:"components",level:3},{value:"<code>pubsub.yaml</code>",id:"pubsubyaml",level:4},{value:"<code>statestore.yaml</code>",id:"statestoreyaml",level:4},{value:"<code>subscription.yaml</code>",id:"subscriptionyaml",level:4},{value:"Bicep",id:"bicep",level:3},{value:"No declarative pubsub subscription support",id:"no-declarative-pubsub-subscription-support",level:3},{value:"You got mail: programmatic subscriptions!",id:"you-got-mail-programmatic-subscriptions",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This post shows how to build and deploy two Azure Container Apps using Bicep and GitHub Actions. These apps will communicate using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.dapr.io/"}),"dapr"),"'s ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.dapr.io/developing-applications/building-blocks/pubsub/howto-publish-subscribe/"}),"publish & subscribe (pubsub) building block"),"."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Azure Container Apps: dapr pubsub&quot;  with the dapr, Bicep, Azure Container Apps and GitHub Actions logos",src:n(48150).Z,width:"1600",height:"900"})),(0,a.kt)("p",null,"This post will build upon code written in a ",(0,a.kt)("a",o({parentName:"p"},{href:"/azure-container-apps-dapr-bicep-github-actions-debug-devcontainer"}),"previous post")," which built and deployed a simple web application to Azure Container Apps using Bicep and GitHub Actions using the GitHub container registry. Behind the scenes, that app was made up of a .NET app and a Node.js app communicating via dapr's ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.dapr.io/developing-applications/building-blocks/service-invocation/howto-invoke-discover-services/"}),"service invocation building block"),"."),(0,a.kt)("p",null,"There's a good chance you've just googled \"pubsub dapr azure container apps\" and you don't want to read through all this. You just want the code. That's fine. The code for this blogpost is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/dapr-devcontainer-debug-and-deploy/releases/tag/v2.0.0"}),"here"),"."),(0,a.kt)("h2",o({},{id:"you-got-mail-service-invocation"}),"You got mail: service invocation"),(0,a.kt)("p",null,"Right now we have a:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Node.js web app and a"),(0,a.kt)("li",{parentName:"ul"},".NET app")),(0,a.kt)("p",null,"The web app, when called, uses dapr service invocation to acquire a weather forecast from a .NET app."),(0,a.kt)("p",null,"What we want to investigate is dapr's pubsub building block. But pubsub doesn't really \"fit\" into our current app. Let's alter it. Instead of showing users a weather forecast when they browse to the site, we'll instead look for our users to provide an email address, and we'll mail them a weather forecast."),(0,a.kt)("p",null,"This kind of app could work both using dapr service invocation or using pubsub. We're going to implement using our current service invocation approach first. Once that works, we'll then pivot that into using dapr pubsub."),(0,a.kt)("p",null,"This isn't rocket surgery; this is playing around with dapr and Azure Container Apps and seeing how they all hang together."),(0,a.kt)("h3",o({},{id:"net-meet-mailgun"}),".NET meet mailgun"),(0,a.kt)("p",null,"Our existing .NET app needs the ability to send email. For that we're going to reach for ",(0,a.kt)("a",o({parentName:"p"},{href:"https://app.mailgun.com/app/dashboard"}),"mailgun"),", and we'll use ",(0,a.kt)("a",o({parentName:"p"},{href:"https://restsharp.dev/"}),"RestSharp")," to call it. Let's add RestSharp as a dependency:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"dotnet add package RestSharp\n")),(0,a.kt)("p",null,"With that in place, let's turn to our ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecastController")," and make it send an email."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using Config;\n\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Extensions.Options;\n\nusing RestSharp;\nusing RestSharp.Authenticators;\n\nnamespace WeatherService.Controllers;\n\n[ApiController]\npublic class WeatherForecastController : ControllerBase\n{\n    private static readonly string[] Summaries = new[]\n    {\n        "Freezing", "Bracing", "Chilly", "Cool", "Mild", "Warm", "Balmy", "Hot", "Sweltering", "Scorching"\n    };\n\n    private readonly ILogger<WeatherForecastController> _logger;\n    private readonly MailConfig _options;\n\n    public WeatherForecastController(\n        ILogger<WeatherForecastController> logger,\n        IOptions<MailConfig> options\n    )\n    {\n        _logger = logger;\n        _options = options.Value;\n    }\n\n    public record SendWeatherForecastBody(string? Email);\n\n    [HttpPost("SendWeatherForecast")]\n    public async Task<string> SendWeatherForecast(SendWeatherForecastBody body)\n    {\n        try\n        {\n            if (string.IsNullOrEmpty(body.Email)) throw new Exception("Email required");\n\n            var weatherForecast = Enumerable.Range(1, 5).Select(index => new WeatherForecast\n            {\n                Date = DateTime.Now.AddDays(index),\n                TemperatureC = Random.Shared.Next(-20, 55),\n                Summary = Summaries[Random.Shared.Next(Summaries.Length)]\n            })\n            .ToArray();\n\n            var toEmailAddress = body.Email;\n            var text = $@"The weather forecast is:\n\n{string.Join("\\n", weatherForecast.Select(wf => $"On {wf.Date} the weather will be {wf.Summary}"))}\n";\n\n            await SendSimpleMessage(\n                toEmailAddress: toEmailAddress,\n                text: text\n            );\n\n            return $"We have mailed {toEmailAddress} with the following:\\n\\n{text}";\n        }\n        catch (Exception exc)\n        {\n            _logger.LogError(exc, $"Problem!");\n\n            return exc.Message;\n        }\n    }\n\n    async Task<RestResponse> SendSimpleMessage(string toEmailAddress, string text)\n    {\n        RestClient client = new(new RestClientOptions\n        {\n            BaseUrl = new Uri("https://api.mailgun.net/v3")\n        })\n        {\n            Authenticator =\n            new HttpBasicAuthenticator("api", _options.MailgunApiKey)\n        };\n        RestRequest request = new();\n        request.AddParameter("domain", "mg.priou.co.uk", ParameterType.UrlSegment);\n        request.Resource = "{domain}/messages";\n        request.AddParameter("from", "John Reilly <johnny_reilly@hotmail.com>");\n        request.AddParameter("to", toEmailAddress);\n        request.AddParameter("subject", "Weather forecast");\n        request.AddParameter("text", text);\n\n        return await client.PostAsync(request);\n    }\n}\n')),(0,a.kt)("p",null,"In our new and improved controller we:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Switch our ",(0,a.kt)("inlineCode",{parentName:"li"},"GET")," endpoint to be a ",(0,a.kt)("inlineCode",{parentName:"li"},"POST")," one instead, to reflect that we're going to take an action (sending an email) each time it's hit. (RESTful to the end)"),(0,a.kt)("li",{parentName:"ul"},"Rather than returning the weather forecast to our caller, we take the email address supplied and we send the weather forecast to it")),(0,a.kt)("p",null,"You'll also notice we're passing a ",(0,a.kt)("inlineCode",{parentName:"p"},"IOptions<MailConfig>")," to the constructor of our class, it's in this configuration object we store our Mailgun api key. So we're going to need to define a ",(0,a.kt)("inlineCode",{parentName:"p"},"MailConfig")," class:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"public class MailConfig\n{\n    public string MailgunApiKey { get; set; } = string.Empty;\n}\n")),(0,a.kt)("p",null,"And we need to update our ",(0,a.kt)("inlineCode",{parentName:"p"},"Program.cs")," so it recognises ",(0,a.kt)("inlineCode",{parentName:"p"},"MailConfig")," and configures it:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'var builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services.Configure<MailConfig>(builder.Configuration.GetSection("Mail"));\n// ...\n')),(0,a.kt)("p",null,"Thanks to the default setup of .NET, we'll now be able to populate this using ",(0,a.kt)("inlineCode",{parentName:"p"},"appsettings.json")," files and environment variables. Since our API key is a secret we'll avoid putting it in source control, and instead populate an environment variable that .NET can read:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"MAIL__MAILGUNAPIKEY=key-goes-here\n")),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"__")," above is the convention that .NET follows for nesting with environment variables; this is equivalent to the following structure in an ",(0,a.kt)("inlineCode",{parentName:"p"},"appsettings.json")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "Mail": {\n    "MailgunApiKey": "api-key-goes-here"\n  }\n  // ...\n}\n')),(0,a.kt)("h3",o({},{id:"webservice-gets-a-form"}),"Webservice gets a form"),(0,a.kt)("p",null,"Now that we've tweaked our WeatherService, we need to tweak the web site that calls it. We'll do that by first adding some dependencies that allow our Koa web service to handle routing a little easier:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"npm install @koa/router koa-body --save\nnpm install @types/koa__router --save-dev\n")),(0,a.kt)("p",null,"Then we'll tweak our ",(0,a.kt)("inlineCode",{parentName:"p"},"index.ts")," like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import Koa from 'koa';\nimport Router from '@koa/router';\nimport koaBody from 'koa-body';\nimport axios from 'axios';\n\n// How we connect to the dotnet service with dapr\nconst daprSidecarBaseUrl = `http://localhost:${\n  process.env.DAPR_HTTP_PORT || 3501\n}`;\n// app id header for service discovery\nconst weatherServiceAppIdHeaders = {\n  'dapr-app-id': process.env.WEATHER_SERVICE_NAME || 'dotnet-app',\n};\n\nconst app = new Koa();\nconst router = new Router();\n\napp.use(async (ctx, next) => {\n  try {\n    await next();\n    const status = ctx.status || 404;\n    if (status === 404) ctx.throw(404);\n  } catch (err: any) {\n    ctx.status = err.status || 500;\n    ctx.body = ctx.status === 404 ? 'not found alas' : `hmmm: ${ctx.status}`;\n  }\n});\n\nconst formHtml = (header: string) => `<!DOCTYPE html>\n<html>\n<head>\n<title>Email me!</title>\n</head>\n<body>\n<form method=\"post\">\n    <h1>${header}</h1>\n    <label for=\"email\">Enter your email:</label>\n    <input type=\"email\" id=\"email\" name=\"email\" required>\n    <button type=\"submit\">Submit</button>\n</form>\n</body>\n</html>\n`;\n\nrouter.get('/', async (ctx, next) => {\n  ctx.body = formHtml(\"We'd like to email you\");\n});\n\nrouter.post('/', koaBody(), async (ctx, next) => {\n  try {\n    if (ctx.request.body.email) {\n      await axios.post(\n        `${daprSidecarBaseUrl}/SendWeatherForecast`,\n        {\n          email: ctx.request.body.email,\n        },\n        {\n          headers: weatherServiceAppIdHeaders,\n        }\n      );\n\n      ctx.body = formHtml('Message sent');\n    } else {\n      ctx.body = formHtml('No email supplied');\n    }\n  } catch (exc) {\n    console.error('Problem calling weather service', exc);\n    ctx.body = 'Something went wrong!';\n  }\n});\n\napp.use(router.routes()).use(router.allowedMethods());\n\nconst portNumber = 3000;\napp.listen(portNumber);\nconsole.log(`listening on port ${portNumber}`);\n")),(0,a.kt)("p",null,"The above leaves us with a very simple form based web app that sends an email containing weather forecast:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A gif that demos entering an email address in the form, submitting it and seeing an email arrive with a weather forecast in",src:n(79924).Z,width:"1460",height:"858"})),(0,a.kt)("h3",o({},{id:"secrets-in-bicep"}),"Secrets in Bicep"),(0,a.kt)("p",null,"Whilst we can run locally, we want to be able to deploy this. So we need to update our Bicep template to receive a ",(0,a.kt)("inlineCode",{parentName:"p"},"MAIL__MAILGUNAPIKEY")," parameter:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param branchName string\n\nparam webServiceImage string\nparam webServicePort int\nparam webServiceIsExternalIngress bool\n\nparam weatherServiceImage string\nparam weatherServicePort int\nparam weatherServiceIsExternalIngress bool\n\nparam containerRegistry string\nparam containerRegistryUsername string\n@secure()\nparam containerRegistryPassword string\n\nparam tags object\n\n@secure()\nparam MAIL__MAILGUNAPIKEY string\n\nparam location string = resourceGroup().location\nvar minReplicas = 1\nvar maxReplicas = 1\n\nvar branch = toLower(last(split(branchName, '/')))\n\nvar environmentName = '${branch}-env'\nvar workspaceName = '${branch}-log-analytics'\nvar appInsightsName = '${branch}-app-insights'\nvar webServiceContainerAppName = '${branch}-web'\nvar weatherServiceContainerAppName = '${branch}-weather'\n\nvar containerRegistryPasswordRef = 'container-registry-password'\nvar mailgunApiKeyRef = 'mailgun-api-key'\n\nresource workspace 'Microsoft.OperationalInsights/workspaces@2021-12-01-preview' = {\n  name: workspaceName\n  location: location\n  tags: tags\n  properties: {\n    sku: {\n      name: 'PerGB2018'\n    }\n    retentionInDays: 30\n    workspaceCapping: {}\n  }\n}\n\nresource appInsights 'Microsoft.Insights/components@2020-02-02' = {\n  name: appInsightsName\n  location: location\n  tags: tags\n  kind: 'web'\n  properties: {\n    Application_Type: 'web'\n    Flow_Type: 'Bluefield'\n  }\n}\n\nresource environment 'Microsoft.App/managedEnvironments@2022-01-01-preview' = {\n  name: environmentName\n  location: location\n  tags: tags\n  properties: {\n    daprAIInstrumentationKey: appInsights.properties.InstrumentationKey\n    appLogsConfiguration: {\n      destination: 'log-analytics'\n      logAnalyticsConfiguration: {\n        customerId: workspace.properties.customerId\n        sharedKey: listKeys(workspace.id, workspace.apiVersion).primarySharedKey\n      }\n    }\n  }\n}\n\nresource weatherServiceContainerApp 'Microsoft.App/containerApps@2022-01-01-preview' = {\n  name: weatherServiceContainerAppName\n  tags: tags\n  location: location\n  properties: {\n    kubeEnvironmentId: environment.id\n    configuration: {\n      secrets: [\n        {\n          name: containerRegistryPasswordRef\n          value: containerRegistryPassword\n        }\n        {\n          name: mailgunApiKeyRef\n          value: MAIL__MAILGUNAPIKEY\n        }\n      ]\n      registries: [\n        {\n          server: containerRegistry\n          username: containerRegistryUsername\n          passwordSecretRef: containerRegistryPasswordRef\n        }\n      ]\n      ingress: {\n        external: weatherServiceIsExternalIngress\n        targetPort: weatherServicePort\n      }\n    }\n    template: {\n      containers: [\n        {\n          image: weatherServiceImage\n          name: weatherServiceContainerAppName\n          env: [\n            {\n              name: 'MAIL__MAILGUNAPIKEY'\n              secretRef: mailgunApiKeyRef\n            }\n          ]\n        }\n      ]\n      scale: {\n        minReplicas: minReplicas\n        maxReplicas: maxReplicas\n      }\n      dapr: {\n        enabled: true\n        appPort: weatherServicePort\n        appId: weatherServiceContainerAppName\n      }\n    }\n  }\n}\n\nresource webServiceContainerApp 'Microsoft.App/containerApps@2022-01-01-preview' = {\n  name: webServiceContainerAppName\n  tags: tags\n  location: location\n  properties: {\n    kubeEnvironmentId: environment.id\n    configuration: {\n      secrets: [\n        {\n          name: containerRegistryPasswordRef\n          value: containerRegistryPassword\n        }\n      ]\n      registries: [\n        {\n          server: containerRegistry\n          username: containerRegistryUsername\n          passwordSecretRef: containerRegistryPasswordRef\n        }\n      ]\n      ingress: {\n        external: webServiceIsExternalIngress\n        targetPort: webServicePort\n      }\n    }\n    template: {\n      containers: [\n        {\n          image: webServiceImage\n          name: webServiceContainerAppName\n          env: [\n            {\n              name: 'WEATHER_SERVICE_NAME'\n              value: weatherServiceContainerAppName\n            }\n          ]\n        }\n      ]\n      scale: {\n        minReplicas: minReplicas\n        maxReplicas: maxReplicas\n      }\n      dapr: {\n        enabled: true\n        appPort: webServicePort\n        appId: webServiceContainerAppName\n      }\n    }\n  }\n}\n\noutput webServiceUrl string = webServiceContainerApp.properties.latestRevisionFqdn\n")),(0,a.kt)("p",null,"We can see that we treat the ",(0,a.kt)("inlineCode",{parentName:"p"},"MAIL__MAILGUNAPIKEY")," as a secret. It's passed in using the ",(0,a.kt)("inlineCode",{parentName:"p"},"@secure")," decorator and it's configured as a secret inside the ",(0,a.kt)("inlineCode",{parentName:"p"},"weatherServiceContainerApp")," Azure Container App."),(0,a.kt)("p",null,"We have a GitHub Action that handles our deployment. We'll need to introduce the ",(0,a.kt)("inlineCode",{parentName:"p"},"MAIL__MAILGUNAPIKEY")," secret both to the deploy step of the ",(0,a.kt)("inlineCode",{parentName:"p"},"build-and-deploy.yaml"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),'deploy:\n  runs-on: ubuntu-latest\n  needs: [build]\n  steps:\n    - name: Checkout repository\n      uses: actions/checkout@v2\n\n    - name: Azure Login\n      uses: azure/login@v1\n      with:\n        creds: ${{ secrets.AZURE_CREDENTIALS }}\n\n    - name: Deploy bicep\n      uses: azure/CLI@v1\n      if: github.event_name != \'pull_request\'\n      with:\n        inlineScript: |\n          REF_SHA=\'${{ github.ref }}.${{ github.sha }}\'\n          DEPLOYMENT_NAME="${REF_SHA////-}"\n          echo "DEPLOYMENT_NAME=$DEPLOYMENT_NAME"\n\n          TAGS=\'{"owner":"johnnyreilly", "email":"johnny_reilly@hotmail.com"}\'\n          az deployment group create \\\n            --resource-group ${{ env.RESOURCE_GROUP }} \\\n            --name "$DEPLOYMENT_NAME" \\\n            --template-file ./infra/main.bicep \\\n            --parameters \\\n                branchName=\'${{ github.event.number == 0 && \'main\' ||  format(\'pr-{0}\', github.event.number) }}\' \\\n                webServiceImage=\'${{ needs.build.outputs.image-node }}\' \\\n                webServicePort=3000 \\\n                webServiceIsExternalIngress=true \\\n                weatherServiceImage=\'${{ needs.build.outputs.image-dotnet }}\' \\\n                weatherServicePort=5000 \\\n                weatherServiceIsExternalIngress=false \\\n                containerRegistry=${{ env.REGISTRY }} \\\n                containerRegistryUsername=${{ github.actor }} \\\n                containerRegistryPassword=${{ secrets.PACKAGES_TOKEN }} \\\n                tags="$TAGS" \\\n                MAIL__MAILGUNAPIKEY="${{ secrets.MAIL__MAILGUNAPIKEY }}"\n')),(0,a.kt)("p",null,"And we'll need to create the associated secret as well:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the secrets in the GitHub website that we need to create including MAIL__MAILGUNAPIKEY",src:n(87826).Z,width:"1586",height:"515"})),(0,a.kt)("h2",o({},{id:"you-got-mail-pubsub"}),"You got mail: pubsub!"),(0,a.kt)("p",null,"So we're now at the point where we have a pubsub style app - but still implemented using the service invocation approach. It's time to start migrating to using dapr's pubsub capabilities. Now, caveat emptor, pivoting from service invocation involves a fair amount of code. I'll try and be as brief as I can as we make the switch. However there will be big ol' lumps of code blocks as we do this. You may find it easier to just examine the finished code. I will in no way feel bad if that's the path you follow."),(0,a.kt)("h3",o({},{id:"publishing-with-dapr-client"}),"Publishing with dapr-client"),(0,a.kt)("p",null,"The first thing we need, is for our Node.js app to publish using the dapr pubsub mechanism. The easiest way to do that is with the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.dapr.io/developing-applications/sdks/js/"}),"dapr-client"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"npm install dapr-client --save\n")),(0,a.kt)("p",null,"We then switch out using axios to send our email command, to use ",(0,a.kt)("inlineCode",{parentName:"p"},"dapr-client")," instead:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import Koa from 'koa';\nimport Router from '@koa/router';\nimport koaBody from 'koa-body';\n\nimport { DaprClient } from 'dapr-client';\n\nconst daprHost = 'localhost'; // Dapr Sidecar Host\nconst daprPort = `${process.env.DAPR_HTTP_PORT || 3501}`; // Dapr Sidecar Port\n\nconst client = new DaprClient(daprHost, daprPort);\n\nconst app = new Koa();\nconst router = new Router();\n\napp.use(async (ctx, next) => {\n  try {\n    await next();\n    const status = ctx.status || 404;\n    if (status === 404) ctx.throw(404);\n  } catch (err: any) {\n    ctx.status = err.status || 500;\n    ctx.body = ctx.status === 404 ? 'not found alas' : `hmmm: ${ctx.status}`;\n  }\n});\n\nconst formHtml = (header: string) => `<!DOCTYPE html>\n<html>\n<head>\n<title>Email me!</title>\n</head>\n<body>\n<form method=\"post\">\n    <h1>${header}</h1>\n    <label for=\"email\">Enter your email:</label>\n    <input type=\"email\" id=\"email\" name=\"email\" required>\n    <button type=\"submit\">Submit</button>\n</form>\n</body>\n</html>\n`;\n\nrouter.get('/', async (ctx, next) => {\n  ctx.body = formHtml(\"We'd like to email you\");\n});\n\nrouter.post('/', koaBody(), async (ctx, next) => {\n  try {\n    if (ctx.request.body.email) {\n      // Send a message\n      const sent = await client.pubsub.publish(\n        /* pubSubName */ 'weather-forecast-pub-sub',\n        /* topic */ 'weather-forecasts',\n        /* data */ {\n          email: ctx.request.body.email,\n        }\n      );\n\n      ctx.body = formHtml(`Message sent: ${sent}`);\n    } else {\n      ctx.body = formHtml('No email supplied');\n    }\n  } catch (exc) {\n    console.error('Problem calling weather service', exc);\n    ctx.body = 'Something went wrong!';\n  }\n});\n\napp.use(router.routes()).use(router.allowedMethods());\n\nconst portNumber = 3000;\napp.listen(portNumber);\nconsole.log(`listening on port ${portNumber}`);\n")),(0,a.kt)("p",null,"The thing to note above is the ",(0,a.kt)("inlineCode",{parentName:"p"},"client.pubsub.publish"),"; our WebService will now be publishing using pubsub, instead of using axios and service invocation."),(0,a.kt)("h3",o({},{id:"subscribing"}),"Subscribing"),(0,a.kt)("p",null,"Our WeatherService needs to be able to receive what is published. To make that happen, we'll make use of the following NuGet package in WeatherService:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"dotnet add package Dapr.AspNetCore --version 1.7.0\n")),(0,a.kt)("p",null,"Our ",(0,a.kt)("inlineCode",{parentName:"p"},"Program.cs")," is adjusted to cater for this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using Config;\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services.Configure<MailConfig>(builder.Configuration.GetSection("Mail"));\n\nbuilder.Services.AddControllers().AddDapr();\n// Learn more about configuring Swagger/OpenAPI at https://aka.ms/aspnetcore/swashbuckle\nbuilder.Services.AddEndpointsApiExplorer();\nbuilder.Services.AddSwaggerGen();\n\nvar app = builder.Build();\n\n// Configure the HTTP request pipeline.\nif (app.Environment.IsDevelopment())\n{\n    app.UseSwagger();\n    app.UseSwaggerUI();\n}\n\napp.UseAuthorization();\n\napp.UseCloudEvents();\n\napp.MapSubscribeHandler(); // This is the Dapr subscribe handler\napp.MapControllers();\n\napp.Run();\n')),(0,a.kt)("p",null,"The significant pieces above are:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"builder.Services.AddControllers().AddDapr();\n\n// ...\n\napp.UseCloudEvents();\napp.MapSubscribeHandler(); // This is the Dapr subscribe handler\n")),(0,a.kt)("p",null,"We'll also need to update our ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecastController.cs"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using Config;\n\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Extensions.Options;\n\nusing RestSharp;\nusing RestSharp.Authenticators;\n\nusing Dapr;\n\nnamespace WeatherService.Controllers;\n\n[ApiController]\npublic class WeatherForecastController : ControllerBase\n{\n    private static readonly string[] Summaries = new[]\n    {\n        "Freezing", "Bracing", "Chilly", "Cool", "Mild", "Warm", "Balmy", "Hot", "Sweltering", "Scorching"\n    };\n\n    private readonly ILogger<WeatherForecastController> _logger;\n    private readonly MailConfig _options;\n\n    public WeatherForecastController(\n        ILogger<WeatherForecastController> logger,\n        IOptions<MailConfig> options\n    )\n    {\n        _logger = logger;\n        _options = options.Value;\n    }\n\n    public record SendWeatherForecastBody(string? Email);\n\n    [Topic(pubsubName: "weather-forecast-pub-sub", name: "weather-forecasts")]\n    [HttpPost("SendWeatherForecast")]\n    public async Task<ActionResult<string>> SendWeatherForecast(SendWeatherForecastBody body)\n    {\n        try\n        {\n            if (string.IsNullOrEmpty(body.Email)) throw new Exception("Email required");\n\n            var weatherForecast = Enumerable.Range(1, 5).Select(index => new WeatherForecast\n            {\n                Date = DateTime.Now.AddDays(index),\n                TemperatureC = Random.Shared.Next(-20, 55),\n                Summary = Summaries[Random.Shared.Next(Summaries.Length)]\n            })\n            .ToArray();\n\n            var toEmailAddress = body.Email;\n            var text = $@"The weather forecast is:\n\n{string.Join("\\n", weatherForecast.Select(wf => $"On {wf.Date} the weather will be {wf.Summary}"))}\n";\n\n            await SendSimpleMessage(\n                toEmailAddress: toEmailAddress,\n                text: text\n            );\n\n            return Ok($"We have mailed {toEmailAddress} with the following:\\n\\n{text})");\n        }\n        catch (Exception exc)\n        {\n            _logger.LogError(exc, $"Problem!");\n\n            return BadRequest(exc.Message);\n        }\n    }\n\n    async Task<RestResponse> SendSimpleMessage(string toEmailAddress, string text)\n    {\n        RestClient client = new(new RestClientOptions\n        {\n            BaseUrl = new Uri("https://api.mailgun.net/v3")\n        })\n        {\n            Authenticator =\n            new HttpBasicAuthenticator("api", _options.MailgunApiKey)\n        };\n        RestRequest request = new();\n        request.AddParameter("domain", "mg.priou.co.uk", ParameterType.UrlSegment);\n        request.Resource = "{domain}/messages";\n        request.AddParameter("from", "John Reilly <johnny_reilly@hotmail.com>");\n        request.AddParameter("to", toEmailAddress);\n        request.AddParameter("subject", "Weather forecast");\n        request.AddParameter("text", text);\n\n        return await client.PostAsync(request);\n    }\n}\n')),(0,a.kt)("p",null,"Really the only new thing here is the ",(0,a.kt)("inlineCode",{parentName:"p"},"Topic")," attribute on the ",(0,a.kt)("inlineCode",{parentName:"p"},"SendWeatherForecast")," endpoint:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[Topic(pubsubName: "weather-forecast-pub-sub", name: "weather-forecasts")]\n')),(0,a.kt)("p",null,"This is used (as you might imagine) to route messages."),(0,a.kt)("p",null,'The real difference to call out in what we\'ve done so far, is that both our publisher (Node.js) and our subscriber (.NET) have become "dapr aware". Although there have been changes in our code to achieve this, they have not been extensive. Noisy, yes. But not big changes.'),(0,a.kt)("h3",o({},{id:"components"}),"Components"),(0,a.kt)("p",null,"In order to communicate via pubsub, dapr needs some ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.dapr.io/concepts/components-concept/"}),"components")," in place. We'll create a folder in the root of our project named ",(0,a.kt)("inlineCode",{parentName:"p"},"components"),", and in there create three files:"),(0,a.kt)("h4",o({},{id:"pubsubyaml"}),(0,a.kt)("inlineCode",{parentName:"h4"},"pubsub.yaml")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"apiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\n  name: weather-forecast-pub-sub\n  namespace: default\nspec:\n  type: pubsub.redis\n  version: v1\n  metadata:\n    - name: redisHost\n      value: localhost:6379\n    - name: redisPassword\n      value: ''\nscopes:\n  - node-app\n  - dotnet-app\n")),(0,a.kt)("h4",o({},{id:"statestoreyaml"}),(0,a.kt)("inlineCode",{parentName:"h4"},"statestore.yaml")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"apiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\n  name: statestore\n  namespace: default\nspec:\n  type: state.redis\n  version: v1\n  metadata:\n    - name: redisHost\n      value: localhost:6379\n    - name: redisPassword\n      value: ''\n    - name: actorStateStore\n      value: 'true'\n")),(0,a.kt)("h4",o({},{id:"subscriptionyaml"}),(0,a.kt)("inlineCode",{parentName:"h4"},"subscription.yaml")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"apiVersion: dapr.io/v1alpha1\nkind: Subscription\nmetadata:\n  name: weather-forecast-pub-sub\nspec:\n  topic: weather-forecasts\n  route: /SendWeatherForecast\n  pubsubname: weather-forecast-pub-sub\nscopes:\n  - node-app\n  - dotnet-app\n")),(0,a.kt)("p",null,"These three files are fairly self-explanatory. It's worth drawing attention to the following though:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"We're going to use these components when running locally and so we'll use Redis for our persistence. When we deploy to Azure Container Apps we'll use something more Azure specific."),(0,a.kt)("li",{parentName:"ol"},"We're granting access in these components to our node-app (WebService) and our dotnet-app (WeatherService)"),(0,a.kt)("li",{parentName:"ol"},"We're wiring up our subscription in ",(0,a.kt)("inlineCode",{parentName:"li"},"subscription.yaml"),"- it's this that will be used to route traffic from publishing to subscription.")),(0,a.kt)("p",null,"With the above in place we're almost ready to be able to run this locally and debug using VS Code. The final tweak is to make our apps aware of the dapr components. This is achieved by adding ",(0,a.kt)("inlineCode",{parentName:"p"},'"componentsPath": "./components",')," to the entries in our ",(0,a.kt)("inlineCode",{parentName:"p"},"tasks.json")," file. In full it looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  // See https://go.microsoft.com/fwlink/?LinkId=733558\n  // for the documentation about the tasks.json format\n  "version": "2.0.0",\n  "tasks": [\n    {\n      "label": "dotnet-build",\n      "command": "dotnet",\n      "type": "process",\n      "args": [\n        "build",\n        "${workspaceFolder}/WeatherService/WeatherService.csproj",\n        "/property:GenerateFullPaths=true",\n        "/consoleloggerparameters:NoSummary"\n      ],\n      "problemMatcher": "$msCompile"\n    },\n    {\n      "label": "daprd-debug-dotnet",\n      "appId": "dotnet-app",\n      "appPort": 5000,\n      "httpPort": 3500,\n      "grpcPort": 50000,\n      "metricsPort": 9090,\n      "componentsPath": "./components",\n      "type": "daprd",\n      "dependsOn": ["dotnet-build"]\n    },\n    {\n      "label": "daprd-down-dotnet",\n      "appId": "dotnet-app",\n      "type": "daprd-down"\n    },\n\n    {\n      "label": "npm-install",\n      "type": "shell",\n      "command": "npm install",\n      "options": {\n        "cwd": "${workspaceFolder}/WebService"\n      }\n    },\n    {\n      "label": "webservice-build",\n      "type": "typescript",\n      "tsconfig": "WebService/tsconfig.json",\n      "problemMatcher": ["$tsc"],\n      "group": {\n        "kind": "build",\n        "isDefault": true\n      },\n      "dependsOn": ["npm-install"]\n    },\n    {\n      "label": "daprd-debug-node",\n      "appId": "node-app",\n      "appPort": 3000,\n      "httpPort": 3501,\n      "grpcPort": 50001,\n      "metricsPort": 9091,\n      "componentsPath": "./components",\n      "type": "daprd",\n      "dependsOn": ["webservice-build"]\n    },\n    {\n      "label": "daprd-down-node",\n      "appId": "node-app",\n      "type": "daprd-down"\n    }\n  ]\n}\n')),(0,a.kt)("p",null,"With this in place we're ready to run our apps locally using pubsub. We can publish from the WebService and receive in the WeatherService. This results in the expected email being sent, as we would hope."),(0,a.kt)("h3",o({},{id:"bicep"}),"Bicep"),(0,a.kt)("p",null,"The missing piece is Azure. How do we deploy this to Azure Container Apps? Well, we have everything we need to do this, save for the Bicep. We need to augment the Bicep we already have to include our Azure Container Apps dapr components. The full template looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param branchName string\n\nparam webServiceImage string\nparam webServicePort int\nparam webServiceIsExternalIngress bool\n\nparam weatherServiceImage string\nparam weatherServicePort int\nparam weatherServiceIsExternalIngress bool\n\nparam containerRegistry string\nparam containerRegistryUsername string\n@secure()\nparam containerRegistryPassword string\n\nparam tags object\n\n@secure()\nparam MAIL__MAILGUNAPIKEY string\n\nparam location string = resourceGroup().location\n\n@description('Storage Account type')\n@allowed([\n  'Premium_LRS'\n  'Premium_ZRS'\n  'Standard_GRS'\n  'Standard_GZRS'\n  'Standard_LRS'\n  'Standard_RAGRS'\n  'Standard_RAGZRS'\n  'Standard_ZRS'\n])\nparam storageAccountType string = 'Standard_LRS'\n\n@description('The name of the Storage Account')\nparam storageAccountName string = 'store${uniqueString(resourceGroup().id)}'\n\nparam serviceBusNamespace string = 'pubsub-namespace'\n\nresource storageAccount 'Microsoft.Storage/storageAccounts@2021-06-01' = {\n  name: storageAccountName\n  location: location\n  sku: {\n    name: storageAccountType\n  }\n  kind: 'StorageV2'\n  properties: {}\n}\n\nresource serviceBus 'Microsoft.ServiceBus/namespaces@2021-06-01-preview' = {\n  name: serviceBusNamespace\n  location: location\n}\n\nresource servicebus_authrule 'Microsoft.ServiceBus/namespaces/AuthorizationRules@2021-06-01-preview' existing = {\n  name: 'RootManageSharedAccessKey'\n  parent: serviceBus\n}\n\nresource topic 'Microsoft.ServiceBus/namespaces/topics@2021-06-01-preview' = {\n  name: 'weather-forecasts'\n  parent: serviceBus\n}\n\nvar minReplicas = 1\nvar maxReplicas = 1\n\nvar branch = toLower(last(split(branchName, '/')))\n\nvar environmentName = 'shared-env'\nvar workspaceName = '${branch}-log-analytics'\nvar appInsightsName = '${branch}-app-insights'\nvar webServiceContainerAppName = '${branch}-web'\nvar weatherServiceContainerAppName = '${branch}-weather'\n\nvar containerRegistryPasswordRef = 'container-registry-password'\nvar mailgunApiKeyRef = 'mailgun-api-key'\n\nresource workspace 'Microsoft.OperationalInsights/workspaces@2021-12-01-preview' = {\n  name: workspaceName\n  location: location\n  tags: tags\n  properties: {\n    sku: {\n      name: 'PerGB2018'\n    }\n    retentionInDays: 30\n    workspaceCapping: {}\n  }\n}\n\nresource appInsights 'Microsoft.Insights/components@2020-02-02' = {\n  name: appInsightsName\n  location: location\n  tags: tags\n  kind: 'web'\n  properties: {\n    Application_Type: 'web'\n    Flow_Type: 'Bluefield'\n  }\n}\n\nresource environment 'Microsoft.App/managedEnvironments@2022-01-01-preview' = {\n  name: environmentName\n  location: location\n  tags: tags\n  properties: {\n    daprAIInstrumentationKey: appInsights.properties.InstrumentationKey\n    appLogsConfiguration: {\n      destination: 'log-analytics'\n      logAnalyticsConfiguration: {\n        customerId: workspace.properties.customerId\n        sharedKey: listKeys(workspace.id, workspace.apiVersion).primarySharedKey\n      }\n    }\n  }\n  resource statestoreComponent 'daprComponents@2022-03-01' = {\n    name: 'statestore'\n    properties: {\n      componentType: 'state.azure.blobstorage'\n      version: 'v1'\n      ignoreErrors: false\n      initTimeout: '5s'\n      secrets: [\n        {\n          name: 'storageaccountkey'\n          value: listKeys(resourceId('Microsoft.Storage/storageAccounts/', storageAccount.name), storageAccount.apiVersion).keys[0].value\n        }\n      ]\n      metadata: [\n        {\n          name: 'accountName'\n          value: storageAccount.name\n        }\n        {\n          name: 'containerName'\n          value: 'storage_container_name'\n        }\n        {\n          name: 'accountKey'\n          secretRef: 'storageaccountkey'\n        }\n      ]\n      scopes: [\n        weatherServiceContainerAppName\n        webServiceContainerAppName\n      ]\n    }\n  }\n  resource pubsubComponent 'daprComponents@2022-03-01' = {\n    name: 'weather-forecast-pub-sub'\n    properties: {\n      componentType: 'pubsub.azure.servicebus'\n      version: 'v1'\n      metadata: [\n        {\n          name: 'connectionString'\n          secretRef: 'sb-root-connectionstring'\n        }\n      ]\n      secrets: [\n        {\n          name: 'sb-root-connectionstring'\n          value: listKeys('${serviceBus.id}/AuthorizationRules/RootManageSharedAccessKey', serviceBus.apiVersion).primaryConnectionString\n        }\n      ]\n      scopes: [\n        weatherServiceContainerAppName\n        webServiceContainerAppName\n      ]\n    }\n  }\n}\n\nresource weatherServiceContainerApp 'Microsoft.App/containerApps@2022-01-01-preview' = {\n  name: weatherServiceContainerAppName\n  tags: tags\n  location: location\n  properties: {\n    managedEnvironmentId: environment.id\n    configuration: {\n      dapr: {\n        enabled: true\n        appPort: weatherServicePort\n        appId: weatherServiceContainerAppName\n      }\n      secrets: [\n        {\n          name: containerRegistryPasswordRef\n          value: containerRegistryPassword\n        }\n        {\n          name: mailgunApiKeyRef\n          value: MAIL__MAILGUNAPIKEY\n        }\n      ]\n      registries: [\n        {\n          server: containerRegistry\n          username: containerRegistryUsername\n          passwordSecretRef: containerRegistryPasswordRef\n        }\n      ]\n      ingress: {\n        external: weatherServiceIsExternalIngress\n        targetPort: weatherServicePort\n      }\n    }\n    template: {\n      containers: [\n        {\n          image: weatherServiceImage\n          name: weatherServiceContainerAppName\n          env: [\n            {\n              name: 'MAIL__MAILGUNAPIKEY'\n              secretRef: mailgunApiKeyRef\n            }\n          ]\n        }\n      ]\n      scale: {\n        minReplicas: minReplicas\n        maxReplicas: maxReplicas\n      }\n    }\n  }\n}\n\nresource webServiceContainerApp 'Microsoft.App/containerApps@2022-01-01-preview' = {\n  name: webServiceContainerAppName\n  tags: tags\n  location: location\n  properties: {\n    managedEnvironmentId: environment.id\n    configuration: {\n      dapr: {\n        enabled: true\n        appPort: webServicePort\n        appId: webServiceContainerAppName\n      }\n      secrets: [\n        {\n          name: containerRegistryPasswordRef\n          value: containerRegistryPassword\n        }\n      ]\n      registries: [\n        {\n          server: containerRegistry\n          username: containerRegistryUsername\n          passwordSecretRef: containerRegistryPasswordRef\n        }\n      ]\n      ingress: {\n        external: webServiceIsExternalIngress\n        targetPort: webServicePort\n      }\n    }\n    template: {\n      containers: [\n        {\n          image: webServiceImage\n          name: webServiceContainerAppName\n          env: [\n            {\n              name: 'WEATHER_SERVICE_NAME'\n              value: weatherServiceContainerAppName\n            }\n          ]\n        }\n      ]\n      scale: {\n        minReplicas: minReplicas\n        maxReplicas: maxReplicas\n      }\n    }\n  }\n}\n\noutput webServiceUrl string = webServiceContainerApp.properties.latestRevisionFqdn\n")),(0,a.kt)("p",null,"Now this is undeniably a big lump of Bicep. Let's drill into the significant differences:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"We're creating an Azure storage account."),(0,a.kt)("li",{parentName:"ol"},"We're creating an Azure Service Bus and a topic under it named ",(0,a.kt)("inlineCode",{parentName:"li"},"'weather-forecasts'"),"."),(0,a.kt)("li",{parentName:"ol"},"Underneath our managed environment, we're creating a statestore (using the storage account) which is the Azure equivalent of our ",(0,a.kt)("inlineCode",{parentName:"li"},"statestore.yml"),", but using Azure storage."),(0,a.kt)("li",{parentName:"ol"},"Also underneath our managed environment, we're creating a pubsub (using the service bus) which is the Azure equivalent of our ",(0,a.kt)("inlineCode",{parentName:"li"},"pubsub.yml"),", but using our Azure ServiceBus.")),(0,a.kt)("p",null,"It's also worth noting that we always have an instance of the services running; ",(0,a.kt)("inlineCode",{parentName:"p"},"minReplicas: 1"),". This is because when we dial it down to 0, the Weather Service will stop running. Probably there's a fancy KEDA trigger that prevents this; I haven't figured it out."),(0,a.kt)("h3",o({},{id:"no-declarative-pubsub-subscription-support"}),"No declarative pubsub subscription support"),(0,a.kt)("p",null,"Whilst you might be thinking \"we're home free now!\" - it turns out we're not. Whilst we'd created Azure equivalents of our ",(0,a.kt)("inlineCode",{parentName:"p"},"statestore.yml")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"pubsub.yml"),", you'll note there didn't seem to be an equivalent of the ",(0,a.kt)("inlineCode",{parentName:"p"},"subscriptions")," component in Bicep."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/container-apps/dapr-overview?tabs=bicep1%2Cyaml#known-limitations"}),"It turns out support for declarative pub/sub subscriptions is not yet available"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Known limitations\nDeclarative pub/sub subscriptions")),(0,a.kt)("p",null,"So whilst we can take the code we have here and run locally, we cannot deploy it to Azure."),(0,a.kt)("p",null,"However, whilst there's no declaritive support for subscriptions, there is programmatic support. It involves more of a pivot in how we put together our code. But since it's the only game in town, we'll give it a go."),(0,a.kt)("h2",o({},{id:"you-got-mail-programmatic-subscriptions"}),"You got mail: programmatic subscriptions!"),(0,a.kt)("p",null,"We can get rid of our ",(0,a.kt)("inlineCode",{parentName:"p"},"subscriptions.yaml")," file now - we're going programmatic instead of declarative."),(0,a.kt)("p",null,"We're going to replace our ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecastController.cs")," with a ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecastEndpoints.cs")," which contains very similar code, but uses the .NET 6 minimal API approach instead: (There appears to be a way to work with MVC but it's not clear how to use it, and it appears to be a more confusing approach than the .NET 6 minimal API approach.)"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using Config;\n\nusing Microsoft.Extensions.Options;\n\nusing RestSharp;\nusing RestSharp.Authenticators;\n\nusing Dapr;\n\nnamespace WeatherService.Endpoints;\n\npublic static class WeatherForecastEndpoints\n{\n    private static readonly string[] Summaries = new[]\n    {\n        "Freezing", "Bracing", "Chilly", "Cool", "Mild", "Warm", "Balmy", "Hot", "Sweltering", "Scorching"\n    };\n\n    public record SendWeatherForecastBody(string? Email);\n\n    public static IEndpointRouteBuilder MapWeatherForecastEndpoints(this IEndpointRouteBuilder endpoints)\n    {\n        endpoints.MapPost("/SendWeatherForecast",\n            [Topic("weather-forecast-pub-sub", "weather-forecasts")]\n            async (\n                SendWeatherForecastBody body,\n                ILogger<SendWeatherForecastBody> logger,\n                IOptions<MailConfig> options\n            ) =>\n            {\n                try\n                {\n                    if (string.IsNullOrEmpty(body.Email)) throw new Exception("Email required");\n\n                    var weatherForecast = Enumerable.Range(1, 5).Select(index => new WeatherForecast\n                    {\n                        Date = DateTime.Now.AddDays(index),\n                        TemperatureC = Random.Shared.Next(-20, 55),\n                        Summary = Summaries[Random.Shared.Next(Summaries.Length)]\n                    })\n                    .ToArray();\n\n                    var toEmailAddress = body.Email;\n                    var text = $@"The weather forecast is:\n\n{string.Join("\\n", weatherForecast.Select(wf => $"On {wf.Date} the weather will be {wf.Summary}"))}\n";\n\n                    await SendSimpleMessage(\n                        mailgunApiKey: options.Value.MailgunApiKey,\n                        toEmailAddress: toEmailAddress,\n                        text: text\n                    );\n\n                    return Results.Ok($"We have mailed {toEmailAddress} with the following:\\n\\n{text})");\n                }\n                catch (Exception exc)\n                {\n                    logger.LogError(exc, $"Problem!");\n\n                    return Results.BadRequest(exc.Message);\n                }\n            });\n\n        return endpoints;\n    }\n\n    static async Task<RestResponse> SendSimpleMessage(string mailgunApiKey, string toEmailAddress, string text)\n    {\n        RestClient client = new(new RestClientOptions\n        {\n            BaseUrl = new Uri("https://api.mailgun.net/v3")\n        })\n        {\n            Authenticator =\n            new HttpBasicAuthenticator("api", mailgunApiKey)\n        };\n        RestRequest request = new();\n        request.AddParameter("domain", "mg.priou.co.uk", ParameterType.UrlSegment);\n        request.Resource = "{domain}/messages";\n        request.AddParameter("from", "John Reilly <johnny_reilly@hotmail.com>");\n        request.AddParameter("to", toEmailAddress);\n        request.AddParameter("subject", "Weather forecast");\n        request.AddParameter("text", text);\n\n        return await client.PostAsync(request);\n    }\n}\n')),(0,a.kt)("p",null,"The significant thing to note above is the ",(0,a.kt)("inlineCode",{parentName:"p"},'[Topic("weather-forecast-pub-sub", "weather-forecasts")]')," that we're adding to our ",(0,a.kt)("inlineCode",{parentName:"p"},"MapPost")," in the ",(0,a.kt)("inlineCode",{parentName:"p"},"MapWeatherForecastEndpoints")," method. This is the equivalent of the ",(0,a.kt)("inlineCode",{parentName:"p"},"subscriptions")," component that we wanted to create in Bicep but couldn't. This is our programmatic subscription."),(0,a.kt)("p",null,"We also need to tweak our ",(0,a.kt)("inlineCode",{parentName:"p"},"Program.cs")," to cater for the new ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecastEndpoints")," class:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using Config;\nusing WeatherService.Endpoints;\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services.Configure<MailConfig>(builder.Configuration.GetSection("Mail"));\n\nbuilder.Services.AddControllers().AddDapr();\n// Learn more about configuring Swagger/OpenAPI at https://aka.ms/aspnetcore/swashbuckle\nbuilder.Services.AddEndpointsApiExplorer();\nbuilder.Services.AddSwaggerGen();\n\nvar app = builder.Build();\n\n// Configure the HTTP request pipeline.\nif (app.Environment.IsDevelopment())\n{\n    app.UseSwagger();\n    app.UseSwaggerUI();\n}\n\napp.UseAuthorization();\n\napp.UseCloudEvents();\n\napp.MapSubscribeHandler(); // This is the Dapr subscribe handler\n\napp.MapWeatherForecastEndpoints();\n\napp.Run();\n')),(0,a.kt)("p",null,"So the ",(0,a.kt)("inlineCode",{parentName:"p"},"app.MapWeatherForecastEndpoints();")," is what wires up our ",(0,a.kt)("inlineCode",{parentName:"p"},"WeatherForecastEndpoints")," class."),(0,a.kt)("p",null,"With that in place, we're ready to deploy to Azure."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A gif that demos entering an email address in the form, submitting it and seeing an email arrive with a weather forecast in",src:n(52879).Z,width:"1464",height:"1228"})),(0,a.kt)("p",null,"We now have Azure Container Apps running in Azure, using the dapr pubsub component. Hopefully in future declarative subscribtions will be available also, but for now we can use the programmatic approach."))}d.isMDXComponent=!0},24753:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"static-web-apps-failed-to-deploy-the-azure-functions",title:"Azure Static Web Apps: Failed to deploy the Azure Functions",authors:"johnnyreilly",tags:["Azure Static Web Apps","Azure Functions"],image:"./title-image.png",description:'Azure Static Web Apps presently have an issue which blocks deployment of Azure Functions with the message "Failed to deploy the Azure Functions". What is it?',hide_table_of_contents:!1},s=void 0,l={permalink:"/static-web-apps-failed-to-deploy-the-azure-functions",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-07-07-static-web-apps-failed-to-deploy-the-azure-functions/index.md",source:"@site/blog/2022-07-07-static-web-apps-failed-to-deploy-the-azure-functions/index.md",title:"Azure Static Web Apps: Failed to deploy the Azure Functions",description:'Azure Static Web Apps presently have an issue which blocks deployment of Azure Functions with the message "Failed to deploy the Azure Functions". What is it?',date:"2022-07-07T00:00:00.000Z",formattedDate:"July 7, 2022",tags:[{label:"Azure Static Web Apps",permalink:"/tags/azure-static-web-apps"},{label:"Azure Functions",permalink:"/tags/azure-functions"}],readingTime:3.15,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"static-web-apps-failed-to-deploy-the-azure-functions",title:"Azure Static Web Apps: Failed to deploy the Azure Functions",authors:"johnnyreilly",tags:["Azure Static Web Apps","Azure Functions"],image:"./title-image.png",description:'Azure Static Web Apps presently have an issue which blocks deployment of Azure Functions with the message "Failed to deploy the Azure Functions". What is it?',hide_table_of_contents:!1},prevItem:{title:"Get Build Validations with the Azure DevOps API",permalink:"/azure-devops-api-build-validations"},nextItem:{title:"Azure Container Apps: dapr pubsub",permalink:"/azure-container-apps-pubsub"}},p={image:n(47773).Z,authorsImageUrls:[void 0]},u=[{value:"Failed to deploy the Azure Functions",id:"failed-to-deploy-the-azure-functions",level:2},{value:"Fiddling with tags",id:"fiddling-with-tags",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'Azure Static Web Apps presently have an issue which blocks deployment of Azure Functions with the message "Failed to deploy the Azure Functions". This happens when the resource is tagged with an ',(0,a.kt)("inlineCode",{parentName:"p"},"EnvironmentId")," tag and is discussed in ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/static-web-apps/issues/723"}),"this GitHub issue"),". There is a workaround which we will examine."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Azure Static Web Apps: Failed to deploy the Azure Functions&quot; with an Azure Functions logo",src:n(47773).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"failed-to-deploy-the-azure-functions"}),"Failed to deploy the Azure Functions"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://azure.microsoft.com/en-us/services/app-service/static/"}),"Azure Static Web Apps")," are a combination of static front end hosting and an optional serverless API back end. The front end portion of Azure Static Web Apps is very plug and play. However there can be complexities when it comes to adding an API back end. One issue is a failure to deploy in the context of an Azure Pipeline which presents like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of an Azure Pipeines run featuring the words &quot;Failed to deploy the Azure Functions&quot;",src:n(13634).Z,width:"1790",height:"690"})),(0,a.kt)("p",null,"Above you can see the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/azure-pipelines-tasks/tree/master/Tasks/AzureStaticWebAppV0"}),(0,a.kt)("inlineCode",{parentName:"a"},"AzureStaticWebApp@0")),' dedicated Azure Pipelines task that is used to deploy Azure Static Web Apps. It fails with the message "Failed to deploy the Azure Functions". There is no actionable feedback in this output, which makes coming up with remedies difficult.'),(0,a.kt)("p",null,"As I was looking into this with Emad Khalifah of Microsoft Support, Emad pointed me to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/static-web-apps/issues/723"}),"this GitHub issue"),". Ironically, this had been raised by my colleage ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnmccormick99"}),"John McCormick")," back in February 2022."),(0,a.kt)("p",null,"The issue he experienced occurred when an ",(0,a.kt)("inlineCode",{parentName:"p"},"EnvironmentId")," tag tag is present on the Azure Static Web Apps resource like so:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the Azure Portal with a tag of &quot;EnvironmentId&quot;",src:n(39921).Z,width:"1928",height:"804"})),(0,a.kt)("p",null,"We do this in our organisation, and looking at the comments on the issue, it appears there are others out there doing the same. Given the name of the tag, this is not terribly surprising."),(0,a.kt)("p",null,"Unfortunately, this issue has not been resolved. Can we work around the issue? Yes."),(0,a.kt)("h2",o({},{id:"fiddling-with-tags"}),"Fiddling with tags"),(0,a.kt)("p",null,"In our organisation we enforce the tags we use in Azure strictly. So we found ourself in the bind of both needing tags for our own internal processes, but needing to work around the issue."),(0,a.kt)("p",null,"However, the excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/ryanmatcook"}),"Ryan Cook")," came up with a workaround. It works like this:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"use the Azure CLI to remove the ",(0,a.kt)("inlineCode",{parentName:"li"},"EnvironmentId")," tag from the static web app resource"),(0,a.kt)("li",{parentName:"ul"},"Deploy the static web app"),(0,a.kt)("li",{parentName:"ul"},"use the Azure CLI to add the ",(0,a.kt)("inlineCode",{parentName:"li"},"EnvironmentId")," tag back to the static web app resource")),(0,a.kt)("p",null,"It's hacky. It can require multiple runs to work (I ascribe this to eventual consistency issues in Azure; but that's not based on evidence). However, it can be a way forward. I acknowledge this is suboptimal."),(0,a.kt)("p",null,"Should anyone else bump on this issue, here is the (hacky) workaround:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- task: AzureCLI@2\n  displayName: 'Remove EnvironmentId tag from resource group'\n  inputs:\n    azureSubscription: ${{ variables.serviceConnection }}\n    scriptType: bash\n    scriptLocation: inlineScript\n    inlineScript: |\n      az tag update --resource-id /subscriptions/$(subscriptionId)/resourcegroups/$(resourceGroup) --operation delete --tags EnvironmentId=$(environmentId)\n\n# you may want to introduce a delay here, without a delay this can be somewhat unreliable\n\n- task: AzureStaticWebApp@0\n  name: DeployStaticWebApp\n  displayName: Deploy Static Web App\n  inputs:\n    app_location: 'MyApp'\n    output_location: 'dist'\n    api_location: 'api'\n    azure_static_web_apps_api_token: $(apiKey)\n\n- task: AzureCLI@2\n  displayName: 'Add EnvironmentId tag back to resource group'\n  inputs:\n    azureSubscription: ${{ variables.serviceConnection }}\n    scriptType: bash\n    scriptLocation: inlineScript\n    inlineScript: |\n      az tag update --resource-id /subscriptions/$(subscriptionId)/resourcegroups/$(resourceGroup) --operation merge --tags EnvironmentId=$(environmentId)\n")),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"Although I haven't tested it, the nature of the failure appears to be general; and so would likely affect deployments using GitHub Actions also. So if you're a GitHub Actions user, I suspect this approach could be tweaked and applied there also."),(0,a.kt)("p",null,"It would be tremendous to see ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/static-web-apps/issues/723"}),"this issue")," fixed within SWAs directly. It's not great that this issue has been marked as closed without (as far as we can tell) fixing the underlying problem."))}d.isMDXComponent=!0},49963:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-devops-api-build-validations",title:"Get Build Validations with the Azure DevOps API",authors:"johnnyreilly",tags:["Azure Pipelines","azure devops api"],image:"./title-image.png",description:"Use the Azure DevOps API to acquire the build validations a project uses. This post shows you how using curl and the Node.js API.",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-devops-api-build-validations",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-07-10-azure-devops-api-build-validations/index.md",source:"@site/blog/2022-07-10-azure-devops-api-build-validations/index.md",title:"Get Build Validations with the Azure DevOps API",description:"Use the Azure DevOps API to acquire the build validations a project uses. This post shows you how using curl and the Node.js API.",date:"2022-07-10T00:00:00.000Z",formattedDate:"July 10, 2022",tags:[{label:"Azure Pipelines",permalink:"/tags/azure-pipelines"},{label:"azure devops api",permalink:"/tags/azure-devops-api"}],readingTime:3.435,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-devops-api-build-validations",title:"Get Build Validations with the Azure DevOps API",authors:"johnnyreilly",tags:["Azure Pipelines","azure devops api"],image:"./title-image.png",description:"Use the Azure DevOps API to acquire the build validations a project uses. This post shows you how using curl and the Node.js API.",hide_table_of_contents:!1},prevItem:{title:"Terry Pratchett and the Azure Static Web Apps",permalink:"/terry-pratchett-x-clacks-overhead-azure-static-webapps"},nextItem:{title:"Azure Static Web Apps: Failed to deploy the Azure Functions",permalink:"/static-web-apps-failed-to-deploy-the-azure-functions"}},p={image:n(49265).Z,authorsImageUrls:[void 0]},u=[{value:"Build validations",id:"build-validations",level:2},{value:"curl build validations",id:"curl-build-validations",level:2},{value:"Node.js API",id:"nodejs-api",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Build validations are a great way to protect your branches in Azure DevOps. It's possible to use the Azure DevOps API to acquire the build validations a project uses. This post shows you how using curl and the Node.js API."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Get Build Validations with the Azure DevOps API&quot; with Azure Pipelines and Azure DevOps logo",src:n(49265).Z,width:"1080",height:"1080"})),(0,a.kt)("h2",o({},{id:"build-validations"}),"Build validations"),(0,a.kt)("p",null,"We care about our ",(0,a.kt)("inlineCode",{parentName:"p"},"main")," branch. Before changes can be made to it, we want them to meet some kind of quality benchmark. In Azure DevOps these come in the form of branch policies. We're interested in a particular type of these called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/devops/repos/git/branch-policies?view=azure-devops&tabs=browser#build-validation"}),"build validations"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"A build validation policy queues a new build when a new PR is created or changes are pushed to an existing PR that targets the branch. The build policy evaluates the build results to determine whether the PR can be completed.")),(0,a.kt)("p",null,"If you want to examine whether a project uses build validations, you can do so using the Azure DevOps API. It's available under the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/rest/api/azure/devops/policy/configurations/list?view=azure-devops-rest-7.1"}),"policy configurations endpoint"),"."),(0,a.kt)("h2",o({},{id:"curl-build-validations"}),"curl build validations"),(0,a.kt)("p",null,"To acquire build validations from the API we'll need a personal access token. We can make one of those here: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://dev.azure.com/organisation-name/_usersSettings/tokens"}),"https://dev.azure.com/organisation-name/_usersSettings/tokens")," (where ",(0,a.kt)("inlineCode",{parentName:"p"},"organisation-name")," is the name of our organisation)."),(0,a.kt)("p",null,"With that in hand, let's acquire the branch policies with a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://curl.se/"}),"curl"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"curl  --user '':'PERSONAL_ACCESS_TOKEN' --header \"Content-Type: application/json\" --header \"Accept:application/json\" https://dev.azure.com/{organisation}/{project}/_apis/policy/configurations?api-version=7.1-preview.1\n")),(0,a.kt)("p",null,"You'll retrieve a JSON array that represents all the branch policies that are in play, ",(0,a.kt)("em",{parentName:"p"},"including")," build validations. Below is an example of a retrieved build validation:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'[\n  //...\n  {\n    "createdBy": {\n      "displayName": "Project Collection Build Service (organisation-name)",\n      "url": "https://spsprodweu1.vssps.visualstudio.com/A2426c3ce-09b0-4333-9218-58da7d53c564/_apis/Identities/aad5a5e5-baf9-40b3-ad30-0cb828c25629",\n      "_links": {\n        "avatar": {\n          "href": "https://dev.azure.com/organisation-name/_apis/GraphProfile/MemberAvatars/svc.MjQyNmMzY2UtMDliMC00MzMzLTkyMTgtNThkYTdkNTNjNTY0OkJ1aWxkOmE1YTE3N2U2LTZhMzAtNGRiMi1iYzMxLTllOTE1M2U3Yjk0Nw"\n        }\n      },\n      "id": "aad5a5e5-baf9-40b3-ad30-0cb828c25629",\n      "uniqueName": "Build\\\\a5a177e6-6a30-4db2-bc31-9e9153e7b947",\n      "imageUrl": "https://dev.azure.com/organisation-name/_api/_common/identityImage?id=aad5a5e5-baf9-40b3-ad30-0cb828c25629",\n      "descriptor": "svc.MjQyNmMzY2UtMDliMC00MzMzLTkyMTgtNThkYTdkNTNjNTY0OkJ1aWxkOmE1YTE3N2U2LTZhMzAtNGRiMi1iYzMxLTllOTE1M2U3Yjk0Nw"\n    },\n    "createdDate": "2022-07-06T14:25:39.5585302Z",\n    "isEnabled": true,\n    "isBlocking": true,\n    "isDeleted": false,\n    "settings": {\n      "buildDefinitionId": 1107,\n      "queueOnSourceUpdateOnly": true,\n      "manualQueueOnly": false,\n      "displayName": "PR Validation",\n      "validDuration": 720,\n      "scope": [\n        {\n          "refName": "refs/heads/main",\n          "matchKind": "Exact",\n          "repositoryId": "dc4213a0-fc26-4afc-8b3e-4fd27eaaafa6"\n        }\n      ]\n    },\n    "isEnterpriseManaged": false,\n    "_links": {\n      "self": {\n        "href": "https://dev.azure.com/organisation-name/ea861f16-ec9d-4256-a2a6-55dd7533af36/_apis/policy/configurations/1261"\n      },\n      "policyType": {\n        "href": "https://dev.azure.com/organisation-name/ea861f16-ec9d-4256-a2a6-55dd7533af36/_apis/policy/types/0609b952-1397-4640-95ec-e00a01b2c241"\n      }\n    },\n    "revision": 2,\n    "id": 1261,\n    "url": "https://dev.azure.com/organisation-name/ea861f16-ec9d-4256-a2a6-55dd7533af36/_apis/policy/configurations/1261",\n    "type": {\n      "id": "0609b952-1397-4640-95ec-e00a01b2c241",\n      "url": "https://dev.azure.com/organisation-name/ea861f16-ec9d-4256-a2a6-55dd7533af36/_apis/policy/types/0609b952-1397-4640-95ec-e00a01b2c241",\n      "displayName": "Build"\n    }\n  }\n]\n')),(0,a.kt)("p",null,"Note the ",(0,a.kt)("inlineCode",{parentName:"p"},"type")," property with the ",(0,a.kt)("inlineCode",{parentName:"p"},"displayName")," of ",(0,a.kt)("inlineCode",{parentName:"p"},'"Build"'),". That's how we identify build validations in amongst the other branch policies. If you'd like to filter the output down to just build validations on the command line, you can by mixing your curl with a little ",(0,a.kt)("a",o({parentName:"p"},{href:"https://stedolan.github.io/jq/"}),"jq"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"curl  --user '':'PERSONAL_ACCESS_TOKEN' --header \"Content-Type: application/json\" --header \"Accept:application/json\" https://dev.azure.com/{organisation}/{project}/_apis/policy/configurations?api-version=7.1-preview.1 | jq -c '.value[] | select(.type.displayName == \"Build\")'\n")),(0,a.kt)("h2",o({},{id:"nodejs-api"}),"Node.js API"),(0,a.kt)("p",null,"If you'd like to achieve the same using TypeScript, you can. The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/azure-devops-node-api"}),"Azure DevOps Client for Node.js")," provides an API and (in large part) the types. Let's obtain the build validations for a project in Node.js using the client:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import * as nodeApi from 'azure-devops-node-api';\n\ninterface BuildValidation {\n  buildDefinitionId: number | undefined;\n  name: string | undefined;\n  repositoryId: string | undefined;\n}\n\nasync function getProjectBuildValidations(\n  projectId: string\n): Promise<BuildValidation[]> {\n  const authHandler = nodeApi.getPersonalAccessTokenHandler(\n    pat,\n    /** allowCrossOriginAuthentication */ true\n  );\n\n  const webApi = new nodeApi.WebApi(orgUrl, authHandler);\n  const policyApi = await webApi.getPolicyApi();\n\n  const configurations = await policyApi.getPolicyConfigurations(projectId);\n\n  const buildValidations = configurations\n    .filter(\n      // we only want the build validations\n      (configuration) => configuration.type?.displayName === 'Build'\n    )\n    .map((configuration) => ({\n      // map down to a custom type\n      buildDefinitionId: configuration.settings.buildDefinitionId,\n      name: configuration.settings.displayName,\n      repositoryId:\n        configuration.settings.scope?.length > 0\n          ? configuration.settings.scope[0].repositoryId\n          : undefined,\n    }));\n\n  return buildValidations;\n}\n")),(0,a.kt)("p",null,"The above ",(0,a.kt)("inlineCode",{parentName:"p"},"getProjectBuildValidations")," function acquires build validations for a given project, and maps them into this custom type:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"interface BuildValidation {\n  /** the id of the azure pipeline which is triggered by the build validation */\n  buildDefinitionId: number | undefined;\n  /** the name of the build validation */\n  name: string | undefined;\n  /** if a build validation is tied to a repository (probable) this is the repository id */\n  repositoryId: string | undefined;\n}\n")),(0,a.kt)("p",null,"Which leaves us with a delightfully strongly typed array of build validations!"),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"This post has detailed what build validations are in Azure DevOps. It has also demonstrated how to query the Azure DevOps API for them using the command line and using Node.js."))}d.isMDXComponent=!0},23122:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"terry-pratchett-x-clacks-overhead-azure-static-webapps",title:"Terry Pratchett and the Azure Static Web Apps",authors:"johnnyreilly",tags:["Azure Static Web Apps"],image:"./title-image.png",description:"Terry Pratchett has a HTTP header: X-Clacks-Overhead. This post shows how we can make Azure Static Web Apps join in.",hide_table_of_contents:!1},s=void 0,l={permalink:"/terry-pratchett-x-clacks-overhead-azure-static-webapps",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-07-23-terry-pratchett-x-clacks-overhead-azure-static-webapps/index.md",source:"@site/blog/2022-07-23-terry-pratchett-x-clacks-overhead-azure-static-webapps/index.md",title:"Terry Pratchett and the Azure Static Web Apps",description:"Terry Pratchett has a HTTP header: X-Clacks-Overhead. This post shows how we can make Azure Static Web Apps join in.",date:"2022-07-23T00:00:00.000Z",formattedDate:"July 23, 2022",tags:[{label:"Azure Static Web Apps",permalink:"/tags/azure-static-web-apps"}],readingTime:2.03,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"terry-pratchett-x-clacks-overhead-azure-static-webapps",title:"Terry Pratchett and the Azure Static Web Apps",authors:"johnnyreilly",tags:["Azure Static Web Apps"],image:"./title-image.png",description:"Terry Pratchett has a HTTP header: X-Clacks-Overhead. This post shows how we can make Azure Static Web Apps join in.",hide_table_of_contents:!1},prevItem:{title:"Swashbuckle and schemaId is already used",permalink:"/swashbuckle-schemaid-already-used"},nextItem:{title:"Get Build Validations with the Azure DevOps API",permalink:"/azure-devops-api-build-validations"}},p={image:n(42284).Z,authorsImageUrls:[void 0]},u=[{value:"What is <code>X-Clacks-Overhead</code>?",id:"what-is-x-clacks-overhead",level:2},{value:"Azure Static Web Apps serving the <code>X-Clacks-Overhead</code> header",id:"azure-static-web-apps-serving-the-x-clacks-overhead-header",level:2},{value:"Who else is out there?",id:"who-else-is-out-there",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Terry Pratchett is remembered on the internet. A non-standardised HTTP header: ",(0,a.kt)("inlineCode",{parentName:"p"},"X-Clacks-Overhead")," is broadcast by websites seeking to pay tribute to the great man. This post shows how we can make Azure Static Web Apps join in."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Terry Pratchett and the Azure Static Web Apps&quot; with the Azure Static Web Apps logo and a Terry Pratchett icon by Lisa Krymova from NounProject.com",src:n(42284).Z,width:"799",height:"450"})),(0,a.kt)("h2",o({},{id:"what-is-x-clacks-overhead"}),"What is ",(0,a.kt)("inlineCode",{parentName:"h2"},"X-Clacks-Overhead"),"?"),(0,a.kt)("p",null,"This is well documented in the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://xclacksoverhead.org/"}),(0,a.kt)("inlineCode",{parentName:"a"},"X-Clacks-Overhead"))," website. To quote the highlights:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"X-Clacks-Overhead is a non-standardised HTTP header based upon the fictional work of the late, great, Sir Terry Pratchett..."),(0,a.kt)("p",{parentName:"blockquote"},"As a way to preserve the memory of Sir Terry Pratchett, the users of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.reddit.com/r/discworld/"}),"SubReddit for the Discworld series")," came up with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.reddit.com/r/discworld/comments/2yt9j6/gnu_terry_pratchett/"}),"the idea behind the X-Clacks-Overhead HTTP Header"),". It allows web authors to silently commemorate someone through the use of a non-invasive header that can be transmitted from server to server, or server to client without operational interference."),(0,a.kt)("p",{parentName:"blockquote"},"You would only know the header is present if you analysed the transmission headers of your content requests on web sites serving the header.")),(0,a.kt)("p",null,"Put simply, participating websites will broadcast the ",(0,a.kt)("inlineCode",{parentName:"p"},"X-Clacks-Overhead: GNU Terry Pratchett")," header when they are serving content to a user."),(0,a.kt)("h2",o({},{id:"azure-static-web-apps-serving-the-x-clacks-overhead-header"}),"Azure Static Web Apps serving the ",(0,a.kt)("inlineCode",{parentName:"h2"},"X-Clacks-Overhead")," header"),(0,a.kt)("p",null,"Now we understand what we want to do, we can make an Azure Static Web Apps project do just that."),(0,a.kt)("p",null,"We're going to need an ",(0,a.kt)("inlineCode",{parentName:"p"},"staticwebappconfig.json")," in root of our app, so we can configure our SWA. To add extra headers in, you use the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/azure/static-web-apps/configuration#global-headers"}),(0,a.kt)("inlineCode",{parentName:"a"},"globalHeaders"))," setting:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "globalHeaders": {\n    "X-Clacks-Overhead": "GNU Terry Pratchett"\n  }\n}\n')),(0,a.kt)("p",null,"Above, we added the ",(0,a.kt)("inlineCode",{parentName:"p"},"X-Clacks-Overhead")," header. When our app is deployed, it will automatically add this header to all requests:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Chrome Devtools showing the `x-clacks-overhead` header on this blog",src:n(33431).Z,width:"1853",height:"636"})),(0,a.kt)("p",null,"The above screenshot shows this very blog broadcasting the ",(0,a.kt)("inlineCode",{parentName:"p"},"X-Clacks-Overhead")," header. If you crack open devtools you can validate this for yourself. The pull request that added it in ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/pull/273"}),"can be found here"),"."),(0,a.kt)("h2",o({},{id:"who-else-is-out-there"}),"Who else is out there?"),(0,a.kt)("p",null,"It's great to know you're in good company. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://xclacksoverhead.org/listing/the-signal"}),"This page")," tracks websites that are broadcasting the ",(0,a.kt)("inlineCode",{parentName:"p"},"X-Clacks-Overhead")," header. You can see from the image below that it has found this website too!"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of https://xclacksoverhead.org/listing/the-signal showing this blog being listed",src:n(2812).Z,width:"1466",height:"903"})),(0,a.kt)("p",null,"So if you'd like your Azure Static Web App to whisper Terry Pratchett's name under its breath; make it so!"))}d.isMDXComponent=!0},24598:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"swashbuckle-schemaid-already-used",title:"Swashbuckle and schemaId is already used",authors:"johnnyreilly",tags:["Swashbuckle"],image:"./title-image.png",description:'Swashbuckle can fail to generate a swagger / Open API document with the message "The same schemaId is already used...". This post offers a way forward.',hide_table_of_contents:!1},s=void 0,l={permalink:"/swashbuckle-schemaid-already-used",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-08-31-swashbuckle-schemaid-already-used/index.md",source:"@site/blog/2022-08-31-swashbuckle-schemaid-already-used/index.md",title:"Swashbuckle and schemaId is already used",description:'Swashbuckle can fail to generate a swagger / Open API document with the message "The same schemaId is already used...". This post offers a way forward.',date:"2022-08-31T00:00:00.000Z",formattedDate:"August 31, 2022",tags:[{label:"Swashbuckle",permalink:"/tags/swashbuckle"}],readingTime:2.255,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"swashbuckle-schemaid-already-used",title:"Swashbuckle and schemaId is already used",authors:"johnnyreilly",tags:["Swashbuckle"],image:"./title-image.png",description:'Swashbuckle can fail to generate a swagger / Open API document with the message "The same schemaId is already used...". This post offers a way forward.',hide_table_of_contents:!1},prevItem:{title:"Reverse engineering the Azure Application Insights Transactions URL",permalink:"/reverse-engineering-azure-app-insights-transactions-url"},nextItem:{title:"Terry Pratchett and the Azure Static Web Apps",permalink:"/terry-pratchett-x-clacks-overhead-azure-static-webapps"}},p={image:n(46432).Z,authorsImageUrls:[void 0]},u=[{value:"&quot;The same schemaId is already used...&quot;",id:"the-same-schemaid-is-already-used",level:2},{value:"Nicer names with <code>SwashbuckleSchemaHelper</code>",id:"nicer-names-with-swashbuckleschemahelper",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'Swashbuckle can fail to generate a swagger / Open API document with the message "The same schemaId is already used...". This post explains what that means, and offers a way to work around it.'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Swashbuckle and schemaId is already used&quot; with the Azure Static Web Apps logo and a Terry Pratchett icon by Lisa Krymova from NounProject.com",src:n(46432).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"the-same-schemaid-is-already-used"}),'"The same schemaId is already used..."'),(0,a.kt)("p",null,"When creating a swagger / Open API document with Swashbuckle, it's possible to encounter an error of this nature:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),'System.InvalidOperationException: Can\'t use schemaId "$MyType" for type "$OneNamespace.MyType". The same schemaId is already used for type "$OtherNamespace.MyType"\n')),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/domaindrivendev"}),"Richard Morris")," explains the reason for this ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/domaindrivendev/Swashbuckle.AspNetCore/issues/1607#issuecomment-788900097"}),"here"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"By default, SB uses the short (unqualified name) which has its benefits because it keeps the docs simpler but also it\u2019s downside if model names are duplicated in different namespaces.")),(0,a.kt)("p",null,"The solution for this is using the ",(0,a.kt)("inlineCode",{parentName:"p"},"CustomSchemaIds")," configuration option for Swashbuckle. This allows the customisation of type names, such that collisions are prevented. We need types to be unique strings. A simple way to tackle this is something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"services.AddSwaggerGen(options =>\n{\n    options.CustomSchemaIds(type => type.ToString());\n});\n")),(0,a.kt)("p",null,"However, the types created using the above approach can be verbose. Wouldn't it be nice if we could essentially have the names we had before, but just handle duplicates with an incrementing number?"),(0,a.kt)("h2",o({},{id:"nicer-names-with-swashbuckleschemahelper"}),"Nicer names with ",(0,a.kt)("inlineCode",{parentName:"h2"},"SwashbuckleSchemaHelper")),(0,a.kt)("p",null,"We can do exactly this. What we'll do is put together a class called ",(0,a.kt)("inlineCode",{parentName:"p"},"SwashbuckleSchemaHelper"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'public class SwashbuckleSchemaHelper\n{\n    private readonly Dictionary<string, List<string>> _schemaNameRepetition = new();\n\n    // borrowed from https://github.com/domaindrivendev/Swashbuckle.AspNetCore/blob/95cb4d370e08e54eb04cf14e7e6388ca974a686e/src/Swashbuckle.AspNetCore.SwaggerGen/SchemaGenerator/SchemaGeneratorOptions.cs#L44\n    private string DefaultSchemaIdSelector(Type modelType)\n    {\n        if (!modelType.IsConstructedGenericType) return modelType.Name.Replace("[]", "Array");\n\n        var prefix = modelType.GetGenericArguments()\n            .Select(genericArg => DefaultSchemaIdSelector(genericArg))\n            .Aggregate((previous, current) => previous + current);\n\n        return prefix + modelType.Name.Split(\'`\').First();\n    }\n\n    public string GetSchemaId(Type modelType)\n    {\n        string id = DefaultSchemaIdSelector(modelType);\n\n        if (!_schemaNameRepetition.ContainsKey(id))\n            _schemaNameRepetition.Add(id, new List<string>());\n\n        var modelNameList = _schemaNameRepetition[id];\n        var fullName = modelType.FullName ?? "";\n        if (!string.IsNullOrEmpty(fullName) && !modelNameList.Contains(fullName))\n            modelNameList.Add(fullName);\n\n        int index = modelNameList.IndexOf(fullName);\n\n        return $"{id}{(index >= 1 ? index.ToString() : "")}";\n    }\n}\n')),(0,a.kt)("p",null,"The above class borrows the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/domaindrivendev/Swashbuckle.AspNetCore/blob/95cb4d370e08e54eb04cf14e7e6388ca974a686e/src/Swashbuckle.AspNetCore.SwaggerGen/SchemaGenerator/SchemaGeneratorOptions.cs#L44"}),(0,a.kt)("inlineCode",{parentName:"a"},"DefaultSchemaIdSelector"))," implementation from Swashbuckle itself. It creates the type name using that, and then uses a ",(0,a.kt)("inlineCode",{parentName:"p"},"Dictionary")," to track the numbers of usages of it; suffixing a number where there are duplicates to indicate which duplicate is in play on this occasion. This number suffix is inspired ",(0,a.kt)("a",o({parentName:"p"},{href:"https://stackoverflow.com/a/72677918/761388"}),"by an answer on Stack Overflow")," and also by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/domaindrivendev/Swashbuckle.AspNetCore/issues/1607#issuecomment-1258337736"}),"Glenn Piper's comment here"),"."),(0,a.kt)("p",null,"Usage of this looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"services.AddSwaggerGen(options =>\n{\n    var schemaHelper = new SwashbuckleSchemaHelper();\n    options.CustomSchemaIds(type => schemaHelper.GetSchemaId(type));\n});\n")),(0,a.kt)("p",null,"The result of using this approach is that you'll start to generate multiple types: ",(0,a.kt)("inlineCode",{parentName:"p"},"MyType")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"MyType2"),', and importantly a goodbye to the "The same schemaId is already used..." message.'))}d.isMDXComponent=!0},83878:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"reverse-engineering-azure-app-insights-transactions-url",title:"Reverse engineering the Azure Application Insights Transactions URL",authors:"johnnyreilly",tags:["Azure Application Insights","typescript","C#"],image:"./title-image.png",description:"This post reverse engineers the Azure Application Insights Transactions URL, showing how to make a link href, using both TypeScript and C#.",hide_table_of_contents:!1},s=void 0,l={permalink:"/reverse-engineering-azure-app-insights-transactions-url",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-09-03-reverse-engineering-azure-app-insights-transactions-url/index.md",source:"@site/blog/2022-09-03-reverse-engineering-azure-app-insights-transactions-url/index.md",title:"Reverse engineering the Azure Application Insights Transactions URL",description:"This post reverse engineers the Azure Application Insights Transactions URL, showing how to make a link href, using both TypeScript and C#.",date:"2022-09-03T00:00:00.000Z",formattedDate:"September 3, 2022",tags:[{label:"Azure Application Insights",permalink:"/tags/azure-application-insights"},{label:"typescript",permalink:"/tags/typescript"},{label:"C#",permalink:"/tags/c"}],readingTime:7.955,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"reverse-engineering-azure-app-insights-transactions-url",title:"Reverse engineering the Azure Application Insights Transactions URL",authors:"johnnyreilly",tags:["Azure Application Insights","typescript","C#"],image:"./title-image.png",description:"This post reverse engineers the Azure Application Insights Transactions URL, showing how to make a link href, using both TypeScript and C#.",hide_table_of_contents:!1},prevItem:{title:"React: storing state in URL with URLSearchParams",permalink:"/react-usesearchparamsstate"},nextItem:{title:"Swashbuckle and schemaId is already used",permalink:"/swashbuckle-schemaid-already-used"}},p={image:n(54524).Z,authorsImageUrls:[void 0]},u=[{value:"Bring me the logs!",id:"bring-me-the-logs",level:2},{value:"Breaking down the link",id:"breaking-down-the-link",level:2},{value:"1. Main Azure Portal routing",id:"1-main-azure-portal-routing",level:3},{value:"2. ResourceId",id:"2-resourceid",level:3},{value:"3. More Azure Portal routing",id:"3-more-azure-portal-routing",level:3},{value:"4. The query",id:"4-the-query",level:3},{value:"Reverse engineering a link",id:"reverse-engineering-a-link",level:2},{value:"TypeScript URL builder",id:"typescript-url-builder",level:2},{value:"C# URL builder",id:"c-url-builder",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Logs matter. In Azure, logs generally live in Application Insights, in the Transaction Search section. This post reverse engineers the Azure Application Insights Transactions URL, and details how to construct a link to take you directly there, using both TypeScript and C#."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Reverse engineering the Azure Application Insights Transactions URL&quot; with a screenshot of the Transactions screen in the Azure Portal",src:n(54524).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"bring-me-the-logs"}),"Bring me the logs!"),(0,a.kt)("p",null,"If you've ever supported a production system, you will know this to be true: logs matter. Logs help you understand what's gone wrong. (You're never looking at logs when something has gone right.) When it comes to Azure, logs tend to reside in Application Insights, specifically Transactions:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the Azure Application Insights Transaction Search screen",src:n(74470).Z,width:"1828",height:"1202"})),(0,a.kt)("p",null,"Whilst Transaction Search is very powerful, it can also be a little tough to find the things that you need. In a system I'm working on now, we've found ourselves building an application that allows us to provide support. We use it to bring together disparate pieces of information across our estate. As we use it, we're usually looking at a particular slice of time. If we don't find what we need in our application we'll find a need to dig into the logs for the same period."),(0,a.kt)("p",null,"Rather than manually logging into Azure, finding Application Insights, going to Transactions and entering the time period, what if we could just go there at the click of a link? We can."),(0,a.kt)("p",null,'Look at the screenshot above, do you see the "Copy link" button? That button copies a URL to the clipboard which encapsulates the current search criteria. And it turns out we can reverse engineer it!'),(0,a.kt)("h2",o({},{id:"breaking-down-the-link"}),"Breaking down the link"),(0,a.kt)("p",null,"First of all, let's take a look at the incredibly long URL that's copied to the clipboard:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-text"}),"https://portal.azure.com/#blade/AppInsightsExtension/BladeRedirect/BladeName/searchV1/ResourceId/%2Fsubscriptions%2F4e41a677-9a57-4a7c-9c4c-e71bae5d998e%2Fresourcegroups%2Frg-maas-shared-storage-dev-001%2Fproviders%2Fmicrosoft.insights%2Fcomponents%2Fappi-maas-shared-dev/BladeInputs/%7B%22tables%22%3A%5B%22traces%22%5D%2C%22timeContextWhereClause%22%3A%22%7C+where+timestamp+%3E+datetime(%5C%222022-05-03T10%3A04%3A33.267Z%5C%22)+and+timestamp+%3C+datetime(%5C%222022-05-03T10%3A34%3A33.267Z%5C%22)%22%2C%22filterWhereClause%22%3A%22%7C+where+severityLevel+in+(%5C%223%5C%22)%7C+where+*+has+%5C%22healthcheck%5C%22%7C+order+by+timestamp+desc%22%2C%22originalParams%22%3A%7B%22eventTypes%22%3A%5B%7B%22value%22%3A%22availabilityResult%22%2C%22tableName%22%3A%22availabilityResults%22%2C%22label%22%3A%22Availability%22%7D%2C%7B%22value%22%3A%22request%22%2C%22tableName%22%3A%22requests%22%2C%22label%22%3A%22Request%22%7D%2C%7B%22value%22%3A%22exception%22%2C%22tableName%22%3A%22exceptions%22%2C%22label%22%3A%22Exception%22%7D%2C%7B%22value%22%3A%22pageView%22%2C%22tableName%22%3A%22pageViews%22%2C%22label%22%3A%22Page+View%22%7D%2C%7B%22value%22%3A%22trace%22%2C%22tableName%22%3A%22traces%22%2C%22label%22%3A%22Trace%22%7D%2C%7B%22value%22%3A%22customEvent%22%2C%22tableName%22%3A%22customEvents%22%2C%22label%22%3A%22Custom+Event%22%7D%2C%7B%22value%22%3A%22dependency%22%2C%22tableName%22%3A%22dependencies%22%2C%22label%22%3A%22Dependency%22%7D%5D%2C%22timeContext%22%3A%7B%22durationMs%22%3A1800000%2C%22endTime%22%3A%222022-05-03T10%3A34%3A33.267Z%22%7D%2C%22filter%22%3A%5B%5D%2C%22searchPhrase%22%3A%7B%22originalPhrase%22%3A%22healthcheck%22%2C%22_tokens%22%3A%5B%7B%22conjunction%22%3A%22and%22%2C%22value%22%3A%22healthcheck%22%2C%22isNot%22%3Afalse%2C%22kql%22%3A%22+*+has+%5C%22healthcheck%5C%22%22%7D%5D%7D%2C%22sort%22%3A%22desc%22%7D%7D\n")),(0,a.kt)("p",null,"There's 1860 characters in there. That's a lot - but still less than the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://stackoverflow.com/questions/417142/what-is-the-maximum-length-of-a-url-in-different-browsers"}),"general limit of 2000 characters"),". This mighty long URL can be broken down into four distinct parts. Let's break it down:"),(0,a.kt)("h3",o({},{id:"1-main-azure-portal-routing"}),"1. Main Azure Portal routing"),(0,a.kt)("p",null,"Firstly this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-text"}),"https://portal.azure.com/#blade/AppInsightsExtension/BladeRedirect/BladeName/searchV1/ResourceId/\n")),(0,a.kt)("p",null,"This is a recognisable base URL and takes us to the relevant part of the Azure Portal."),(0,a.kt)("h3",o({},{id:"2-resourceid"}),"2. ResourceId"),(0,a.kt)("p",null,"Next we have a URL encoded ResourceId:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-text"}),"%2Fsubscriptions%2F4e41a677-9a57-4a7c-9c4c-e71bae5d998e%2Fresourcegroups%2Frg-maas-shared-storage-dev-001%2Fproviders%2Fmicrosoft.insights%2Fcomponents%2Fappi-maas-shared-dev\n")),(0,a.kt)("p",null,"If we run it through ",(0,a.kt)("inlineCode",{parentName:"p"},"decodeURIComponent")," you can see it in it's raw form:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"decodeURIComponent(\n  '%2Fsubscriptions%2F4e41a677-9a57-4a7c-9c4c-e71bae5d998e%2Fresourcegroups%2Frg-maas-shared-storage-dev-001%2Fproviders%2Fmicrosoft.insights%2Fcomponents%2Fappi-maas-shared-dev'\n);\n\n// creates: /subscriptions/4e41a677-9a57-4a7c-9c4c-e71bae5d998e/resourcegroups/rg-maas-shared-storage-dev-001/providers/microsoft.insights/components/appi-maas-shared-dev'\n")),(0,a.kt)("p",null,"This is the ResourceId of the Application Insights instance that we're looking at. This is the same as the one we saw in the URL when we were looking at the Application Insights instance in the Azure Portal, and it's the ResourceId that can be obtained by clicking on the \"JSON View\" link:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the application insights overview screen with a JSON View icon on the right",src:n(39405).Z,width:"2538",height:"190"})),(0,a.kt)("h3",o({},{id:"3-more-azure-portal-routing"}),"3. More Azure Portal routing"),(0,a.kt)("p",null,"The next part of the URL is just some more Azure Portal routing:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-text"}),"/BladeInputs/\n")),(0,a.kt)("h3",o({},{id:"4-the-query"}),"4. The query"),(0,a.kt)("p",null,"Finally we have the (very long) query:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-text"}),"%7B%22tables%22%3A%5B%22traces%22%5D%2C%22timeContextWhereClause%22%3A%22%7C+where+timestamp+%3E+datetime(%5C%222022-05-03T10%3A04%3A33.267Z%5C%22)+and+timestamp+%3C+datetime(%5C%222022-05-03T10%3A34%3A33.267Z%5C%22)%22%2C%22filterWhereClause%22%3A%22%7C+where+severityLevel+in+(%5C%223%5C%22)%7C+where+_+has+%5C%22healthcheck%5C%22%7C+order+by+timestamp+desc%22%2C%22originalParams%22%3A%7B%22eventTypes%22%3A%5B%7B%22value%22%3A%22availabilityResult%22%2C%22tableName%22%3A%22availabilityResults%22%2C%22label%22%3A%22Availability%22%7D%2C%7B%22value%22%3A%22request%22%2C%22tableName%22%3A%22requests%22%2C%22label%22%3A%22Request%22%7D%2C%7B%22value%22%3A%22exception%22%2C%22tableName%22%3A%22exceptions%22%2C%22label%22%3A%22Exception%22%7D%2C%7B%22value%22%3A%22pageView%22%2C%22tableName%22%3A%22pageViews%22%2C%22label%22%3A%22Page+View%22%7D%2C%7B%22value%22%3A%22trace%22%2C%22tableName%22%3A%22traces%22%2C%22label%22%3A%22Trace%22%7D%2C%7B%22value%22%3A%22customEvent%22%2C%22tableName%22%3A%22customEvents%22%2C%22label%22%3A%22Custom+Event%22%7D%2C%7B%22value%22%3A%22dependency%22%2C%22tableName%22%3A%22dependencies%22%2C%22label%22%3A%22Dependency%22%7D%5D%2C%22timeContext%22%3A%7B%22durationMs%22%3A1800000%2C%22endTime%22%3A%222022-05-03T10%3A34%3A33.267Z%22%7D%2C%22filter%22%3A%5B%5D%2C%22searchPhrase%22%3A%7B%22originalPhrase%22%3A%22healthcheck%22%2C%22_tokens%22%3A%5B%7B%22conjunction%22%3A%22and%22%2C%22value%22%3A%22healthcheck%22%2C%22isNot%22%3Afalse%2C%22kql%22%3A%22+_+has+%5C%22healthcheck%5C%22%22%7D%5D%7D%2C%22sort%22%3A%22desc%22%7D%7D\n")),(0,a.kt)("p",null,"Initially this doesn't look like much. It's just a long string of characters. But if we run it through ",(0,a.kt)("inlineCode",{parentName:"p"},"decodeURIComponent")," we can see that it's actually a JSON object:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),'decodeURIComponent(\n  \'%7B%22tables%22%3A%5B%22traces%22%5D%2C%22timeContextWhereClause%22%3A%22%7C+where+timestamp+%3E+datetime(%5C%222022-05-03T10%3A04%3A33.267Z%5C%22)+and+timestamp+%3C+datetime(%5C%222022-05-03T10%3A34%3A33.267Z%5C%22)%22%2C%22filterWhereClause%22%3A%22%7C+where+severityLevel+in+(%5C%223%5C%22)%7C+where+_+has+%5C%22healthcheck%5C%22%7C+order+by+timestamp+desc%22%2C%22originalParams%22%3A%7B%22eventTypes%22%3A%5B%7B%22value%22%3A%22availabilityResult%22%2C%22tableName%22%3A%22availabilityResults%22%2C%22label%22%3A%22Availability%22%7D%2C%7B%22value%22%3A%22request%22%2C%22tableName%22%3A%22requests%22%2C%22label%22%3A%22Request%22%7D%2C%7B%22value%22%3A%22exception%22%2C%22tableName%22%3A%22exceptions%22%2C%22label%22%3A%22Exception%22%7D%2C%7B%22value%22%3A%22pageView%22%2C%22tableName%22%3A%22pageViews%22%2C%22label%22%3A%22Page+View%22%7D%2C%7B%22value%22%3A%22trace%22%2C%22tableName%22%3A%22traces%22%2C%22label%22%3A%22Trace%22%7D%2C%7B%22value%22%3A%22customEvent%22%2C%22tableName%22%3A%22customEvents%22%2C%22label%22%3A%22Custom+Event%22%7D%2C%7B%22value%22%3A%22dependency%22%2C%22tableName%22%3A%22dependencies%22%2C%22label%22%3A%22Dependency%22%7D%5D%2C%22timeContext%22%3A%7B%22durationMs%22%3A1800000%2C%22endTime%22%3A%222022-05-03T10%3A34%3A33.267Z%22%7D%2C%22filter%22%3A%5B%5D%2C%22searchPhrase%22%3A%7B%22originalPhrase%22%3A%22healthcheck%22%2C%22_tokens%22%3A%5B%7B%22conjunction%22%3A%22and%22%2C%22value%22%3A%22healthcheck%22%2C%22isNot%22%3Afalse%2C%22kql%22%3A%22+_+has+%5C%22healthcheck%5C%22%22%7D%5D%7D%2C%22sort%22%3A%22desc%22%7D%7D\'\n);\n\n// creates: \'{"tables":["traces"],"timeContextWhereClause":"|+where+timestamp+>+datetime(\\\\"2022-05-03T10:04:33.267Z\\\\")+and+timestamp+<+datetime(\\\\"2022-05-03T10:34:33.267Z\\\\")","filterWhereClause":"|+where+severityLevel+in+(\\\\"3\\\\")|+where+_+has+\\\\"healthcheck\\\\"|+order+by+timestamp+desc","originalParams":{"eventTypes":[{"value":"availabilityResult","tableName":"availabilityResults","label":"Availability"},{"value":"request","tableName":"requests","label":"Request"},{"value":"exception","tableName":"exceptions","label":"Exception"},{"value":"pageView","tableName":"pageViews","label":"Page+View"},{"value":"trace","tableName":"traces","label":"Trace"},{"value":"customEvent","tableName":"customEvents","label":"Custom+Event"},{"value":"dependency","tableName":"dependencies","label":"Dependency"}],"timeContext":{"durationMs":1800000,"endTime":"2022-05-03T10:34:33.267Z"},"filter":[],"searchPhrase":{"originalPhrase":"healthcheck","_tokens":[{"conjunction":"and","value":"healthcheck","isNot":false,"kql":"+_+has+\\\\"healthcheck\\\\""}]},"sort":"desc"}}\'\n')),(0,a.kt)("p",null,"And if we parse that JSON object we get:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "tables": ["traces"],\n  "timeContextWhereClause": "|+where+timestamp+>+datetime(\\"2022-05-03T10:04:33.267Z\\")+and+timestamp+<+datetime(\\"2022-05-03T10:34:33.267Z\\")",\n  "filterWhereClause": "|+where+severityLevel+in+(\\"3\\")|+where+_+has+\\"healthcheck\\"|+order+by+timestamp+desc",\n  "originalParams": {\n    "eventTypes": [\n      {\n        "value": "availabilityResult",\n        "tableName": "availabilityResults",\n        "label": "Availability"\n      },\n      {\n        "value": "request",\n        "tableName": "requests",\n        "label": "Request"\n      },\n      {\n        "value": "exception",\n        "tableName": "exceptions",\n        "label": "Exception"\n      },\n      {\n        "value": "pageView",\n        "tableName": "pageViews",\n        "label": "Page+View"\n      },\n      {\n        "value": "trace",\n        "tableName": "traces",\n        "label": "Trace"\n      },\n      {\n        "value": "customEvent",\n        "tableName": "customEvents",\n        "label": "Custom+Event"\n      },\n      {\n        "value": "dependency",\n        "tableName": "dependencies",\n        "label": "Dependency"\n      }\n    ],\n    "timeContext": {\n      "durationMs": 1800000,\n      "endTime": "2022-05-03T10:34:33.267Z"\n    },\n    "filter": [],\n    "searchPhrase": {\n      "originalPhrase": "healthcheck",\n      "_tokens": [\n        {\n          "conjunction": "and",\n          "value": "healthcheck",\n          "isNot": false,\n          "kql": "+_+has+\\"healthcheck\\""\n        }\n      ]\n    },\n    "sort": "desc"\n  }\n}\n')),(0,a.kt)("p",null,"We can clearly see in the object above the aspects that contribute to our query. It's worth highlighting that when I generated the above query, I had the ",(0,a.kt)("inlineCode",{parentName:"p"},"traces"),' table selected and I was searching for the phrase "healthcheck". If I had selected ',(0,a.kt)("inlineCode",{parentName:"p"},"requests")," instead, the ",(0,a.kt)("inlineCode",{parentName:"p"},"tables")," array would have contained ",(0,a.kt)("inlineCode",{parentName:"p"},"requests")," instead of ",(0,a.kt)("inlineCode",{parentName:"p"},"traces"),". If I had been searching for a different phrase, the ",(0,a.kt)("inlineCode",{parentName:"p"},"searchPhrase")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"filterWhereClause")," objects would have contained different values."),(0,a.kt)("h2",o({},{id:"reverse-engineering-a-link"}),"Reverse engineering a link"),(0,a.kt)("p",null,"Now that we understand what makes up a URL, we're safe to build our own mechanisms to generate a URL."),(0,a.kt)("h2",o({},{id:"typescript-url-builder"}),"TypeScript URL builder"),(0,a.kt)("p",null,"We'll start by creating the TypeScript version of the URL builder. We'll start by creating a new file called ",(0,a.kt)("inlineCode",{parentName:"p"},"urlBuilder.ts")," and we'll add the following code:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"function makeAzureApplicationInsightsTransactionUrl({\n  applicationInsightsId,\n  endDate,\n  startDate,\n}: {\n  applicationInsightsId: string;\n  startDate: Date;\n  endDate: Date;\n}) {\n  const endDateAsString = endDate.toISOString(); // eg 2022-05-03T14:22:51.180Z\n  const startDateAsString = startDate.toISOString();\n  const durationMs = endDate.getTime() - startDate.getTime();\n  const logsQuery = {\n    tables: [\n      'availabilityResults',\n      'requests',\n      'exceptions',\n      'pageViews',\n      'traces',\n      'customEvents',\n      'dependencies',\n    ],\n    timeContextWhereClause: `| where timestamp > datetime(${startDateAsString}) and timestamp < datetime(\"${endDateAsString}\")`,\n    filterWhereClause: '| order by timestamp desc',\n    originalParams: {\n      eventTypes: [\n        {\n          value: 'availabilityResult',\n          tableName: 'availabilityResults',\n          label: 'Availability',\n        },\n        { value: 'request', tableName: 'requests', label: 'Request' },\n        {\n          value: 'exception',\n          tableName: 'exceptions',\n          label: 'Exception',\n        },\n        {\n          value: 'pageView',\n          tableName: 'pageViews',\n          label: 'Page View',\n        },\n        { value: 'trace', tableName: 'traces', label: 'Trace' },\n        {\n          value: 'customEvent',\n          tableName: 'customEvents',\n          label: 'Custom Event',\n        },\n        {\n          value: 'dependency',\n          tableName: 'dependencies',\n          label: 'Dependency',\n        },\n      ],\n      timeContext: {\n        durationMs: durationMs,\n        endTime: endDateAsString,\n      },\n      filter: [],\n      searchPhrase: {\n        originalPhrase: '',\n        _tokens: [],\n      },\n      sort: 'desc',\n    },\n  };\n\n  const baseUrl = `https://portal.azure.com/#blade/AppInsightsExtension/BladeRedirect/BladeName/searchV1/ResourceId/`;\n  const encodedApplicationInsightsId = encodeURIComponent(\n    applicationInsightsId\n  );\n  const moreRouting = `/BladeInputs/`;\n  const encodedLogsQuery = encodeURIComponent(JSON.stringify(logsQuery));\n  const logsUrl = `${baseUrl}${encodedApplicationInsightsId}${moreRouting}${encodedLogsQuery}`;\n\n  return logsUrl;\n}\n")),(0,a.kt)("p",null,"The above code is a function that takes in an object with the following properties:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"applicationInsightsId")," - the ID of the Application Insights resource"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"startDate")," - the start date of the time range"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"endDate")," - the end date of the time range")),(0,a.kt)("p",null,"You can see that it takes these inputs and uses them to build up a URL made up of the four sections we identified earlier."),(0,a.kt)("p",null,"The URL it generates is the URL that will open the Application Insights logs blade in the Azure portal with the time range selected. This code is not including any kind of search phrase, but it could easily be adjusted to cater for that."),(0,a.kt)("h2",o({},{id:"c-url-builder"}),"C# URL builder"),(0,a.kt)("p",null,"We can do the same thing in C#. It's a bit more verbose than the TypeScript version, but it's still pretty straightforward. We'll create a new file called ",(0,a.kt)("inlineCode",{parentName:"p"},"UrlBuilder.cs")," and add the following code:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System.Collections.Generic;\nusing Newtonsoft.Json;\n\nnamespace AzureApplicationInsightsTransactionSearchUrl\n{\n  public static class UrlBuilder\n  {\n    /// <summary>\n    /// eg 2022-05-03T14:22:51.180Z\n    /// </summary>\n    public static string ToAzureLogsString(this DateTime value) =>\n        value.ToString("yyyy-MM-ddTHH:mm:ss.fffK", CultureInfo.InvariantCulture);\n\n    public static string MakeAzureApplicationInsightsTransactionUrl(\n      string applicationInsightsId,\n      DateTime startDate,\n      DateTime endDate\n    )\n    {\n      var endDateAsString = endDate.ToAzureLogsString();\n      var startDateAsString = startDate.ToAzureLogsString();\n      var durationMs = Convert.ToInt32((endDate - startDate).TotalMilliseconds);\n\n      var logsQuery = new LogsQuery(\n        Tables: new List<string> {\n          "availabilityResults",\n          "requests",\n          "exceptions",\n          "pageViews",\n          "traces",\n          "customEvents",\n          "dependencies"\n        },\n        TimeContextWhereClause: $"| where timestamp > datetime(\\"{startDateAsString}\\") and timestamp < datetime(\\"{endDateAsString}\\")",\n        FilterWhereClause: $"| order by timestamp desc",\n        OriginalParams: new OriginalParams(\n          EventTypes: new List<EventType>\n          {\n            new (\n                Value: "availabilityResult",\n                TableName: "availabilityResults",\n                Label: "Availability"\n            ),\n            new (\n                Value: "request",\n                TableName: "requests",\n                Label: "Request"\n            ),\n            new (\n                Value: "exception",\n                TableName: "exceptions",\n                Label: "Exception"\n            ),\n            new (\n                Value: "pageView",\n                TableName: "pageViews",\n                Label: "Page View"\n            ),\n            new (\n                Value: "trace",\n                TableName: "traces",\n                Label: "Trace"\n            ),\n            new (\n                Value: "customEvent",\n                TableName: "customEvents",\n                Label: "Custom Event"\n            ),\n            new (\n                Value: "dependency",\n                TableName: "dependencies",\n                Label: "Dependency"\n            ),\n          },\n          TimeContext: new TimeContext(\n              DurationMs: durationMs,\n              EndTime: endDateAsString\n          ),\n          Filter: new List<Filter>(),\n          SearchPhrase: new SearchPhrase(\n              OriginalPhrase: "",\n              Tokens: new List<Token>()\n          ),\n          Sort: "desc"\n        )\n      );\n\n      var baseUrl = "https://portal.azure.com/#blade/AppInsightsExtension/BladeRedirect/BladeName/searchV1/ResourceId/";\n      var encodedApplicationInsightsId = WebUtility.UrlEncode(applicationInsightsId);\n      var moreRouting = "/BladeInputs/";\n      var encodedLogsQuery = WebUtility.UrlEncode(JsonConvert.SerializeObject(logsQuery));\n      var logsUrl = $"{baseUrl}{encodedApplicationInsightsId}{moreRouting}{encodedLogsQuery}";\n\n      return logsUrl;\n    }\n  }\n\n  public record EventType(\n      [property: JsonProperty("value")] string Value,\n      [property: JsonProperty("tableName")] string TableName,\n      [property: JsonProperty("label")] string Label\n  );\n\n  public record TimeContext(\n      [property: JsonProperty("durationMs")] int DurationMs,\n      [property: JsonProperty("endTime")] string EndTime\n  );\n\n  public record Dimension(\n      [property: JsonProperty("displayName")] string DisplayName,\n      [property: JsonProperty("tables")] IReadOnlyList<string> Tables,\n      [property: JsonProperty("name")] string Name,\n      [property: JsonProperty("draftKey")] string DraftKey\n  );\n\n  public record Operator(\n      [property: JsonProperty("label")] string Label,\n      [property: JsonProperty("value")] string Value,\n      [property: JsonProperty("isSelected")] bool IsSelected\n  );\n\n  public record Filter(\n      [property: JsonProperty("dimension")] Dimension Dimension,\n      [property: JsonProperty("values")] IReadOnlyList<string> Values,\n      [property: JsonProperty("operator")] Operator Operator\n  );\n\n  public record Token(\n      [property: JsonProperty("conjunction")] string Conjunction,\n      [property: JsonProperty("value")] string Value,\n      [property: JsonProperty("isNot")] bool IsNot,\n      [property: JsonProperty("kql")] string Kql\n  );\n\n  public record SearchPhrase(\n      [property: JsonProperty("originalPhrase")] string OriginalPhrase,\n      [property: JsonProperty("_tokens")] IReadOnlyList<Token> Tokens\n  );\n\n  public record OriginalParams(\n      [property: JsonProperty("eventTypes")] IReadOnlyList<EventType> EventTypes,\n      [property: JsonProperty("timeContext")] TimeContext TimeContext,\n      [property: JsonProperty("filter")] IReadOnlyList<Filter> Filter,\n      [property: JsonProperty("searchPhrase")] SearchPhrase SearchPhrase,\n      [property: JsonProperty("sort")] string Sort\n  );\n\n  public record LogsQuery(\n      [property: JsonProperty("tables")] IReadOnlyList<string> Tables,\n      [property: JsonProperty("timeContextWhereClause")] string TimeContextWhereClause,\n      [property: JsonProperty("filterWhereClause")] string FilterWhereClause,\n      [property: JsonProperty("originalParams")] OriginalParams OriginalParams\n  );\n}\n')),(0,a.kt)("p",null,"Note that most of the verbosity comes from the fact that we're using C# 9 record types to represent the JSON objects that we're serializing. If you're not familiar with C# 9 ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docs.microsoft.com/en-us/dotnet/csharp/whats-new/csharp-9#record-types"}),"record types"),". We're also using JSON.Net for our serialization, but you could use System.Text.Json if you wanted to. You would need to amend the ",(0,a.kt)("inlineCode",{parentName:"p"},"JsonProperty")," attributes to be ",(0,a.kt)("inlineCode",{parentName:"p"},"JsonPropertyName")," attributes instead."),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"In this post we've understood what goes into the URL for Application Insights Transactions, and we've seen how to generate that URL in TypeScript and C#. We've also seen how to use the URL to search for transactions in Application Insights. I hope you found this post useful. Thanks for reading!"))}d.isMDXComponent=!0},52566:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"react-usesearchparamsstate",title:"React: storing state in URL with URLSearchParams",authors:"johnnyreilly",tags:["React","typescript","React Router"],description:"The React `useState` hook is a great way to persist state. This post demos a simple React hook that stores state in the URL querystring.",hide_table_of_contents:!1},s=void 0,l={permalink:"/react-usesearchparamsstate",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-09-20-react-usesearchparamsstate/index.md",source:"@site/blog/2022-09-20-react-usesearchparamsstate/index.md",title:"React: storing state in URL with URLSearchParams",description:"The React `useState` hook is a great way to persist state. This post demos a simple React hook that stores state in the URL querystring.",date:"2022-09-20T00:00:00.000Z",formattedDate:"September 20, 2022",tags:[{label:"React",permalink:"/tags/react"},{label:"typescript",permalink:"/tags/typescript"},{label:"React Router",permalink:"/tags/react-router"}],readingTime:6.68,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"react-usesearchparamsstate",title:"React: storing state in URL with URLSearchParams",authors:"johnnyreilly",tags:["React","typescript","React Router"],description:"The React `useState` hook is a great way to persist state. This post demos a simple React hook that stores state in the URL querystring.",hide_table_of_contents:!1},prevItem:{title:"Faster Docusaurus builds with swc-loader",permalink:"/faster-docusaurus-build-swc-loader"},nextItem:{title:"Reverse engineering the Azure Application Insights Transactions URL",permalink:"/reverse-engineering-azure-app-insights-transactions-url"}},p={authorsImageUrls:[void 0]},u=[{value:"<code>useState</code>",id:"usestate",level:2},{value:"A stateful URL",id:"a-stateful-url",level:2},{value:"<code>useSearchParams</code>",id:"usesearchparams",level:2},{value:"The <code>useSearchParamsState</code> hook",id:"the-usesearchparamsstate-hook",level:2},{value:"Performance - updated 18th December 2022",id:"performance---updated-18th-december-2022",level:2},{value:"Persisting querystring across your site",id:"persisting-querystring-across-your-site",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The React ",(0,a.kt)("a",o({parentName:"p"},{href:"https://reactjs.org/docs/hooks-reference.html#usestate"}),(0,a.kt)("inlineCode",{parentName:"a"},"useState"))," hook is a great way to persist state inside the context of a component in React. This post demonstrates a simple React hook that stores state in the URL querystring, building on top of React Routers ",(0,a.kt)("inlineCode",{parentName:"p"},"useSearchParams")," hook."),(0,a.kt)("h2",o({},{id:"usestate"}),(0,a.kt)("inlineCode",{parentName:"h2"},"useState")),(0,a.kt)("p",null,"Usage of the ",(0,a.kt)("inlineCode",{parentName:"p"},"useState")," hook looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const [greeting, setGreeting] = useState('hello world');\n\n// ....\n\nsetGreeting('hello John'); // will set greeting to 'hello John'\n")),(0,a.kt)("p",null,"However, there is a disadvantage to using ",(0,a.kt)("inlineCode",{parentName:"p"},"useState"),"; that state is not persistent and not shareable. So if you want someone else to see what you can see in an application, you're reliant on them carrying out the same actions that got your application into its current state. Doing that can be time consuming and error prone. Wouldn't it be great if there was a simple way to share state?"),(0,a.kt)("h2",o({},{id:"a-stateful-url"}),"A stateful URL"),(0,a.kt)("p",null,"An effective way to share state between users, without needing a backend for persistence, is with the URL. A URL can contain the required state in the form of the route and the querystring / search parameters. The search parameters are particularly powerful as they are entirely generic and customisable."),(0,a.kt)("p",null,"Thanks to the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/API/URLSearchParams"}),"URLSearchParams API"),", it's possible to manipulate the querystring ",(0,a.kt)("em",{parentName:"p"},"without")," round-tripping to the server. This is a primitive upon which we can build; as long as the URL limit (around ",(0,a.kt)("a",o({parentName:"p"},{href:"https://stackoverflow.com/a/417184/761388"}),"2000 chars"),") is not exceeded, we're free to persist state in your URL. Consider:"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://our-app.com?greeting=hi"}),"https://our-app.com?greeting=hi")),(0,a.kt)("p",null,"The URL above is storing a single piece of state; the ",(0,a.kt)("inlineCode",{parentName:"p"},"greeting"),". Consider:"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://our-app.com?greeting=hi&name=john"}),"https://our-app.com?greeting=hi&name=john")),(0,a.kt)("p",null,"The URL above is going further and storing multiple pieces of state; the ",(0,a.kt)("inlineCode",{parentName:"p"},"greeting")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"name"),"."),(0,a.kt)("h2",o({},{id:"usesearchparams"}),(0,a.kt)("inlineCode",{parentName:"h2"},"useSearchParams")),(0,a.kt)("p",null,"If you're working with React, the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://reactrouter.com/"}),"React Router")," project makes consuming state in the URL, particularly in the form of querystring or search parameters, straightforward. It achieves this with the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://reactrouter.com/docs/en/v6/hooks/use-search-params"}),(0,a.kt)("inlineCode",{parentName:"a"},"useSearchParams"))," hook:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { useSearchParams } from 'react-router-dom';\n\nconst [searchParams, setSearchParams] = useSearchParams();\n\nconst greeting = searchParams.get('greeting');\n\n// ...\n\nsetSearchParams({ greeting: 'bonjour' }); // will set URL like so https://our-app.com?greeting=bonjour - this value will feed through to anything driven by the URL\n")),(0,a.kt)("p",null,"This is a great mechanism for persisting state both locally and in a shareable way."),(0,a.kt)("p",null,"A significant benefit of this approach is that it doesn't require posting to the server. It's just using browser APIs like the URLSearchParams API. Changing a query string parameter happens entirely locally and instantaneously."),(0,a.kt)("h2",o({},{id:"the-usesearchparamsstate-hook"}),"The ",(0,a.kt)("inlineCode",{parentName:"h2"},"useSearchParamsState")," hook"),(0,a.kt)("p",null,"What the ",(0,a.kt)("inlineCode",{parentName:"p"},"useSearchParams")," hook doesn't do, is maintain other query string or search parameters."),(0,a.kt)("p",null,"If you are maintaining multiple pieces of state in your application, that will likely mean multiple query string or search parameters. What would be quite useful, is a hook which allows us the update state ",(0,a.kt)("em",{parentName:"p"},"without")," losing other state. Furthermore, it would be great if we didn't have to first acquire the ",(0,a.kt)("inlineCode",{parentName:"p"},"searchParams")," object and then manipulate it. It's time for our ",(0,a.kt)("inlineCode",{parentName:"p"},"useSearchParamsState")," hook:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { useSearchParams } from 'react-router-dom';\n\nexport function useSearchParamsState(\n  searchParamName: string,\n  defaultValue: string\n): readonly [\n  searchParamsState: string,\n  setSearchParamsState: (newState: string) => void\n] {\n  const [searchParams, setSearchParams] = useSearchParams();\n\n  const acquiredSearchParam = searchParams.get(searchParamName);\n  const searchParamsState = acquiredSearchParam ?? defaultValue;\n\n  const setSearchParamsState = (newState: string) => {\n    const next = Object.assign(\n      {},\n      [...searchParams.entries()].reduce(\n        (o, [key, value]) => ({ ...o, [key]: value }),\n        {}\n      ),\n      { [searchParamName]: newState }\n    );\n    setSearchParams(next);\n  };\n  return [searchParamsState, setSearchParamsState];\n}\n")),(0,a.kt)("p",null,"The above hook can roughly be thought of as ",(0,a.kt)("inlineCode",{parentName:"p"},"useState<string>")," but storing that state in the URL."),(0,a.kt)("p",null,"Let's think about how it works. When initialised, the hook takes two parameters:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"searchParamName")," - this is the name of the querystring parameter where state is persisted."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"defaultValue")," - if there is no value in the querystring, this is the fallback value")),(0,a.kt)("p",null,"The hook then goes on to wrap the ",(0,a.kt)("inlineCode",{parentName:"p"},"useSearchParams")," hook. It interrogates the ",(0,a.kt)("inlineCode",{parentName:"p"},"searchParams")," for the supplied ",(0,a.kt)("inlineCode",{parentName:"p"},"searchParamName"),", and if it isn't present, falls back to the ",(0,a.kt)("inlineCode",{parentName:"p"},"defaultValue"),"."),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"setSearchParamsState")," method definition looks somewhat complicated but essentially all it does is get the contents of the existing search parameters, and applies the new state for the current property. It's probably worth pausing here a second to observe an opinion that's lurking in this implementation. It is actually valid to have multiple values for the same search parameter. Whilst this is possible, it's somewhat rare for this to be used. This implementation only allows for a single value for any given parameter, as that is quite useful behaviour."),(0,a.kt)("p",null,"With all this in place, we have a hook that can be used like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const [greeting, setGreeting] = useSearchParamsState('greeting', 'hello');\n")),(0,a.kt)("p",null,"The above code returns back a ",(0,a.kt)("inlineCode",{parentName:"p"},"greeting")," value which is derived from the ",(0,a.kt)("inlineCode",{parentName:"p"},"greeting")," search parameter. It also returns a ",(0,a.kt)("inlineCode",{parentName:"p"},"setGreeting")," function which allows setting the ",(0,a.kt)("inlineCode",{parentName:"p"},"greeting")," value. This is the same API as ",(0,a.kt)("inlineCode",{parentName:"p"},"useState")," and so should feel idiomatic to a user of React. Tremendous!"),(0,a.kt)("h2",o({},{id:"performance---updated-18th-december-2022"}),"Performance - updated 18th December 2022"),(0,a.kt)("p",null,'At this point you might be thinking "why don\u2019t we use the ',(0,a.kt)("inlineCode",{parentName:"p"},"useSearchParamsState"),' hook always?". The fact of the matter is, you could but there\u2019s a reason why you might not want to: performance. The ',(0,a.kt)("inlineCode",{parentName:"p"},"useSearchParamsState")," hook is slower to use than the ",(0,a.kt)("inlineCode",{parentName:"p"},"useState")," hook. Let's think about why."),(0,a.kt)("p",null,"If you\u2019re using the ",(0,a.kt)("inlineCode",{parentName:"p"},"useState")," hook, then ultimately a variable is being updated inside the program that represents your application. This is internal state. However, for the ",(0,a.kt)("inlineCode",{parentName:"p"},"useSearchParamsState")," hook the story is slightly different. The ",(0,a.kt)("inlineCode",{parentName:"p"},"useSearchParamsState")," hook is built upon the ",(0,a.kt)("inlineCode",{parentName:"p"},"useSearchParams")," hook in react-router, as we\u2019ve seen. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/remix-run/react-router/blob/590b7a25a454d998c83f4e5d6f00ad5a6217533b/packages/react-router-dom/index.tsx#L785"}),"If you look at the implementation of that hook"),", you can see that it relies on various browser APIs such as ",(0,a.kt)("inlineCode",{parentName:"p"},"location")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"History"),"."),(0,a.kt)("p",null,"The upshot of this is that the state for our ",(0,a.kt)("inlineCode",{parentName:"p"},"useSearchParamsState")," hook is ",(0,a.kt)("inlineCode",{parentName:"p"},"external")," to our application. It might not feel external because we haven't had to set up a database or an API or anything, but external it is. State lives in the browsers APIs, and with that comes a performance penalty. Every time we change state the following happens:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"The ",(0,a.kt)("inlineCode",{parentName:"li"},"useSearchParams")," hook in react-router will invoke the ",(0,a.kt)("inlineCode",{parentName:"li"},"History")," API"),(0,a.kt)("li",{parentName:"ul"},"The browser will update the URL"),(0,a.kt)("li",{parentName:"ul"},"The instance of react-router running at the root of your application will detect changes in the ",(0,a.kt)("inlineCode",{parentName:"li"},"location.search")," and will surface a new value for your application."),(0,a.kt)("li",{parentName:"ul"},"The code in your application that depends upon this will react.")),(0,a.kt)("p",null,"The above is slower than just invoking ",(0,a.kt)("inlineCode",{parentName:"p"},"useState")," and relying upon a local variable. It\u2019s not overwhelmingly slower; generally I\u2019ve not had an issue because browsers are very fast these days. But it\u2019s worth bearing in mind, that if you\u2019re intending to write code that is as performant as possible, then this is probably a hook to avoid. Anything that involves an external API, even if it\u2019s an API that lives in the browser, will be slower than local variables. That said, I would expect there to be few applications to which this is a significant factor - but it\u2019s worth considering."),(0,a.kt)("h2",o({},{id:"persisting-querystring-across-your-site"}),"Persisting querystring across your site"),(0,a.kt)("p",null,"Now we have this exciting mechanism set up which allows us to store state in our URL and consequently easily share state by sending someone our URL."),(0,a.kt)("p",null,"What would also be useful is a way to navigate around our site ",(0,a.kt)("em",{parentName:"p"},"without")," losing that state. Imagine I've got a date range selected and stored in my URL. As I click around from screen to screen, I want to persist that. I don't want to have to reselect the date range on each screen."),(0,a.kt)("p",null,"How can we do this? Well, it turns out to be quite easy. All we need is the ",(0,a.kt)("inlineCode",{parentName:"p"},"useLocation")," hook and the corresponding ",(0,a.kt)("inlineCode",{parentName:"p"},"location.search")," property. That represents the querystring, hence every time we render a link we just include that like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const [location] = useLocation();\n\nreturn (<Link to={`/my-page${location.search}`}>Page</>)\n")),(0,a.kt)("p",null,"Now as we navigate around our site, that state will be maintained."),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"In this post we've created a ",(0,a.kt)("inlineCode",{parentName:"p"},"useSearchParamsState")," hook, which allows state to be persisted to URLs for sharing purposes."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/use-state-url-persist-state-usesearchparams/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/use-state-url-persist-state-usesearchparams/"})))}d.isMDXComponent=!0},35468:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"faster-docusaurus-build-swc-loader",title:"Faster Docusaurus builds with swc-loader",authors:"johnnyreilly",tags:["Docusaurus","webpack"],image:"./title-image.png",description:"This post demonstrates how to speed up your Docusaurus build by using SWC and the `swc-loader` for webpack.",hide_table_of_contents:!1},s=void 0,l={permalink:"/faster-docusaurus-build-swc-loader",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-09-29-faster-docusaurus-build-swc-loader/index.md",source:"@site/blog/2022-09-29-faster-docusaurus-build-swc-loader/index.md",title:"Faster Docusaurus builds with swc-loader",description:"This post demonstrates how to speed up your Docusaurus build by using SWC and the `swc-loader` for webpack.",date:"2022-09-29T00:00:00.000Z",formattedDate:"September 29, 2022",tags:[{label:"Docusaurus",permalink:"/tags/docusaurus"},{label:"webpack",permalink:"/tags/webpack"}],readingTime:2.215,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"faster-docusaurus-build-swc-loader",title:"Faster Docusaurus builds with swc-loader",authors:"johnnyreilly",tags:["Docusaurus","webpack"],image:"./title-image.png",description:"This post demonstrates how to speed up your Docusaurus build by using SWC and the `swc-loader` for webpack.",hide_table_of_contents:!1},prevItem:{title:"TypeScript Unit Tests with Debug Support",permalink:"/typescript-unit-tests-with-debug-support"},nextItem:{title:"React: storing state in URL with URLSearchParams",permalink:"/react-usesearchparamsstate"}},p={image:n(91690).Z,authorsImageUrls:[void 0]},u=[{value:"SWC",id:"swc",level:2},{value:"Goodbye <code>babel-loader</code>, hello <code>swc-loader</code>",id:"goodbye-babel-loader-hello-swc-loader",level:2},{value:"Build times",id:"build-times",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This post demonstrates how to speed up your Docusaurus build by using SWC and the ",(0,a.kt)("inlineCode",{parentName:"p"},"swc-loader")," for webpack."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Faster Docusaurus builds with swc-loader&quot; with Docusaurus, SWC and webpack logos",src:n(91690).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"swc"}),"SWC"),(0,a.kt)("p",null,"At present there's a number of projects which have been providing alternate transpilation mechanisms to transform TypeScript / modern JavaScript into JavaScript that will run widely supported browsers. Historically this has been handled by tools like the TypeScript compiler itself and Babel. Both of these tools are written in TypeScript / JavaScript. The new tools and projects which have been appearing often use languages like Go and Rust which offer the gift of performance gains. Shorter build times in other words."),(0,a.kt)("p",null,"We're going to make use of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://swc.rs/"}),"SWC (Speedy Web Compiler)")," to speed up the Docusaurus build. To quote the SWC docs:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"SWC can be used for both compilation and bundling. For compilation, it takes JavaScript / TypeScript files using modern JavaScript features and outputs valid code that is supported by all major browsers."),(0,a.kt)("p",{parentName:"blockquote"},"\ud83c\udfce SWC is 20x faster than Babel on a single thread and 70x faster on four cores.")),(0,a.kt)("p",null,"We like faster! Interestingly, the Docusaurus site itself is built with SWC and has been since 19th March 2022. You can see ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/SidaChen63"}),"Josh Cena"),"'s ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/pull/6944"}),"PR implementing SWC for Docusaurus here"),"."),(0,a.kt)("p",null,"However, by default, Docusaurus is built using Babel. This post will demonstrate how to make the switch. In fact as part of the PR that implements this post, this blog (also platformed on Docusaurus) will migrate from Babel to SWC. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/pull/288"}),"See the blog post PR here"),"."),(0,a.kt)("h2",o({},{id:"goodbye-babel-loader-hello-swc-loader"}),"Goodbye ",(0,a.kt)("inlineCode",{parentName:"h2"},"babel-loader"),", hello ",(0,a.kt)("inlineCode",{parentName:"h2"},"swc-loader")),(0,a.kt)("p",null,"Docusaurus is bundled using webpack. As a consequence, we need a tool to bridge the gap between webpack and SWC. That tool is the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/swc-project/swc-loader"}),(0,a.kt)("inlineCode",{parentName:"a"},"swc-loader")),"."),(0,a.kt)("p",null,"By default, the Docusaurus build uses Babel for its build. Let's add ",(0,a.kt)("inlineCode",{parentName:"p"},"swc-loader")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"@swc/core")," to the project:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"yarn add @swc/core swc-loader\n")),(0,a.kt)("p",null,"With those in place, we're now able to tweak our the webpack config in ",(0,a.kt)("inlineCode",{parentName:"p"},"docusaurus.config.js")," to use ",(0,a.kt)("inlineCode",{parentName:"p"},"swc-loader")," instead of ",(0,a.kt)("inlineCode",{parentName:"p"},"babel-loader"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const config = {\n  // ....\n\n  webpack: {\n    jsLoader: (isServer) => ({\n      loader: require.resolve('swc-loader'),\n      options: {\n        jsc: {\n          parser: {\n            syntax: 'typescript',\n            tsx: true,\n          },\n          target: 'es2017',\n        },\n        module: {\n          type: isServer ? 'commonjs' : 'es6',\n        },\n      },\n    }),\n  },\n\n  // ....\n};\n")),(0,a.kt)("h2",o({},{id:"build-times"}),"Build times"),(0,a.kt)("p",null,"With this in place, we're done. We can now run ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn build")," and see the difference in build times. On GitHub actions (where I build my blog), the build time for the blog site went from around 6 minutes to around 4 minutes. It's somewhat variable, but there's a definite improvement, and every little helps!"))}d.isMDXComponent=!0},26917:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"typescript-unit-tests-with-debug-support",title:"TypeScript Unit Tests with Debug Support",authors:"johnnyreilly",tags:["typescript","Unit Tests","Debug"],image:"./title-image.png",description:"Unit tests are an important part of the development process. This post will outline how to write unit tests using TypeScript and how to debug them as well.",hide_table_of_contents:!1},s=void 0,l={permalink:"/typescript-unit-tests-with-debug-support",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-10-01-typescript-unit-tests-with-debug-support/index.md",source:"@site/blog/2022-10-01-typescript-unit-tests-with-debug-support/index.md",title:"TypeScript Unit Tests with Debug Support",description:"Unit tests are an important part of the development process. This post will outline how to write unit tests using TypeScript and how to debug them as well.",date:"2022-10-01T00:00:00.000Z",formattedDate:"October 1, 2022",tags:[{label:"typescript",permalink:"/tags/typescript"},{label:"Unit Tests",permalink:"/tags/unit-tests"},{label:"Debug",permalink:"/tags/debug"}],readingTime:6.34,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"typescript-unit-tests-with-debug-support",title:"TypeScript Unit Tests with Debug Support",authors:"johnnyreilly",tags:["typescript","Unit Tests","Debug"],image:"./title-image.png",description:"Unit tests are an important part of the development process. This post will outline how to write unit tests using TypeScript and how to debug them as well.",hide_table_of_contents:!1},prevItem:{title:"Bicep: Static Web Apps and Linked Backends",permalink:"/bicep-static-web-apps-linked-backends"},nextItem:{title:"Faster Docusaurus builds with swc-loader",permalink:"/faster-docusaurus-build-swc-loader"}},p={image:n(41427).Z,authorsImageUrls:[void 0]},u=[{value:"Unit Tests",id:"unit-tests",level:2},{value:"Setting up our TypeScript project",id:"setting-up-our-typescript-project",level:2},{value:"Setting up the Jest project",id:"setting-up-the-jest-project",level:2},{value:"Set up debugging support",id:"set-up-debugging-support",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://meticulous.ai/blog/typescript-unit-tests-with-debugging/"})),(0,a.kt)("p",null,"Unit tests are an important part of the development process. They are used to verify that the code is working as intended. This post will outline how to write unit tests using TypeScript and how to debug them as well."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;TypeScript Unit Tests with Debug Support&quot; with TypeScript and Jest logos",src:n(41427).Z,width:"1600",height:"900"})),(0,a.kt)("h2",o({},{id:"unit-tests"}),"Unit Tests"),(0,a.kt)("p",null,"When we are writing unit tests to verify system behaviour, we have to make choices. We need to choose the test framework that we'll use to run our tests. In the JavaScript world we'll be choosing from options including Jest, Mocha, tape, Jasmine and others. There are numerous other testing tools like Cypress and Playwright which cover broader automated testing needs, but we're intentionally just thinking about unit tests right now and so we'll exclude those."),(0,a.kt)("p",null,"Of the various choices available, Jest is (at time of writing) very much the most popular. Since we have do not have a particular reason for favouring one of the frameworks that isn't as popular as Jest, that's what we'll use."),(0,a.kt)("p",null,"Tests are a wonderful tool for asserting system behaviour. However, they can fail for mysterious reasons. When that happens, it can be helpful to see what the computer can see. It can be helpful to be able to debug your tests in the way you might hope to debug your other code."),(0,a.kt)("p",null,"In this post:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"We'll set up a TypeScript Node.js project, containing some code we'd like to test."),(0,a.kt)("li",{parentName:"ol"},"We'll configure our project to work with Jest and we'll write a test."),(0,a.kt)("li",{parentName:"ol"},"We'll debug our unit test.")),(0,a.kt)("p",null,"Let's begin."),(0,a.kt)("h2",o({},{id:"setting-up-our-typescript-project"}),"Setting up our TypeScript project"),(0,a.kt)("p",null,"First we'll create ourselves a new Node.js project:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"mkdir typescript-unit-tests-with-debug-support\ncd typescript-unit-tests-with-debug-support\nnpm init --yes\n")),(0,a.kt)("p",null,"At this point we have an empty Node.js project. Let's add TypeScript to it as a dependency and initialise our TypeScript project:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"npm install typescript\nnpx -p typescript tsc --init\n")),(0,a.kt)("p",null,"We now have a fully working TypeScript Node.js project and we're ready to start writing some code!"),(0,a.kt)("p",null,"This is a post about demonstrating unit testing with TypeScript. So naturally we need something to test. We're going write a simple module called ",(0,a.kt)("inlineCode",{parentName:"p"},"greeter.ts")," which has the following content:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export function makeGreeting(name: string): string {\n  const lengthOfName = name.length;\n  const greeting = `Well hello there ${name}, I see your name is ${lengthOfName} characters long!`;\n  return greeting;\n}\n")),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"greeter.ts")," is a TypeScript file that contains a single simple function. The ",(0,a.kt)("inlineCode",{parentName:"p"},"makeGreeting")," function takes a string parameter and, over a number of lines, constructs a greeting string which the function returns. The nature of the greeting is inconsequential. However, remember later we want to be able to debug our test. We've intentionally written a function featuring more than one line of code. We've done this so we can demonstrate the benefits of debugging by showing the program state as it is in the process of executing."),(0,a.kt)("h2",o({},{id:"setting-up-the-jest-project"}),"Setting up the Jest project"),(0,a.kt)("p",null,"The next step after setting up our TypeScript Node.js project, is adding tests, and the ability to run them, using Jest."),(0,a.kt)("p",null,"First of all we're going to need to add Jest to our project and initially configure it:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"npm install --save-dev jest\nnpx jest --init\n")),(0,a.kt)("p",null,"As part of the initialisation you should be prompted with a number of questions:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{}),"npx jest --init\n\nThe following questions will help Jest to create a suitable configuration for your project\n\n\u2714 Would you like to use Typescript for the configuration file? \u2026 no\n\u2714 Choose the test environment that will be used for testing \u203a node\n\u2714 Do you want Jest to add coverage reports? \u2026 no\n\u2714 Which provider should be used to instrument code for coverage? \u203a v8\n\u2714 Automatically clear mock calls, instances, contexts and results before every test? \u2026 no\n")),(0,a.kt)("p",null,"We'll select all the defaults; including ",(0,a.kt)("em",{parentName:"p"},"not")," using TypeScript for the configuration file. We don't require a configuration file written in TypeScript to be able to write TypeScript tests. The initialisation will create a ",(0,a.kt)("inlineCode",{parentName:"p"},"jest.config.js")," file which contains the configuration used to run our tests."),(0,a.kt)("p",null,"Next, we'll update the ",(0,a.kt)("inlineCode",{parentName:"p"},"scripts")," section of our ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," to invoke Jest:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'  "scripts": {\n    "test": "jest"\n  },\n')),(0,a.kt)("p",null,"At this point we're in a place where we can run tests written in JavaScript. But we want to run tests written in TypeScript. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://jestjs.io/docs/getting-started#using-typescript"}),"Jest supports this scenario well"),", using Babel. So we'll add the dependencies we need:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"npm install --save-dev babel-jest @babel/core @babel/preset-env @babel/preset-typescript @types/jest\n")),(0,a.kt)("p",null,"With all that done, let's see if we can write a test. We'll create a ",(0,a.kt)("inlineCode",{parentName:"p"},"greeter.test.ts")," file to sit alongside ",(0,a.kt)("inlineCode",{parentName:"p"},"greeter.ts"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { makeGreeting } from './greeter';\n\ntest('given a name produces the expected greeting', () => {\n  expect(makeGreeting('George')).toBe(\n    'Well hello there George, I see your name is 6 characters long!'\n  );\n});\n")),(0,a.kt)("p",null,"This simple test, invokes the ",(0,a.kt)("inlineCode",{parentName:"p"},"makeGreeting")," function in our ",(0,a.kt)("inlineCode",{parentName:"p"},"greeter.ts")," file and asserts the return value is as expected. Let us see if we can run our test with ",(0,a.kt)("inlineCode",{parentName:"p"},"npm run test"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of tests running and passing in the terminal",src:n(83914).Z,width:"866",height:"370"})),(0,a.kt)("p",null,"Success! We've now created a TypeScript project, written a function, written a test for that function and we have the ability to run it."),(0,a.kt)("h2",o({},{id:"set-up-debugging-support"}),"Set up debugging support"),(0,a.kt)("p",null,"The final thing we wanted to tackle was adding debug support. In times past, this was often quite tricky to configure. However, debugging has become much easier due to the excellent ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/jest-community/vscode-jest"}),(0,a.kt)("inlineCode",{parentName:"a"},"vscode-jest")),' project, which is dedicated to making "testing more intuitive and fun". In fact, with this extension the experience is now very "plug and play" which is a great thing.'),(0,a.kt)("p",null,"Inside VS Code, we will install the vscode-jest extension:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the VS Code Jest extension",src:n(58584).Z,width:"906",height:"352"})),(0,a.kt)("p",null,"Once it's installed, we'll need to restart VS Code, and we may also need to enter the ",(0,a.kt)("inlineCode",{parentName:"p"},"Jest: Start All Runners")," command in VS Codes power bar:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the Jest: Start All Runners command in VS Code",src:n(45740).Z,width:"1192",height:"350"})),(0,a.kt)("p",null,"Once the Jest runners have started, we start to see the benefits that the VS Code Jest plugin offers. Where tests exist in our code, they are detected by the plugin and run. Depending upon whether tests are passing or failing we will be presented with a red cross or a green tick denoting failure or success directly alongside the code:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the jest test explorer with a green tick next to a passing test",src:n(61886).Z,width:"2140",height:"406"})),(0,a.kt)("p",null,"Using the test explorer, it's possible to run tests on demand. Even more excitingly, it's now possible to debug them too. If you examine the test explorer and right / command click on a given test, you'll be presented with the option to debug a test:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the context menu in the Jest explorer featuring the words &quot;Debug Test&quot;",src:n(89574).Z,width:"2140",height:"480"})),(0,a.kt)("p",null,"Excitingly this means exactly what we might hope. If we put breakpoints in our code, when the test runs we'll now hit them. We'll be able to debug and introspect each test that runs:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of a test being debugged",src:n(14522).Z,width:"2480",height:"480"})),(0,a.kt)("p",null,"If you look at the screenshot above you'll see we've stopped on a breakpoint, we're able to examine the context of the program at the point that it has paused. We can step further on in our code, we can do all the useful things that debugging affords us. We have succeeded in debugging."),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"In this piece we've taken a look at how to get up and running with a unit testable TypeScript project. Beyond that, we've demonstrated how we can debug our TypeScript tests using the VS Code editor."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://meticulous.ai/blog/typescript-unit-tests-with-debugging/"}),"This post was originally published on Meticulous.")))}d.isMDXComponent=!0},60533:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"bicep-static-web-apps-linked-backends",title:"Bicep: Static Web Apps and Linked Backends",authors:"johnnyreilly",tags:["Bicep","Azure","Static Web Apps","Linked Backends"],image:"./title-image.png",description:"Azure Static Web Apps can be linked to Azure Functions, Azure Container Apps etc to provide the linked backend for a site. This post provisions with Bicep.",hide_table_of_contents:!1},s=void 0,l={permalink:"/bicep-static-web-apps-linked-backends",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-10-14-bicep-static-web-apps-linked-backends/index.md",source:"@site/blog/2022-10-14-bicep-static-web-apps-linked-backends/index.md",title:"Bicep: Static Web Apps and Linked Backends",description:"Azure Static Web Apps can be linked to Azure Functions, Azure Container Apps etc to provide the linked backend for a site. This post provisions with Bicep.",date:"2022-10-14T00:00:00.000Z",formattedDate:"October 14, 2022",tags:[{label:"Bicep",permalink:"/tags/bicep"},{label:"Azure",permalink:"/tags/azure"},{label:"Static Web Apps",permalink:"/tags/static-web-apps"},{label:"Linked Backends",permalink:"/tags/linked-backends"}],readingTime:3.14,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"bicep-static-web-apps-linked-backends",title:"Bicep: Static Web Apps and Linked Backends",authors:"johnnyreilly",tags:["Bicep","Azure","Static Web Apps","Linked Backends"],image:"./title-image.png",description:"Azure Static Web Apps can be linked to Azure Functions, Azure Container Apps etc to provide the linked backend for a site. This post provisions with Bicep.",hide_table_of_contents:!1},prevItem:{title:"Getting started with the Web Monetization API",permalink:"/web-monetization-api"},nextItem:{title:"TypeScript Unit Tests with Debug Support",permalink:"/typescript-unit-tests-with-debug-support"}},p={image:n(70037).Z,authorsImageUrls:[void 0]},u=[{value:"Introduction",id:"introduction",level:2},{value:"The Function App Bicep",id:"the-function-app-bicep",level:2},{value:"The Static Web App Bicep",id:"the-static-web-app-bicep",level:2},{value:"The Deployment",id:"the-deployment",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Azure Static Web Apps can be linked to Azure Functions, Azure Container Apps etc to provide the linked backend for a site. This post will demonstrate how to do this with Bicep."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Bicep: Static Web Apps and Linked Backends&quot; with Bicep and Static Web App logos",src:n(70037).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"introduction"}),"Introduction"),(0,a.kt)("p",null,'Azure Static Web Apps ship with their own slightly restricted Azure Functions backend; it does not have all of the triggers of the standard offering. If you should need that wider featureset, you can link to an existing Azure Functions instance instead. This is known as the "bring your own functions" approach and is ',(0,a.kt)("a",o({parentName:"p"},{href:"https://learn.microsoft.com/en-us/azure/static-web-apps/functions-bring-your-own"}),"documented here"),". The back end doesn't have to be Azure Functions; it could be Azure Container Apps also. This post will demonstrate how to do this with Azure Functions and with Bicep."),(0,a.kt)("h2",o({},{id:"the-function-app-bicep"}),"The Function App Bicep"),(0,a.kt)("p",null,"You're going to need to create an Azure Function in your Bicep template. We'll do this here with a Bicep module called ",(0,a.kt)("inlineCode",{parentName:"p"},"function.bicep"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param functionAppName string\nparam location string\nparam hostingPlanName string\nparam storageAccountName string\nparam tags object\n\nresource functionApp 'Microsoft.Web/sites@2022-03-01' = {\n  name: functionAppName\n  kind: 'functionapp,linux'\n  location: location\n  tags: tags\n  properties: {\n    siteConfig: {\n      appSettings: [\n        {\n          name: 'FUNCTIONS_EXTENSION_VERSION'\n          value: '~4'\n        }\n        {\n          name: 'FUNCTIONS_WORKER_RUNTIME'\n          value: 'node'\n        }\n        {\n          name: 'AzureWebJobsStorage'\n          value: 'DefaultEndpointsProtocol=https;AccountName=${storageAccount.name};EndpointSuffix=${environment().suffixes.storage};AccountKey=${storageAccount.listKeys().keys[0].value}'\n        }\n        {\n          name: 'WEBSITE_CONTENTAZUREFILECONNECTIONSTRING'\n          value: 'DefaultEndpointsProtocol=https;AccountName=${storageAccount.name};EndpointSuffix=${environment().suffixes.storage};AccountKey=${storageAccount.listKeys().keys[0].value}'\n        }\n        {\n          name: 'WEBSITE_CONTENTSHARE'\n          value: '${toLower(functionAppName)}a6e3'\n        }\n      ]\n      cors: {\n        allowedOrigins: [\n          'https://portal.azure.com'\n        ]\n      }\n      use32BitWorkerProcess: false\n      ftpsState: 'FtpsOnly'\n      linuxFxVersion: 'Node|16'\n    }\n    serverFarmId: serverFarm.id\n    clientAffinityEnabled: false\n    httpsOnly: true\n  }\n}\n\nresource serverFarm 'Microsoft.Web/serverfarms@2022-03-01' = {\n  name: hostingPlanName\n  location: location\n  kind: 'linux'\n  tags: {}\n  properties: {\n    reserved: true\n  }\n  sku: {\n    tier: 'Dynamic'\n    name: 'Y1'\n  }\n  dependsOn: []\n}\n\nresource storageAccount 'Microsoft.Storage/storageAccounts@2022-05-01' = {\n  name: storageAccountName\n  location: location\n  tags: {}\n  sku: {\n    name: 'Standard_LRS'\n  }\n  properties: {\n    supportsHttpsTrafficOnly: true\n    minimumTlsVersion: 'TLS1_2'\n  }\n  kind: 'StorageV2'\n}\n\noutput functionAppResourceId string = functionApp.id\n")),(0,a.kt)("p",null,"It also creates a storage account and a server farm to support the function app. You'll note it exports the resource name of the function app. We'll use this in the next step."),(0,a.kt)("h2",o({},{id:"the-static-web-app-bicep"}),"The Static Web App Bicep"),(0,a.kt)("p",null,"In our main Bicep template we'll create a static web app and link it to the function app we created in the previous step. We'll do this with a Bicep module called ",(0,a.kt)("inlineCode",{parentName:"p"},"main.bicep"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param location string\nparam branch string\nparam staticWebAppName string\nparam functionAppName string\nparam hostingPlanName string\nparam storageAccountName string\nparam tags object\n@secure()\nparam repositoryToken string\nparam customDomainName string\n\nmodule functionApp 'function.bicep' = {\n  name: 'functionApp'\n  params: {\n    location: location\n    tags: tags\n    functionAppName: functionAppName\n    hostingPlanName: hostingPlanName\n    storageAccountName: storageAccountName\n  }\n}\n\nresource staticWebApp 'Microsoft.Web/staticSites@2021-02-01' = {\n  name: staticWebAppName\n  location: location\n  tags: tags\n  sku: {\n    // Free doesn't work with linked backends\n    name: 'Standard'\n    tier: 'Standard'\n  }\n  properties: {\n    repositoryUrl: 'https://github.com/johnnyreilly/blog.johnnyreilly.com'\n    repositoryToken: repositoryToken\n    branch: branch\n    provider: 'GitHub'\n    stagingEnvironmentPolicy: 'Enabled'\n    allowConfigFileUpdates: true\n    buildProperties:{\n      skipGithubActionWorkflowGeneration: true\n    }\n  }\n}\n\nresource customDomain 'Microsoft.Web/staticSites/customDomains@2021-02-01' = {\n  parent: staticWebApp\n  name: customDomainName\n  properties: {}\n}\n\nresource staticWebAppBackend 'Microsoft.Web/staticSites/linkedBackends@2022-03-01' = {\n  name: '${staticWebAppName}/backend'\n  properties: {\n    backendResourceId: functionApp.outputs.functionAppResourceId\n    region: location\n  }\n}\n\noutput staticWebAppDefaultHostName string = staticWebApp.properties.defaultHostname // eg gentle-bush-0db02ce03.azurestaticapps.net\noutput staticWebAppId string = staticWebApp.id\noutput staticWebAppName string = staticWebApp.name\n")),(0,a.kt)("p",null,"The crucial bit above is this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"resource staticWebAppBackend 'Microsoft.Web/staticSites/linkedBackends@2022-03-01' = {\n  name: '${staticWebAppName}/backend'\n  properties: {\n    backendResourceId: functionApp.outputs.functionAppResourceId\n    region: location\n  }\n}\n")),(0,a.kt)("p",null,"This links the static web app to the function app we created in the previous step. We use the ",(0,a.kt)("inlineCode",{parentName:"p"},"functionApp.outputs.functionAppResourceId")," to get the resource ID of the function app from our module."),(0,a.kt)("h2",o({},{id:"the-deployment"}),"The Deployment"),(0,a.kt)("p",null,"Once this is deployed to Azure, if you click on the APIs section of the static web app you'll see the function app is now linked:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"The function app is now linked to the static web app as demonstrated in the Azure Portal",src:n(21018).Z,width:"1920",height:"494"})))}d.isMDXComponent=!0},35779:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"web-monetization-api",title:"Getting started with the Web Monetization API",authors:"johnnyreilly",tags:["Web Monetization"],image:"./title-image.png",description:"The Web Monetization API is a browser API streams payment from the browser to the website. This post walks through getting started adding it to a site.",hide_table_of_contents:!1},s=void 0,l={permalink:"/web-monetization-api",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-10-20-web-monetization-api/index.md",source:"@site/blog/2022-10-20-web-monetization-api/index.md",title:"Getting started with the Web Monetization API",description:"The Web Monetization API is a browser API streams payment from the browser to the website. This post walks through getting started adding it to a site.",date:"2022-10-20T00:00:00.000Z",formattedDate:"October 20, 2022",tags:[{label:"Web Monetization",permalink:"/tags/web-monetization"}],readingTime:7.68,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"web-monetization-api",title:"Getting started with the Web Monetization API",authors:"johnnyreilly",tags:["Web Monetization"],image:"./title-image.png",description:"The Web Monetization API is a browser API streams payment from the browser to the website. This post walks through getting started adding it to a site.",hide_table_of_contents:!1},prevItem:{title:"Debugging Azure Functions in VS Code on Mac OS",permalink:"/debugging-azure-functions-vs-code-mac-os"},nextItem:{title:"Bicep: Static Web Apps and Linked Backends",permalink:"/bicep-static-web-apps-linked-backends"}},p={image:n(76011).Z,authorsImageUrls:[void 0]},u=[{value:"The Web Monetization API",id:"the-web-monetization-api",level:2},{value:"Wallet",id:"wallet",level:2},{value:"Uphold",id:"uphold",level:2},{value:"Payment pointer",id:"payment-pointer",level:2},{value:"Monetization link tag",id:"monetization-link-tag",level:2},{value:"Docusaurus link tag: updated 30/10/2022",id:"docusaurus-link-tag-updated-30102022",level:2},{value:"Hello world Web Monetization API?",id:"hello-world-web-monetization-api",level:2},{value:"Coil",id:"coil",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The Web Monetization API is a JavaScript browser API that allows the creation of a payment stream from the user agent to the website. This post walks through getting started adding it to a site."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Web Monetization API - getting started&quot; with the Web Monetization logo",src:n(76011).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"the-web-monetization-api"}),"The Web Monetization API"),(0,a.kt)("p",null,"Over the summer I attended the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://halfstackconf.com/newquay/"}),"HalfStack at the Beach")," conference and heard a talk from ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/avolakatos"}),"Alex Lakatos")," on the Web Monetization API. I hadn't heard about this API previously; it turns out it is a new way to monetize a website. My own blog already featured a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.buymeacoffee.com/qUBm0Wh"}),"Buy Me a Coffee")," link, which allows generous people to send me small amounts of money if they've found something I've written useful. The Web Monetization API appears to be that, but built into the browser and proposed as a W3C standard at the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://discourse.wicg.io/t/proposal-web-monetization-a-new-revenue-model-for-the-web/3785"}),"Web Platform Incubator Community Group"),"."),(0,a.kt)("p",null,"I was intrigued by the Web Monetization API. Alex was kind enough to share some links with me, and I decided to take it for a spin; to try out using it and to document the findings. This post is going to be exactly that. It's written from the perspective of someone who doesn't know the Web Monetization API save for what they've heard in a talk. Over the course of this post I'll try to get to know it a little better, and try to integrate it into ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.johnnyreilly.com"}),"my blog"),". As I do that I'll share what I'm doing and how I found things; to try to provide a useful resource (and some feedback) on what adoption feels like."),(0,a.kt)("p",null,"I'll start with the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://webmonetization.org/"}),"https://webmonetization.org/")," site - in there I found a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://webmonetization.org/docs/getting-started"}),"quick start")," which I decided to work through."),(0,a.kt)("h2",o({},{id:"wallet"}),"Wallet"),(0,a.kt)("p",null,"The first thing to do, if you'd like to adopt Web Monetization, is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://webmonetization.org/docs/getting-started#1-set-up-a-web-monetized-wallet"}),"set up a wallet"),". This allows you to receive money from people - it's a bank account essentially; one that supports integration with Web Monetization. There appeared to be two options for this:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://wallet.uphold.com/"}),"uphold")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://gatehub.net/"}),"gatehub"))),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://webmonetization.org/docs/ilp-wallets/#digital-wallets"}),"Right now, uphold offers a greater number of features"),", so decided to create a wallet with them."),(0,a.kt)("h2",o({},{id:"uphold"}),"Uphold"),(0,a.kt)("p",null,"The signup process was pretty straightforward. I got slightly confused was seeing this prompt:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot reading &quot;How will you use Uphold? ... Trade cryptocurrencies, Currency conversion, Deposit or withdraw cryptocurrencies, Transfers between users&quot;",src:n(10741).Z,width:"891",height:"866"})),(0,a.kt)("p",null,"I wasn't entirely sure what I needed. The Web Monetization API seemed most likely to be about transfers between users, so I went with that."),(0,a.kt)("p",null,"When it asked this question:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot reading &quot;International payments/transfers Tell us where you&#39;ll be moving money. Select from the regions below.&quot;",src:n(50872).Z,width:"914",height:"981"})),(0,a.kt)("p",null,"I opted to accept all regions. After the usual signup process, I was able to see able to see my new (empty) account:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the dashboard of uphold with a balance of \xa30",src:n(23020).Z,width:"3001",height:"1466"})),(0,a.kt)("h2",o({},{id:"payment-pointer"}),"Payment pointer"),(0,a.kt)("p",null,'The next thing we needed to do was acquire our payment pointer. This was a little tricky to track down and eventually Alex showed me where to go. On the right hand side of the dashboard, there is an "anything to anything" section:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"gif of the payment pointer found in uphold",src:n(74860).Z,width:"930",height:"1474"})),(0,a.kt)("p",null,'Clicking on the "copy" button copies the payment pointer to the clipboard. I\'ll need this later. In my case that is: ',(0,a.kt)("inlineCode",{parentName:"p"},"$ilp.uphold.com/LwQQhXdpwxeJ"),"."),(0,a.kt)("p",null,'You might be looking at the payment pointer and thinking, "that looks kinda URL-y" ... And you\'d be be right! Because ',(0,a.kt)("inlineCode",{parentName:"p"},"$ilp.uphold.com/LwQQhXdpwxeJ")," is equivalent to this URL: ",(0,a.kt)("inlineCode",{parentName:"p"},"https://ilp.uphold.com/LwQQhXdpwxeJ"),". We just swap out the ",(0,a.kt)("inlineCode",{parentName:"p"},"$")," for ",(0,a.kt)("inlineCode",{parentName:"p"},"https://"),"."),(0,a.kt)("h2",o({},{id:"monetization-link-tag"}),"Monetization link tag"),(0,a.kt)("p",null,"The next thing to do is to make a ",(0,a.kt)("inlineCode",{parentName:"p"},"link")," tag using the payment pointer. This is the tag that will tell the browser that the page supports Web Monetization. That ",(0,a.kt)("inlineCode",{parentName:"p"},"link")," tag should live in every page of our Web Monetized site. The tag looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<link rel="monetization" href="https://ilp.uphold.com/LwQQhXdpwxeJ" />\n')),(0,a.kt)("p",null,"As you can see, the ",(0,a.kt)("inlineCode",{parentName:"p"},"href"),' attribute is the payment pointer we just acquired; in its "https" form.'),(0,a.kt)("h2",o({},{id:"docusaurus-link-tag-updated-30102022"}),"Docusaurus link tag: updated 30/10/2022"),(0,a.kt)("p",null,"The final step here would be adding this ",(0,a.kt)("inlineCode",{parentName:"p"},"link")," tag to the pages served up by our site. In my case, I use Docusaurus to power my blog. To add an extra ",(0,a.kt)("inlineCode",{parentName:"p"},"link")," tag with Docusaurus we need to add it to the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/docs/next/seo#global-metadata"}),(0,a.kt)("inlineCode",{parentName:"a"},"docusaurus.config.js"))," file."),(0,a.kt)("p",null,"If you're using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/blog/releases/2.2#config-headtags"}),"Docusaurus 2.2 or greater")," you can use the new ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/docs/api/docusaurus-config#headTags"}),(0,a.kt)("inlineCode",{parentName:"a"},"headTags")," API"),". Usage looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"module.exports = {\n  // ...\n  headTags: [\n    {\n      tagName: 'link',\n      attributes: {\n        rel: 'monetization',\n        href: 'https://ilp.uphold.com/LwQQhXdpwxeJ',\n      },\n    },\n    // This will become <link rel=\"monetization\" href=\"https://ilp.uphold.com/LwQQhXdpwxeJ\" /> in the generated HTML\n  ],\n  // ...\n};\n")),(0,a.kt)("p",null,"If you're using an older version of Docusaurus, you can the syntax for adding an extra ",(0,a.kt)("inlineCode",{parentName:"p"},"link")," tag in the head comes in the form of a mini plugin:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"module.exports = {\n  // ...\n  plugins: [\n    // ...\n    function extraHeadTagsPlugin(context, options) {\n      return {\n        name: 'extra-head-tags-plugin',\n        injectHtmlTags({ content }) {\n          return {\n            headTags: [\n              {\n                tagName: 'link',\n                attributes: {\n                  rel: 'monetization',\n                  href: 'https://ilp.uphold.com/LwQQhXdpwxeJ',\n                },\n                // This will become <link rel=\"monetization\" href=\"https://ilp.uphold.com/LwQQhXdpwxeJ\" /> in the generated HTML\n              },\n            ],\n          };\n        },\n      };\n    },\n    // ...\n  ],\n};\n")),(0,a.kt)("p",null,"It's also worth knowing that historically the Web Monetization API used a ",(0,a.kt)("inlineCode",{parentName:"p"},"meta")," tag instead of a ",(0,a.kt)("inlineCode",{parentName:"p"},"link")," tag - and that tag used the ",(0,a.kt)("inlineCode",{parentName:"p"},"$")," prefix instead of ",(0,a.kt)("inlineCode",{parentName:"p"},"https://"),". That tag looked like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-html"}),'<meta name="monetization" content="$ilp.uphold.com/LwQQhXdpwxeJ" />\n')),(0,a.kt)("p",null,"But the ",(0,a.kt)("inlineCode",{parentName:"p"},"link")," tag is the current standard, and that's what you should look to adopt."),(0,a.kt)("h2",o({},{id:"hello-world-web-monetization-api"}),"Hello world Web Monetization API?"),(0,a.kt)("p",null,'With this done, my site is web monetized! Or at least... I think it is... What does that mean? Well, I wasn\'t entirely sure. I reached out to Alex again, showed him my site and said "does this work?" He said:'),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of conversation with Alex on Twitter, him saying &quot;Hey John. That&#39;s it! I just sent you a little tip on uphold, if you&#39;ve set that up correctly, you&#39;ll see it in your account&quot;",src:n(45804).Z,width:"1178",height:"1449"})),(0,a.kt)("p",null,"And sure enough, I found Alex had indeed sent me the princely sum of 83 pence ($1) on Uphold... It had worked!"),(0,a.kt)("h2",o({},{id:"coil"}),"Coil"),(0,a.kt)("p",null,"It turned out that Alex had used a browser extension called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://coil.com/"}),"Coil")," to send me the money. It's a browser extension that allows you to send money to websites that support Web Monetization. It's a bit like a browser based Patreon or Buy Me a Coffee. But slightly different; ",(0,a.kt)("a",o({parentName:"p"},{href:"https://help.coil.com/docs/general-info/intro-to-coil/index.html#how-is-coil-different-from-other-membership-services-like-patreon-and-flattr"}),"to quote their docs"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"With services like Patreon, you select which creators to support, then pay each creator separately, depending on the membership plans they offer. Coil streams payments in real time to any web monetized sites you visit.")),(0,a.kt)("p",null,'So people can explicitly tip a website using Coil, or they can just use Coil to browse the web and the website will get a small amount of money from Coil. For years I\'ve heard whispers of "micropayments are the missing piece of the web" - this seemed to be solving that problem and I was intrigued.'),(0,a.kt)("p",null,"I'd set up an Uphold account so I could receive money from other people. Coil is like the flipside of that; it would let me send money to other people. You need that money to come from somewhere. It turned out that I could set up a Coil account using the Uphold account I'd just created:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of entering my uphold payment pointer into my coil account",src:n(30194).Z,width:"1161",height:"869"})),(0,a.kt)("p",null,"So that's what I did. I entered my payment pointer into Coil and now I can send money to other people's sites that support Web Monetization. But what does that look like? Well, I decided to try it out on my own site. I installed the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://coil.com/"}),"Coil browser extension")," and then went to my site and gave it a whirl:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"GIF of tipping myself $1 using Coil",src:n(24205).Z,width:"2294",height:"1150"})),(0,a.kt)("p",null,"I went to my blog and sure enough, I was able to send a tip to myself. When I flipped over to my Uphold account, I could see that the money was on its way!"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of uphold including details of an incoming payment of $1 or 93 pence",src:n(56946).Z,width:"912",height:"826"})),(0,a.kt)("p",null,"Just as Alex had been able to send me $1 on September 4th, I was able to send myself $1 on September 10th! (Incidentally, the shift in amount from 83 pence to 93 pence between transactions is purely due to the changing value exchange rate between GBP and USD. At present the Pound is decreasing in value against the Dollar, so the amount of money I received in GBP when I tipped myself $1 worked out to be more than when Alex did.)"),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"In this post we have got to know the Web Monetization API, we've used it to monetize our own site and we've used it to tip ourselves. We've also seen how Coil works and how it can be used to tip other people's sites. I'm excited to see how this develops. It feels like a way to support people who are making things we care about on the web."),(0,a.kt)("p",null,"Thanks so much to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/avolakatos"}),"Alex Lakatos")," for telling me about this in the first place and for answering all my questions!"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/getting-started-web-monetization-api/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/getting-started-web-monetization-api/"})))}d.isMDXComponent=!0},68257:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"debugging-azure-functions-vs-code-mac-os",title:"Debugging Azure Functions in VS Code on Mac OS",authors:"johnnyreilly",tags:["Azure Functions","VS Code","Mac OS"],image:"./title-image.png",description:"The VS Code debugging mechanism for Azure Functions on Mac OS frequently breaks. This post documents an approach to get it working.",hide_table_of_contents:!1},s=void 0,l={permalink:"/debugging-azure-functions-vs-code-mac-os",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-11-11-debugging-azure-functions-vs-code-mac-os/index.md",source:"@site/blog/2022-11-11-debugging-azure-functions-vs-code-mac-os/index.md",title:"Debugging Azure Functions in VS Code on Mac OS",description:"The VS Code debugging mechanism for Azure Functions on Mac OS frequently breaks. This post documents an approach to get it working.",date:"2022-11-11T00:00:00.000Z",formattedDate:"November 11, 2022",tags:[{label:"Azure Functions",permalink:"/tags/azure-functions"},{label:"VS Code",permalink:"/tags/vs-code"},{label:"Mac OS",permalink:"/tags/mac-os"}],readingTime:2.08,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"debugging-azure-functions-vs-code-mac-os",title:"Debugging Azure Functions in VS Code on Mac OS",authors:"johnnyreilly",tags:["Azure Functions","VS Code","Mac OS"],image:"./title-image.png",description:"The VS Code debugging mechanism for Azure Functions on Mac OS frequently breaks. This post documents an approach to get it working.",hide_table_of_contents:!1},prevItem:{title:"Azure AD Claims with Static Web Apps and Azure Functions",permalink:"/azure-ad-claims-static-web-apps-azure-functions"},nextItem:{title:"Getting started with the Web Monetization API",permalink:"/web-monetization-api"}},p={image:n(73847).Z,authorsImageUrls:[void 0]},u=[{value:"The problem",id:"the-problem",level:2},{value:"The workaround",id:"the-workaround",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"VS Code's debugging mechanism for Azure Functions on Mac OS frequently breaks. This post documents an approach to get it working."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Debugging Azure Functions in VS Code on Mac OS&quot; with Docusaurus, SWC and webpack logos",src:n(73847).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"the-problem"}),"The problem"),(0,a.kt)("p",null,"I frequently use a Mac to develop Azure Functions. I use VS Code as my editor."),(0,a.kt)("p",null,"Debugging is can be very useful when you're developing; getting to understand what the computer can see at runtime is a superpower. Regrettably with Azure Functions, I often find that the debugger fails to attach. When this happens, I can't actually debug my Azure Functions."),(0,a.kt)("p",null,"This is a known issue. In fact, this blog post is me sharing a workaround that I've needed again and again, but keep losing. Not my own work, the work of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/basilfx"}),"Bas Stottelaar"),". I share it as a public service announcement - and to remind myself how to do it! ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/OmniSharp/omnisharp-vscode/issues/4903#issuecomment-993015843"}),"The original issue (and workaround) is here"),". Yay Bas!"),(0,a.kt)("p",null,"There appears to be something wrong with the standard code signing of ",(0,a.kt)("inlineCode",{parentName:"p"},"vsdbg")," and / or ",(0,a.kt)("inlineCode",{parentName:"p"},"vsdbg-ui"),". The workaround is to sign the binaries yourself."),(0,a.kt)("h2",o({},{id:"the-workaround"}),"The workaround"),(0,a.kt)("p",null,"You'll first need to generate a self signed certificate to be used for code signing. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://stackoverflow.com/a/58363510/761388"}),"There's a good resource on Stack Overflow covering this"),". You should only ever need to do this once. You can then use the same certificate every time you apply the workaround."),(0,a.kt)("p",null,"In fact it's probably worth emphasising that you'll likely need to apply this workaround again and again. It's not a permanent fix. The workaround script that you need to run is:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"cd ~/.vscode/extensions/ms-dotnettools.csharp-1.25.2-darwin-x64/.debugger/x86_64\ncodesign --remove-signature vsdbg-ui && codesign --remove-signature vsdbg\ncodesign -s my-codesign-cert vsdbg-ui && codesign -s my-codesign-cert vsdbg\n")),(0,a.kt)("p",null,"A thing to note about the above is the version in the path. You'll need to change that to match the version of the C# extension that you have installed. You can find the version in the VS Code extensions view:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of C# extension in VS Code; in this case version 1.25.2",src:n(55471).Z,width:"1104",height:"344"})),(0,a.kt)("p",null,"In this case the version is ",(0,a.kt)("inlineCode",{parentName:"p"},"1.25.2"),"; as is reflected in the path above."),(0,a.kt)("p",null,'Once the script has been run, I\'ve found that restarting VS Code is a good idea. Regrettably the "I cannot debug my Azure Functions" issue is likely to reoccur in future. When it does, the workaround will need to be reapplied.'),(0,a.kt)("p",null,"In the long term, I'd love to see some debugging improvements for Azure Functions. Until that time, we have this."))}d.isMDXComponent=!0},96743:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-ad-claims-static-web-apps-azure-functions",title:"Azure AD Claims with Static Web Apps and Azure Functions",authors:"johnnyreilly",tags:["Authorization","Azure Functions","Static Web Apps","Linked Backends","Azure AD"],image:"./title-image.png",description:"Authorization with Azure Static Web Apps linked to Azure Functions has an issue. Azure AD app role claims are not supplied; this post will demo a workaround.",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-ad-claims-static-web-apps-azure-functions",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-11-17-azure-ad-claims-static-web-apps-azure-functions/index.md",source:"@site/blog/2022-11-17-azure-ad-claims-static-web-apps-azure-functions/index.md",title:"Azure AD Claims with Static Web Apps and Azure Functions",description:"Authorization with Azure Static Web Apps linked to Azure Functions has an issue. Azure AD app role claims are not supplied; this post will demo a workaround.",date:"2022-11-17T00:00:00.000Z",formattedDate:"November 17, 2022",tags:[{label:"Authorization",permalink:"/tags/authorization"},{label:"Azure Functions",permalink:"/tags/azure-functions"},{label:"Static Web Apps",permalink:"/tags/static-web-apps"},{label:"Linked Backends",permalink:"/tags/linked-backends"},{label:"Azure AD",permalink:"/tags/azure-ad"}],readingTime:11.74,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-ad-claims-static-web-apps-azure-functions",title:"Azure AD Claims with Static Web Apps and Azure Functions",authors:"johnnyreilly",tags:["Authorization","Azure Functions","Static Web Apps","Linked Backends","Azure AD"],image:"./title-image.png",description:"Authorization with Azure Static Web Apps linked to Azure Functions has an issue. Azure AD app role claims are not supplied; this post will demo a workaround.",hide_table_of_contents:!1},prevItem:{title:"XML: read and write with Node.js",permalink:"/xml-read-and-write-with-node-js"},nextItem:{title:"Debugging Azure Functions in VS Code on Mac OS",permalink:"/debugging-azure-functions-vs-code-mac-os"}},p={image:n(82274).Z,authorsImageUrls:[void 0]},u=[{value:"Updated 28th November 2022",id:"updated-28th-november-2022",level:2},{value:"Where&#39;s my claims?",id:"wheres-my-claims",level:2},{value:"Maybe they&#39;re hiding in <code>x-ms-client-principal</code>?",id:"maybe-theyre-hiding-in-x-ms-client-principal",level:2},{value:"Microsoft Graph API",id:"microsoft-graph-api",level:2},{value:"Interrogating the Microsoft Graph API",id:"interrogating-the-microsoft-graph-api",level:2},{value:"Using the <code>PrincipalService</code>",id:"using-the-principalservice",level:2},{value:"<code>GetPrincipal</code> - what claims do we have?",id:"getprincipal---what-claims-do-we-have",level:3},{value:"<code>AmIInRole</code> - test <code>IsInRole</code> functionality",id:"amiinrole---test-isinrole-functionality",level:3},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Authorization in Azure Functions is impaired by an issue with Azure Static Web Apps linked to Azure Functions. Azure AD app role claims are not supplied to Azure Functions. This post will demonstrate a workaround."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Azure AD Claims with Static Web Apps and Azure Functions&quot; with Azure AD, Azure Functions and Static Web App logos",src:n(82274).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"updated-28th-november-2022"}),"Updated 28th November 2022"),(0,a.kt)("p",null,"After I posted this, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/thomasgauvin"}),"Thomas Gauvin")," (Product manager for Static Web Apps) was kind enough to tweet this:"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/thomasgauvin/status/1596242773686079496"}),(0,a.kt)("img",{loading:"lazy",alt:"screenshot of tweet from Thomas Gauvin saying &quot;Thanks for writing this @johnny_reilly, I know this is a pain point with SWA auth at the moment. I&#39;m sure this article will help others in the meantime. We&#39;re working on correcting our docs + looking to add support for this in the future&quot;",src:n(32123).Z,width:"2005",height:"689"}))),(0,a.kt)("p",null,"So by the sounds of it, this blog post will not be required in the longer term, as support should to be added directly. Tremendous news!"),(0,a.kt)("h2",o({},{id:"wheres-my-claims"}),"Where's my claims?"),(0,a.kt)("p",null,"There is a limitation that affects authorization when you have a linked backend paired with an Azure Static Web App. Let's take the case of having an Azure Function App as the linked backend. Essentially the Azure Function app ",(0,a.kt)("em",{parentName:"p"},"does not")," receive the claims that the Static Web App receives. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/static-web-apps/issues/988"}),"There's an issue tracking this on GitHub"),", and it seems that this is a general problem with Static Web Apps, Azure AD and linked backends."),(0,a.kt)("p",null,"We have a Static Web App, with an associated C# Function App (using the ",(0,a.kt)("a",o({parentName:"p"},{href:"/bicep-static-web-apps-linked-backends"}),"Bring Your Own Functions"),' AKA "linked backend" approach). Both the Static Web App and Function App are associated with the same Azure AD App Registration.'),(0,a.kt)("p",null,"When we're authenticated with Azure AD and go to the auth endpoint in our Static Web App: ",(0,a.kt)("inlineCode",{parentName:"p"},"/.auth/me")," we see:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "clientPrincipal": {\n    "identityProvider": "aad",\n    "userId": "d9178465-3847-4d98-9d23-b8b9e403b323",\n    "userDetails": "johnny_reilly@hotmail.com",\n    "userRoles": ["authenticated", "anonymous"],\n    "claims": [\n      // ...\n      {\n        "typ": "http://schemas.microsoft.com/identity/claims/objectidentifier",\n        "val": "d9178465-3847-4d98-9d23-b8b9e403b323"\n      },\n      {\n        "typ": "http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress",\n        "val": "johnny_reilly@hotmail.com"\n      },\n      {\n        "typ": "name",\n        "val": "John Reilly"\n      },\n      {\n        "typ": "roles",\n        "val": "OurApp.Read"\n      },\n      // ...\n      {\n        "typ": "ver",\n        "val": "2.0"\n      }\n    ]\n  }\n}\n')),(0,a.kt)("p",null,"Note the claims in there. These include custom claims that we've configured against our Azure AD App Registration such as roles with ",(0,a.kt)("inlineCode",{parentName:"p"},"OurApp.Read"),"."),(0,a.kt)("p",null,"So we can access claims successfully in the Static Web App (the front end). However, the associated Function App does ",(0,a.kt)("strong",{parentName:"p"},"not")," have access to the claims."),(0,a.kt)("p",null,"It's possible to see this by implementing a function in our Azure Function App which surfaces roles:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[FunctionName("GetRoles")]\npublic static async Task<IActionResult> Run(\n    [HttpTrigger(AuthorizationLevel.Anonymous, "get", "post", Route = "GetRoles")] HttpRequest req\n)\n{\n    var roles = req.HttpContext.User?.Claims.Select(c => new { c.Type, c.Value });\n\n    return new OkObjectResult(roles);\n}\n')),(0,a.kt)("p",null,"When this ",(0,a.kt)("inlineCode",{parentName:"p"},"/api/GetRoles")," endpoint is accessed we see this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'[\n  {\n    "Type": "http://schemas.xmlsoap.org/ws/2005/05/identity/claims/nameidentifier",\n    "Value": "d9178465-3847-4d98-9d23-b8b9e403b323"\n  },\n  {\n    "Type": "http://schemas.xmlsoap.org/ws/2005/05/identity/claims/name",\n    "Value": "johnny_reilly@hotmail.com"\n  },\n  {\n    "Type": "http://schemas.microsoft.com/ws/2008/06/identity/claims/role",\n    "Value": "authenticated"\n  },\n  {\n    "Type": "http://schemas.microsoft.com/ws/2008/06/identity/claims/role",\n    "Value": "anonymous"\n  }\n]\n')),(0,a.kt)("p",null,"At first look, this seems great; we have claims! But when we look again we realise that we have far less claims than we might have hoped for. Crucially, our custom claims / app roles like ",(0,a.kt)("inlineCode",{parentName:"p"},"OurApp.Read")," are missing."),(0,a.kt)("h2",o({},{id:"maybe-theyre-hiding-in-x-ms-client-principal"}),"Maybe they're hiding in ",(0,a.kt)("inlineCode",{parentName:"h2"},"x-ms-client-principal"),"?"),(0,a.kt)("p",null,"If we look directly at the ",(0,a.kt)("inlineCode",{parentName:"p"},"x-ms-client-principal")," header, maybe we'll find what we need?"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'[FunctionName("GetRoles")]\npublic static async Task<IActionResult> GetRoles(\n    [HttpTrigger(AuthorizationLevel.Anonymous, "get", Route = "GetRoles")] HttpRequest req\n)\n{\n    var header = req.Headers["x-ms-client-principal"];\n    var data = header.FirstOrDefault();\n    if (data == null)\n    {\n        return new OkObjectResult("nothing");\n    }\n\n    var decoded = System.Convert.FromBase64String(data);\n    var json = System.Text.ASCIIEncoding.ASCII.GetString(decoded);\n\n    return new OkObjectResult(json);\n}\n')),(0,a.kt)("p",null,'Alas not. We have the user\'s email and some simple roles ("authenticated" and "anonymous"), but no sign of our custom claims / app roles:'),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "identityProvider": "aad",\n  "userId": "d9178465-3847-4d98-9d23-b8b9e403b323",\n  "userDetails": "johnny_reilly@hotmail.com",\n  "userRoles": ["authenticated", "anonymous"]\n}\n')),(0,a.kt)("p",null,"This is the problem: we want our Azure Function App to be able to make use of the same custom claims / app roles that we use for authorization in the Static Web App. How can we achieve this?"),(0,a.kt)("h2",o({},{id:"microsoft-graph-api"}),"Microsoft Graph API"),(0,a.kt)("p",null,"The answer lies with the Microsoft Graph API. We can interrogate it to get the app role assignments for the user. This will give us the same information that we have in the Static Web App. (Well to be strictly accurate, it will be a slightly different set of claims. But what matters is it will be the app role assignment claims that we want to use for authorization.)"),(0,a.kt)("p",null,"We already have an Azure AD app registration. In order that we can interrogate the Microsoft Graph API, we'll need the following permissions:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the Azure AD app registration API permissions screen",src:n(26436).Z,width:"970",height:"290"})),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://learn.microsoft.com/en-us/graph/permissions-reference#delegated-permissions-85"}),"User.Read")," - to sign in"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://learn.microsoft.com/en-us/graph/permissions-reference#application-permissions-81"}),"User.Read.All")," - for acquiring the app role assignments against a user"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",o({parentName:"li"},{href:"https://learn.microsoft.com/en-us/graph/permissions-reference#application-permissions-4"}),"Application.Read.All")," - to get more information about the app role assignments - allowing us to translate the app role assignments into the claims that we want to use for authorization")),(0,a.kt)("p",null,"Of the above permissions, it's likely that you'll already have delegated ",(0,a.kt)("inlineCode",{parentName:"p"},"User.Read")," in place; the other two you might need to add and ensure they're granted in Azure."),(0,a.kt)("h2",o({},{id:"interrogating-the-microsoft-graph-api"}),"Interrogating the Microsoft Graph API"),(0,a.kt)("p",null,"Now we have an Azure AD App Registration with sufficient permissions, we'll need a ",(0,a.kt)("inlineCode",{parentName:"p"},"GraphClient")," to interrogate the Microsoft Graph API. To get that we're going to build an ",(0,a.kt)("inlineCode",{parentName:"p"},"AuthenticatedGraphClientFactory"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System.Net.Http;\nusing System.Net.Http.Headers;\nusing System.Threading.Tasks;\nusing Microsoft.Graph;\nusing Microsoft.Identity.Client;\n\nnamespace MyApp.Auth\n{\n    public interface IAuthenticatedGraphClientFactory\n    {\n        (GraphServiceClient, string) GetAuthenticatedGraphClientAndClientId();\n    }\n\n    public class AuthenticatedGraphClientFactory : IAuthenticatedGraphClientFactory\n    {\n        private GraphServiceClient? _graphServiceClient;\n        private readonly string _clientId;\n        private readonly string _clientSecret;\n        private readonly string _tenantId;\n\n        public AuthenticatedGraphClientFactory(\n            string clientId,\n            string clientSecret,\n            string tenantId\n        )\n        {\n            _clientId = clientId;\n            _clientSecret = clientSecret;\n            _tenantId = tenantId;\n        }\n\n        public (GraphServiceClient, string) GetAuthenticatedGraphClientAndClientId()\n        {\n            var authenticationProvider = CreateAuthenticationProvider();\n\n            _graphServiceClient = new GraphServiceClient(authenticationProvider);\n\n            return (_graphServiceClient, _clientId);\n        }\n\n        private IAuthenticationProvider CreateAuthenticationProvider()\n        {\n            // this specific scope means that application will default to what is defined in the application registration rather than using dynamic scopes\n            string[] scopes = new string[]\n            {\n                "https://graph.microsoft.com/.default"\n            };\n\n            var confidentialClientApplication = ConfidentialClientApplicationBuilder.Create(_clientId)\n                .WithAuthority($"https://login.microsoftonline.com/{_tenantId}/v2.0")\n                .WithClientSecret(_clientSecret)\n                .Build();\n\n            return new MsalAuthenticationProvider(confidentialClientApplication, scopes); ;\n        }\n    }\n\n    public class MsalAuthenticationProvider : IAuthenticationProvider\n    {\n        private readonly IConfidentialClientApplication _clientApplication;\n        private readonly string[] _scopes;\n\n        public MsalAuthenticationProvider(IConfidentialClientApplication clientApplication, string[] scopes)\n        {\n            _clientApplication = clientApplication;\n            _scopes = scopes;\n        }\n\n        /// <summary>\n        /// Update HttpRequestMessage with credentials\n        /// </summary>\n        public async Task AuthenticateRequestAsync(HttpRequestMessage request)\n        {\n            var token = await GetTokenAsync();\n\n            request.Headers.Authorization = new AuthenticationHeaderValue("bearer", token);\n        }\n\n        /// <summary>\n        /// Acquire Token\n        /// </summary>\n        public async Task<string?> GetTokenAsync()\n        {\n            var authResult = await _clientApplication.AcquireTokenForClient(_scopes).ExecuteAsync();\n\n            return authResult.AccessToken;\n        }\n    }\n}\n')),(0,a.kt)("p",null,"When we execute ",(0,a.kt)("inlineCode",{parentName:"p"},"GetAuthenticatedGraphClientAndClientId")," we'll get back a ",(0,a.kt)("inlineCode",{parentName:"p"},"GraphServiceClient")," that we can use to interrogate the Microsoft Graph API. We'll also get back the client ID of the Graph API App. We'll need this later. Note that the ",(0,a.kt)("inlineCode",{parentName:"p"},"AuthenticatedGraphClientFactory")," requires the client ID, client secret and tenant ID of the Azure AD App Registration."),(0,a.kt)("p",null,"Now we have the ability to interrogate the Microsoft Graph API, we can write a ",(0,a.kt)("inlineCode",{parentName:"p"},"PrincipalService.cs")," class that will interrogate it and return the app role assignments for the user:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Security.Claims;\nusing System.Text;\nusing System.Text.Json;\nusing System.Threading.Tasks;\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.Extensions.Logging;\nusing Microsoft.Graph;\n\nnamespace MyApp.Auth\n{\n    public interface IPrincipalService\n    {\n        Task<ClaimsPrincipal> GetPrincipal(HttpRequest req);\n    }\n\n    public class PrincipalService : IPrincipalService\n    {\n        readonly ILogger<PrincipalService> _log;\n        readonly IAuthenticatedGraphClientFactory _graphClientFactory;\n\n        public PrincipalService(\n            IAuthenticatedGraphClientFactory graphClientFactory,\n            ILogger<PrincipalService> log\n        )\n        {\n            _graphClientFactory = graphClientFactory;\n            _log = log;\n        }\n\n        public async Task<ClaimsPrincipal> GetPrincipal(HttpRequest req)\n        {\n            try\n            {\n                MsClientPrincipal? principal = MakeMsClientPrincipal(req);\n\n                if (principal == null)\n                    return new ClaimsPrincipal();\n\n                if (!principal.UserRoles?.Where(NotAnonymous).Any() ?? true)\n                    return new ClaimsPrincipal();\n\n                ClaimsIdentity identity = await MakeClaimsIdentity(principal);\n\n                return new ClaimsPrincipal(identity);\n            }\n            catch (Exception e)\n            {\n                _log.LogError(e, "Error parsing claims principal");\n                return new ClaimsPrincipal();\n            }\n        }\n\n        MsClientPrincipal? MakeMsClientPrincipal(HttpRequest req)\n        {\n            MsClientPrincipal? principal = null;\n\n            if (req.Headers.TryGetValue("x-ms-client-principal", out var header))\n            {\n                var data = header.FirstOrDefault();\n                if (data != null)\n                {\n                    var decoded = Convert.FromBase64String(data);\n                    var json = Encoding.UTF8.GetString(decoded);\n                    _log.LogInformation($"x-ms-client-principal: {json}");\n                    principal = JsonSerializer.Deserialize<MsClientPrincipal>(json, new JsonSerializerOptions { PropertyNameCaseInsensitive = true });\n                }\n            }\n\n            return principal;\n        }\n\n        async Task<ClaimsIdentity> MakeClaimsIdentity(MsClientPrincipal principal)\n        {\n            var identity = new ClaimsIdentity(principal.IdentityProvider);\n\n            identity.AddClaim(new Claim(ClaimTypes.NameIdentifier, principal.UserId!));\n            identity.AddClaim(new Claim(ClaimTypes.Name, principal.UserDetails!));\n\n            if (principal.UserRoles != null)\n                identity.AddClaims(principal.UserRoles\n                    .Where(NotAnonymous)\n                    .Select(userRole => new Claim(ClaimTypes.Role, userRole)));\n\n            var username = principal.UserDetails;\n            if (username != null)\n            {\n                var userAppRoleAssignments = await GetUserAppRoleAssignments(username);\n                identity.AddClaims(userAppRoleAssignments\n                    .Select(userAppRoleAssignments => new Claim(ClaimTypes.Role, userAppRoleAssignments)));\n            }\n\n            return identity;\n        }\n\n        static bool NotAnonymous(string r) =>\n            !string.Equals(r, "anonymous", StringComparison.CurrentCultureIgnoreCase);\n\n        async Task<string[]> GetUserAppRoleAssignments(string username)\n        {\n            try\n            {\n                var (graphClient, clientId) = _graphClientFactory.GetAuthenticatedGraphClientAndClientId();\n                _log.LogInformation("Getting AppRoleAssignments for {username}", username);\n\n                var userRoleAssignments = await graphClient.Users[username]\n                    .AppRoleAssignments\n                    .Request()\n                    .GetAsync();\n\n                var roleIds = new List<string>();\n                var pageIterator = PageIterator<AppRoleAssignment>\n                    .CreatePageIterator(\n                        graphClient,\n                        userRoleAssignments,\n                        // Callback executed for each item in the collection\n                        (appRoleAssignment) =>\n                        {\n                            if (appRoleAssignment.AppRoleId.HasValue && appRoleAssignment.AppRoleId.Value != Guid.Empty)\n                                roleIds.Add(appRoleAssignment.AppRoleId.Value.ToString());\n\n                            return true;\n                        },\n                        // Used to configure subsequent page requests\n                        (baseRequest) =>\n                        {\n                            // Re-add the header to subsequent requests\n                            baseRequest.Header("Prefer", "outlook.body-content-type=\\"text\\"");\n                            return baseRequest;\n                        });\n\n                await pageIterator.IterateAsync();\n\n                var applications = await graphClient.Applications\n                    .Request()\n                    .Filter($"appId eq \'{clientId}\'") // we\'re only interested in the app that we\'re running as\n                    .GetAsync();\n\n                var appRoleAssignments = applications\n                    .FirstOrDefault()\n                    ?.AppRoles\n                    ?.Where(appRole => appRole.Id.HasValue && roleIds.Contains(appRole.Id!.Value.ToString()))\n                    .Select(appRole => appRole.Value)\n                    .ToArray();\n\n                return appRoleAssignments ?? Array.Empty<string>();\n            }\n            catch (Exception e)\n            {\n                _log.LogError(e, "Error getting AppRoleAssignments");\n                return Array.Empty<string>();\n            }\n        }\n\n        class MsClientPrincipal\n        {\n            public string? IdentityProvider { get; set; }\n            public string? UserId { get; set; }\n            public string? UserDetails { get; set; }\n            public IEnumerable<string>? UserRoles { get; set; }\n        }\n    }\n}\n')),(0,a.kt)("p",null,"Quite a lot of code! Let's walk through what it does:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"It takes the ",(0,a.kt)("inlineCode",{parentName:"li"},"x-ms-client-principal")," header and deserializes it into a ",(0,a.kt)("inlineCode",{parentName:"li"},"MsClientPrincipal")," object - this is the cut down version of the ",(0,a.kt)("inlineCode",{parentName:"li"},"ClaimsPrincipal")," object that we saw earlier:")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "identityProvider": "aad",\n  "userId": "d9178465-3847-4d98-9d23-b8b9e403b323",\n  "userDetails": "johnny_reilly@hotmail.com",\n  "userRoles": ["authenticated", "anonymous"]\n}\n')),(0,a.kt)("ol",o({},{start:2}),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"It creates a new ",(0,a.kt)("inlineCode",{parentName:"p"},"ClaimsIdentity")," using that information, but stripping out the ",(0,a.kt)("inlineCode",{parentName:"p"},"anonymous")," role as it's superfluous.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Using the ",(0,a.kt)("inlineCode",{parentName:"p"},"userDetails")," (email address) from the ",(0,a.kt)("inlineCode",{parentName:"p"},"MsClientPrincipal")," object, it gets the app role assignments for that user from the Graph API. (We needed ",(0,a.kt)("inlineCode",{parentName:"p"},"User.Read.All")," to do this.)")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"In a perfect world, we'd be able to use the ",(0,a.kt)("inlineCode",{parentName:"p"},"AppRoleAssignments")," property on the ",(0,a.kt)("inlineCode",{parentName:"p"},"User")," object to get the app role assignments for a user, but unfortunately that doesn't come with the human readable name you'd hope for; the ",(0,a.kt)("inlineCode",{parentName:"p"},"MyApp.Read"),". So we have to interrogate the Graph API once more and use the ",(0,a.kt)("inlineCode",{parentName:"p"},"Application")," that represents our Azure AD App Registration (we acquire this by filtering for an ",(0,a.kt)("inlineCode",{parentName:"p"},"appId")," matching our ",(0,a.kt)("inlineCode",{parentName:"p"},"clientId"),"). Then we can get the human readable / ",(0,a.kt)("inlineCode",{parentName:"p"},"MyApp.Read")," role assignment.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"It adds the app role assignments as role claims to the ",(0,a.kt)("inlineCode",{parentName:"p"},"ClaimsIdentity")," object.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"It returns the ",(0,a.kt)("inlineCode",{parentName:"p"},"ClaimsIdentity")," object wrapped in a ",(0,a.kt)("inlineCode",{parentName:"p"},"ClaimsPrincipal")," object."))),(0,a.kt)("h2",o({},{id:"using-the-principalservice"}),"Using the ",(0,a.kt)("inlineCode",{parentName:"h2"},"PrincipalService")),(0,a.kt)("p",null,"In order that we can make use of our ",(0,a.kt)("inlineCode",{parentName:"p"},"PrincipalService")," we need to configure it and the ",(0,a.kt)("inlineCode",{parentName:"p"},"AuthenticatedGraphClientFactory")," in our ",(0,a.kt)("inlineCode",{parentName:"p"},"Startup")," class:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),"services.AddTransient<IAuthenticatedGraphClientFactory>(sp =>\n    new AuthenticatedGraphClientFactory(\n        // The parameters can be sourced from the Azure AD App Registration\n        clientId,\n        clientSecret,\n        tenantId\n    ));\n\nservices.AddTransient<IPrincipalService, PrincipalService>();\n")),(0,a.kt)("p",null,"With that in place, we can now use the ",(0,a.kt)("inlineCode",{parentName:"p"},"IPrincipalService")," in a function:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-cs"}),'using System.Linq;\nusing System.Threading.Tasks;\nusing MyApp.Auth;\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Azure.WebJobs;\nusing Microsoft.Azure.WebJobs.Extensions.Http;\n\nnamespace MyApp.Functions\n{\n    public class GetClaimsPrincipalFunction\n    {\n        private readonly IPrincipalService _principalService;\n\n        public GetClaimsPrincipalFunction(\n            IPrincipalService principalService\n        )\n        {\n            _principalService = principalService;\n        }\n\n        [FunctionName(nameof(GetPrincipal))]\n        public async Task<IActionResult> GetPrincipal(\n            [HttpTrigger(AuthorizationLevel.Anonymous, "get", Route = "get-principal")] HttpRequest request\n        )\n        {\n            var principal = await _principalService.GetPrincipal(request);\n            var identity = principal?.Identity;\n            var data = new\n            {\n                Name = identity?.Name ?? "",\n                AuthenticationType = identity?.AuthenticationType ?? "",\n                Claims = principal?.Claims.Select(c => new { c.Type, c.Value }),\n            };\n\n            return new OkObjectResult(data);\n        }\n\n        [FunctionName(nameof(AmIInRole))]\n        public async Task<IActionResult> AmIInRole(\n            [HttpTrigger(AuthorizationLevel.Anonymous, "get", Route = "am-i-in-role")] HttpRequest request\n        )\n        {\n            var role = request.Query["role"].FirstOrDefault();\n\n            if (string.IsNullOrEmpty(role))\n                return new BadRequestObjectResult("role query parameter is required");\n\n            var principal = await _principalService.GetPrincipal(request);\n\n            var isInRole = principal?.IsInRole(role) == true;\n            if (!isInRole)\n                return new ObjectResult($"Forbidden for {role}")\n                {\n                    StatusCode = Status403Forbidden\n                };\n\n            return new OkObjectResult($"Welcome {principal?.Identity?.Name} - you have role {role}!");\n        }\n    }\n}\n')),(0,a.kt)("p",null,"The above class has 2 functions:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"GetPrincipal")," - returns the ",(0,a.kt)("inlineCode",{parentName:"li"},"ClaimsPrincipal")," object as JSON"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"AmIInRole")," - takes a ",(0,a.kt)("inlineCode",{parentName:"li"},"role")," query parameter, tests if a user has that role and returns a 403 if they don't and a 200 with a welcome message if they do")),(0,a.kt)("h3",o({},{id:"getprincipal---what-claims-do-we-have"}),(0,a.kt)("inlineCode",{parentName:"h3"},"GetPrincipal")," - what claims do we have?"),(0,a.kt)("p",null,"Let's try out the ",(0,a.kt)("inlineCode",{parentName:"p"},"GetPrincipal")," function, when I go to the ",(0,a.kt)("inlineCode",{parentName:"p"},"/api/get-principal")," endpoint I see this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "name": "johnny_reilly@hotmail.com",\n  "authenticationType": "aad",\n  "claims": [\n    {\n      "type": "http://schemas.xmlsoap.org/ws/2005/05/identity/claims/nameidentifier",\n      "value": "d9178465-3847-4d98-9d23-b8b9e403b323"\n    },\n    {\n      "type": "http://schemas.xmlsoap.org/ws/2005/05/identity/claims/name",\n      "value": "johnny_reilly@hotmail.com"\n    },\n    {\n      "type": "http://schemas.microsoft.com/ws/2008/06/identity/claims/role",\n      "value": "authenticated"\n    },\n    {\n      "type": "http://schemas.microsoft.com/ws/2008/06/identity/claims/role",\n      "value": "OurApp.Read"\n    }\n  ]\n}\n')),(0,a.kt)("p",null,"This isn't the ",(0,a.kt)("em",{parentName:"p"},"same")," information as the Static Web Apps principal, but it's close enough for our purposes. Crucially, we can see the AppRoleAssignment ",(0,a.kt)("inlineCode",{parentName:"p"},"OurApp.Read")," that we assigned to our user in the Azure Portal. That is the key information that we need, and that we are missing by default."),(0,a.kt)("p",null,"Crucially this is enough information for us to be able to apply authorization to our functions."),(0,a.kt)("h3",o({},{id:"amiinrole---test-isinrole-functionality"}),(0,a.kt)("inlineCode",{parentName:"h3"},"AmIInRole")," - test ",(0,a.kt)("inlineCode",{parentName:"h3"},"IsInRole")," functionality"),(0,a.kt)("p",null,"We can demonstrate applying authorization by using the ",(0,a.kt)("inlineCode",{parentName:"p"},"AmIInRole")," function. This internally uses the inbuilt ",(0,a.kt)("a",o({parentName:"p"},{href:"https://learn.microsoft.com/en-us/dotnet/api/system.security.claims.claimsprincipal.isinrole?view=net-6.0"}),(0,a.kt)("inlineCode",{parentName:"a"},"IsInRole"))," functionality of the ",(0,a.kt)("inlineCode",{parentName:"p"},"ClaimsPrincipal")," object, and returns an appropriate API result accordingly."),(0,a.kt)("p",null,"If I go to the ",(0,a.kt)("inlineCode",{parentName:"p"},"/api/am-i-in-role?role=OurApp.Read")," endpoint I get a 200 status code and the message: ",(0,a.kt)("inlineCode",{parentName:"p"},"Welcome johnny_reilly@hotmail.com - you have role OurApp.Read!"),". This makes sense, my user account has the ",(0,a.kt)("inlineCode",{parentName:"p"},"OurApp.Read")," role."),(0,a.kt)("p",null,"Let's test that we also deny access appropriately. There is an ",(0,a.kt)("inlineCode",{parentName:"p"},"OurApp.Write")," role; my account does not have this. If I go to the ",(0,a.kt)("inlineCode",{parentName:"p"},"/api/am-i-in-role?role=OurApp.Write")," endpoint I get a 403 status code and the message: ",(0,a.kt)("inlineCode",{parentName:"p"},"Forbidden for OurApp.Write"),"."),(0,a.kt)("p",null,"It works!"),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"We've demonstrated a way to acquire a ",(0,a.kt)("inlineCode",{parentName:"p"},"ClaimsPrincipal")," object that contains the AppRoleAssignments for a user. This is enough information for us to be able to apply authorization to our functions."),(0,a.kt)("p",null,"It would be ideal if this wasn't required, and I'm hoping that the Static Web Apps team will be able to provide a solution for this in the future. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/static-web-apps/issues/988"}),"Keep an eye on this GitHub issue.")," In the meantime, this is a workable solution."),(0,a.kt)("p",null,"Thanks to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/warrenandre"}),"Warren Joubert")," for his help with this post."))}d.isMDXComponent=!0},41185:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"xml-read-and-write-with-node-js",title:"XML: read and write with Node.js",authors:"johnnyreilly",tags:["XML","Node.js","Docusaurus"],image:"./title-image.png",description:"This post demonstrates reading and writing XML in Node.js using fast-xml-parser. We will use the Docusauruses XML sitemap as an example.",hide_table_of_contents:!1},s=void 0,l={permalink:"/xml-read-and-write-with-node-js",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-11-22-xml-read-and-write-with-node-js/index.md",source:"@site/blog/2022-11-22-xml-read-and-write-with-node-js/index.md",title:"XML: read and write with Node.js",description:"This post demonstrates reading and writing XML in Node.js using fast-xml-parser. We will use the Docusauruses XML sitemap as an example.",date:"2022-11-22T00:00:00.000Z",formattedDate:"November 22, 2022",tags:[{label:"XML",permalink:"/tags/xml"},{label:"Node.js",permalink:"/tags/node-js"},{label:"Docusaurus",permalink:"/tags/docusaurus"}],readingTime:5.62,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"xml-read-and-write-with-node-js",title:"XML: read and write with Node.js",authors:"johnnyreilly",tags:["XML","Node.js","Docusaurus"],image:"./title-image.png",description:"This post demonstrates reading and writing XML in Node.js using fast-xml-parser. We will use the Docusauruses XML sitemap as an example.",hide_table_of_contents:!1},prevItem:{title:"Adding lastmod to sitemap based on git commits",permalink:"/adding-lastmod-to-sitemap-git-commit-date"},nextItem:{title:"Azure AD Claims with Static Web Apps and Azure Functions",permalink:"/azure-ad-claims-static-web-apps-azure-functions"}},p={image:n(31250).Z,authorsImageUrls:[void 0]},u=[{value:"Docusaurus sitemap",id:"docusaurus-sitemap",level:2},{value:"<code>fast-xml-parser</code>",id:"fast-xml-parser",level:2},{value:"Reading XML",id:"reading-xml",level:2},{value:"Filtering and writing XML",id:"filtering-and-writing-xml",level:2},{value:"Conclusion",id:"conclusion",level:2},{value:"PS <code>noindex</code>",id:"ps-noindex",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This post demonstrates reading and writing XML in Node.js using ",(0,a.kt)("inlineCode",{parentName:"p"},"fast-xml-parser"),". We'll use the Docusauruses XML sitemap as an example."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;XML: read and write with Node.js&quot; with XML and Docusaurus logos",src:n(31250).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"docusaurus-sitemap"}),"Docusaurus sitemap"),(0,a.kt)("p",null,"I was prompted to write this post by wanting to edit the sitemap on my Docusaurus blog. I wanted to remove the ",(0,a.kt)("inlineCode",{parentName:"p"},"/page/")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"/tag/")," routes from the sitemap. They effectively serve as duplicate content and I don't want them to be indexed by search engines. (A little more is required to remove them from search engines - see the section at the end of the post.)"),(0,a.kt)("p",null,"I was able to find the sitemap in the ",(0,a.kt)("inlineCode",{parentName:"p"},"build")," folder of my Docusaurus site. It's called ",(0,a.kt)("inlineCode",{parentName:"p"},"sitemap.xml")," and it's in the root of the ",(0,a.kt)("inlineCode",{parentName:"p"},"build")," folder. It looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<?xml version="1.0" encoding="UTF-8"?><urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9" xmlns:news="http://www.google.com/schemas/sitemap-news/0.9" xmlns:xhtml="http://www.w3.org/1999/xhtml" xmlns:image="http://www.google.com/schemas/sitemap-image/1.1" xmlns:video="http://www.google.com/schemas/sitemap-video/1.1">\n  <url>\n    <loc>https://blog.johnnyreilly.com/2012/01/07/standing-on-shoulders-of-giants</loc>\n    <changefreq>weekly</changefreq>\n    <priority>0.5</priority>\n  </url>\n  <url>\n    <loc>https://blog.johnnyreilly.com/2022/09/20/react-usesearchparamsstate</loc>\n    <changefreq>weekly</changefreq>\n    <priority>0.5</priority>\n  </url>\n  <url>\n    <loc>https://blog.johnnyreilly.com/page/10</loc>\n    <changefreq>weekly</changefreq>\n    <priority>0.5</priority>\n  </url>\n  <url>\n    <loc>https://blog.johnnyreilly.com/tags/ajax</loc>\n    <changefreq>weekly</changefreq>\n    <priority>0.5</priority>\n  </url>\n  \x3c!-- ... --\x3e\n</urlset>\n')),(0,a.kt)("h2",o({},{id:"fast-xml-parser"}),(0,a.kt)("inlineCode",{parentName:"h2"},"fast-xml-parser")),(0,a.kt)("p",null,"After experimenting with a few different XML parsers I settled on ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/NaturalIntelligence/fast-xml-parser"}),(0,a.kt)("inlineCode",{parentName:"a"},"fast-xml-parser")),". It's fast, it's simple and it's well maintained. It also handles XML namespaces and attributes well. (This appears to be rare in XML parsers.)"),(0,a.kt)("p",null,"Let's scaffold up an example project alongside our Docusaurus site:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"mkdir trim-xml\ncd trim-xml\nnpx typescript --init\nyarn init\nyarn add @types/node fast-xml-parser ts-node typescript\n")),(0,a.kt)("p",null,"And in the ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," file add a ",(0,a.kt)("inlineCode",{parentName:"p"},"start")," script:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "scripts": {\n    "start": "ts-node index.ts"\n  }\n}\n')),(0,a.kt)("p",null,"Finally, create an empty ",(0,a.kt)("inlineCode",{parentName:"p"},"index.ts")," file."),(0,a.kt)("h2",o({},{id:"reading-xml"}),"Reading XML"),(0,a.kt)("p",null,"Our Docusaurus sitemap is in the ",(0,a.kt)("inlineCode",{parentName:"p"},"build")," folder of our Docusaurus site. Let's read it in and parse it into a JavaScript object:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { XMLParser, XMLBuilder } from 'fast-xml-parser';\nimport fs from 'fs';\nimport path from 'path';\n\ninterface Sitemap {\n  urlset: {\n    url: { loc: string; changefreq: string; priority: number }[];\n  };\n}\n\nasync function trimXML() {\n  const sitemapPath = path.resolve(\n    '..',\n    'blog-website',\n    'build',\n    'sitemap.xml'\n  );\n\n  console.log(`Loading ${sitemapPath}`);\n  const sitemapXml = await fs.promises.readFile(sitemapPath, 'utf8');\n\n  const parser = new XMLParser({\n    ignoreAttributes: false,\n  });\n  let sitemap: Sitemap = parser.parse(sitemapXml);\n\n  console.log(sitemap);\n}\n\ntrimXML();\n")),(0,a.kt)("p",null,"We're using the ",(0,a.kt)("inlineCode",{parentName:"p"},"XMLParser")," class to parse the XML into a JavaScript object. We're also using the ",(0,a.kt)("inlineCode",{parentName:"p"},"ignoreAttributes")," option to ensure that attributes are included in the parsed object. When we run this we get the following output:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"Loading /home/john/code/github/blog.johnnyreilly.com/blog-website/build/sitemap.xml\n{\n  '?xml': { '@_version': '1.0', '@_encoding': 'UTF-8' },\n  urlset: {\n    url: [\n      [Object], [Object], [Object], [Object], [Object], [Object],\n      [Object], [Object], [Object], [Object], [Object], [Object],\n      [Object], [Object], [Object], [Object], [Object], [Object],\n      [Object], [Object], [Object], [Object], [Object], [Object],\n      [Object], [Object], [Object], [Object], [Object], [Object],\n      [Object], [Object], [Object], [Object], [Object], [Object],\n      [Object], [Object], [Object], [Object], [Object], [Object],\n      [Object], [Object], [Object], [Object], [Object], [Object],\n      [Object], [Object], [Object], [Object], [Object], [Object],\n      [Object], [Object], [Object], [Object], [Object], [Object],\n      [Object], [Object], [Object], [Object], [Object], [Object],\n      [Object], [Object], [Object], [Object], [Object], [Object],\n      [Object], [Object], [Object], [Object], [Object], [Object],\n      [Object], [Object], [Object], [Object], [Object], [Object],\n      [Object], [Object], [Object], [Object], [Object], [Object],\n      [Object], [Object], [Object], [Object], [Object], [Object],\n      [Object], [Object], [Object], [Object],\n      ... 1481 more items\n    ],\n    '@_xmlns': 'http://www.sitemaps.org/schemas/sitemap/0.9',\n    '@_xmlns:news': 'http://www.google.com/schemas/sitemap-news/0.9',\n    '@_xmlns:xhtml': 'http://www.w3.org/1999/xhtml',\n    '@_xmlns:image': 'http://www.google.com/schemas/sitemap-image/1.1',\n    '@_xmlns:video': 'http://www.google.com/schemas/sitemap-video/1.1'\n  }\n}\n")),(0,a.kt)("p",null,"As we can see, the ",(0,a.kt)("inlineCode",{parentName:"p"},"fast-xml-parser")," library has parsed the XML into a JavaScript object. We can see that the ",(0,a.kt)("inlineCode",{parentName:"p"},"urlset")," element has an array of ",(0,a.kt)("inlineCode",{parentName:"p"},"url")," elements. Each ",(0,a.kt)("inlineCode",{parentName:"p"},"url")," element has a ",(0,a.kt)("inlineCode",{parentName:"p"},"loc"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"changefreq")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"priority")," element. We can also see that the ",(0,a.kt)("inlineCode",{parentName:"p"},"urlset")," element has a number of attributes. This matches the XML we saw earlier and the interface we defined."),(0,a.kt)("h2",o({},{id:"filtering-and-writing-xml"}),"Filtering and writing XML"),(0,a.kt)("p",null,"Now that we have the XML parsed into a JavaScript object we can filter it just like we would any other JavaScript object. We have all the power of JavaScript at our fingertips!"),(0,a.kt)("p",null,'As I mentioned earlier, I want to remove all the URLs that represent duplicate content. This includes "pagination" URLs. These are URLs that are used to navigate between pages of content. For example, the URL ',(0,a.kt)("inlineCode",{parentName:"p"},"https://blog.johnnyreilly.com/page/10"),' is a pagination URL. I want to remove these URLs from the sitemap. I also want to get rid of the "tags" URLs. These are URLs that are used to navigate between posts that have a particular tag. For example, the URL ',(0,a.kt)("inlineCode",{parentName:"p"},"https://blog.johnnyreilly.com/tags/ajax")," is a tag URL. I want to remove these URLs from the sitemap too."),(0,a.kt)("p",null,"This is simplicity itself now we're in JavaScript land. We can use the ",(0,a.kt)("inlineCode",{parentName:"p"},"filter")," method on the ",(0,a.kt)("inlineCode",{parentName:"p"},"url")," array to remove the URLs we don't want:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const rootUrl = 'https://blog.johnnyreilly.com';\nconst filteredUrls = sitemap.urlset.url.filter(\n  (url) =>\n    url.loc !== `${rootUrl}/tags` &&\n    !url.loc.startsWith(rootUrl + '/tags/') &&\n    !url.loc.startsWith(rootUrl + '/page/')\n);\n")),(0,a.kt)("p",null,"We can then update the ",(0,a.kt)("inlineCode",{parentName:"p"},"url")," array with the filtered URLs:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"sitemap.urlset.url = filteredUrls;\n")),(0,a.kt)("p",null,"Finally, we can write the XML back out to a file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const builder = new XMLBuilder({\n  ignoreAttributes: false,\n});\nconst xml = builder.buildObject(sitemap);\n\nconst outputPath = path.resolve('sitemap.xml');\nawait fs.promises.writeFile(outputPath, xml);\n")),(0,a.kt)("p",null,"Note again that we're using the ",(0,a.kt)("inlineCode",{parentName:"p"},"ignoreAttributes")," option to ensure that attributes are included in the XML."),(0,a.kt)("p",null,"Let's put it all together into a single file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { XMLParser, XMLBuilder } from 'fast-xml-parser';\nimport fs from 'fs';\nimport path from 'path';\n\ninterface Sitemap {\n  urlset: {\n    url: { loc: string; changefreq: string; priority: number }[];\n  };\n}\n\nasync function trimXML() {\n  const sitemapPath = path.resolve(\n    '..',\n    'blog-website',\n    'build',\n    'sitemap.xml'\n  );\n\n  console.log(`Loading ${sitemapPath}`);\n  const sitemapXml = await fs.promises.readFile(sitemapPath, 'utf8');\n\n  const parser = new XMLParser({\n    ignoreAttributes: false,\n  });\n  let sitemap: Sitemap = parser.parse(sitemapXml);\n\n  const rootUrl = 'https://blog.johnnyreilly.com';\n  const filteredUrls = sitemap.urlset.url.filter(\n    (url) =>\n      url.loc !== `${rootUrl}/tags` &&\n      !url.loc.startsWith(rootUrl + '/tags/') &&\n      !url.loc.startsWith(rootUrl + '/page/')\n  );\n\n  console.log(\n    `Reducing ${sitemap.urlset.url.length} urls to ${filteredUrls.length} urls`\n  );\n\n  sitemap.urlset.url = filteredUrls;\n\n  const builder = new XMLBuilder({ format: false, ignoreAttributes: false });\n  const shorterSitemapXml = builder.build(sitemap);\n\n  console.log(`Saving ${sitemapPath}`);\n  await fs.promises.writeFile(sitemapPath, shorterSitemapXml);\n}\n\ntrimXML();\n")),(0,a.kt)("p",null,"With that we're done. We can run the script and see the result:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"Loading /github/workspace/blog-website/build/sitemap.xml\nReducing 1598 urls to 281 urls\nSaving /github/workspace/blog-website/build/sitemap.xml\n")),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"In this post we've seen how to use the ",(0,a.kt)("inlineCode",{parentName:"p"},"fast-xml-parser")," library to parse XML into a JavaScript object, operate upon that object and then write it back out to XML."),(0,a.kt)("p",null,"If you'd to see how I'm using this directly on my blog, it's probably worth looking at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/pull/344"}),"this PR"),"."),(0,a.kt)("h2",o({},{id:"ps-noindex"}),"PS ",(0,a.kt)("inlineCode",{parentName:"h2"},"noindex")),(0,a.kt)("p",null,"This is unrelated to XML processing, but I didn't want to miss this out. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/search/docs/crawling-indexing/remove-information"}),"Merely editing the sitemap isn't enough to remove them from search engines"),". We're also going to serve a ",(0,a.kt)("inlineCode",{parentName:"p"},"noindex")," response header for those routes by adjusting the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://learn.microsoft.com/en-us/azure/static-web-apps/configuration"}),(0,a.kt)("inlineCode",{parentName:"a"},"staticwebapp.config.json")," file of our Static Web App"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  // ...\n  "routes": [\n    // ...\n    {\n      "route": "/tags/*",\n      "headers": {\n        "X-Robots-Tag": "noindex"\n      }\n    },\n    {\n      "route": "/page/*",\n      "headers": {\n        "X-Robots-Tag": "noindex"\n      }\n    }\n  ]\n  // ...\n}\n')))}d.isMDXComponent=!0},19969:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"adding-lastmod-to-sitemap-git-commit-date",title:"Adding lastmod to sitemap based on git commits",authors:"johnnyreilly",tags:["Node.js","Docusaurus"],image:"./title-image.png",description:"This post demonstrates enriching an XML sitemap with `lastmod` timestamps based on git commits.",hide_table_of_contents:!1},s=void 0,l={permalink:"/adding-lastmod-to-sitemap-git-commit-date",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-11-25-adding-lastmod-to-sitemap-git-commit-date/index.md",source:"@site/blog/2022-11-25-adding-lastmod-to-sitemap-git-commit-date/index.md",title:"Adding lastmod to sitemap based on git commits",description:"This post demonstrates enriching an XML sitemap with `lastmod` timestamps based on git commits.",date:"2022-11-25T00:00:00.000Z",formattedDate:"November 25, 2022",tags:[{label:"Node.js",permalink:"/tags/node-js"},{label:"Docusaurus",permalink:"/tags/docusaurus"}],readingTime:3.415,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"adding-lastmod-to-sitemap-git-commit-date",title:"Adding lastmod to sitemap based on git commits",authors:"johnnyreilly",tags:["Node.js","Docusaurus"],image:"./title-image.png",description:"This post demonstrates enriching an XML sitemap with `lastmod` timestamps based on git commits.",hide_table_of_contents:!1},prevItem:{title:"Docusaurus: Using fontaine to reduce custom font cumulative layout shift",permalink:"/docusaurus-using-fontaine-to-reduce-custom-font-cumulative-layout-shift"},nextItem:{title:"XML: read and write with Node.js",permalink:"/xml-read-and-write-with-node-js"}},p={image:n(49716).Z,authorsImageUrls:[void 0]},u=[{value:"Reading git log in Node.js",id:"reading-git-log-in-nodejs",level:2},{value:"From sitemap to git log",id:"from-sitemap-to-git-log",level:2},{value:"GitHub Actions - <code>fetch_depth</code>",id:"github-actions---fetch_depth",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This post demonstrates enriching an XML sitemap with ",(0,a.kt)("inlineCode",{parentName:"p"},"lastmod")," timestamps based on git commits."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Adding lastmod to sitemap based on git commits&quot; with XML and Docusaurus logos",src:n(49716).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"reading-git-log-in-nodejs"}),"Reading git log in Node.js"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"/xml-read-and-write-with-node-js"}),"In the last post I showed how to manipulate XML in Node.js, and filter our sitemap"),". In this post we'll build upon what we did last time, read the git log in Node.js and use that to power a ",(0,a.kt)("inlineCode",{parentName:"p"},"lastmod")," property."),(0,a.kt)("p",null,"To read the git log in Node.js we'll use the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/simple-git"}),"simple-git")," package. It's a great package that makes it easy to read the git log. Other stuff too - but that's what we care about today."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-shell"}),"yarn add simple-git\n")),(0,a.kt)("p",null,"To work with ",(0,a.kt)("inlineCode",{parentName:"p"},"simple-git")," we need to create a ",(0,a.kt)("inlineCode",{parentName:"p"},"Git")," instance. We can do that like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { simpleGit, SimpleGit, SimpleGitOptions } from 'simple-git';\n\nfunction getSimpleGit(): SimpleGit {\n  const baseDir = path.resolve(process.cwd(), '..');\n\n  const options: Partial<SimpleGitOptions> = {\n    baseDir,\n    binary: 'git',\n    maxConcurrentProcesses: 6,\n    trimmed: false,\n  };\n\n  const git = simpleGit(options);\n\n  return git;\n}\n")),(0,a.kt)("h2",o({},{id:"from-sitemap-to-git-log"}),"From sitemap to git log"),(0,a.kt)("p",null,"It's worth pausing to consider what our sitemap looks like:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<?xml version="1.0" encoding="UTF-8"?><urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9" xmlns:news="http://www.google.com/schemas/sitemap-news/0.9" xmlns:xhtml="http://www.w3.org/1999/xhtml" xmlns:image="http://www.google.com/schemas/sitemap-image/1.1" xmlns:video="http://www.google.com/schemas/sitemap-video/1.1">\n  <url>\n    <loc>https://blog.johnnyreilly.com/2012/01/07/standing-on-shoulders-of-giants</loc>\n    <changefreq>weekly</changefreq>\n    <priority>0.5</priority>\n  </url>\n  <url>\n    <loc>https://blog.johnnyreilly.com/2022/09/20/react-usesearchparamsstate</loc>\n    <changefreq>weekly</changefreq>\n    <priority>0.5</priority>\n  </url>\n  \x3c!-- ... --\x3e\n</urlset>\n')),(0,a.kt)("p",null,"If you look at the URL (",(0,a.kt)("inlineCode",{parentName:"p"},"loc"),") you can see that it's fairly easy to determine the path to the original markdown file. If we take ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.johnnyreilly.com/2012/01/07/standing-on-shoulders-of-giants"}),"https://blog.johnnyreilly.com/2012/01/07/standing-on-shoulders-of-giants"),", we can see that the path to the markdown file is ",(0,a.kt)("inlineCode",{parentName:"p"},"blog-website/blog/2012-01-07-standing-on-shoulders-of-giants/index.md"),"."),(0,a.kt)("p",null,"As long as we don't have a custom slug in play (and I rarely do), we have a reliable way to get from blog post URL (",(0,a.kt)("inlineCode",{parentName:"p"},"loc"),") to markdown file. With that we can use ",(0,a.kt)("inlineCode",{parentName:"p"},"simple-git")," to get the git log for that file. We can then use that to populate the ",(0,a.kt)("inlineCode",{parentName:"p"},"lastmod")," property."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const dateBlogUrlRegEx = /(\\d\\d\\d\\d\\/\\d\\d\\/\\d\\d)\\/(.+)/;\n\nasync function enrichUrlsWithLastmod(\n  filteredUrls: SitemapUrl[]\n): Promise<SitemapUrl[]> {\n  const git = getSimpleGit();\n\n  const urls: SitemapUrl[] = [];\n  for (const url of filteredUrls) {\n    if (urls.includes(url)) {\n      continue;\n    }\n\n    try {\n      // example url.loc: https://blog.johnnyreilly.com/2012/01/07/standing-on-shoulders-of-giants\n      const pathWithoutRootUrl = url.loc.replace(rootUrl + '/', ''); // eg 2012/01/07/standing-on-shoulders-of-giants\n\n      const match = pathWithoutRootUrl.match(dateBlogUrlRegEx);\n\n      if (!match || !match[1] || !match[2]) {\n        urls.push(url);\n        continue;\n      }\n\n      const date = match[1].replaceAll('/', '-'); // eg 2012-01-07\n      const slug = match[2]; // eg standing-on-shoulders-of-giants\n\n      const file = `blog-website/blog/${date}-${slug}/index.md`;\n      const log = await git.log({\n        file,\n      });\n\n      const lastmod = log.latest?.date.substring(0, 10);\n      urls.push(lastmod ? { ...url, lastmod } : url);\n      console.log(url.loc, lastmod);\n    } catch (e) {\n      console.log('file date not looked up', url.loc, e);\n      urls.push(url);\n    }\n  }\n  return urls;\n}\n")),(0,a.kt)("p",null,"Above we're using a regular expression to extract the date and slug from the URL. We then use those to construct the path to the markdown file. We then use ",(0,a.kt)("inlineCode",{parentName:"p"},"simple-git")," to get the git log for that file. We then use the latest commit date to populate the ",(0,a.kt)("inlineCode",{parentName:"p"},"lastmod")," property, and push that onto the ",(0,a.kt)("inlineCode",{parentName:"p"},"urls")," array."),(0,a.kt)("p",null,"Finally we return the ",(0,a.kt)("inlineCode",{parentName:"p"},"urls")," array and write that to the sitemap before we write it out:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"sitemap.urlset.url = await enrichUrlsWithLastmod(filteredUrls);\n")),(0,a.kt)("p",null,"Our new sitemap looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-xml"}),'<?xml version="1.0" encoding="UTF-8"?><urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9" xmlns:news="http://www.google.com/schemas/sitemap-news/0.9" xmlns:xhtml="http://www.w3.org/1999/xhtml" xmlns:image="http://www.google.com/schemas/sitemap-image/1.1" xmlns:video="http://www.google.com/schemas/sitemap-video/1.1">\n  <url>\n    <loc>https://blog.johnnyreilly.com/2012/01/07/standing-on-shoulders-of-giants</loc>\n    <changefreq>weekly</changefreq>\n    <priority>0.5</priority>\n    <lastmod>2021-12-19</lastmod>\n  </url>\n  <url>\n    <loc>https://blog.johnnyreilly.com/2012/01/14/jqgrid-its-just-far-better-grid</loc>\n    <changefreq>weekly</changefreq>\n    <priority>0.5</priority>\n    <lastmod>2022-11-03</lastmod>\n  </url>\n  \x3c!-- ... --\x3e\n</urlset>\n')),(0,a.kt)("p",null,"You see the ",(0,a.kt)("inlineCode",{parentName:"p"},"lastmod")," property has been populated for URLs based upon the most recent commit for that file. Yay!"),(0,a.kt)("h2",o({},{id:"github-actions---fetch_depth"}),"GitHub Actions - ",(0,a.kt)("inlineCode",{parentName:"h2"},"fetch_depth")),(0,a.kt)("p",null,"You might think we were done (I thought we were done), but we're not. We're not done because we're using GitHub Actions to build the site."),(0,a.kt)("p",null,"When I tested this locally, it worked fine. However, when I pushed it to GitHub Actions, it surfaced a ",(0,a.kt)("inlineCode",{parentName:"p"},"latest.date")," which wasn't populated with the value you'd hope. The reason was that the ",(0,a.kt)("inlineCode",{parentName:"p"},"fetch_depth")," was set to 1 (the default). This meant that the git log wasn't providing the information we'd hope for. By changing the ",(0,a.kt)("inlineCode",{parentName:"p"},"fetch_depth")," to 0 the situation is resolved."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),"- uses: actions/checkout@v3\n  with:\n    # Number of commits to fetch. 0 indicates all history for all branches and tags.\n    # Default: 1\n    fetch-depth: 0\n")))}d.isMDXComponent=!0},84119:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"docusaurus-using-fontaine-to-reduce-custom-font-cumulative-layout-shift",title:"Docusaurus: Using fontaine to reduce custom font cumulative layout shift",authors:"johnnyreilly",tags:["Docusaurus"],image:"./title-image.png",description:'Custom font usage can introduce cumulative layout shift (or "jank") to your website. This post shows how to use fontaine to reduce this with Docusaurus sites.',hide_table_of_contents:!1},s=void 0,l={permalink:"/docusaurus-using-fontaine-to-reduce-custom-font-cumulative-layout-shift",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-12-01-docusaurus-using-fontaine-to-reduce-custom-font-cumulative-layout-shift/index.md",source:"@site/blog/2022-12-01-docusaurus-using-fontaine-to-reduce-custom-font-cumulative-layout-shift/index.md",title:"Docusaurus: Using fontaine to reduce custom font cumulative layout shift",description:'Custom font usage can introduce cumulative layout shift (or "jank") to your website. This post shows how to use fontaine to reduce this with Docusaurus sites.',date:"2022-12-01T00:00:00.000Z",formattedDate:"December 1, 2022",tags:[{label:"Docusaurus",permalink:"/tags/docusaurus"}],readingTime:5.055,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"docusaurus-using-fontaine-to-reduce-custom-font-cumulative-layout-shift",title:"Docusaurus: Using fontaine to reduce custom font cumulative layout shift",authors:"johnnyreilly",tags:["Docusaurus"],image:"./title-image.png",description:'Custom font usage can introduce cumulative layout shift (or "jank") to your website. This post shows how to use fontaine to reduce this with Docusaurus sites.',hide_table_of_contents:!1},prevItem:{title:"Deep linking with Azure Static Web Apps and Easy Auth",permalink:"/azure-static-web-apps-easyauth-deeplink"},nextItem:{title:"Adding lastmod to sitemap based on git commits",permalink:"/adding-lastmod-to-sitemap-git-commit-date"}},p={image:n(54592).Z,authorsImageUrls:[void 0]},u=[{value:"What is cumulative layout shift?",id:"what-is-cumulative-layout-shift",level:2},{value:"What &quot;jank&quot; looks like",id:"what-jank-looks-like",level:2},{value:"fontaine",id:"fontaine",level:2},{value:"Using fontaine with Docusaurus",id:"using-fontaine-with-docusaurus",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,'Custom font usage can introduce cumulative layout shift (or "jank") to your website. This post shows how to use ',(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/unjs/fontaine"}),"fontaine")," to reduce this with Docusaurus sites."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Docusaurus: Using fontaine to reduce custom font cumulative layout shift&quot; in a ridiculous font with the Docusaurus logo and a screenshot of a preload link HTML element",src:n(54592).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"what-is-cumulative-layout-shift"}),"What is cumulative layout shift?"),(0,a.kt)("p",null,"Cumulative layout shift (CLS) is a metric that measures the instability of content on a web page. It's a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://web.dev/vitals/"}),"Core Web Vitals")," metric."),(0,a.kt)("p",null,"You may well know it as \"jank\". It's jank that you see when a page loads and the text moves around. It's an irritation. There's a great description of it in ",(0,a.kt)("a",o({parentName:"p"},{href:"https://web.dev/cls/"}),"this post on the topic"),"; let me quote it here:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Have you ever been reading an article online when something suddenly changes on the page? Without warning, the text moves, and you've lost your place. Or even worse: you're about to tap a link or a button, but in the instant before your finger lands\u2014BOOM\u2014the link moves, and you end up clicking something else!")),(0,a.kt)("p",null,"For the rest of this post I'll generally to refer to CLS as jank, as it's a more relatable term."),(0,a.kt)("h2",o({},{id:"what-jank-looks-like"}),'What "jank" looks like'),(0,a.kt)("p",null,"My blog uses a custom font called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://fonts.google.com/specimen/Poppins"}),"Poppins"),". Lovely though it is, using the font introduces jank to my site. It's particularly noticeable on mobile phones. Here's a gif of the jank in action:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A gif of the mobile view of my blog loading and shifting in layout as the custom font arrives",src:n(76230).Z,width:"862",height:"904"})),(0,a.kt)("p",null,"You see how the text shifts around as the custom font arrives? On the first line we either see:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"the fallback font rendering four words on one line: ",(0,a.kt)("em",{parentName:"p"},'"Bicep: Static Web Apps"')),(0,a.kt)("p",{parentName:"li"},"OR")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"the custom font (Poppins) rendering three words on one line: ",(0,a.kt)("em",{parentName:"p"},'"Bicep: Static Web"')))),(0,a.kt)("p",null,"It's very noticeable. You can actually put a number on it. The number is the CLS score which you can determine with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.chrome.com/docs/lighthouse/overview/"}),"Lighthouse"),". The CLS score is the sum of the layout shifts that occur on the page. The higher the score, the more jank there is. Cumulative Layout Shift was logged as ",(0,a.kt)("strong",{parentName:"p"},"0.019")," for the page above. That's not great."),(0,a.kt)("p",null,"I'd taken steps to reduce the issues experienced, such as ",(0,a.kt)("a",o({parentName:"p"},{href:"/preload-fonts-with-docusaurus"}),"font preloading"),". But the issues still remained, particularly on mobile networks where speed of loading is decreased, and it takes a longer time for the custom font to load."),(0,a.kt)("p",null,"I had rather given up on improving things further. But then...."),(0,a.kt)("h2",o({},{id:"fontaine"}),"fontaine"),(0,a.kt)("p",null,"One evening I was vaguely browsing Twitter when I came across a tweet from ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/danielcroe"}),"Daniel Roe")," which ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/danielcroe/status/1581428654479138817"}),"announced a new tool called fontaine"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of tweet saying: &quot;\u26a1\ufe0f Announcing `fontaine`! It&#39;s a zero-runtime, cross-framework library that significantly &amp; automatically reduces layout shift caused by custom fonts.&quot;",src:n(37389).Z,width:"909",height:"1344"})),(0,a.kt)("p",null,"I was intrigued. I wanted to try it out. I wanted to see if it could reduce the jank on my blog."),(0,a.kt)("h2",o({},{id:"using-fontaine-with-docusaurus"}),"Using fontaine with Docusaurus"),(0,a.kt)("p",null,"I added fontaine as a dependency to my blog:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"yarn add -D fontaine\n")),(0,a.kt)("p",null,"I then added cracked open my ",(0,a.kt)("inlineCode",{parentName:"p"},"docusaurus.config.js")," file and wrote a small plugin to make use of fontaine:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const fontaine = require('fontaine');\n\n// ...\n\n/** @type {import('@docusaurus/types').Config} */\nconst config = {\n  // ...\n\n  plugins: [\n    // ...\n    function fontainePlugin(_context, _options) {\n      return {\n        name: 'fontaine-plugin',\n        configureWebpack(_config, _isServer) {\n          return {\n            plugins: [\n              fontaine.fontaineTransform.webpack({\n                fallbacks: [\n                  'system-ui',\n                  '-apple-system',\n                  'BlinkMacSystemFont',\n                  'Segoe UI',\n                  'Roboto',\n                  'Oxygen',\n                  'Ubuntu',\n                  'Cantarell',\n                  'Open Sans',\n                  'Helvetica Neue',\n                  'sans-serif',\n                ],\n                // You may need to resolve assets like `/fonts/Poppins-Bold.ttf` to a particular directory\n                resolvePath: (id) => '../fonts/' + id,\n              }),\n            ],\n          };\n        },\n      };\n    },\n    // ...\n  ],\n  // ...\n};\n")),(0,a.kt)("p",null,"This didn't initially seem to make any difference. I put it up as a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/pull/305"}),"work-in-progress PR")," and wrote up my findings as best I could. Daniel was kind enough to take a look. He uncovered two issues:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"There was a bug in fontaine around how it handled CSS variables; ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/unjs/fontaine/commit/a708bb07ccc48f385c67ccc3b1eed280d8ee47fc"}),"he implemented a fix")),(0,a.kt)("li",{parentName:"ul"},"Docusaurus uses custom fonts through the mechanism of CSS variables. This indirection confuses fontaine as it can't read those variables. To accomodate this, we needed to update my CSS variable to add the override font family to the CSS variable:")),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),"-  --ifm-font-family-base: 'Poppins';\n+  --ifm-font-family-base: 'Poppins', 'Poppins override';\n")),(0,a.kt)("p",null,"Behind the scenes, there is a 'Poppins override' ",(0,a.kt)("inlineCode",{parentName:"p"},"@font-face")," rule that has been created by fontaine. By manually adding this override font family to our CSS variable, we make our site use the fallback 'Poppins override' ",(0,a.kt)("inlineCode",{parentName:"p"},"@font-face")," rule with the correct font metrics that fontaine generates."),(0,a.kt)("p",null,"It's worth emphasising that for the typical user of fontaine, this is not something they need to do. It's only necessary for Docusaurus users because they use custom fonts through CSS variables. Using fontaine is very \"plug and play\" for most users."),(0,a.kt)("p",null,"Daniel was kind enough to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/pull/307"}),"raise a PR incorporating both the tweaks"),". When I merged that PR, I saw the following:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"A gif of the mobile view of my blog loading and shifting in layout as the custom font arrives",src:n(36078).Z,width:"862",height:"904"})),(0,a.kt)("p",null,"Look at that! You can see the font loading, but there's no more jumping of words from one line to another. It's a huge improvement."),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"If you want to improve your CLS score, fontaine is a great tool. This post demonstrates using it with Docusaurus. But please note that this is a generally useful tool that you can use with Vite, Next.js and others. It's not specific to Docusaurus."),(0,a.kt)("p",null,"Prior to using fontaine, my blogs Cumulative Layout Shift was logged as ",(0,a.kt)("strong",{parentName:"p"},"0.019"),". After incorporating it, the same score is logged as ",(0,a.kt)("strong",{parentName:"p"},"0"),". This is good news!"),(0,a.kt)("p",null,"I'm very grateful to Daniel for his help in getting it working with my blog. He went above and beyond, so thank you Daniel!"),(0,a.kt)("p",null,"In testament to what a great idea fontaine is built upon, in the time I've been writing this post ",(0,a.kt)("a",o({parentName:"p"},{href:"https://nextjs.org/blog/next-13#nextfont"}),(0,a.kt)("inlineCode",{parentName:"a"},"@next/font"))," has been announced, which is based upon a similar idea."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/docusaurus-using-fontaine-reduce-cumulative-layout-shift/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/docusaurus-using-fontaine-reduce-cumulative-layout-shift/"})))}d.isMDXComponent=!0},26529:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-static-web-apps-easyauth-deeplink",title:"Deep linking with Azure Static Web Apps and Easy Auth",authors:"johnnyreilly",tags:["authorization","Easy Auth","Azure Static Web Apps","Azure AD"],image:"./title-image.png",description:"Azure Static Web Apps does not support deep linking with authentication. This post describes how to work around this limitation.",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-static-web-apps-easyauth-deeplink",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-12-04-azure-static-web-apps-easyauth-deeplink/index.md",source:"@site/blog/2022-12-04-azure-static-web-apps-easyauth-deeplink/index.md",title:"Deep linking with Azure Static Web Apps and Easy Auth",description:"Azure Static Web Apps does not support deep linking with authentication. This post describes how to work around this limitation.",date:"2022-12-04T00:00:00.000Z",formattedDate:"December 4, 2022",tags:[{label:"authorization",permalink:"/tags/authorization"},{label:"Easy Auth",permalink:"/tags/easy-auth"},{label:"Azure Static Web Apps",permalink:"/tags/azure-static-web-apps"},{label:"Azure AD",permalink:"/tags/azure-ad"}],readingTime:6.27,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-static-web-apps-easyauth-deeplink",title:"Deep linking with Azure Static Web Apps and Easy Auth",authors:"johnnyreilly",tags:["authorization","Easy Auth","Azure Static Web Apps","Azure AD"],image:"./title-image.png",description:"Azure Static Web Apps does not support deep linking with authentication. This post describes how to work around this limitation.",hide_table_of_contents:!1},prevItem:{title:"Publishing Docusaurus to dev.to with the dev.to API",permalink:"/publishing-docusaurus-to-devto-with-devto-api"},nextItem:{title:"Docusaurus: Using fontaine to reduce custom font cumulative layout shift",permalink:"/docusaurus-using-fontaine-to-reduce-custom-font-cumulative-layout-shift"}},p={image:n(9532).Z,authorsImageUrls:[void 0]},u=[{value:"Updated 1st March 2023",id:"updated-1st-march-2023",level:2},{value:"Deep linking",id:"deep-linking",level:2},{value:"The workaround",id:"the-workaround",level:2},{value:"The implementation",id:"the-implementation",level:2},{value:"Announcing <code>easyauth-deeplink</code>",id:"announcing-easyauth-deeplink",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Azure Static Web Apps doesn't support deep linking with authentication. The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://learn.microsoft.com/en-us/azure/static-web-apps/authentication-authorization?tabs=invitations#post-login-redirect"}),"post login redirect")," parameter of ",(0,a.kt)("inlineCode",{parentName:"p"},"post_login_redirect_uri")," does not support query string parameters. This post describes how to work around this limitation."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Deep linking with Azure Static Web Apps and Easy Auth&quot; with Azure AD and Static Web App logos",src:n(9532).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"updated-1st-march-2023"}),"Updated 1st March 2023"),(0,a.kt)("p",null,"I'm happy to say that this blog post is no longer necessary; ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/static-web-apps/issues/435#issuecomment-1353985870"}),"the behavour is now built into Azure Static Web Apps"),". Here is an example ",(0,a.kt)("inlineCode",{parentName:"p"},"staticwebapp.config.json")," which supports deep linking using the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://learn.microsoft.com/en-us/azure/static-web-apps/authentication-authorization?tabs=invitations#set-up-post-sign-in-redirect"}),(0,a.kt)("inlineCode",{parentName:"a"},".referrer"))," post sign-in redirect:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "auth": {\n    "identityProviders": {\n      "azureActiveDirectory": {\n        // ...\n      }\n    }\n  },\n  "navigationFallback": {\n    "rewrite": "index.html"\n  },\n  "routes": [\n    {\n      "route": "/login",\n      "rewrite": "/.auth/login/aad",\n      "allowedRoles": ["anonymous", "authenticated"]\n    },\n    {\n      "route": "/.auth/login/github",\n      "statusCode": 404\n    },\n    {\n      "route": "/.auth/login/twitter",\n      "statusCode": 404\n    },\n    {\n      "route": "/logout",\n      "redirect": "/.auth/logout",\n      "allowedRoles": ["anonymous", "authenticated"]\n    },\n    {\n      "route": "/*",\n      "allowedRoles": ["authenticated"]\n    }\n  ],\n  "responseOverrides": {\n    "401": {\n      "redirect": "/.auth/login/aad?post_login_redirect_uri=.referrer",\n      "statusCode": 302\n    }\n  },\n  // ...\n}\n')),(0,a.kt)("h2",o({},{id:"deep-linking"}),"Deep linking"),(0,a.kt)("p",null,"Imagine the situation: your colleague sends you ",(0,a.kt)("inlineCode",{parentName:"p"},"https://our-app.com/pages/important-page?someId=theId"),". You click the link and you're presented with a login screen. You login and you're presented with a page, but not the one your colleague meant you to see. What do you do now? If you realise what's happened, you'll likely paste the URL into the address bar again so you end up where you hope to. But what if you don't realise what's happened? Answer: confusion and frustration."),(0,a.kt)("p",null,"If you're using Azure Static Web Apps, you're likely to have this problem. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/static-web-apps/issues/435"}),"Azure Static Web Apps doesn't support deep linking with authentication"),". When you get redirected you'll find you are (at best) missing the query parameters. If you take a look at the link here you'll see a suggested workaround. We're going to develop that idea in this post."),(0,a.kt)("h2",o({},{id:"the-workaround"}),"The workaround"),(0,a.kt)("p",null,"The idea of the workaround is this:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"at the start of the authentication process, store the URL you're trying to get to in local storage"),(0,a.kt)("li",{parentName:"ul"},"when the authentication process completes, redirect to the URL you stored in local storage")),(0,a.kt)("p",null,"The post suggested a React specific approach. We'd like something that is framework agnostic. So if you're running with Svelte, Vue, Angular or something else, you can use this approach too."),(0,a.kt)("h2",o({},{id:"the-implementation"}),"The implementation"),(0,a.kt)("p",null,"We're going to need to make sure our ",(0,a.kt)("a",o({parentName:"p"},{href:"https://learn.microsoft.com/en-us/azure/static-web-apps/configuration"}),(0,a.kt)("inlineCode",{parentName:"a"},"staticwebapp.config.json"))," is set up to support our goal:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "auth": {\n    "identityProviders": {\n      "azureActiveDirectory": {\n        "registration": {\n          "openIdIssuer": "https://login.microsoftonline.com/AAD_TENANT_ID/v2.0",\n          "clientIdSettingName": "AAD_CLIENT_ID",\n          "clientSecretSettingName": "AAD_CLIENT_SECRET"\n        }\n      }\n    }\n  },\n  "navigationFallback": {\n    "rewrite": "index.html"\n  },\n  "routes": [\n    {\n      "route": "/login",\n      "rewrite": "/.auth/login/aad",\n      "allowedRoles": ["anonymous", "authenticated"]\n    },\n    {\n      "route": "/.auth/login/github",\n      "statusCode": 404\n    },\n    {\n      "route": "/.auth/login/twitter",\n      "statusCode": 404\n    },\n    {\n      "route": "/logout",\n      "redirect": "/.auth/logout",\n      "allowedRoles": ["anonymous", "authenticated"]\n    },\n    {\n      "route": "/*.json",\n      "allowedRoles": ["authenticated"]\n    }\n  ],\n  "responseOverrides": {\n    "401": {\n      "redirect": "/login",\n      "statusCode": 302\n    }\n  },\n  "globalHeaders": {\n    "content-security-policy": "default-src https: \'unsafe-eval\' \'unsafe-inline\'; object-src \'none\'"\n  },\n  "mimeTypes": {\n    ".json": "text/json",\n    ".md": "text/markdown",\n    ".xml": "application/xml"\n  }\n}\n')),(0,a.kt)("p",null,"There's a number of things to note here:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"we're using Azure Active Directory as our identity provider (and disabling others) - the approach in this post will work with any identity provider; this is just the one I'm using. Easy Auth supports ",(0,a.kt)("a",o({parentName:"li"},{href:"https://learn.microsoft.com/en-us/azure/app-service/overview-authentication-authorization#identity-providers"}),"a number of identity providers")),(0,a.kt)("li",{parentName:"ul"},"we're creating a ",(0,a.kt)("inlineCode",{parentName:"li"},"/login")," route to redirect to the Azure AD login page - you don't have to do this, but it's a nice touch."),(0,a.kt)("li",{parentName:"ul"},"we're protecting the ",(0,a.kt)("inlineCode",{parentName:"li"},"*.json")," files with authentication - this is because our JSON files actually contain secure information. If we were using say an API instead, we'd protect that with authentication instead. Crucially, access to HTML / JS / CSS is ",(0,a.kt)("em",{parentName:"li"},"not")," protected. This is important, because we need to be able to access our ",(0,a.kt)("inlineCode",{parentName:"li"},"index.html")," file and associated JavaScript to store the URL we're trying to get to in local storage.")),(0,a.kt)("p",null,"With this in place, we can implement our workaround. Let's create a file called ",(0,a.kt)("inlineCode",{parentName:"p"},"deeplink.ts"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const deeplinkPathAndQueryKey = 'deeplink:pathAndQuery';\n\n/**\n * If authenticated, redirect to the path and query string stored in local storage.\n * If not authenticated, store the current path and query string in local storage and redirect to the login page.\n *\n * @param loginUrl The URL to redirect to if the user is not authenticated\n */\nexport async function deeplink(loginUrl: string) {\n  if (!loginUrl) {\n    throw new Error('loginUrl is required');\n  }\n\n  const pathAndQuery = location.pathname + location.search;\n  console.log(`deeplink: URL before: ${pathAndQuery}`);\n\n  const deeplinkPathAndQuery = localStorage.getItem(deeplinkPathAndQueryKey);\n\n  const isAuth = await isAuthenticated();\n\n  if (isAuth) {\n    if (deeplinkPathAndQuery && pathAndQuery === '/') {\n      console.log(`deeplink: Redirecting to ${deeplinkPathAndQuery}`);\n      localStorage.removeItem(deeplinkPathAndQueryKey);\n      history.replaceState(null, '', deeplinkPathAndQuery);\n    }\n  } else if (!deeplinkPathAndQuery) {\n    if (pathAndQuery !== '/' && pathAndQuery !== loginUrl) {\n      console.log(\n        `deeplink: Storing redirect URL of ${pathAndQuery} and redirecting to ${loginUrl}`\n      );\n      localStorage.setItem(deeplinkPathAndQueryKey, pathAndQuery);\n      location.href = loginUrl;\n    } else {\n      console.log(`deeplink: Redirecting to ${loginUrl}`);\n      location.href = loginUrl;\n    }\n  }\n}\n\nasync function isAuthenticated() {\n  try {\n    const response = await fetch('/.auth/me');\n    const authMe = (await response.json()) as AuthMe;\n    const isAuth = authMe.clientPrincipal !== null;\n    return isAuth;\n  } catch (error) {\n    console.error('Failed to fetch /.auth/me', error);\n    return false;\n  }\n}\n\ninterface AuthMe {\n  clientPrincipal: null | {\n    claims: {\n      typ: string;\n      val: string;\n    }[];\n    identityProvider: string;\n    userDetails: string;\n    userId: string;\n    userRoles: string[];\n  };\n}\n")),(0,a.kt)("p",null,"The code above implements our workaround. It does the following:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"it checks whether a user is authenticated by hitting the ",(0,a.kt)("inlineCode",{parentName:"li"},"/.auth/me")," endpoint that is provided by the Easy Auth / Static Web Apps authentication system"),(0,a.kt)("li",{parentName:"ul"},"if users are not authenticated, it:",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"stores the path and query string in localStorage and"),(0,a.kt)("li",{parentName:"ul"},"redirects them to the login page"))),(0,a.kt)("li",{parentName:"ul"},"when they return post-authentication it retrieves the path and query string from localStorage and sets the URL to that")),(0,a.kt)("p",null,"What does usage look like? Well let's take the root of a simple React app:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-tsx"}),"import { StrictMode } from 'react';\nimport { BrowserRouter } from 'react-router-dom';\nimport { createRoot } from 'react-dom/client';\nimport App from './App';\nimport { deeplink } from 'easyauth-deeplink';\n\nfunction main() {\n  const container = document.getElementById('root');\n  if (container) {\n    const root = createRoot(container);\n    root.render(\n      <StrictMode>\n        <BrowserRouter>\n          <App />\n        </BrowserRouter>\n      </StrictMode>\n    );\n  }\n}\n\ndeeplink('/login').then(main);\n// or\ndeeplink('/.auth/login/aad').then(main);\n// or\ndeeplink('/.auth/login/github').then(main);\n// or\ndeeplink('/.auth/login/twitter').then(main);\n// or\ndeeplink('/.auth/login/google').then(main);\n// etc\n")),(0,a.kt)("p",null,"You can see here that the first thing we do is call ",(0,a.kt)("inlineCode",{parentName:"p"},"deeplink")," with the URL of the login page (you can see I've provided a number of options). This will redirect the user to the login page if they're not authenticated, and will redirect them to the URL they were trying to access if they are authenticated. Once that's done, we render our app."),(0,a.kt)("p",null,"You should be able to apply this regardless of your framework. The important thing is that you call ",(0,a.kt)("inlineCode",{parentName:"p"},"deeplink")," before you render your app."),(0,a.kt)("h2",o({},{id:"announcing-easyauth-deeplink"}),"Announcing ",(0,a.kt)("inlineCode",{parentName:"h2"},"easyauth-deeplink")),(0,a.kt)("p",null,"I've created a package called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/easyauth-deeplink"}),(0,a.kt)("inlineCode",{parentName:"a"},"easyauth-deeplink"))," that implements the workaround above. You can install it with ",(0,a.kt)("inlineCode",{parentName:"p"},"npm install easyauth-deeplink")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn add easyauth-deeplink"),". It's a single file, so you can just copy and paste it into your project if you prefer."),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"It would be tremendous if this became a feature that was built into Azure Static Web Apps. Maybe one day it will be. In the meantime, I hope this workaround helps you."),(0,a.kt)("p",null,"It should be said that whilst we've described usage in this post with Static Web Apps, the same approach should work with any Azure Service that has Easy Auth enabled; App Service / Function Apps etc. I've not tried it, but I'd be surprised if it didn't work."))}d.isMDXComponent=!0},71120:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"publishing-docusaurus-to-devto-with-devto-api",title:"Publishing Docusaurus to dev.to with the dev.to API",authors:"johnnyreilly",tags:["Docusaurus","GitHub Actions"],image:"./title-image.png",description:"The dev.to API provides a way to cross post your Docusaurus blogs to dev.to. This post describes how to do that with TypeScript, Node.js and the dev.to API.",hide_table_of_contents:!1},s=void 0,l={permalink:"/publishing-docusaurus-to-devto-with-devto-api",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-12-11-publishing-docusaurus-to-devto-with-devto-api/index.md",source:"@site/blog/2022-12-11-publishing-docusaurus-to-devto-with-devto-api/index.md",title:"Publishing Docusaurus to dev.to with the dev.to API",description:"The dev.to API provides a way to cross post your Docusaurus blogs to dev.to. This post describes how to do that with TypeScript, Node.js and the dev.to API.",date:"2022-12-11T00:00:00.000Z",formattedDate:"December 11, 2022",tags:[{label:"Docusaurus",permalink:"/tags/docusaurus"},{label:"GitHub Actions",permalink:"/tags/git-hub-actions"}],readingTime:9.18,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"publishing-docusaurus-to-devto-with-devto-api",title:"Publishing Docusaurus to dev.to with the dev.to API",authors:"johnnyreilly",tags:["Docusaurus","GitHub Actions"],image:"./title-image.png",description:"The dev.to API provides a way to cross post your Docusaurus blogs to dev.to. This post describes how to do that with TypeScript, Node.js and the dev.to API.",hide_table_of_contents:!1},prevItem:{title:"Azure Static Web Apps: build app externally",permalink:"/azure-static-web-apps-build-app-externally"},nextItem:{title:"Deep linking with Azure Static Web Apps and Easy Auth",permalink:"/azure-static-web-apps-easyauth-deeplink"}},p={image:n(3422).Z,authorsImageUrls:[void 0]},u=[{value:"Why not use &quot;Publishing to DEV Community \ud83d\udc69\u200d\ud83d\udcbb\ud83d\udc68\u200d\ud83d\udcbb from RSS&quot;?",id:"why-not-use-publishing-to-dev-community--from-rss",level:2},{value:"The dev.to API",id:"the-devto-api",level:2},{value:"TypeScript console app",id:"typescript-console-app",level:2},{value:"TypeScript dev.to API client",id:"typescript-devto-api-client",level:2},{value:"From blog post markdown to published blog posts",id:"from-blog-post-markdown-to-published-blog-posts",level:2},{value:"Running the script from GitHub Actions",id:"running-the-script-from-github-actions",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The dev.to API provides a way to cross post your Docusaurus blogs to dev.to. This post describes how to do that with TypeScript, Node.js and the dev.to API."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Deep linking with Azure Static Web Apps and Easy Auth&quot; with Azure AD and Static Web App logos",src:n(3422).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"why-not-use-publishing-to-dev-community--from-rss"}),'Why not use "Publishing to DEV Community \ud83d\udc69\u200d\ud83d\udcbb\ud83d\udc68\u200d\ud83d\udcbb from RSS"?'),(0,a.kt)("p",null,"If you take a look at the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://dev.to/settings/extensions"}),"dev.to settings (under extensions)")," you'll see that you can post to dev.to using an RSS feed:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the &quot;Publishing to DEV Community \ud83d\udc69\u200d\ud83d\udcbb\ud83d\udc68\u200d\ud83d\udcbb from RSS&quot; section of dev.to",src:n(24831).Z,width:"1347",height:"1350"})),(0,a.kt)("p",null,"This is great, but it has a number of downsides:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"every post published to your blog will be published to dev.to - there's no fine grained control"),(0,a.kt)("li",{parentName:"ul"},'every post published arrives as "draft" - you have to manually push it "live".'),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("em",{parentName:"li"},"most significantly")," - it handles code snippets poorly. Everything ends up as a single line of text. This is a real shame because code snippets are a key part of a blog post.")),(0,a.kt)("p",null,"So after initially setting this up, I decided to look for a better way."),(0,a.kt)("h2",o({},{id:"the-devto-api"}),"The dev.to API"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.forem.com/api"}),"It turns out that dev.to have an API."),". The API is pretty well documented and it's pretty easy to use. The docs mention version 0 and version 1 of the API. Version 0 is officially deprecated, but version 1 appears to be incomplete - certainly the docs are. I ended up using version 0 for this post despite attempting to use version 1; I'll update this post when v1 gets there."),(0,a.kt)("p",null,"The only thing you need to do to use the API is ",(0,a.kt)("a",o({parentName:"p"},{href:"https://dev.to/settings/extensions"}),"generate an API key"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the &quot;DEV Community \ud83d\udc69\u200d\ud83d\udcbb\ud83d\udc68\u200d\ud83d\udcbb API Keys&quot; screen",src:n(10293).Z,width:"1347",height:"835"})),(0,a.kt)("h2",o({},{id:"typescript-console-app"}),"TypeScript console app"),(0,a.kt)("p",null,"I'm going to use a TypeScript console app to do the work. Let's scaffold up an example project alongside our Docusaurus site:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"mkdir from-docusaurus-to-devto\ncd from-docusaurus-to-devto\nnpx typescript --init\nyarn init\nyarn add @types/node ts-node typescript @docusaurus/utils\n")),(0,a.kt)("p",null,"And in the ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," file add a ",(0,a.kt)("inlineCode",{parentName:"p"},"start")," script:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "scripts": {\n    "start": "ts-node index.ts"\n  }\n}\n')),(0,a.kt)("p",null,"Finally, create an empty ",(0,a.kt)("inlineCode",{parentName:"p"},"index.ts")," file. We'll fill this in shortly."),(0,a.kt)("h2",o({},{id:"typescript-devto-api-client"}),"TypeScript dev.to API client"),(0,a.kt)("p",null,"Before we do that, we're going to need a dev.to API client. Let's create a ",(0,a.kt)("inlineCode",{parentName:"p"},"devtoApiClient.ts")," file and add the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"export interface User {\n  name: string;\n  username: string;\n  twitter_username: string;\n  github_username: string;\n  user_id: number;\n  website_url: string;\n  profile_image: string;\n  profile_image_90: string;\n}\n\nexport interface ArticleToPublish {\n  title: string;\n  body_markdown: string;\n  published: boolean;\n  main_image: string | undefined;\n  canonical_url: string;\n  description?: string;\n  tags: string[];\n}\n\nexport interface Article {\n  type_of: string;\n  id: number;\n  title: string;\n  description: string;\n  published: boolean;\n  published_at: string;\n  slug: string;\n  path: string;\n  url: string;\n  comments_count: number;\n  public_reactions_count: number;\n  page_views_count: number;\n  positive_reactions_count: number;\n  cover_image: string | null;\n  canonical_url: string;\n  published_timestamp: string;\n  tag_list: string[];\n  user: User;\n  body_markdown: string;\n  body_html: string;\n  reading_time_minutes: number;\n}\n\nexport interface DevToApiClient {\n  getArticles: () => Promise<Article[]>;\n  createArticle: (article: ArticleToPublish) => Promise<void>;\n  updateArticle: (id: number, article: ArticleToPublish) => Promise<void>;\n}\n\nexport function devtoApiClientFactory(apiKey: string): DevToApiClient {\n  const baseUrl = 'https://dev.to/api';\n\n  return {\n    getArticles: async () => {\n      try {\n        const articles: Article[] = [];\n        let page = 1;\n        const pageSize = 100;\n        while (true) {\n          const url = `${baseUrl}/articles/me/published?page=${page}&page_size=${pageSize}`;\n          const res = await fetch(url, {\n            headers: {\n              'api-key': apiKey,\n              accept: 'application/vnd.forem.api-v1+json',\n            },\n          });\n          if (!res.ok) {\n            console.error(res);\n            throw new Error(`Failed to get articles ${url}`);\n          }\n          const data = (await res.json()) as Article[];\n          if (data.length === 0) break;\n\n          page += 1;\n          articles.push(...data);\n        }\n        return articles;\n      } catch (e) {\n        console.error('Failed to get articles', e);\n        throw new Error('Failed to get articles');\n      }\n    },\n\n    createArticle: async (article: ArticleToPublish) => {\n      try {\n        const url = `${baseUrl}/articles`;\n        const res = await fetch(url, {\n          headers: {\n            'api-key': apiKey,\n            'Content-Type': 'application/json',\n          },\n          method: 'POST',\n          body: JSON.stringify({\n            article,\n          }),\n        });\n        if (!res.ok) {\n          console.error(res);\n          console.error(await res.json());\n          throw new Error(`Failed to create article ${article.canonical_url}`);\n        }\n        const data = (await res.json()) as Article;\n        const { body_html, body_markdown, ...rest } = data;\n        console.log(`Created article ${article.canonical_url}`, rest);\n      } catch (e) {\n        console.error('Failed to create article', e);\n        throw new Error('Failed to create article');\n      }\n    },\n\n    updateArticle: async (id: number, article: ArticleToPublish) => {\n      try {\n        const url = `${baseUrl}/articles/${id}`;\n        const res = await fetch(url, {\n          headers: {\n            'api-key': apiKey,\n            'Content-Type': 'application/json',\n          },\n          method: 'PUT',\n          body: JSON.stringify({\n            article,\n          }),\n        });\n        if (!res.ok) {\n          console.error(res);\n          console.error(await res.json());\n          throw new Error(`Failed to update article ${article.canonical_url}`);\n        }\n        const data = (await res.json()) as Article;\n        const { body_html, body_markdown, ...rest } = data;\n        console.log(`Updated article ${article.canonical_url}`, rest);\n      } catch (e) {\n        console.error('Failed to update article', e);\n        throw new Error('Failed to update article');\n      }\n    },\n  };\n}\n")),(0,a.kt)("p",null,"This is a simple API client that uses the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API"}),"Fetch API")," to make requests to the dev.to API. It's not a complete implementation of the API, but we only need a few article related endpoints to do the following:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Get all the articles that have been published to dev.to"),(0,a.kt)("li",{parentName:"ul"},"Create a new article"),(0,a.kt)("li",{parentName:"ul"},"Update an existing article")),(0,a.kt)("h2",o({},{id:"from-blog-post-markdown-to-published-blog-posts"}),"From blog post markdown to published blog posts"),(0,a.kt)("p",null,"Now we can use the API client in our ",(0,a.kt)("inlineCode",{parentName:"p"},"index.ts")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import fs from 'fs';\nimport path from 'path';\nimport { parseFrontMatter } from '@docusaurus/utils';\nimport {\n  Article,\n  DevToApiClient,\n  devtoApiClientFactory,\n} from './devtoApiClient';\n\nconst rootUrl = 'https://blog.johnnyreilly.com';\nconst rootGitHubUrl =\n  'https://raw.githubusercontent.com/johnnyreilly/blog.johnnyreilly.com/main/blog-website/blog/';\nconst docusaurusBlogDirectory = '../blog-website/blog';\n\nconst markdownImageRexEx = /!\\[.*\\]\\((.*)\\)/g;\nconst markdownRelativeBlogUrlRegex = /\\[.*\\]\\(\\.\\.\\/(.*)\\/index.md\\)/g;\n\nasync function getLastXBlogPostsToPublish({\n  numberOfPosts,\n}: {\n  numberOfPosts: number;\n}) {\n  const blogPosts = await fs.promises.readdir(docusaurusBlogDirectory, {\n    withFileTypes: true,\n  });\n  const blogPostDirectoryNames = blogPosts\n    .slice(0)\n    .reverse()\n    .filter((post) => post.isDirectory())\n    .map((post) => post.name)\n    .slice(0, numberOfPosts);\n\n  return blogPostDirectoryNames;\n}\n\nasync function publishBlogPostToDevTo({\n  blogFilePathRelative,\n  articlesByCanonicalUrl,\n  devtoApiClient,\n}: {\n  blogFilePathRelative: string;\n  articlesByCanonicalUrl: Map<string, Article>;\n  devtoApiClient: DevToApiClient;\n}) {\n  const blogFilePath = path.join(\n    docusaurusBlogDirectory,\n    blogFilePathRelative,\n    'index.md'\n  );\n  console.log(`Processing ${blogFilePath}`);\n\n  const blogFileContent = await fs.promises.readFile(blogFilePath, 'utf8');\n  const { frontMatter, content } = parseFrontMatter(blogFileContent);\n\n  const canonicalUrl = makeCanonicalUrl(\n    blogFilePathRelative,\n    frontMatter['slug'] as string | undefined\n  );\n  const contentWithCanonicalUrls = enrichMarkdownWithCanonicalUrls(content);\n  const contentWithGitHubImages = enrichMarkdownWithImagesFromGitHub(\n    contentWithCanonicalUrls,\n    blogFilePathRelative\n  );\n  const tags = frontMatter['tags'] as string[];\n  const title = frontMatter['title'] as string;\n  const published = true;\n  const main_image = makeMainImage(frontMatter, blogFilePathRelative);\n  const trimmedTags = tags.slice(0, 4).map((tag) => tag.replace(/\\W/g, ''));\n\n  const body_markdown = `---\ntitle: ${title}\npublished: ${published}\ntags: ${trimmedTags.join(',')}\ncanonical_url: ${canonicalUrl}\n---\n${contentWithGitHubImages}`;\n\n  const article = {\n    title,\n    body_markdown,\n    published,\n    main_image,\n    canonical_url: canonicalUrl,\n    tags: trimmedTags,\n  };\n\n  console.log(`\\n---------------------------------------------------\\n\\n`);\n  const existingArticle = articlesByCanonicalUrl.get(canonicalUrl);\n\n  if (existingArticle) {\n    console.log(`Updating article ${canonicalUrl}`);\n    await devtoApiClient.updateArticle(existingArticle.id, article);\n  } else {\n    console.log(`Creating article ${canonicalUrl}`);\n    await devtoApiClient.createArticle(article);\n  }\n}\n\nfunction makeMainImage(\n  frontMatter: { [key: string]: unknown },\n  blogFilePathRelative: string\n) {\n  const image =\n    typeof frontMatter['image'] === 'string'\n      ? (frontMatter['image'] as string)\n      : '';\n  const main_image = image\n    ? rootGitHubUrl +\n      blogFilePathRelative +\n      '/' +\n      image.substring(image.indexOf('/') + 1)\n    : undefined;\n  return main_image;\n}\n\nfunction makeCanonicalUrl(\n  blogFilePathRelative: string,\n  frontMatterSlug?: string\n) {\n  const parsedBlogFileName = `${rootUrl}/${blogFilePathRelative\n    .substring(0, 10)\n    .split('-')\n    .join('/')}/${blogFilePathRelative.substring(11)}`;\n\n  const canonicalUrl = frontMatterSlug\n    ? `${rootUrl}/${frontMatterSlug}`\n    : parsedBlogFileName;\n  return canonicalUrl;\n}\n\nfunction enrichMarkdownWithImagesFromGitHub(\n  content: string,\n  blogFilePathRelative: string\n) {\n  return Array.from(content.matchAll(markdownImageRexEx))\n    .map((matches) => {\n      const [completeMatch, url] = matches;\n      const withGitHubUrl = completeMatch.replace(\n        url,\n        rootGitHubUrl + blogFilePathRelative + '/' + url\n      );\n      console.log(`Replacing ${completeMatch} with ${withGitHubUrl}`);\n      return { oldImage: completeMatch, newImage: withGitHubUrl };\n    })\n    .reduce(\n      (contentInProgress, { oldImage, newImage }) =>\n        contentInProgress.replace(oldImage, newImage),\n      content\n    );\n}\n\nfunction enrichMarkdownWithCanonicalUrls(content: string) {\n  return Array.from(content.matchAll(markdownRelativeBlogUrlRegex))\n    .map((matches) => {\n      const [\n        /* eg [I wanted to add the last modified date to my blog posts.](../2022-11-25-adding-lastmod-to-sitemap-git-commit-date/index.md) */\n        completeMatch,\n        /* eg 2022-11-25-adding-lastmod-to-sitemap-git-commit-date */\n        relativeBlogPath,\n      ] = matches;\n\n      const withCanonicalUrl = completeMatch.replace(\n        `../${relativeBlogPath}/index.md`,\n        makeCanonicalUrl(relativeBlogPath)\n      );\n      console.log(`Replacing ${completeMatch} with ${withCanonicalUrl}`);\n      return { oldImage: completeMatch, newImage: withCanonicalUrl };\n    })\n    .reduce(\n      (contentInProgress, { oldImage, newImage }) =>\n        contentInProgress.replace(oldImage, newImage),\n      content\n    );\n}\n\nfunction makeDevtoApiClient() {\n  const devToApiKey = process.env.DEVTO_APIKEY;\n\n  if (!devToApiKey) {\n    console.log('No dev.to API key specified!');\n    process.exit(1);\n  }\n\n  return devtoApiClientFactory(devToApiKey);\n}\n\nconst sleep = async ({ seconds }: { seconds: number }) =>\n  new Promise((resolve) => setTimeout(resolve, seconds * 1000));\n\nasync function run() {\n  const devtoApiClient = makeDevtoApiClient();\n  const articles = await devtoApiClient.getArticles();\n  const articlesByCanonicalUrl = new Map<string, Article>(\n    Array.from(articles).map((article) => [article.canonical_url, article])\n  );\n  const blogPostsToPublish = await getLastXBlogPostsToPublish({\n    numberOfPosts: 5,\n  });\n\n  for (const blogFilePathRelative of blogPostsToPublish) {\n    await publishBlogPostToDevTo({\n      blogFilePathRelative,\n      articlesByCanonicalUrl,\n      devtoApiClient,\n    });\n\n    console.log('Sleeping for 5 seconds because rate limiting...');\n    await sleep({ seconds: 5 });\n  }\n}\n\n// do it!\nrun();\n")),(0,a.kt)("p",null,"There's a lot happening here, let me summarise it:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Grab the last 5 blog posts from the Docusaurus blog directory; this is the number of posts I want to publish to dev.to on each run"),(0,a.kt)("li",{parentName:"ul"},"For each blog post, parse the front matter and the content"),(0,a.kt)("li",{parentName:"ul"},"Build up the article object to send to dev.to. We do a few tricks here to make the article look nice:",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"To make the URL we'll use the ",(0,a.kt)("inlineCode",{parentName:"li"},"slug")," front matter if it exists, otherwise use the date and title"),(0,a.kt)("li",{parentName:"ul"},"Enrich the images in the content with the GitHub URLs so we can use images from the blog post"),(0,a.kt)("li",{parentName:"ul"},"Use the first 4 tags from the front matter - dev.to only allows 4 tags. Also we'll strip those tags of any non-word characters"),(0,a.kt)("li",{parentName:"ul"},"Default to ",(0,a.kt)("inlineCode",{parentName:"li"},"published")," immediately"))),(0,a.kt)("li",{parentName:"ul"},"If the article already exists on dev.to, update it, otherwise create it")),(0,a.kt)("p",null,"Because dev.to practise rate limiting on their API, I've added a 5 second sleep between each article to ensure we don't get blocked. It's a little arbitrary, but it works well enough."),(0,a.kt)("p",null,"Does it work? Let's find out!"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of dev.to dashboard showing published posts",src:n(66231).Z,width:"1822",height:"1008"})),(0,a.kt)("p",null,"It works! I've published 5 posts to dev.to from my blog. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://dev.to/johnnyreilly"}),"I can now go to dev.to and see them.")),(0,a.kt)("h2",o({},{id:"running-the-script-from-github-actions"}),"Running the script from GitHub Actions"),(0,a.kt)("p",null,"Now that we have the script, we need to run it. I'm going to use GitHub Actions to do this, but you could use any CI/CD tool you like."),(0,a.kt)("p",null,"I add a new ",(0,a.kt)("inlineCode",{parentName:"p"},"deploy_to_devto_job")," to my existing workflow and I set it to run on every push to the ",(0,a.kt)("inlineCode",{parentName:"p"},"main")," branch. I don't want to publish to dev.to on every pull request; I want to publish once a blog post is published. So I add an ",(0,a.kt)("inlineCode",{parentName:"p"},"if")," condition to the job to check that the event is not a pull request."),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),"deploy_to_devto_job:\n  name: Publish to dev.to \ud83d\uddde\ufe0f\n  needs: build_and_deploy_swa_job\n  if: github.event_name != 'pull_request'\n  runs-on: ubuntu-latest\n  steps:\n    - uses: actions/checkout@v3\n\n    - name: Setup Node.js \ud83d\udd27\n      uses: actions/setup-node@v3\n      with:\n        node-version: '18'\n        cache: 'yarn'\n\n    - name: Publish to dev.to \ud83d\uddde\ufe0f\n      run: |\n        cd from-docusaurus-to-devto\n        yarn install --frozen-lockfile\n        DEVTO_APIKEY=${{ secrets.DEVTO_APIKEY }} yarn start\n")),(0,a.kt)("p",null,"If you'd like to use this you'll need to add a ",(0,a.kt)("inlineCode",{parentName:"p"},"DEVTO_APIKEY")," secret to your repository secrets. You can get this from your dev.to account settings. Remember to keep it secret!"),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"This is all a bit of an experiment to see what happens if I start to cross publish my blog posts to dev.to. I'm not sure if I'll keep doing it, but I'm going to trial it and see how it goes."),(0,a.kt)("p",null,"You can use this approach with your own blog site - you'll need to do a little path and URL fiddling, but everything else should be just as you need."))}d.isMDXComponent=!0},57662:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-static-web-apps-build-app-externally",title:"Azure Static Web Apps: build app externally",authors:"johnnyreilly",tags:["Azure Static Web Apps","GitHub Actions"],image:"./title-image.png",description:"Azure Static Web Apps can generally build themselves with Oryx. If you need finer grained control of your build, you can with `skip_app_build: true`.",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-static-web-apps-build-app-externally",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-12-18-azure-static-web-apps-build-app-externally/index.md",source:"@site/blog/2022-12-18-azure-static-web-apps-build-app-externally/index.md",title:"Azure Static Web Apps: build app externally",description:"Azure Static Web Apps can generally build themselves with Oryx. If you need finer grained control of your build, you can with `skip_app_build: true`.",date:"2022-12-18T00:00:00.000Z",formattedDate:"December 18, 2022",tags:[{label:"Azure Static Web Apps",permalink:"/tags/azure-static-web-apps"},{label:"GitHub Actions",permalink:"/tags/git-hub-actions"}],readingTime:3.135,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-static-web-apps-build-app-externally",title:"Azure Static Web Apps: build app externally",authors:"johnnyreilly",tags:["Azure Static Web Apps","GitHub Actions"],image:"./title-image.png",description:"Azure Static Web Apps can generally build themselves with Oryx. If you need finer grained control of your build, you can with `skip_app_build: true`.",hide_table_of_contents:!1},prevItem:{title:"Azure Static Web Apps: dynamic redirects with Azure Functions",permalink:"/azure-static-web-apps-dynamic-redirects-azure-functions"},nextItem:{title:"Publishing Docusaurus to dev.to with the dev.to API",permalink:"/publishing-docusaurus-to-devto-with-devto-api"}},p={image:n(43662).Z,authorsImageUrls:[void 0]},u=[{value:"Build with Oryx",id:"build-with-oryx",level:2},{value:"Build externally",id:"build-externally",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Azure Static Web Apps can generally build themselves with Oryx. If you need finer grained control of your build, you can with ",(0,a.kt)("inlineCode",{parentName:"p"},"skip_app_build: true")," and some GitHub Actions."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Azure Static Web Apps: build app externally&quot; with the Static Web Apps logo",src:n(43662).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"build-with-oryx"}),"Build with Oryx"),(0,a.kt)("p",null,"I love Azure Static Web Apps. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.johnnyreilly.com"}),"My blog")," is built with them. I've written about them many times."),(0,a.kt)("p",null,"One of the things I like about Azure Static Web Apps is that they can build themselves. You can just push your code to GitHub and they'll build it using a tool called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/Oryx"}),"Oryx"),'. This is great for simple scenarios. Actually, it\'s good for medium to complex scenarios too. However, if you ever get to that "break glass" moment where you need to do something unusual with your build, you can.'),(0,a.kt)("p",null,"Let's start by looking at a simple Azure Static Web Apps configuration:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),"- name: Static Web App - get API key for deployment\n  id: static_web_app_apikey\n  uses: azure/CLI@v1\n  with:\n    inlineScript: |\n      APIKEY=$(az staticwebapp secrets list --name '${{ env.STATICWEBAPPNAME }}' | jq -r '.properties.apiKey')\n      echo \"::set-output name=APIKEY::$APIKEY\"\n\n- name: Static Web App - build and deploy\n  id: static_web_app_build_and_deploy\n  uses: Azure/static-web-apps-deploy@v1\n  with:\n    azure_static_web_apps_api_token: ${{ steps.static_web_app_apikey.outputs.APIKEY }}\n    repo_token: ${{ secrets.GITHUB_TOKEN }} # Used for Github integrations (i.e. PR comments)\n    action: 'upload'\n    app_location: '/blog-website' # App source code path\n    output_location: 'build' # Built app content directory - optional\n\n    # For more information regarding Static Web App workflow configurations, please visit: https://aka.ms/swaworkflowconfig\n    api_location: '' # Api source code path - optional\n")),(0,a.kt)("p",null,"Above is an old version of what my blog used to build and deploy itself. With the yaml above, Oryx built the app and deployed it. ",(0,a.kt)("a",o({parentName:"p"},{href:"/adding-lastmod-to-sitemap-git-commit-date"}),"I wanted to add the last modified date to my blog posts.")," It would have been fiddly to do this in Oryx."),(0,a.kt)("h2",o({},{id:"build-externally"}),"Build externally"),(0,a.kt)("p",null,"So, I decided to build the app externally and then deploy it. I did this by tweaking the yaml above to add some extra steps:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),"- name: Get API key \ud83d\udd11\n  id: static_web_app_apikey\n  uses: azure/CLI@v1\n  with:\n    inlineScript: |\n      APIKEY=$(az staticwebapp secrets list --name '${{ env.STATICWEBAPPNAME }}' | jq -r '.properties.apiKey')\n      echo \"::set-output name=APIKEY::$APIKEY\"\n\n- name: Setup Node.js \ud83d\udd27\n  uses: actions/setup-node@v3\n  with:\n    node-version: '18'\n    cache: 'yarn'\n\n- name: Install and build site \ud83d\udd27\n  run: |\n    cd blog-website\n    yarn install --frozen-lockfile\n    yarn run build\n    # copy staticwebapp.config.json to build folder\n    cp staticwebapp.config.json build/staticwebapp.config.json\n\n- name: Deploy site \ud83d\ude80\n  id: static_web_app_build_and_deploy\n  uses: Azure/static-web-apps-deploy@v1\n  with:\n    azure_static_web_apps_api_token: ${{ steps.static_web_app_apikey.outputs.APIKEY }}\n    repo_token: ${{ secrets.GITHUB_TOKEN }} # Used for Github integrations (i.e. PR comments)\n    action: 'upload'\n    skip_app_build: true\n    app_location: '/blog-website/build' # App source code path\n    # output_location: 'build' # Built app content directory - optional\n\n    # For more information regarding Static Web App workflow configurations, please visit: https://aka.ms/swaworkflowconfig\n    api_location: '' # Api source code path - optional\n")),(0,a.kt)("p",null,"What's changed? Well, I've added a few steps:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Setup Node.js - essentially, this is just installing Node.js so we can build the app"),(0,a.kt)("li",{parentName:"ul"},"Install and build site - this is where we actually do install the dependencies and build the app"),(0,a.kt)("li",{parentName:"ul"},"Significantly (and ",(0,a.kt)("a",o({parentName:"li"},{href:"https://github.com/Azure/static-web-apps/issues/1017#issuecomment-1356786140"}),"thanks to Vivek Jilla for this tip"),"), we copy the ",(0,a.kt)("inlineCode",{parentName:"li"},"staticwebapp.config.json")," file to the build folder. This is important because it contains the routing information for the app. Without it, any rules you have in your ",(0,a.kt)("inlineCode",{parentName:"li"},"staticwebapp.config.json")," file won't be applied."),(0,a.kt)("li",{parentName:"ul"},"We set ",(0,a.kt)("inlineCode",{parentName:"li"},"skip_app_build: true")," - this tells Azure Static Web Apps to skip the build step and point it at the ",(0,a.kt)("inlineCode",{parentName:"li"},"build")," folder instead, where the built app (with ",(0,a.kt)("inlineCode",{parentName:"li"},"staticwebapp.config.json"),") can be found.")),(0,a.kt)("p",null,"With this in place I'm now able to build the app externally and deploy it to Azure Static Web Apps. This is great for when you need to do something a little more complex than Oryx can handle."))}d.isMDXComponent=!0},61322:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-static-web-apps-dynamic-redirects-azure-functions",title:"Azure Static Web Apps: dynamic redirects with Azure Functions",authors:"johnnyreilly",tags:["Azure Static Web Apps","Azure Functions","GitHub Actions"],image:"./title-image.png",description:"Azure Static Web Apps can perform URL redirects using the `routes` section in the `staticwebapp.config.json`. However it is limited. This post will demonstrate dynamic URL redirects with Azure Functions.",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-static-web-apps-dynamic-redirects-azure-functions",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-12-22-azure-static-web-apps-dynamic-redirects-azure-functions/index.md",source:"@site/blog/2022-12-22-azure-static-web-apps-dynamic-redirects-azure-functions/index.md",title:"Azure Static Web Apps: dynamic redirects with Azure Functions",description:"Azure Static Web Apps can perform URL redirects using the `routes` section in the `staticwebapp.config.json`. However it is limited. This post will demonstrate dynamic URL redirects with Azure Functions.",date:"2022-12-22T00:00:00.000Z",formattedDate:"December 22, 2022",tags:[{label:"Azure Static Web Apps",permalink:"/tags/azure-static-web-apps"},{label:"Azure Functions",permalink:"/tags/azure-functions"},{label:"GitHub Actions",permalink:"/tags/git-hub-actions"}],readingTime:4.78,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-static-web-apps-dynamic-redirects-azure-functions",title:"Azure Static Web Apps: dynamic redirects with Azure Functions",authors:"johnnyreilly",tags:["Azure Static Web Apps","Azure Functions","GitHub Actions"],image:"./title-image.png",description:"Azure Static Web Apps can perform URL redirects using the `routes` section in the `staticwebapp.config.json`. However it is limited. This post will demonstrate dynamic URL redirects with Azure Functions.",hide_table_of_contents:!1},prevItem:{title:"Serving Docusaurus images with Cloudinary",permalink:"/docusaurus-image-cloudinary-rehype-plugin"},nextItem:{title:"Azure Static Web Apps: build app externally",permalink:"/azure-static-web-apps-build-app-externally"}},p={image:n(84949).Z,authorsImageUrls:[void 0]},u=[{value:"The limits of <code>routes</code> in <code>staticwebapp.config.json</code>",id:"the-limits-of-routes-in-staticwebappconfigjson",level:2},{value:"Adding an Azure Function to our Azure Static Web App",id:"adding-an-azure-function-to-our-azure-static-web-app",level:2},{value:"JSDoc types with <code>@azure/functions</code>",id:"jsdoc-types-with-azurefunctions",level:2},{value:"Consuming the Azure Function from our Azure Static Web App",id:"consuming-the-azure-function-from-our-azure-static-web-app",level:2},{value:"Deploying our Azure Function",id:"deploying-our-azure-function",level:2},{value:"Testing our Azure Function",id:"testing-our-azure-function",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Azure Static Web Apps can perform URL redirects using the ",(0,a.kt)("inlineCode",{parentName:"p"},"routes")," section in the ",(0,a.kt)("inlineCode",{parentName:"p"},"staticwebapp.config.json"),". However it is limited. This post will demonstrate dynamic URL redirects with Azure Functions."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Azure Static Web Apps: dynamic redirects with Azure Functions&quot; with the Static Web Apps and Azure Functions logo",src:n(84949).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"the-limits-of-routes-in-staticwebappconfigjson"}),"The limits of ",(0,a.kt)("inlineCode",{parentName:"h2"},"routes")," in ",(0,a.kt)("inlineCode",{parentName:"h2"},"staticwebapp.config.json")),(0,a.kt)("p",null,"I recently found myself fixing up some redirects for my blog, which runs on Azure Static Web Apps. I had quite a few redirects to implement and I ended up with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://learn.microsoft.com/en-us/azure/static-web-apps/configuration#routes"}),"a very large ",(0,a.kt)("inlineCode",{parentName:"a"},"routes")," section"),". It was so large that I exceeded ",(0,a.kt)("a",o({parentName:"p"},{href:"https://learn.microsoft.com/en-us/azure/static-web-apps/configuration#restrictions"}),"the 20kb limit that affect Azure Static Web Apps"),"."),(0,a.kt)("p",null,"I bemoaned this on Twitter and got some great advice from ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/nthonyChu"}),"Anthony Chu who works on Azure Static Web Apps"),":"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/nthonyChu/status/1605248878009208832"}),(0,a.kt)("img",{loading:"lazy",alt:"Tweet that reads: Your best bet today might be to use a function that handles 404 response overrides. You can do the lookup with it and return a redirect if found. There might be a small cold start on those routes but for this case maybe it\u2019s okay.",src:n(13449).Z,width:"1121",height:"1410"}))),(0,a.kt)("p",null,"Anthony went on to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/nthonyChu/status/1605429770715402240"}),"share details of an example implementation that Nuxt.js has implemented"),". I took this as a challenge to implement something similar for my blog. Let's see how we got on."),(0,a.kt)("h2",o({},{id:"adding-an-azure-function-to-our-azure-static-web-app"}),"Adding an Azure Function to our Azure Static Web App"),(0,a.kt)("p",null,"The first thing we need to do is add an Azure Function to our Azure Static Web App. All Static Web Apps can be backed by an Azure Function App. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://learn.microsoft.com/en-us/azure/static-web-apps/add-api?tabs=react#create-the-api"}),"We can create a simple JavaScript HttpTrigger Azure Function following this guide"),". I used JavScript as it seemed like the simplest option. If we wanted a different language we could use one."),(0,a.kt)("p",null,"We're going to name the single function ",(0,a.kt)("inlineCode",{parentName:"p"},"fallback"),", so it will be served up at ",(0,a.kt)("inlineCode",{parentName:"p"},"/api/fallback"),". The code of the function is:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"//@ts-check\nconst { parseURL } = require('ufo');\nconst routes = require('./redirects');\n\n/**\n *\n * @param { import(\"@azure/functions\").Context } context\n * @param { import(\"@azure/functions\").HttpRequest } req\n */\nasync function fallback(context, req) {\n  const originalUrl = req.headers['x-ms-original-url'];\n  if (originalUrl) {\n    // This URL has been proxied as there was no static file matching it.\n    context.log(`x-ms-original-url: ${originalUrl}`);\n\n    const parsedURL = parseURL(originalUrl);\n\n    const matchedRoute = routes.find((route) =>\n      parsedURL.pathname.includes(route.route)\n    );\n\n    if (matchedRoute) {\n      context.log(`Redirecting ${originalUrl} to ${matchedRoute.redirect}`);\n\n      context.res = {\n        status: matchedRoute.statusCode,\n        headers: { location: matchedRoute.redirect },\n      };\n      return;\n    }\n  }\n\n  context.log(\n    `No explicit redirect for ${originalUrl} so will redirect to 404`\n  );\n\n  context.res = {\n    status: 302,\n    headers: {\n      location: originalUrl\n        ? `/404?originalUrl=${encodeURIComponent(originalUrl)}`\n        : '/404',\n    },\n  };\n}\n\nmodule.exports = fallback;\n")),(0,a.kt)("p",null,"What's happening here? Well, we're using the ",(0,a.kt)("inlineCode",{parentName:"p"},"ufo")," package to parse the URL which we grab from the ",(0,a.kt)("inlineCode",{parentName:"p"},"x-ms-original-url")," header. We then look for a match in our ",(0,a.kt)("inlineCode",{parentName:"p"},"redirects.js"),", which is a ",(0,a.kt)("em",{parentName:"p"},"big")," list of potential redirects."),(0,a.kt)("p",null,"If we find a match, we redirect based upon that match. Otherwise we redirect to the custom 404 screen in our app. And we include the original URL in the query string for visibility. (With this in place, any unhandled redirects should show up in Google Analytics etc.)"),(0,a.kt)("h2",o({},{id:"jsdoc-types-with-azurefunctions"}),"JSDoc types with ",(0,a.kt)("inlineCode",{parentName:"h2"},"@azure/functions")),(0,a.kt)("p",null,"You'll notice that we're using JSDoc types in the above code and enabling type checking through use of ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/docs/handbook/intro-to-js-ts.html#ts-check"}),(0,a.kt)("inlineCode",{parentName:"a"},"// @ts-check")),". We're providing types to our function through the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/@azure/functions"}),(0,a.kt)("inlineCode",{parentName:"a"},"@azure/functions"))," package which we've added as a ",(0,a.kt)("inlineCode",{parentName:"p"},"devDependency"),". You don't have to do this, but it's a nice way to get some type safety."),(0,a.kt)("h2",o({},{id:"consuming-the-azure-function-from-our-azure-static-web-app"}),"Consuming the Azure Function from our Azure Static Web App"),(0,a.kt)("p",null,"Now our Azure Function is in place, we need to configure our Azure Static Web App to use it. In our ",(0,a.kt)("inlineCode",{parentName:"p"},"staticwebapp.config.json")," we'll make some changes:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'  "navigationFallback": {\n    "rewrite": "/api/fallback"\n  },\n  "platform": {\n    "apiRuntime": "node:18"\n  },\n  "routes": [\n    {\n      "route": "/404",\n      "statusCode": 404\n    },\n')),(0,a.kt)("p",null,"Here we:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Point to our apps navigation fallback to our ",(0,a.kt)("inlineCode",{parentName:"li"},"fallback")," function (",(0,a.kt)("inlineCode",{parentName:"li"},"/api/fallback"),") - this will be called whenever a URL is not matched by a static file."),(0,a.kt)("li",{parentName:"ul"},"We declare an ",(0,a.kt)("inlineCode",{parentName:"li"},"apiRuntime")," of Node.js 18 - this is the version of Node.js that our Azure Function is using."),(0,a.kt)("li",{parentName:"ul"},"Whenever the ",(0,a.kt)("inlineCode",{parentName:"li"},"/404")," route is hit in our app, we ensure the status code presented is 404."),(0,a.kt)("li",{parentName:"ul"},"We remove the ",(0,a.kt)("inlineCode",{parentName:"li"},"route")," redirects we had in place as these will now be handled by ",(0,a.kt)("inlineCode",{parentName:"li"},"/api/fallback")," (this isn't shown in the above snippet)")),(0,a.kt)("h2",o({},{id:"deploying-our-azure-function"}),"Deploying our Azure Function"),(0,a.kt)("p",null,"We need to deploy our Function, and we achieve that by tweaking the our GitHub Action that deploys our Static Web App. We add the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"api_location: '/blog-website/api'\n")),(0,a.kt)("p",null,"And now our Azure Function will be built and deployed alongside our blog."),(0,a.kt)("h2",o({},{id:"testing-our-azure-function"}),"Testing our Azure Function"),(0,a.kt)("p",null,"We can demonstrate this works pretty easily. Let's take a super old blog post of mine, where I upgraded to TypeScript 0.9.5 (!!!) The route has changed since I originally posted back in 2014. If we go to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.johnnyreilly.com/2014/01/upgrading-to-typescript-095-personal.html"}),"https://blog.johnnyreilly.com/2014/01/upgrading-to-typescript-095-personal.html")," (the old Blogger URL), we'll be redirected (301'd to be specific - signalling a permanent move) to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.johnnyreilly.com/2014/01/09/upgrading-to-typescript-095-personal"}),"https://blog.johnnyreilly.com/2014/01/09/upgrading-to-typescript-095-personal")," - the new URL. This is demonstrated in the following screenshot - note the ",(0,a.kt)("inlineCode",{parentName:"p"},"location")," header in the response:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of redirect in Chrome Devtools",src:n(52606).Z,width:"1799",height:"541"})),(0,a.kt)("p",null,"This particular redirect is driven by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/blob/e21d3faf897505e860fc351260ab45ef6fa21d60/blog-website/api/fallback/redirects.js#L475-L479"}),"an entry in our ",(0,a.kt)("inlineCode",{parentName:"a"},"redirects.js"))," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),"  {\n    route: '/2014/01/upgrading-to-typescript-095-personal.html',\n    redirect: '/2014/01/09/upgrading-to-typescript-095-personal',\n    statusCode: 301,\n  },\n")),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"I'd love it if there was a way to do this without an Azure Function. Imagine a ",(0,a.kt)("inlineCode",{parentName:"p"},"staticwebapp.config.js")," that could be used to configure redirects. That would be awesome. But for now, this is a pretty good solution. Thanks to Anthony Chu for the inspiration and the example. (And thanks to the Nuxt.js team for the example too!)"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/pull/384"}),"If you'd like to see what it looked like when this landed in this very blog, then look at this pull request"),"."))}d.isMDXComponent=!0},5182:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"docusaurus-image-cloudinary-rehype-plugin",title:"Serving Docusaurus images with Cloudinary",authors:"johnnyreilly",tags:["Docusaurus","Cloudinary","rehype plugin"],image:"./title-image.png",description:"Cloudinary offers an image CDN which can improve performance of your site. This post details how to get Docusaurus to use Cloudinary to serve optimised images.",hide_table_of_contents:!1},s=void 0,l={permalink:"/docusaurus-image-cloudinary-rehype-plugin",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2022-12-26-docusaurus-image-cloudinary-rehype-plugin/index.md",source:"@site/blog/2022-12-26-docusaurus-image-cloudinary-rehype-plugin/index.md",title:"Serving Docusaurus images with Cloudinary",description:"Cloudinary offers an image CDN which can improve performance of your site. This post details how to get Docusaurus to use Cloudinary to serve optimised images.",date:"2022-12-26T00:00:00.000Z",formattedDate:"December 26, 2022",tags:[{label:"Docusaurus",permalink:"/tags/docusaurus"},{label:"Cloudinary",permalink:"/tags/cloudinary"},{label:"rehype plugin",permalink:"/tags/rehype-plugin"}],readingTime:9.535,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"docusaurus-image-cloudinary-rehype-plugin",title:"Serving Docusaurus images with Cloudinary",authors:"johnnyreilly",tags:["Docusaurus","Cloudinary","rehype plugin"],image:"./title-image.png",description:"Cloudinary offers an image CDN which can improve performance of your site. This post details how to get Docusaurus to use Cloudinary to serve optimised images.",hide_table_of_contents:!1},prevItem:{title:"Using Application Insights with Bicep to monitor Azure Static Web Apps and Azure Functions",permalink:"/application-insights-bicep-azure-static-web-apps"},nextItem:{title:"Azure Static Web Apps: dynamic redirects with Azure Functions",permalink:"/azure-static-web-apps-dynamic-redirects-azure-functions"}},p={image:n(61016).Z,authorsImageUrls:[void 0]},u=[{value:"Updated 13th January 2023 - <code>f_auto</code> / <code>q_auto</code> support",id:"updated-13th-january-2023---f_auto--q_auto-support",level:2},{value:"What is Cloudinary?",id:"what-is-cloudinary",level:2},{value:"Cloudinary account settings",id:"cloudinary-account-settings",level:2},{value:"Disable restricted media types: Fetched URL",id:"disable-restricted-media-types-fetched-url",level:3},{value:"Allowed fetch domains",id:"allowed-fetch-domains",level:3},{value:"Docusaurus Cloudinary rehype image plugin",id:"docusaurus-cloudinary-rehype-image-plugin",level:2},{value:"Using the plugin",id:"using-the-plugin",level:2},{value:"Introducing <code>rehype-cloudinary-docusaurus</code>",id:"introducing-rehype-cloudinary-docusaurus",level:2},{value:"What about pull request previews?",id:"what-about-pull-request-previews",level:2},{value:"Core Web Vitals and preconnect",id:"core-web-vitals-and-preconnect",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Cloudinary offers an image CDN which can improve performance of your site. This post details how to get Docusaurus to use Cloudinary to serve optimised images."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Serving Docusaurus images with Cloudinary&quot; with the Docusaurus and Cloudinary logos",src:n(61016).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"updated-13th-january-2023---f_auto--q_auto-support"}),"Updated 13th January 2023 - ",(0,a.kt)("inlineCode",{parentName:"h2"},"f_auto")," / ",(0,a.kt)("inlineCode",{parentName:"h2"},"q_auto")," support"),(0,a.kt)("p",null,"I received a note from the marvellous ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/rebeccapeltz"}),"Rebeccca Peltz")," of Cloudinary, alerting me to the fact that Cloudinary supports using ",(0,a.kt)("inlineCode",{parentName:"p"},"f_auto")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"q_auto")," for images fetched from URLs. To quote her:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("inlineCode",{parentName:"p"},"f_auto")," causes Cloudinary to look at User Agent information in the request header and provides the best image format for the browser or device making the request. ",(0,a.kt)("inlineCode",{parentName:"p"},"q_auto")," provides compression that makes the image smaller without creating pixelation."),(0,a.kt)("p",{parentName:"blockquote"},"..."),(0,a.kt)("p",{parentName:"blockquote"},"Here\u2019s what one of your URLs would look like with fetch and f_auto,q_auto"),(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("inlineCode",{parentName:"p"},"https://res.cloudinary.com/priou/image/fetch/f_auto,q_auto/https://johnnyreilly.com/assets/images/screenshot-image-from-cloudinary-cb313fdeb91761d777ed1732f7c054c9.webp"))),(0,a.kt)("p",null,"This sounded nothing but advantageous and so it's now the default behaviour of the plugin, as of v1.2.0. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/rehype-cloudinary-docusaurus/pull/5"}),"See the pull request here"),". Thanks Rebecca!"),(0,a.kt)("h2",o({},{id:"what-is-cloudinary"}),"What is Cloudinary?"),(0,a.kt)("p",null,"To quote ",(0,a.kt)("a",o({parentName:"p"},{href:"https://cloudinary.com/blog/delivering_all_your_websites_images_through_a_cdn"}),"Cloudinary's website"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Most leading blogs deliver their assets (images, JS, CSS, etc.) through state-of-the-art CDNs and utilize online resizing technologies. With faster, off-site access, they greatly improve their users\u2019 browsing experience, while reducing load on their servers."),(0,a.kt)("p",{parentName:"blockquote"},"Using Cloudinary you can use these same technologies today, in your website or blog, without any hassle.")),(0,a.kt)("p",null,"Consumption of the CDN is very simple. You simply prefix the URL of the image you want to serve with the URL of the Cloudinary CDN. For example, if you want to serve the following image:"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"https://blog.johnnyreilly.com/img/profile-64x64.jpg")),(0,a.kt)("p",null,"you can serve it from Cloudinary with the following URL:"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"https://res.cloudinary.com/demo/image/fetch/https://blog.johnnyreilly.com/img/profile-64x64.jpg"),"."),(0,a.kt)("p",null,"You see? All we did was prefix ",(0,a.kt)("inlineCode",{parentName:"p"},"https://res.cloudinary.com/demo/image/fetch/")," to the URL of the image we wanted to serve. That's it. When you visit the URL, you'll see the image served from Cloudinary. Behind the scenes, Cloudinary will fetch the image from the original source and serve it to you."),(0,a.kt)("admonition",o({},{type:"note"}),(0,a.kt)("p",{parentName:"admonition"},"The ",(0,a.kt)("inlineCode",{parentName:"p"},"demo")," part of the URL is the name of the Cloudinary account. You can create your own account and use that instead.")),(0,a.kt)("h2",o({},{id:"cloudinary-account-settings"}),"Cloudinary account settings"),(0,a.kt)("p",null,"Once you have created your account, you'll need to tweak the settings. There's two tweaks, one mandatory and one that's optional."),(0,a.kt)("h3",o({},{id:"disable-restricted-media-types-fetched-url"}),"Disable restricted media types: Fetched URL"),(0,a.kt)("p",null,"First the mandatory one. We need to uncheck the ",(0,a.kt)("inlineCode",{parentName:"p"},"Disable restricted media types: Fetched URL")," setting. The double negative shenanigans make this confusing; to read it another way we are \"allowing fetching URLs\". Much clearer! We need to do this is because we're fetching the image from a URL. If we didn't make the change, Cloudinary would refuse to serve the image. It wouldn't even try to fetch it."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Cloudinary settings with the Disable restricted media types: Fetched URL unchecked",src:n(29130).Z,width:"1134",height:"580"})),(0,a.kt)("admonition",o({},{type:"caution"}),(0,a.kt)("p",{parentName:"admonition"},'Remember to scroll down and hit the "Save" button. (Otherwise your changes won\'t be saved.)')),(0,a.kt)("h3",o({},{id:"allowed-fetch-domains"}),"Allowed fetch domains"),(0,a.kt)("p",null,"The second setting is optional. If you want to restrict the domains from which you can fetch images, you can do so. You might want to do this if you want to prevent others from making use of your Cloudinary account and blowing your limits. I'm not sure how likely that is, but it's a possibility."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Cloudinary settings with the allowed fetch domains restricted to blog.johnnyreilly.com",src:n(11028).Z,width:"1683",height:"345"})),(0,a.kt)("p",null,"Above I'm restricting my account to only fetch images from my own site; ",(0,a.kt)("inlineCode",{parentName:"p"},"blog.johnnyreilly.com"),". To my mind, it's the Cloudinary content security policy for fetching images."),(0,a.kt)("h2",o({},{id:"docusaurus-cloudinary-rehype-image-plugin"}),"Docusaurus Cloudinary rehype image plugin"),(0,a.kt)("p",null,"Now we have our Cloudinary account set up, we can use it with Docusaurus. To do so, we need to create a rehype plugin. This is a plugin for the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/rehypejs/rehype/"}),"rehype")," HTML processor. It's a plugin that will transform the HTML image syntax into a Cloudinary URL."),(0,a.kt)("p",null,"The plugin takes the form of a JavaScript file we'll call ",(0,a.kt)("inlineCode",{parentName:"p"},"docusaurus-cloudinary-rehype-plugin.js"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"//@ts-check\nconst visit = require('unist-util-visit');\n\n/**\n * Create a rehype plugin that will replace image URLs with Cloudinary URLs\n * @param {*} options cloudName your Cloudinary\u2019s cloud name eg demo, baseUrl the base URL of your website eg https://blog.johnnyreilly.com - should not include a trailing slash, will likely be the same as the config.url in your docusaurus.config.js\n * @returns rehype plugin that will replace image URLs with Cloudinary URLs\n */\nfunction imageCloudinaryRehypePluginFactory(\n  /** @type {{ cloudName: string; baseUrl: string }} */ options\n) {\n  const { cloudName, baseUrl } = options;\n  const srcRegex = / src={(.*)}/;\n\n  /** @type {import('unified').Plugin<[], import('hast').Root>} */\n  return (tree) => {\n    visit(tree, ['element', 'jsx'], (node) => {\n      if (node.type === 'element' && node['tagName'] === 'img') {\n        // handles nodes like this:\n\n        // {\n        //   type: 'element',\n        //   tagName: 'img',\n        //   properties: {\n        //     src: 'https://some.website.com/cat.gif',\n        //     alt: null\n        //   },\n        //   ...\n        // }\n\n        const url = node['properties'].src;\n\n        node[\n          'properties'\n        ].src = `https://res.cloudinary.com/${cloudName}/image/fetch/${url}`;\n      } else if (node.type === 'jsx' && node['value']?.includes('<img ')) {\n        // handles nodes like this:\n\n        // {\n        //   type: 'jsx',\n        //   value: '<img src={require(\"!/workspaces/blog.johnnyreilly.com/blog-website/node_modules/url-loader/dist/cjs.js?limit=10000&name=assets/images/[name]-[hash].[ext]&fallback=/workspaces/blog.johnnyreilly.com/blog-website/node_modules/file-loader/dist/cjs.js!./bower-with-the-long-paths.png\").default} width=\"640\" height=\"497\" />'\n        // }\n\n        const match = node['value'].match(srcRegex);\n        if (match) {\n          const urlOrRequire = match[1];\n          node['value'] = node['value'].replace(\n            srcRegex,\n            ` src={${`\\`https://res.cloudinary.com/${cloudName}/image/fetch/${baseUrl}\\$\\{${urlOrRequire}\\}\\``}}`\n          );\n        }\n      }\n    });\n  };\n}\n\nmodule.exports = imageCloudinaryRehypePluginFactory;\n")),(0,a.kt)("p",null,"This plugin is a factory function that takes two parameters: the name of your Cloudinary account and the base URL of your website. It returns a rehype plugin that will transform the HTML image syntax into a Cloudinary URL."),(0,a.kt)("p",null,"If you look at the code, you'll see that it handles two different types of image syntax; an ",(0,a.kt)("inlineCode",{parentName:"p"},"img")," tag and a JSX image tag. The ",(0,a.kt)("inlineCode",{parentName:"p"},"img")," tag is a very simple transform; it just prefixes the ",(0,a.kt)("inlineCode",{parentName:"p"},"src")," attribute with ",(0,a.kt)("inlineCode",{parentName:"p"},"https://res.cloudinary.com/${cloudName}/image/fetch/")," where ",(0,a.kt)("inlineCode",{parentName:"p"},"${cloudName}")," is the name of your Cloudinary account; eg ",(0,a.kt)("inlineCode",{parentName:"p"},"demo"),"."),(0,a.kt)("p",null,"The JSX image tag is a little more complex. It's a little more complex because we have a complete JSX node which contains an ",(0,a.kt)("inlineCode",{parentName:"p"},"img")," element. The ",(0,a.kt)("inlineCode",{parentName:"p"},"src")," attribute is a JavaScript expression. It's not a string. It's a JavaScript expression that will be evaluated at runtime through some webpack goodness."),(0,a.kt)("p",null,"This means that we need to do a little more work to transform it into a Cloudinary URL. We need to wrap the expression in backticks and prefix it with ",(0,a.kt)("inlineCode",{parentName:"p"},"https://res.cloudinary.com/${cloudName}/image/fetch/${baseUrl}")," where ",(0,a.kt)("inlineCode",{parentName:"p"},"${baseUrl}")," is the base URL of your website. We also need to prefix the expression with a ",(0,a.kt)("inlineCode",{parentName:"p"},"$")," to indicate that it's a JavaScript expression. Tough to read but it works."),(0,a.kt)("h2",o({},{id:"using-the-plugin"}),"Using the plugin"),(0,a.kt)("p",null,"Now we have our plugin, we can use it. We need to add it to our ",(0,a.kt)("inlineCode",{parentName:"p"},"docusaurus.config.js")," file. We do this by adding it to the ",(0,a.kt)("inlineCode",{parentName:"p"},"rehypePlugins")," array:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"//@ts-check\nconst docusaurusCloudinaryRehypePlugin = require('./docusaurus-cloudinary-rehype-plugin');\n\nconst url = 'https://blog.johnnyreilly.com';\n\n/** @type {import('@docusaurus/types').Config} */\nconst config = {\n  // ...\n  presets: [\n    [\n      '@docusaurus/preset-classic',\n      /** @type {import('@docusaurus/preset-classic').Options} */\n      ({\n        // ...\n        blog: {\n          // ...\n          rehypePlugins: [\n            [\n              docusaurusCloudinaryRehypePlugin,\n              {\n                cloudName: 'demo',\n                baseUrl: url,\n              },\n            ],\n          ],\n          // ...\n        },\n        // ...\n      }),\n    ],\n  ],\n  // ...\n};\n\nmodule.exports = config;\n")),(0,a.kt)("p",null,"Note that we pass in the name of our Cloudinary account and the base URL of our website. We can now run our website and see the images being transformed into Cloudinary URLs:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of image being served from the Cloudinary CDN",src:n(25558).Z,width:"2536",height:"1266"})),(0,a.kt)("p",null,"Excellent! We're now serving our images from the Cloudinary CDN."),(0,a.kt)("h2",o({},{id:"introducing-rehype-cloudinary-docusaurus"}),"Introducing ",(0,a.kt)("inlineCode",{parentName:"h2"},"rehype-cloudinary-docusaurus")),(0,a.kt)("p",null,"But who wants to make a rehype plugin? I don't. I want to use a rehype plugin. So I created one. It's called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/rehype-cloudinary-docusaurus"}),(0,a.kt)("inlineCode",{parentName:"a"},"rehype-cloudinary-docusaurus"))," and you can find it on npm. It's a drop-in replacement for the plugin we created above. You can add it like this (use whichever package manager CLI tool you prefer):"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"npm i rehype-cloudinary-docusaurus\n")),(0,a.kt)("p",null,"And then usage is:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"//@ts-check\nconst docusaurusCloudinaryRehypePlugin = require('rehype-cloudinary-docusaurus');\n\nconst url = 'https://blog.johnnyreilly.com';\n\n/** @type {import('@docusaurus/types').Config} */\nconst config = {\n  // ...\n  presets: [\n    [\n      '@docusaurus/preset-classic',\n      /** @type {import('@docusaurus/preset-classic').Options} */\n      ({\n        // ...\n        blog: {\n          // ...\n          rehypePlugins: [\n            [\n              docusaurusCloudinaryRehypePlugin,\n              {\n                cloudName: 'demo',\n                baseUrl: url,\n              },\n            ],\n          ],\n          // ...\n        },\n        // ...\n      }),\n    ],\n  ],\n  // ...\n};\n\nmodule.exports = config;\n")),(0,a.kt)("p",null,"You will also need to disable the ",(0,a.kt)("inlineCode",{parentName:"p"},"url-loader")," in your Docusaurus build which transforms images into base64 strings, as this will conflict with the plugin. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/pull/5498"}),"There isn't a first class way to do this in Docusaurus at present"),". However by setting the environment variable ",(0,a.kt)("inlineCode",{parentName:"p"},"WEBPACK_URL_LOADER_LIMIT")," to ",(0,a.kt)("inlineCode",{parentName:"p"},"0")," you can disable it. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/pull/397"}),"You can see an implementation example in this pull request"),". It amounts to adding the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/kentcdodds/cross-env"}),(0,a.kt)("inlineCode",{parentName:"a"},"cross-env"))," package and then adding the following to your ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'    "build": "cross-env WEBPACK_URL_LOADER_LIMIT=0 docusaurus build",\n')),(0,a.kt)("h2",o({},{id:"what-about-pull-request-previews"}),"What about pull request previews?"),(0,a.kt)("p",null,"We've done all the hard stuff, now let's do some finessing. We want to make sure that our pull request previews still work. My blog runs on Azure Static Web Apps and benefits from a ",(0,a.kt)("a",o({parentName:"p"},{href:"/azure-static-web-apps-a-netlify-alternative"}),"staging environments / pull request previews feature that lets you see a change before it is merged"),". It's useful not only for human intrigue, but for running ",(0,a.kt)("a",o({parentName:"p"},{href:"/lighthouse-meet-github-actions"}),"tools like Lighthouse against your site to catch issues"),"."),(0,a.kt)("p",null,"We don't want to be serving images from the Cloudinary CDN when we're running a pull request preview. We could make it work, but it doesn't seem worth the candle. We can just serve the images from our website."),(0,a.kt)("p",null,"However, to support that we need to have a mechanism to detect when we're running a pull request preview. We can do that by setting an environment variable in our Azure Static Web Apps configuration:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"- name: Install and build site \ud83d\udd27\n  run: |\n    cd blog-website\n    yarn install --frozen-lockfile\n    USE_CLOUDINARY=${{ github.event_name != 'pull_request' }} yarn run build\n")),(0,a.kt)("p",null,"The above code sets an environment variable called ",(0,a.kt)("inlineCode",{parentName:"p"},"USE_CLOUDINARY")," to ",(0,a.kt)("inlineCode",{parentName:"p"},"false")," if the GitHub Action is running for a pull request, and ",(0,a.kt)("inlineCode",{parentName:"p"},"true")," if not. ",(0,a.kt)("a",o({parentName:"p"},{href:"/azure-static-web-apps-build-app-externally"}),"You'll note that I'm building my website externally to the Azure Static Web Apps build process"),". If I was building my website as part of the Azure Static Web Apps build process, I'd use the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://learn.microsoft.com/en-us/azure/static-web-apps/build-configuration?tabs=github-actions#custom-build-commands"}),"custom ",(0,a.kt)("inlineCode",{parentName:"a"},"app_build_command")," feature")," to set the environment variable."),(0,a.kt)("p",null,"With our environment variable in place, we can conditionally add the plugin to our ",(0,a.kt)("inlineCode",{parentName:"p"},"rehypePlugins")," array:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"//@ts-check\nconst docusaurusCloudinaryRehypePlugin = require('rehype-cloudinary-docusaurus');\n\nconst USE_CLOUDINARY = process.env['USE_CLOUDINARY'] === 'true';\n\nconst url = 'https://blog.johnnyreilly.com';\n\n/** @type {import('@docusaurus/types').Config} */\nconst config = {\n  // ...\n  presets: [\n    [\n      '@docusaurus/preset-classic',\n      /** @type {import('@docusaurus/preset-classic').Options} */\n      ({\n        // ...\n        blog: {\n          // ...\n          rehypePlugins: USE_CLOUDINARY\n            ? [\n                [\n                  docusaurusCloudinaryRehypePlugin,\n                  {\n                    cloudName: 'demo',\n                    baseUrl: url,\n                  },\n                ],\n              ]\n            : [],\n          // ...\n        },\n        // ...\n      }),\n    ],\n  ],\n\n  // ...\n};\n\nmodule.exports = config;\n")),(0,a.kt)("p",null,"With that in place, images will be served from the Cloudinary CDN when we're running our website normally, but will be served from our website when we're running a pull request preview."),(0,a.kt)("h2",o({},{id:"core-web-vitals-and-preconnect"}),"Core Web Vitals and preconnect"),(0,a.kt)("p",null,"Finally, it's worth adding an entry to the ",(0,a.kt)("inlineCode",{parentName:"p"},"headTags")," of your ",(0,a.kt)("inlineCode",{parentName:"p"},"docusaurus.config.js")," to ensure that your site preconnects to Cloudinary's CDN. This speeds up the time until images will be served to your users. That addition looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"/** @type {import('@docusaurus/types').Config} */\nconst config = {\n  // ...\n  headTags: [\n    // ...\n\n    // <link rel=\"preconnect\" href=\"https://res.cloudinary.com\" />\n    {\n      tagName: 'link',\n      attributes: {\n        rel: 'preconnect',\n        href: 'https://res.cloudinary.com',\n      },\n    },\n\n    // ...\n  ],\n  // ...\n};\n")),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"We've seen how we can use a rehype plugin to transform HTML image syntax into Cloudinary URLs. We've also seen how we can use an environment variable to conditionally add the plugin to our Docusaurus configuration."))}d.isMDXComponent=!0},88082:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"application-insights-bicep-azure-static-web-apps",title:"Using Application Insights with Bicep to monitor Azure Static Web Apps and Azure Functions",authors:"johnnyreilly",tags:["Azure Static Web Apps","Application Insights","Azure Functions","Bicep"],image:"./title-image.png",description:"Application Insights are a great way to monitor Azure Static Web Apps and Azure Functions. But how do you deploy that using Bicep? Let's find out!",hide_table_of_contents:!1},s=void 0,l={permalink:"/application-insights-bicep-azure-static-web-apps",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2023-01-01-application-insights-bicep-azure-static-web-apps/index.md",source:"@site/blog/2023-01-01-application-insights-bicep-azure-static-web-apps/index.md",title:"Using Application Insights with Bicep to monitor Azure Static Web Apps and Azure Functions",description:"Application Insights are a great way to monitor Azure Static Web Apps and Azure Functions. But how do you deploy that using Bicep? Let's find out!",date:"2023-01-01T00:00:00.000Z",formattedDate:"January 1, 2023",tags:[{label:"Azure Static Web Apps",permalink:"/tags/azure-static-web-apps"},{label:"Application Insights",permalink:"/tags/application-insights"},{label:"Azure Functions",permalink:"/tags/azure-functions"},{label:"Bicep",permalink:"/tags/bicep"}],readingTime:5.605,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"application-insights-bicep-azure-static-web-apps",title:"Using Application Insights with Bicep to monitor Azure Static Web Apps and Azure Functions",authors:"johnnyreilly",tags:["Azure Static Web Apps","Application Insights","Azure Functions","Bicep"],image:"./title-image.png",description:"Application Insights are a great way to monitor Azure Static Web Apps and Azure Functions. But how do you deploy that using Bicep? Let's find out!",hide_table_of_contents:!1},prevItem:{title:"Azure Pipelines - Node.js 16 and custom pipelines task extensions",permalink:"/azure-pipelines-custom-pipelines-task-extension-node-16"},nextItem:{title:"Serving Docusaurus images with Cloudinary",permalink:"/docusaurus-image-cloudinary-rehype-plugin"}},p={image:n(76364).Z,authorsImageUrls:[void 0]},u=[{value:"Updated 9 March 2023",id:"updated-9-march-2023",level:2},{value:"Monitoring Azure Static Web Apps",id:"monitoring-azure-static-web-apps",level:2},{value:"Deploying Application Insights with Bicep",id:"deploying-application-insights-with-bicep",level:2},{value:"Using the Application Insights module",id:"using-the-application-insights-module",level:2},{value:"Configuring the Azure Static Web App to use Application Insights",id:"configuring-the-azure-static-web-app-to-use-application-insights",level:2},{value:"1. Configuring the Azure Static Web App and Azure Function to use Application Insights",id:"1-configuring-the-azure-static-web-app-and-azure-function-to-use-application-insights",level:3},{value:"2. Connecting the Azure Static Web App to the Application Insights resource in the Azure Portal",id:"2-connecting-the-azure-static-web-app-to-the-application-insights-resource-in-the-azure-portal",level:3},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Application Insights are a great way to monitor Azure Static Web Apps and Azure Functions. But how do you deploy that using Bicep? Let's find out!"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Using Application Insights with Bicep to monitor Azure Static Web Apps and Azure Functions&quot; with the Bicep, Application Insights, Azure Static Web Apps and Azure Functions logos",src:n(76364).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"updated-9-march-2023"}),"Updated 9 March 2023"),(0,a.kt)("p",null,"I've updated this post to use the correct configuration approach for Static Web Apps with Azure Functions. Historically they used to be configured separately but that's no longer the case. You can see some discussion of this ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/Azure/static-web-apps/issues/1089#issuecomment-1458710885"}),"on this GitHub issue"),"."),(0,a.kt)("p",null,"To be super clear; the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://learn.microsoft.com/en-us/azure/templates/microsoft.web/staticsites/config-functionappsettings?pivots=deployment-language-bicep"}),(0,a.kt)("inlineCode",{parentName:"a"},"Microsoft.Web/staticSites/config@2022-03-01")," ",(0,a.kt)("inlineCode",{parentName:"a"},"functionappsettings")," is deprecated"),". Don't use it. Use the ",(0,a.kt)("inlineCode",{parentName:"p"},"appsettings")," resource alone instead."),(0,a.kt)("h2",o({},{id:"monitoring-azure-static-web-apps"}),"Monitoring Azure Static Web Apps"),(0,a.kt)("p",null,"This post should possibly win some kind of \"least pithy blog title\" award. But it's definitely descriptive. Let's get into it."),(0,a.kt)("p",null,"I recently wrote ",(0,a.kt)("a",o({parentName:"p"},{href:"/azure-static-web-apps-dynamic-redirects-azure-functions"}),"about using dynamic redirects in Azure Static Web Apps using the Azure Function they support"),". I wanted to monitor the redirects that were being performed. I knew I could do this with Application Insights. But how do I deploy Application Insights using Bicep?"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://johnnyreilly.com"}),"My blog")," runs on Azure Static Web Apps which is deployed using Bicep. ",(0,a.kt)("a",o({parentName:"p"},{href:"/migrating-from-github-pages-to-azure-static-web-apps"}),"I've written about deploying Azure Static Web Apps with Bicep previously"),". I wanted to add Application Insights to that deployment."),(0,a.kt)("h2",o({},{id:"deploying-application-insights-with-bicep"}),"Deploying Application Insights with Bicep"),(0,a.kt)("p",null,"The first thing we need to do is deploy the Application Insights workspace. This is a resource that is required for Application Insights to work. And then deploy an Application Insights resource that uses it. We can achieve that with the following ",(0,a.kt)("inlineCode",{parentName:"p"},"appInsights.bicep")," Bicep module:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param location string\nparam tags object\nparam workspaceName string = 'appInsightsWorkspace'\nparam appInsightsName string = 'appInsights'\n\n// https://learn.microsoft.com/en-us/azure/templates/microsoft.operationalinsights/workspaces?pivots=deployment-language-bicep\nresource workspace 'Microsoft.OperationalInsights/workspaces@2022-10-01' = {\n  name: workspaceName\n  location: location\n  tags: tags\n  properties: {\n    sku: {\n      name: 'PerGB2018'\n    }\n    retentionInDays: 30\n    workspaceCapping: {}\n  }\n}\n\n// https://learn.microsoft.com/en-us/azure/templates/microsoft.insights/components?pivots=deployment-language-bicep\nresource appInsights 'Microsoft.Insights/components@2020-02-02' = {\n  name: appInsightsName\n  location: location\n  kind: 'other'\n  properties: {\n    Application_Type: 'web'\n    Flow_Type: 'Bluefield'\n    WorkspaceResourceId: workspace.id\n    RetentionInDays: 90\n    IngestionMode: 'LogAnalytics'\n    publicNetworkAccessForIngestion: 'Enabled'\n    publicNetworkAccessForQuery: 'Enabled'\n  }\n}\n\noutput appInsightsId string = appInsights.id\noutput appInsightsInstrumentationKey string = appInsights.properties.InstrumentationKey\noutput appInsightsConnectionString string = appInsights.properties.ConnectionString\n")),(0,a.kt)("p",null,"You'll note we're outputting the ",(0,a.kt)("inlineCode",{parentName:"p"},"id"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"InstrumentationKey")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"ConnectionString")," properties of the Application Insights resource. We'll need those later."),(0,a.kt)("h2",o({},{id:"using-the-application-insights-module"}),"Using the Application Insights module"),(0,a.kt)("p",null,"We can now use the module in our ",(0,a.kt)("inlineCode",{parentName:"p"},"main.bicep")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param location string\nparam branch string\nparam staticWebAppName string\nparam tags object\n@secure()\nparam repositoryToken string\nparam rootCustomDomainName string\nparam blogCustomDomainName string\nparam workspaceName string = 'blog-app-insights-workspace'\nparam appInsightsName string = 'blog-app-insights'\n\nmodule appInsights './appInsights.bicep' = {\n  name: 'appInsights'\n  params: {\n    location: location\n    tags: tags\n    workspaceName: workspaceName\n    appInsightsName: appInsightsName\n  }\n}\n\nmodule staticWebApp './staticWebApp.bicep' = {\n  name: 'staticWebApp'\n  params: {\n    location: location\n    branch: branch\n    staticWebAppName: staticWebAppName\n    tags: tags\n    repositoryToken: repositoryToken\n    rootCustomDomainName: rootCustomDomainName\n    blogCustomDomainName: blogCustomDomainName\n    appInsightsId: appInsights.outputs.appInsightsId\n    appInsightsConnectionString: appInsights.outputs.appInsightsConnectionString\n    appInsightsInstrumentationKey: appInsights.outputs.appInsightsInstrumentationKey\n  }\n}\n\noutput staticWebAppDefaultHostName string = staticWebApp.outputs.staticWebAppDefaultHostName\noutput staticWebAppId string = staticWebApp.outputs.staticWebAppId\noutput staticWebAppName string = staticWebApp.outputs.staticWebAppName\n")),(0,a.kt)("p",null,"There's a few things to note here:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"We have two modules. One for the Application Insights workspace and one for the Azure Static Web App."),(0,a.kt)("li",{parentName:"ul"},"The Static Web App module ",(0,a.kt)("em",{parentName:"li"},"depends")," on the outputs from the Application Insights module. This is because we need the ",(0,a.kt)("inlineCode",{parentName:"li"},"id"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"InstrumentationKey")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"ConnectionString")," properties of the Application Insights resource.")),(0,a.kt)("h2",o({},{id:"configuring-the-azure-static-web-app-to-use-application-insights"}),"Configuring the Azure Static Web App to use Application Insights"),(0,a.kt)("p",null,"At this point we have something that deploys the Application Insights. The interesting part now is how we configure the Azure Static Web App to use Application Insights. We need to do that in the ",(0,a.kt)("inlineCode",{parentName:"p"},"staticWebApp.bicep")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"param location string\nparam branch string\nparam staticWebAppName string\nparam tags object\n@secure()\nparam repositoryToken string\nparam rootCustomDomainName string\nparam blogCustomDomainName string\nparam appInsightsId string\nparam appInsightsInstrumentationKey string\nparam appInsightsConnectionString string\n\nvar tagsWithHiddenLinks = union({\n  'hidden-link: /app-insights-resource-id': appInsightsId\n  'hidden-link: /app-insights-instrumentation-key': appInsightsInstrumentationKey\n  'hidden-link: /app-insights-conn-string': appInsightsConnectionString\n}, tags)\n\nresource staticWebApp 'Microsoft.Web/staticSites@2022-03-01' = {\n  name: staticWebAppName\n  location: location\n  tags: tagsWithHiddenLinks\n  sku: {\n    name: 'Free'\n    tier: 'Free'\n  }\n  properties: {\n    repositoryUrl: 'https://github.com/johnnyreilly/blog.johnnyreilly.com'\n    repositoryToken: repositoryToken\n    branch: branch\n    provider: 'GitHub'\n    stagingEnvironmentPolicy: 'Enabled'\n    allowConfigFileUpdates: true\n    buildProperties:{\n      skipGithubActionWorkflowGeneration: true\n    }\n  }\n}\n\nresource staticWebAppAppSettings 'Microsoft.Web/staticSites/config@2022-03-01' = {\n  name: 'appsettings'\n  kind: 'string'\n  parent: staticWebApp\n  properties: {\n    APPINSIGHTS_INSTRUMENTATIONKEY: appInsightsInstrumentationKey\n    APPLICATIONINSIGHTS_CONNECTION_STRING: appInsightsConnectionString\n  }\n}\n\nresource rootCustomDomain 'Microsoft.Web/staticSites/customDomains@2022-03-01' = {\n  parent: staticWebApp\n  name: rootCustomDomainName\n  properties: {}\n}\n\nresource blogCustomDomain 'Microsoft.Web/staticSites/customDomains@2022-03-01' = {\n  parent: staticWebApp\n  name: blogCustomDomainName\n  properties: {}\n}\n\noutput staticWebAppDefaultHostName string = staticWebApp.properties.defaultHostname\noutput staticWebAppId string = staticWebApp.id\noutput staticWebAppName string = staticWebApp.name\n")),(0,a.kt)("p",null,"There's some code here you can ignore; the part related to custom domains for instance."),(0,a.kt)("p",null,"But there's two relevant things to note:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Configuring the Azure Static Web App and Azure Function to use Application Insights"),(0,a.kt)("li",{parentName:"ol"},"Connecting the Azure Static Web App to the Application Insights resource in the Azure Portal")),(0,a.kt)("h3",o({},{id:"1-configuring-the-azure-static-web-app-and-azure-function-to-use-application-insights"}),"1. Configuring the Azure Static Web App and Azure Function to use Application Insights"),(0,a.kt)("p",null,"First of all, let's look at how we get data flowing from the Azure Static Web App and Azure Function to Application Insights:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"resource staticWebAppAppSettings 'Microsoft.Web/staticSites/config@2022-03-01' = {\n  name: 'appsettings'\n  kind: 'string'\n  parent: staticWebApp\n  properties: {\n    APPINSIGHTS_INSTRUMENTATIONKEY: appInsightsInstrumentationKey\n    APPLICATIONINSIGHTS_CONNECTION_STRING: appInsightsConnectionString\n  }\n}\n")),(0,a.kt)("p",null,"We're setting the ",(0,a.kt)("inlineCode",{parentName:"p"},"APPINSIGHTS_INSTRUMENTATIONKEY")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"APPLICATIONINSIGHTS_CONNECTION_STRING")," application settings on the Azure Static Web App and its associated Azure Function. These settings are what tells the Azure Static Web App and Azure Function to use Application Insights. Please note that the configuration above is ",(0,a.kt)("em",{parentName:"p"},"shared")," by the Azure Static Web App and Azure Function."),(0,a.kt)("h3",o({},{id:"2-connecting-the-azure-static-web-app-to-the-application-insights-resource-in-the-azure-portal"}),"2. Connecting the Azure Static Web App to the Application Insights resource in the Azure Portal"),(0,a.kt)("p",null,"The other thing we need to do is to connect the Azure Static Web App to the Application Insights resource in the Azure Portal. What that means is that when you click on the Application Insights resource in the Azure Portal, you'll have a button which takes you from the Azure Static Web App in the portal to Application Insights resource:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the Azure Portal Static Web App connected to the Application Insights resource",src:n(65534).Z,width:"1552",height:"856"})),(0,a.kt)("p",null,"This is done by setting the ",(0,a.kt)("inlineCode",{parentName:"p"},"hidden-link")," tags on the Azure Static Web App resource. Here's how we do that:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bicep"}),"var tagsWithHiddenLinks = union({\n  'hidden-link: /app-insights-resource-id': appInsightsId\n  'hidden-link: /app-insights-instrumentation-key': appInsightsInstrumentationKey\n  'hidden-link: /app-insights-conn-string': appInsightsConnectionString\n}, tags)\n\nresource staticWebApp 'Microsoft.Web/staticSites@2022-03-01' = {\n  name: staticWebAppName\n  location: location\n  tags: tagsWithHiddenLinks\n  // ...\n}\n")),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"With this in place, we can now deploy our Azure Static Web App with an Application Insights resource using Bicep and have the Azure Static Web App connected to, and providing data to, the Application Insights resource. Monitoring awaits!"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of Application Insights in the Azure Portal - see how they try to hack me with their spurious `sellers.json` requests ;-)",src:n(83262).Z,width:"3051",height:"1437"})))}d.isMDXComponent=!0},21215:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"azure-pipelines-custom-pipelines-task-extension-node-16",title:"Azure Pipelines - Node.js 16 and custom pipelines task extensions",authors:"johnnyreilly",tags:["Azure Pipelines","Node.js","typescript"],image:"./title-image.png",description:"Support for Node.js 16 for Azure Pipelines custom pipelines task extensions has arrived. From a TypeScript perspective, this post documents how to migrate.",hide_table_of_contents:!1},s=void 0,l={permalink:"/azure-pipelines-custom-pipelines-task-extension-node-16",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2023-01-05-azure-pipelines-custom-pipelines-task-extension-node-16/index.md",source:"@site/blog/2023-01-05-azure-pipelines-custom-pipelines-task-extension-node-16/index.md",title:"Azure Pipelines - Node.js 16 and custom pipelines task extensions",description:"Support for Node.js 16 for Azure Pipelines custom pipelines task extensions has arrived. From a TypeScript perspective, this post documents how to migrate.",date:"2023-01-05T00:00:00.000Z",formattedDate:"January 5, 2023",tags:[{label:"Azure Pipelines",permalink:"/tags/azure-pipelines"},{label:"Node.js",permalink:"/tags/node-js"},{label:"typescript",permalink:"/tags/typescript"}],readingTime:3.44,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"azure-pipelines-custom-pipelines-task-extension-node-16",title:"Azure Pipelines - Node.js 16 and custom pipelines task extensions",authors:"johnnyreilly",tags:["Azure Pipelines","Node.js","typescript"],image:"./title-image.png",description:"Support for Node.js 16 for Azure Pipelines custom pipelines task extensions has arrived. From a TypeScript perspective, this post documents how to migrate.",hide_table_of_contents:!1},prevItem:{title:"How I ruined my SEO",permalink:"/how-i-ruined-my-seo"},nextItem:{title:"Using Application Insights with Bicep to monitor Azure Static Web Apps and Azure Functions",permalink:"/application-insights-bicep-azure-static-web-apps"}},p={image:n(3913).Z,authorsImageUrls:[void 0]},u=[{value:"The road to Node.js 16",id:"the-road-to-nodejs-16",level:2},{value:"Migrating a task to Node.js 16",id:"migrating-a-task-to-nodejs-16",level:2},{value:"Updating TypeScript to use Node 16",id:"updating-typescript-to-use-node-16",level:2},{value:"How do we know we&#39;re using Node 16?",id:"how-do-we-know-were-using-node-16",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Support for Node.js 16 for Azure Pipelines custom pipelines task extensions has arrived. From a TypeScript perspective, this post documents how to migrate from a Node.js 10 custom task to one that runs on Node 16 using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/azure-pipelines-task-lib"}),(0,a.kt)("inlineCode",{parentName:"a"},"azure-pipelines-task-lib")),"."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Azure Pipelines - Node.js 16 and custom pipelines task extensions&quot; with Azure Pipelines, Node.js and TypeScript logos",src:n(3913).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"the-road-to-nodejs-16"}),"The road to Node.js 16"),(0,a.kt)("p",null,"Azure Pipelines custom pipelines task extensions have been around for a while. They're a great way to extend the functionality of Azure Pipelines. They're written in TypeScript and run on Node.js. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://learn.microsoft.com/en-us/azure/devops/extend/develop/add-build-task?view=azure-devops"}),"You can learn how to write one here"),". However, until recently they were restricted to only be able to run on Node.js 6 or Node.js 10. This was a problem as ",(0,a.kt)("a",o({parentName:"p"},{href:"https://endoflife.date/nodejs"}),"support for Node 6 ended in 2018 and Node 10 ended in 2020"),"."),(0,a.kt)("p",null,"A ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/azure-pipelines-agent/issues/3195"}),"GitHub issue was opened to track support for different Node versions with custom tasks"),", but it remained unresolved for a long time. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://learn.microsoft.com/en-us/azure/devops/release-notes/2022/sprint-210-update#node-16-task-runner-in-pipeline-agent"}),"In October 2022 it was announced that Node.js 16 support was available"),"."),(0,a.kt)("h2",o({},{id:"migrating-a-task-to-nodejs-16"}),"Migrating a task to Node.js 16"),(0,a.kt)("p",null,"There's an official migration guide to help you migrate your task from Node.js 6 or Node.js 10 to Node.js 16. It's ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/microsoft/azure-pipelines-tasks/blob/3ab93334eb3e5c1f3750403e3b6f976909ae45c3/docs/migrateNode16.md"}),"available here"),". It gave me a couple of pointers but I wanted to document the process in a bit more detail. Also, I wanted to show how you can start to get some benefits from being on Node.js 16 with TypeScript."),(0,a.kt)("p",null,"The version of the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.npmjs.com/package/azure-pipelines-task-lib"}),(0,a.kt)("inlineCode",{parentName:"a"},"azure-pipelines-task-lib"))," being used in the ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," should be incremented to ",(0,a.kt)("inlineCode",{parentName:"p"},"4.0.0")," or higher. If you haven't already, it's worth updating the ",(0,a.kt)("inlineCode",{parentName:"p"},"@types/node")," version to ",(0,a.kt)("inlineCode",{parentName:"p"},"16.0.0")," or higher. This will give you access to the types of the Node 16 APIs."),(0,a.kt)("p",null,"The migration guide suggests updating the ",(0,a.kt)("inlineCode",{parentName:"p"},"task.json")," to have a ",(0,a.kt)("inlineCode",{parentName:"p"},"Node16")," property alongside the existing ",(0,a.kt)("inlineCode",{parentName:"p"},"Node10")," one:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),'"execution": {\n  "Node10": {\n    "target": "bash.js",\n    "argumentFormat": ""\n  },\n+  "Node16": {\n+    "target": "bash.js",\n+    "argumentFormat": ""\n+  }\n}\n')),(0,a.kt)("p",null,"I'm rather unclear as to the benefits of having a ",(0,a.kt)("inlineCode",{parentName:"p"},"Node10")," and a ",(0,a.kt)("inlineCode",{parentName:"p"},"Node16")," alongside each other; there's no useful reason to do so that I can come up with. I may be missing something."),(0,a.kt)("p",null,"Either way, in my own case I wanted to take advantage of the Node 16 environment and so I removed the ",(0,a.kt)("inlineCode",{parentName:"p"},"Node10")," property entirely. My ",(0,a.kt)("inlineCode",{parentName:"p"},"task.json")," now looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'  "execution": {\n    "Node16": {\n      "target": "index.js"\n    }\n  }\n')),(0,a.kt)("p",null,"This was all I needed to do, to get to the point of having a Node 16 compatible task. But we want to go a little further."),(0,a.kt)("h2",o({},{id:"updating-typescript-to-use-node-16"}),"Updating TypeScript to use Node 16"),(0,a.kt)("p",null,"Now we have Node 16, we can now start using some of the APIs available there if we'd like, and we can stop transpiling to an older version of JavaScript. To do this we need to update our TypeScript configuration in our ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),"-    \"target\": \"es6\" /* Specify ECMAScript target version: 'ES3' (default), 'ES5', 'ES2015', 'ES2016', 'ES2017', 'ES2018', 'ES2019', 'ES2020', or 'ESNEXT'. */,\n-    \"lib\": [] /* Specify library files to be included in the compilation. */,\n+    \"target\": \"es2021\" /* Specify ECMAScript target version: 'ES3' (default), 'ES5', 'ES2015', 'ES2016', 'ES2017', 'ES2018', 'ES2019', 'ES2020', or 'ESNEXT'. */,\n+    \"lib\": [\"ES2021\"] /* Specify library files to be included in the compilation. */,\n")),(0,a.kt)("p",null,"Here we're just changing the emitted JavaScript to be more modern. We're also updating the ",(0,a.kt)("inlineCode",{parentName:"p"},"lib")," property to include the ",(0,a.kt)("inlineCode",{parentName:"p"},"ES2021")," library. This will give us access to the types of the Node 16 APIs."),(0,a.kt)("h2",o({},{id:"how-do-we-know-were-using-node-16"}),"How do we know we're using Node 16?"),(0,a.kt)("p",null,"Great question! I was suspicious that the task was still running on Node 10. I wanted to know for sure. I ran a migrated task with system diagnostics enabled:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of Azure Pipelines including the text &quot;##[debug]Using node path: /home/vsts/agents/2.213.2/externals/node16/bin/node&quot;",src:n(26225).Z,width:"1204",height:"194"})),(0,a.kt)("p",null,"As we can see, we're using Node 16. This is great news!"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"##[debug]Using node path: /home/vsts/agents/2.213.2/externals/node16/bin/node\n")),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"That's it, we're now writing modern custom pipelines task extensions using Node.js 16 and TypeScript. Fingers crossed it won't be such a long wait for newer versions of Node.js to be supported! \ud83e\udd1e"))}d.isMDXComponent=!0},69189:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"how-i-ruined-my-seo",title:"How I ruined my SEO",authors:"johnnyreilly",tags:["SEO"],image:"./title-image.png",description:"In October 2022 traffic to my blog dropped like a stone. What happened?",hide_table_of_contents:!1},s=void 0,l={permalink:"/how-i-ruined-my-seo",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2023-01-15-how-i-ruined-my-seo/index.md",source:"@site/blog/2023-01-15-how-i-ruined-my-seo/index.md",title:"How I ruined my SEO",description:"In October 2022 traffic to my blog dropped like a stone. What happened?",date:"2023-01-15T00:00:00.000Z",formattedDate:"January 15, 2023",tags:[{label:"SEO",permalink:"/tags/seo"}],readingTime:8.96,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"how-i-ruined-my-seo",title:"How I ruined my SEO",authors:"johnnyreilly",tags:["SEO"],image:"./title-image.png",description:"In October 2022 traffic to my blog dropped like a stone. What happened?",hide_table_of_contents:!1},prevItem:{title:"Docusaurus: improving Core Web Vitals with fetchpriority",permalink:"/docusaurus-improve-core-web-vitals-fetchpriority"},nextItem:{title:"Azure Pipelines - Node.js 16 and custom pipelines task extensions",permalink:"/azure-pipelines-custom-pipelines-task-extension-node-16"}},p={image:n(15194).Z,authorsImageUrls:[void 0]},u=[{value:"What I did on my holidays",id:"what-i-did-on-my-holidays",level:2},{value:"Upgraded to Docusaurus 2.2",id:"upgraded-to-docusaurus-22",level:2},{value:"Added fontaine",id:"added-fontaine",level:2},{value:"Google Analytics - sharing my g-tag with the Docusaurus docs",id:"google-analytics---sharing-my-g-tag-with-the-docusaurus-docs",level:2},{value:"Googles new spam update",id:"googles-new-spam-update",level:2},{value:"From PNG to WebP and back again",id:"from-png-to-webp-and-back-again",level:2},{value:"Backlinks / referring domains",id:"backlinks--referring-domains",level:2},{value:"RSS feeds",id:"rss-feeds",level:2},{value:"Dynamic redirects - too little too late?",id:"dynamic-redirects---too-little-too-late",level:2},{value:"Help me Obi-Wan, you&#39;re my only hope",id:"help-me-obi-wan-youre-my-only-hope",level:2},{value:"Discussion on Hacker News",id:"discussion-on-hacker-news",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"In October 2022 traffic to my blog dropped like a stone. What happened? Somehow I ruined my SEO. Don't be me. I'll tell you what I got up to and hopefully you can avoid doing the same."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;How I ruined my SEO&quot; with an image of a tire fire in the background",src:n(15194).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"what-i-did-on-my-holidays"}),"What I did on my holidays"),(0,a.kt)("p",null,"Naturally I blame all of this on a holiday to the British seaside. I was away for a week, and whilst I was away I did not have access to a laptop. This is intentional by the way; I spend too much time on computers one way or another. I force myself to disconnect on holidays. But whilst I didn't have the ability to program, I had the ability to ponder."),(0,a.kt)("p",null,"I found myself going down a rabbit hole on SEO. I'd never really thought about it previously, and I thought \"what would happen if I made some tweaks?\" My expectation was that I'd slightly improve my SEO. Probably not by much, but I'd learn something and it'd be fun. What actually happened was that in October 2022 (after my fiddling), traffic from search engines more or less dried up. Not quite the plan."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of google analytics demonstrating traffic rapidly tailing off",src:n(88528).Z,width:"2443",height:"1063"})),(0,a.kt)("p",null,"Odds are, the was probably because of my actions. I'm not sure what I did wrong, but I'm going to share what I did and maybe you can tell me where I pulled the pin out of the hand grenade."),(0,a.kt)("p",null,"Frustratingly, the feedback loop on SEO is anything but tight. You make a change, and then weeks (or months) later you see the results. And by then you've forgotten what you did. So I'm going to try and document what I did and what I think I did wrong."),(0,a.kt)("p",null,"Incidentally, I'm hoping someone will read this and tell me what I did wrong. I did something. I assume I did something. Come with me and embrace your inner Sherlock. I'm going to share evidence and maybe you can draw some conclusions."),(0,a.kt)("p",null,"So what did I get up to? In the time before my traffic fell off a cliff I did all kinds of things. Let's begin."),(0,a.kt)("h2",o({},{id:"upgraded-to-docusaurus-22"}),"Upgraded to Docusaurus 2.2"),(0,a.kt)("p",null,"My blog runs on Docusaurus. I upgraded from 2.1 to 2.2. I can't see why that would be an issue. I don't think it is."),(0,a.kt)("h2",o({},{id:"added-fontaine"}),"Added fontaine"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/pull/305"}),"I started using fontaine on my blog"),". If you haven't tried it out, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/danielroe/fontaine"}),"you can find it here"),". It helps reduce Cumulative Layout Shift. The flash of unstyled content jank that you can see when you first land on a site, before fonts have loaded. I can't see why that would be an issue. It should improve my blogs Core Web Vitals and help stuff rank better, not worse. I think this is a red herring."),(0,a.kt)("h2",o({},{id:"google-analytics---sharing-my-g-tag-with-the-docusaurus-docs"}),"Google Analytics - sharing my g-tag with the Docusaurus docs"),(0,a.kt)("p",null,'Here\'s where I suspect we may have a candidate. I did a foolish thing. You may be aware that Google are sunsetting Google Analytics as was, in favour of Google Analytics 4. I was using Google Analytics to track my blog traffic and thought "oh well I best migrate then".'),(0,a.kt)("p",null,"Migration involved using in a new plugin for Docusaurus. However, the docs weren't great. I managed to work out how to get it working, and I thought I'd help the community by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/pull/7252"}),"submitting a docs PR"),". Can you see where this is going?"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot showing me submitting my actual GA4 tag",src:n(95076).Z,width:"2963",height:"468"})),(0,a.kt)("p",null,"Yup. I managed to land my GA4 tag in the actual Docusaurus docs... I know, I know. I'm a mug. You might be wondering how I found out. Well the real giveaway was that I've never written any blogposts in Chinese."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of search console insights with traffic from Chinese websites",src:n(77465).Z,width:"1134",height:"1396"})),(0,a.kt)("p",null,"I started seeing unfamiliar entries in my search traffic. I couldn't work out what was going on. It didn't make sense. Then I remembered my PR and the terrible truth became apparent:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"It is a truth universally acknowledged, that a developer in possession of a good keyboard, must ",(0,a.kt)("strong",{parentName:"p"},"copy and paste"),".")),(0,a.kt)("p",null,"Nightmare. Other people were using my GA4 tag."),(0,a.kt)("p",null,"I did try to roll this back; search GitHub for my tag and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/pull/8313"}),"submit PRs to remove it"),". But not every PR was merged. In the end I gave up and created a new GA4 property and started again. Out there right now, there are still websites sending my old GA4 tag traffic to Google. What a horlicks."),(0,a.kt)("p",null,"I don't know if Google tracks for sites sharing analytics tags and deranks them as a consequence, but I suspect it's a possibility. Who knows? (Maybe you do? Tell me!)"),(0,a.kt)("h2",o({},{id:"googles-new-spam-update"}),"Googles new spam update"),(0,a.kt)("p",null,"When I started to see traffic tail off, I started to look around for clues. It turns out there's a subculture of SEO tools out there. I'm not sure how I missed them before. I found ",(0,a.kt)("a",o({parentName:"p"},{href:"https://ahrefs.com"}),"ahrefs")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://semrush.com"}),"semrush"),"; others too. This graph from ahrefs caught my eye:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of ahrefs demonstrating traffic rapidly tailing off aligned with google spam update",src:n(39576).Z,width:"1746",height:"1232"})),(0,a.kt)("p",null,"You can see everything going South for me in October. What you can also see are Google search updates on the X axis. It turns out Google regularly update their search algorithm. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://ahrefs.com/google-algorithm-updates#october-2022-spam-update-2022-10-19"}),"Interestingly, one of their updates coincides with my traffic tailing off"),"."),(0,a.kt)("blockquote",null,(0,a.kt)("h3",o({parentName:"blockquote"},{id:"october-2022-spam-update"}),"October 2022 Spam Update"),(0,a.kt)("p",{parentName:"blockquote"},"Spam updates target sites that don't follow the webmaster guidelines. Sites impacted by these updates may be seeking short term gains while ignoring best practices. This update was completed on October 21st."),(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/search/updates/spam-updates"}),"Google Search spam updates and your site \u2197"))),(0,a.kt)("p",null,'"Bingo!" I thought. "This is it!" But as I dug through the details, I became doubtful. Nothing on my site looks spammy. In my opinion obviously. But try as I might, I couldn\'t see it any other way. My content isn\'t spammy. Unless I\'m missing something? Am I?'),(0,a.kt)("h2",o({},{id:"from-png-to-webp-and-back-again"}),"From PNG to WebP and back again"),(0,a.kt)("p",null,"Most of the images on my blog were PNGs. Lighthouse would regularly suggest migrating to a newer image format. I read around and the suggestion generally was that WebP was the way to go. So I did. But I think I made a bit of a mistake. As the images were converted, their filenames changed."),(0,a.kt)("p",null,"Because I didn't think it mattered, I didn't implement redirects. My view was \"the blog posts have references to the new image names - that's likely all that matters\". I'd lay money that's a mistake; that I should have implemented redirects and the site is being penalised."),(0,a.kt)("p",null,"Again, do tell me if I'm running with a false assumption here."),(0,a.kt)("p",null,'Oh the "and back again". I make use of ',(0,a.kt)("a",o({parentName:"p"},{href:"/open-graph-sharing-previews-guide"}),"Open Graph sharing previews on my blog")," - so people using my links on social media get a nice preview of the content. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://www.stevefenton.co.uk/blog/2022/10/webp-opengraph-images/"}),"I learned from Steve Fenton that open graph doesn't always support WebP"),". Which sucks."),(0,a.kt)("p",null,"So I decided to revert my Open Graph images back to being PNGs; with entirely different names. Again I didn't implement redirects - no wonder Google loves me!"),(0,a.kt)("h2",o({},{id:"backlinks--referring-domains"}),"Backlinks / referring domains"),(0,a.kt)("p",null,"As I did my deepdive into SEO, I learned that backlinks and referring domains are important. I had a lot of them; I've been blogging for a long time. However, I suspect I had rather scorched the earth by failing to implement redirects. This chart from ahrefs shows the impact:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of an ahrefs graph showing a drop off in the number of referring domains around mid 2022",src:n(83590).Z,width:"1440",height:"556"})),(0,a.kt)("p",null,"My assumption here is that by failing to implement redirects, I've lost a lot of backlinks. Previous 200s had transitioned to be 404s and Google had noticed."),(0,a.kt)("h2",o({},{id:"rss-feeds"}),"RSS feeds"),(0,a.kt)("p",null,"I mentioned that I've been blogging a long time. Consequently I have a lot of blog posts. I also have ",(0,a.kt)("a",o({parentName:"p"},{href:"/atom.xml"}),"Atom")," / ",(0,a.kt)("a",o({parentName:"p"},{href:"/rss.xml"}),"RSS")," feeds on my blog. I didn't realise that there are limits on the size of these feeds. It doesn't appear to be standardised; but when I took a look at my feeds in various feed readers, I found they were erroring due to the size of the feeds."),(0,a.kt)("p",null,"I decided to start truncating the number of entries in my feeds. It's not so hard to do, just a post build step which ",(0,a.kt)("a",o({parentName:"p"},{href:"/xml-read-and-write-with-node-js"}),"reads, amends and writes the XML"),"."),(0,a.kt)("p",null,"With this in place RSS readers seemed to be happier. And given a number of publications read my RSS feeds, it's likely that this will increase my backlinks over time."),(0,a.kt)("p",null,"I also contributed a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/pull/8378"}),"PR to Docusaurus")," that will allow everyone to configure and adjust the number of entries in their feeds directly through Docusaurus; as opposed to afterwards in a post build step."),(0,a.kt)("h2",o({},{id:"dynamic-redirects---too-little-too-late"}),"Dynamic redirects - too little too late?"),(0,a.kt)("p",null,"As I've mentioned, I broke links by not implementing redirects. It might be closing the stable door after the horse has bolted, but I decided to go back and implement redirects. In December 2022 ",(0,a.kt)("a",o({parentName:"p"},{href:"/azure-static-web-apps-dynamic-redirects-azure-functions"}),"I implemented dynamic redirects on my blog using Azure Static Web Apps and Azure Functions"),"."),(0,a.kt)("p",null,"I implemented redirects for:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"images"),(0,a.kt)("li",{parentName:"ul"},"blog posts (from my old Blogger URLs to my new Docusaurus URLs)"),(0,a.kt)("li",{parentName:"ul"},"RSS / Atom feeds (Blogger had both of these but at different endpoints)"),(0,a.kt)("li",{parentName:"ul"},"renamed blog posts (I renamed a number of blog posts over time to be more SEO friendly)")),(0,a.kt)("p",null,"I also decided to do some research. ",(0,a.kt)("a",o({parentName:"p"},{href:"/application-insights-bicep-azure-static-web-apps"}),"I plugged Application Insights into my blog")," and started logging out when redirects were being hit. I also started logging out when 404s were being hit. I wanted to see if I was missing anything. I've been checking the logs every day since, and adding new redirects as I go."),(0,a.kt)("p",null,"Will this help over time? Answers on a postcard please. Or toot / tweet / email / DM me."),(0,a.kt)("p",null,"As an aside, looking at the logs in itself has been a lesson:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"many redirects from Wordpress URLs",src:n(81664).Z,width:"3004",height:"1368"})),(0,a.kt)("p",null,"Someone on the internet is ",(0,a.kt)("em",{parentName:"p"},"always")," trying to hack you. And usually under the assumption you're running WordPress / PHP."),(0,a.kt)("h2",o({},{id:"help-me-obi-wan-youre-my-only-hope"}),"Help me Obi-Wan, you're my only hope"),(0,a.kt)("p",null,"As you can see, I've done a lot of tinkering. I'm not quite sure what torched my SEO. It may be one thing, it may be a combination of things. I don't know if there's a road back."),(0,a.kt)("p",null,"I'm hoping someone will read this and tell me what I did wrong. I did something. Or at least I assume I'm the cause. Maybe I'm not? Maybe I'm missing something entirely. If you know, please let me know. I really want to understand!"),(0,a.kt)("h2",o({},{id:"discussion-on-hacker-news"}),"Discussion on Hacker News"),(0,a.kt)("p",null,"This was disussed on Hacker News. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://news.ycombinator.com/item?id=34389421"}),"You can read the discussion here"),"."))}d.isMDXComponent=!0},81252:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"docusaurus-improve-core-web-vitals-fetchpriority",title:"Docusaurus: improving Core Web Vitals with fetchpriority",authors:"johnnyreilly",tags:["Core Web Vitals","Docusaurus","web performance"],image:"./title-image.png",description:"By using `fetchpriority` on your Largest Contentful Paint you can improve your Core Web Vitals. This post implements that with Docusaurus.",hide_table_of_contents:!1},s=void 0,l={permalink:"/docusaurus-improve-core-web-vitals-fetchpriority",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2023-01-18-docusaurus-improve-core-web-vitals-fetchpriority/index.md",source:"@site/blog/2023-01-18-docusaurus-improve-core-web-vitals-fetchpriority/index.md",title:"Docusaurus: improving Core Web Vitals with fetchpriority",description:"By using `fetchpriority` on your Largest Contentful Paint you can improve your Core Web Vitals. This post implements that with Docusaurus.",date:"2023-01-18T00:00:00.000Z",formattedDate:"January 18, 2023",tags:[{label:"Core Web Vitals",permalink:"/tags/core-web-vitals"},{label:"Docusaurus",permalink:"/tags/docusaurus"},{label:"web performance",permalink:"/tags/web-performance"}],readingTime:4.8,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"docusaurus-improve-core-web-vitals-fetchpriority",title:"Docusaurus: improving Core Web Vitals with fetchpriority",authors:"johnnyreilly",tags:["Core Web Vitals","Docusaurus","web performance"],image:"./title-image.png",description:"By using `fetchpriority` on your Largest Contentful Paint you can improve your Core Web Vitals. This post implements that with Docusaurus.",hide_table_of_contents:!1},prevItem:{title:"Image Optimisation with the TinyPNG API",permalink:"/image-optimisation-tinypng-api"},nextItem:{title:"How I ruined my SEO",permalink:"/how-i-ruined-my-seo"}},p={image:n(24211).Z,authorsImageUrls:[void 0]},u=[{value:"Avoiding lazy loading on the Largest Contentful Paint",id:"avoiding-lazy-loading-on-the-largest-contentful-paint",level:2},{value:"<code>fetchpriority</code>",id:"fetchpriority",level:2},{value:"Swizzling the image component",id:"swizzling-the-image-component",level:2},{value:"Adding <code>fetchpriority=&quot;high&quot;</code> to the LCP with a custom plugin",id:"adding-fetchpriorityhigh-to-the-lcp-with-a-custom-plugin",level:2},{value:"What does it look like when applied?",id:"what-does-it-look-like-when-applied",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"By using ",(0,a.kt)("inlineCode",{parentName:"p"},"fetchpriority")," on your Largest Contentful Paint you can improve your Core Web Vitals. This post implements that with Docusaurus."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Docusaurus: improving Core Web Vitals with fetchpriority&quot;",src:n(24211).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"avoiding-lazy-loading-on-the-largest-contentful-paint"}),"Avoiding lazy loading on the Largest Contentful Paint"),(0,a.kt)("p",null,"At the weekend ",(0,a.kt)("a",o({parentName:"p"},{href:"/how-i-ruined-my-seo"}),"I wrote a post documenting how I believe I ruined the SEO on my blog"),". That post ended up ",(0,a.kt)("a",o({parentName:"p"},{href:"https://news.ycombinator.com/item?id=34389421"}),"trending on Hacker News"),". People made suggestions around things I could do that could improve things. One post in particular caught my eye from ",(0,a.kt)("a",o({parentName:"p"},{href:"https://growtika.com"}),"Growtika")," saying:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Page speed: It's one of the most important ranking factor. You don't have to get 100 score, but passing the core web vitals score and having higher score on mobile is recommended."),(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("a",o({parentName:"p"},{href:"https://pagespeed.web.dev/report?url=https%3A%2F%2Fjohnnyreilly.com%2F&form_factor=mobile"}),"https://pagespeed.web.dev/report?url=https%3A%2F%2Fjohnnyreilly.com%2F&form_factor=mobile")),(0,a.kt)("p",{parentName:"blockquote"},"A cool trick to improve the result fast is by removing the lazy load effect from the LCP:")),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of web test results that reads largest contentful paint image was lazily loaded ",src:n(79193).Z,width:"2220",height:"1014"})),(0,a.kt)("p",null,"Another person chimed in with:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Indeed. Even better, making it high priority instead of normal: ",(0,a.kt)("a",o({parentName:"p"},{href:"https://addyosmani.com/blog/fetch-priority/"}),"https://addyosmani.com/blog/fetch-priority/"))),(0,a.kt)("h2",o({},{id:"fetchpriority"}),(0,a.kt)("inlineCode",{parentName:"h2"},"fetchpriority")),(0,a.kt)("p",null,"I hadn't heard of ",(0,a.kt)("inlineCode",{parentName:"p"},"fetchpriority")," before this, but the linked article by ",(0,a.kt)("a",o({parentName:"p"},{href:"https://addyosmani.com"}),"Addy Osmani")," carried this tip:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Add ",(0,a.kt)("inlineCode",{parentName:"p"},'fetchpriority="high"')," to your Largest Contentful Paint (LCP) image to get it to load sooner. Priority Hints sped up Etsy\u2019s LCP by 4% with some sites seeing an improvement of up to 20-30% in their lab tests. In many cases, fetchpriority should lead to a nice boost for LCP.")),(0,a.kt)("p",null,"I was keen to try this out. Somewhat interestingly, I was the person responsible for ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/pull/6598"}),"originally contributing lazy loading to Docusaurus"),". For what it's worth, lazy loading is a ",(0,a.kt)("em",{parentName:"p"},"good thing")," to do. It's just that in this case, it was causing the LCP to be lazy loaded. I wanted to change that."),(0,a.kt)("h2",o({},{id:"swizzling-the-image-component"}),"Swizzling the image component"),(0,a.kt)("p",null,"Since my initial contribution, the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/pull/6990"}),"implementation had been tweaked to allow user control via Swizzling"),". By the way, ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/docs/swizzling"}),"swizzling is a great feature of Docusaurus"),". It allows you to override the default implementation of a component. In this case, I wanted to override the ",(0,a.kt)("inlineCode",{parentName:"p"},"Img")," component and opt out of lazy loading. I did this by running the following command:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"yarn swizzle @docusaurus/theme-classic MDXComponents/Img -- --eject\n")),(0,a.kt)("p",null,"This created a file at ",(0,a.kt)("inlineCode",{parentName:"p"},"src/theme/MDXComponents/Img.js"),". I then made the following change:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),"import React from 'react';\nimport clsx from 'clsx';\nimport styles from './styles.module.css';\nfunction transformImgClassName(className) {\n  return clsx(className, styles.img);\n}\nexport default function MDXImg(props) {\n  return (\n    // eslint-disable-next-line jsx-a11y/alt-text\n    <img\n-      loading=\"lazy\"\n      {...props}\n      className={transformImgClassName(props.className)}\n    />\n  );\n}\n")),(0,a.kt)("p",null,"Getting rid of the ",(0,a.kt)("inlineCode",{parentName:"p"},'loading="lazy"')," attribute was all I needed to do. This gets us to the point where none of our images are lazy loaded anymore. Stage 1 complete!"),(0,a.kt)("h2",o({},{id:"adding-fetchpriorityhigh-to-the-lcp-with-a-custom-plugin"}),"Adding ",(0,a.kt)("inlineCode",{parentName:"h2"},'fetchpriority="high"')," to the LCP with a custom plugin"),(0,a.kt)("p",null,"The next thing to do was to write a small Rehype plugin to add ",(0,a.kt)("inlineCode",{parentName:"p"},'fetchpriority="high"')," to the LCP. I did this by creating a new JavaScript file called ",(0,a.kt)("inlineCode",{parentName:"p"},"image-fetchpriority-rehype-plugin.js"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"// @ts-check\nconst visit = require('unist-util-visit');\n\n/**\n * Create a rehype plugin that will make the first image eager loaded with fetchpriority=\"high\" and lazy load all other images\n * @returns rehype plugin that will make the first image eager loaded with fetchpriority=\"high\" and lazy load all other images\n */\nfunction imageFetchPriorityRehypePluginFactory() {\n  /** @type {Map<string, string>} */ const files = new Map();\n\n  /** @type {import('unified').Transformer} */\n  return (tree, vfile) => {\n    visit(tree, ['element', 'jsx'], (node) => {\n      if (node.type === 'element' && node['tagName'] === 'img') {\n        // handles nodes like this:\n        // {\n        //   type: 'element',\n        //   tagName: 'img',\n        //   properties: {\n        //     src: 'https://some.website.com/cat.gif',\n        //     alt: null\n        //   },\n        //   ...\n        // }\n\n        const key = `img|${vfile.history[0]}`;\n        const imageAlreadyProcessed = files.get(key);\n        const fetchpriorityThisImage =\n          !imageAlreadyProcessed ||\n          imageAlreadyProcessed === node['properties']['src'];\n\n        if (!imageAlreadyProcessed) {\n          files.set(key, node['properties']['src']);\n        }\n\n        if (fetchpriorityThisImage) {\n          node['properties'].fetchpriority = 'high';\n          node['properties'].loading = 'eager';\n        } else {\n          node['properties'].loading = 'lazy';\n        }\n      } else if (node.type === 'jsx' && node['value']?.includes('<img ')) {\n        // handles nodes like this:\n\n        // {\n        //   type: 'jsx',\n        //   value: '<img src={require(\"!/workspaces/blog.johnnyreilly.com/blog-website/node_modules/url-loader/dist/cjs.js?limit=10000&name=assets/images/[name]-[hash].[ext]&fallback=/workspaces/blog.johnnyreilly.com/blog-website/node_modules/file-loader/dist/cjs.js!./bower-with-the-long-paths.png\").default} width=\"640\" height=\"497\" />'\n        // }\n\n        // if (!vfile.history[0].includes('blog/2023-01-15')) return;\n\n        const key = `jsx|${vfile.history[0]}`;\n        const imageAlreadyProcessed = files.get(key);\n        const fetchpriorityThisImage =\n          !imageAlreadyProcessed || imageAlreadyProcessed === node['value'];\n\n        if (!imageAlreadyProcessed) {\n          files.set(key, node['value']);\n        }\n\n        if (fetchpriorityThisImage) {\n          node['value'] = node['value'].replace(\n            /<img /g,\n            '<img loading=\"eager\" fetchpriority=\"high\" '\n          );\n        } else {\n          node['value'] = node['value'].replace(\n            /<img /g,\n            '<img loading=\"lazy\" '\n          );\n        }\n      }\n    });\n  };\n}\n\nmodule.exports = imageFetchPriorityRehypePluginFactory;\n")),(0,a.kt)("p",null,"The above plugin runs over the AST of the MDX file and adds ",(0,a.kt)("inlineCode",{parentName:"p"},'fetchpriority="high"')," to the first image. It also adds ",(0,a.kt)("inlineCode",{parentName:"p"},'loading="eager"')," to the first image and ",(0,a.kt)("inlineCode",{parentName:"p"},'loading="lazy"')," to all other images."),(0,a.kt)("p",null,"Interestingly, when I was writing it I discovered that the visitor is invoked multiple times for the same elements. I'm not quite sure why, but the logic in the plugin uses a ",(0,a.kt)("inlineCode",{parentName:"p"},"Map")," to keep track of which images have already been processed. TL;DR it works!"),(0,a.kt)("p",null,"I then added the plugin to the ",(0,a.kt)("inlineCode",{parentName:"p"},"docusaurus.config.js")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"//@ts-check\nconst imageFetchPriorityRehypePlugin = require('./image-fetchpriority-rehype-plugin');\n\n/** @type {import('@docusaurus/types').Config} */\nconst config = {\n  // ...\n  presets: [\n    [\n      '@docusaurus/preset-classic',\n      /** @type {import('@docusaurus/preset-classic').Options} */\n      ({\n        // ...\n        blog: {\n          // ...\n          rehypePlugins: [imageFetchPriorityRehypePlugin],\n          // ...\n        },\n        // ...\n      }),\n    ],\n  ],\n  // ...\n};\n\nmodule.exports = config;\n")),(0,a.kt)("h2",o({},{id:"what-does-it-look-like-when-applied"}),"What does it look like when applied?"),(0,a.kt)("p",null,"Now we have this in place, if we run the same test with ",(0,a.kt)("a",o({parentName:"p"},{href:"https://pagespeed.web.dev/"}),"pagespeed")," we have different results:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot showing fetchpriority=&quot;high&quot; has been applied to LCP image",src:n(33224).Z,width:"2016",height:"1087"})),(0,a.kt)("p",null,"We're now ",(0,a.kt)("em",{parentName:"p"},"not")," lazy loading the image and we're also making it a high priority fetch. Great news!"),(0,a.kt)("p",null,"I'd like for this to be the default behaviour for Docusaurus. I'm not sure if it's possible to do this in a way that's straightforward. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/issues/8552"}),"I've raised an issue on the Docusaurus repo to see if it's possible"),"."))}d.isMDXComponent=!0},89234:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"image-optimisation-tinypng-api",title:"Image Optimisation with the TinyPNG API",authors:"johnnyreilly",tags:["image optimisation","TinyPNG"],image:"./title-image.webp",description:"Image optimisation can be automated with the TinyPNG API. This post demonstrates how to do that.",hide_table_of_contents:!1},s=void 0,l={permalink:"/image-optimisation-tinypng-api",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2023-01-22-image-optimisation-tinypng-api/index.md",source:"@site/blog/2023-01-22-image-optimisation-tinypng-api/index.md",title:"Image Optimisation with the TinyPNG API",description:"Image optimisation can be automated with the TinyPNG API. This post demonstrates how to do that.",date:"2023-01-22T00:00:00.000Z",formattedDate:"January 22, 2023",tags:[{label:"image optimisation",permalink:"/tags/image-optimisation"},{label:"TinyPNG",permalink:"/tags/tiny-png"}],readingTime:6.395,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"image-optimisation-tinypng-api",title:"Image Optimisation with the TinyPNG API",authors:"johnnyreilly",tags:["image optimisation","TinyPNG"],image:"./title-image.webp",description:"Image optimisation can be automated with the TinyPNG API. This post demonstrates how to do that.",hide_table_of_contents:!1},prevItem:{title:"Docusaurus blogs: using the createFeedItems API with git commit date",permalink:"/docusaurus-createfeeditems-api-git-commit-date"},nextItem:{title:"Docusaurus: improving Core Web Vitals with fetchpriority",permalink:"/docusaurus-improve-core-web-vitals-fetchpriority"}},p={image:n(96315).Z,authorsImageUrls:[void 0]},u=[{value:"Images and optimisation",id:"images-and-optimisation",level:2},{value:"The TinyPNG API",id:"the-tinypng-api",level:2},{value:"Making a command line tool",id:"making-a-command-line-tool",level:2},{value:"Using the tool",id:"using-the-tool",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Image optimisation can be automated with the TinyPNG API. This post demonstrates how to do that."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Image Optimisation with the TinyPNG API&quot; with TinyPNG and Lighthouse logos",src:n(96315).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"images-and-optimisation"}),"Images and optimisation"),(0,a.kt)("p",null,"Images are a big part of the web. They're also a big part of the web's payload. If we're not careful, we can end up with a site that's slow to load and expensive to host. I run ",(0,a.kt)("a",o({parentName:"p"},{href:"https://developer.chrome.com/docs/lighthouse/overview/"}),"Lighthouse")," on my blog and I'm always looking for ways to improve the performance of the site. One of the things that Lighthouse flags is image optimisation."),(0,a.kt)("p",null,"It's a good idea to optimise our images; to make sure they're not unhelpfully large. We can do this manually using tools like ",(0,a.kt)("a",o({parentName:"p"},{href:"https://tinypng.com/"}),"TinyPNG")," or ",(0,a.kt)("a",o({parentName:"p"},{href:"https://squoosh.app/"}),"Squoosh"),". However, it's also possible to automate this process. In this post, I'll show you how to do that using the TinyPNG API."),(0,a.kt)("h2",o({},{id:"the-tinypng-api"}),"The TinyPNG API"),(0,a.kt)("p",null,"The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://tinypng.com/developers"}),"TinyPNG API")," is a paid service. We can get a free API key which allows us to optimise 500 images per month. If we need to optimise more than that, we'll need to pay for a subscription. I rarely find I optimise more than 500 images per month so I'm happy with the free plan."),(0,a.kt)("p",null,"It's worth noting that the name \"TinyPNG\" is a bit of a misnomer. The API supports a number of image formats including PNG, JPEG and WebP. It's not just for PNGs. In fact we'll be using the WebP format in this post."),(0,a.kt)("p",null,"You can just use the API directly. However, I prefer to use a client library. We'll be using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://tinypng.com/developers/reference/nodejs"}),"the Node.js")," library."),(0,a.kt)("h2",o({},{id:"making-a-command-line-tool"}),"Making a command line tool"),(0,a.kt)("p",null,'We\'re going to initialise a simple Node.js console application called "tinify" using ',(0,a.kt)("a",o({parentName:"p"},{href:"https://www.typescriptlang.org/"}),"TypeScript")," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://typestrong.org/ts-node/"}),(0,a.kt)("inlineCode",{parentName:"a"},"ts-node")),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"mkdir tinify\ncd tinify\nnpm init -y\nnpm install @types/node tinify ts-node typescript\nnpx tsc --init\n")),(0,a.kt)("p",null,"You'll note that we're using the ",(0,a.kt)("inlineCode",{parentName:"p"},"tinify")," npm package ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/tinify/tinify-nodejs"}),"which is developed here"),". Handily this package ships with TypeScript definitions, so we don't need to install a separate types package."),(0,a.kt)("p",null,"In our ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," file we'll add a ",(0,a.kt)("inlineCode",{parentName:"p"},"start")," script to run our application:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'  "scripts": {\n    "start": "ts-node index.ts"\n  },\n')),(0,a.kt)("p",null,"In our ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," file we'll also up the ",(0,a.kt)("inlineCode",{parentName:"p"},"target")," to a new ECMAScript emit version to allow us to use some newer language features. We don't need this for TinyPNG, but it's nice to use the newer features:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "compilerOptions": {\n    "target": "es2021"\n  }\n}\n')),(0,a.kt)("p",null,"Now we can create our ",(0,a.kt)("inlineCode",{parentName:"p"},"index.ts")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import fs from 'fs';\nimport path from 'path';\nimport tinify from 'tinify';\n\nfunction setUpTinify() {\n  if (!process.env.TINIFY_KEY) {\n    console.log(\n      'Run with: TINIFY_KEY=$YOUR_API_KEY IMAGE_DIR=$YOUR_IMAGE_DIRECTORY yarn start'\n    );\n    process.exit(1);\n  }\n\n  tinify.key = process.env.TINIFY_KEY;\n}\n\nfunction getImageFilesFromDirectory(dir: string) {\n  return fs\n    .readdirSync(dir)\n    .filter(\n      (file) =>\n        file.endsWith('.jpg') ||\n        file.endsWith('.jpeg') ||\n        file.endsWith('.webp') ||\n        file.endsWith('.png')\n    )\n    .map((file) => path.resolve(dir, file))\n    .filter((file) => fs.statSync(file).size > 0);\n}\n\nasync function processImageFiles(imageFiles: string[]) {\n  let processed = 0;\n  let totalOriginalSizeKb = 0n;\n  let totalNewSizeKb = 0n;\n  let failed: string[] = [];\n\n  for (const imageFilePath of imageFiles) {\n    try {\n      console.log(`\n\ud83d\uddbc\ufe0f  Processing ${imageFilePath}\n`);\n      const originalImageFilePrefix = imageFilePath.substring(\n        0,\n        imageFilePath.lastIndexOf('.')\n      );\n\n      const originalStats = await fs.promises.stat(imageFilePath, {\n        bigint: true,\n      });\n      const originalSizeKb = originalStats.size / 1024n;\n\n      const source = tinify.fromFile(imageFilePath);\n      const converted = source.convert({ type: ['image/webp', 'image/png'] });\n      const convertedExtension = await converted.result().extension();\n      const newImageFilePath = `${originalImageFilePrefix}.${convertedExtension}`;\n      await converted.toFile(newImageFilePath);\n\n      const newStats = await fs.promises.stat(newImageFilePath, {\n        bigint: true,\n      });\n      const newSizeKb = newStats.size / 1024n;\n\n      const imageFileName = path.basename(imageFilePath);\n      const newImageFileName = path.basename(newImageFilePath);\n\n      totalOriginalSizeKb += originalSizeKb;\n      totalNewSizeKb += newSizeKb;\n\n      console.log(`- \ud83d\udd34 ${originalSizeKb}kb - ${imageFileName}\n- \ud83d\udfe2 ${newSizeKb}kb - ${newImageFileName}\n- \ud83d\udd3d ${calculatePercentageReduction({ originalSizeKb, newSizeKb }).toFixed(\n        2\n      )}% reduction\n\n\u2705 Processed! (${++processed} of ${imageFiles.length})\n\n----------------------`);\n    } catch (e) {\n      console.log(`\\n\u274c Failed to process ${imageFilePath}`);\n      failed.push(imageFilePath);\n    }\n  }\n\n  console.log(`\n************************************************\n* Total savings for ${imageFiles.length} images \n- \ud83d\udd34 ${totalOriginalSizeKb}kb\n- \ud83d\udfe2 ${totalNewSizeKb}kb\n- \ud83d\udd3d ${calculatePercentageReduction({\n    originalSizeKb: totalOriginalSizeKb,\n    newSizeKb: totalNewSizeKb,\n  }).toFixed(2)}% reduction\n************************************************\n`);\n\n  if (failed.length > 0) console.log('Failed to process', failed);\n}\n\nfunction calculatePercentageReduction({\n  originalSizeKb,\n  newSizeKb,\n}: {\n  originalSizeKb: bigint;\n  newSizeKb: bigint;\n}) {\n  return (\n    ((Number(originalSizeKb) - Number(newSizeKb)) / Number(originalSizeKb)) *\n    100\n  );\n}\n\nasync function run() {\n  setUpTinify();\n\n  let directory = process.env.IMAGE_DIR;\n\n  if (!directory) {\n    console.log('No directory specified!');\n    process.exit(1);\n  }\n\n  const imageFiles = getImageFilesFromDirectory(directory);\n  console.log(`Found ${imageFiles.length} image files in ${directory}`);\n  await processImageFiles(imageFiles);\n}\n\n// do it!\nrun();\n")),(0,a.kt)("p",null,"There's a number of things happening here. Let me walk it through; each time we run:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"We're checking that we have a TinyPNG API key and an image directory specified. If not, we'll exit with an error message."),(0,a.kt)("li",{parentName:"ol"},"We're getting a list of image files from the specified directory. We look for files with the extensions ",(0,a.kt)("inlineCode",{parentName:"li"},".jpg"),", ",(0,a.kt)("inlineCode",{parentName:"li"},".jpeg"),", ",(0,a.kt)("inlineCode",{parentName:"li"},".webp")," and ",(0,a.kt)("inlineCode",{parentName:"li"},".png")," (those formats supported by TinyPNG). We also filter out any files that are empty."),(0,a.kt)("li",{parentName:"ol"},"We're looping through the image files and processing them one by one. We're using the ",(0,a.kt)("inlineCode",{parentName:"li"},"tinify")," package to shrink the image; and we say we'll accept either ",(0,a.kt)("inlineCode",{parentName:"li"},"webp")," or ",(0,a.kt)("inlineCode",{parentName:"li"},"png")," as our target format. Tinify will decide which is the most optimal format upon each request and render accordingly. Finally we're saving the new files to the same directory as the original file. We're also calculating the percentage reduction in file size.")),(0,a.kt)("p",null,"If we wanted to look just at the code that does the actual conversion, it's this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"const source = tinify.fromFile(imageFilePath);\nconst converted = source.convert({ type: ['image/webp', 'image/png'] });\nconst convertedExtension = await converted.result().extension();\nconst newImageFilePath = `${originalImageFilePrefix}.${convertedExtension}`;\nawait converted.toFile(newImageFilePath);\n")),(0,a.kt)("h2",o({},{id:"using-the-tool"}),"Using the tool"),(0,a.kt)("p",null,"With our tool written, we now need to test it out. I've a directory of images that I want to compress: ",(0,a.kt)("inlineCode",{parentName:"p"},"~/code/github/open-graph-sharing-previews/images-to-shrink")),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of image files before optimisation",src:n(5881).Z,width:"1391",height:"610"})),(0,a.kt)("p",null,"Now let's run our tool against that directory and see what happens:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"TINIFY_KEY=YOUR_API_KEY_GOES_HERE IMAGE_DIR=~/code/github/open-graph-sharing-previews/images-to-shrink yarn start\n\nyarn run v1.22.18\n$ ts-node index.ts\nFound 6 image files in /home/john/code/github/open-graph-sharing-previews/images-to-shrink\n\n\ud83d\uddbc\ufe0f  Processing /home/john/code/github/open-graph-sharing-previews/images-to-shrink/screenshot-of-demo-with-devtools-open.png\n\n- \ud83d\udd34 253kb - screenshot-of-demo-with-devtools-open.png\n- \ud83d\udfe2 83kb - screenshot-of-demo-with-devtools-open.png\n- \ud83d\udd3d 67.19% reduction\n\n\u2705 Processed! (1 of 6)\n\n----------------------\n\n\ud83d\uddbc\ufe0f  Processing /home/john/code/github/open-graph-sharing-previews/images-to-shrink/screenshot-of-email-demonstrating-sharing-with-a-non-cropped-image.png\n\n- \ud83d\udd34 158kb - screenshot-of-email-demonstrating-sharing-with-a-non-cropped-image.png\n- \ud83d\udfe2 50kb - screenshot-of-email-demonstrating-sharing-with-a-non-cropped-image.png\n- \ud83d\udd3d 68.35% reduction\n\n\u2705 Processed! (2 of 6)\n\n----------------------\n\n\ud83d\uddbc\ufe0f  Processing /home/john/code/github/open-graph-sharing-previews/images-to-shrink/screenshot-of-tweet-demonstrating-sharing-with-a-cropped-image.png\n\n- \ud83d\udd34 391kb - screenshot-of-tweet-demonstrating-sharing-with-a-cropped-image.png\n- \ud83d\udfe2 64kb - screenshot-of-tweet-demonstrating-sharing-with-a-cropped-image.webp\n- \ud83d\udd3d 83.63% reduction\n\n\u2705 Processed! (3 of 6)\n\n----------------------\n\n\ud83d\uddbc\ufe0f  Processing /home/john/code/github/open-graph-sharing-previews/images-to-shrink/screenshot-of-tweet-demonstrating-sharing.png\n\n- \ud83d\udd34 407kb - screenshot-of-tweet-demonstrating-sharing.png\n- \ud83d\udfe2 78kb - screenshot-of-tweet-demonstrating-sharing.webp\n- \ud83d\udd3d 80.84% reduction\n\n\u2705 Processed! (4 of 6)\n\n----------------------\n\n\ud83d\uddbc\ufe0f  Processing /home/john/code/github/open-graph-sharing-previews/images-to-shrink/screenshot-of-twitter-validator.png\n\n- \ud83d\udd34 162kb - screenshot-of-twitter-validator.png\n- \ud83d\udfe2 49kb - screenshot-of-twitter-validator.webp\n- \ud83d\udd3d 69.75% reduction\n\n\u2705 Processed! (5 of 6)\n\n----------------------\n\n\ud83d\uddbc\ufe0f  Processing /home/john/code/github/open-graph-sharing-previews/images-to-shrink/title-image.png\n\n- \ud83d\udd34 308kb - title-image.png\n- \ud83d\udfe2 49kb - title-image.webp\n- \ud83d\udd3d 84.09% reduction\n\n\u2705 Processed! (6 of 6)\n\n----------------------\n\n************************************************\n* Total savings for 6 images\n- \ud83d\udd34 1679kb\n- \ud83d\udfe2 373kb\n- \ud83d\udd3d 77.78% reduction\n************************************************\n\nDone in 25.23s.\n")),(0,a.kt)("p",null,"Isn't that impressive? We've reduced the file size of all of these images by an average amount of 77.78%! That's a huge saving."),(0,a.kt)("p",null,"If we look a little closer, we'll see that on two occasions the format has remained as a PNG file and the size has shrunk. In four cases, the format has changed to a WebP file. When we look at our directory again, we'll see that the files have been updated, and some new WebP files have been created:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of image files after optimisation",src:n(16631).Z,width:"1391",height:"971"})),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"We've seen how we can use the TinyPNG API to optimise our images. We've also built a tool that uses the TinyPNG API to optimise the images in a given directory."),(0,a.kt)("p",null,"It's all automated. We can now run this script whenever we want to optimise the images in any directory!"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/automate-image-optimization-tinypng-api/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/automate-image-optimization-tinypng-api/"})))}d.isMDXComponent=!0},25420:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"docusaurus-createfeeditems-api-git-commit-date",title:"Docusaurus blogs: using the createFeedItems API with git commit date",authors:"johnnyreilly",tags:["Docusaurus","RSS"],image:"./title-image.png",description:"The Docusaurus createFeedItems API can be used to tweak RSS feeds for your blog. This post shows how to use it with the git commit date.",hide_table_of_contents:!1},s=void 0,l={permalink:"/docusaurus-createfeeditems-api-git-commit-date",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2023-01-28-docusaurus-createfeeditems-api-git-commit-date/index.md",source:"@site/blog/2023-01-28-docusaurus-createfeeditems-api-git-commit-date/index.md",title:"Docusaurus blogs: using the createFeedItems API with git commit date",description:"The Docusaurus createFeedItems API can be used to tweak RSS feeds for your blog. This post shows how to use it with the git commit date.",date:"2023-01-28T00:00:00.000Z",formattedDate:"January 28, 2023",tags:[{label:"Docusaurus",permalink:"/tags/docusaurus"},{label:"RSS",permalink:"/tags/rss"}],readingTime:5.415,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"docusaurus-createfeeditems-api-git-commit-date",title:"Docusaurus blogs: using the createFeedItems API with git commit date",authors:"johnnyreilly",tags:["Docusaurus","RSS"],image:"./title-image.png",description:"The Docusaurus createFeedItems API can be used to tweak RSS feeds for your blog. This post shows how to use it with the git commit date.",hide_table_of_contents:!1},prevItem:{title:"Docusaurus blogs: adding breadcrumb Structured Data",permalink:"/docusaurus-blogs-adding-breadcrumb-structured-data"},nextItem:{title:"Image Optimisation with the TinyPNG API",permalink:"/image-optimisation-tinypng-api"}},p={image:n(15978).Z,authorsImageUrls:[void 0]},u=[{value:"<code>createFeedItems</code> API",id:"createfeeditems-api",level:2},{value:"<code>createFeedItems</code> API usage",id:"createfeeditems-api-usage",level:2},{value:"Our implementation",id:"our-implementation",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"A new API landed in Docusaurus 2.3.0 - it's called ",(0,a.kt)("inlineCode",{parentName:"p"},"createFeedItems"),". It's a great API that allows you to tweak the Atom / RSS / JSON feeds for your blog. This post shows how to use it with the git commit date."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Docusaurus: using the createFeedItems API with git commit date&quot; with the Docusaurus logo",src:n(15978).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"createfeeditems-api"}),(0,a.kt)("inlineCode",{parentName:"h2"},"createFeedItems")," API"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/pull/8378"}),"I worked on the createFeedItems API for Docusaurus"),". When the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/docusaurus/status/1619019412610191379"}),"feature was announced"),", there were a number of suggested use cases:"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/docusaurus/status/1619019412610191379"}),(0,a.kt)("img",{loading:"lazy",alt:"screenshot of a tweet describing things you could do with the createFeedItems API",src:n(41283).Z,width:"589",height:"811"}))),(0,a.kt)("p",null,"As someone who worked on the API, you naturally might imagine that I'd have some ideas for how to use it. I do!"),(0,a.kt)("p",null,"There's two particular use cases that I've been thinking about:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Trimming the number of feed items"),(0,a.kt)("li",{parentName:"ol"},"Using the latest git commit date for the feed item date")),(0,a.kt)("p",null,"The reason I want to trim the number of feed items is because I have written a lot of blog posts. I learned that some RSS readers were choking on the size of my feed and rendering it unusable. So I thought a decent approach would be to trim the number of feed items to a more manageable number."),(0,a.kt)("p",null,"The second use case is a lot more fun! I want to use the git commit date for the feed item date. Docusaurus uses the date of post itself to drive this by default. You can see this by looking at the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/blog/atom.xml"}),"Docusaurus atom feed"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Docusaurus atom feed",src:n(27352).Z,width:"494",height:"312"})),(0,a.kt)("p",null,"That's not a bad default. However, I tend to go back and edit my posts, particularly in the recent weeks after publishing. I don't want the date of the feed item to be the date of the post. I want it to be the date of the most recent commit. That way, if I go back and edit a post, the feed item date will be updated."),(0,a.kt)("p",null,"We're going to implement both of these."),(0,a.kt)("h2",o({},{id:"createfeeditems-api-usage"}),(0,a.kt)("inlineCode",{parentName:"h2"},"createFeedItems")," API usage"),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"createFeedItems")," API is a function that takes a list of feed items and returns a list of feed items. I find looking at code easier than reading about code so let's look at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/docs/blog#feed"}),"the example code from the docs"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"module.exports = {\n  // ...\n  presets: [\n    [\n      '@docusaurus/preset-classic',\n      {\n        blog: {\n          feedOptions: {\n            type: 'all',\n            copyright: `Copyright \xa9 ${new Date().getFullYear()} Facebook, Inc.`,\n            createFeedItems: async (params) => {\n              const { blogPosts, defaultCreateFeedItems, ...rest } = params;\n              return defaultCreateFeedItems({\n                // keep only the 10 most recent blog posts in the feed\n                blogPosts: blogPosts.filter((item, index) => index < 10),\n                ...rest,\n              });\n            },\n          },\n        },\n      },\n    ],\n  ],\n};\n")),(0,a.kt)("p",null,"As we can see - this is a function, which receives a single parameter. That parameter is an object with a number of properties. The most important of these is ",(0,a.kt)("inlineCode",{parentName:"p"},"blogPosts"),". This is a list of blog posts. We can filter this list and return a new list. We can also call ",(0,a.kt)("inlineCode",{parentName:"p"},"defaultCreateFeedItems")," to get the default behaviour. We can then tweak the result of that call."),(0,a.kt)("p",null,"Importantly it's an ",(0,a.kt)("inlineCode",{parentName:"p"},"async")," function. This means that we can do async work in it. We're going to use that when we get the git commit date."),(0,a.kt)("h2",o({},{id:"our-implementation"}),"Our implementation"),(0,a.kt)("p",null,"Now we know how to use the API, let's implement it to handle our use cases. To get the git commit date, we're going to use a package called ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/steveukx/git-js"}),(0,a.kt)("inlineCode",{parentName:"a"},"simple-git")),". We'll add this as a dependency of our Docusaurus project:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"yarn add simple-git\n")),(0,a.kt)("p",null,"We're going to create a new file to sit alongside our ",(0,a.kt)("inlineCode",{parentName:"p"},"docusaurus.config.js")," file. We'll call it ",(0,a.kt)("inlineCode",{parentName:"p"},"createFeedItems.js"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"const path = require('path');\nconst { simpleGit, SimpleGit, SimpleGitOptions } = require('simple-git');\n\n/** @type {import('@docusaurus/plugin-content-blog').CreateFeedItemsFn} */\nasync function createFeedItems(params) {\n  const { blogPosts, defaultCreateFeedItems, ...rest } = params;\n\n  const feedItems = await defaultCreateFeedItems({\n    blogPosts,\n    ...rest,\n  });\n\n  for (const feedItem of feedItems) {\n    // blogPost.metadata.permalink: '/2023/01/22/image-optimisation-tinypng-api',\n    // feedItem.link: 'https://johnnyreilly.com/2023/01/22/image-optimisation-tinypng-api',\n    const relatedBlogEntry = blogPosts.find((blogPost) =>\n      feedItem.link.endsWith(blogPost.metadata.permalink)\n    );\n    if (!relatedBlogEntry) {\n      console.log('blogFilePath not found', feedItem.link);\n      throw new Error(`blogFilePath not found ${feedItem.link}`);\n    }\n\n    // source: '@site/blog/2023-01-22-image-optimisation-tinypng-api/index.md',\n    const gitLatestCommitString = await getGitLatestCommitDateFromFilePath(\n      relatedBlogEntry.metadata.source.replace('@site/', 'blog-website/')\n    );\n    const gitLatestCommitDate = gitLatestCommitString\n      ? new Date(gitLatestCommitString)\n      : undefined;\n    if (gitLatestCommitDate) {\n      feedItem.date = gitLatestCommitDate;\n    }\n  }\n\n  // keep only the 20 most recently updated blog posts in the feed\n  const latest20FeedItems = Array.from(feedItems)\n    .sort((a, b) => b.date - a.date)\n    .slice(0, 20);\n\n  return latest20FeedItems;\n}\n\n/**\n * Given a file path, return the last commit date\n * @param {string} filePath\n * @returns\n */\nasync function getGitLatestCommitDateFromFilePath(filePath) {\n  const git = getSimpleGit();\n\n  const log = await git.log({\n    file: filePath,\n  });\n\n  const latestCommitDate = log.latest?.date;\n\n  return latestCommitDate;\n}\n\n/** @type {SimpleGit | undefined} */\nlet git;\n\n/**\n * get a simple git instance\n * @returns SimpleGit\n */\nfunction getSimpleGit() {\n  if (!git) {\n    const baseDir = path.resolve(process.cwd(), '..');\n\n    /** @type {Partial<SimpleGitOptions>} */\n    const options = {\n      baseDir,\n      binary: 'git',\n      maxConcurrentProcesses: 6,\n      trimmed: false,\n    };\n\n    git = simpleGit(options);\n  }\n\n  return git;\n}\n\nmodule.exports = createFeedItems;\n")),(0,a.kt)("p",null,"What's happening here? Well, the ",(0,a.kt)("inlineCode",{parentName:"p"},"createFeedItems")," function is taking the blog posts that come in and then calling ",(0,a.kt)("inlineCode",{parentName:"p"},"defaultCreateFeedItems")," to get the default behaviour. We then iterate over the feed items and for each one we find the related blog post. We then use ",(0,a.kt)("inlineCode",{parentName:"p"},"simple-git")," to get the last commit date for the blog post. We then set the feed item's date to the last commit date. We then sort the feed items by date and take the first 20. We then return those 20 feed items."),(0,a.kt)("p",null,"It's as simple as that. There's a few bits in there which are specific to my blog (like the ",(0,a.kt)("inlineCode",{parentName:"p"},"blog-website")," directory) but you can see how you can tweak this to suit your needs."),(0,a.kt)("p",null,"With this implemented, we'll reference this in our ",(0,a.kt)("inlineCode",{parentName:"p"},"docusaurus.config.js")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-js"}),"//@ts-check\nconst createFeedItems = require('./createFeedItems');\n\n/** @type {import('@docusaurus/types').Config} */\nconst config = {\n  // ...\n  presets: [\n    [\n      '@docusaurus/preset-classic',\n      /** @type {import('@docusaurus/preset-classic').Options} */\n      ({\n        // ...\n        feedOptions: {\n          // ...\n          createFeedItems,\n          // ...\n        },\n        // ...\n      }),\n    ],\n  ],\n  // ...\n};\n\nmodule.exports = config;\n")),(0,a.kt)("p",null,"And we're done! We can now run ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn build")," and see the results:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Docusaurus atom feed for johnnyreilly",src:n(27122).Z,width:"883",height:"350"})),(0,a.kt)("p",null,"Look for yourself at ",(0,a.kt)("a",o({parentName:"p"},{href:"https://johnnyreilly.com/atom.xml"}),"johnnyreilly.com/atom.xml")," or ",(0,a.kt)("a",o({parentName:"p"},{href:"https://johnnyreilly.com/rss.xml"}),"johnnyreilly.com/rss.xml"),"."),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"Here we've learned how to use the ",(0,a.kt)("inlineCode",{parentName:"p"},"createFeedItems")," API to customise the feed items that are generated. We've also seen how to use ",(0,a.kt)("inlineCode",{parentName:"p"},"simple-git")," to get the last commit date for a file. We've then used that to set the date of the feed item to the last commit date."))}d.isMDXComponent=!0},61860:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"docusaurus-blogs-adding-breadcrumb-structured-data",title:"Docusaurus blogs: adding breadcrumb Structured Data",authors:"johnnyreilly",tags:["Docusaurus","Structured Data","SEO"],image:"./title-image.png",description:"Docusaurus blogs can add breadcrumb Structured Data to their blog posts. This post shows how to add it using the JSON-LD format.",hide_table_of_contents:!1},s=void 0,l={permalink:"/docusaurus-blogs-adding-breadcrumb-structured-data",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2023-02-05-docusaurus-blogs-adding-breadcrumb-structured-data/index.md",source:"@site/blog/2023-02-05-docusaurus-blogs-adding-breadcrumb-structured-data/index.md",title:"Docusaurus blogs: adding breadcrumb Structured Data",description:"Docusaurus blogs can add breadcrumb Structured Data to their blog posts. This post shows how to add it using the JSON-LD format.",date:"2023-02-05T00:00:00.000Z",formattedDate:"February 5, 2023",tags:[{label:"Docusaurus",permalink:"/tags/docusaurus"},{label:"Structured Data",permalink:"/tags/structured-data"},{label:"SEO",permalink:"/tags/seo"}],readingTime:5.685,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"docusaurus-blogs-adding-breadcrumb-structured-data",title:"Docusaurus blogs: adding breadcrumb Structured Data",authors:"johnnyreilly",tags:["Docusaurus","Structured Data","SEO"],image:"./title-image.png",description:"Docusaurus blogs can add breadcrumb Structured Data to their blog posts. This post shows how to add it using the JSON-LD format.",hide_table_of_contents:!1},prevItem:{title:"In defence of pull requests",permalink:"/in-defence-of-pull-requests"},nextItem:{title:"Docusaurus blogs: using the createFeedItems API with git commit date",permalink:"/docusaurus-createfeeditems-api-git-commit-date"}},p={image:n(11954).Z,authorsImageUrls:[void 0]},u=[{value:"What are breadcrumbs?",id:"what-are-breadcrumbs",level:2},{value:"Adding a breadcrumb to a blog post",id:"adding-a-breadcrumb-to-a-blog-post",level:2},{value:"Adding a breadcrumb to the blog archive page",id:"adding-a-breadcrumb-to-the-blog-archive-page",level:2},{value:"Adding a breadcrumb to the blog post page",id:"adding-a-breadcrumb-to-the-blog-post-page",level:2},{value:"Using the Rich Results test to validate the breadcrumbs",id:"using-the-rich-results-test-to-validate-the-breadcrumbs",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"By default, Docusaurus blogs don't add breadcrumb Structured Data to their blog posts. It's not hard to make it happen though; this post shows how to add it using the JSON-LD format."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Docusaurus blogs: adding breadcrumb Structured Data&quot; with the Docusaurus logo",src:n(11954).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"what-are-breadcrumbs"}),"What are breadcrumbs?"),(0,a.kt)("p",null,"Take a look at this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of Google search results with a highlighted breadcrumb",src:n(52410).Z,width:"954",height:"327"})),(0,a.kt)("p",null,"What you're looking at is a ",(0,a.kt)("a",o({parentName:"p"},{href:"/directory-build-props-c-sharp-9-for-all"}),"blog post of mine"),' showing up in Google search results. Significantly, it has a breadcrumb which I\'ve highlighted. It indicates that the blog post sits under the blogs "Archive" page, which in turn sits under the home page of the site.'),(0,a.kt)("p",null,"This breadcrumb was driven by Structured Data that my blog surfaces. Structured Data is a form of metadata that is intended to be easily machine readable; and consequently helpful to search engines like Google. Now, what is a breadcrumb to Google?"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Google Search uses breadcrumb markup in the body of a web page to categorize the information from the page in search results.")),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://developers.google.com/search/docs/appearance/structured-data/breadcrumb"}),"You can read more on breadcrumbs in the Google documentation"),". This post is about how to add breadcrumbs to your Docusaurus blog posts, to help Google categorise your blog posts."),(0,a.kt)("p",null,"It's worth noting that what we're going to do here is add a JSON-LD Structured Data breadcrumb to the blog post. There's going to be no physical breadcrumb on the page itself. It could be nice to add a physical breadcrumb, but that's not what we're going to do here as it would not be a trivial addition. (As an aside, Docusaurus does use physical breadcrumbs in its documentation pages; which surface Structured Data.)"),(0,a.kt)("p",null,"Docusaurus already has Structured Data support for blog posts; ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/pull/5322"}),"in fact I had a hand in that"),". I like me some Structured Data \ud83d\ude09. The existing Structured Data is article / ",(0,a.kt)("inlineCode",{parentName:"p"},"BlogPosting")," metadata. We're going to enrich the Structured Data for blog posts by adding a ",(0,a.kt)("inlineCode",{parentName:"p"},"BreadcrumbList")," as well."),(0,a.kt)("p",null,"Incidentally, if you'd like to learn more about React, JSON-LD and Structured Data, I've ",(0,a.kt)("a",o({parentName:"p"},{href:"/structured-data-seo-and-react"}),"written about it, and done a short talk on the topic"),"."),(0,a.kt)("h2",o({},{id:"adding-a-breadcrumb-to-a-blog-post"}),"Adding a breadcrumb to a blog post"),(0,a.kt)("p",null,"With all that preamble out of the way, let's get to the good stuff. We're going to add a breadcrumb to a blog post. To do that, we need to adjust two components in Docusaurus; the ",(0,a.kt)("inlineCode",{parentName:"p"},"BlogArchivePage")," and the ",(0,a.kt)("inlineCode",{parentName:"p"},"BlogPostPage"),". We're going to do this by swizzling. Let's crack open the terminal and get started:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"npm run swizzle @docusaurus/theme-classic BlogArchivePage -- --wrap --danger\nnpm run swizzle @docusaurus/theme-classic BlogPostPage -- --wrap --danger\n")),(0,a.kt)("p",null,"This will create two files in the ",(0,a.kt)("inlineCode",{parentName:"p"},"src/theme/")," directory:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"src/theme/BlogArchivePage/index.js")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"src/theme/BlogPostPage/index.js"))),(0,a.kt)("p",null,"You'll note from the command that we've used the ",(0,a.kt)("inlineCode",{parentName:"p"},"--wrap")," flag. This is because we want to wrap the existing component. If we didn't use the ",(0,a.kt)("inlineCode",{parentName:"p"},"--wrap")," flag, we'd be replacing the existing component. We're wrapping rather than replacing as it will make maintenance easier as Docusaurus evolves."),(0,a.kt)("h2",o({},{id:"adding-a-breadcrumb-to-the-blog-archive-page"}),"Adding a breadcrumb to the blog archive page"),(0,a.kt)("p",null,"We're now going to replace the generated ",(0,a.kt)("inlineCode",{parentName:"p"},"BlogArchivePage")," component with the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-jsx"}),"import React from 'react';\nimport BlogArchivePage from '@theme-original/BlogArchivePage';\nimport useDocusaurusContext from '@docusaurus/useDocusaurusContext';\n\nexport default function BlogArchivePageWrapper(props) {\n  const { siteConfig } = useDocusaurusContext();\n\n  // https://developers.google.com/search/docs/appearance/structured-data/breadcrumb#json-ld\n  const breadcrumbStructuredData = {\n    '@context': 'https://schema.org',\n    '@type': 'BreadcrumbList',\n    name: 'Archive breadcrumb',\n    itemListElement: [\n      {\n        '@type': 'ListItem',\n        position: 1,\n        name: 'Home',\n        item: siteConfig.url,\n      },\n      {\n        '@type': 'ListItem',\n        position: 2,\n        name: 'Archive',\n      },\n    ],\n  };\n\n  return (\n    <>\n      <script type=\"application/ld+json\">\n        {JSON.stringify(breadcrumbStructuredData)}\n      <\/script>\n      <BlogArchivePage {...props} />\n    </>\n  );\n}\n")),(0,a.kt)("p",null,"Here we're constructing a JSON-LD Structured Data object that represents a breadcrumb. We're then adding it to the page as a script tag with the ",(0,a.kt)("inlineCode",{parentName:"p"},"type")," of ",(0,a.kt)("inlineCode",{parentName:"p"},"application/ld+json"),". And we're rendering the wrapped ",(0,a.kt)("inlineCode",{parentName:"p"},"BlogArchivePage")," component. This is so that we can add the Structured Data breadcrumb to the page without having to duplicate the existing code."),(0,a.kt)("p",null,"There's two entries in the ",(0,a.kt)("inlineCode",{parentName:"p"},"itemListElement")," array. The first is the home page of the site. The second is the archive page itself. We're not going to add a link to the archive page as it's the current page."),(0,a.kt)("h2",o({},{id:"adding-a-breadcrumb-to-the-blog-post-page"}),"Adding a breadcrumb to the blog post page"),(0,a.kt)("p",null,"Okay, one down - one to go. We're now going to replace the generated ",(0,a.kt)("inlineCode",{parentName:"p"},"BlogPostPage")," component with the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-jsx"}),"import React from 'react';\nimport BlogPostPage from '@theme-original/BlogPostPage';\nimport useDocusaurusContext from '@docusaurus/useDocusaurusContext';\n\nexport default function BlogPostPageWrapper(props) {\n  const { siteConfig } = useDocusaurusContext();\n\n  /** @type {import('@docusaurus/plugin-content-blog').BlogPostMetadata} */ const blogMetaData =\n    props.content.metadata;\n\n  // https://developers.google.com/search/docs/appearance/structured-data/breadcrumb#json-ld\n  const archiveBreadcrumbStructuredData = {\n    '@context': 'https://schema.org',\n    '@type': 'BreadcrumbList',\n    name: 'Archive breadcrumb',\n    itemListElement: [\n      {\n        '@type': 'ListItem',\n        position: 1,\n        name: 'Home',\n        item: siteConfig.url,\n      },\n      {\n        '@type': 'ListItem',\n        position: 2,\n        name: 'Archive',\n        item: `${siteConfig.url}/archive`,\n      },\n      {\n        '@type': 'ListItem',\n        position: 3,\n        name: blogMetaData.title,\n      },\n    ],\n  };\n\n  const tagsBreadcrumbStructuredData = blogMetaData.tags.map((tag) => ({\n    '@context': 'https://schema.org',\n    '@type': 'BreadcrumbList',\n    name: `Tags ${tag.label} breadcrumb`,\n    itemListElement: [\n      {\n        '@type': 'ListItem',\n        position: 1,\n        name: 'Home',\n        item: siteConfig.url,\n      },\n      {\n        '@type': 'ListItem',\n        position: 2,\n        name: 'Tags',\n        item: `${siteConfig.url}/tags`,\n      },\n      {\n        '@type': 'ListItem',\n        position: 3,\n        name: tag.label,\n        item: `${siteConfig.url}${tag.permalink}`,\n      },\n      {\n        '@type': 'ListItem',\n        position: 4,\n        name: blogMetaData.title,\n      },\n    ],\n  }));\n\n  const breadcrumbStructuredData = [\n    archiveBreadcrumbStructuredData,\n    ...tagsBreadcrumbStructuredData,\n  ];\n\n  return (\n    <>\n      <script type=\"application/ld+json\">\n        {JSON.stringify(breadcrumbStructuredData)}\n      <\/script>\n      <BlogPostPage {...props} />\n    </>\n  );\n}\n")),(0,a.kt)("p",null,"Again, we're constructing a JSON-LD Structured Data object that represents a breadcrumb. But this time we're going to add multiple breadcrumbs to the page. The first is the archive breadcrumb. The other breadcrumbs are generated for each tag."),(0,a.kt)("p",null,"I'm somewhat on the fence as to whether it's useful to have a breadcrumb for each tag. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/pull/416"}),"In fact, originally I didn't have it when I first added support"),". But I've added it in as it's not a lot of work and it's not a lot of code. I'm not sure if it's useful or not. ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/commit/e69633ca6cc6cae98cd405580e9659594ac92f8a"}),"I've added it now"),"; I'm going to leave it in in place for a bit and see how it goes."),(0,a.kt)("h2",o({},{id:"using-the-rich-results-test-to-validate-the-breadcrumbs"}),"Using the Rich Results test to validate the breadcrumbs"),(0,a.kt)("p",null,"Once we've shipped the changes we can test them using the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://search.google.com/test/rich-results"}),"Google Rich Results Test"),". The screenshot below was taken after I'd deployed the changes and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://search.google.com/test/rich-results?url=https%3A%2F%2Fjohnnyreilly.com%2Fdirectory-build-props-c-sharp-9-for-all"}),"the test was run"),"."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the Rich Results Test featuring article and breadcrumbs",src:n(40292).Z,width:"1043",height:"810"})),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the Rich Results Test featuring the specific 4 breadcrumbs",src:n(66959).Z,width:"1044",height:"840"})),(0,a.kt)("p",null,"We can also check the breadcrumbs in the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://search.google.com/search-console/r/breadcrumbs"}),"Google Search Console"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the Google search console",src:n(94712).Z,width:"1053",height:"860"})),(0,a.kt)("p",null,"So that's it, now we have breadcrumbs on the blog posts."),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,'This is a useful addition to the blog. I\'d like it more if it was a physical breadcrumb as well; not just an "invisible" one. ',(0,a.kt)("a",o({parentName:"p"},{href:"https://docusaurus.io/feature-requests/p/add-breadcrumb-for-blog-posts"}),"I've opened an issue with Docusaurus to see if that's possible"),". I would imagine, if that does get added, it would likely be a single breadcrumb rather than multiple ones. But let me not preempt; let's see what comes of it."))}d.isMDXComponent=!0},30720:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"in-defence-of-pull-requests",title:"In defence of pull requests",authors:"johnnyreilly",tags:["pull requests"],image:"./title-image.png",description:"Some people feel that pull requests are a barrier to contribution. I disagree.",hide_table_of_contents:!1},s=void 0,l={permalink:"/in-defence-of-pull-requests",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2023-02-11-in-defence-of-pull-requests/index.md",source:"@site/blog/2023-02-11-in-defence-of-pull-requests/index.md",title:"In defence of pull requests",description:"Some people feel that pull requests are a barrier to contribution. I disagree.",date:"2023-02-11T00:00:00.000Z",formattedDate:"February 11, 2023",tags:[{label:"pull requests",permalink:"/tags/pull-requests"}],readingTime:3.42,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"in-defence-of-pull-requests",title:"In defence of pull requests",authors:"johnnyreilly",tags:["pull requests"],image:"./title-image.png",description:"Some people feel that pull requests are a barrier to contribution. I disagree.",hide_table_of_contents:!1},prevItem:{title:"Node.js 18, Axios and unsafe legacy renegotiation disabled",permalink:"/node-18-axios-and-unsafe-legacy-renegotiation-disabled"},nextItem:{title:"Docusaurus blogs: adding breadcrumb Structured Data",permalink:"/docusaurus-blogs-adding-breadcrumb-structured-data"}},p={image:n(58117).Z,authorsImageUrls:[void 0]},u=[{value:"Pull Requests provide a moment for contemplation",id:"pull-requests-provide-a-moment-for-contemplation",level:2},{value:"Pull Requests provide a chance for communication",id:"pull-requests-provide-a-chance-for-communication",level:2},{value:"Pull Requests provide an opportunity for collaboration",id:"pull-requests-provide-an-opportunity-for-collaboration",level:2},{value:"Where does automated testing fit in?",id:"where-does-automated-testing-fit-in",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Not everyone values pull requests. I really do, and this post explains why."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;In defence of pull requests&quot;",src:n(58117).Z,width:"800",height:"450"})),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/lockersmyboy"}),"Graeme Lockley")," recently shared ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/nhumrich/status/1623435760379768832"}),"this tweet")," with me:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of tweet saying &quot;Code reviews and pull requests were invented for open source projects where you want to gatekeep changes from people you don&#39;t know and don&#39;t trust to change the code safely&quot;",src:n(32175).Z,width:"1125",height:"679"})),(0,a.kt)("p",null,"I don't feel the same way; and ended up writing a long screed back to Graeme as to why. I thought I'd share it here too, in only slightly refined format:"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"I've seen this idea floating around. There is something to be said for low friction contribution for people that you trust. For that reason I definitely apply more scrutiny to PRs from people that I know / trust less as compared to people I know / trust more. However, to add a little more nuance. Here we go!")),(0,a.kt)("h2",o({},{id:"pull-requests-provide-a-moment-for-contemplation"}),"Pull Requests provide a moment for contemplation"),(0,a.kt)("p",null,"A moment to take stock of what's been built, and whether we'd be happy with it landing that way. Because I'm an equal opportunities kinda guy, I apply that to myself. When I raise a PR, before I let others know it's ready for review, I will tend to do a first review myself. It's amazing the different perspective you can have as the consumer of a PR as compared to a producer. I find I change things often before sharing with others as a consequence."),(0,a.kt)("h2",o({},{id:"pull-requests-provide-a-chance-for-communication"}),"Pull Requests provide a chance for communication"),(0,a.kt)("p",null,"Engineers are not obligated to communicate about what they do. And famously many of us aren't very good at it either. You become good at things that you practice at. PRs provide an opportunity to express in clear language, the aim of a change and why it is implemented in a certain way. That allows the engineer to practice repeatedly the act of communication, which will make them a more useful engineer to those around them."),(0,a.kt)("p",null,"Very much related to this, PRs are a teaching opportunity. It's a way to level up the next generation of engineers that are learning from you. What we do is more than the code we write, it's the culture we create."),(0,a.kt)("h2",o({},{id:"pull-requests-provide-an-opportunity-for-collaboration"}),"Pull Requests provide an opportunity for collaboration"),(0,a.kt)("p",null,'This may shock you, but I don\'t always get things perfect. My ideas and implementations are often "good starts", but which are wildly improved through collaboration with others. PRs provide a way to collaborate on a change. I value them specifically for that reason.'),(0,a.kt)("p",null,"Unfortunately the prompting tweet is talking about PRs being used on OSS projects; and the nature of work I do that ",(0,a.kt)("em",{parentName:"p"},"isn't")," OSS means I can't evidence it. However, I can point you to a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/facebook/docusaurus/pull/8378#discussion_r1044277801"}),"PR I raised on the Docusaurus repo")," where I was collaborating with the marvellous ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/slorber"}),"S\xe9bastien Lorber")," on a change. I'd say it's a good example of how PRs can be used to collaborate on a change; it's definitely how I want to roll regardless of the project I'm working on."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of the linked PR demonstrating collaboration https://github.com/facebook/docusaurus/pull/8378#discussion_r1044277801",src:n(11513).Z,width:"829",height:"633"})),(0,a.kt)("h2",o({},{id:"where-does-automated-testing-fit-in"}),"Where does automated testing fit in?"),(0,a.kt)("p",null,"Finally, automated testing. If you value automated testing, you must ask yourself the question: where does it fit into the contribution picture? Running automated tests against contributions is a good way to test the value those contributions provide. If you don't run them prior to contribution, then when do you run them? And how do you evidence the results?"),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"Low friction contribution is a good goal. In the case of very simple pull requests, automating from top to bottom with minimal need for human interaction is a great idea. In fact if you'd like to see an example of this in the wild, it's worth taking a look at the automation the TypeScript team, and in particular ",(0,a.kt)("a",o({parentName:"p"},{href:"https://orta.io"}),"Orta Therox"),", applied to the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/DefinitelyTyped/DefinitelyTyped"}),"Definitely Typed")," repo."),(0,a.kt)("p",null,"But, safe to say, I think there's a great deal more nuance to the topic than implied by the raw tweet. Pull requests are to be cherished, not spurned. Yay pull requests!"))}d.isMDXComponent=!0},32221:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"node-18-axios-and-unsafe-legacy-renegotiation-disabled",title:"Node.js 18, Axios and unsafe legacy renegotiation disabled",authors:"johnnyreilly",tags:["TLS","Node.js"],image:"./title-image.png",description:"With Node.js 18, unsafe legacy renegotiation was disabled. However, there are APIs that still need it. This post shows how support them with Axios.",hide_table_of_contents:!1},s=void 0,l={permalink:"/node-18-axios-and-unsafe-legacy-renegotiation-disabled",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2023-03-09-node-18-axios-and-unsafe-legacy-renegotiation-disabled/index.md",source:"@site/blog/2023-03-09-node-18-axios-and-unsafe-legacy-renegotiation-disabled/index.md",title:"Node.js 18, Axios and unsafe legacy renegotiation disabled",description:"With Node.js 18, unsafe legacy renegotiation was disabled. However, there are APIs that still need it. This post shows how support them with Axios.",date:"2023-03-09T00:00:00.000Z",formattedDate:"March 9, 2023",tags:[{label:"TLS",permalink:"/tags/tls"},{label:"Node.js",permalink:"/tags/node-js"}],readingTime:1.265,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"node-18-axios-and-unsafe-legacy-renegotiation-disabled",title:"Node.js 18, Axios and unsafe legacy renegotiation disabled",authors:"johnnyreilly",tags:["TLS","Node.js"],image:"./title-image.png",description:"With Node.js 18, unsafe legacy renegotiation was disabled. However, there are APIs that still need it. This post shows how support them with Axios.",hide_table_of_contents:!1},prevItem:{title:"Migrating from ts-node to Bun",permalink:"/migrating-from-ts-node-to-bun"},nextItem:{title:"In defence of pull requests",permalink:"/in-defence-of-pull-requests"}},p={image:n(8016).Z,authorsImageUrls:[void 0]},u=[{value:"The error",id:"the-error",level:2},{value:"The fix",id:"the-fix",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Node.js 18 doesn't allow legacy TLS renegotion by default. But some APIs still need it. This post shows how to support them with Axios."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Node.js 18, Axios and unsafe legacy renegotiation disabled&quot;",src:n(8016).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"the-error"}),"The error"),(0,a.kt)("p",null,"If you have code that uses Node.js and Axios, you may have encountered this error when you upgraded to Node.js 18:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"EPROTO B8150000:error:0A000152:SSL routines:final_renegotiate:unsafe legacy renegotiation disabled\n")),(0,a.kt)("p",null,"The source of this error is Node.js 18 disabling unsafe legacy TLS renegotiation. The motivation for this is noble; it's to mitigate ",(0,a.kt)("a",o({parentName:"p"},{href:"https://cve.mitre.org/cgi-bin/cvename.cgi?name=cve-2009-3555"}),"CVE-2009-3555")," by all accounts. Alas, there are APIs that still use legacy TLS negotiation. It appears that one such API is the ",(0,a.kt)("a",o({parentName:"p"},{href:"/teams-notification-webhooks"}),"Teams webhook API"),"."),(0,a.kt)("h2",o({},{id:"the-fix"}),"The fix"),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://stackoverflow.com/questions/74324019/allow-legacy-renegotiation-for-nodejs/74600467#74600467"}),"I found the answer on Stack Overflow"),"; but not immediately. So I'm going to record it here since I'm bound to need this again."),(0,a.kt)("p",null,"To cope with older APIs, making an Axios request ends up looking like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import crypto from 'crypto';\nimport https from 'https';\n\n/**\n * Handle this problem with Node 18\n * write EPROTO B8150000:error:0A000152:SSL routines:final_renegotiate:unsafe legacy renegotiation disabled\n * see https://stackoverflow.com/questions/74324019/allow-legacy-renegotiation-for-nodejs/74600467#74600467\n **/\nconst allowLegacyRenegotiationforNodeJsOptions = {\n  httpsAgent: new https.Agent({\n    // for self signed you could also add\n    // rejectUnauthorized: false,\n    // allow legacy server\n    secureOptions: crypto.constants.SSL_OP_LEGACY_SERVER_CONNECT,\n  }),\n};\n\nfunction makeRequest(url: string, data: object) {\n  return axios({\n    ...allowLegacyRenegotiationforNodeJsOptions,\n    url,\n    headers: {\n      Accept: 'application/json',\n      'Content-Type': 'application/json',\n    },\n    method: 'POST',\n    data: telemetryRequestWrapper,\n  });\n}\n")),(0,a.kt)("p",null,"I'd imagine that you could use this pattern for the fetch API too, but I haven't tried it."))}d.isMDXComponent=!0},51877:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"migrating-from-ts-node-to-bun",title:"Migrating from ts-node to Bun",authors:"johnnyreilly",tags:["bun"],image:"./title-image.png",description:"Migrating from ts-node to Bun is surprisingly easy - this post ports a console app from ts-node to Bun and compares performance.",hide_table_of_contents:!1},s=void 0,l={permalink:"/migrating-from-ts-node-to-bun",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2023-03-18-migrating-from-ts-node-to-bun/index.md",source:"@site/blog/2023-03-18-migrating-from-ts-node-to-bun/index.md",title:"Migrating from ts-node to Bun",description:"Migrating from ts-node to Bun is surprisingly easy - this post ports a console app from ts-node to Bun and compares performance.",date:"2023-03-18T00:00:00.000Z",formattedDate:"March 18, 2023",tags:[{label:"bun",permalink:"/tags/bun"}],readingTime:9.245,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"migrating-from-ts-node-to-bun",title:"Migrating from ts-node to Bun",authors:"johnnyreilly",tags:["bun"],image:"./title-image.png",description:"Migrating from ts-node to Bun is surprisingly easy - this post ports a console app from ts-node to Bun and compares performance.",hide_table_of_contents:!1},prevItem:{title:"Playwright, GitHub Actions and Azure Static Web Apps staging environments",permalink:"/playwright-github-actions-and-azure-static-web-apps-staging-environments"},nextItem:{title:"Node.js 18, Axios and unsafe legacy renegotiation disabled",permalink:"/node-18-axios-and-unsafe-legacy-renegotiation-disabled"}},p={image:n(79436).Z,authorsImageUrls:[void 0]},u=[{value:"The ts-node app",id:"the-ts-node-app",level:2},{value:"Installing Bun",id:"installing-bun",level:2},{value:"Porting the install from yarn to bun",id:"porting-the-install-from-yarn-to-bun",level:2},{value:"From <code>@types/node</code> to <code>bun/types</code>",id:"from-typesnode-to-buntypes",level:2},{value:"<code>moduleResolution</code> with Bun",id:"moduleresolution-with-bun",level:2},{value:"File APIs with Bun",id:"file-apis-with-bun",level:2},{value:"Clarification on <code>fs.promises</code>",id:"clarification-on-fspromises",level:3},{value:"Running the app",id:"running-the-app",level:2},{value:"Top level <code>await</code> and Bun",id:"top-level-await-and-bun",level:2},{value:"GitHub Actions and Bun",id:"github-actions-and-bun",level:2},{value:"Performance comparison; Bun vs ts-node",id:"performance-comparison-bun-vs-ts-node",level:2},{value:"ts-node",id:"ts-node",level:3},{value:"Bun",id:"bun",level:3},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"I've wanted to take a look at some of the alternative JavaScript runtimes for a while. The thing that has held me back is npm compatibility. I want to be able to run my code in a runtime that isn't Node.js and still be able to use npm packages. I've been using ",(0,a.kt)("a",o({parentName:"p"},{href:"https://typestrong.org/ts-node/"}),"ts-node")," for a long time now; it's what I reach for when I'm building any kind of console app. In this post I want to port a console app from ts-node to ",(0,a.kt)("a",o({parentName:"p"},{href:"https://bun.sh/"}),"Bun")," and see how easy it is."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;From ts-node to Bun&quot;",src:n(79436).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"the-ts-node-app"}),"The ts-node app"),(0,a.kt)("p",null,"I have a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://johnnyreilly.com/"}),"technical blog")," which is built on Docusaurus. When the Docusaurus build completes, a post processing script runs to do things like:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"update the ",(0,a.kt)("inlineCode",{parentName:"li"},"sitemap.xml")," to include the ",(0,a.kt)("inlineCode",{parentName:"li"},"lastmod")," date based on ",(0,a.kt)("a",o({parentName:"li"},{href:"https://johnnyreilly.com/docusaurus-createfeeditems-api-git-commit-date"}),"git commit date"),", and truncate the number of entries in the file"),(0,a.kt)("li",{parentName:"ul"},"patch the html files to use Cloudinary as an image CDN for open graph images")),(0,a.kt)("p",null,"These scripts are implemented as a simple ts-node console app. For historical reasons it's called ",(0,a.kt)("inlineCode",{parentName:"p"},"trim-xml")," (it originally just truncated the ",(0,a.kt)("inlineCode",{parentName:"p"},"sitemap.xml")," file). It's not a particularly good name but I'm not going to change it now. As the blog is open source, you can see the ","[code of ",(0,a.kt)("inlineCode",{parentName:"p"},"trim-xml")," here]","(",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com/tree/main/trim-xml%5D"}),"https://github.com/johnnyreilly/blog.johnnyreilly.com/tree/main/trim-xml]"),"."),(0,a.kt)("p",null,"What we're interested in, is porting this app from ts-node to Bun. The app has a few dependencies; so npm compatibility is important to us. Let's see how it goes."),(0,a.kt)("h2",o({},{id:"installing-bun"}),"Installing Bun"),(0,a.kt)("p",null,"I installed Bun on my Ubuntu machine using the following command:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"curl -fsSL https://bun.sh/install | bash\n")),(0,a.kt)("p",null,"Which resulted in the following output:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),'bun was installed successfully to ~/.bun/bin/bun\n\nAdded "~/.bun/bin" to $PATH in "~/.zshrc"\n\nTo get started, run:\n\n exec /usr/bin/zsh\n  bun --help\n')),(0,a.kt)("p",null,"I was a little weirded out by the inconsistent indentation in the output but I'm sure that's just a formatting issue. (I submitted a ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/oven-sh/bun/pull/2175"}),"PR to fix this"),".) When I ran the suggested commands it looked like bun was happy and healthy."),(0,a.kt)("h2",o({},{id:"porting-the-install-from-yarn-to-bun"}),"Porting the install from yarn to bun"),(0,a.kt)("p",null,"With bun in place I was ready to port the app. I opened up the (as I say, badly named) ",(0,a.kt)("inlineCode",{parentName:"p"},"trim-xml")," directory and triggered installation of the dependencies using ",(0,a.kt)("inlineCode",{parentName:"p"},"bun install"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"cd trim-xml\nbun install\n")),(0,a.kt)("p",null,"Output looked like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"bun install v0.5.7 (5929daee)\n + @types/node@18.14.1\n + fast-xml-parser@4.1.2\n + simple-git@3.16.1\n + typescript@4.9.5\n\n 5 packages installed [2.34s]\n")),(0,a.kt)("p",null,"As well, a new ",(0,a.kt)("inlineCode",{parentName:"p"},"bun.lockb")," file had appeared in the directory alongside the ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json"),". Although I can't find any documentation on it, I'm guessing that this is the Bun equivalent of ",(0,a.kt)("inlineCode",{parentName:"p"},"package-lock.json")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn.lock"),". It's a binary file, so you can't read it. I did find this ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/JacksonKearl/bun-lockb"}),"project which allows you read bun.lockb files")," which looks like a useful way to solve that problem."),(0,a.kt)("p",null,"To avoid confusion, I also deleted the ",(0,a.kt)("inlineCode",{parentName:"p"},"yarn.lock")," file. Yay - I've installed things! And pretty fast! What next?"),(0,a.kt)("h2",o({},{id:"from-typesnode-to-buntypes"}),"From ",(0,a.kt)("inlineCode",{parentName:"h2"},"@types/node")," to ",(0,a.kt)("inlineCode",{parentName:"h2"},"bun/types")),(0,a.kt)("p",null,"As I looked at the output for the install I realised that the ",(0,a.kt)("inlineCode",{parentName:"p"},"@types/node")," package had been installed. The ",(0,a.kt)("inlineCode",{parentName:"p"},"@types/node")," package is a package that contains TypeScript definitions for the Node.js runtime. Given we're moving to using Bun, it seemed likely that I didn't need these. But I likely did need something that represented the Bun runtime types. (Which incidentally, I would imagine to be pretty similar to the Node.js runtime types.)"),(0,a.kt)("p",null,"I had a quick look at the Bun documentation and found the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://oven-sh.github.io/bun-types/"}),(0,a.kt)("inlineCode",{parentName:"a"},"bun/types"))," package. I added it to my project, whilst removing ",(0,a.kt)("inlineCode",{parentName:"p"},"@types/node")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-node"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"bun remove @types/node\nbun remove ts-node\nbun add bun-types\n")),(0,a.kt)("p",null,"Output looked like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"bun remove v0.5.7 (5929daee)\n - @types/node\n\n 1 packages removed [3.00ms]\nbun remove v0.5.7 (5929daee)\n - ts-node\n\n 1 packages removed [843.00ms]\nbun add v0.5.7 (5929daee)\n\n installed bun-types@0.5.7\n\n\n 1 packages installed [1.97s]\n")),(0,a.kt)("p",null,"The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://oven-sh.github.io/bun-types/#usage"}),"docs also say"),":"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Add this to your ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"jsconfig.json"),":"),(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",o({parentName:"pre"},{className:"language-json"}),'{\n  "compilerOptions": {\n    "lib": ["ESNext"],\n    "module": "esnext",\n    "target": "esnext",\n    // "bun-types" is the important part\n    "types": ["bun-types"]\n  }\n}\n'))),(0,a.kt)("p",null,"I aligned my existing ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," with the above. For my console app this meant the following changes:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),'  {\n    "compilerOptions": {\n-      "target": "ES2022",\n+      "target": "esnext",\n-      // "lib": [],\n+      "lib": ["ESNext"],\n-      "module": "NodeNext",\n+      "module": "esnext",\n-      // "types": [],\n+      "types": ["bun-types"],\n    },\n  }\n')),(0,a.kt)("h2",o({},{id:"moduleresolution-with-bun"}),(0,a.kt)("inlineCode",{parentName:"h2"},"moduleResolution")," with Bun"),(0,a.kt)("p",null,"I'd imagined that at this point I'd be able to run the app, but when I navigated around in VS Code I saw that I had a bunch of errors. I was getting errors like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of VS Code saying &quot;Cannot find module &#39;fast-xml-parser&#39;. Did you mean to set the &#39;moduleResolution&#39; option to &#39;node&#39;, or to add aliases to the &#39;paths&#39; option?ts(2792)&quot;",src:n(42802).Z,width:"1270",height:"230"})),(0,a.kt)("p",null,"The error message was suggesting I needed to explicitly state that I wanted to use the Node.js module resolution algorithm. Whilst we're using Bun, we're porting a Node app - so this made sense. So I made one more change to the ",(0,a.kt)("inlineCode",{parentName:"p"},"tsconfig.json")," to satisy this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),'  {\n    "compilerOptions": {\n-      // "moduleResolution": "node",\n+      "moduleResolution": "nodenext",\n    },\n  }\n')),(0,a.kt)("p",null,"With that in place, the module resolution errors were... resolved. (Sorry.)"),(0,a.kt)("h2",o({},{id:"file-apis-with-bun"}),"File APIs with Bun"),(0,a.kt)("p",null,"However, I was still getting errors. This time they were about the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://nodejs.org/api/fs.html#promises-api"}),(0,a.kt)("inlineCode",{parentName:"a"},"fs.promises")," API"),". I was getting errors like this:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"screenshot of errors in VS Code reporting the absence of the fs.promises API",src:n(68779).Z,width:"761",height:"165"})),(0,a.kt)("p",null,"It looked like the version of bun I was using didn't support that API. As I dug through my code I realised that I was using the ",(0,a.kt)("inlineCode",{parentName:"p"},"fs.promises")," API in a few places. I was using it in the following ways:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"await fs.promises.readdir")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"await fs.promises.readFile")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"await fs.promises.writeFile"))),(0,a.kt)("p",null,"For ",(0,a.kt)("inlineCode",{parentName:"p"},"fs.promises.readFile")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"fs.promises.writeFile")," I was able to replace them with the Bun equivalents ",(0,a.kt)("a",o({parentName:"p"},{href:"https://bun.sh/docs/api/file-io#reading-files"}),(0,a.kt)("inlineCode",{parentName:"a"},"Bun.file(path).text()"))," and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://bun.sh/docs/api/file-io#writing-files"}),(0,a.kt)("inlineCode",{parentName:"a"},"Bun.write(path, content)"))," respectively:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),"- `await fs.promises.readFile`\n+ `await Bun.file(path).text()`\n- `await fs.promises.writeFile(path, content)`\n+ `await Bun.write(path, content)`\n")),(0,a.kt)("p",null,"There appeared to be no Bun equivalent for ",(0,a.kt)("inlineCode",{parentName:"p"},"fs.promises.readdir"),", so I used the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://nodejs.org/api/fs.html#fsreaddirsyncpath-options"}),"sync Node.js API"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),"- `await fs.promises.readdir`\n+ `fs.readdirSync(path)`\n")),(0,a.kt)("p",null,"We now had code without any errors. (At least in VS Code as far as TypeScript was concerned. I had yet to run the app to see if it worked.)"),(0,a.kt)("h3",o({},{id:"clarification-on-fspromises"}),"Clarification on ",(0,a.kt)("inlineCode",{parentName:"h3"},"fs.promises")),(0,a.kt)("p",null,"I was tweeting about my findings as I wrote this, and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://twitter.com/jarredsumner/status/1629818921904902145"}),"Jarred Sumner (who works on Bun) was kind enough to share")," that the ",(0,a.kt)("inlineCode",{parentName:"p"},"fs.promises")," API is implemented but the types aren't as yet."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of exchange on Twitter with Jarred responding &quot;it sort of exists, but looks like the types are out of date. I say sort of because, actually everything async is sync for node:fs and it just wraps in a Promise. If you use fs createReadStream / fs.createWriteStream or Bun.file(path).stream() it\u2019ll be concurrent / async&quot;",src:n(27476).Z,width:"558",height:"833"})),(0,a.kt)("h2",o({},{id:"running-the-app"}),"Running the app"),(0,a.kt)("p",null,"I now needed to do one more thing:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),'-    "start": "ts-node index.ts"\n+    "start": "bun index.ts"\n')),(0,a.kt)("p",null,"That's right; update the ",(0,a.kt)("inlineCode",{parentName:"p"},"start")," script in ",(0,a.kt)("inlineCode",{parentName:"p"},"package.json")," to use ",(0,a.kt)("inlineCode",{parentName:"p"},"bun")," instead of ",(0,a.kt)("inlineCode",{parentName:"p"},"ts-node"),". And now I was able to run the app with ",(0,a.kt)("inlineCode",{parentName:"p"},"bun start"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"Loading /home/john/code/github/blog.johnnyreilly.com/blog-website/build/sitemap.xml\nReducing 526 urls to 512 urls\n")),(0,a.kt)("p",null,"The first positive thing about what I saw, was that we appeared to have running code. Yay! The program also appeared to be executing instantaneously, which seemed surprising. I was expecting Bun to be faster, but this seemed too fast."),(0,a.kt)("p",null,"Also, we seemed to be lacking many of the log messages I'd expect. I was expecting to see about 1000 log messages. Something wasn't right."),(0,a.kt)("h2",o({},{id:"top-level-await-and-bun"}),"Top level ",(0,a.kt)("inlineCode",{parentName:"h2"},"await")," and Bun"),(0,a.kt)("p",null,"The issue was that my ",(0,a.kt)("inlineCode",{parentName:"p"},"main")," function was asynchronous. However, because support for top level ",(0,a.kt)("inlineCode",{parentName:"p"},"await")," wasn't available in Node.js when I originally wrote the code, I'd called the ",(0,a.kt)("inlineCode",{parentName:"p"},"main")," function synchronously. Fortunately Node didn't complain about that, and the program behaved in the way required."),(0,a.kt)("p",null,"However Bun looked like it was respecting the fact that ",(0,a.kt)("inlineCode",{parentName:"p"},"main")," was asynchronous. That's why it was apparently executing so quickly; it wasn't waiting for the ",(0,a.kt)("inlineCode",{parentName:"p"},"main")," method to complete before terminating."),(0,a.kt)("p",null,"To be honest, Bun's behaviour here is just right; the code as is didn't suggest that it was interested in waiting for the ",(0,a.kt)("inlineCode",{parentName:"p"},"main")," function to complete. But it turns out that waiting is exactly the desired behaviour. To bring things right, we could use top level ",(0,a.kt)("inlineCode",{parentName:"p"},"await"),". So I made the following change to my ",(0,a.kt)("inlineCode",{parentName:"p"},"index.ts")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-diff"}),"- main();\n+ await main();\n")),(0,a.kt)("p",null,"And now I was getting the expected log messages; and the program appeared to be working as expected."),(0,a.kt)("h2",o({},{id:"github-actions-and-bun"}),"GitHub Actions and Bun"),(0,a.kt)("p",null,"I was now able to run the app locally. But I wanted to run it in GitHub Actions. I just needed to add the ",(0,a.kt)("inlineCode",{parentName:"p"},"setup-bun")," action to my workflow, so bun was available in the GitHub Actions environment:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yaml"}),"- name: Setup bun \ud83d\udd27\n  uses: oven-sh/setup-bun@v1\n  with:\n    bun-version: latest\n")),(0,a.kt)("h2",o({},{id:"performance-comparison-bun-vs-ts-node"}),"Performance comparison; Bun vs ts-node"),(0,a.kt)("p",null,"I was expecting Bun to be faster than ts-node. Let's take a run of our app in GitHub Actions with ts-node and compare it to a run of our app with Bun:"),(0,a.kt)("h3",o({},{id:"ts-node"}),"ts-node"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"Post processing finished in 17.09 seconds\nDone in 19.52s.\n")),(0,a.kt)("h3",o({},{id:"bun"}),"Bun"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"Post processing finished in 12.367 seconds\nDone in 12.72s.\n")),(0,a.kt)("p",null,"I haven't done any formal benchmarking, but it looks like Bun is about 50% faster than ts-node for this usecase. That's pretty good. It's also worth expanding on how this breaks down."),(0,a.kt)("p",null,"You'll notice in the logs above there's two log entries:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},'The "Post processing" reflects the time taken to run the ',(0,a.kt)("inlineCode",{parentName:"li"},"main")," function."),(0,a.kt)("li",{parentName:"ol"},'The "Done" reflects the time taken to run the ',(0,a.kt)("inlineCode",{parentName:"li"},"bun")," command end to end.")),(0,a.kt)("p",null,"What can we learn from this? First of all, running code in ts-node takes 17 seconds, compared to 12 seconds with Bun. ",(0,a.kt)("strong",{parentName:"p"},"So Bun is performing about 40% faster at running code.")),(0,a.kt)("p",null,"The end to end is 19 seconds with ts-node, compared to 14 seconds with Bun. ",(0,a.kt)("strong",{parentName:"p"},"So Bun is performing about 50% faster end to end.")," There's two parts to this; the time taken to compile the code and the time taken to start up. We're doing type checking with ts-node; which if deactivated would make a difference."),(0,a.kt)("p",null,"However, when you look at the difference between the end to end runtime and code runtime with Bun, it's a mere 0.353 seconds. ts-node clocks in at 2.43 seconds for the same. So ts-node is about 6.5 times slower at starting up. That's a pretty big difference; it's unlikely that all of this is TypeScript compilation; Node.js is fundamentally slower at getting going than Bun is."),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"Moving from ts-node to Bun was a pretty easy process. I was able to do it in a few hours. I was able to run the app locally and in GitHub Actions. And I was able to run the app in less time."),(0,a.kt)("p",null,"This all makes me feel very positive about Bun. I'm looking forward to using it more in the future."),(0,a.kt)("p",null,(0,a.kt)("a",o({parentName:"p"},{href:"https://blog.logrocket.com/migrating-typescript-app-node-js-bun/"}),"This post was originally published on LogRocket.")),(0,a.kt)("head",null,(0,a.kt)("link",{rel:"canonical",href:"https://blog.logrocket.com/migrating-typescript-app-node-js-bun/"})))}d.isMDXComponent=!0},27546:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});n(67294);var a=n(3905);function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}const r={slug:"playwright-github-actions-and-azure-static-web-apps-staging-environments",title:"Playwright, GitHub Actions and Azure Static Web Apps staging environments",authors:"johnnyreilly",tags:["Azure Static Web Apps","GitHub Actions"],image:"./title-image.png",description:"Azure Static Web Apps staging environments allow you to test changes before they go live. This shows how to use Playwright against staging environments.",hide_table_of_contents:!1},s=void 0,l={permalink:"/playwright-github-actions-and-azure-static-web-apps-staging-environments",editUrl:"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2023-03-20-playwright-github-actions-and-azure-static-web-apps-staging-environments/index.md",source:"@site/blog/2023-03-20-playwright-github-actions-and-azure-static-web-apps-staging-environments/index.md",title:"Playwright, GitHub Actions and Azure Static Web Apps staging environments",description:"Azure Static Web Apps staging environments allow you to test changes before they go live. This shows how to use Playwright against staging environments.",date:"2023-03-20T00:00:00.000Z",formattedDate:"March 20, 2023",tags:[{label:"Azure Static Web Apps",permalink:"/tags/azure-static-web-apps"},{label:"GitHub Actions",permalink:"/tags/git-hub-actions"}],readingTime:8.97,hasTruncateMarker:!0,authors:[{name:"John Reilly",title:"OSS Engineer - TypeScript, Azure, React, Node.js, .NET",url:"https://johnnyreilly.com/about",imageURL:"https://johnnyreilly.com/img/profile.jpg",key:"johnnyreilly"}],frontMatter:{slug:"playwright-github-actions-and-azure-static-web-apps-staging-environments",title:"Playwright, GitHub Actions and Azure Static Web Apps staging environments",authors:"johnnyreilly",tags:["Azure Static Web Apps","GitHub Actions"],image:"./title-image.png",description:"Azure Static Web Apps staging environments allow you to test changes before they go live. This shows how to use Playwright against staging environments.",hide_table_of_contents:!1},nextItem:{title:"Migrating from ts-node to Bun",permalink:"/migrating-from-ts-node-to-bun"}},p={image:n(76102).Z,authorsImageUrls:[void 0]},u=[{value:"Playwright, GitHub Actions and Azure Static Web Apps",id:"playwright-github-actions-and-azure-static-web-apps",level:2},{value:"Adding Playwright to the project",id:"adding-playwright-to-the-project",level:2},{value:"A test using <code>baseURL</code>",id:"a-test-using-baseurl",level:2},{value:"Creating a GitHub Actions workflow",id:"creating-a-github-actions-workflow",level:2},{value:"Site build and deploy \ud83c\udfd7\ufe0f",id:"site-build-and-deploy-\ufe0f",level:3},{value:"Integration tests \ud83d\udca1\ud83c\udfe0",id:"integration-tests-",level:3},{value:"How does it look?",id:"how-does-it-look",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function d(e){var{components:t}=e,r=i(e,["components"]);return(0,a.kt)("wrapper",o({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Azure Static Web Apps staging environments allow you to test changes before they go live. This post shows how to use Playwright against staging environments with GitHub Actions. It's a follow up to my previous post on ",(0,a.kt)("a",o({parentName:"p"},{href:"/lighthouse-meet-github-actions"}),"using Lighthouse with Azure Static Web Apps staging environments"),"."),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"eager",fetchpriority:"high",alt:"title image reading &quot;Playwright, GitHub Actions and Azure Static Web Apps staging environments&quot; with product logos",src:n(76102).Z,width:"800",height:"450"})),(0,a.kt)("h2",o({},{id:"playwright-github-actions-and-azure-static-web-apps"}),"Playwright, GitHub Actions and Azure Static Web Apps"),(0,a.kt)("p",null,"What's the problem we're trying to solve? Let's do our best Simon Sinek impression and start with \"Why?\". The \"Why?\" is that we want only to ship changes that haven't broken our application."),(0,a.kt)("p",null,'Now let\'s move onto "How?" The way we guard against breaking production is by running automated tests on all changes. Playwright is a tool that allows us to do that. We get a fully fledged staging environment available to us on all pull requests. We want to run Playwright integration tests against our staging environment. We want to do this as part of our CI/CD pipeline; in our GitHub Actions workflow.'),(0,a.kt)("p",null,"I'm going to write about this in the context of my blog. My blog is open source and ",(0,a.kt)("a",o({parentName:"p"},{href:"https://github.com/johnnyreilly/blog.johnnyreilly.com"}),"you can find the code here"),". I'm going to present a simplified solution in this post, but you can find the full solution on GitHub."),(0,a.kt)("h2",o({},{id:"adding-playwright-to-the-project"}),"Adding Playwright to the project"),(0,a.kt)("p",null,"To add Playwright to my blog I followed the ",(0,a.kt)("a",o({parentName:"p"},{href:"https://playwright.dev/docs/intro"}),"instructions on the Playwright website"),". Essentially I ran the following command:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-bash"}),"npm init playwright@latest\n")),(0,a.kt)("p",null,"By and large I accepted the defaults. However, I deleted the GitHub Actions workflow that was created, in favour of my own which we'll get to soon. I'd created my tests in a ",(0,a.kt)("inlineCode",{parentName:"p"},"blog-website-tests")," directory. This sits alongside the ",(0,a.kt)("inlineCode",{parentName:"p"},"blog-website")," directory which contains the code for my blog."),(0,a.kt)("p",null,"I made one tweak to the ",(0,a.kt)("inlineCode",{parentName:"p"},"playwright.config.ts")," file that was created. I added the following line:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"//...\n\n/**\n * See https://playwright.dev/docs/test-configuration.\n */\nexport default defineConfig({\n  //...\n\n  use: {\n    //...\n\n    // WE WILL SET THIS IN THE GITHUB ACTIONS WORKFLOW\n    baseURL: process.env.PLAYWRIGHT_TEST_BASE_URL || 'http://localhost:3000',\n  },\n\n  //...\n});\n")),(0,a.kt)("p",null,"What's going on here? I'm setting the ",(0,a.kt)("inlineCode",{parentName:"p"},"baseURL")," to be the value of the ",(0,a.kt)("inlineCode",{parentName:"p"},"PLAYWRIGHT_TEST_BASE_URL")," environment variable. If that's not set then I'm defaulting to ",(0,a.kt)("inlineCode",{parentName:"p"},"http://localhost:3000"),", which is where my blog is served when running locally. I'll explain why I'm doing this in a moment."),(0,a.kt)("h2",o({},{id:"a-test-using-baseurl"}),"A test using ",(0,a.kt)("inlineCode",{parentName:"h2"},"baseURL")),(0,a.kt)("p",null,"The ",(0,a.kt)("a",o({parentName:"p"},{href:"https://playwright.dev/docs/api/class-testoptions#test-options-base-url"}),(0,a.kt)("inlineCode",{parentName:"a"},"baseURL"))," can be used in a Playwright test to determine where to run the tests. That's exactly what I'm doing in the following test file named ",(0,a.kt)("inlineCode",{parentName:"p"},"the.spec.ts"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-ts"}),"import { test, expect } from '@playwright/test';\n\ntest('page should have title and a root navigation link', async ({\n  page,\n  baseURL,\n}) => {\n  await page.goto(baseURL!);\n  const title = await page.title();\n  expect(title).toBe('johnnyreilly | johnnyreilly');\n\n  const navTitle = page.getByRole('link', {\n    name: 'Profile picture of John Reilly John Reilly \u2764\ufe0f\ud83c\udf3b',\n  });\n  await expect(navTitle).toBeVisible();\n});\n\ntest('can navigate to about page', async ({ page, baseURL }) => {\n  await page.goto(baseURL!);\n  await page.getByRole('link', { name: 'About', exact: true }).click();\n\n  const navTitle = page.getByRole('heading', {\n    name: \"Hi! I'm John Reilly - welcome! \u2764\ufe0f\ud83c\udf3b\",\n  });\n  await expect(navTitle).toBeVisible();\n});\n")),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"baseURL")," is used in the ",(0,a.kt)("inlineCode",{parentName:"p"},"page.goto")," call. This means that the tests will run against the URL that I specify. In the case of the GitHub Actions workflow, I'll specify the URL of the staging environment. These are simple tests that check that the title of the page is correct and that I can navigate to the about page. Consider them smoke tests."),(0,a.kt)("h2",o({},{id:"creating-a-github-actions-workflow"}),"Creating a GitHub Actions workflow"),(0,a.kt)("p",null,"We now have a test that we can run against a URL. We need to create a GitHub Actions workflow that will run the test against the staging environment. I've created a workflow file named ",(0,a.kt)("inlineCode",{parentName:"p"},"build-and-deploy-static-web-app.yml")," in the ",(0,a.kt)("inlineCode",{parentName:"p"},".github/workflows")," directory. It looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",o({parentName:"pre"},{className:"language-yml"}),"name: Static Web App - Build and Deploy \ud83c\udfd7\ufe0f\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    types: [opened, synchronize, reopened, closed]\n    branches:\n      - main\n  workflow_dispatch:\n\npermissions:\n  id-token: write\n  contents: write\n  pull-requests: write\n\nenv:\n  LOCATION: westeurope\n  STATICWEBAPPNAME: blog.johnnyreilly.com\n\njobs:\n  build_and_deploy_swa_job:\n    if: github.event_name == 'push' || (github.event_name == 'pull_request' && github.event.action != 'closed')\n    runs-on: ubuntu-latest\n    name: Site build and deploy \ud83c\udfd7\ufe0f\n    steps:\n      - name: Checkout \ud83d\udce5\n        uses: actions/checkout@v3\n\n      # Auth between GitHub and Azure is handled by https://github.com/jongio/github-azure-oidc\n      # https://github.com/Azure/login#sample-workflow-that-uses-azure-login-action-using-oidc-to-run-az-cli-linux\n      # other login options are possible too\n      - name: AZ CLI login \ud83d\udd11\n        uses: azure/login@v1\n        with:\n          client-id: ${{ secrets.AZURE_CLIENT_ID }}\n          tenant-id: ${{ secrets.AZURE_TENANT_ID }}\n          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\n\n      - name: Get preview URL \ud83d\udcdd\n        id: static_web_app_preview_url\n        uses: azure/CLI@v1\n        with:\n          inlineScript: |\n            DEFAULTHOSTNAME=$(az staticwebapp show -n '${{ env.STATICWEBAPPNAME }}' | jq -r '.defaultHostname')\n\n            PREVIEW_URL=\"https://${DEFAULTHOSTNAME/.[1-9]./-${{github.event.pull_request.number }}.${{ env.LOCATION }}.1.}\"\n\n            echo \"PREVIEW_URL=$PREVIEW_URL\" >> $GITHUB_OUTPUT\n\n      - name: Setup Node.js \ud83d\udd27\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n          cache: 'yarn'\n\n      - name: Install and build site \ud83d\udd27\n        run: |\n          cd blog-website\n          yarn install --frozen-lockfile\n          yarn run build\n          cp staticwebapp.config.json build/staticwebapp.config.json\n\n      - name: Get API key \ud83d\udd11\n        id: static_web_app_apikey\n        uses: azure/CLI@v1\n        with:\n          inlineScript: |\n            APIKEY=$(az staticwebapp secrets list --name '${{ env.STATICWEBAPPNAME }}' | jq -r '.properties.apiKey')\n            echo \"APIKEY=$APIKEY\" >> $GITHUB_OUTPUT\n\n      - name: Deploy site \ud83d\ude80\n        id: static_web_app_build_and_deploy\n        uses: Azure/static-web-apps-deploy@v1\n        with:\n          azure_static_web_apps_api_token: ${{ steps.static_web_app_apikey.outputs.APIKEY }}\n          repo_token: ${{ secrets.GITHUB_TOKEN }} # Used for Github integrations (i.e. PR comments)\n          action: 'upload'\n          skip_app_build: true\n          app_location: '/blog-website/build' # App source code path\n          api_location: '/blog-website/api' # Api source code path - optional\n\n    outputs:\n      preview-url: ${{steps.static_web_app_preview_url.outputs.PREVIEW_URL}}\n\n  integration_tests_job:\n    name: Integration tests \ud83d\udca1\ud83c\udfe0\n    needs: build_and_deploy_swa_job\n    if: github.event_name == 'pull_request' && github.event.action != 'closed'\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Wait for preview ${{ needs.build_and_deploy_swa_job.outputs.preview-url }} \u231a\n        id: static_web_app_wait_for_preview\n        uses: nev7n/wait_for_response@v1\n        with:\n          url: '${{ needs.build_and_deploy_swa_job.outputs.preview-url }}'\n          responseCode: 200\n          timeout: 600000\n          interval: 1000\n\n      - uses: actions/setup-node@v3\n        with:\n          node-version: 18\n\n      - name: Install dependencies\n        run: npm ci\n        working-directory: ./blog-website-tests\n\n      - name: Install Playwright Browsers\n        run: npx playwright install --with-deps\n        working-directory: ./blog-website-tests\n\n      - name: Run Playwright tests\n        env:\n          PLAYWRIGHT_TEST_BASE_URL: '${{ needs.build_and_deploy_swa_job.outputs.preview-url }}'\n        run: npx playwright test\n        working-directory: ./blog-website-tests\n\n      - uses: actions/upload-artifact@v3\n        if: always()\n        with:\n          name: playwright-report\n          path: blog-website-tests/playwright-report/\n          retention-days: 30\n\n  close_pull_request_job:\n    if: github.event_name == 'pull_request' && github.event.action == 'closed'\n    runs-on: ubuntu-latest\n    name: Cleanup staging \ud83d\udca5\n    steps:\n      - name: AZ CLI login \ud83d\udd11\n        uses: azure/login@v1\n        with:\n          client-id: ${{ secrets.AZURE_CLIENT_ID }}\n          tenant-id: ${{ secrets.AZURE_TENANT_ID }}\n          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\n\n      - name: Get API key \ud83d\udd11\n        id: apikey\n        uses: azure/CLI@v1\n        with:\n          inlineScript: |\n            APIKEY=$(az staticwebapp secrets list --name '${{ env.STATICWEBAPPNAME }}' | jq -r '.properties.apiKey')\n            echo \"APIKEY=$APIKEY\" >> $GITHUB_OUTPUT\n\n      - name: Destroy staging environment \ud83d\udca5\n        id: closepullrequest\n        uses: Azure/static-web-apps-deploy@v1\n        with:\n          azure_static_web_apps_api_token: ${{ steps.apikey.outputs.APIKEY }}\n          action: 'close'\n")),(0,a.kt)("p",null,"As I said earlier, this has been chopped down from the full version in my repo. It contains specific variables from my own project, but you can see the general structure of the workflow."),(0,a.kt)("p",null,"Let's look at what happens above; there are 3 jobs:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Site build and deploy \ud83c\udfd7\ufe0f - This is the main job that builds the site and deploys it to the Static Web App."),(0,a.kt)("li",{parentName:"ol"},"Integration tests \ud83d\udca1\ud83c\udfe0 - This job runs the Playwright tests against the preview URL of our Static Web App."),(0,a.kt)("li",{parentName:"ol"},"Cleanup staging \ud83d\udca5 - This job runs when a pull request is closed, and destroys the staging environment.")),(0,a.kt)("p",null,"Let's dig into 1 and 2 a bit more. We'll ignore 3 as it's pretty self explanatory."),(0,a.kt)("h3",o({},{id:"site-build-and-deploy-\ufe0f"}),"Site build and deploy \ud83c\udfd7\ufe0f"),(0,a.kt)("p",null,"This job is the main job that builds the site and deploys it to the Static Web App. It's a bit long, but it's not too complicated. Let's break it down:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Checkout \ud83d\udce5 - This is the first step, and it checks out the code from GitHub.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"AZ CLI login \ud83d\udd11 - This step logs into Azure using the ",(0,a.kt)("inlineCode",{parentName:"p"},"azure/login")," action. This is required to run the ",(0,a.kt)("inlineCode",{parentName:"p"},"az")," CLI commands.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Get preview URL \ud83d\udcdd - This step constructs the preview URL of the Static Web App using the ",(0,a.kt)("inlineCode",{parentName:"p"},"defaultHostname"),", the location of deployment, the pull request number and the partition id."),(0,a.kt)("p",{parentName:"li"},"The partition id is the ",(0,a.kt)("inlineCode",{parentName:"p"},"1")," in the URL. It matches whichever partition id that exists for the domain. Right now, if you create a new SWA, you will not get a ",(0,a.kt)("inlineCode",{parentName:"p"},"1")," since SWA is now on partition ",(0,a.kt)("inlineCode",{parentName:"p"},"2"),". When that partition gets filled, it will move on to partition ",(0,a.kt)("inlineCode",{parentName:"p"},"3"),". Ultimately, you just need to find out what the partition id for your SWA is, then you can hardcode it into your workflow."),(0,a.kt)("p",{parentName:"li"},"The complete preview URL is required to run the Playwright tests against the preview URL.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Setup Node.js \ud83d\udd27 - This step sets up Node.js, which is required to build the site.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Install and build site \ud83d\udd27 - This step installs the dependencies and builds the site - we build our SWA ourselves; you can generally just leave this to the ",(0,a.kt)("inlineCode",{parentName:"p"},"Azure/static-web-apps-deploy@v1")," task. We don't because ",(0,a.kt)("a",o({parentName:"p"},{href:"/migrating-from-ts-node-to-bun"}),"we have some post processing to do that requires Bun"),".")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Get API key \ud83d\udd11 - This step gets the API key for the Static Web App. This is required to deploy the site.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Deploy site \ud83d\ude80 - This step deploys the site to the Static Web App."))),(0,a.kt)("h3",o({},{id:"integration-tests-"}),"Integration tests \ud83d\udca1\ud83c\udfe0"),(0,a.kt)("p",null,"Our tests job depends upon the previous job; specifically the preview URL of our Static Web App. You can't run Playwright tests if you've nothing to run them against! Again, let's dig into it:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Checkout \ud83d\udce5 - This is the first step, and it checks out the code from GitHub."),(0,a.kt)("li",{parentName:"ol"},"Wait for preview ... \u231a - This step waits for the preview URL to be available. This is required because the Static Web App takes a few minutes to deploy, and we don't want to run the tests until it's deployed."),(0,a.kt)("li",{parentName:"ol"},"Setup Node.js \ud83d\udd27 - This step sets up Node.js, which is required to run the tests."),(0,a.kt)("li",{parentName:"ol"},"Install dependencies - This step installs the dependencies for the tests."),(0,a.kt)("li",{parentName:"ol"},"Install Playwright Browsers - This step installs the browsers that Playwright will use to run the tests."),(0,a.kt)("li",{parentName:"ol"},"Run Playwright tests - This step runs the Playwright tests."),(0,a.kt)("li",{parentName:"ol"},"Upload test report - This step uploads the test report as an artifact. This is useful if you want to see the test report after the tests have run.")),(0,a.kt)("h2",o({},{id:"how-does-it-look"}),"How does it look?"),(0,a.kt)("p",null,"When we put all this together and push it up to GitHub, we see that tests run as part of the pull request:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the GitHub Action with passing tests",src:n(71380).Z,width:"921",height:"849"})),(0,a.kt)("p",null,"This screenshot is taken directly from my own blog, and so includes things like Lighthouse that are excluded from this post. But what you can see is that tests are indeed running; and we can see the test report as an artifact:"),(0,a.kt)("p",null,(0,a.kt)("img",{loading:"lazy",alt:"Screenshot of the test report",src:n(15725).Z,width:"996",height:"784"})),(0,a.kt)("h2",o({},{id:"conclusion"}),"Conclusion"),(0,a.kt)("p",null,"So there you have it; a simple way to run Playwright tests against your Static Web App. I hope you found this useful, and if you have any questions, please feel free to reach out to me."))}d.isMDXComponent=!0},58824:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Check-out-the-JSON-22f341ec646ab8f585e451fab303cf5b.webp"},20164:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/jqgrid-in-all-its-glory-af580dfcf8740aed547e02dd42ec77b4.webp"},41221:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Using-JSON-f768388299d36538142bab904c6aa89d.webp"},35615:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/validation-screenshot2-7d2018fce6a002850a83a0a459bb1e51.webp"},37553:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/IDE-70c79404a67eeb869491ec15aea7474f.png"},28067:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Mad-Stuff-5dc864cbbda35460fb52a9b9c085c8a0.webp"},90672:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/CSharp-version-of-JohnReilly-836e0b7414d5a336104847981658261c.webp"},62991:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/JavaScript-version-of-JohnReilly-8e8928f803782798071a689ae95a2bcb.webp"},34535:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Extensions-a0125814fba87f127354ae52c4509b3f.webp"},21613:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/JSLint-8f63767579064fce2f1881bc45bb1f11.webp"},76705:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/FireBug-Dates-12e5f5715cbb23911a5101410ce12521.webp"},22170:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/IE9-screenshot-3392aa8eaaddfbef70b519098f51fb71.webp"},35745:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/6a0120a85dcdae970b0120a86ddeee970b-21f45bc31016b9a08a9668c096b1cc00.webp"},91257:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/CPC6128-71187b61f768a1c9aded9abd417c661d.webp"},69826:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/images-c8e814195ded95659f239f60bcba454c.webp"},7353:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/AJAX-bleach-7c931a5a01ab27817afe7d3dcc51b4fe.webp"},51718:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/1200.JSDoc_in_VS.png-486x314-1568cd0c8b31ea01f2611a089c50d18e.png"},55224:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/jquery-type-definition-tweet-1da0464128c37f92056fe03cc4f80481.webp"},85541:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2014-09-06-21.43.15-5e25ff0477bfc04d2262532fb4cc065c.webp"},4477:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2014-09-06-21.49.38-07607fe83d2edca25166cafa3321d7b3.webp"},12521:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/sageDetailScreen-4bfe2805dcd359ed1871fb34960eeb93.webp"},84438:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2014-09-12-23.15.22-819912598822bd7c4fde15e97e8d113a.webp"},54758:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2014-10-21-17.02.11-e6efce21155e122138e6ea2793f2fa06.webp"},35455:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2014-12-05-05.39.00-4eab29decfc200a9f26bb3d0af71ec57.webp"},30064:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2014-12-05-05.41.59-903fdf1871d122e8033d8f2f8a047ecc.webp"},30014:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2014-12-29-06.22.46-2908990aadcd679ca4e964ebeae7f575.webp"},60422:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/AppVeyor-encrypt-731a03275554a257dbb8e563f4de8890.webp"},42715:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/GitHub-Personal-Access-Token-6b41dbb8a19385c54e80f2c2b366a712.webp"},58035:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/GitHubApplicationSettings-7a5a90987a902ef8990614b5c6c1d848.webp"},37769:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2015-02-27-16.05.29-437ecf05abfbb13a3e58e687bdb2b34b.webp"},82183:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot_emoji-74a00c34492a1c5fa7e4eec3263cb155.jpg"},27644:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot_input_languages-b5c1456649891db67d95fa4727fd33ea.png"},62879:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/MigrationHistory-8904b3e0bbb58f999644df4666d69b92.webp"},69682:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Migrations-3ddbdaf0fb45daa7122fc2fa7ef323c9.png"},35300:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2015-06-19-13.07.50-b5f34a048c42393b95bf8ec80d17a178.png"},38526:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2015-06-19-13.08.46-1b8014508b5d028482b42e7c51c2ffc4.png"},22780:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2015-06-19-13.35.40-f22e0660c499845cd98e5551595c0dc3.webp"},66102:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/where-were-going-1320a9efce695617ff7978b03d4a43ec.webp"},79304:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/bower-with-the-long-paths-809754f96c480d0a06dc9eded60c8187.png"},26740:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2015-07-29-06.03.04-a4188b82d910c03087d7a763cf11b6fa.webp"},69599:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2015-07-30-20.21.19-fe572a5ad387af4abc3b9457cfb6606e.webp"},57950:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/mind-equals-blown-342005173a8a84b38b9df2d94f463b6a.gif"},86686:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2015-09-23-05.51.14-b45da704dfc6d06b1a9cd3e9c0e68d08.webp"},84583:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/tumblr_mxjpcobvcg...6_r2_250-4abb938-089317fff1ed86c364efad9d63daf226.gif"},88583:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/EditBuildConfiguration-f967bc792fa4fb8b3e392a6a028fc70b.webp"},7468:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2016-03-17-06.17.03-2893dbf39737fcb340044d562e45b844.webp"},66148:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2016-03-17-06.17.53-82d1d84d2d9419946054e4583418bf35.webp"},19888:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2016-03-17-06.23.18-a04b7e7a459702da3c3461c5ad209632.webp"},83440:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/caretaker-eb218d7ebab47b302dee1cbda583767d.webp"},64857:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-james-brantly-tweet-a4b55993bc177856d93e7208e57ec246.webp"},13106:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-f69532762e50de029ad89ccbf1e3a55f.png"},15994:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/beingjohnm-fab70161af7577ca61c664373794b401.webp"},79080:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/documentation-is-for-wimps-7c864a1ff7b36ddc74fdf5d76a146311.webp"},50391:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2017-01-29-14.45.57-c944026441e54615ecd30d05a3850879.webp"},69904:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/firstgo-6ca57e5f2c4f6099896ab9461625e4f7.webp"},12313:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/secondgo-f682959513f67dc34adb0a717122c5a5.webp"},85941:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2017-05-20-05.58.54-76d3c078e451088831481b0afab9cd0e.webp"},85968:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2017-06-11-15.05.47-f5f66f1e872d5d6b35858ea6903cbc6c.webp"},71794:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/KITT-3469e8898ad54c053362ec457b08d1cb.webp"},6494:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/webkitt-ad4cd5a70afa0ad74caa4cf9e4b60028.webp"},24901:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2017-09-12-06.12.25-9cd139a9749bbda7fddd886baddfb66f.webp"},50080:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2017-09-12-06.35.48-c91b2e9793b84bc772c93f9863362e4f.webp"},40900:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/one-definition-to-rule-them-all-d818d30587f50c0d0b031f572d382da0.webp"},81780:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2017-11-19-18.29.15-0620d7597f3405c271ea4d7bfc8fdd95.webp"},52831:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2017-11-19-18.34.12-1889a0eb044fdbb8918d0a60cb12f025.webp"},29307:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2017-11-19-20.05.19-5b7acec4d982478cae87750781988ae6.webp"},43344:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2017-11-19-21.34.54-8a4212758f8e61e3f2d74c61ddfad33a.webp"},48714:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2017-11-19-21.55.18-71429ecadce9e985a46d89c9a5ea8405.webp"},54936:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2017-11-19-22.01.37-2d5633f29beb11cfd5845f54e29d8907.webp"},35585:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Brooooooklyn-745ec304e54219f9adba0d8e752dcd71.jpg"},24764:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/HerringtonDarkholme-f2fce8de129c0b80759792dbf4e5c069.jpg"},6464:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Igorbek-e67cd1bb4014726ad252e0e138f0b9fe.jpg"},44402:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Loilo-90cad0819f6e79ea3f49e88f842b3a35.jpg"},63028:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Pajn-bb659024be4d59ebc8fa104187dbb263.jpg"},15478:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Venryx-86870969ae336940a8dffec79a0b180f.jpg"},45041:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/WillMartin-519b59cb48536ba7feb850ea2dbb74db.jpg"},28486:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/aindlq-012d25f39201c4fd91343f3263969e2e.jpg"},57549:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/bancek-f295be63486265ce2b3e5115ed10cfd7.jpg"},16220:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/bsouthga-fb8872b613e57f2cfd832735ce67a472.jpg"},50728:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/christiantinauer-e20781c9f130926ea882f696d17c43a4.jpg"},86822:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/develar-27486201a76c6f98bf91081f35891fe3.jpg"},49642:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/donaldpipowitch-a5937a30bdea498be3ed90861924ac2e.jpg"},28101:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/false-3104cfe0e5d5187354b06bfa4b9f6970.jpg"},88564:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/jbrantly-b874296070feff3df886bc9ef73abe7c.jpg"},25499:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/johnnyreilly-55164b100e9193a09ca40addec824856.jpg"},17951:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/ldrick-a92d84244aa67415765f562724829c8b.jpg"},95590:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/longlho-984563761a707461d513b21963e95c51.jpg"},46654:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/maier49-1f675e571374adf6394c8aa53888b66d.jpg"},94178:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/mattlewis92-ff291934668bad8b16c44c5966986864.jpg"},90603:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/mengxy-d631a8727a808f778bea460c62e5ac15.jpg"},82921:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/mredbishop-2268349ff5d6da975db607c9ce434824.jpg"},71331:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/octref-acb3e243d993255334a3648c25a7a3be.jpg"},34296:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/rhyek-c69b3383fc98d3cdf4557142eea8913f.jpg"},18230:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/roddypratt-e92c97d22cc2fec377deebc02c918678.jpg"},96512:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/schmuli-b4b484cd66e8963ce2deed2ffbdd31f2.jpg"},38568:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/sokra-4e993375add960813bc9b7513876a266.jpg"},27368:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/vhqtvn-6bb8f7265a04a4b0c1640eddd0d07dd3.jpg"},830:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/wearymonkey-3a361cce6182fb309925bf2819cbb86c.jpg"},50798:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/zinserjan-1eff723e89aded196f611775f81af48a.jpg"},68429:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2018-01-13-18.40.21-9e4bddb4a95e03eb4b5a21987952430f.webp"},94803:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2018-01-13-18.47.49-80755d76b228c7780aebfecaee13b7aa.webp"},77803:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2018-01-14-08.26.54-f554dafaf6445ce38c41dbe0c3ff2bd6.webp"},94210:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2018-01-14-08.32.59-0ffd1e9829f22749d13b62be0cc276e6.webp"},81430:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Bestival_2008_Increase_the_Peace_banner-428c52e0523068a2ea587d34f0a67d05.webp"},16585:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/vsts-screenshot-of-copy-to-clipboard-432e25d124ec728e2c87f15bc5342fb8.png"},75673:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/vsts-screenshot-of-restore-task-ed31dbd3e6bc7371f80325fbdf1ed9b0.webp"},13030:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2018-06-24-08.59.00-39910cf309f5075fbcc553017f211e57.webp"},55915:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2018-06-24-09.02.22-30c819c9fdb520aab7ef9251a53fe9d2.webp"},51076:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Screenshot-2018-06-24-10.55.27-36e07c6dfcf7c2496dab97504c0e81bc.webp"},24557:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/auth0-enable-password-grant-type-8ee502754568e2a02f38de706c4cfdb7.webp"},33269:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/appservice_classic-7949df2dfffa3df9e73d643cd6bc1d3b.webp"},72270:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/appservice_colons_fine-f02bf4ae673e1605e0a683ff525af590.png"},90357:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/appservice_container_colons_bad-9cac2407b620440ced783f7350707e1d.webp"},59183:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/i-must-break-you-6212db0b9e54e386eb08a58d0e170dd1.webp"},95299:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/yarn-outdated-68e521f76ff8178b2583d6742ac7595f.webp"},29825:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/not-so-sure-about-this-feedback-c6e981576bf5de4242d207126dec3474.webp"},75760:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/we-dug-this-feedback-0f78960b3b088cbd43c43bab2d589b0c.webp"},97023:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/ts-profile2-4c5d8cf4610f69e36465d4ec955ae94a.webp"},64251:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/hang-on-lads-ive-got-a-great-idea-1f149b8af4aa7df5f8b7f66965781ceb.webp"},55337:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/DOM-massive-9ed81ff6de342d3ac926256f9a8865f0.webp"},62702:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/play-codesandbox-d27ff822b6a759948e7d790b8062e14c.svg"},33118:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/RTL-9.1.1-c05d16d3b7193ffdf9e5bfc2debc980f.webp"},60746:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/RTL-9.1.2-4958d9388edcebc443db644b11100c15.webp"},3141:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/hang-on-lads-ive-got-a-great-idea-d944cc3f086e9be5f2bab9d4b8d005dc.webp"},4689:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Initial-CommitsDefinitelyTyped-6f420450b502196e44fed48cf90c6207.webp"},79713:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/RyansDefTypReport-a81666ab9d382d4f4aedd39a7a8db100.webp"},22361:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/TypeScriptTeam-181c6a5b9476942673836ebba64b3c71.webp"},98556:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/basarat-e12eb55f89189e4215163854e7ba1e91.webp"},97121:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/blake_embrey-b0baf565efb8af95bb8cfe7c3f28c0a9.webp"},25431:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/boris_yankov-8b0747a93bd6e7fb2fb1beb0f8e01bbf.webp"},25236:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/dt-logo-smallish-2447f9d52bd33ab5014d1a093ea38f64.webp"},74999:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/johnny_reilly-8b93d5d08788627bba02a622f8ad9246.webp"},88396:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/masahiro_wakame-4fe42c460705933ebb1dbc1ff5e4c695.webp"},39334:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/rotation-423d4bf6534c96e29ff61850e7463076.png"},14448:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/steveognibe-e3f548e80e07087f2b5bda25a13d11cf.webp"},22653:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-e4607503e793a8995512874fdf05d838.png"},87399:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/twitter-direct-message-from-basarat-2b5ab0647e04111145ac1de1f964ab41.webp"},76473:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/types20goinggreen-4fb96268e21b3dff94f7650c9a81ec32.webp"},58991:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/typings-1908a24df9419674fbb4934aaf660c94.webp"},54670:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/typings_typescript_collaboration-84c77b9519a18a1219d62256e37a2841.webp"},65586:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/teams-notification-5470b24212a79f0803965fe07a66a935.gif"},27544:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/teams-webhook-connector-0b0449a31c3fde572e975f476cbcbaf0.gif"},4543:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/LICENSE-cannot-be-cached-cdad74cbc2bb62a0b33f523c5f81c5e6.webp"},40204:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/LICENSE-file-screwing-me-over-7850432a918679c3d1ff5ad3d684b683.webp"},32750:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/netlify-auth-ebb38ba8e4c2406c18a9b6c9c0916850.webp"},57825:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/netlify-deploy-settings-b216b60069104b1f2d0a2bde1eae9bf2.png"},14900:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/netlify-deployed-0cc133e3e018c3459313b421df49bd3d.webp"},54740:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/netlify-repo-permissions-a7b98bace45f710db8a6a4750c1f5fdc.webp"},36003:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/pwa-audit-7f7fc3c4f706cae6533e3519a65040f6.png"},77670:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/blocking-react-44a9a66bd37610a072f0e929b6998e6d.gif"},87544:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/blocking-965713b34266d77b0c9a9d03b4bdd772.gif"},86124:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/non-blocking-react-aa1265a0c8b82278544358197e1a5d67.gif"},51026:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/non-blocking-2da0a00a6cf9dda57e1b373aefb06b64.gif"},75148:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/robski-dynamic-auth-b50b7efd118b1c8ed1297a010749e0f4.webp"},75271:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/hello_world_idb_keyval-49f89525ce6991f4e81e29b8a4054cae.webp"},98321:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/use-dark-mode-with-idb-keyval-178802eeeaf5455bb3feaa276468f0a5.gif"},73797:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/use-dark-mode-b394c50948f78181757868747195ac95.gif"},17806:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/autofac-webapplicationfactory-tests-7bba4e24108831728e50363688060494.webp"},50721:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/autofac-integration-tests-7eae6e7477002b42a76517fc1c85313b.webp"},28672:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-6b35feaf96ec67a0727126df6e4c3081.png"},51593:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/blogging-devs-e9b6ca6c427832fe283ccae4acfa9a64.gif"},84774:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/i-want-it-all-with-hook-b0c4e380859556daa50e13bc35109275.gif"},65521:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/i-want-it-all-41ce87fdb0503ffa4e8e22e0c68d97fa.gif"},94120:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/azure-devops-marketplace-1bdb3a833d6a0e48a6c8840314143902.webp"},99028:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/AccessDenied-8f7fe7a5efb19bea55dcae3920dce906.webp"},34929:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/Forbidden-300fbe3de9f26ca1e8cfd55ee6cbd806.webp"},87158:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-7fc4956ba503155ee49cece0524868fc.png"},45981:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/test-and-publish-steps-6dd5225a40e251de11981f8c2742f43c.png"},26693:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/test-results-632037432512f69b74332d1e7b19a97f.webp"},13630:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/strongly-typing-usequeries-f119af57c2df5e76f0d8c31836806c62.webp"},25418:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/about-page-770705599a33cec4e60eb1f6442b1832.png"},94754:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/api-build-screenshot-361f0ca3aa93a3340fdce01739fd0ef4.png"},45074:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/application-insights-properties-4e13662317205327d8f3bac2b4729e08.webp"},75818:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/coloured-console-b9e2a0d37ebe73e8434cd06937b5ce16.png"},54072:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-ba106de0d9e9a8f0299795d40b17e087.png"},98941:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/with-great-power-comes-great-responsibility-eb047ce82cd828af159a5a72536dcc60.webp"},34010:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/app-service-with-slots-and-build-number-0f5ae4841544e4192ed19075775ba2fa.png"},15402:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/app-service-with-slots-bdbc420150a05a222ec247beeeda469f.png"},75531:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/health-check-failure-diagram-09ee3a02f74f2d594fbfd235aec3efaa.webp"},18676:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/easy-auth-zero-downtime-deployment-d8f0e5334be29100329883e0cbacc7b1.webp"},44717:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/token-77748db651b8d338a8d98a693bdb4ede.webp"},99166:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/data-protection-zero-downtime-9d20eed45f88922baca6bafa0ede8b65.png"},42135:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/traffic-to-app-service-431500979c75ac598fca93286ac657d1.png"},73812:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/swagger-44c75962c8d5a84333bfbcd776308ad9.webp"},47350:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/use-generated-client-68121118d8862aee3faf83860aeb6de9.gif"},43403:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/entity-framework-core-nuget-2e0e4c9d7a78d3028ccf7353c62e3dac.png"},88439:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/managed-identity-object-id-3da5c83d54dee3a1bd11a6c97b3efa88.webp"},80854:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/blogs-as-markdown-d0ae123f276e854e30d80d1cfb718b19.webp"},28240:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/docusaurus-8b2bed4be1119e96fdf8bb904f9b5544.png"},13336:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-blogger-back-up-content-1e3143c50e03cdd358fc5799e47206d6.webp"},14276:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-cloudflare-atom-page-rule-e714fa217e8c219707c3ddb3045c28d1.png"},46683:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-cloudflare-dns-1a04ccc6aa59c857f479478f2f199bf6.webp"},37201:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-do-we-need-comments-josh-goldberg-9756ecd1d9860971b2213217602a497e.webp"},11895:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-31fddaf140ebaed7130acb4c09ee165b.png"},53051:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/rss-cc693369b8222014cab67c9ff5b2b3b8.png"},79696:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/bicep-in-a-pipeline-9d105c451a17132adcaf8403e587857b.png"},81474:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/bicep-meet-azure-pipelines-395092edba2730e38d21373a36d96e28.webp"},79530:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/azure-pipeline-with-bicep-e95ad282dc1ec2774dba4e3645d20bbc.png"},80029:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/bicep-meet-azure-pipelines-395092edba2730e38d21373a36d96e28.webp"},60703:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/hello-world-bicep-8b4ddbfc7322a7fb3929ac871f62607b.webp"},94045:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/ts-loader-9-414595577372387f39261670825dc882.png"},31527:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/ts-ervice-now-2574e7b8c34954ee44997d3766ff8aa8.png"},84011:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/blogger-blog-archive-small-c9dea0bee98e3cb7e45f56eddff28435.webp"},72567:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/docusaurus-blog-archive-f9281238fad82398a8dacf083f802c2c.png"},77347:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/require.context-dc18c038f7100a816deea61f47c7ab50.png"},52960:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/new-pipeline-af7c998d7c1ce67f30ffee8756145e81.webp"},84213:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/dev-container-start-3af06d7f824b78f55827d683962fe5be.gif"},38637:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/gettodaysvisits-dcbd78683a30f8294b718d3af86d62f1.png"},82785:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/savevisits-a8d90f0716f36cad91c8b791242352b7.png"},27809:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/application-settings-03a89ec8679efd18aa79e3793c61647e.png"},28061:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-8c454e88184cf532ac81230927060f90.png"},8314:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/createNode-error-fc2359bd913fb3297a9236a0ffc81fd7.png"},78908:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/null_is_not_assignable-error-0a911a8777a58062f2957139ea2c5aab.png"},52716:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/calling-hello-record-3718d7a642315632d15fced0638c9489.webp"},60062:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/debugging-hello-record-086ac36a5a8c21883decfe20bb16a0a8.png"},49167:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/dotnet-functions-roadmap-4f8c92dc82df396648ea7e3d35ef61ac.webp"},63830:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-b8b84348dde4a80d4de091c908ecc77d.png"},10362:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/event-hub-connection-string-c332b535fe5ae987d0b5095cbc7e08de.webp"},10108:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/storage-account-access-keys-eb71c62a744303169c7c0679f95bd9e5.png"},47088:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-674ca0e9fcf44f133fd835cefe4888e2.png"},19895:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/create-react-app-esbuild-af4fcbde4d8ddda49c2536d4dda5f20a.png"},19960:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/create-react-app-raw-80ae6b3dc408f0f9a4843b85dfafb4bd.png"},87690:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/webpack-esbuild-why-not-both-1cec8624b8b0d5d595ea480a78dcd638.webp"},2898:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/daniel-earwicker-tweet-e28ea936a83541e26ef0810214f8fe9f.png"},32172:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-2b4a386c34040c43329911cbc5e99384.png"},10489:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/vs-code-abstract-screenshot-aff89651ee4a8e45696b778b00b02c05.png"},3597:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/vs-code-new-constructor-075f84da6bb40b23f7fc1f8b28efdda6.png"},57773:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/vs-code-no-new-constructor-f0198ea24fe5d3bed575ef8f17baec6e.webp"},71276:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/does-work-in-typescript-4-4-b6092c470006483598bfd553beed8b18.png"},86243:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/doesnt-work-in-typescript-4-3-5d22493977b52f1fcba86b544437563d.png"},92688:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/reactions-on-github-b46c49a7de3c4208a65afd71691e2b0f.webp"},96731:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/reactions-on-twitter-c940bf1cec864927e25ce805d6a03999.webp"},92051:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/deployed-azure-static-web-app-screenshot-ffb2d909dc180d9eeca7093df08e0ab4.png"},70563:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/successful-azure-pipelines-run-screenshot-2307f958e834b2e8fa65ba0c158e5098.png"},82116:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-2f09fb58fbc23a5988344f6bb4334136.png"},33377:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/bicep-syntax-highlighting-with-prismjs-2993a202461d4ae1cd52d7b8e91dba1c.webp"},53254:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/app-registration-60776596c3236539cc77a675eded9682.png"},12715:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/auth-code-3b4611936fd3bc6fc0f983340f536e4d.png"},66320:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/calendars-response-150fac6b78879b2f74e712de04ce959a.png"},20395:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/create-credentials-6a08c402f494192c188402c58923b0ea.png"},39189:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/create-oauth-client-id-type-aaf200142cb69ae168cf53beab122323.png"},81712:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/google-cloud-platform-create-project-ca240da4fd0c896d3f0f773d5dce907c.png"},81531:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/grant-consent-e4e7bb0642475e4f3ef9f369946722f1.png"},62e3:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/oauth-client-id-ca53eee5c7e7d7b775b3e4330e97c19d.png"},22143:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/oauth-consent-screen-3edda5b2ba3dcbae0205dca7269eb84d.png"},69862:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-devops-service-connection-623de8f6bdeea63957be924cd7255b42.webp"},64967:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-pipelines-tests-passing-762e135c23ea73f4ef7923e135467810.png"},37001:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-add-role-assignment-member-65e88913e7113f4ab4b4a5cc91245bd2.png"},85098:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-add-role-assignment-aeea44597b09df30017a3c706b0fc2a0.png"},72653:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-service-principal-access-control-e4a7c068872b8b6d43cd95badae9ffca.png"},64664:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-service-principal-2fc73899429ae3d2c20d658c9f8098ab.png"},88630:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-subscription-resource-providers-76f58d02bc0b369b0ff3925b9dacfa15.webp"},55513:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-46cc8f39c57972b35cd9c539259b88f4.png"},18608:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-article-82544e2af127c1a0781739707a0c6ae2.png"},86373:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-rich-results-tool-test-0c61f465c48ee530d7bcd58e0bb9ae0c.webp"},61889:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-rich-results-tool-c43fa464de447d64bd384b5558231081.png"},53415:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-rich-text-results-c65673aef62ffa06091ad78fe31a6b64.webp"},7896:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/single-structured-data-as-JSON-d61f2d9d830f8ddf8b9019d09c1e2030.png"},32440:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/structured-data-in-action-b581410fb74cdde241c1fe9e52a13ef6.png"},53008:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-cc0f8426fd87354ed6a8b36ae06df06d.png"},70135:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-discover-in-search-console-880ad7102bdcdd9d312ce3cbe4401621.webp"},66792:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-meta-tag-33de29c356c69f2f6b1a36136def8bee.png"},96879:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-89f64976a72959cfb5d586dc83063a14.png"},56910:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-9d10b6aaac2d152813dbc2d20789b6b7.png"},87550:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-availability-4639f627993291117dc4b932a56b6415.png"},44013:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-deployments-resource-should-exist-in-the-same-resource-group-190e7c644667cf344f9895d2f01bab96.webp"},58406:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-90f6b7716712d9f72a72a2d0895cb8f7.png"},32775:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-2ec6e22ec68ab3c6e2ba401177bf6015.png"},72207:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-deploy-preview-small-5b1bd0616fb5dfda77cbeeedb01d0d05.png"},95234:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-deploy-preview-a0e8a35d7e11252b8ae55d8563fcb80d.webp"},51498:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-git-repository-security-settings-61266ccedec8b6f4c77397e7ac51cc04.webp"},47200:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-netlify-deploy-preview-in-pull-request-2cac9529fbd9078beb5f4adc5167ca4d.png"},52736:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-staging-environments-not-available-yet-5ef7010067aa4a349807721b6dcd8307.png"},54797:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-6c24f801b948bdab6196e7c45155411d.png"},74018:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-demo-with-devtools-open-9175e0caae087e98546c1e36cfaf80d2.png"},33244:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-email-demonstrating-sharing-with-a-non-cropped-image-2ddbdec0484bd20393753981ad31b8b5.png"},19131:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-tweet-demonstrating-sharing-with-a-cropped-image-a4bf32936840d57d732941e377b80935.webp"},6981:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-tweet-demonstrating-sharing-422aa4496f18dff26a505a6222cff97d.webp"},1437:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-twitter-validator-54e216720b96b80c77d13328a8416ccb.webp"},7092:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-82d942edc0e083dd6a80c07e40e68b3f.png"},11719:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-container-app-626731be670f8d3df0473c24245c1264.png"},62767:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-github-secrets-0301b0c474cce2035eda58d8f4c1cc2d.webp"},52713:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-running-container-app-9c2faf56fe8f79d635d7365293bc823a.png"},79984:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-7a669054be446a898a58586c2b1d466d.png"},37300:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-container-app-url-5bea8416dd5cb87d01a310bdb78ffd3c.png"},19774:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-container-app-49e8c53b98212824e2d1bdc70f2cee58.png"},7262:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-github-secrets-3033a56320387aa46bc91fdf09828bcb.png"},31702:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-7df6bacd073b7bc881e2ae3c4512f415.png"},79665:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-deployment-outputs-ef95ea65dbbc38a67a5734b878d26579.png"},2393:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-9d464523ef4bead98a36a95e5c569945.png"},6935:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-preload-devtools-627f8f6610d2f2df248ee9f37bef04a8.png"},51659:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-64c2d7d4d97b32cb04d677c3b63f4460.png"},50702:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/app-running-f560d14fbaf0900443be72da0e2531a7.png"},4187:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/dapr-sidecar.drawio-eab5aa6a6db152b2d4b5dc0a2ee50cc2.svg"},35541:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/debugging-660bb23b8958f3362aac922d0a188a9a.png"},52684:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-container-app-9b737cce4d0bdd153a640ce08538cb4f.png"},42643:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-resource-group-b64514fc0f1f74a4c50a2fa94f13d5c2.png"},7175:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-github-secrets-29ef6fe4f7b252562e7a9130dcb05f7c.png"},23770:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-working-app-2e37ea9245120191848855f9ca826399.png"},565:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-ce3537156e15ded6dd344102c8a164b7.png"},39318:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/cloudflare-dns-cname-74c273890645a831bf2fa49f3bde5938.png"},50088:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/cloudflare-dns-d9df7cafd40c6388e97edda262be7b08.png"},33499:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/custom-domain-code-validated-8e721890979ebf0d5823de0edbcebfee.png"},78380:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/custom-domain-code-64901834ff6f7a170af783107c9fa592.png"},20876:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/custom-domain-c95f2521026a77cc61ab80762729a016.png"},36285:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-ad58fe39a1ddaa20c7531b54ca75e98b.png"},97386:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-chrome-devtools-showing-only-onscreen-images-loaded-a96686c6db91d40a25052e0960b80f4c.png"},97854:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-img-loading-lazy-element-3ac644b9a2be213dd60d46755535562c.png"},66308:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-3cda6484d06c3541fb8da68e96e133ce.png"},59943:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-create-a-resource-dialog-repo-a2de23b7816aec676ed4ff67d8ad050b.png"},198:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-create-a-resource-dialog-e673221e269c82a9827c07084ae1216b.png"},7733:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-create-a-resource-c96b4cc01f5980cce0e35108319a9421.png"},22276:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-static-web-app-resource-environments-1bcff031a37577bd59bbed46f0c27699.png"},6962:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-static-web-app-resource-aeb5bad8b5e9a499469c9816398670db.png"},3689:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-github-action-37011d8698869ba4b04a84fc5fe0c3af.png"},3735:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-github-pull-request-deploy-preview-dc7d94503a04d87d62a4d862937412a9.png"},51594:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-static-web-app-devtools-me-6697fe8eaf0101940022da23f53ee984.png"},63073:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-static-web-app-logged-in-e8adf36cea4a79badc437f5c54a137d9.png"},97578:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-static-web-app-login-github-48c74b198021cce9eaa978d85e85dbb9.png"},11402:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-static-web-app-login-3000a60604403556485f63c37b6cda49.png"},46230:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-static-web-app-818eff8dedecdbba13d53408c97b2494.png"},81410:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-initial-swagger-ui-bd6fdb1604bb88f69a25f6419618eaf4.png"},45752:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-swagger-ui-with-location-47ddbace31520c3ec84fc570bbde9aa6.png"},19251:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-cb268ba4b2458174c1b6f43e85ea82a3.png"},97541:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-create-a-resource-dialog-repo-30e69b65ef18951c83d5da76db4a3e63.png"},40494:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-create-a-resource-dialog-268b26c4cae1910b5389c1669e40224c.png"},14748:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-create-a-resource-669ec9b2896df1cceff60ed97e143ee0.png"},69271:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-static-web-app-custom-domain-01c5006416e2f32e8abd7d6ad5b63660.png"},6723:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-static-web-app-resource-74134a8113e6cd6bba5eb0501d2a3467.png"},18611:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-static-web-app-rg-location-365ddb7efff78cb93200df17397e262a.png"},2858:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-github-action-50c36cec629e143cce5556963112c43d.png"},56693:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-lighthouse-github-comment-2ec95ab3ae5a917a152b89f1aa54e74d.png"},9227:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-lighthouse-report-b0bbf2eae9955184266ebd7bd3c09e98.png"},38666:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-static-web-app-2c0d50f760d773a40c145cd79e6c4546.png"},48203:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-71d327509012cdc524b03e49eb12bba8.png"},84814:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-ea584a1fdea0e34de9d5662fbc8cbb42.png"},73717:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-extra-problems-as-errors-753de9462785f55b91272b8b0dfb9983.png"},83825:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-extra-problems-622e7c587e2a7dc14e3a4263d08aed77.png"},67646:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-information-as-warning-5e8dd5f493f8f7031ef721f1fe5d5604.png"},59541:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-initial-problems-d207f6c0d2dca332da0080fde9c75cd8.png"},28144:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-vs-code-restart-omnisharp-858fcfe240064dc4edec6eeba3f919b0.png"},36803:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-vs-code-settings-enable-f4ba085cb894787c5241d94f62aeb3f0.png"},47452:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-87463977cb164b6169999f94ac2e9988.png"},38889:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-types-in-the-chrome-console-2f656d1328f435bddf88bb8b66369847.png"},55485:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-84ae91cde9aba574acfb0a7501676727.png"},85885:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-codemod-in-action-82e961f8e497535e5c5bb07235ea3ace.png"},12330:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-no-children-d7923b56dd33dd95c0dc45ebea500805.png"},51871:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-4dd9b1a8a94b8d60d914d0a504c6f9e2.png"},9413:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/both-environments-b890794a924a785bb1624c0df66fa1f1.gif"},21041:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-azure-pipeline-main-deployment-a76135fdbb4c2e010bd4562fab9a9fea.png"},20161:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-azure-pipeline-preview-deployment-31a4f6a54877fa3821190e629d01b081.png"},81648:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-main-static-web-app-950a25d4b231ffc8668cdf6a9b7ce9bb.png"},39517:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-preview-static-web-app-d2ab822989018ad0c005e5496792f62a.png"},88461:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-44b5814dcf8723af68514dd3807b577a.png"},90764:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-b683e623552cedc511247615df08535b.png"},76198:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-output-files-9909cf81f2820eb8cb1148d3d3186866.png"},62289:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-51300ba4c5cfd4700a16f915bbbe51d2.png"},52879:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/demo-send-email-with-pubsub-42a65d1ab700b6145f6e994f87806c9f.gif"},79924:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/demo-send-email-8b9d6fdfb4709356c1b32bb2bfa592ee.gif"},87826:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-github-secrets-c7d53c9822c48d0f16997a6470264d0b.png"},48150:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-1083426a9aa76352a87988e08d382718.png"},13634:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-azure-pipelines-failed-to-deploy-the-azure-functions-86d1adddaa73e4eee962c628e749e26a.png"},39921:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-azure-portal-with-environmentid-1a64eee108bb5b609ed4fd1adf8e0e8f.png"},47773:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-83f3f66f91b04b5ee4578663e73054c8.png"},49265:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-f73e7c9a5db1270af6e9e8fe22260b5f.png"},2812:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-x-clacks-overhead-listing-dbaf746588db96b70af164799bfd6585.png"},33431:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-x-clacks-overhead-response-header-3064ead5b8d6d77be6ed3f158e316cd1.png"},42284:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-68b48b13ddbedca6210b5aafbe89f3c3.png"},46432:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-a19b6b9e1f30eedcfcdf6c06e664f63f.png"},39405:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-application-insights-overview-ab9b002ad2d38bfd7f73ed221c9df952.png"},74470:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-application-insights-transaction-search-d83ae6f0d987fad63200bdfa60dcd9fa.png"},54524:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-266dde76087b5bc181fc9bf730d1a868.png"},91690:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-1469e6c4ff5cb686cb1dd8ef0ed1e653.png"},14522:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-jest-debug-test-df3894e357383bcdfedfcaf1133309ce.png"},45740:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-jest-start-all-runners-f2b658005aaa5058e5f53945e1833477.png"},89574:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-jest-test-explorer-debug-test-e30494b6c7a343a98d906d146984f9b4.png"},61886:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-jest-test-explorer-cf9d396c8212b3a48beb40625b8585f3.png"},83914:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-tests-passing-0b849ef654b02c80b48a2d969237213b.png"},58584:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-of-vscode-jest-d8ec4174a380e090da1608f22f7dde0d.png"},41427:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-0e63c04f8d1675d5dde527914ccc9f7f.png"},21018:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-linked-backend-f49e3a6cfb38bfc7ad34bc22d4d942cf.webp"},70037:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-8c4c5f95e4f0573b835f4e894fc669e8.png"},74860:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/payment-pointer-ae4a756850e4fca7d32f296dad9e620e.gif"},45804:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-am-i-doing-it-right-alex-27c651fd0053f432b137cc2805b51005.webp"},30194:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-setting-up-coil-960e3802a49e0125ba13368ea66bb74e.png"},23020:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-uphold-dashboard-47ca0fa7370a47ed44ef05721bcdc244.webp"},56946:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-uphold-incoming-tip-e3bd13660b7ff467938c06d395f82a39.webp"},10741:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-uphold-purpose-56af442e7a5211cc2f724f41757cfbfe.webp"},50872:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-uphold-transfers-75d99c6d7c54a17c5170d639c7b5bf66.webp"},24205:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/tipping-with-coil-069f1e7a97b6d99d7bb342e0914990d4.gif"},76011:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-028eb91096f498f5204b8093116968ed.png"},55471:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-csharp-extension-vs-code-db10e4b244a489b94ba27076ddbfdf3b.webp"},73847:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-5df2b9bf726270716f542cfad893c18a.png"},26436:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-azure-ad-app-registration-api-permissions-2475b91d55370c463f10fc45a802996d.png"},32123:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-twitter-thomas-gauvin-support-in-future-0b27ec1d7904bd7e15c073d9065eb0e5.webp"},82274:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-bf4b643f03830f5f5ad3512d581138f3.png"},31250:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-993d3a3acf60b36d542817c2ea943ec7.png"},49716:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-83e5a8ec1684626cf7373c7c6c529fe4.png"},36078:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/my-jank-fixed-f960067f17761d5f1035bc6f25769826.gif"},76230:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/my-jank-fbb8a939013d450dfffd291689c434b7.gif"},37389:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-tweet-about-fontaine-f80170e8985fb12a76925230827bf2bc.webp"},54592:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-5aabb3a132e8d0b151a0e9f9cca01a25.png"},9532:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-16c274872bbe952c01d84fb9f277865b.png"},10293:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-devto-apikey-cacee8316051553f62a90adaca79a6f6.png"},66231:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-devto-published-posts-275f85e2536b3c9e2ac8fc85e3ae9f67.png"},24831:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-devto-publishing-rss-ad0658517234e6610941cdda10a43489.png"},3422:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-6d961844b168cc54d38548ca0fff8a93.png"},43662:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-79fba965babb965fc9084336814cfefc.png"},52606:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-redirect-in-chrome-devtools-6e20527e1021498c5e0dedec16153dfa.png"},13449:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-tweet-azure-function-redirect-16535320bd761808f4da0f64250fade3.webp"},84949:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-8e14b55a0d1eda8f92a7d486b1b3c664.png"},11028:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-cloudinary-allowed-fetch-domains-9738141317dcef4b0544627eaf6f964b.webp"},29130:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-cloudinary-restricted-6ff069b066155f452b45559594b4dbd1.webp"},25558:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-image-from-cloudinary-cb313fdeb91761d777ed1732f7c054c9.webp"},61016:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-934557b5733320b51dc0b371cf808e3a.png"},83262:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-application-insights-67bed4833a4aa1e00dcc759fcd094388.png"},65534:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-portal-application-insights-hidden-link-ae51a8aef4b8705b4a93b77c2fe518e8.webp"},76364:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-77c999aef8a2d4635e14bf29aa13b6c1.png"},26225:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-azure-pipelines-node-16-3eb58b25bf50cf0f3cb901d84779cc86.png"},3913:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-f76c725f0d8f48c86123fca4b5f0b2e6.png"},39576:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-ahrefs-spam-update-af7a8bd795f5f80ee5ed9b91a52e63bc.webp"},81664:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-application-insights-404-74d01b8261d32e20db3949856e0c3ee2.webp"},95076:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-docusaurus-g-tag-6febc3ec0a9593c70f1ae5f1bfa6db53.png"},88528:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-google-analytics-d5b72ebc10073b0adaf87160e2093585.png"},83590:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-referring-domains-fc1f2a38cb17f4adf911dacbabfd705d.webp"},77465:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-search-console-insights-43382286fa41f34d6f4e95f748714fdd.webp"},15194:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-1e3ac833283e88bed622002df4a9e229.png"},33224:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-largest-contentful-paint-image-fetchpriority-31cedb4594bb5ec65e5610145d329853.webp"},79193:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-largest-contentful-paint-image-lazy-loaded-d35874ba942d893ab14c16b5048c8567.webp"},24211:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-f8a29b4095d1ca4087fd83550d8b1b1c.png"},16631:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-files-after-optimisation-6f7e4394defa4ef63878ac29cb9638c2.png"},5881:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-files-before-optimisation-49a7947a0a404b61bce1b97d582dc75d.png"},96315:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-84b1568885dbbcdc1a7c97d1336b8558.webp"},27352:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-docusaurus-atom-feed-8d96893a0377d25aee230d6a0c32cc2a.webp"},27122:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-johnnyreilly-atom-feed-e1f421f90437f743937c3ce15e88b718.webp"},41283:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-tweet-createfeeditems-b20141fe97f47937eb9f59c63c8402f9.webp"},15978:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-e36109db4972b5cefaee9b5c417a3c39.png"},66959:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-google-rich-results-test-breadcrumbs-breakdown-7c784707aa30b741a8d1910abdd2738f.png"},40292:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-google-rich-results-test-breadcrumbs-11885edfb2bbd57f6a5b30155b6cae25.webp"},94712:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-google-search-console-breadcrumbs-7f4b06a345be9e6b2154662089fc79b5.webp"},52410:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-google-search-results-breadcrumbs-52876f7da35364e23a3e878bef810fd0.webp"},11954:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-e80a4fa94841330420bfb9d28d8d0f1e.png"},11513:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-collaborating-on-github-a8c20f7ff3bcd580383a88641785b468.png"},32175:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-tweet-code-reviews-and-pull-requests-c3ec9c76401084639fb0a49ae5972e49.webp"},58117:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-cf24b33baa2151fc67a3a16ee20cb9cb.png"},8016:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-44858975d62999ba0013697b9d10be4f.png"},42802:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-cannot-find-module-2c4a1e2ec791d0084998c18f3930a9bc.png"},68779:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-file-apis-bff7e0019757fd8bacbd8d36107b013a.png"},27476:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-tweet-fs-promises-exists-84f95682cf54e900231b5c959d974a95.png"},79436:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-59128fb2fcf34321698642211daaad26.png"},71380:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-github-action-7af9b984dec3f0c523afc6f657b1a3fc.webp"},15725:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/screenshot-playwright-test-results-78f3fe2fb01270d10997e1994849d8a9.png"},76102:(e,t,n)=>{"use strict";n.d(t,{Z:()=>a});const a=n.p+"assets/images/title-image-3374754db55f364cd0bce20c5ff1c2c4.png"}}]);